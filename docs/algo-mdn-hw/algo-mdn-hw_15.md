# 指令表

> 原文：[`en.algorithmica.org/hpc/pipelining/tables/`](https://en.algorithmica.org/hpc/pipelining/tables/)

执行阶段的交错是数字电子学中的一个通用概念，它不仅应用于主 CPU 流水线，还应用于单独的指令和内存层面。大多数执行单元都有自己的小型流水线，可以在前一个指令后的一个或两个周期内取另一个指令。

在这个背景下，使用两种不同的“成本”来衡量指令是有意义的：

+   *延迟*：需要多少周期才能收到指令的结果。

+   *吞吐量*：平均每个周期可以执行多少条指令。

您可以从称为[指令表](https://www.agner.org/optimize/instruction_tables.pdf)的特殊文档中获取特定架构的延迟和吞吐量数值。以下是我 Zen 2 的一些示例值（所有指定为 32 位操作数，如果有任何差异）：

| 指令 | 延迟 | RThroughput |
| --- | --- | --- |
| `jmp` | - | 2 |
| `mov r, r` | - | 1/4 |
| `mov r, m` | 4 | 1/2 |
| `mov m, r` | 3 | 1 |
| `add` | 1 | 1/3 |
| `cmp` | 1 | 1/4 |
| `popcnt` | 1 | 1/4 |
| `mul` | 3 | 1 |
| `div` | 13-28 | 13-28 |

一些注释：

+   由于我们的思维习惯于“更多”意味着“更差”的成本模型，因此人们主要使用吞吐量的倒数而不是吞吐量本身。

+   如果某个指令特别频繁，其执行单元可以被复制以增加其吞吐量——可能甚至超过一个，但不能超过解码宽度。

+   一些指令的延迟为 0。这意味着这些指令用于控制调度器，并不达到执行阶段。尽管如此，它们仍然具有非零的倒数吞吐量，因为 CPU 前端仍然需要处理它们。

+   大多数指令都是流水线的，如果它们具有倒数吞吐量 n，这通常意味着它们的执行单元可以在 n 个周期后（如果小于 1，这意味着有多个执行单元，所有这些单元都能在下个周期取另一个指令）。一个值得注意的例外是整数除法：它要么流水线非常差，要么根本不流水线。

+   一些指令的延迟是可变的，不仅取决于操作数的大小，还取决于操作数的值。对于内存操作（包括像`add`这样的融合操作），延迟通常指定为最佳情况（L1 缓存命中）。

还有更多重要的细节，但这个心理模型现在就足够了。

[无分支编程](https://en.algorithmica.org/hpc/pipelining/branchless/)[吞吐量计算 →](https://en.algorithmica.org/hpc/pipelining/throughput/)
