# IEEE 754 浮点数

> 原文：[`en.algorithmica.org/hpc/arithmetic/ieee-754/`](https://en.algorithmica.org/hpc/arithmetic/ieee-754/)

当我们设计我们的 DIY 浮点类型 时，我们省略了很多重要的细节：

+   我们为尾数和指数分配了多少位？

+   一个 `0` 符号位意味着 `+`，还是相反？

+   这些位是如何存储在内存中的？

+   我们如何表示 `0`？

+   四舍五入是如何发生的？

+   如果我们除以零会发生什么？

+   如果我们对一个负数开平方会发生什么？

+   如果我们增加最大的可表示数会发生什么？

+   我们能否以某种方式检测到上述三种情况中的任何一种发生了？

大多数早期的计算机不支持浮点运算，当供应商开始添加浮点协处理器时，他们对这些问题的答案有着略微不同的看法。不同的实现使得浮点运算难以可靠和可移植地使用——尤其是对于开发编译器的人来说。

在 1985 年，电气和电子工程师协会（Institute of Electrical and Electronics Engineers）发布了一个标准（称为 [IEEE 754](https://en.wikipedia.org/wiki/IEEE_754)），该标准提供了关于浮点数应该如何工作的正式规范，该规范很快被供应商采用，现在几乎所有的通用计算机都在使用。

## [#](https://en.algorithmica.org/hpc/arithmetic/ieee-754/#float-formats)浮点数格式

与我们手工实现的浮点数类似，硬件浮点数使用一个位表示符号，并使用可变数量的位表示指数和尾数部分。例如，标准的 32 位 `float` 编码使用第一个（最高位）位表示符号，接下来的 8 位表示指数，剩余的 23 位表示尾数。

![](img/4a38d9eb0e5ede2e39b6ada470654594.png)

它们以这种确切顺序存储的一个原因是因为比较和排序它们更容易：你可以使用与 无符号整数 相似的大部分比较器电路，除非在其中一个数是负数的情况下可能需要翻转一些位。

由于同样的原因，指数是**偏置的**：实际值比存储的无符号整数小 127，这使得我们也能覆盖小于一（带有负指数）的值。在上面的例子中：

$$ (-1)⁰ \times 2^{01111100_2 - 127} \times (1 + 2^{-2}) = 2^{124 - 127} \times 1.25 = \frac{1.25}{8} = 0.15625 $$

IEEE 754 和一些后续标准定义了不止一种表示方式，这些表示方式在大小上有所不同，最值得注意的是：

| 类型 | 符号 | 指数 | 尾数 | 总位数 | 近似十进制位数 |
| --- | --- | --- | --- | --- | --- |
| single | 1 | 8 | 23 | 32 | ~7.2 |
| double | 1 | 11 | 52 | 64 | ~15.9 |
| half | 1 | 5 | 10 | 16 | ~3.3 |
| extended | 1 | 15 | 64 | 80 | ~19.2 |
| quadruple | 1 | 15 | 112 | 128 | ~34.0 |
| bfloat16 | 1 | 8 | 7 | 16 | ~2.3 |

它们的可用性从芯片到芯片各不相同：

+   大多数 CPU 支持单精度和双精度——在 C 语言中，`float`和`double`类型就是指这些。

+   扩展格式仅适用于 x86 架构，在 C 语言中以`long double`类型提供，在 Arm CPU 上会回退到双精度。选择 64 位作为尾数位是为了确保每个`long long`整数都可以精确表示。还有一个 40 位格式，它同样分配了 32 位尾数位。

+   四倍精度以及 256 位的“八倍精度”格式仅用于特定的科学计算，并且不被通用硬件支持。

+   半精度算术只支持一小部分操作，通常用于机器学习等应用，尤其是神经网络，因为它们倾向于执行大量的计算，但不需要高精度。

+   半精度正在逐渐被 bfloat 取代，它通过牺牲 3 位尾数位来获得与单精度相同的范围，从而实现与它的互操作性。它主要被专用硬件采用：TPU、FGPA 和 GPU。这个名字代表“[大脑](https://en.wikipedia.org/wiki/Google_Brain)浮点数”。

低精度类型在移动时需要的内存带宽更少，通常在操作上需要的周期也更少（例如，除法指令可能需要$x$、$y$或$z$个周期，具体取决于类型），这就是为什么在容错允许的情况下，它们更受欢迎。

深度学习作为一个非常流行且计算密集型的领域，对低精度矩阵乘法产生了巨大的需求，这促使制造商开发专门的硬件，或者至少添加支持这些类型计算的特殊指令——最值得注意的是，谷歌开发了一种名为 TPU（张量处理单元）的定制芯片，专门用于乘以 128-by-128 的 bfloat 矩阵，以及英伟达在其所有较新的 GPU 中添加了“张量核心”，能够一次性执行 4-by-4 矩阵乘法。

除了大小之外，所有浮点类型之间的行为大多相同，我们现在将对此进行澄清。

## [#](https://en.algorithmica.org/hpc/arithmetic/ieee-754/#handling-corner-cases)处理边缘情况

整数算术处理边缘情况（如除以零）的默认方式是崩溃。

有时，软件崩溃反过来又会导致真正的物理损坏。1996 年，[阿丽亚娜 5 号](https://en.wikipedia.org/wiki/Ariane_5)（欧洲航天局用来将物体送入近地轨道的运载火箭）的首飞以[一次灾难性的爆炸](https://www.youtube.com/watch?v=gp_D8r-2hwk)告终，原因是由于在算术错误时中止计算的策略，在这种情况下是一个浮点数到整数的转换溢出，导致导航系统认为它偏离了航线，并进行了大的修正，最终导致价值 2 亿美元的火箭解体。

处理这类边缘情况，例如硬件中断，有优雅的方法：当发生异常时，CPU 会将异常传递给操作系统，操作系统随后会调用处理代码（如果存在“try-except”块）或者终止程序。

+   中断程序的执行；

+   将所有相关信息打包到一个称为“中断向量”的数据结构中；

+   程序将异常传递给操作系统，操作系统随后会调用处理代码（如果存在）或者终止程序。

这是一个复杂的机制，值得单独一篇文章来探讨，但既然这本书是关于性能的，你只需要知道的是，它们相当慢，在实时系统（如火箭导航）中并不理想。

### [#](https://en.algorithmica.org/hpc/arithmetic/ieee-754/#nans-zeros-and-infinities)NaNs，零和无穷大

浮点运算经常处理嘈杂的、现实世界的数据。在这些数据中，异常比整数情况中更常见，因此处理它们时的默认行为也不同。它们不会崩溃，而是用一个特殊值替换结果，而不会中断程序执行（除非程序员明确想要这样做）。

这种值的第一种类型是两种无穷大：一个正无穷和一个负无穷。当操作的结果无法在可表示的范围内表示时，它们会被生成，并且在算术中被这样处理。

$$ \begin{aligned} -∞ < x &< ∞ \\ ∞ + x &= ∞ \\ x ÷ ∞ &= 0 \end{aligned} $$ 如果我们除以零会发生什么？应该是正无穷还是负无穷？这个情况实际上是明确的，因为，不那么直观的是，也存在两个零：一个正零和一个负零。$$ \frac{1}{+0} = +∞ \;\;\;\; \frac{1}{-0} = -∞ $$

有趣的事实：`x + 0.0`不能折叠为`x`，但`x + (-0.0)`可以，因此负零比正零是一个更好的初始化值，因为它更有可能被编译器优化掉。`+0.0`不工作是因为 IEEE 规定`+0.0 + -0.0 == +0.0`，所以对于`x = -0.0`会给出错误的结果。两个零的存在经常导致这样的头疼问题——好消息是，如果你想禁用这种行为，可以向编译器传递`-fno-signed-zeros`。

零是通过将所有位设置为 0 来编码的，除了负数情况下的符号位。无穷大是通过将所有指数位设置为 1 并将所有尾数位设置为 0 来编码的，符号位区分正无穷和负无穷。

另一种类型是“非数字”（NaN），它是由于数学运算错误产生的：

$$ \log(-1),\; \arccos(1.01),\; ∞ − ∞,\; −∞ + ∞,\; 0 × ∞,\; 0 ÷ 0,\; ∞ ÷ ∞ $$

存在两种 NaN 类型：*信号 NaN*和*静默 NaN*。信号 NaN 会引发一个异常标志，这可能会或可能不会根据 FPU 配置立即引起硬件中断，而静默 NaN 则几乎在所有算术操作中传播，导致更多的 NaN 产生。

在二进制中，两个 NaN 都有全部的指数位被设置，而尾数部分不是全零（以区别无穷大）。请注意，对于 NaN 有非常多的有效编码。

## [#](https://en.algorithmica.org/hpc/arithmetic/ieee-754/#further-reading) 进一步阅读

如果你感兴趣，可以阅读经典文献 “[每位计算机科学家都应该了解的浮点运算](https://www.itu.dk/~sestoft/bachelor/IEEE754_article.pdf)” (1991) 以及介绍 Grisu3 的论文 [the paper introducing Grisu3](https://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf)，这是目前打印浮点数的最新技术。 [← 浮点数](https://en.algorithmica.org/hpc/arithmetic/float/)[舍入误差 →](https://en.algorithmica.org/hpc/arithmetic/errors/)
