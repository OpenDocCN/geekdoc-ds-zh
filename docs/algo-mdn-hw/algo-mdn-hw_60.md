# 指针替代方案

> 原文：[`en.algorithmica.org/hpc/cpu-cache/pointers/`](https://en.algorithmica.org/hpc/cpu-cache/pointers/)

在指针追逐基准测试中，为了简单起见，我们没有使用实际的指针，而是使用相对于基址的整数索引：

```cpp
for (int i = 0; i < N; i++)
    k = q[k]; 
```

x86 上的内存寻址运算符与地址计算融合，所以`k = q[k]`这一行折叠成一条简洁的指令，该指令还暗中执行乘以 4 和加法操作：

```cpp
mov rax, DWORD PTR q[0+rax*4] 
```

虽然完全融合，但这些额外的计算会给内存操作增加一些延迟。L1 缓存的读取延迟是 4 或 5 个周期——后者是我们需要执行地址的复杂计算时的情况。因此，排列基准测试测量每次跳跃 3 纳秒或 6 个周期：4+1 用于读取和地址计算，另一个用于将结果移动到正确的寄存器。

### [#](https://en.algorithmica.org/hpc/cpu-cache/pointers/#pointers)指针

如果我们用实际的指针替换“假指针”——索引，我们的基准测试可以稍微快一些。

在使“指针到指针到指针……”这样的结构正常工作方面存在一些语法问题，所以我们将定义一个结构体，它只是封装了指向其自身类型的指针——这正是大多数指针追逐的工作方式：

```cpp
struct node { node* ptr; }; 
```

现在我们随机填充我们的数组指针，然后追逐它们：

```cpp
node* k = q + p[N - 1];

for (int i = 0; i < N; i++)
    k = k->ptr = q + p[i];

for (int i = 0; i < N; i++)
    k = k->ptr; 
```

这段代码现在在适合 L1 缓存的数组上运行，每秒 2 纳秒/4 个周期。为什么不是 4+1=5？因为 Zen 2 [有一个有趣的功能](https://www.agner.org/forum/viewtopic.php?t=41)，它允许通过地址访问的数据零延迟重用，所以这里的“移动”是透明的，从而节省了整个两个周期。

不幸的是，在 64 位系统上存在一个问题，因为指针的大小加倍，使得数组比使用 32 位索引更早地溢出缓存。延迟与大小图看起来就像向左移动了一个二进制位——这正是它应该的样子：

![](img/056a930394d7fd4f3950099f1a65dbaf.png)

通过切换到 32 位模式可以减轻这个问题：

![](img/e7771d2e8d9297605c558166e3f8a705.png)

你需要费些周折才能获取 32 位库，以便在这台本世纪的计算机上运行，但这不应该引起其他问题，除非你需要与 64 位软件交互或访问超过 4G 的 RAM

### [#](https://en.algorithmica.org/hpc/cpu-cache/pointers/#bit-fields)位字段

在较大的问题规模上，性能瓶颈是内存而不是 CPU，这让我们可以尝试一些更奇怪的事情：我们可以使用少于 4 个字节来存储索引。这可以通过位字段来实现：

```cpp
struct __attribute__ ((packed)) node { int idx : 24; }; 
```

除了定义位字段的结构之外，你不需要做任何事情——编译器会自己处理 3 字节的整数：

```cpp
int k = p[N - 1];

for (int i = 0; i < N; i++) {
    k = q[k].idx = p[i];

for (int i = 0; i < N; i++) {
    k = q[k].idx; 
```

这段代码测量了 L1 缓存的 6.5ns。由于编译器选择的默认转换过程不是最优的，因此还有改进的空间。我们可以手动加载一个 4 字节整数并自行截断它（我们还需要向`q`数组中添加一个额外的元素以确保我们拥有那额外的 1 个字节内存）：

```cpp
k = *((int*) (q + k));
k &= ((1<<24) - 1); 
```

现在它运行在 4ns，并生成以下图表：

![](img/d921de7b5200b975d35a4ba6e4b6053c.png)

如果你足够接近地放大（图表是一个 svg），你会看到在非常小的数组上指针获胜，然后从大约 L2-L3 缓存边界开始，我们的自定义位字段接管，对于非常大的数组来说，这并不重要，因为我们无论如何也不会命中缓存。

这不是一种能给你带来 5 倍改进的优化，但仍然是在所有其他资源耗尽时值得一试的方法。[← 对齐和打包](https://en.algorithmica.org/hpc/cpu-cache/alignment/)[缓存关联性 →](https://en.algorithmica.org/hpc/cpu-cache/associativity/)
