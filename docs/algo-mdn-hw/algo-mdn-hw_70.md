# 自动向量化和 SPMD

> 原文：[`en.algorithmica.org/hpc/simd/auto-vectorization/`](https://en.algorithmica.org/hpc/simd/auto-vectorization/)

SIMD 并行性最常用于*令人尴尬的并行*计算：这种情况下，你只需对数组的所有元素应用一些逐元素函数，并将其写回其他地方。在这种设置中，你甚至不需要知道 SIMD 是如何工作的：编译器完全能够自行优化这样的循环——你只需要意识到这种优化存在，并且它通常会产生 5-10 倍的速度提升。

不采取任何行动，依赖自动向量化实际上是使用 SIMD 最流行的方式。事实上，在许多情况下，甚至建议坚持使用普通的标量代码，因为它简单且易于维护。

但通常，即使是看起来可以直接向量化的循环也可能因为一些技术细节而没有被优化。就像许多其他情况一样，编译器可能需要程序员提供一些额外的输入，因为程序员可能比从静态分析中推断出的更多了解问题。

### [#](https://en.algorithmica.org/hpc/simd/auto-vectorization/#potential-problems)潜在问题

考虑我们开始时的“a + b”示例：

```cpp
void sum(int *a, int *b, int *c, int n) {
    for (int i = 0; i < n; i++)
        c[i] = a[i] + b[i];
} 
```

让我们换位思考，想象一下当这个循环被向量化时可能会出什么问题。

**数组大小。**如果数组大小在事先未知，那么它可能太小，以至于向量化一开始就无益。即使它足够大，我们也需要在循环的剩余部分插入一个额外的检查来处理它标量，这将花费我们一个分支。

为了消除这些运行时检查，使用编译时常数的数组大小，并且最好将数组填充到最近的 SIMD 块大小的倍数。

**内存别名。**即使数组大小问题不存在，向量化这个循环也不总是技术上是正确的。例如，数组`a`和`c`可以以它们的开头相差一个位置的方式相交——因为谁知道，也许程序员想通过这种方式通过卷积计算斐波那契序列。在这种情况下，SIMD 块中的数据将相交，观察到的行为将与标量情况不同。

当编译器无法证明函数可能用于交集数组时，它必须生成两种实现变体——一个是向量化的，另一个是“安全的”——并插入运行时检查以在这两者之间进行选择。为了避免这些检查，我们可以通过添加`__restrict__`关键字来告诉编译器没有任何内存被别名化：

```cpp
void add(int * __restrict__ a, const int * __restrict__ b, int n) {
    for (int i = 0; i < n; i++)
        a[i] += b[i];
} 
```

另一种特定于 SIMD 的方法是“忽略向量依赖”指令。这是一种通用方式，用来通知编译器循环迭代之间没有依赖关系：

```cpp
#pragma GCC ivdep
for (int i = 0; i < n; i++)
    // ... 
```

**对齐。**编译器对这些数组的对齐情况一无所知，必须在开始向量化部分之前处理这些数组开头的一些元素，或者通过使用非对齐内存访问来潜在地损失一些性能。

为了帮助编译器消除这个特殊情况，我们可以在静态数组上使用`alignas`指定符，并使用`std::assume_aligned`函数来标记指针对齐。

**检查向量化是否发生。**在任何情况下，检查编译器是否按照你的意图向量化了循环都是有用的。你可以将其编译成汇编代码并查找以“v”开头的指令块，或者添加`-fopt-info-vec-optimized`编译器标志，以便编译器指示自动向量化发生的位置以及正在使用的 SIMD 宽度。如果你将`optimized`交换为`missed`或`all`，你也可能得到一些解释，说明为什么在其他地方没有发生。

有许多其他方法可以告诉编译器我们确切的意思，但在特别复杂的情况下——例如，当循环内部有很多分支或函数调用时——向下降低一个抽象级别并手动向量化会更简单。

### [#](https://en.algorithmica.org/hpc/simd/auto-vectorization/#spmd)SPMD

在自动向量化和手动使用 SIMD 内建函数之间有一个巧妙的折衷方案：“单程序，多数据”（SPMD）。这是一个计算模型，其中程序员编写看起来像是常规串行程序的内容，但实际上在硬件上并行执行。

编程体验在很大程度上是相同的，并且仍然存在一个基本限制，即计算必须是数据并行的，但 SPMD 确保无论编译器还是目标 CPU 架构如何，向量化都会发生。它还允许计算自动并行化到多个核心，在某些情况下，甚至可以卸载到其他类型的并行硬件。

一些现代语言（如[Julia](https://docs.julialang.org/en/v1/base/base/#Base.SimdLoop.@simd)）、多进程 API（如[OpenMP](https://www.openmp.org/spec-html/5.0/openmpsu42.html)）和专用编译器（如 Intel [ISPC](https://ispc.github.io/)）支持 SPMD，但在 GPU 编程的背景下，它取得了最大的成功，因为在这个环境中，问题和硬件都是高度并行的。

我们将在第二部分中更深入地介绍这个计算模型[← 寄存器级洗牌](https://en.algorithmica.org/hpc/simd/shuffling/)[→ 算法案例研究](https://en.algorithmica.org/hpc/algorithms/)
