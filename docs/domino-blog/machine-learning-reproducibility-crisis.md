# 机器学习再现性危机

> 原文：<https://www.dominodatalab.com/blog/machine-learning-reproducibility-crisis>

## 我们又回到黑暗时代了吗？没有源代码管理？

我最近和一个朋友聊天，他的初创公司的机器学习模型非常混乱，导致了严重的问题，因为他的团队试图建立在彼此的工作基础上，并与客户分享。即使是原作者有时也无法训练出相同的模型，得到相似的结果！他希望我有一个可以推荐的解决方案，但是我不得不承认，我在自己的工作中也遇到了同样的问题。这很难向没有与机器学习合作过的人解释，但在跟踪变化和从头重建模型方面，我们仍然回到了黑暗时代。这太糟糕了，有时感觉就像回到了没有源代码控制的时候。

当我在 90 年代中期开始专业编程时，跟踪和协作源代码的标准是微软的 Visual SourceSafe。为了让您体验一下这种体验，它没有原子签入，因此多人无法处理同一个文件，网络副本需要每夜扫描以避免神秘的损坏，即使这样也不能保证数据库在早上完好无损。不过我觉得很幸运，我面试过的一个地方有一整面墙的便利贴，树中的每个文件都有一个便利贴，编码人员在修改文件时会把它们拿下来，完成后再放回去！

## 走进黑暗的中心:在 ML 模型上的合作

这就是说，在版本控制方面，我不是一个害羞的人。我经历过一些糟糕的系统，如果有必要，我仍然可以使用 rsync 和 chicken wire 拼凑出一个解决方案。即使所有这些都过去了，我可以用手捂着心口说，机器学习是迄今为止我发现的最糟糕的合作和跟踪变化的环境。

为了解释为什么，这里有一个机器学习模型的典型生命周期:

*   一名研究人员决定尝试一种新的图像分类架构。
*   她复制并粘贴了以前项目中的一些代码，以处理她正在使用的数据集的输入。
*   该数据集位于网络上她的一个文件夹中。这可能是 ImageNet 下载的一个，但不清楚是哪一个。在某个时候，有人可能删除了一些实际上不是 JPEGs 的图像，或者做了其他小的修改，但没有这方面的历史记录。
*   她尝试了许多略有不同的想法，修复错误并调整算法。这些变化发生在她的本地机器上，当她想要开始完整的训练运行时，她可能只是将源代码的大量文件拷贝到她的 GPU 集群。
*   她执行许多不同的训练运行，经常在作业进行的同时改变本地机器上的代码，因为它们需要几天或几周才能完成。
*   在大型集群上运行到最后可能会有一个 bug，这意味着她在恢复作业之前修改了一个文件中的代码，并将其复制到所有机器上。
*   她可以从一次跑步中获得部分训练的重量，并使用它们作为不同代码的新跑步的起点。
*   她保存了所有运行的模型权重和评估分数，并在没有时间进行更多实验时选择发布哪些权重作为最终模型。这些权重可以来自任何一次运行，并且可能是由与她当前在开发机器上的代码非常不同的代码产生的。
*   她可能将最终代码签入到源代码管理中，但是是在一个个人文件夹中。
*   她公布了自己的结果，包括代码和经过训练的重量。

对于一个有责任心的研究人员来说，这是一个乐观的情景，但是你已经可以看到，对于其他人来说，重复所有这些步骤并得出相同的结果是多么困难。这些要点中的每一个都是不一致的机会。让事情更加混乱的是， [ML 框架](https://www.dominodatalab.com/blog/choosing-the-right-machine-learning-framework)用精确的数字确定性来换取性能。因此，如果奇迹发生，有人成功地复制了这些步骤，最终结果仍然会有微小的差异！

在许多现实世界的案例中，研究人员不会做笔记或确切地记得她做了什么，所以即使她也无法重现模型。即使她可以，模型代码所依赖的框架也会随着时间的推移而改变，有时会彻底改变，因此她还需要对她所使用的整个系统进行快照，以确保事情正常运行。我发现，当我联系 ML 研究人员要求他们帮助复制模型结果时，他们非常慷慨，但即使有原作者的帮助，这通常也是长达数月的任务。

## 为什么再现性很重要

为什么这些都很重要？我有几个朋友联系我，告诉我他们在复制已发表的模型作为自己论文的基线时遇到的困难。如果他们不能获得与原作者相同的准确性，他们如何判断他们的新方法是否有所改进？如果您没有办法重建模型来应对变化的需求或平台，那么依赖生产系统中的模型显然也是值得关注的。在这一点上，你的模型从技术债务的高息信用卡变成了更像高利贷的东西。这也令人窒息的研究实验；由于对代码或训练数据进行更改可能很难回滚，所以尝试不同的变化会有更大的风险，就像没有源代码控制的编码会增加尝试更改的成本一样。

这并不完全是悲观的，在社区中有一些值得注意的关于再现性的努力。我最喜欢的一个是 Toby Boyd 领导的 TensorFlow 基准测试项目(T1)。他让他的团队的任务不仅是准确地规划如何在许多不同的平台上以高训练速度从头开始训练一些领先的模型，而且还要确保模型训练达到预期的精度。我见过他拼命想让模型达到那个精度，因为我上面列出的任何步骤的变化都会影响结果，而且没有简单的方法来调试潜在的原因，即使有作者的帮助。这也是一项永无止境的工作，因为 TensorFlow、GPU 驱动程序甚至数据集的变化都可能以微妙的方式损害准确性。通过做这项工作，Toby 的团队帮助我们发现并修复由他们覆盖的模型中 TensorFlow 的变化引起的错误，并追踪由外部依赖性引起的问题，但很难扩展到相对较小的平台和模型集之外。

我还知道其他团队，他们认真对待在生产中使用模型，投入了类似的时间和精力来确保他们的培训可以被复制，但问题是这仍然是一个非常手工的过程。关于如何将培训过程存档，以便将来可以成功地重新运行，没有与源代码控制等同的东西，甚至没有公认的最佳实践。我心中也没有解决方案，但在这里开始讨论的是一些原则，我认为任何方法都需要遵循这些原则才能成功:

*   研究人员必须能够轻松地提出新想法，而不必支付高额的“过程税”。如果这不是真的，他们就不会使用它。理想情况下，该系统实际上会提高他们的生产率。
*   如果一名研究人员被一辆公交车撞了，但却创建了自己的创业公司，其他人应该可以在第二天介入并训练他们迄今为止创建的所有模型，并获得相同的结果。
*   应该有某种方法来打包你训练一个特定模型所需要的东西，以一种可以公开分享的方式，而不透露作者不希望的任何历史。
*   为了重现结果，需要准确地记录代码、训练数据和整个平台。

我已经看到开源和创业界围绕这些挑战的解决方案出现了一些有趣的动向，就我个人而言，我迫不及待地想花更少的时间来处理所有相关的问题，但我不期望在短期内看到完全的解决方案。无论我们想出什么，都需要改变我们使用模型的方式，就像源代码管理意味着我们所有个人编码过程的巨大改变一样。就最佳实践达成共识并对社区进行教育就像我们提出的工具一样重要。我迫不及待地想看看会出现什么！

^(*编辑注:本文由[皮特](https://petewarden.com/)提供，[最初出现在皮特的博客](https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/)。*)