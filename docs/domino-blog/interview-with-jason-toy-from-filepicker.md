# 数据科学家访谈:来自 Filepicker 的 Jason Toy

> 原文：<https://www.dominodatalab.com/blog/interview-with-jason-toy-from-filepicker>

![Jason Toy](img/b985f5b2b8bc0e281ef34114811ad53f.png)
我们最近采访了面向开发者的云文件管理平台 filepicker.io 的 CEO Jason Toy。此前，Jason 是话题影响者平台 Socmetrics 的首席技术官和联合创始人。作为 Socmetrics 的首席技术官，Jason 和他的团队为客户提供商业智能，使他们能够从现有客户身上获取更多价值。

## 你是如何对数据科学产生兴趣的？

我有相当的技术背景，已经写了将近 15 年的软件。我开发了软件；我做过基础设施、DevOps 和一大堆网站建设。但是对我来说最有趣的东西一直是数据。我们将如何利用数据来改进我们的产品和服务？我们如何更好地从数据中学习？数据分析是当今任何业务中最重要的部分之一。有如此多的数据涌入，我们需要工具来跟踪所有这些数据，还需要工具来获得洞察力。通过 Socmetrics，我们非常关注客户细分和社交媒体，将这两个数据集结合起来，然后进行分析。所以我花了很长时间思考和建立分析平台。

## 日常工作中需要哪些技能？

处理数据的首要能力是数学。你需要对数学概念有非常强的理解，优秀的编程技能，以及分析思维。数据科学有很多不同的名称:数据科学、机器学习、分析、大数据、人工智能、统计学等。

## 我们经常听说，要成为数据科学家，你需要成为独角兽，你同意这种说法吗？

你不需要成为独角兽，但如果你能成为独角兽，你将处于非常有利的地位。通常大多数人选择进入数据科学的一个特定领域。有工程方面；您可以将专门清理数据和移动数据作为一项全职工作。然后是分析部分，数据科学家正在处理数据，寻找见解，并测试不同的假设。第三个是理论上的，这是数据科学家实际上提出算法的时候。这种用例在学术界和拥有大型研究团队的大公司中更常见，在较小的企业中你不会看到它被大量使用。你可以把田地分割成不同的部分。成为独角兽固然很好，但我建议专注于自己的优势，在那个特定的领域深入钻研。

## 在你过去的分析工作中，哪一项技能是你运用得最多的？

我在*“应用”*或实践方面的技能更强，从构建系统到处理数据到进行实际分析的任何地方。我有一个计算机科学的本科学位，但没有一个可以真正提出新算法的博士学位。那是一个艰难的领域。有很多人在研究这个问题；谷歌、微软和所有其他大公司都有庞大的研究团队。一般来说，大多数数据科学家不会从事研究工作。

## 有没有什么作品可以和我们分享，个人视角？

我在以前的公司开发了一些有趣的产品。我之前提到的其中一个是 Socmetrics，另一个是 [Truelens](http://truelens.com/) 。我还在 filepicker.io 建立了不少基于机器学习的内部营销工具，以帮助我们在营销方面做出更好的决策。

## 在复杂的企业环境中，数据科学面临哪些挑战？

大型企业面临的挑战之一是，为他们的所有数据找到一个集中的位置。大型企业有如此多的*数据“孤岛”，通常没有足够的知识共享。如果您可以将所有数据放在一个地方，并与 Spark 或 Hadoop 同步，您可以获得更多交叉分析。除此之外，选择正确的工具可能很困难。数据科学已经存在了相当长一段时间，但机器学习-数据科学运动是相当新的。在过去几年中，像 Hadoop 这样的产品引起了人们的热议。自从我全职处理数据以来，事情发生了很大的变化，Spark 是现在最热门的东西，我还没有用过它。*

 *## 你如何在分析中利用技术？

我用的一个工具是 R，各种严格做分析和机器学习的 R 包。还有 scikit-learn，这是一个 python 库，许多数据科学家使用它来将其集成到自己的流中进行分析。同样是 Hadoop，我在亚马逊的 EMR 平台上编程了很多 Hadoop 项目。

## 对于那些试图决定是否使用 Hadoop 的组织，你有什么建议吗？

这完全取决于你有多少数据，如果你试图通过注入更多的数据来获得更多的见解，我会首先尝试看看你是否真的可以用更小的数据集来解决问题。还有另一种趋势是所谓的*“小数据”*，它说，不要陷入拥有太多数据的宣传中。除非你是 Google scale，你有这样的数据，在大多数情况下，你可以用更少的数据做得更好，因为开发算法和实际将数据注入这些系统所需的处理和时间是一个漫长而乏味的过程。即使几千兆或几十千兆的数据实际上也是“小数据”，所以我会首先尝试这样做。很多人认为他们拥有大数据，但他们实际上没有。

## 如果你可以挥动魔杖，让今天的数据科学有所不同，那会是什么？

我不会说魔杖，因为技术总是在变化，但有时我确实希望我们有工具来简化数据科学家的生活。有一些平台，包括我见过的做这个的 Domino。但我一直梦想着这个神奇的 API，你只需输入数据，它就会自动为你运行所有不同的算法，运行所有不同类型的回归测试和统计显著性测试，以确保你选择了正确的算法，并确保你的数据不会过度拟合。当您选择要使用的算法时，您有时会发现，例如，使用这一组特定的功能和这些算法，使用这一数据集时，它的性能会更好，但使用其他算法和其他因素时，它的性能却不会更好。这常常会给我们错误的答案，因为我们没有正确地分割数据，没有正确地测试数据，所以我们引入了偏见，系统没有正确地学习，它只是学习特定的数据集。作为一名数据科学家，你必须做大量的工作，以确保你的系统得到适当的训练。我希望有一种算法或 API 可以自动为你做到这一点。这是我正在做的一个小秘密小项目:)。

## 对于初入这行的人，你有什么建议？

就像我之前说的，确保你有很强的数学背景，因为数据科学是非常数学化的。您可以通过使用不同的库来解决这个问题，但是我会尝试手工学习和实现一些基本算法，以便您对它们的工作原理有一个基本的了解。网上有很多数据集可供你使用。我还会尝试与 Kaggle 一起参加这些较小的数据科学竞赛。你可以和其他人竞争，或者下载数据，自己做分析，稍后比较你的结果。这将让你知道你在进步方面所处的位置，以及你在整个数据科学市场中所处的位置。位置也很重要；开启数据科学家职业生涯的最佳地点是硅谷和旧金山。然而，网上也有一个大数据科学社区，大多数主要城市都有数据科学聚会。如果没有数据科学小组，就会有人工智能小组，这是一个略有不同但相似的领域。

* * *

我们非常感谢 Jason 的时间和洞察力。可以关注杰森 [@jtoy](https://twitter.com/jtoy) 。*