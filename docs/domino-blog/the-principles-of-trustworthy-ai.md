# 解决可信人工智能的三个 r:道德、合法和可靠的模型

> 原文：<https://www.dominodatalab.com/blog/the-principles-of-trustworthy-ai>

由达美乐数据科学战略和宣传负责人 Kjell Carlsson 于 2022 年 4 月 27 日在 [透视](https://www.dominodatalab.com/blog/tag/perspective)

*![Hand showing an AI face](img/a0a0e35c44c45e27e5b73c64a468d383.png)*

*您的业务成果、声誉和合规性取决于值得信赖的人工智能*

尽管通俗小说(和埃隆·马斯克)试图说服我们不要这样，但我们并没有面临人工智能引发的天启的威胁。正如吴恩达所说，对流氓人工智能的担忧仍然像是对“火星人口过剩问题”的担忧相反，越来越多的人一致认为，真正需要防范的人工智能威胁是不可信的人工智能。在最近的一项调查中，82%的数据科学领导者[](https://www.dominodatalab.com/news/data-science-leaders-say-their-companies-focus-on-short-term-payoffs)表示，高管需要担心支撑不可信人工智能解决方案的糟糕和失败模型的严重后果。

不可信的人工智能已经造成了真实的——尽管通常是隐藏的——伤害。在同一项调查中，46%的数据科学领导者表示，他们因这些模型的错误决策和收入损失而失眠，41%的人指出了歧视和偏见的风险。更糟糕的是，随着你扩大自己和第三方人工智能解决方案的规模，你的客户、员工和企业面临的 [风险](https://www.mckinsey.com/capabilities/quantumblack/our-insights/confronting-the-risks-of-artificial-intelligence) 几乎肯定会增加。

*可信的人工智能*和——根据定义，*可信的人工智能*——是关于*道德、* *法律合规*以及最重要的是*可靠的*人工智能解决方案的非常真实的挑战，通过正确的设计、开发和维护为它们提供动力的机器学习模型。让我们来探索*可信的人工智能*如此重要的原因，以及你需要克服的挑战，以确保它。(此外，请于 5 月 5 日至 6 日参加关于该主题的 [Rev 3](https://rev.dominodatalab.com/?utm_campaign=rev_2021&utm_content=204875409&utm_medium=social&utm_source=linkedin&hss_channel=lcp-3542130) 小组讨论和演示。)

## 可信人工智能的三个“R”

在数据科学之外，很少有高管理解信任对于他们的组织利用人工智能的能力有多重要。金融服务(finserv)和保险公司知道可信赖的人工智能在监管合规性方面的重要性，例如围绕 [信用风险评分](https://www.brookings.edu/research/an-ai-fair-lending-policy-agenda-for-the-federal-financial-regulators/) 的规则。安全公司已经敏锐地意识到即将到来的监管，特别是执法部门对面部识别的使用。而且，每个人都在媒体上看到过人工智能解决方案陷入困境的尴尬事件——想想微软 Tay 的 [种族主义爆发](https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAIPobh3XAFbjnGHUHkN7NI6RwnP_xacdbNEOfXpHOYOW0DPKkpLekJP6rDOnKIiptsM-Uq_StvHw-yMElC3lxiDMYHCJgzYwx8nu1IixIBJSgSCLUq_OE8SEGPktEnIHwHOYaPNEZuf6fnv9TUNKSm_4PvxkTsyWKFIOm0n7IIAS) 或谷歌照片“将人标记为 [大猩猩](https://www.bbc.com/news/technology-33347866) ”。然而，这些仅仅触及了可信人工智能对每个组织的人工智能运营和雄心至关重要的一小部分方式。所有这些都受到可信人工智能的三个“R”的影响。

### 结果

不可信的人工智能解决方案经历了较少的验证、鲁棒性测试和对预测驱动因素的检查，与可信的解决方案相比，交付了更差的业务结果。为什么？因为他们表现更差，将来更容易失败，更不容易被采纳。此外，不公平的人工智能模型通常会通过使用种族和性别等歧视性信息来走捷径，并且不如经过实际行为驱动因素训练的模型准确。此外，不可信的人工智能解决方案会减缓创新，因为它们在整个开发、实施和采用过程中受到利益相关者的怀疑和抵制。

### 名声

当人工智能解决方案被发现不公平、不可靠甚至非法时，公司的声誉就会受到打击，影响客户与公司做生意的意愿，以及人才申请或留在他们的职位上的意愿。大多数重大失误来自谷歌、脸书、微软和亚马逊等科技公司，这不应被视为其他公司风险较小的迹象。这些公司只是更早地开始了他们的人工智能之旅，并更多地使用人工智能模型。然而，它们也能经受住重大失误带来的声誉影响——因为它们实际上是核心业务的垄断者。你的竞争企业已经花费了大量的金钱和多年的时间来建立你的关系和声誉，可能没有这种奢侈。一个互联网巨头不会有招聘问题，即使它的招聘工具[被证明是性别歧视](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G) 。不要指望你的组织如此幸运。

### 规章制度

除了一组有限的(尽管非常有价值)用例，主要是在 [金融服务](https://www.federalreserve.gov/newsevents/testimony/braunstein20100323a.htm#:~:text=Under%20ECOA%20and%20Regulation%20B,to%20evaluate%20an%20applicant's%20creditworthiness.) 中，这些用例早在人工智能出现之前就受到了严格的监管，我们在人工智能监管方面基本上一直生活在无政府主义者的天堂。在欧盟，以 GDPR 的形式存在强有力的*数据*监管，这间接影响了利用客户数据的人工智能用例。此外，中国上个月出台了全面的人工智能立法，尽管其影响仍不明朗。在美国，还没有关于人工智能的联邦立法，只有小城市和州一级的立法，其中大部分是关于面部识别和客户数据的使用。但是，调控来了。欧盟提出了广泛的人工智能监管——罚款高达全球收入的 6%——美国预计将在不久的将来推出更温和的联邦人工智能立法。

## 没有灵丹妙药，但有一个不断增长的道德 AI & ML 工具包

虽然大多数公司几乎肯定低估了它的重要性，但有一个压倒性的共识，即可信的人工智能是重要的。在如何实现这一点上，并不存在同样的共识。阐明一套道德的人工智能原则一直很受欢迎——比如微软、IBM、谷歌、德勤和 [梵蒂冈](https://www.reuters.com/article/vatican-artificial-intelligence/pope-to-endorse-principles-on-ai-ethics-with-microsoft-ibm-idUSL2N2AS01S) 提出的那些原则。不幸的是，这些原则中的许多对实践者提供的指导很少，相互矛盾，并且经常与实际技术及其应用明显脱节。

不幸的是，也很少有证据表明，公司设立的人工智能道德顾问委员会提供了合理、实用的指导。在人工智能技术领域拥有专业知识的人似乎很少参与这两种努力。例如，值得注意的是，这些实体中有多少要求绝对的客户数据隐私，同时坚持消除所有有害的偏见。这忽略了一个对任何从业者来说都显而易见的事实，即如果没有客户信息来检测或减轻歧视性偏见，您就无法消除它。

值得信赖的人工智能不是由人工智能道德委员会颁布的法令产生的，而是最终依赖于参与开发和维护这些人工智能解决方案的团队的辛勤工作和不断警惕。谢天谢地，有一个不断扩展的 [方法](https://www.trustworthyml.org/) 工具包，从业者可以用它来提高可信度。这些方法包括可解释性技术、公平性测试和偏差缓解方法，以及始终重要的模型验证和监控的传统方法。

由于信任本身的许多不同方面，从业者总是需要使用大量的这些技术，这取决于上下文和用例。平台(如 Domino Data Lab)可以轻松应用所有这些工具，实现可用的新方法，确保模型的可重复性，并促进持续监控，这对于确保信任至关重要。但让了解数据科学、值得信赖的人工智能方法和道德规范以及流程的人持续记录、评估、测试和监控您的解决方案至关重要。正如人工智能中的一切一样，人类智能是最重要的成分。

有关如何确保现实世界的人工智能解决方案是可靠的、道德的，并且符合新的和未来的法规的更多信息，请查看在 [Rev 3](https://rev.dominodatalab.com/) 的会议。

[![New call-to-action](img/ff0f86b10fb5e777d83869be28e7dc01.png)](https://cta-redirect.hubspot.com/cta/redirect/6816846/99d47ffd-cdb9-4123-810e-6b640812f848)