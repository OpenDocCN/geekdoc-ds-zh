# 面向 MLOps 的民主化 GPU 访问:Domino 扩展了对 NVIDIA AI Enterprise 的支持

> 原文：<https://www.dominodatalab.com/blog/domino-expands-support-to-nvidia-ai-enterprise>

我们客户的趋势很明显:对于构建日益复杂的模型的企业来说，基于 GPU 的培训是一种竞争优势。从预测性供应链的[NLP](https://go.dominodatalab.com/how-lockheed-martin-is-pushing-the-boundaries-of-rocket-science-with-data-science-video)到临床试验中组织病理学的 [图像处理](https://www.youtube.com/watch?v=Sd_mCXYcPWk) ，以及能源基础设施的 [预测性维护](https://www.dominodatalab.com/resources/how-aes-went-from-zero-to-50-deployed-models/) 到保险行业的 [自动理赔](https://go.dominodatalab.com/solving-expert-problems-with-nlp-algorithms-in-insurance) ，我们在任何事情中都可以看到这一点。

Domino [于 2020 年与英伟达](https://www.dominodatalab.com/news/domino-data-lab-joins-nvidia-as-dgx-ready-software-program-partner/) 合作，在英伟达 DGX 系统上认证 Domino Enterprise MLOps 平台。这种支持使我们的客户能够将强大的 NVIDIA A100 Tensor Core GPUs 用于人工智能和 ML 工作负载。客户可以使用 Domino 在一个 NVIDIA DGX 系统中的一到八个 A100 GPUs 上训练模型。而今年早些时候，我们 [宣布支持](https://venturebeat.com/2021/04/14/domino-accelerates-mlops-with-new-nvidia-integrations/) 通过 Ray & Dask(除了 Spark)进行多节点训练。该功能允许在大规模 DGX 集群基础设施上进行大规模模型训练。此外，Domino 对 A100 GPU 中的 [NVIDIA 多实例 GPU (MIG)特性](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/) 的支持有助于客户轻松地在单个 DGX 系统上同时部署多达 56 台笔记本电脑或推理作业。

但是英伟达的人工智能产品不仅仅局限于 DGX 的 [英伟达人工智能企业](https://nvda.ws/3CW2049) ，它建立在 [英伟达 EGX](https://www.nvidia.com/en-us/data-center/products/egx/) 平台上。这种架构支持在各种部署中快速部署、管理和扩展人工智能工作负载，包括主流加速服务器和现代混合云。

这就是为什么今天，我们很兴奋地 [宣布](https://nvidianews.nvidia.com/news/global-availability-of-nvidia-ai-enterprise-makes-ai-accessible-for-every-industry) 我们正在与英伟达密切合作，通过支持 Domino Enterprise MLOps 平台运行更广泛的英伟达 GPU，并针对英伟达 AI Enterprise 进行验证，以使 Domino 在 [英伟达认证系统](https://www.nvidia.com/en-us/data-center/products/certified-systems/) 上无缝运行，来深化我们的产品集成。

## 对客户来说，差异是显而易见的

对于 Domino 客户来说，好处是显而易见的。通过支持 NVIDIA AI 企业软件套件，Domino 将扩展我们对更多 NVIDIA 加速计算平台的支持。除了 DGX，Domino 将通过戴尔、HPE、联想或其他硬件提供商的包装，支持主流加速服务器的各种 NVIDIA GPUs，包括 A100、A30、A40、A10 和 T4。这将在更广泛的 NVIDIA 加速系统上为客户提供相同的认证 Domino 功能。

由于 NVIDIA AI Enterprise 使成千上万运行 VMware vSphere 的公司能够在主流 NVIDIA 认证系统上虚拟化 AI 工作负载，这一新的集成使企业更容易采购、运行和扩展 Domino 的 Enterprise MLOps 平台。

随着 Domino 支持扩展到更多基于 NVIDIA 的平台，企业可以获得两全其美的优势:领先的 NVIDIA AI 训练和推理性能跨各种系统，以及所有必要的数据隐私性、完整性和可靠性。

Domino 强大、可扩展和协作的企业 MLOps 平台帮助数据科学团队在构建人工智能和机器学习解决方案的模型时利用英伟达的高级 GPU。

## 建立在成功记录的基础上

Domino 强大、可扩展和协作的企业 MLOps 平台帮助数据科学团队在构建人工智能和机器学习解决方案的模型时利用英伟达的高级 GPU。

洛克希德·马丁公司[通过使用 Domino 集中整个企业的工具，使用 NVIDIA 作为其在高性能计算领域的选择，为 300 名数据科学家带来了超过 2000 万美元的数据科学效率和成本节约。通过结合使用 Domino 和 NVIDIA，it 简化了协作和知识共享，同时自动化了阻碍数据科学家工作效率的手动开发任务。](/customers/lockheed-martin)

强生公司还利用 Domino 和 NVIDIA 的技术组合，构建企业 MLOps 战略来实现模型速度。在最近的 NVIDIA GTC 上，我们的首席执行官 Nick Elprin 和强生企业首席信息官 Jim Swanson 讨论了该公司在业务中嵌入数据科学的经验，考虑到了人员、流程和技术。

在不到两年的时间里，AES 使用 Domino 的企业 MLOps 平台[从 0 到 50 个模型投入生产](/resources/how-aes-went-from-zero-to-50-deployed-models/)。利用英伟达 GPU，AES 的模型覆盖了各种不同的领域:预测发电设备的维护需求，指导金融科技能源交易，进行水文预测，为公用事业提供天气预报，等等。

我们对与 NVIDIA 不断增长的合作伙伴关系的前景感到兴奋，这将使我们的客户能够利用模型实现其业务核心。