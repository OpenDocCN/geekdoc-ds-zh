# 15 万圣节分析

> 原文：[`dcic-world.org/2025-08-27/amortized-analysis.html`](https://dcic-world.org/2025-08-27/amortized-analysis.html)

|     15.1 第一个例子 |
| --- |
|     15.2 新的分析方法 |
|     15.3 一个例子：从列表到队列 |
|       15.3.1 列表表示 |
|       15.3.2 第一次分析 |
|       15.3.3 更自由的操作序列 |
|       15.3.4 第二次分析 |
|       15.3.5 摊销与单个操作 |
|     15.4 阅读更多 |

在 预测增长 中，我们介绍了大 O 复杂度的概念，用于衡量计算的最坏情况时间。然而，正如我们在 选择表示形式 中看到的，当复杂性高度依赖于操作的精确序列时，这有时是一个过于粗略的界限。现在，我们将考虑一种不同的复杂性分析方法，它更好地适应操作序列。

### 15.1 第一个例子 "链接到此处")

考虑，例如，一个开始为空的集合，然后是 \(k\) 次插入和 \(k\) 次成员资格测试的序列，假设我们使用的是无重复的表示。插入时间与集合（和列表）的大小成比例；最初是 \(0\)，然后是 \(1\)，以此类推，直到达到大小 \(k\)。因此，插入序列的总成本是 \(k \cdot (k+1) / 2\)。最坏情况下的成员资格测试成本为 \(k\)，因为我们已经将最多 \(k\) 个不同的元素插入到集合中。因此，总时间是

\begin{equation*}k² / 2 + k / 2 + k²\end{equation*}

总共 \(2k\) 次操作，平均为

\begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}

最坏情况下的每个操作步骤。

### 15.2 新的分析方法 "链接到此处")

我们计算了什么？我们仍在计算最坏情况下的成本，因为我们已经按照最坏情况考虑了序列中每个操作的成本。然后我们计算每个操作的平均成本。因此，这是最坏情况下的平均值。重要的是，这与所谓的平均情况分析不同，后者使用概率论来计算计算的估计成本。在这里我们没有使用任何概率。请注意，因为这是每个操作的平均值，它并没有说明任何单个操作可能有多糟糕（正如我们将看到的 [摊销与单个操作]，可能相当糟糕）；它只说明了它们的平均值。

在上述情况下，这种新的分析并没有带来任何大的惊喜。我们发现平均每次操作我们花费大约\(k\)步；大 O 分析会告诉我们我们在每个不同元素上执行了\(2k\)次操作，每次操作的成本为\(O([k \rightarrow k])\)；因此，每次操作，我们在最坏情况下集合元素的数量上执行的工作大致是线性的。

然而，正如我们很快就会看到的，这并不总是情况：这种新的分析可能会带来意想不到的惊喜。

在我们继续之前，我们应该给这种分析起一个名字。正式来说，它被称为摊销分析。摊销是将支付分散到延长但固定期限的过程。同样，我们将计算的成本分散到固定序列中，然后确定每次支付的金额。我们给它起了一个古怪的名字，因为[万圣节](http://en.wikipedia.org/wiki/Halloween)是一个（美国的）节日，致力于鬼魂、恶魔和其他死亡象征。摊销来自拉丁语词根 mort-，意为死亡，因为摊销分析是在“死亡”时进行的，即在固定操作序列的末尾。

### 15.3 一个例子：从列表中创建队列 "链接至此")

我们已经看到了列表[从表格到列表]和集合[集合的几种变体]。在这里，我们专注于队列，队列也可以表示为列表：从列表中创建队列。如果您还没有阅读那部分内容，现在至少阅读前面的部分是值得的。在本节中，我们将忽略那里讨论的各种编程细节，并专注于原始列表表示来阐述算法观点。

#### 15.3.1 列表表示 "链接至此")

考虑两种使用列表定义队列的自然方法。一种方法是在每次入队操作中使用`link`，而每次出队操作则需要遍历整个列表直到其末尾。相反，我们也可以让入队操作遍历到末尾，而出队操作对应于`.rest`。无论哪种方式，这些操作中的一种将需要常数时间，而另一种将线性依赖于表示队列的列表长度。（这应该会让人联想到我们在将集合表示为列表时遇到的权衡：将集合表示为列表。）

然而，事实上，上述段落包含了一个关键的洞见，这将使我们做得更好。

注意，如果我们以最近入队的元素为首位存储队列到列表中，入队操作将非常便宜（常数时间）。相比之下，如果我们以相反的顺序存储队列，那么出队操作将是常数时间。如果我们可以同时拥有这两种情况，那将是极好的，但一旦我们选择了一种顺序，我们就必须放弃其中之一。除非，那就是，我们选择……两者。

这一半很简单。我们只需将元素入队到一个列表中，最新的添加在第一个位置。现在，对于（第一次）关键的洞见：当我们需要出队时，我们反转列表。现在，出队操作也保持恒定时间。

#### 15.3.2 初步分析 "链接至此")

当然，为了完全分析这个数据结构的复杂性，我们必须考虑反转操作。在最坏的情况下，我们可以争论任何操作都可能反转（因为它可能是第一次出队）；因此，任何操作的最坏情况时间就是反转所需的时间，这是与列表长度成线性关系的（对应于队列的元素）。

然而，这个答案可能不会令人满意。如果我们执行 \(k\) 次入队操作，然后执行 \(k\) 次出队操作，那么每次入队操作需要一步；最后 \(k-1\) 次出队操作每次也需要一步；只有第一次出队需要反转，这需要与列表中元素数量成比例的步骤，在那个时刻是 \(k\)。因此，这个操作序列的总成本是 \(k \cdot 1 + k + (k-1) \cdot 1 = 3k-1\)，总共 \(2k\) 次操作，给出每操作平均恒定时间的复杂度！

#### 15.3.3 更自由的操作序列 "链接至此")

然而，在这个过程中，我们默默地忽略了一些你可能没有注意到的事情：在我们的候选序列中，所有的出队操作都跟随着所有的入队操作。下一个入队操作会发生什么？因为列表现在被反转了，它将需要线性时间！所以，我们只是部分解决了这个问题。

现在我们可以引入第二个洞见：有两个列表而不是一个。其中一个将是队列的尾部，新元素在这里入队；另一个将是队列的头部，元素在这里出队：

```py
data Queue<T>:
  | queue(tail :: List<T>, head :: List<T>)
end

mt-q :: Queue = queue(empty, empty)
```

假设尾部存储的方式是最新的元素在第一个位置，那么入队操作将保持恒定时间：

```py
fun enqueue<T>(q :: Queue<T>, e :: T) -> Queue<T>:
  queue(link(e, q.tail), q.head)
end
```

为了使出队操作的时间保持恒定，队列的头部必须以相反的方向存储。然而，任何元素是如何从尾部到达头部的呢？简单：当我们尝试出队但头部没有元素时，我们将（整个）尾部反转到头部（从而产生一个空尾部）。我们首先定义一个数据类型来表示出队操作的响应：

```py
data Response<T>:
  | elt-and-q(e :: T, r :: Queue<T>)
end
```

现在来实现`dequeue`：

```py
fun dequeue<T>(q :: Queue<T>) -> Response<T>:
  cases (List) q.head:
    | empty =>
      new-head = q.tail.reverse()
      elt-and-q(new-head.first,
        queue(empty, new-head.rest))
    | link(f, r) =>
      elt-and-q(f,
        queue(q.tail, r))
  end
end
```

#### 15.3.4 第二次分析 "链接至此")

我们现在可以像以前一样推理操作序列，通过累加成本并取平均值。然而，另一种思考方式是这样的。让我们给队列中的每个元素分配三个“信用”。每个信用可以用于一个恒定时间的操作。

入队操作会消耗一个信用。只要元素保持在尾列表中，它仍然有额外的两个信用。当它需要移动到头列表时，它会在反转步骤中再消耗一个信用。最后，出队操作执行一个额外的操作。

因为元素没有耗尽信用，我们知道它必须有足够的信用。这些信用反映了对该元素的操作成本。从这个（非常非正式的）分析中，我们可以得出结论，在最坏的情况下，任何入队和出队的排列都将仅花费常数摊销时间。

#### 15.3.5 摊销与单个操作 "链接到此处")

然而，要注意的是，这个常数代表的是操作序列的平均值。它并不对任何单个操作的成本施加限制。实际上，正如我们上面所看到的，当出列操作发现头列表为空时，它会反转尾，这需要与尾的大小成线性关系的时间——根本不是常数！因此，我们应该小心，不要假设序列中的每一步都会受到限制。尽管如此，摊销分析有时能让我们比单独的最坏情况分析更深入地理解数据结构的实际行为。

### 15.4 阅读更多 "链接到此处")

在这一点上，我们只是简要地触及了摊销分析的主题。Rebecca Fiebrink 的一个非常好的[教程](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)提供了更多信息。关于算法的权威书籍，Cormen、Leiserson、Rivest 和 Stein 合著的《算法导论》，详细介绍了摊销分析。

### 15.1 第一个例子 "链接到此处")

例如，考虑一个开始为空的集合，然后是\(k\)次插入和\(k\)次成员资格测试的序列，并且假设我们使用的是无重复的表示。插入时间与集合（和列表）的大小成比例；这最初是\(0\)，然后是\(1\)，以此类推，直到达到大小\(k\)。因此，插入序列的总成本是\(k \cdot (k+1) / 2\)。在最坏的情况下，成员资格测试的成本是\(k\)，因为我们已经将多达\(k\)个不同的元素插入到集合中。因此，总时间是

\begin{equation*}k² / 2 + k / 2 + k²\end{equation*}

总共\(2k\)次操作，平均每次操作

\begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}

步骤数在最坏情况下。

### 15.2 新的分析方法 "链接到此处")

我们计算了什么？我们仍在计算最坏情况成本，因为我们已经考虑了序列中每个操作的最坏情况成本。然后我们计算每个操作的平均成本。因此，这是一个最坏情况的平均值。重要的是，这与所谓的平均情况分析不同，后者使用概率论来计算计算的估计成本。我们没有在这里使用任何概率。请注意，因为这是一个每个操作的平均值，它并没有说明任何单个操作可能有多糟糕（正如我们将看到的 [摊销与单个操作]，可能相当糟糕）；它只说明了它们的平均值。

在上述情况下，这项新的分析并没有带来任何大的惊喜。我们发现，平均而言，我们每个操作花费大约 \(k\) 步；一个大 O 分析会告诉我们，我们执行了 \(2k\) 个操作，每个操作的成本为 \(O([k \rightarrow k])\) 的不同元素数量；因此，每个操作，我们在最坏情况下对集合元素的数量执行了大致线性的工作。

然而，正如我们很快就会看到的，情况并不总是这样：这项新的分析可能会带来令人愉快的惊喜。

在我们继续之前，我们应该给这项分析起一个名字。正式来说，它被称为摊销分析。摊销是将支付分散到延长但固定期限的过程。同样，我们将计算的成本分散到固定序列中，然后确定每次支付的金额。我们给它起了一个古怪的名字，因为 [万圣节](http://en.wikipedia.org/wiki/Halloween) 是一个（美国的）节日，致力于鬼魂、恶魔和其他死亡象征。摊销来自拉丁语词根 mort-，意为死亡，因为摊销分析是在“死亡”时进行的，即在固定操作序列的末尾。

### 15.3 列表中的示例：队列 "链接到这里")

我们已经看到了列表 [从表格到列表] 和集合 [集合的几种变体]。在这里，我们关注队列，队列也可以表示为列表：从列表到队列。如果你还没有阅读那部分内容，现在至少应该阅读前面的部分。在本节中，我们将忽略那里讨论的各种编程细节，专注于原始列表表示来阐述算法观点。

#### 15.3.1 列表表示 "链接到这里")

考虑使用列表定义队列的两种自然方式。一种方式是每个入队操作都使用`link`实现，而每个出队操作都需要遍历整个列表直到其末尾。相反，我们也可以让入队操作遍历到末尾，而出队操作对应于`.rest`。无论哪种方式，这些操作中的一种将花费常数时间，而另一种将线性于表示队列的列表长度。 (这应该会让人联想到我们在将集合表示为列表时遇到的权衡：将集合表示为列表。)

然而，事实上，上述段落中包含了一个关键的洞见，这将使我们做得更好。

注意，如果我们以最近入队的元素为首位将队列存储在列表中，入队操作的成本很低（常数时间）。相比之下，如果我们以相反的顺序存储队列，则出队操作是常数时间。如果能同时拥有这两种操作那就太好了，但一旦我们选择了顺序，就必须放弃其中之一。除非，那就是，我们选择……两者都要。

其中一半是容易的。我们只需将元素以最近添加的顺序入队到列表中。现在，对于（第一次）关键洞见：当我们需要出队时，我们反转列表。现在，出队操作也花费常数时间。

#### 15.3.2 初步分析 "链接至此")

当然，为了完全分析这种数据结构的复杂性，我们必须考虑反转操作。在最坏的情况下，我们可能会认为任何操作都可能需要反转（因为它可能是第一次出队）；因此，任何操作的最坏情况时间都是反转所需的时间，这是线性于列表长度的（对应于队列的元素）。

然而，这个答案可能不会令人满意。如果我们执行 \(k\) 次入队操作，然后执行 \(k\) 次出队操作，那么每次入队操作花费一步；最后 \(k-1\) 次出队操作每次也花费一步；而只有第一次出队需要反转，这需要与列表中元素数量成比例的步骤，在那个时刻是 \(k\)。因此，这个操作序列的总成本是 \(k \cdot 1 + k + (k-1) \cdot 1 = 3k-1\)，总共 \(2k\) 次操作，给出每个操作平均为常数时间的复杂度！

#### 15.3.3 更自由的操作序列 "链接至此")

在这个过程中，我们却悄悄地忽略了你可能没有注意到的事情：在我们的候选序列中，所有出队操作都跟随着所有入队操作。下一次入队会发生什么？因为列表现在是反转的，它将需要线性时间！所以，我们只部分解决了这个问题。

现在我们可以引入第二个洞见：使用两个列表而不是一个。其中一个将是队列的尾部，新元素将在这里入队；另一个将是队列的头部，元素将在这里出队：

```py
data Queue<T>:
  | queue(tail :: List<T>, head :: List<T>)
end

mt-q :: Queue = queue(empty, empty)
```

假设尾部的存储方式使得最新元素是第一个，那么入队操作将花费常数时间：

```py
fun enqueue<T>(q :: Queue<T>, e :: T) -> Queue<T>:
  queue(link(e, q.tail), q.head)
end
```

为了使出队操作花费常数时间，队列的头部必须以相反的方向存储。然而，任何元素是如何从尾部移动到头部的呢？简单：当我们尝试出队并且发现头部没有元素时，我们将（整个）尾部反转到头部（导致尾部为空）。我们首先定义一个数据类型来表示出队操作的响应：

```py
data Response<T>:
  | elt-and-q(e :: T, r :: Queue<T>)
end
```

现在来看`dequeue`的实现：

```py
fun dequeue<T>(q :: Queue<T>) -> Response<T>:
  cases (List) q.head:
    | empty =>
      new-head = q.tail.reverse()
      elt-and-q(new-head.first,
        queue(empty, new-head.rest))
    | link(f, r) =>
      elt-and-q(f,
        queue(q.tail, r))
  end
end
```

#### 15.3.4 第二次分析 "链接到此处")

我们现在可以像以前一样推理操作序列，通过累加成本并取平均值。然而，另一种思考方式是这样的。让我们给队列中的每个元素分配三个“信用”。每个信用可以用于一个常数时间的操作。

入队操作会消耗一个信用。只要元素保持在尾部列表中，它仍然有额外的两个信用。当它需要移动到头部列表时，它会在反转步骤中再消耗一个信用。最后，出队操作执行一个额外的操作。

因为元素没有耗尽信用，我们知道它必须有足够的信用。这些信用反映了在该元素上操作的成本。从这个（非常非正式的）分析中，我们可以得出结论，在最坏的情况下，任何入队和出队的排列组合都将仅花费常数时间的摊销时间。

#### 15.3.5 摊销时间与单个操作 "链接到此处")

然而，请注意，这个常数代表了一系列操作的平均值。它并没有对任何单个操作的成本设定界限。确实，正如我们上面所看到的，当出队操作发现头部列表为空时，它会反转尾部，这需要与尾部大小成线性关系的操作时间——绝对不是常数！因此，我们应该小心，不要假设序列中的每一步都是有限的。尽管如此，摊销分析有时能比单独的最坏情况分析更细致地理解数据结构的实际行为。

#### 15.3.1 列表表示 "链接到此处")

考虑使用列表定义队列的两种自然方式。一种方式是每个入队操作都使用`link`实现，而每个出队操作都需要遍历整个列表直到其末尾。相反，我们也可以使入队操作遍历到末尾，而出队操作对应于`.rest`。无论哪种方式，这些操作中的一种将花费常数时间，而另一种将线性于表示队列的列表长度。 (这应该会让人联想到我们在将集合表示为列表时遇到的权衡：将集合表示为列表。)

事实上，然而，上述段落包含了一个关键洞见，这将使我们做得更好。

注意，如果我们以最新入队元素在前的顺序将队列存储在列表中，入队操作的成本很低（恒定时间）。相反，如果我们以相反的顺序存储队列，那么出队操作是恒定时间的。如果我们可以同时拥有两者，那将是极好的，但一旦我们选择了顺序，我们就必须放弃其中一个。除非，我们选择……两者。

这其中的一半是容易的。我们只需将元素以最新添加的顺序入队到一个列表中。现在，对于（第一个）关键洞见：当我们需要出队时，我们反转列表。现在，出队操作也变成了恒定时间。

#### 15.3.2 初步分析 "链接至此")

当然，为了完全分析这个数据结构的复杂性，我们必须也考虑反转操作。在最坏的情况下，我们可能会认为任何操作都可能需要反转（因为它可能是第一次出队）；因此，任何操作的最坏情况时间就是反转所需的时间，这是与列表长度成线性关系的（对应于队列的元素）。

然而，这个答案可能不会令人满意。如果我们执行\(k\)次入队操作，然后执行\(k\)次出队操作，那么每次入队操作需要一步；最后\(k-1\)次出队操作每次也需要一步；只有第一次出队需要反转，这需要与列表中元素数量成比例的步骤，在那个时刻是\(k\)。因此，这个操作序列的总成本是\(k \cdot 1 + k + (k-1) \cdot 1 = 3k-1\)，总共是\(2k\)次操作，给出了每个操作平均恒定时间的复杂度！

#### 15.3.3 更自由的操作序列 "链接至此")

然而，在这个过程中，我们却悄悄地忽略了一些你可能没有注意到的事情：在我们的候选序列中，所有的出队操作都跟随着所有的入队操作。下一个入队操作会发生什么？因为列表现在被反转了，它将需要线性时间！所以，我们只部分解决了这个问题。

现在我们可以介绍第二个洞见：有两个列表而不是一个。其中一个将是队列的尾部，新元素将在这里入队；另一个将是队列的头部，元素将在这里出队：

```py
data Queue<T>:
  | queue(tail :: List<T>, head :: List<T>)
end

mt-q :: Queue = queue(empty, empty)
```

假设尾部存储的方式是最新的元素在第一个位置，那么入队操作的时间是恒定的：

```py
fun enqueue<T>(q :: Queue<T>, e :: T) -> Queue<T>:
  queue(link(e, q.tail), q.head)
end
```

为了使出队操作的时间保持恒定，队列的头部必须以相反的方向存储。然而，任何元素是如何从尾部到达头部的呢？简单：当我们尝试出队但头部没有元素时，我们将（整个）尾部反转到头部（从而产生一个空尾部）。我们首先定义一个数据类型来表示出队操作的响应：

```py
data Response<T>:
  | elt-and-q(e :: T, r :: Queue<T>)
end
```

现在是`dequeue`实现的步骤：

```py
fun dequeue<T>(q :: Queue<T>) -> Response<T>:
  cases (List) q.head:
    | empty =>
      new-head = q.tail.reverse()
      elt-and-q(new-head.first,
        queue(empty, new-head.rest))
    | link(f, r) =>
      elt-and-q(f,
        queue(q.tail, r))
  end
end
```

#### 15.3.4 第二次分析 "链接至此")

我们现在可以像以前一样，通过累加成本和平均来推理操作序列。然而，另一种思考方式是这样的。让我们给队列中的每个元素分配三个“信用额度”。每个信用额度可以用于一次常数时间的操作。

一个信用额度在入队时被消耗。只要元素保持在尾列表中，它仍然有剩余两个信用额度。当它需要移动到头列表时，它在反转链接步骤中再消耗一个信用额度。最后，出队操作执行了一个额外的操作。

因为元素没有耗尽信用额度，我们知道它一定有足够的。这些信用额度反映了在该元素上操作的成本。从这个（非常非正式的）分析中，我们可以得出结论，在最坏的情况下，任何入队和出队的排列组合都将仅花费常数量的摊销时间。

#### 15.3.5 摊销与单个操作 "链接到此处")

然而，请注意，这个常数代表的是操作序列的平均值。它并不对任何单个操作的成本施加限制。确实，正如我们上面所看到的，当出队发现头列表为空时，它会反转尾，这需要与尾的大小成线性关系的时间——根本不是常数！因此，我们应该小心不要假设序列中的每一步都是有限的。尽管如此，摊销分析有时能让我们比单独的最坏情况分析更深入地理解数据结构的实际行为。 

### 15.4 阅读更多 "链接到此处")

到目前为止，我们只是简要地提到了摊销分析的主题。Rebecca Fiebrink 的一个非常好的[教程](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)提供了更多信息。关于算法的权威书籍，Cormen、Leiserson、Rivest 和 Stein 合著的《算法导论》，详细介绍了摊销分析。
