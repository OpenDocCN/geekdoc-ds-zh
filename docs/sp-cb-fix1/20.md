# 二十、性能

*   [使用 Python 进行性能计算的初学者指南](PerformancePython.html)
*   [带 numpy 和 scipy 的并行编程](ParallelProgramming.html)

# 使用 Python 进行性能计算的初学者指南

# 使用 Python 进行性能计算的初学者指南

用 NumPy、Pyrex、Psyco、Fortran (77 和 90)和 C++求解拉普拉斯方程的编织比较。这篇文章最初是由帕布·拉玛钱德朗写的。

[`laplace.py`](../_downloads/laplace.py) 是下面讨论的完整 Python 代码。源 tarball ( [`perfpy_2.tgz`](../_downloads/perfpy_2.tgz) )还包含 Fortran 代码、纯 C++代码、Pyrex 源和用于构建 f2py 和 Pyrex 模块的 setup.py 脚本。

## 介绍

这是一个使用 Python 进行性能计算的简单介绍性文档。我们将使用 NumPy、SciPy 的编织(同时使用 weave.blitz 和 weave.inline)和 Pyrex。我们还将展示如何使用 f2py 包装一个 Fortran 子例程，并从 Python 内部调用它。

我们还将利用这个机会，用 Python 对解决特定数值问题的各种方法进行基准测试，并将它们与 C++中的算法实现进行比较。

## 问题描述

我们将考虑的例子是使用迭代有限差分格式(四点平均法、高斯-塞德尔法或高斯-乔丹法)求解 2D 拉普拉斯方程的一个非常简单(简单)的例子。问题的正式说明如下。我们需要求解一些未知函数 u(x，y ),使得∇2u = 0，并指定边界条件。为了方便起见，感兴趣的区域被认为是一个矩形，并且给出了这个矩形的边的边界值。

可以表明，这个问题可以通过使用简单的四点平均方案来解决，如下所示。将域离散成一个(nx x ny)点网格。那么函数 u 可以表示为二维数组 u(nx，ny)。给出了沿矩形边的 u 值。解决方案可以通过以下方式迭代获得。

```py
for i in range(1, nx-1):
    for j in range(1, ny-1):
        u[i,j] = ((u[i-1, j] + u[i+1, j])*dy**2 +
                  (u[i, j-1] + u[i, j+1])*dx**2)/(2.0*(dx**2 + dy**2)) 
```

其中 dx 和 dy 是离散化域沿 x 和 y 轴的长度。

## 数解

在纯 Python 中，实现求解器是非常简单的。使用一个简单的 NumPy 数组来存储解矩阵 u。

```py
import numpy

class Grid:
    """A simple grid class that stores the details and solution of the
    computational grid."""
    def __init__(self, nx=10, ny=10, xmin=0.0, xmax=1.0,
                 ymin=0.0, ymax=1.0):
        self.xmin, self.xmax, self.ymin, self.ymax = xmin, xmax, ymin, ymax
        self.dx = float(xmax-xmin)/(nx-1)
        self.dy = float(ymax-ymin)/(ny-1)
        self.u = numpy.zeros((nx, ny), 'd')
        # used to compute the change in solution in some of the methods.
        self.old_u = self.u.copy()

    def setBCFunc(self, func):
        """Sets the BC given a function of two variables."""
        xmin, ymin = self.xmin, self.ymin
        xmax, ymax = self.xmax, self.ymax
        x = numpy.arange(xmin, xmax + self.dx*0.5, self.dx)
        y = numpy.arange(ymin, ymax + self.dy*0.5, self.dy)
        self.u[0 ,:] = func(xmin,y)
        self.u[-1,:] = func(xmax,y)
        self.u[:, 0] = func(x,ymin)
        self.u[:,-1] = func(x,ymax)

    def computeError(self):
        """Computes absolute error using an L2 norm for the solution.
        This requires that self.u and self.old_u must be appropriately
        setup."""
        v = (self.u - self.old_u).flat
        return numpy.sqrt(numpy.dot(v,v))

class LaplaceSolver:
    """A simple Laplacian solver that can use different schemes to
    solve the problem."""
    def __init__(self, grid, stepper='numeric'):
        self.grid = grid
        self.setTimeStepper(stepper)

    def slowTimeStep(self, dt=0.0):
        """Takes a time step using straight forward Python loops."""
        g = self.grid
        nx, ny = g.u.shape
        dx2, dy2 = g.dx**2, g.dy**2
        dnr_inv = 0.5/(dx2 + dy2)
        u = g.u

        err = 0.0
        for i in range(1, nx-1):
            for j in range(1, ny-1):
                tmp = u[i,j]
                u[i,j] = ((u[i-1, j] + u[i+1, j])*dy2 +
                         (u[i, j-1] + u[i, j+1])*dx2)*dnr_inv
                diff = u[i,j] - tmp
                err += diff*diff

        return numpy.sqrt(err)

    def setTimeStepper(self, stepper='numeric'):
        """Sets the time step scheme to be used while solving given a
        string which should be one of ['slow', 'numeric', 'blitz',
        'inline', 'fastinline', 'fortran']."""
         if stepper == 'slow':
           self.timeStep = self.slowTimeStep
         # ...
         else:
            self.timeStep = self.numericTimeStep

    def solve(self, n_iter=0, eps=1.0e-16):
        err = self.timeStep()
        count = 1

        while err > eps:
            if n_iter and count >= n_iter:
                return err
            err = self.timeStep()
            count = count + 1

        return count 
```

代码非常简单，非常容易编写，但是如果我们运行它来解决任何大问题(比如 500 x 500 个点的网格)，我们会发现它需要*永远*才能运行。这种情况下的 CPU 占道就是`slowTimeStep`法。在下一节中，我们将使用 NumPy 加速它。

## 使用 NumPy

原来`LaplaceSolver.slowTimeStep`方法的最内循环可以很容易地用简单得多的 NumPy 表达式来表示。这是一个重写的时间步长方法。

```py
def numericTimeStep(self, dt=0.0):
    """Takes a time step using a NumPy expression."""
    g = self.grid
    dx2, dy2 = g.dx**2, g.dy**2
    dnr_inv = 0.5/(dx2 + dy2)
    u = g.u
    g.old_u = u.copy() # needed to compute the error.

    # The actual iteration
    u[1:-1, 1:-1] = ((u[0:-2, 1:-1] + u[2:, 1:-1])*dy2 +
                     (u[1:-1,0:-2] + u[1:-1, 2:])*dx2)*dnr_inv

    return g.computeError() 
```

整个 for i 和 j 循环已经被一个 NumPy 表达式所取代。NumPy 表达式是元素式的，因此上面的表达式是有效的。它基本上计算四点平均值。如果你已经完成了 NumPy 教程并玩了一点`NumPy`，你应该能够理解这是如何工作的。这个表达式的美妙之处在于它完全是用 c 语言完成的。这使得计算*比*快得多。为了快速比较，这里有一些 500x500 网格上的单次迭代的数字。在具有 192 兆内存的 PIII 450 兆赫兹上，上面的过程需要大约 0.3 秒，而前一个过程需要大约 15 秒。这接近 50 倍的速度提升。你也会注意到一些事情。

1.  我们不能像前面在 for 循环中那样计算错误。我们需要复制一份数据，然后使用 computeError 函数来完成这项工作。这耗费了我们的记忆，也不是很美好。这当然是一个限制，但值得增加 50 倍的速度。
2.  表达式将使用临时变量。因此，在一次迭代期间，在已经计算的位置的计算值将不在迭代期间使用。例如，在原始 For 循环中，一旦计算出 u[1，1]的值，u[1，2]的下一个值将使用新计算的 u[1，1]，而不是旧的值。但是，由于 NumPy 表达式在内部使用临时变量，因此将只使用 u[1，1]的旧值。在这种情况下，这不是一个严重的问题，因为众所周知，即使发生这种情况，算法也会收敛(但收敛时间是原来的两倍，这将收益减少了 2 倍，这仍然使我们的收益增加了 25 倍)。

除了这两个问题之外，很明显，使用 NumPy 可以极大地提高速度。我们现在将使用惊人的编织包来进一步加快速度。

## 使用编织。闪电战

如果我们使用 weave.blitz，NumPy 表达式可以大大加快速度。

```py
# import necessary modules and functions
from scipy import weave
# ...
    def blitzTimeStep(self, dt=0.0):
        """Takes a time step using a NumPy expression that has been
        blitzed using weave."""
        g = self.grid
        dx2, dy2 = g.dx**2, g.dy**2
        dnr_inv = 0.5/(dx2 + dy2)
        u = g.u
        g.old_u = u.copy()

        # The actual iteration
        expr = "u[1:-1, 1:-1] = ((u[0:-2, 1:-1] + u[2:, 1:-1])*dy2 + "\
               "(u[1:-1,0:-2] + u[1:-1, 2:])*dx2)*dnr_inv"
        weave.blitz(expr, check_size=0)

        return g.computeError() 
```

如果您注意到了，唯一改变的是我们在原始数值表达式周围加上引号，并调用这个字符串“expr”，然后调用 weave.blitz。当设置为 1 时，“check_size”关键字会进行一些健全性检查，并将在您调试代码时使用。然而，对于纯速度，将其设置为 0 是明智的。这一次，当我们对 500x500 数组的代码进行一次迭代时，只需要大约 0.1 秒，大约增加了三倍！还有几件事需要注意。

1.  第一次调用这个方法，需要很长时间才能在背后做一些神奇的事情。下次调用它时，它将立即运行。编织文档中有更多的细节。基本上，weave.blitz 将 NumPy 表达式转换为 C++代码，并将 blitz++用于数组表达式，构建一个 Python 模块，将其存储在一个特殊的位置，并在下次进行函数调用时调用该模块。
2.  同样，我们需要使用临时数组来计算错误。
3.  blitz 不使用*而使用*进行计算，因此其行为更像循环的原始(慢)方式，因为计算的值会被立即重用。

除了这些点之外，与原始的 for 循环相比，结果是相同的。只比原代码快 170 倍左右！我们现在将看看另一种方法来加快我们最初的 for 循环。输入 weave.inline！

## 使用编织。直列

内联允许将 C 或 C++代码直接嵌入到 Python 代码中。下面是代码内联版本的简单版本。

```py
from scipy.weave import converters
# ...
    def inlineTimeStep(self, dt=0.0):
        """Takes a time step using inlined C code -- this version uses
        blitz arrays."""
        g = self.grid
        nx, ny = g.u.shape
        dx2, dy2 = g.dx**2, g.dy**2
        dnr_inv = 0.5/(dx2 + dy2)
        u = g.u

        code = """
               #line 120 "laplace.py" (This is only useful for debugging)
               double tmp, err, diff;
               err = 0.0;
               for (int i=1; i<nx-1; ++i) {
                   for (int j=1; j<ny-1; ++j) {
                       tmp = u(i,j);
                       u(i,j) = ((u(i-1,j) + u(i+1,j))*dy2 +
                                 (u(i,j-1) + u(i,j+1))*dx2)*dnr_inv;
                       diff = u(i,j) - tmp;
                       err += diff*diff;
                   }
              }
               return_val = sqrt(err);
               """
        # compiler keyword only needed on windows with MSVC installed
        err = weave.inline(code,
                           ['u', 'dx2', 'dy2', 'dnr_inv', 'nx', 'ny'],
                           type_converters=converters.blitz,
                           compiler = 'gcc')
        return err 
```

代码本身看起来非常简单(这就是内联如此酷的原因)。内联函数调用参数都是不言自明的。带' # 120 行...'的行只用于调试，无论如何不影响速度。同样，第一次运行这个函数时，需要花很长时间在幕后做一些事情，下一次它就会消失。这次请注意，我们的循环具有更大的灵活性，可以轻松计算错误项，而不需要临时数组。为这个版本计时会导致 500x500 数组每次迭代的时间仅为 0.04 秒！这相当于一个巨大的 375 倍的速度增加了平原旧的循环。请记住，我们没有牺牲 Python 不可思议的灵活性！这个循环包含看起来非常好的代码，但是如果我们愿意，我们可以通过编写一点脏代码来进一步加快速度。我们在这里不讨论这个问题，但是可以说，通过使用不同的方法，有可能获得 2 倍的速度。这个代码基本上是对 NumPy 数组数据进行指针运算，而不是使用 blitz++数组。这段代码是埃里克·琼斯贡献的。本文附带的源代码包含此代码。

接下来，我们看看如何在 Fortran 中轻松实现循环，并通过使用 f2py 从 Python 中调用它。

## 使用 f2py

f2py 是一个惊人的实用程序，可以让你轻松地从 Python 中调用 Fortran 函数。首先，我们将编写一个小的 Fortran77 子程序来进行计算。这是代码。

```py
c File flaplace.f
      subroutine timestep(u,n,m,dx,dy,error)
      double precision u(n,m)
      double precision dx,dy,dx2,dy2,dnr_inv,tmp,diff
      integer n,m,i,j
cf2py intent(in) :: dx,dy
cf2py intent(in,out) :: u
cf2py intent(out) :: error
cf2py intent(hide) :: n,m
      dx2 = dx*dx
      dy2 = dy*dy
      dnr_inv = 0.5d0 / (dx2+dy2)
      error = 0
      do 200,j=2,m-1
         do 100,i=2,n-1
            tmp = u(i,j)
            u(i,j) = ((u(i-1,j) + u(i+1,j))*dy2+
     &           (u(i,j-1) + u(i,j+1))*dx2)*dnr_inv
            diff = u(i,j) - tmp
            error = error + diff*diff
 100     continue
 200  continue
      error = sqrt(error)
      end 
```

以 cf2py 开头的行是特殊的 f2py 指令，记录在 f2py 中。对于懂一些 Fortran 的人来说，剩下的代码很简单。我们通常使用以下命令为此创建一个 Python 模块。

```py
% f2py -c flaplace.f -m flaplace 
```

下面是 Python 的外观。

```py
import flaplace

    def fortranTimeStep(self, dt=0.0):
        """Takes a time step using a simple fortran module that
        implements the loop in Fortran.  """
        g = self.grid
        g.u, err = flaplace.timestep(g.u, g.dx, g.dy)
        return err 
```

就是这样！希望有一天 scipy.weave 能让我们在线完成这项工作，而不需要我们编写单独的 Fortran 文件。Fortran 代码和 f2py 示例由 f2py 的作者 Pearu Peterson 提供。无论如何，使用这个模块，对于 500x500 的网格，每次迭代大约需要 0.029 秒！这比原始代码的速度提高了大约 500 倍。

f2py 还可以与更现代的 Fortran 版本一起工作。这很有用，因为 Fortran90 有特殊的数组特性，允许更紧凑、更好、更快的代码。Fortran90 中有相同的子程序:

```py
! File flaplace90_arrays.f90
subroutine timestep(u,n,m,dx,dy,error)
implicit none
!Pythonic array indices, from 0 to n-1.
real (kind=8), dimension(0:n-1,0:m-1), intent(inout):: u
real (kind=8), intent(in) :: dx,dy
real (kind=8), intent(out) :: error
integer, intent(in) :: n,m
real (kind=8), dimension(0:n-1,0:m-1) :: diff
real (kind=8) :: dx2,dy2,dnr_inv
!f2py intent(in) :: dx,dy
!f2py intent(in,out) :: u
!f2py intent(out) :: error
!f2py intent(hide) :: n,m
dx2 = dx*dx
dy2 = dy*dy
dnr_inv = 0.5d0 / (dx2+dy2)
diff=u
u(1:n-2, 1:m-2) = ((u(0:n-3, 1:m-2) + u(2:n-1, 1:m-2))*dy2 + &
                         (u(1:n-2,0:m-3) + u(1:n-2, 2:m-1))*dx2)*dnr_inv
error=sqrt(sum((u-diff)**2))
end subroutine 
```

请注意，这些操作是在一行中执行的，非常类似于 Numpy。编译步骤完全相同。在 1000x1000 的网格中，这段代码比 fortran77 循环快 2.2 倍。

源 tarball([perppy _ 2 . tgz](PerformancePython86aa.html))还包含一个使用 forall 构造的 Fortran95 子例程，其性能非常相似。

## 使用 Pyrex/Cython

我们还使用快速内联版本的代码在 Pyrex 中实现了 timeStep 函数。Pyrex 源代码比 weave、blitz 或 Fortran 代码稍长，因为我们必须公开 NumPy 数组结构。基本功能如下。

特拉维斯·奥列芬特写了一个 Cython 版本的例子。

```py
def pyrexTimeStep(ndarray u, double dx, double dy):
    if chr(u.descr.type) <> "d":
        raise TypeError("Double array required")
    if u.nd <> 2:
        raise ValueError("2 dimensional array required")
    cdef int nx, ny
    cdef double dx2, dy2, dnr_inv, err
    cdef double *elem

    nx = u.dimensions[0]
    ny = u.dimensions[1]
    dx2, dy2 = dx**2, dy**2
    dnr_inv = 0.5/(dx2 + dy2)
    elem = u.data

    err = 0.0
    cdef int i, j
    cdef double *uc, *uu, *ud, *ul, *ur
    cdef double diff, tmp
    for i from 1 <= i < nx-1:
        uc = elem + i*ny + 1
        ur = elem + i*ny + 2
        ul = elem + i*ny
        uu = elem + (i+1)*ny + 1
        ud = elem + (i-1)*ny + 1

        for j from 1 <= j < ny-1:
            tmp = uc[0]
            uc[0] = ((ul[0] + ur[0])*dy2 +
                     (uu[0] + ud[0])*dx2)*dnr_inv
            diff = uc[0] - tmp
            err = err + diff*diff
            uc = uc + 1; ur = ur + 1;  ul = ul + 1
            uu = uu + 1; ud = ud + 1

    return sqrt(err) 
```

这个函数看起来很长，但写起来并不太难。通过提供方便的函数来访问数组，也可以在不进行指针运算的情况下进行写入。然而，上面显示的代码很快。本文提供的源代码包含完整的 Pyrex 文件和一个 setup.py 脚本来构建它。计时这个版本，我们发现这个版本和快速内联版本一样快，只需要 0.025 秒。

## 利用 Matlab 和 Octave

我们已经在 Matlab 和 Octave 中实现了数字版本( [laplace.m](Per%20formancePythonffae.html) )并在不同的计算机上运行测试(因此得到下表中的“估计”值)。我们发现，在 Matlab 中没有获得显著的加速，而 Octave 的运行速度比`NumPy`慢两倍。详细的图表可以在[这里](http://lbolla.wordpress.com/2007/04/11/numerical-%20computing-matlab-vs-pythonnumpyweave/)找到。

## C++中的一个实现

最后，作为比较，我们在没有任何 Python 的情况下，用简单的 C++实现了这个。人们会期望 C++代码会更快，但令人惊讶的是，不会太快！考虑到使用 Python 开发非常容易，这种速度上的降低并不是很明显。

## 最后的比较

以下是 100 次迭代的 500x500 网格的一些时序结果。请注意，我们还比较了将慢速 Python 版本与 Psyco 一起使用的结果。

解决方案类型|花费的时间(秒)—|—Python(估计)|1500.0Python + Psyco(估计)|1138.0Python + `NumPy`表达式| 29.3 blitz | 9.5 Inline | 4.3 fast Inline | 2.3 Tyson/Fortran | 2.9 pyrex | 2.5 atlab(估计)| 29.0Octave(估计)| 60.0Pure C++ | 2.16

考虑到 Python 的灵活性和强大功能，这是相当惊人的。

在这里下载本指南的源代码: [`perfpy_2.tgz`](../_downloads/perfpy_2.tgz)

查看完整的 Python 代码示例: [`laplace.py`](../_downloads/laplace.py)

查看完整的 Matlab/Octave 代码示例: [`laplace.m`](../_downloads/laplace.py)

## 附件

*   [`laplace.m`](../_downloads/laplace.m)
*   [`laplace.py`](../_downloads/laplace.py)
*   [`perfpy_2.tgz`](../_downloads/perfpy_2.tgz)

# 用 numpy 和 scipy 进行并行编程

# 用 numpy 和 scipy 进行并行编程

多处理器和多核机器变得越来越普遍，利用它们让代码运行得更快会很好。numpy/scipy 在这方面并不完美，但有些事情你可以做。利用并行处理系统的最佳方式取决于您正在执行的任务和您正在使用的并行系统。如果你有一个大的复杂的工作或一群机器，充分利用将需要很多思考。但是许多任务可以用一种相当简单的方式并行化。

俗话说，“[过早优化是万恶之源](http://www.acm.org/ubiquity/views/v7i24_fallacy.html)”。使用多核机器最多可以提供可用内核数量的一倍加速。在考虑并行化之前，先让你的代码工作起来。然后问问你自己你的代码是否真的需要更快。除非迫不得已，否则不要走上充满 bug 的并行化之路。

## 简单并行化

### 将您的工作分解成更小的工作，并同时运行它们

例如，如果你正在分析来自脉冲星调查的数据，并且你有数千束光束要分析，每束花一天的时间，最简单的(也可能是最有效的)并行化任务的方法是简单地运行每束光束作为一项工作。有两个处理器的机器只能运行两个作业。无需担心锁定或通信；不需要编写知道并行运行的代码。如果每个进程都需要和你的机器一样多的内存，或者它们都是 IO 重的，你可能会有问题，但是总的来说，这是一个简单有效的并行化你的代码的方法——如果它有效的话。并不是所有的任务都能很好地完成。如果您的目标是处理单个图像，那么不需要大量工作就不清楚如何完成。

### 使用并行原语

numpy 的一大优势是您可以非常清晰地表达数组操作。例如，要计算矩阵 A 和矩阵 B 的乘积，只需:

```py
>>> C = numpy.dot(A,B) 
```

这不仅读写简单明了，因为 numpy 知道你想做一个矩阵点积，它可以使用作为“BLAS”(基本线性代数子程序)的一部分获得的优化实现。这通常是一个经过精心调整的库，通过利用高速缓冲存储器和汇编器实现在您的硬件上尽可能快地运行。但是现在许多架构都有 BLAS，它也利用了多核机器。如果您的 numpy/scipy 是使用其中的一个编译的，那么 dot()将被并行计算(如果这样更快的话)，而您不需要做任何事情。类似的还有其他矩阵运算，像求逆、奇异值分解、行列式等等。例如，开源库 [ATLAS](http://math-atlas.sourceforge.net/) 允许在编译时选择并行度(线程数)。英特尔专有的 [MKL](http://www.intel.com/cd/software/products/asmo-%20na/eng/307757.htm) 库提供了在运行时选择并行级别的可能性。还有 [GOTO](http://www.tacc.utexas.edu/resources/software/software_downloads.php) 库，允许运行时选择并行级别。这是一个商业产品，但源代码是免费分发的学术用途。

最后，scipy/numpy 不会像

```py
>>> A = B + C
>>> A = numpy.sin(B)
>>> A = scipy.stats.norm.isf(B) 
```

这些操作按顺序运行，没有利用多核机器的优势(见下文)。原则上，这可以在不做太多工作的情况下改变。OpenMP 是 C 语言的扩展，它允许编译器为适当注释的循环(和其他东西)生成并行代码。如果有人坐下来在 numpy 中注释了几个核心循环(也可能在 scipy 中)，然后在 OpenMP 打开的情况下编译了 numpy/scipy，那么上述三个循环将自动并行运行。当然，在现实中，人们会想要一些运行时控制——例如，如果计划在同一台多处理器机器上运行几个作业，人们可能想要关闭自动并行化。

### 编写多线程或多处理代码

有时你可以看到如何将你的问题分解成几个并行的任务，但是这些任务需要某种同步或通信。例如，您可能有一个可以并行运行的作业列表，但是您需要收集它们的所有结果，进行一些汇总计算，然后启动另一批并行作业。在 Python 中有两种方法可以做到这一点，使用多个[线程](http://en.wikipe%20dia.org/wiki/Thread_(computer_science)或[进程](http://en.wikipedia.org/wiki/Process_(computing)。

#### 线

线程通常比进程“轻”，并且可以比进程更快地创建、销毁和切换。它们通常是利用多核系统的首选。但是，python 的多线程有一个关键的限制；[全局解释器锁定](http://docs.python.org/api/threads.html) ( [GIL](http://effbot.org/pyfaq/what-is-the-global-%20interpreter-lock.htm) )。由于各种原因(快速的网络搜索会出现大量的[讨论](http://blog.ianbicking.org/gil-of-%20doom.html)，更不用说[争论](http://mail.python.org%20/pipermail/python-3000/2007-May/007414.html)，关于[为什么会存在](http://www.artima.com/weblogs/viewpost.jsp?thread=214235)和[这是否是个好主意](http://blog.snaplogic.org/?p=94)，python 的实现方式是一次只能有一个线程访问解释器。这基本上意味着一次只能有一个线程运行 python 代码。这几乎意味着你根本没有利用并行处理的任何优势。例外很少，但很重要:当一个线程在等待 IO 时(比如，让你键入一些东西，或者等待网络中出现一些东西)，python 会释放 GIL，这样其他线程就可以运行了。对我们来说更重要的是，当 numpy 进行数组操作时，python 也发布了 GIL。因此，如果你告诉一个线程去做:

```py
>>> print "%s  %s  %s  %s and %s" %( ("spam",) *3 + ("eggs",) + ("spam",) )
>>> A = B + C
>>> print A 
```

在打印操作和%格式化操作期间，没有其他线程可以执行。但是在 A = B + C 期间，另一个线程可以运行——如果您已经用 numpy 风格编写了代码，那么大部分计算将在 A = B + C 这样的一些数组操作中完成。因此，您实际上可以通过使用多个线程来获得加速。

python 线程模块是标准库的一部分，并提供多线程工具。鉴于上面讨论的限制，在多线程架构中仔细重写代码可能不值得。但是有时候你可以不费吹灰之力完成多线程，在这些情况下，这是值得的。一个例子见`Cookbook/Multithreading`。[这个秘籍](http://code.activestate.com/recipes/576519/)提供了一个线程池()接口，该接口的 API 与进程(如下)的 API 相同，这也是我们感兴趣的。还有非常类似的 [ThreadPo ol](http://www.chrisarndt.de/projects/threadpool/) 模块。

#### 处理

克服上述 GIL 限制的一种方法是使用多个完整进程，而不是线程。每个进程都有自己的 GIL，所以它们不会像线程那样互相阻塞。从 python 2.6 开始，标准库包括一个[多处理](http:/%20/docs.python.org/library/multiprocessing.html)模块，与线程模块具有相同的接口。对于 Python 的早期版本，这可以作为[处理](http://pyprocessing.berlios.de/)模块获得(python 2.6 的多处理模块的一个后端口，适用于 python 2.4 和 2.5，正在开发中:[多处理](http://code.google.com/p/python-%20multiprocessing))。可以在进程之间共享内存，包括 [numpy 数组](http://coding.derkeiler.com/Arc%20hive/Python/comp.lang.python/2008-09/msg00937.html)。这使得线程的大部分好处没有 GIL 的问题。它还提供了一个简单的 Pool()接口，该接口的功能是映射和应用类似于`Cookbook/Multithreading`示例中的命令。

#### 比较

下面是一个非常基本的比较，它说明了 GIL(在双核机器上)的效果。

```py
import numpy as np
import math
def f(x):
    print x
    y = [1]*10000000
    [math.exp(i) for i in y]
def g(x):
    print x
    y = np.ones(10000000)
    np.exp(y)

from handythread import foreach
from processing import Pool
from timings import f,g
def fornorm(f,l):
    for i in l:
        f(i)
time fornorm(g,range(100))
time fornorm(f,range(10))
time foreach(g,range(100),threads=2)
time foreach(f,range(10),threads=2)
p = Pool(2)
time p.map(g,range(100))
time p.map(f,range(100)) 
```

| 100*g()| 10*f()—|—|—正常| `43.5s` | `48s` 2 线程| `31s` | `71.5s` 2 进程| `27s` | `31.23`

对于不释放 GIL 的函数`f()`，线程实际上比串行代码表现更差，大概是由于上下文切换的开销。然而，使用两个进程确实提供了显著的加速。对于使用 numpy 并释放 GIL 的函数`g()`，线程和进程都提供了显著的速度提升，尽管多进程稍快。

## 复杂的并行化

如果你需要复杂的并行性——比如说，你有一个计算集群，你的工作需要经常相互交流——你就需要开始考虑真正的并行编程。这是计算机科学研究生课程的一个主题，我不打算在这里讨论它。但是有一些 python 工具可以用来实现你在研究生课程中学到的东西。(我可能有些夸张——有些并行化并没有那么难，其中一些工具让它变得相当容易。但是要意识到并行代码比串行代码更难编写和调试。)

*   [IPython1](http://ipython.scipy.org/moin/IPython1)
*   `mpi4py`
*   [平行蟒](http://www.parallelpython.com/)
*   [POSH](http://poshmodule.sourceforge.net/)