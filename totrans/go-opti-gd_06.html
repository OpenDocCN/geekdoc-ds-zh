<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Memory Preallocation¶</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Memory Preallocation¶</h1>
<blockquote>原文：<a href="https://goperf.dev/01-common-patterns/mem-prealloc/">https://goperf.dev/01-common-patterns/mem-prealloc/</a></blockquote>
                
                  


  
  



<p>Memory preallocation is a simple but effective way to improve performance in Go programs that work with slices or maps that grow over time. Instead of letting the runtime resize these structures as they fill up—often at unpredictable points—you allocate the space you need upfront. This avoids the cost of repeated allocations, internal copying, and extra GC pressure as intermediate objects are created and discarded.</p>
<p>In high-throughput or latency-sensitive systems, preallocating memory makes execution more predictable and helps avoid performance cliffs that show up under load. If the workload size is known or can be reasonably estimated, there’s no reason to let the allocator do the guessing.</p>
<h2 id="why-preallocation-matters">Why Preallocation Matters<a class="headerlink" href="#why-preallocation-matters" title="Permanent link">¶</a></h2>
<p>Go’s slices and maps grow automatically as new elements are added, but that convenience comes with a cost. When capacity is exceeded, the runtime allocates a larger backing array or hash table and copies the existing data over. This reallocation adds memory pressure, burns CPU cycles, and can stall tight loops in high-throughput paths. In performance-critical code—especially where the size is known or can be estimated—frequent resizing is unnecessary overhead. Preallocating avoids these penalties by giving the runtime enough room to work without interruption.</p>
<p>Go uses a hybrid growth strategy for slices to balance speed and memory efficiency. Early on, capacities double with each expansion—2, 4, 8, 16—minimizing the number of allocations. But once a slice exceeds around 1024 elements, the growth rate slows to roughly 25%. So instead of jumping from 1024 to 2048, the next allocation might grow to about 1280.</p>
<p>This shift reduces memory waste on large slices but increases the frequency of allocations if the final size is known but not preallocated. In those cases, using make([]T, 0, expectedSize) is the more efficient choice—it avoids repeated resizing and cuts down on unnecessary copying.</p>
<div class="highlight"><pre><code>s := make([]int, 0)
for i := 0; i &lt; 10_000; i++ {
    s = append(s, i)
    fmt.Printf("Len: %d, Cap: %d\n", len(s), cap(s))
}
</code></pre></div>
<p>Output illustrating typical growth:</p>
<div class="highlight"><pre><code>Len: 1, Cap: 1
Len: 2, Cap: 2
Len: 3, Cap: 4
Len: 5, Cap: 8
...
Len: 1024, Cap: 1024
Len: 1025, Cap: 1280
</code></pre></div>
<h2 id="practical-preallocation-examples">Practical Preallocation Examples<a class="headerlink" href="#practical-preallocation-examples" title="Permanent link">¶</a></h2>
<h3 id="slice-preallocation">Slice Preallocation<a class="headerlink" href="#slice-preallocation" title="Permanent link">¶</a></h3>
<p>Without preallocation, each append operation might trigger new allocations:</p>
<div class="highlight"><pre><code>// Inefficient
var result []int
for i := 0; i &lt; 10000; i++ {
    result = append(result, i)
}
</code></pre></div>
<p>This pattern causes Go to allocate larger underlying arrays repeatedly as the slice grows, resulting in memory copying and GC pressure. We can avoid that by using <code>make</code> with a specified capacity:</p>
<div class="highlight"><pre><code>// Efficient
result := make([]int, 0, 10000)
for i := 0; i &lt; 10000; i++ {
    result = append(result, i)
}
</code></pre></div>
<p>If it is known that the slice will be fully populated, we can be even more efficient by avoiding bounds checks:</p>
<div class="highlight"><pre><code>// Efficient
result := make([]int, 10000)
for i := range result {
    result[i] = i
}
</code></pre></div>
<h3 id="map-preallocation">Map Preallocation<a class="headerlink" href="#map-preallocation" title="Permanent link">¶</a></h3>
<p>Maps grow similarly. By default, Go doesn’t know how many elements you’ll add, so it resizes the underlying structure as needed.</p>
<div class="highlight"><pre><code>// Inefficient
m := make(map[int]string)
for i := 0; i &lt; 10000; i++ {
    m[i] = fmt.Sprintf("val-%d", i)
}
</code></pre></div>
<p>Starting with Go 1.11, you can preallocate <code>map</code> capacity too:</p>
<div class="highlight"><pre><code>// Efficient
m := make(map[int]string, 10000)
for i := 0; i &lt; 10000; i++ {
    m[i] = fmt.Sprintf("val-%d", i)
}
</code></pre></div>
<p>This helps the runtime allocate enough internal storage upfront, avoiding rehashing and resizing costs.</p>
<h2 id="benchmarking-impact">Benchmarking Impact<a class="headerlink" href="#benchmarking-impact" title="Permanent link">¶</a></h2>
<p>Here’s a simple benchmark comparing appending to a preallocated slice vs. a zero-capacity slice:</p>
<details class="example">
<summary>Show the benchmark file</summary>
<div class="highlight"><pre><code>package perf

import (
    "testing"
)

func BenchmarkAppendNoPrealloc(b *testing.B) {
    for b.Loop() {
        var s []int
        for j := 0; j &lt; 10000; j++ {
            s = append(s, j)
        }
    }
}

func BenchmarkAppendWithPrealloc(b *testing.B) {
    for b.Loop() {
        s := make([]int, 0, 10000)
        for j := 0; j &lt; 10000; j++ {
            s = append(s, j)
        }
    }
}
</code></pre></div>
</details>
<p>You’ll typically observe that preallocation reduces allocations to a single one per operation and significantly improves throughput.</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Iterations</th>
<th>Time per op (ns)</th>
<th>Bytes per op</th>
<th>Allocs per op</th>
</tr>
</thead>
<tbody>
<tr>
<td>BenchmarkAppendNoPrealloc-14</td>
<td>41,727</td>
<td>28,539</td>
<td>357,626</td>
<td>19</td>
</tr>
<tr>
<td>BenchmarkAppendWithPrealloc-14</td>
<td>170,154</td>
<td>7,093</td>
<td>81,920</td>
<td>1</td>
</tr>
</tbody>
</table>
<h2 id="when-to-preallocate">When To Preallocate<a class="headerlink" href="#when-to-preallocate" title="Permanent link">¶</a></h2>
<p><svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8c.76 0 1.5.11 2.2.31l1.57-1.57A9.8 9.8 0 0 0 12 2 10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10M7.91 10.08 6.5 11.5 11 16 21 6l-1.41-1.42L11 13.17z"/></svg> Preallocate when:</p>
<ul>
<li>The number of elements in slices or maps is known or reasonably predictable. Allocating memory up front avoids the cost of repeated resizing as the data structure grows.</li>
<li>Your application involves tight loops or high-throughput data processing. Preallocation reduces per-iteration overhead and helps maintain steady performance under load.</li>
<li>Minimizing garbage collection overhead is crucial for your application's performance. Fewer allocations mean less work for the garbage collector, resulting in lower latency and more consistent behavior.</li>
</ul>
<p><svg viewbox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M448 128H270.4c1 5.2 1.6 10.5 1.6 16v16h176c8.8 0 16-7.2 16-16s-7.2-16-16-16m-224 16c0-17.7-14.3-32-32-32h-24c-66.3 0-120 53.7-120 120v48c0 52.5 33.7 97.1 80.7 113.4-.5-3.1-.7-6.2-.7-9.4 0-20 9.2-37.9 23.6-49.7-4.9-9-7.6-19.4-7.6-30.3 0-15.1 5.3-29 14-40-8.8-11-14-24.9-14-40v-40c0-13.3 10.7-24 24-24s24 10.7 24 24v40c0 8.8 7.2 16 16 16s16-7.2 16-16zm-32-80c18 0 34.6 6 48 16h208c35.3 0 64 28.7 64 64s-28.7 64-64 64h-82c1.3 5.1 2 10.5 2 16 0 25.3-14.7 47.2-36 57.6 2.6 7 4 14.5 4 22.4 0 20-9.2 37.9-23.6 49.7 4.9 9 7.6 19.4 7.6 30.3 0 35.3-28.7 64-64 64h-88C75.2 448 0 372.8 0 280v-48C0 139.2 75.2 64 168 64zm64 336c8.8 0 16-7.2 16-16s-7.2-16-16-16h-64c-8.8 0-16 7.2-16 16s7.2 16 16 16zm16-176c0 5.5-.7 10.9-2 16h34c8.8 0 16-7.2 16-16s-7.2-16-16-16h-32zm-24 64h-40c-8.8 0-16 7.2-16 16s7.2 16 16 16h64c8.8 0 16-7.2 16-16s-7.2-16-16-16z"/></svg> Avoid preallocation when:</p>
<ul>
<li>The data size is highly variable and unpredictable. If input sizes fluctuate widely, any fixed-size preallocation risks being either too small (leading to reallocations) or too large (wasting memory).</li>
<li>Over-allocation risks significant memory waste. Reserving more memory than needed increases your application’s footprint and can negatively impact cache locality or trigger unnecessary GC activity.</li>
<li>You’re prematurely optimizing. Always verify with profiling. Preallocation is effective, but only when it addresses a real bottleneck or allocation hotspot in your workload.</li>
</ul>









  




                
                  
</body>
</html>