- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DYNAMIC PROGRAMMING
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic programming** was invented by Richard Bellman in the 1950s. Don''t
    try to infer anything about the technique from its name. As Bellman described
    it, the name “dynamic programming” was chosen to hide from governmental sponsors
    “the fact that I was really doing mathematics… [the phrase dynamic programming]
    was something not even a Congressman could object to.” [^(94)](#c15-fn-0001)'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic programming is a method for efficiently solving problems that exhibit
    the characteristics of overlapping subproblems and optimal substructure. Fortunately,
    many optimization problems exhibit these characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: A problem has **optimal substructure** if a globally optimal solution can be
    found by combining optimal solutions to local subproblems. We've already looked
    at a number of such problems. Merge sort, for example, exploits the fact that
    a list can be sorted by first sorting sublists and then merging the solutions.
  prefs: []
  type: TYPE_NORMAL
- en: A problem has **overlapping subproblems** if an optimal solution involves solving
    the same problem multiple times. Merge sort does not exhibit this property. Even
    though we are performing a merge many times, we are merging different lists each
    time.
  prefs: []
  type: TYPE_NORMAL
- en: It's not immediately obvious, but the 0/1 knapsack problem exhibits both of
    these properties. First, however, we digress to look at a problem where the optimal
    substructure and overlapping subproblems are more obvious.
  prefs: []
  type: TYPE_NORMAL
- en: 15.1 Fibonacci Sequences, Revisited
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Chapter 4, we looked at a straightforward recursive implementation of the
    Fibonacci function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: While this implementation of the recurrence is obviously correct, it is terribly
    inefficient. Try, for example, running `fib(120)`, but don't wait for it to complete.
    The complexity of the implementation is a bit hard to derive, but it is roughly
    `O(fib(n))`. That is, its growth is proportional to the growth in the value of
    the result, and the growth rate of the Fibonacci sequence is substantial. For
    example, `fib(120)` is `8,670,007,398,507,948,658,051,921`. If each recursive
    call took a nanosecond, `fib(120)` would take about `250,000` years to finish.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try and figure out why this implementation takes so long. Given the tiny
    amount of code in the body of `fib`, it's clear that the problem must be the number
    of times that `fib` calls itself. As an example, look at the tree of calls associated
    with the invocation `fib(6)`.
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0001.jpg](../images/c15-fig-0001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15-1 Tree of calls for recursive Fibonacci
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we are computing the same values over and over again. For example,
    `fib` gets called with `3` three times, and each of these calls provokes four
    additional calls of `fib`. It doesn't require a genius to think that it might
    be a good idea to record the value returned by the first call, and then look it
    up rather than compute it each time it is needed. This is the key idea behind
    dynamic programming.
  prefs: []
  type: TYPE_NORMAL
- en: There are two approaches to dynamic programming
  prefs: []
  type: TYPE_NORMAL
- en: '**Memoization** solves the original problem top-down. It starts from the original
    problem, breaks it into subproblems, breaks the subproblems into subproblems,
    etc. Each time it solves a subproblem, it stores the answer in a table. Each time
    it needs to solve a subproblem, it first tries to look up the answer in the table.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tabular** is a bottom-up method. It starts from the smallest problems, and
    stores the answers to those in a table. It then combines the solutions to these
    problems to solve the next smallest problems, and stores those answers in the
    table.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 15-2](#c15-fig-0002) contains implementations of Fibonacci using each
    approach to dynamic programming. The function `fib_memo` has a parameter, `memo`,
    that it uses to keep track of the numbers it has already evaluated. The parameter
    has a default value, the empty dictionary, so that clients of `fib_memo` don''t
    have to worry about supplying an initial value for `memo`. When `fib_memo` is
    called with an `n > 1`, it attempts to look up `n` in `memo`. If it is not there
    (because this is the first time `fib_memo` has been called with that value), an
    exception is raised. When this happens, `fib_memo` uses the normal Fibonacci recurrence,
    and then stores the result in `memo`.'
  prefs: []
  type: TYPE_NORMAL
- en: The function `fib_tab` is quite simple. It exploits the fact that all of the
    subproblems for Fibonacci are known in advance and easy to enumerate in a useful
    order.
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0002.jpg](../images/c15-fig-0002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-2](#c15-fig-0002a) Implementing Fibonacci using a memo'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you try running `fib_memo` and `fib_tab`, you will see that they are indeed
    quite fast: `fib(120)` returns almost instantly. What is the complexity of these
    functions? `fib_memo` calls `fib` exactly once for each value from 0 to `n`. Therefore,
    under the assumption that dictionary lookup can be done in constant time, the
    time complexity of `fib_memo(n)` is in `O(n)`. `fib_tab` is even more obviously
    in `O(n)`.'
  prefs: []
  type: TYPE_NORMAL
- en: If solving the original problem requires solving all subproblems, it is usually
    better to use the tabular approach. It is simpler to program, and faster because
    it doesn't have the overhead associated with recursive calls and can pre-allocate
    a table of the appropriate size rather than growing a memo. If only some of the
    subproblems need to be solved (which is often the case), memoization is typically
    more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: Use the tabular method to implement a dynamic programming
    solution that meets the specification'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 15.2 Dynamic Programming and the 0/1 Knapsack Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the optimization problems we looked at in Chapter 14 was the 0/1 knapsack
    problem. Recall that we looked at a greedy algorithm that ran in `n log n` time,
    but was not guaranteed to find an optimal solution. We also looked at a brute-force
    algorithm that was guaranteed to find an optimal solution, but ran in exponential
    time. Finally, we discussed the fact that the problem is inherently exponential
    in the size of the input. In the worst case, one cannot find an optimal solution
    without looking at all possible answers.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the situation is not as bad as it seems. Dynamic programming provides
    a practical method for solving most 0/1 knapsack problems in a reasonable amount
    of time. As a first step in deriving such a solution, we begin with an exponential
    solution based on exhaustive enumeration. The key idea is to think about exploring
    the space of possible solutions by constructing a rooted binary tree that enumerates
    all states satisfying the weight constraint.
  prefs: []
  type: TYPE_NORMAL
- en: A **rooted binary tree** is an acyclic directed graph in which
  prefs: []
  type: TYPE_NORMAL
- en: There is exactly one node with no parents. This is called the **root**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each non-root node has exactly one parent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each node has at most two children. A childless node is called a **leaf**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each node in the search tree for the 0/1 knapsack problem is labeled with a
    quadruple that denotes a partial solution to the knapsack problem. The elements
    of the quadruple are:'
  prefs: []
  type: TYPE_NORMAL
- en: A set of items to be taken
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of items for which a decision has not been made
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total value of the items in the set of items to be taken (this is merely
    an optimization, since the value could be computed from the set)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The remaining space in the knapsack. (Again, this is an optimization, since
    it is merely the difference between the weight allowed and the weight of all the
    items taken so far.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tree is built top-down starting with the root.[^(95)](#c15-fn-0002) One
    element is selected from the still-to-be-considered items. If there is room for
    that item in the knapsack, a node is constructed that reflects the consequence
    of choosing to take that item. By convention, we draw that node as the left child.
    The right child shows the consequences of choosing not to take that item. The
    process is then applied recursively until either the knapsack is full or there
    are no more items to consider. Because each edge represents a decision (to take
    or not to take an item), such trees are called **decision trees**.[^(96)](#c15-fn-0003)
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 15-3](#c15-fig-0003) is a table describing a set of items.'
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0003.jpg](../images/c15-fig-0003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-3](#c15-fig-0003a) Table of items with values and weights'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 15-4](#c15-fig-0004) is a decision tree for deciding which of those
    items to take under the assumption that the knapsack has a maximum weight of `5`.
    The root of the tree (node 0) has a label `<{}, [a,b,c,d], 0, 5>`, indicating
    that no items have been taken, all items remain to be considered, the value of
    the items taken is `0`, and a weight of `5` is still available. Node `1` indicates
    that item `a` has been taken, `[b,c,d]` remain to be considered, the value of
    the items taken is `6`, and the knapsack can hold another `2` pounds. Node `1`
    has no left child since item `b`, which weighs `3` pounds, would not fit in the
    knapsack.'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 15-4](#c15-fig-0004), the numbers that precede the colon in each
    node indicate one order in which the nodes could be generated. This particular
    ordering is called left-first depth-first. At each node, we attempt to generate
    a left node. If that is impossible, we attempt to generate a right node. If that
    too is impossible, we back up one node (to the parent) and repeat the process.
    Eventually, we find ourselves having generated all descendants of the root, and
    the process halts. When it does, each combination of items that could fit in the
    knapsack has been generated, and any leaf node with the greatest value represents
    an optimal solution. Notice that for each leaf node, either the second element
    is the empty list (indicating that there are no more items to consider taking)
    or the fourth element is 0 (indicating that there is no room left in the knapsack).
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0004.jpg](../images/c15-fig-0004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-4](#c15-fig-0004a) Decision tree for knapsack problem'
  prefs: []
  type: TYPE_NORMAL
- en: Unsurprisingly (especially if you read Chapter 14), the natural implementation
    of a depth-first tree search is recursive. [Figure 15‑5](#c15-fig-0005) contains
    such an implementation. It uses class `Item` and the functions defined in Figure
    14-2.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function `max_val` returns two values, the set of items chosen and the
    total value of those items. It is called with two arguments, corresponding to
    the second and fourth elements of the labels of the nodes in the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '`to_consider`. Those items that nodes higher up in the tree (corresponding
    to earlier calls in the recursive call stack) have not yet considered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`avail`. The amount of space still available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that the implementation of `max_val` does not build the decision tree
    and then look for an optimal node. Instead, it uses the local variable `result`
    to record the best solution found so far. The code in [Figure 15-6](#c15-fig-0006)
    can be used to test `max_val`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When `small_test` (which uses the values in [Figure 15-3](#c15-fig-0003)) is
    run it prints a result indicating that node `8` in [Figure 15-4](#c15-fig-0004)
    is an optimal solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![c15-fig-0005.jpg](../images/c15-fig-0005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-5](#c15-fig-0005a) Using a decision tree to solve a knapsack problem'
  prefs: []
  type: TYPE_NORMAL
- en: The functions `build_many_items` and `big_test` can be used to test `max_val`
    on randomly generated sets of items. Try `big_test(10, 40)`. That didn't take
    long. Now try `big_test(40, 100)`. After you get tired of waiting for it to return,
    stop the computation and ask yourself what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: Let's think about the size of the tree we are exploring. Since at each level
    of the tree we are deciding to keep or not keep one item, the maximum depth of
    the tree is `len(items)`. At level `0` we have only one node, at level `1` up
    to two nodes, at level `2` up to four nodes, and at level `3` up to eight nodes.
    At level `39` we have up to 2^(39) nodes. No wonder it takes a long time to run!
  prefs: []
  type: TYPE_NORMAL
- en: Let's see if dynamic programming can help.
  prefs: []
  type: TYPE_NORMAL
- en: Optimal substructure is visible both in [Figure 15-4](#c15-fig-0004) and in
    [Figure 15-5](#c15-fig-0005). Each parent node combines the solutions reached
    by its children to derive an optimal solution for the subtree rooted at that parent.
    This is reflected in [Figure 15-5](#c15-fig-0005) by the code following the comment
    `#Choose better branch`.
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0006.jpg](../images/c15-fig-0006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-6](#c15-fig-0006a) Testing the decision tree-based implementation'
  prefs: []
  type: TYPE_NORMAL
- en: Are there also overlapping subproblems? At first glance, the answer seems to
    be “no.” At each level of the tree we have a different set of available items
    to consider. This implies that if common subproblems do exist, they must be at
    the same level of the tree. And indeed, at each level of the tree, each node has
    the same set of items to consider taking. However, we can see by looking at the
    labels in [Figure 15-4](#c15-fig-0004) that each node at a level represents a
    different set of choices about the items considered higher in the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think about what problem is being solved at each node: finding the optimal
    items to take from those left to consider, given the remaining available weight.
    The available weight depends upon the total weight of the items taken so far,
    but not on which items are taken or the total value of the items taken. So, for
    example, in [Figure 15-4](#c15-fig-0004), nodes 2 and 7 are actually solving the
    same problem: deciding which elements of [c,d] should be taken, given that the
    available weight is `2`.'
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Figure 15-7](#c15-fig-0007) exploits the optimal substructure and
    overlapping subproblems to provide a memorization-based dynamic programming solution
    to the 0/1 knapsack problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0007.jpg](../images/c15-fig-0007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-7](#c15-fig-0007a) Dynamic programming solution to knapsack problem'
  prefs: []
  type: TYPE_NORMAL
- en: An extra parameter, `memo`, has been added to keep track of solutions to subproblems
    that have already been solved. It is implemented using a dictionary with a key
    constructed from the length of `to_consider` and the available weight. The expression
    `len(to_consider)` is a compact way of representing the items still to be considered.
    This works because items are always removed from the same end (the front) of the
    list `to_consider`.
  prefs: []
  type: TYPE_NORMAL
- en: "Now, replace the call to `max_val` by a call to `fast_max_val` in `big_test`,\
    \ and try running \uFEFF`big_test(40, 100)`. It returns almost instantly with\
    \ an optimal solution to the problem."
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 15-8](#c15-fig-0008) shows the number of calls made when we ran the
    code on problems with a varying number of items and a maximum weight of 100\.
    The growth is hard to quantify, but it is clearly far less than exponential.[^(97)](#c15-fn-0004)
    But how can this be, since we know that the 0/1 knapsack problem is inherently
    exponential in the number of items? Have we found a way to overturn fundamental
    laws of the universe? No, but we have discovered that computational complexity
    can be a subtle notion.[^(98)](#c15-fn-0005)'
  prefs: []
  type: TYPE_NORMAL
- en: '![c15-fig-0008.jpg](../images/c15-fig-0008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 15-8](#c15-fig-0008a) Performance of dynamic programming solution'
  prefs: []
  type: TYPE_NORMAL
- en: The running time of `fast_max_val` is governed by the number of distinct pairs,
    `<to_consider, avail>`, generated. This is because the decision about what to
    do next depends only upon the items still available and the total weight of the
    items already taken.
  prefs: []
  type: TYPE_NORMAL
- en: The number of possible values of `to_consider` is bounded by `len(items)`. The
    number of possible values of `avail` is more difficult to characterize. It is
    bounded from above by the maximum number of distinct totals of weights of the
    items that the knapsack can hold. If the knapsack can hold at most `n` items (based
    on the capacity of the knapsack and the weights of the available items), `avail`
    can take on at most `2`^n different values. In principle, this could be a rather
    large number. However, in practice, it is not usually so large. Even if the knapsack
    has a large capacity, if the weights of the items are chosen from a reasonably
    small set of possible weights, many sets of items will have the same total weight,
    greatly reducing the running time.
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm falls into a complexity class called **pseudo-polynomial**. A
    careful explanation of this concept is beyond the scope of this book. Roughly
    speaking, `fast_max_val` is exponential in the number of bits needed to represent
    the possible values of `avail`.
  prefs: []
  type: TYPE_NORMAL
- en: To see what happens when the values of `avail` are chosen from a considerably
    larger space, change the call to `max_val` in the function `big_test` in [Figure
    15-6](#c15-fig-0006) to
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Finding a solution now takes `1,028,403` calls of `fast_max_val` when the number
    of items is `1024`.
  prefs: []
  type: TYPE_NORMAL
- en: To see what happens when the weights are chosen from an enormous space, we can
    choose the possible weights from the positive reals rather than the positive integers.
    To do this, replace the line,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: in `build_many_items` by the line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Each time it is called, `random.random()` returns a random floating-point number
    between `0.0` and `1.0`, so there are, for all intents and purposes, an infinite
    number of possible weights. Don't hold your breath waiting for this last test
    to finish. Dynamic programming may be a miraculous technique in the common sense
    of the word,[^(99)](#c15-fn-0006) but it is not capable of performing miracles
    in the liturgical sense.
  prefs: []
  type: TYPE_NORMAL
- en: 15.3 Dynamic Programming and Divide-and-Conquer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like divide-and-conquer algorithms, dynamic programming is based upon solving
    independent subproblems and then combining those solutions. There are, however,
    some important differences.
  prefs: []
  type: TYPE_NORMAL
- en: Divide-and-conquer algorithms are based upon finding subproblems that are substantially
    smaller than the original problem. For example, merge sort works by dividing the
    problem size in half at each step. In contrast, dynamic programming involves solving
    problems that are only slightly smaller than the original problem. For example,
    computing the nineteenth Fibonacci number is not a substantially smaller problem
    than computing the twentieth Fibonacci number.
  prefs: []
  type: TYPE_NORMAL
- en: Another important distinction is that the efficiency of divide-and-conquer algorithms
    does not depend upon structuring the algorithm so that identical problems are
    solved repeatedly. In contrast, dynamic programming is efficient only when the
    number of distinct subproblems is significantly smaller than the total number
    of subproblems.
  prefs: []
  type: TYPE_NORMAL
- en: 15.4 Terms Introduced in Chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: dynamic programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optimal substructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: overlapping subproblems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: memoization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tabular method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: rooted binary tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: root
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: leaf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pseudo-polynomial complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
