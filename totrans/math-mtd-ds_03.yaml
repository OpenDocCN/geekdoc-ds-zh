- en: '1.1\. Motivating example: identifying penguin species#'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap01_intro/01_motiv/roch-mmids-intro-motiv.html](https://mmids-textbook.github.io/chap01_intro/01_motiv/roch-mmids-intro-motiv.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Imagine that you are an evolutionary biologist studying penguins. You have collected
    measurements on a large number of individual specimens. Your goal is to identify
    different [species](https://en.wikipedia.org/wiki/Species) within this collection
    based on those measurements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure:** An Adelie penguin. Credit: Andrew Shiva. ([Source](https://commons.wikimedia.org/wiki/File:Hope_Bay-2016-Trinity_Peninsula%E2%80%93Ad%C3%A9lie_penguin_%28Pygoscelis_adeliae%29_04.jpg))'
  prefs: []
  type: TYPE_NORMAL
- en: '![An Adelie penguin](../Images/a64395f1a1be1001d459ff85e5f9fe66.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: We use a penguin dataset collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)
    and the [Palmer Station, Antarctica LTER](https://pallter.marine.rutgers.edu/).
    We upload the data in the form of a data table (similar to a spreadsheet) called
    [`DataFrame`](https://pandas.pydata.org/docs/reference/frame.html) in [`pandas`](https://pandas.pydata.org/docs/),
    where the columns are different measurements (or features) and the rows are different
    samples. Below, we load the data using [`pandas.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html?highlight=read_csv#)
    and show the first \(5\) lines of the dataset (using [`DataFrame.head`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)).
    This dataset is a simplified version (i.e., with some columns removed) of the
    full dataset from [Allison Horst](https://allisonhorst.com/)’s [GitHub page](https://github.com/allisonhorst/palmerpenguins/blob/main/README.md).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '|  | bill_length_mm | bill_depth_mm | flipper_length_mm | body_mass_g |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 39.1 | 18.7 | 181.0 | 3750.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 39.5 | 17.4 | 186.0 | 3800.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 40.3 | 18.0 | 195.0 | 3250.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | NaN | NaN | NaN | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 36.7 | 19.3 | 193.0 | 3450.0 |'
  prefs: []
  type: TYPE_TB
- en: Observe that this dataset has missing values (i.e., the entries `NaN` above).
    A common way to deal with this issue is to remove all rows with missing values.
    This can be done using [`pandas.DataFrame.dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html).
    This kind of pre-processing is fundamental in data science, but we will not discuss
    it much in this book. It is however important to be aware of it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '|  | bill_length_mm | bill_depth_mm | flipper_length_mm | body_mass_g |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 39.1 | 18.7 | 181.0 | 3750.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 39.5 | 17.4 | 186.0 | 3800.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 40.3 | 18.0 | 195.0 | 3250.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 36.7 | 19.3 | 193.0 | 3450.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 39.3 | 20.6 | 190.0 | 3650.0 |'
  prefs: []
  type: TYPE_TB
- en: There are \(342\) samples, as can be seen by using [`pandas.DataFrame.shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)
    which gives the dimensions of the DataFrame as a tuple.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let us first extract the columns into a NumPy array using [`pandas.DataFrame.to_numpy`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html).
    We will have more to say later on about NumPy, a numerical library for Python
    that in essence allows to manipulate vectors and matrices.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We visualize two measurements in the data, the bill depth and flipper length.
    (The original dataset used the more precise term [culmen](https://en.wikipedia.org/wiki/Beak#Culmen)
    depth.) Below, each point is a sample. This is called a scatter plot\(\idx{scatter
    plot}\xdi\). Quoting [Wikipedia](https://en.wikipedia.org/wiki/Scatter_plot):'
  prefs: []
  type: TYPE_NORMAL
- en: The data are displayed as a collection of points, each having the value of one
    variable determining the position on the horizontal axis and the value of the
    other variable determining the position on the vertical axis.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We use [`matplotlib.pyplot`](https://matplotlib.org/stable/api/pyplot_summary.html)
    for most of our plotting needs in this book, with a few exceptions. Specifically,
    here we use the function [`matplotlib.pyplot.scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/841ea45e51e4d9614c6e0d11681af2bd8a1b95f52ca0ce2f9019cc83e12125c3.png](../Images/27baf658807e24de61b4747f7526a8f4.png)'
  prefs: []
  type: TYPE_IMG
- en: We observe what appears to be two fairly well-defined clusters of samples on
    the top left and bottom right respectively. What is a [cluster](https://en.wikipedia.org/wiki/Cluster_analysis)?
    Intuitively, it is a group of samples that are close to each other, but far from
    every other sample. In this case, it may be an indication that these samples come
    from a separate species.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look at the full dataset. Visualizing the full \(4\)-dimensional data
    is not straightforward. One way to do this is to consider all pairwise scatter
    plots. We use the function [`seaborn.pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html)
    from the library [Seaborn](https://seaborn.pydata.org/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/4f74fb1d6995969d8c0a1189b3b4b33ca52879ec220dc33404a8dbedd0b259b3.png](../Images/55cbba0230d16ef4027d863c6d33cc84.png)'
  prefs: []
  type: TYPE_IMG
- en: How many species of penguins do you think there are in this dataset?
  prefs: []
  type: TYPE_NORMAL
- en: 'What would be useful is a method that *automatically* identifies clusters *whatever
    the dimension of the data*. In this chapter, we will discuss a standard way to
    do this: \(k\)-means clustering. We will come back to the penguins dataset later
    in the chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: But first we need to review some basic concepts about vectors and distances
    in order to formulate clustering as an appropriate *optimization* problem, a perspective
    that will be recurring throughout.
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Ask your favorite AI chatbot for alternative ways to deal
    with missing values in a dataset. Implement one of these alternatives on the penguins
    dataset (you can ask the chatbot for the code!). ([Open in Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_intro_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
