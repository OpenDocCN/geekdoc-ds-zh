- en: Functions and Recursion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/architecture/functions/](https://en.algorithmica.org/hpc/architecture/functions/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To “call a function” in assembly, you need to [jump](../loops) to its beginning
    and then jump back. But then two important problems arise:'
  prefs: []
  type: TYPE_NORMAL
- en: What if the caller stores data in the same registers as the callee?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where is “back”?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both of these concerns can be solved by having a dedicated location in memory
    where we can write all the information we need to return from the function before
    calling it. This location is called *the stack*.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#the-stack)The
    Stack'
  prefs: []
  type: TYPE_NORMAL
- en: 'The hardware stack works the same way software stacks do and is similarly implemented
    as just two pointers:'
  prefs: []
  type: TYPE_NORMAL
- en: The *base pointer* marks the start of the stack and is conventionally stored
    in `rbp`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *stack pointer* marks the last element of the stack and is conventionally
    stored in `rsp`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you need to call a function, you push all your local variables onto the
    stack (which you can also do in other circumstances; e.g., when you run out of
    registers), push the current instruction pointer, and then jump to the beginning
    of the function. When exiting from a function, you look at the pointer stored
    on top of the stack, jump there, and then carefully read all the variables stored
    on the stack back into their registers.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can implement all that with the usual memory operations and jumps, but
    because of how frequently it is used, there are 4 special instructions for doing
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`push` writes data at the stack pointer and decrements it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pop` reads data from the stack pointer and increments it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`call` puts the address of the following instruction on top of the stack and
    jumps to a label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ret` reads the return address from the top of the stack and jumps to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You would call them “syntactic sugar” if they weren’t actual hardware instructions
    — they are just fused equivalents of these two-instruction snippets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The memory region between `rbp` and `rsp` is called a *stack frame*, and this
    is where local variables of functions are typically stored. It is pre-allocated
    at the start of the program, and if you push more data on the stack than its capacity
    (8MB by default on Linux), you encounter a *stack overflow* error. Because modern
    operating systems don’t actually give you memory pages until you read or write
    to their address space, you can freely specify a very large stack size, which
    acts more like a limit on how much stack memory can be used, and not a fixed amount
    every program has to use.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#calling-conventions)Calling
    Conventions'
  prefs: []
  type: TYPE_NORMAL
- en: The people who develop compilers and operating systems eventually came up with
    [conventions](https://wiki.osdev.org/Calling_Conventions) on how to write and
    call functions. These conventions enable some important [software engineering
    marvels](/hpc/compilation/stages/) such as splitting compilation into separate
    units, reusing already-compiled libraries, and even writing them in different
    programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example in C:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'By convention, a function should take its arguments in `rdi`, `rsi`, `rdx`,
    `rcx`, `r8`, `r9` (and the rest in the stack if those weren’t enough), put the
    return value into `rax`, and then return. Thus, `square`, being a simple one-argument
    function, can be implemented like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Each time we call it from `distance`, we just need to go through some trouble
    preserving its local variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: There are a lot more nuances, but we won’t go into detail here because this
    book is about performance, and the best way to deal with functions calls is actually
    to avoid making them in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#inlining)Inlining'
  prefs: []
  type: TYPE_NORMAL
- en: Moving data to and from the stack creates noticeable overhead for small functions
    like these. The reason you have to do this is that, in general, you don’t know
    whether the callee is modifying the registers where you store your local variables.
    But when you have access to the code of `square`, you can solve this problem by
    stashing the data in registers that you know won’t be modified.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This is better, but we are still implicitly accessing stack memory: you need
    to push and pop the instruction pointer on each function call. In simple cases
    like this, we can *inline* function calls by stitching the callee’s code into
    the caller and resolving conflicts over registers. In our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is fairly close to what optimizing compilers produce out of this snippet
    — only they use the [lea trick](../assembly) to make the resulting machine code
    sequence a few bytes smaller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In situations like these, function inlining is clearly beneficial, and compilers
    mostly do it [automatically](/hpc/compilation/situational), but there are cases
    when it’s not — and we will talk about them [in a bit](../layout).
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#tail-call-elimination)Tail
    Call Elimination'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inlining is straightforward to do when the callee doesn’t make any other function
    calls, or at least if these calls are not recursive. Let’s move on to a more complex
    example. Consider this recursive computation of a factorial:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Equivalent assembly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If the function is recursive, it is still often possible to make it “call-less”
    by restructuring it. This is the case when the function is *tail recursive*, that
    is, it returns right after making a recursive call. Since no actions are required
    after the call, there is also no need for storing anything on the stack, and a
    recursive call can be safely replaced with a jump to the beginning — effectively
    turning the function into a loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make our `factorial` function tail-recursive, we can pass a “current product”
    argument to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then this function can be easily folded into a loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The primary reason why recursion can be slow is that it needs to read and write
    data to the stack, while iterative and tail-recursive algorithms do not. This
    concept is very important in functional programming, where there are no loops
    and all you can use are functions. Without tail call elimination, functional programs
    would require way more time and memory to execute. [← Loops and Conditionals](https://en.algorithmica.org/hpc/architecture/loops/)[Indirect
    Branching →](https://en.algorithmica.org/hpc/architecture/indirect/)
  prefs: []
  type: TYPE_NORMAL
