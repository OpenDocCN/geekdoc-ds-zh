- en: Functions and Recursion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数和递归
- en: 原文：[https://en.algorithmica.org/hpc/architecture/functions/](https://en.algorithmica.org/hpc/architecture/functions/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/architecture/functions/](https://en.algorithmica.org/hpc/architecture/functions/)
- en: 'To “call a function” in assembly, you need to [jump](../loops) to its beginning
    and then jump back. But then two important problems arise:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在汇编中“调用函数”时，你需要[跳转](../loops)到其开始处，然后跳转回来。但随后出现了两个重要问题：
- en: What if the caller stores data in the same registers as the callee?
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果调用者将数据存储在调用者相同的寄存器中怎么办？
- en: Where is “back”?
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “返回”在哪里？
- en: Both of these concerns can be solved by having a dedicated location in memory
    where we can write all the information we need to return from the function before
    calling it. This location is called *the stack*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在内存中有一个专门的位置，我们可以在这里写入在调用函数之前需要返回的所有信息，这两个问题都可以得到解决。这个位置被称为*栈*。
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#the-stack)The
    Stack'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#the-stack)栈'
- en: 'The hardware stack works the same way software stacks do and is similarly implemented
    as just two pointers:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件栈的工作方式与软件栈相同，并且类似地仅由两个指针实现：
- en: The *base pointer* marks the start of the stack and is conventionally stored
    in `rbp`.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基指针*标记栈的起始位置，并且传统上存储在`rbp`中。'
- en: The *stack pointer* marks the last element of the stack and is conventionally
    stored in `rsp`.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*栈指针*标记栈的最后一个元素，并且传统上存储在`rsp`中。'
- en: When you need to call a function, you push all your local variables onto the
    stack (which you can also do in other circumstances; e.g., when you run out of
    registers), push the current instruction pointer, and then jump to the beginning
    of the function. When exiting from a function, you look at the pointer stored
    on top of the stack, jump there, and then carefully read all the variables stored
    on the stack back into their registers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要调用一个函数时，你需要将所有局部变量推送到栈上（你也可以在其他情况下这样做；例如，当你用完寄存器时），推送当前指令指针，然后跳转到函数的开始处。当从函数退出时，你查看存储在栈顶的指针，跳转到那里，然后仔细将存储在栈上的所有变量读回到它们的寄存器中。
- en: 'You can implement all that with the usual memory operations and jumps, but
    because of how frequently it is used, there are 4 special instructions for doing
    this:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用常规的内存操作和跳转来实现这些功能，但由于其频繁使用，为此有4个特殊指令：
- en: '`push` writes data at the stack pointer and decrements it.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`push`在栈指针处写入数据并递减它。'
- en: '`pop` reads data from the stack pointer and increments it.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pop`从栈指针读取数据并递增它。'
- en: '`call` puts the address of the following instruction on top of the stack and
    jumps to a label.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`call`将后续指令的地址放在栈顶并跳转到标签。'
- en: '`ret` reads the return address from the top of the stack and jumps to it.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ret`从栈顶读取返回地址并跳转到它。'
- en: 'You would call them “syntactic sugar” if they weren’t actual hardware instructions
    — they are just fused equivalents of these two-instruction snippets:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它们不是实际的硬件指令，你会称它们为“语法糖”——它们只是这两个指令片段的融合等效：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The memory region between `rbp` and `rsp` is called a *stack frame*, and this
    is where local variables of functions are typically stored. It is pre-allocated
    at the start of the program, and if you push more data on the stack than its capacity
    (8MB by default on Linux), you encounter a *stack overflow* error. Because modern
    operating systems don’t actually give you memory pages until you read or write
    to their address space, you can freely specify a very large stack size, which
    acts more like a limit on how much stack memory can be used, and not a fixed amount
    every program has to use.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`rbp`和`rsp`之间的内存区域被称为*栈帧*，通常函数的局部变量存储在这里。它在程序开始时预先分配，如果你在栈上推送的数据超过了其容量（Linux默认为8MB），你会遇到*栈溢出*错误。因为现代操作系统实际上只有在读取或写入其地址空间时才会给你内存页面，所以你可以自由地指定一个非常大的栈大小，这更像是对可以使用多少栈内存的限制，而不是每个程序都必须使用的固定数量。'
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#calling-conventions)Calling
    Conventions'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#calling-conventions)调用约定'
- en: The people who develop compilers and operating systems eventually came up with
    [conventions](https://wiki.osdev.org/Calling_Conventions) on how to write and
    call functions. These conventions enable some important [software engineering
    marvels](/hpc/compilation/stages/) such as splitting compilation into separate
    units, reusing already-compiled libraries, and even writing them in different
    programming languages.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 开发编译器和操作系统的那些人最终制定了一套[约定](https://wiki.osdev.org/Calling_Conventions)，用于如何编写和调用函数。这些约定使得一些重要的[软件工程奇迹](/hpc/compilation/stages/)成为可能，例如将编译拆分为独立的单元、重用已编译的库，甚至可以用不同的编程语言编写。
- en: 'Consider the following example in C:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下C语言的示例：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'By convention, a function should take its arguments in `rdi`, `rsi`, `rdx`,
    `rcx`, `r8`, `r9` (and the rest in the stack if those weren’t enough), put the
    return value into `rax`, and then return. Thus, `square`, being a simple one-argument
    function, can be implemented like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，一个函数应该在其`rdi`、`rsi`、`rdx`、`rcx`、`r8`、`r9`（如果不够，则其余部分在栈上）中接收参数，将返回值放入`rax`，然后返回。因此，作为简单单参数函数的`square`可以这样实现：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Each time we call it from `distance`, we just need to go through some trouble
    preserving its local variables:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们从`distance`调用它时，我们只需要做一些麻烦来保留其局部变量：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There are a lot more nuances, but we won’t go into detail here because this
    book is about performance, and the best way to deal with functions calls is actually
    to avoid making them in the first place.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多细微之处，但在这里我们不会深入探讨，因为这本书是关于性能的，而处理函数调用的最佳方式实际上是从一开始就避免它们。
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#inlining)Inlining'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#inlining) 内联'
- en: Moving data to and from the stack creates noticeable overhead for small functions
    like these. The reason you have to do this is that, in general, you don’t know
    whether the callee is modifying the registers where you store your local variables.
    But when you have access to the code of `square`, you can solve this problem by
    stashing the data in registers that you know won’t be modified.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据在栈之间移动为这些小型函数创建了明显的开销。你必须这样做的原因是，通常情况下，你不知道被调用者是否正在修改你存储局部变量的寄存器。但是当你能够访问`square`的代码时，你可以通过将数据存储在你知道不会被修改的寄存器中来解决这个问题。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This is better, but we are still implicitly accessing stack memory: you need
    to push and pop the instruction pointer on each function call. In simple cases
    like this, we can *inline* function calls by stitching the callee’s code into
    the caller and resolving conflicts over registers. In our example:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这比之前好，但我们仍然隐式地访问栈内存：你需要在每次函数调用时推送和弹出指令指针。在像这样的简单情况下，我们可以通过将调用者的代码缝合到被调用者中并解决寄存器冲突来内联函数调用。在我们的例子中：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is fairly close to what optimizing compilers produce out of this snippet
    — only they use the [lea trick](../assembly) to make the resulting machine code
    sequence a few bytes smaller:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这与优化编译器从这段代码中产生的结果非常接近——只是它们使用了[lea技巧](../assembly)来使生成的机器代码序列小几字节：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In situations like these, function inlining is clearly beneficial, and compilers
    mostly do it [automatically](/hpc/compilation/situational), but there are cases
    when it’s not — and we will talk about them [in a bit](../layout).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，函数内联显然是有益的，编译器通常[自动](/hpc/compilation/situational)执行这一操作，但也有一些情况不适合内联——我们将在稍后讨论它们[这些情况](../layout)。
- en: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#tail-call-elimination)Tail
    Call Elimination'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/architecture/functions/#tail-call-elimination)
    尾调用消除'
- en: 'Inlining is straightforward to do when the callee doesn’t make any other function
    calls, or at least if these calls are not recursive. Let’s move on to a more complex
    example. Consider this recursive computation of a factorial:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当被调用者不进行任何其他函数调用，或者至少这些调用不是递归的时，内联操作很简单。让我们来看一个更复杂的例子。考虑以下阶乘的递归计算：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Equivalent assembly:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 等价的汇编代码：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If the function is recursive, it is still often possible to make it “call-less”
    by restructuring it. This is the case when the function is *tail recursive*, that
    is, it returns right after making a recursive call. Since no actions are required
    after the call, there is also no need for storing anything on the stack, and a
    recursive call can be safely replaced with a jump to the beginning — effectively
    turning the function into a loop.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果函数是递归的，通过重构它，仍然经常可以使其“无调用”。这种情况发生在函数是**尾递归**时，即它在进行递归调用后立即返回。由于调用后不需要执行任何操作，因此也不需要在栈上存储任何东西，递归调用可以安全地替换为跳转到开始处——实际上将函数转换成了一个循环。
- en: 'To make our `factorial` function tail-recursive, we can pass a “current product”
    argument to it:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要使我们的`factorial`函数成为尾递归，我们可以向它传递一个“当前乘积”参数：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then this function can be easily folded into a loop:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这个函数可以很容易地折叠成一个循环：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The primary reason why recursion can be slow is that it needs to read and write
    data to the stack, while iterative and tail-recursive algorithms do not. This
    concept is very important in functional programming, where there are no loops
    and all you can use are functions. Without tail call elimination, functional programs
    would require way more time and memory to execute. [← Loops and Conditionals](https://en.algorithmica.org/hpc/architecture/loops/)[Indirect
    Branching →](https://en.algorithmica.org/hpc/architecture/indirect/)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 递归之所以可能慢，主要原因是它需要读写数据到栈中，而迭代和尾递归算法则不需要。这个概念在函数式编程中非常重要，因为在函数式编程中没有循环，你只能使用函数。如果没有尾调用消除，函数式程序将需要更多的时间和内存来执行。[←
    循环和条件](https://en.algorithmica.org/hpc/architecture/loops/)[间接分支 →](https://en.algorithmica.org/hpc/architecture/indirect/)
