<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>GPU-Accelerated Simulation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>GPU-Accelerated Simulation</h1>
<blockquote>原文：<a href="https://phys-sim-book.github.io/lec4.6-gpu_accel.html">https://phys-sim-book.github.io/lec4.6-gpu_accel.html</a></blockquote>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"/>

<p>*<em>Author of this section: <a href="https://roushelfy.github.io/">Zhaofeng Luo</a>, Carnegie Mellon University</em></p>
<p>We now rewrite the 2D mass-spring simulator to leverage GPU acceleration.
Instead of directly writing <a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a>, we resort to <a href="https://github.com/MuGdxy/muda">MUDA</a>, a lightweight library that provides a simple interface for GPU-accelerated computations.</p>
<p>The architecture of the GPU-accelerated simulator is similar to the Python version. All function and variable names are consistent with the Numpy version. However, the implementation details are different due to the GPU architecture and programming model. Before delving into the details, let's first get a feeling of the speedup that GPU could bring us from the following gif (<a href="#fig:lec4:cpu_vs_gpu">Figure 4.6.1</a>).</p>
<figure>
    <center>
    <img src="../Images/fbd53762482cd3796eb946c75f5c6562.png" data-original-src="https://phys-sim-book.github.io/img/lec4/cpu_gif.gif"/>
    <img src="../Images/ac44bb5d43380bbdb6eebffdc5e83ef8.png" data-original-src="https://phys-sim-book.github.io/img/lec4/gpu_gif.gif"/>
    </center>
    <figcaption><b><a name="fig:lec4:cpu_vs_gpu"/>
Figure 4.6.1.</b> An illustration of simulation speed of the Numpy CPU (left) and the MUDA GPU (right) versions.</figcaption>
</figure>
<h3 id="key-considerations-for-gpu-programming"><a class="header" href="#key-considerations-for-gpu-programming">Key Considerations for GPU Programming</a></h3>
<p>To maximize resource utilization on the GPU, there are two important aspects to consider:</p>
<ul>
<li><strong>Minimizing Data Transfer.</strong> In most modern architectures, CPU and GPU have separate memory spaces. Transferring data between these spaces can be expensive. Therefore, it is essential to minimize data transfers between CPU and GPU.</li>
<li><strong>Exploiting Parallelism.</strong> GPUs excel at parallel computations. However, care must be taken to avoid read-write conflicts that can arise when multiple threads attempt to access the same memory locations simultaneously.</li>
</ul>
<h3 id="minimizing-data-transfer"><a class="header" href="#minimizing-data-transfer">Minimizing Data Transfer</a></h3>
<p>To reduce data transfer between the CPU and GPU, we store the main energy values and their derivatives on the GPU. Computations are then performed directly on the GPU, and only the necessary position information is transferred back to the CPU for control and rendering. A more efficient implementation could render directly on the GPU, eliminating even this data transfer, but for simplicity and readability, we have not implemented that here.</p>
<p>To make the code more readable, the variables begin with <code>device_</code> are stored in the GPU memory, and the variables begin with <code>host_</code> are stored in the CPU memory.</p>
<p><a name="imp:lec4:energy_definition"/>
<strong>Implementation 4.6.1 (Data structure, MassSpringEnergy.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
struct MassSpringEnergy&lt;T, dim&gt;::Impl
{
	DeviceBuffer&lt;T&gt; device_x;
	DeviceBuffer&lt;T&gt; device_l2, device_k;
	DeviceBuffer&lt;int&gt; device_e;
	int N;
	DeviceBuffer&lt;T&gt; device_grad;
	DeviceTripletMatrix&lt;T, 1&gt; device_hess;
};
</code></pre>
<p>As shown in the code above, the energy values and their derivatives, as well as all the necessary parameters are stored in a <code>DeviceBuffer</code> object, which is a wrapper of the CUDA device memory implemented by the MUDA library. This allows us to perform computations directly on the GPU without the need for data transfer between the CPU and GPU.</p>
<h3 id="newtons-method"><a class="header" href="#newtons-method">Newton's Method</a></h3>
<p>The iterations of Newton's method is a serial process and cannot be parallelized. Therefore, we implement this part on the CPU:</p>
<p><a name="imp:lec4:gpu_time_integrator"/>
<strong>Implementation 4.6.2 (Newton's method, simulator.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
void MassSpringSimulator&lt;T, dim&gt;::Impl::step_forward()
{
    update_x_tilde(add_vector&lt;T&gt;(device_x, device_v, 1, h));
    DeviceBuffer&lt;T&gt; device_x_n = device_x; // Copy current positions to device_x_n
    int iter = 0;
    T E_last = IP_val();
    DeviceBuffer&lt;T&gt; device_p = search_direction();
    T residual = max_vector(device_p) / h;
    while (residual &gt; tol)
    {
        std::cout &lt;&lt; "Iteration " &lt;&lt; iter &lt;&lt; " residual " &lt;&lt; residual &lt;&lt; "E_last" &lt;&lt; E_last &lt;&lt; "\n";
        // Line search
        T alpha = 1;
        DeviceBuffer&lt;T&gt; device_x0 = device_x;
        update_x(add_vector&lt;T&gt;(device_x0, device_p, 1.0, alpha));
        while (IP_val() &gt; E_last)
        {
            alpha /= 2;
            update_x(add_vector&lt;T&gt;(device_x0, device_p, 1.0, alpha));
        }
        std::cout &lt;&lt; "step size = " &lt;&lt; alpha &lt;&lt; "\n";
        E_last = IP_val();
        device_p = search_direction();
        residual = max_vector(device_p) / h;
        iter += 1;
    }
    update_v(add_vector&lt;T&gt;(device_x, device_x_n, 1 / h, -1 / h));
}
</code></pre>
<p>In this function, <code>step_forward</code>, the projected Newton method with line search is implemented, performing necessary computations on the GPU while controlling the process on the CPU.
Any variable begin with <code>device_</code> here is a <code>DeviceBuffer</code> object on the GPU. To print the values in <code>DeviceBuffer</code> for debugging purposes, the common practice is to transfer the data back to the CPU, or call the <code>display_vec</code> function (which calls <code>printf</code> in parallel on the GPU) implemented in <code>uti.cu</code>.</p>
<p>The <code>update_x</code> function updates the positions of the nodes to all Energy classes and transfers the updated positions back to the CPU for rendering:</p>
<p><a name="imp:lec4:gpu_update_x"/>
<strong>Implementation 4.6.3 (Update positions, simulator.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
void MassSpringSimulator&lt;T, dim&gt;::Impl::update_x(const DeviceBuffer&lt;T&gt; &amp;new_x)
{
    inertialenergy.update_x(new_x);
    massspringenergy.update_x(new_x);
    device_x = new_x;
}
</code></pre>
<p>As the Energy classes has already updated its positions, the <code>IP_val</code> function no loner needs to pass any parameters, avoiding unnecessary data transfer.
In fact, it only calls the <code>val</code> function of all energy classes and then sum the results together:</p>
<p><a name="imp:lec4:gpu_ip_val"/>
<strong>Implementation 4.6.4 (Computing IP, simulator.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
T MassSpringSimulator&lt;T, dim&gt;::Impl::IP_val()
{

    return inertialenergy.val() + massspringenergy.val() * h * h;
}
</code></pre>
<p>Similarly for the <code>IP_grad</code> and <code>IP_hess</code> functions:</p>
<p><a name="imp:lec4:gpu_ip_grad_hess"/>
<strong>Implementation 4.6.5 (Computing IP gradient and Hessian, simulator.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
DeviceBuffer&lt;T&gt; MassSpringSimulator&lt;T, dim&gt;::Impl::IP_grad()
{
    return add_vector&lt;T&gt;(inertialenergy.grad(), massspringenergy.grad(), 1.0, h * h);
}

template &lt;typename T, int dim&gt;
DeviceTripletMatrix&lt;T, 1&gt; MassSpringSimulator&lt;T, dim&gt;::Impl::IP_hess()
{
    DeviceTripletMatrix&lt;T, 1&gt; inertial_hess = inertialenergy.hess();
    DeviceTripletMatrix&lt;T, 1&gt; massspring_hess = massspringenergy.hess();
    DeviceTripletMatrix&lt;T, 1&gt; hess = add_triplet&lt;T&gt;(inertial_hess, massspring_hess, 1.0, h * h);
    return hess;
}
</code></pre>
<p>Notice that they utilize the parallel operations (<code>add_vector</code> and <code>add_triplet</code>, which are implemented in <code>uti.cu</code>) on the GPU to perform the summation for gradients and Hessians.</p>
<h3 id="parallel-computations"><a class="header" href="#parallel-computations">Parallel Computations</a></h3>
<p>In our implementation, parallel computation is primarily employed in the computation of energy and its derivatives, as well as vector addition and subtraction. Let's take the MassSpringEnergy computation as an example.</p>
<h4 id="energy-computation"><a class="header" href="#energy-computation">Energy Computation</a></h4>
<p><a name="imp:lec4:MassSpringEnergyVal"/>
<strong>Implementation 4.6.6 (Computing energy, MassSpringEnergy.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
T MassSpringEnergy&lt;T, dim&gt;::val()
{
	auto &amp;device_x = pimpl_-&gt;device_x;
	auto &amp;device_e = pimpl_-&gt;device_e;
	auto &amp;device_l2 = pimpl_-&gt;device_l2;
	auto &amp;device_k = pimpl_-&gt;device_k;
	int N = device_e.size() / 2;
	DeviceBuffer&lt;T&gt; device_val(N);
	ParallelFor(256).apply(N, [device_val = device_val.viewer(), device_x = device_x.cviewer(), device_e = device_e.cviewer(), device_l2 = device_l2.cviewer(), device_k = device_k.cviewer()] __device__(int i) mutable
						   {
		int idx1= device_e(2 * i); // First node index
		int idx2 = device_e(2 * i + 1); // Second node index
		T diff = 0;
		for (int d = 0; d &lt; dim;d++){
			T diffi = device_x(dim * idx1 + d) - device_x(dim * idx2 + d);
			diff += diffi * diffi;
		}
		device_val(i) = 0.5 * device_l2(i) * device_k(i) * (diff / device_l2(i) - 1) * (diff / device_l2(i) - 1); })
		.wait();

	return devicesum(device_val);
} // Calculate the energy
</code></pre>
<p>The <code>ParallelFor</code> function distributes the computation across multiple GPU threads. The captured variables in the lambda function allow access to the necessary data structures within each thread.</p>
<h4 id="gradient-computation"><a class="header" href="#gradient-computation">Gradient Computation</a></h4>
<p><a name="imp:lec4:MassSpringEnergyGrad"/>
<strong>Implementation 4.6.7 (Computing gradients, MassSpringEnergy.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
const DeviceBuffer&lt;T&gt; &amp;MassSpringEnergy&lt;T, dim&gt;::grad()
{
	auto &amp;device_x = pimpl_-&gt;device_x;
	auto &amp;device_e = pimpl_-&gt;device_e;
	auto &amp;device_l2 = pimpl_-&gt;device_l2;
	auto &amp;device_k = pimpl_-&gt;device_k;
	auto N = pimpl_-&gt;device_e.size() / 2;
	auto &amp;device_grad = pimpl_-&gt;device_grad;
	device_grad.fill(0);
	ParallelFor(256).apply(N, [device_x = device_x.cviewer(), device_e = device_e.cviewer(), device_l2 = device_l2.cviewer(), device_k = device_k.cviewer(), device_grad = device_grad.viewer()] __device__(int i) mutable
						   {
		int idx1= device_e(2 * i); // First node index
		int idx2 = device_e(2 * i + 1); // Second node index
		T diff = 0;
		T diffi[dim];
		for (int d = 0; d &lt; dim;d++){
			diffi[d] = device_x(dim * idx1 + d) - device_x(dim * idx2 + d);
			diff += diffi[d] * diffi[d];
		}
		T factor = 2 * device_k(i) * (diff / device_l2(i) -1);
		for(int d=0;d&lt;dim;d++){
		   atomicAdd(&amp;device_grad(dim * idx1 + d), factor * diffi[d]);
		   atomicAdd(&amp;device_grad(dim * idx2 + d), -factor * diffi[d]);	  
		} })
		.wait();
	// display_vec(device_grad);
	return device_grad;
}
</code></pre>
<p>The <code>atomicAdd</code> function is crucial in the gradient computation to ensure safe concurrent updates to shared data (different edges can update the gradient of the same node), thus preventing race conditions.</p>
<h4 id="hessian-computation"><a class="header" href="#hessian-computation">Hessian Computation</a></h4>
<p>We utilized the Sparse Matrix data structure to store the Hessian matrix. The computation is parallelized across multiple threads, with each thread updating a specific element of the Hessian matrix. The actual size of the Sparse Matrix is calculated at the start of the simulation, allocating just enough memory for non-zero entries. The main consideration here is to calculate the correct indices for each element during simulation:</p>
<p><a name="imp:lec4:MassSpringEnergyHess"/>
<strong>Implementation 4.6.8 (Computing Hessians, MassSpringEnergy.cu).</strong></p>
<pre><code class="language-cpp">template &lt;typename T, int dim&gt;
const DeviceTripletMatrix&lt;T, 1&gt; &amp;MassSpringEnergy&lt;T, dim&gt;::hess()
{
	auto &amp;device_x = pimpl_-&gt;device_x;
	auto &amp;device_e = pimpl_-&gt;device_e;
	auto &amp;device_l2 = pimpl_-&gt;device_l2;
	auto &amp;device_k = pimpl_-&gt;device_k;
	auto N = device_e.size() / 2;
	auto &amp;device_hess = pimpl_-&gt;device_hess;
	auto device_hess_row_idx = device_hess.row_indices();
	auto device_hess_col_idx = device_hess.col_indices();
	auto device_hess_val = device_hess.values();
	device_hess_val.fill(0);
	ParallelFor(256).apply(N, [device_x = device_x.cviewer(), device_e = device_e.cviewer(), device_l2 = device_l2.cviewer(), device_k = device_k.cviewer(), device_hess_val = device_hess_val.viewer(), device_hess_row_idx = device_hess_row_idx.viewer(), device_hess_col_idx = device_hess_col_idx.viewer(), N] __device__(int i) mutable
						   {
		int idx[2] = {device_e(2 * i), device_e(2 * i + 1)}; // First node index
		T diff = 0;
		T diffi[dim];
		for (int d = 0; d &lt; dim; d++)
		{
			diffi[d] = device_x(dim * idx[0] + d) - device_x(dim * idx[1] + d);
			diff += diffi[d] * diffi[d];
		}
		Eigen::Matrix&lt;T, dim, 1&gt; diff_vec(diffi);
		Eigen::Matrix&lt;T, dim, dim&gt; diff_outer = diff_vec * diff_vec.transpose();
		T scalar = 2 * device_k(i) / device_l2(i);
		Eigen::Matrix&lt;T, dim, dim&gt; H_diff = scalar * (2 * diff_outer + (diff_vec.dot(diff_vec) - device_l2(i)) * Eigen::Matrix&lt;T, dim, dim&gt;::Identity());
		Eigen::Matrix&lt;T, dim * 2, dim * 2&gt; H_block, H_local;
		H_block &lt;&lt; H_diff, -H_diff,
			-H_diff, H_diff;
		make_PSD(H_block, H_local);
		// add to global matrix
		for (int ni = 0; ni &lt; 2; ni++)
			for (int nj = 0; nj &lt; 2; nj++)
			{
				int indStart = i * 4*dim*dim + (ni * 2 + nj) * dim*dim;
				for (int d1 = 0; d1 &lt; dim; d1++)
					for (int d2 = 0; d2 &lt; dim; d2++){
						device_hess_row_idx(indStart + d1 * dim + d2)= idx[ni] * dim + d1;
						device_hess_col_idx(indStart + d1 * dim + d2)= idx[nj] * dim + d2;
						device_hess_val(indStart + d1 * dim + d2) = H_local(ni * dim + d1, nj * dim + d2);
					}
			} })
		.wait();
	return device_hess;
} // Calculate the Hessian of the energy
</code></pre>

                        
</body>
</html>