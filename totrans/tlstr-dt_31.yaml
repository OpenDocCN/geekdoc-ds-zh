- en: 17  Text as data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://tellingstorieswithdata.com/16-text.html](https://tellingstorieswithdata.com/16-text.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Applications](./14-causality_from_obs.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[17  Text as data](./16-text.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read *Text as data: An overview*, ([Benoit 2020](99-references.html#ref-benoit2020text))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter provides an overview of using text as data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Read *Supervised Machine Learning for Text Analysis in R*, ([Hvitfeldt and Silge
    2021](99-references.html#ref-hvitfeldt2021supervised))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on Chapters 6 “Regression”, and 7 “Classification”, which implements linear
    and generalized linear models using text as data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Read *The Naked Truth: How the names of 6,816 complexion products can reveal
    bias in beauty*, ([Amaka and Thomas 2021](99-references.html#ref-thenakedtruth))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of text on make-up products.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key concepts and skills**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding text as a source of data that we can analyze enables many interesting
    questions to be considered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text cleaning and preparation are especially critical because of the large number
    of possible outcomes. There are many decisions that need to be made at this stage,
    which have important effects later in the analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One way to consider a text dataset is to look at which words distinguish particular
    documents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another is to consider which topics are contained in a document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software and packages**'
  prefs: []
  type: TYPE_NORMAL
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`astrologer` ([Gelfand 2022](99-references.html#ref-astrologer)) (this package
    is not on CRAN, so install it with: `devtools::install_github("sharlagelfand/astrologer")`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`beepr` ([Bååth 2018](99-references.html#ref-beepr))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fs` ([Hester, Wickham, and Csárdi 2021](99-references.html#ref-fs))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gutenbergr` ([Johnston and Robinson 2022](99-references.html#ref-gutenbergr))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`quanteda` ([Benoit et al. 2018](99-references.html#ref-quanteda))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stm` ([Roberts, Stewart, and Tingley 2019](99-references.html#ref-stm))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidytext` ([Silge and Robinson 2016](99-references.html#ref-SilgeRobinson2016))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*## 17.1 Introduction'
  prefs: []
  type: TYPE_NORMAL
- en: 'Text is all around us. In many cases, text is the earliest type of data that
    we are exposed to. Increases in computational power, the development of new methods,
    and the enormous availability of text, mean that there has been a great deal of
    interest in using text as data. Using text as data provides opportunities for
    unique analyses. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: text analysis of state-run newspapers in African countries can identify manipulation
    by governments ([Hassan 2022](99-references.html#ref-Hassan2022));
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the text from UK daily newspapers can be used to generate better forecasts of
    GDP and inflation ([Kalamara et al. 2022](99-references.html#ref-Kalamara2022)),
    and similarly, *The New York Times* can be used to create an uncertainty index
    which correlates with US economic activity ([Alexopoulos and Cohen 2015](99-references.html#ref-Alexopoulos2015));
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the analysis of notes in Electronic Health Records (EHR) can improve the efficiency
    of disease prediction ([Gronsbell et al. 2019](99-references.html#ref-jessgronsbell));
    and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: analysis of US congressional records indicates just how often women legislators
    are interrupted by men ([Miller and Sutherland 2022](99-references.html#ref-millersutherland2022)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Earlier approaches to the analysis of text tend to convert words into numbers,
    divorced of context. They could then be analyzed using traditional approaches,
    such as variants of logistic regression. More recent methods try to take advantage
    of the structure inherent in text, which can bring additional meaning. The difference
    is perhaps like a child who can group similar colors, compared with a child who
    knows what objects are; although both crocodiles and trees are green, and you
    can do something with that knowledge, it is useful to know that a crocodile could
    eat you while a tree probably would not.
  prefs: []
  type: TYPE_NORMAL
- en: Text can be considered an unwieldy, yet similar, version of the datasets that
    we have used throughout this book. The main difference is that we will typically
    begin with wide data, where each variable is a word, or token more generally.
    Often each entry is then a count. We would then typically transform this into
    rather long data, with one variable of words and another of the counts. Considering
    text as data naturally requires some abstraction from its context. But this should
    not be entirely separated as this can perpetuate historical inequities. For instance,
    Koenecke et al. ([2020](99-references.html#ref-koenecke2020)) find that automated
    speech recognition systems perform much worse for Black compared with White speakers,
    and Davidson, Bhattacharya, and Weber ([2019](99-references.html#ref-davidson2019racial))
    find that tweets that use Black American English, which is a specifically defined
    technical term, are classified at hate speech at higher rates than similar tweets
    in Standard American English, which again is a technical term.
  prefs: []
  type: TYPE_NORMAL
- en: One exciting aspect of text data is that it is typically not generated for the
    purposes of our analysis. The trade-off is that we typically must do a bunch more
    work to get it into a form that we can work with. There are a lot of decisions
    to be made in the data cleaning and preparation stages.
  prefs: []
  type: TYPE_NORMAL
- en: The larger size of text datasets means that it is especially important to simulate,
    and start small, when it comes to their analysis. Using text as data is exciting
    because of the quantity and variety of text that is available to us. But in general,
    dealing with text datasets is messy. There is a lot of cleaning and preparation
    that is typically required. Often, text datasets are large. As such having a reproducible
    workflow in place and then clearly communicating your findings, becomes critical.
    Nonetheless, it is an exciting area.
  prefs: []
  type: TYPE_NORMAL
- en: '*Shoulders of giants* *Professor Kenneth Benoit is Professor of Computational
    Social Science and Director of the Data Science Institute at the London School
    of Economics and Political Science (LSE). After obtaining a PhD in Government
    from Harvard University in 1998, supervised by Gary King and Kenneth Shepsle,
    he took a position at Trinity College, Dublin, where he was promoted to professor
    in 2007\. He moved to the LSE in 2020\. He is an expert in using quantitative
    methods to analyse text data, especially political text, and social media. Some
    of his important papers include Laver, Benoit, and Garry ([2003](99-references.html#ref-laver2003))
    which extracted policy positions from political texts and helped start the “text
    as data” subfield in political science. He has also worked extensively in other
    methods for estimating policy positions, such as Benoit and Laver ([2006](99-references.html#ref-benoitbook)),
    which provided original expert survey positions in dozens of countries, and Benoit
    and Laver ([2007](99-references.html#ref-benoit2007)) in which he compared expert
    surveys with hand coded analysis of party policy positions. A core contribution
    is the family of R packages known as `quanteda`, for the “quantitative analysis
    of textual data” ([Benoit et al. 2018](99-references.html#ref-quanteda)) which
    makes it easy to analyse text data.*  *In this chapter we first consider preparing
    text datasets. We then consider Term Frequency-Inverse Document Frequency (TF-IDF)
    and topic models.*  *## 17.2 Text cleaning and preparation'
  prefs: []
  type: TYPE_NORMAL
- en: Text modeling is an exciting area of research. But, and this is true more generally,
    the cleaning and preparation aspect is often at least as difficult as the modeling.
    We will cover some essentials and provide a foundation that can be built on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to get some data. We discussed data gathering in [Chapter
    7](07-gather.html) and mentioned in passing many sources including:'
  prefs: []
  type: TYPE_NORMAL
- en: Using *Inside Airbnb*, which provides text from reviews.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project Gutenberg which provides the text from out-of-copyright books.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scraping Wikipedia or other websites.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The workhorse packages that we need for text cleaning and preparation are `stringr`,
    which is part of the `tidyverse`, and `quanteda`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For illustrative purposes we construct a corpus of the first sentence or two,
    from three books: *Beloved* by Toni Morrison, *The Last Samurai* by Helen DeWitt,
    and *Jane Eyre* by Charlotte Brontë.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE2]*  *We typically want to construct a document-feature matrix, which
    has documents in each observation, words in each column, and a count for each
    combination, along with associated metadata. For instance, if our corpus was the
    text from Airbnb reviews, then each document may be a review, and typical features
    could include: “The”, “Airbnb”, “was”, “great”. Notice here that the sentence
    has been split into different words. We typically talk of “tokens” to generalize
    away from words, because of the variety of aspects we may be interested in, but
    words are commonly used.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE4]*  *We use the tokens in the corpus to construct a document-feature
    matrix (DFM) using `dfm()` from `quanteda` ([Benoit et al. 2018](99-references.html#ref-quanteda)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE6]*  *We now consider some of the many decisions that need to be made
    as part of this process. There is no definitive right or wrong answer. Instead,
    we make those decisions based on what we will be using the dataset for.'
  prefs: []
  type: TYPE_NORMAL
- en: 17.2.1 Stop words
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Stop words are words such as “the”, “and”, and “a”. For a long time stop words
    were not thought to convey much meaning, and there were concerns around memory-constrained
    computation. A common step of preparing a text dataset was to remove stop words.
    We now know that stop words can have a great deal of meaning ([Schofield, Magnusson,
    and Mimno 2017](99-references.html#ref-schofield2017)). The decision to remove
    them is a nuanced one that depends on circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: We can get a list of stop words using `stopwords()` from `quanteda`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE8]*  *We could then look for all instances of words in that list and crudely
    remove them with `str_replace_all()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE10]*  *There are many different lists of stop words that have been put
    together by others. For instance, `stopwords()` can use lists including: “snowball”,
    “stopwords-iso”, “smart”, “marimo”, “ancient”, and “nltk”. More generally, if
    we decide to use stop words then we often need to augment such lists with project-specific
    words. We can do this by creating a count of individual words in the corpus, and
    then sorting by the most common and adding those to the stop words list as appropriate.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE12]*  *We can integrate the removal of stop words into our construction
    of the DFM with `dfm_remove()` from `quanteda`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE14]*  *When we remove stop words we artificially adjust our dataset. Sometimes
    there may be a good reason to do that. But it must not be done unthinkingly. For
    instance, in [Chapter 6](06-farm.html) and [Chapter 10](10-store_and_share.html)
    we discussed how sometimes datasets may need to be censored, truncated, or manipulated
    in other similar ways, to preserve the privacy of respondents. It is possible
    that the integration of the removal of stop words as a default step in natural
    language processing was due to computational power, which may have been more limited
    when these methods were developed. In any case, Jurafsky and Martin ([[2000] 2023,
    62](99-references.html#ref-jurafskymartin)) conclude that removing stop words
    does not improve performance for text classification. Relatedly, Schofield, Magnusson,
    and Mimno ([2017](99-references.html#ref-schofield2017)) find that inference from
    topic models is not improved by the removal of anything other than the most frequent
    words. If stop words are to be removed, then they recommend doing this after topics
    are constructed.****  ***### 17.2.2 Case, numbers, and punctuation'
  prefs: []
  type: TYPE_NORMAL
- en: There are times when all we care about is the word, not the case or punctuation.
    For instance, if the text corpus was particularly messy or the existence of particular
    words was informative. We trade-off the loss of information for the benefit of
    making things simpler. We can convert to lower case with `str_to_lower()`, and
    use `str_replace_all()` to remove punctuation with “[:punct:]”, and numbers with
    “[:digit:]”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE16]*  *[PRE17]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE18]*  *As an aside, we can remove letters, numbers, and punctuation with
    “[:graph:]” in `str_replace_all()`. While this is rarely needed in textbook examples,
    it is especially useful with real datasets, because they will typically have a
    small number of unexpected symbols that we need to identify and then remove. We
    use it to remove everything that we are used to, leaving only that which we are
    not.'
  prefs: []
  type: TYPE_NORMAL
- en: More generally, we can use arguments in `tokens()` from `quanteda()` to do this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE20]***  ***### 17.2.3 Typos and uncommon words'
  prefs: []
  type: TYPE_NORMAL
- en: Then we need to decide what to do about typos and other minor issues. Every
    real-world text has typos. Sometimes these should clearly be fixed. But if they
    are made in a systematic way, for instance, a certain writer always makes the
    same mistakes, then they could have value if we were interested in grouping by
    the writer. The use of OCR will introduce common issues as well, as was seen in
    [Chapter 7](07-gather.html). For instance, “the” is commonly incorrectly recognized
    as “thc”.
  prefs: []
  type: TYPE_NORMAL
- en: We could fix typos in the same way that we fixed stop words, i.e. with lists
    of corrections. When it comes to uncommon words, we can build this into our document-feature
    matrix creation with `dfm_trim()`. For instance, we could use “min_termfreq =
    2” to remove any word that does not occur at least twice, or “min_docfreq = 0.05”
    to remove any word that is not in at least five per cent of documents or “max_docfreq
    = 0.90” to remove any word that is in at least 90 per cent of documents.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE22]*  *### 17.2.4 Tuples'
  prefs: []
  type: TYPE_NORMAL
- en: A tuple is an ordered list of elements. In the context of text it is a series
    of words. If the tuple comprises two words, then we term this a “bi-gram”, three
    words is a “tri-gram”, etc. These are an issue when it comes to text cleaning
    and preparation because we often separate terms based on a space. This would result
    in an inappropriate separation.
  prefs: []
  type: TYPE_NORMAL
- en: This is a clear issue when it comes to place names. For instance, consider “British
    Columbia”, “New Hampshire”, “United Kingdom”, and “Port Hedland”. One way forward
    is to create a list of such places and then use `str_replace_all()` to add an
    underscore, for instance, “British_Columbia”, “New_Hampshire”, “United_Kingdom”,
    and “Port_Hedland”. Another option is to use `tokens_compound()` from `quanteda`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE24]*  *In that case, we knew what the tuples were. But it might be that
    we were not sure what the common tuples were in the corpus. We could use `tokens_ngrams()`
    to identify them. We could ask for, say, all bi-grams in an excerpt from *Jane
    Eyre*. We showed how to download the text of this book from Project Gutenberg
    in [Chapter 13](13-ijaglm.html) and so here we load the local version that we
    saved earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE26]'
  prefs: []
  type: TYPE_NORMAL
- en: As there are many blank lines we will remove them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE28]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE29]*  *Having identified some common bi-grams, we could add them to the
    list to be changed. This example includes names like “Mr Rochester” and “St John”
    which would need to remain together for analysis.****  ***### 17.2.5 Stemming
    and lemmatizing'
  prefs: []
  type: TYPE_NORMAL
- en: Stemming and lemmatizing words is another common approach for reducing the dimensionality
    of a text dataset. Stemming means to remove the last part of the word, in the
    expectation that this will result in more general words. For instance, “Canadians”,
    “Canadian”, and “Canada” all stem to “Canad”. Lemmatizing is similar, but is more
    involved. It means changing words, not just on their spelling, but on their canonical
    form ([Grimmer, Roberts, and Stewart 2022, 54](99-references.html#ref-textasdata)).
    For instance, “Canadians”, “Canadian”, “Canucks”, and “Canuck” may all be changed
    to “Canada”.
  prefs: []
  type: TYPE_NORMAL
- en: We can do this with `dfm_wordstem()`. We notice, that, say, “minister”, has
    been changed to “minist”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE31]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE33]**  **While this is a common step in using text as data, Schofield
    et al. ([2017](99-references.html#ref-schofield2017understanding)) find that in
    the context of topic modeling, which we cover later, stemming has little effect
    and there is little need to do it.**  **### 17.2.6 Duplication'
  prefs: []
  type: TYPE_NORMAL
- en: Duplication is a major concern with text datasets because of their size. For
    instance, Bandy and Vincent ([2021](99-references.html#ref-bandy2021addressing))
    showed that around 30 per cent of the data were inappropriately duplicated in
    the BookCorpus dataset, and Schofield, Thompson, and Mimno ([2017](99-references.html#ref-schofield2017quantifying))
    show that this is a major concern and could substantially affect results. However,
    it can be a subtle and difficult to diagnose problem. For instance, in [Chapter
    13](13-ijaglm.html) when we considered counts of page numbers for various authors
    in the context of Poisson regression, we could easily have accidentally included
    each Shakespeare entry twice because not only are there entries for each play,
    but also many anthologies that contained all of them. Careful consideration of
    our dataset identified the issue, but that would be difficult at scale.***************  ***##
    17.3 Term Frequency-Inverse Document Frequency (TF-IDF)
  prefs: []
  type: TYPE_NORMAL
- en: 17.3.1 Distinguishing horoscopes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Install and load `astrologer`, which is a dataset of horoscopes to explore a
    real dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We can then access the “horoscopes” dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE35]*  *There are four variables: “startdate”, “zodiacsign”, “horoscope”,
    and “url” (note that URL is out-of-date because the website has been updated,
    for instance, the first one refers to [here](https://chaninicholas.com/horoscopes-week-january-5th/)).
    We are interested in the words that are used to distinguish the horoscope of each
    zodiac sign.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE37]*  *There are 106 horoscopes for each zodiac sign. In this example
    we first tokenize by word, and then create counts based on zodiac sign only, not
    date. We use `tidytext` because it is used extensively in Hvitfeldt and Silge
    ([2021](99-references.html#ref-hvitfeldt2021supervised)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE39]*  *We can see that the most popular words appear to be similar for
    the different zodiacs. At this point, we could use the data in a variety of ways.'
  prefs: []
  type: TYPE_NORMAL
- en: We might be interested to know which words characterize each group—that is to
    say, which words are commonly used only in each group. We can do that by first
    looking at a word’s term frequency (TF), which is how many times a word is used
    in the horoscopes for each zodiac sign. The issue is that there are a lot of words
    that are commonly used regardless of context. As such, we may also like to look
    at the inverse document frequency (IDF) in which we “penalize” words that occur
    in the horoscopes for many zodiac signs. A word that occurs in the horoscopes
    of many zodiac signs would have a lower IDF than a word that only occurs in the
    horoscopes of one. The term frequency–inverse document frequency (tf-idf) is then
    the product of these.
  prefs: []
  type: TYPE_NORMAL
- en: We can create this value using `bind_tf_idf()` from `tidytext`. It will create
    new variables for each of these measures.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE41]*  *In [Table 17.1](#tbl-zodiac) we look at the words that distinguish
    the horoscopes of each zodiac sign. The first thing to notice is that some of
    them have their own zodiac sign. On the one hand, there is an argument for removing
    this, but on the other hand, the fact that it does not happen for all of them
    is perhaps informative of the nature of the horoscopes for each sign.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 17.1: Most common words in horoscopes that are unique to a particular
    zodiac sign'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zodiac sign | Most common words unique to that sign |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Capricorn | goat; capricorn; capricorns; signify; neighborhood |'
  prefs: []
  type: TYPE_TB
- en: '| Pisces | pisces; wasted; missteps; node; shoes |'
  prefs: []
  type: TYPE_TB
- en: '| Sagittarius | sagittarius; rolodex; distorted; coat; reinvest |'
  prefs: []
  type: TYPE_TB
- en: '| Cancer | cancer; organize; overwork; procrastinate; scuttle |'
  prefs: []
  type: TYPE_TB
- en: '| Gemini | gemini; mood; output; admit; faces |'
  prefs: []
  type: TYPE_TB
- en: '| Taurus | bulls; let''s; painfully; virgin; taurus |'
  prefs: []
  type: TYPE_TB
- en: '| Aries | warns; vesta; aries; fearful; chase |'
  prefs: []
  type: TYPE_TB
- en: '| Virgo | digesting; trace; liberate; someone''s; final |'
  prefs: []
  type: TYPE_TB
- en: '| Libra | proof; inevitably; recognizable; reference; disguise |'
  prefs: []
  type: TYPE_TB
- en: '| Scorpio | skate; advocate; knots; bottle; meditating |'
  prefs: []
  type: TYPE_TB
- en: '| Aquarius | saves; consult; yearnings; sexy; athene |'
  prefs: []
  type: TYPE_TB
- en: '| Leo | trines; blessed; regrets; leo; agree |*****  ***## 17.4 Topic models'
  prefs: []
  type: TYPE_NORMAL
- en: Topic models are useful when we have many statements and we want to create groups
    based on which sentences that use similar words. We consider those groups of similar
    words to define topics. One way to get consistent estimates of the topics of each
    statement is to use topic models. While there are many variants, one way is to
    use the latent Dirichlet allocation (LDA) method of Blei, Ng, and Jordan ([2003](99-references.html#ref-Blei2003latent)),
    as implemented by `stm`. For clarity, in the context of this chapter, LDA refers
    to latent Dirichlet allocation and not Linear Discriminant Analysis, although
    this is another common subject associated with the acronym LDA.
  prefs: []
  type: TYPE_NORMAL
- en: The key assumption behind the LDA method is that for each statement, a document,
    is made by a person who decides the topics they would like to talk about in that
    document, and who then chooses words, terms, that are appropriate to those topics.
    A topic could be thought of as a collection of terms, and a document as a collection
    of topics. The topics are not specified *ex ante*; they are an outcome of the
    method. Terms are not necessarily unique to a particular topic, and a document
    could be about more than one topic. This provides more flexibility than other
    approaches such as a strict word count method. The goal is to have the words found
    in documents group themselves to define topics.
  prefs: []
  type: TYPE_NORMAL
- en: LDA considers each statement to be a result of a process where a person first
    chooses the topics they want to speak about. After choosing the topics, the person
    then chooses appropriate words to use for each of those topics. More generally,
    the LDA topic model works by considering each document as having been generated
    by some probability distribution over topics. For instance, if there were five
    topics and two documents, then the first document may be comprised mostly of the
    first few topics; the other document may be mostly about the final few topics
    ([Figure 17.1](#fig-topicsoverdocuments)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fbc15fd6ef3ff8378003cea402ea8a39.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Distribution for Document 1
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1be89f333d393157f69c754533cd56f0.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distribution for Document 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 17.1: Probability distributions over topics'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, each topic could be considered a probability distribution over terms.
    To choose the terms used in each document the speaker picks terms from each topic
    in the appropriate proportion. For instance, if there were ten terms, then one
    topic could be defined by giving more weight to terms related to immigration;
    and some other topic may give more weight to terms related to the economy ([Figure 17.2](#fig-topicsoverterms)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f5195e9764a781ae7ff7f3acfdeb9eac.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Distribution for Topic 1
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f77fcbeec6f092f969cc794bb1077e47.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distribution for Topic 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 17.2: Probability distributions over terms'
  prefs: []
  type: TYPE_NORMAL
- en: By way of background, the Dirichlet distribution is a variation of the beta
    distribution that is commonly used as a prior for categorical and multinomial
    variables. If there are just two categories, then the Dirichlet and the beta distributions
    are the same. In the special case of a symmetric Dirichlet distribution, \(\eta=1\),
    it is equivalent to a uniform distribution. If \(\eta<1\), then the distribution
    is sparse and concentrated on a smaller number of the values, and this number
    decreases as \(\eta\) decreases. A hyperparameter, in this usage, is a parameter
    of a prior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: After the documents are created, they are all that we can analyze. The term
    usage in each document is observed, but the topics are hidden, or “latent”. We
    do not know the topics of each document, nor how terms defined the topics. That
    is, we do not know the probability distributions of [Figure 17.1](#fig-topicsoverdocuments)
    or [Figure 17.2](#fig-topicsoverterms). In a sense we are trying to reverse the
    document generation process—we have the terms, and we would like to discover the
    topics.
  prefs: []
  type: TYPE_NORMAL
- en: If we observe the terms in each document, then we can obtain estimates of the
    topics ([Steyvers and Griffiths 2006](99-references.html#ref-SteyversGriffiths2006)).
    The outcomes of the LDA process are probability distributions. It is these distributions
    that define the topics. Each term will be given a probability of being a member
    of a particular topic, and each document will be given a probability of being
    about a particular topic.
  prefs: []
  type: TYPE_NORMAL
- en: The initial practical step when implementing LDA given a corpus of documents
    is usually to remove stop words. Although, as mentioned earlier, this is not necessary,
    and may be better done after the groups are created. We often also remove punctuation
    and capitalization. We then construct our document-feature matrix using `dfm()`
    from `quanteda`.
  prefs: []
  type: TYPE_NORMAL
- en: After the dataset is ready, `stm` can be used to implement LDA and approximate
    the posterior. The process attempts to find a topic for a particular term in a
    particular document, given the topics of all other terms for all other documents.
    Broadly, it does this by first assigning every term in every document to a random
    topic, specified by Dirichlet priors. It then selects a particular term in a particular
    document and assigns it to a new topic based on the conditional distribution where
    the topics for all other terms in all documents are taken as given ([Grün and
    Hornik 2011, 6](99-references.html#ref-Grun2011)). Once this has been estimated,
    then estimates for the distribution of words into topics and topics into documents
    can be backed out.
  prefs: []
  type: TYPE_NORMAL
- en: The conditional distribution assigns topics depending on how often a term has
    been assigned to that topic previously, and how common the topic is in that document
    ([Steyvers and Griffiths 2006](99-references.html#ref-SteyversGriffiths2006)).
    The initial random allocation of topics means that the results of early passes
    through the corpus of document are poor, but given enough time the algorithm converges
    to an appropriate estimate.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of the number of topics, \(k\), affects the results, and must be
    specified *a priori*. If there is a strong reason for a particular number, then
    this can be used. Otherwise, one way to choose an appropriate number is to use
    a test and training set process. Essentially, this means running the process on
    a variety of possible values for *k* and then picking an appropriate value that
    performs well.
  prefs: []
  type: TYPE_NORMAL
- en: One weakness of the LDA method is that it considers a “bag of words” where the
    order of those words does not matter ([Blei 2012](99-references.html#ref-blei2012)).
    It is possible to extend the model to reduce the impact of the bag-of-words assumption
    and add conditionality to word order. Additionally, alternatives to the Dirichlet
    distribution can be used to extend the model to allow for correlation.
  prefs: []
  type: TYPE_NORMAL
- en: 17.4.1 What is talked about in the Canadian parliament?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Following the example of the British, the written record of what is said in
    the Canadian parliament is called “Hansard”. It is not completely verbatim, but
    is very close. It is available in CSV format from [LiPaD](https://www.lipad.ca),
    which was constructed by Beelen et al. ([2017](99-references.html#ref-BeelenEtc2017)).
  prefs: []
  type: TYPE_NORMAL
- en: We are interested in what was talked about in the Canadian parliament in 2018\.
    To get started we can download the entire corpus from [here](https://www.lipad.ca/data/),
    and then discard all of the years apart from 2018\. If the datasets are in a folder
    called “2018”, we can use `read_csv()` to read and combine all the CSVs.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE44]'
  prefs: []
  type: TYPE_NORMAL
- en: The use of `filter()` at the end is needed because sometimes aspects such as
    “directions” and similar non-speech aspects are included in the Hansard. For instance,
    if we do not include that `filter()` then the first line is “The House resumed
    from November 9, 2017, consideration of the motion.” We can then construct a corpus.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE46]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE48]**  **We use the tokens in the corpus to construct a document-feature
    matrix. To make our life a little easier, computationally, we remove any word
    that does not occur at least twice, and any word that does not occur in at least
    two documents.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE50]*  *At this point we can use `stm()` from `stm` to implement a LDA
    model. We need to specify a document-feature matrix and the number of topics.
    Topic models are essentially just summaries. Instead of a document becoming a
    collection of words, they become a collection of topics with some probability
    associated with each topic. But because it is just providing a collection of words
    that tend to be used at similar times, rather than actual underlying meaning,
    we need to specify the number of topics that we are interested in. This decision
    will have a big impact, and we should consider a few different numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '*This will take some time, likely 15-30 minutes, so it is useful to save the
    model when it is done using `write_rds()`, and use `beep` to get a notification
    when it is done. We could then read the results back in with `read_rds()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '*We can look at the words in each topic with `labelTopics()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE54]*******  ***## 17.5 Exercises'
  prefs: []
  type: TYPE_NORMAL
- en: Practice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*(Plan)* Consider the following scenario: *You run a news website and are trying
    to understand whether to allow anonymous comments. You decide to do a A/B test,
    where we keep everything the same, but only allow anonymous comments on one version
    of the site. All you will have to decide is the text data that you obtain from
    the test.* Please sketch out what that dataset could look like and then sketch
    a graph that you could build to show all observations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation. Please include at least ten tests based on the simulated data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Acquire)* Please describe one possible source of such a dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched. Use
    `rstanarm` to build a model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Communicate)* Please write two paragraphs about what you did.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which argument to `str_replace_all()` would remove punctuation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: “[:punct:]”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “[:digit:]”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “[:alpha:]”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “[:lower:]”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Change `stopwords(source = "snowball")[1:10]` to find the ninth stopword in
    the “nltk” list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: “her”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “my”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “you”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “i”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which function from quanteda() will tokenize a corpus?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`tokenizer()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`token()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`tokenize()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`tokens()`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which argument to `dfm_trim()` should be used if we want to only include terms
    that occur at least twice? = 2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: “min_wordfreq”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “min_termfreq”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “min_term_occur”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: “min_ occurrence”
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is your favorite example of a tri-gram?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the second-most common word used in the zodiac signs for Cancer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: to
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: your
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: the
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: you
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the sixth-most common word used in the zodiac signs for Pisces, that
    is unique to that sign?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: shoes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: prayer
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: fishes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: pisces
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Re-run the Canadian topic model, but only including five topics. Looking at
    the words in each topic, how would you describe what each of them is about?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Class activities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do children learn “dog”, “cat”, or “bird” first? Use the Wordbank database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please follow the code of Hvitfeldt and Silge ([2021](99-references.html#ref-hvitfeldt2021supervised))
    in *Supervised Machine Learning for Text Analysis in R*, Chapter 5.2 “Understand
    word embeddings by finding them yourself”, freely available [here](https://smltar.com/embeddings.html),
    to implement your own word embeddings for one year’s worth of data from [LiPaD](https://www.lipad.ca).
  prefs: []
  type: TYPE_NORMAL
- en: 'Alexopoulos, Michelle, and Jon Cohen. 2015\. “The power of print: Uncertainty
    shocks, markets, and the economy.” *International Review of Economics & Finance*
    40 (November): 8–28\. [https://doi.org/10.1016/j.iref.2015.02.002](https://doi.org/10.1016/j.iref.2015.02.002).Amaka,
    Ofunne, and Amber Thomas. 2021\. “The Naked Truth: How the Names of 6,816 Complexion
    Products Can Reveal Bias in Beauty.” *The Pudding*, March. [https://pudding.cool/2021/03/foundation-names/](https://pudding.cool/2021/03/foundation-names/).Arel-Bundock,
    Vincent. 2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,”
    “Markdown,” “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Bååth,
    Rasmus. 2018\. *beepr: Easily Play Notification Sounds on any Platform*. [https://CRAN.R-project.org/package=beepr](https://CRAN.R-project.org/package=beepr).Bandy,
    John, and Nicholas Vincent. 2021\. “Addressing ‘Documentation Debt’ in Machine
    Learning: A Retrospective Datasheet for BookCorpus.” In *Proceedings of the Neural
    Information Processing Systems Track on Datasets and Benchmarks*, edited by J.
    Vanschoren and S. Yeung. Vol. 1\. [https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf).Beelen,
    Kaspar, Timothy Alberdingk Thim, Christopher Cochrane, Kees Halvemaan, Graeme
    Hirst, Michael Kimmins, Sander Lijbrink, et al. 2017\. “Digitization of the Canadian
    Parliamentary Debates.” *Canadian Journal of Political Science* 50 (3): 849–64.Benoit,
    Kenneth. 2020\. “Text as Data: An Overview.” In *The SAGE Handbook of Research
    Methods in Political Science and International Relations*, edited by Luigi Curini
    and Robert Franzese, 461–97\. London: SAGE Publishing. [https://doi.org/10.4135/9781526486387.n29](https://doi.org/10.4135/9781526486387.n29).Benoit,
    Kenneth, and Michael Laver. 2006\. *Party Policy in Modern Democracies*. Routledge.———.
    2007\. “Estimating Party Policy Positions: Comparing Expert Surveys and Hand-Coded
    Content Analysis.” *Electoral Studies* 26 (1): 90–107\. [https://doi.org/10.1016/j.electstud.2006.04.008](https://doi.org/10.1016/j.electstud.2006.04.008).Benoit,
    Kenneth, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan Müller, and
    Akitaka Matsuo. 2018\. “quanteda: An R package for the quantitative analysis of
    textual data.” *Journal of Open Source Software* 3 (30): 774\. [https://doi.org/10.21105/joss.00774](https://doi.org/10.21105/joss.00774).Blei,
    David. 2012\. “Probabilistic Topic Models.” *Communications of the ACM* 55 (4):
    77–84\. [https://doi.org/10.1145/2133806.2133826](https://doi.org/10.1145/2133806.2133826).Blei,
    David, Andrew Ng, and Michael Jordan. 2003\. “Latent Dirichlet Allocation.” *Journal
    of Machine Learning Research* 3 (Jan): 993–1022\. [https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf).Davidson,
    Thomas, Debasmita Bhattacharya, and Ingmar Weber. 2019\. “Racial Bias in Hate
    Speech and Abusive Language Detection Datasets.” In *Proceedings of the Third
    Workshop on Abusive Language Online*, 25–35.Gelfand, Sharla. 2022\. *Astrologer:
    Chani Nicholas Weekly Horoscopes (2013-2017)*. [http://github.com/sharlagelfand/astrologer](http://github.com/sharlagelfand/astrologer).Grimmer,
    Justin, Margaret Roberts, and Brandon Stewart. 2022\. *Text As Data: A New Framework
    for Machine Learning and the Social Sciences*. New Jersey: Princeton University
    Press.Gronsbell, Jessica, Jessica Minnier, Sheng Yu, Katherine Liao, and Tianxi
    Cai. 2019\. “Automated Feature Selection of Predictors in Electronic Medical Records
    Data.” *Biometrics* 75 (1): 268–77\. [https://doi.org/10.1111/biom.12987](https://doi.org/10.1111/biom.12987).Grün,
    Bettina, and Kurt Hornik. 2011\. “topicmodels: An R Package for Fitting Topic
    Models.” *Journal of Statistical Software* 40 (13): 1–30\. [https://doi.org/10.18637/jss.v040.i13](https://doi.org/10.18637/jss.v040.i13).Hassan,
    Mai. 2022\. “New Insights on Africa’s Autocratic Past.” *African Affairs* 121
    (483): 321–33\. [https://doi.org/10.1093/afraf/adac002](https://doi.org/10.1093/afraf/adac002).Hester,
    Jim, Hadley Wickham, and Gábor Csárdi. 2021\. *fs: Cross-Platform File System
    Operations Based on “libuv”*. [https://CRAN.R-project.org/package=fs](https://CRAN.R-project.org/package=fs).Hvitfeldt,
    Emil, and Julia Silge. 2021\. *Supervised Machine Learning for Text Analysis in
    R*. 1st ed. Chapman; Hall/CRC. [https://doi.org/10.1201/9781003093459](https://doi.org/10.1201/9781003093459).Johnston,
    Myfanwy, and David Robinson. 2022\. *gutenbergr: Download and Process Public Domain
    Works from Project Gutenberg*. [https://CRAN.R-project.org/package=gutenbergr](https://CRAN.R-project.org/package=gutenbergr).Jurafsky,
    Dan, and James Martin. (2000) 2023\. *Speech and Language Processing*. 3rd ed.
    [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/).Kalamara,
    Eleni, Arthur Turrell, Chris Redl, George Kapetanios, and Sujit Kapadia. 2022\.
    “Making text count: Economic forecasting using newspaper text.” *Journal of Applied
    Econometrics* 37 (5): 896–919\. [https://doi.org/10.1002/jae.2907](https://doi.org/10.1002/jae.2907).Koenecke,
    Allison, Andrew Nam, Emily Lake, Joe Nudell, Minnie Quartey, Zion Mengesha, Connor
    Toups, John Rickford, Dan Jurafsky, and Sharad Goel. 2020\. “Racial Disparities
    in Automated Speech Recognition.” *Proceedings of the National Academy of Sciences*
    117 (14): 7684–89\. [https://doi.org/10.1073/pnas.1915768117](https://doi.org/10.1073/pnas.1915768117).Laver,
    Michael, Kenneth Benoit, and John Garry. 2003\. “Extracting Policy Positions from
    Political Texts Using Words as Data.” *American Political Science Review* 97 (2):
    311–31\. [https://doi.org/10.1017/S0003055403000698](https://doi.org/10.1017/S0003055403000698).Miller,
    Michael, and Joseph Sutherland. 2022\. “The Effect of Gender on Interruptions
    at Congressional Hearings.” *American Political Science Review*, 1–19\. [https://doi.org/10.1017/S0003055422000260](https://doi.org/10.1017/S0003055422000260).R
    Core Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Roberts,
    Margaret, Brandon Stewart, and Dustin Tingley. 2019\. “stm: An R Package for Structural
    Topic Models.” *Journal of Statistical Software* 91 (2): 1–40\. [https://doi.org/10.18637/jss.v091.i02](https://doi.org/10.18637/jss.v091.i02).Schofield,
    Alexandra, Måns Magnusson, and David Mimno. 2017\. “Pulling Out the Stops: Rethinking
    Stopword Removal for Topic Models.” In *Proceedings of the 15th Conference of
    the European Chapter of the Association for Computational Linguistics: Volume
    2, Short Papers*, 432–36\. Valencia, Spain: Association for Computational Linguistics.
    [https://aclanthology.org/E17-2069](https://aclanthology.org/E17-2069).Schofield,
    Alexandra, Måns Magnusson, Laure Thompson, and David Mimno. 2017\. “Understanding
    Text Pre-Processing for Latent Dirichlet Allocation.” In *ACL Workshop for Women
    in NLP (WiNLP)*. [https://www.cs.cornell.edu/~xanda/winlp2017.pdf](https://www.cs.cornell.edu/~xanda/winlp2017.pdf).Schofield,
    Alexandra, Laure Thompson, and David Mimno. 2017\. “Quantifying the Effects of
    Text Duplication on Semantic Models.” In *Proceedings of the 2017 Conference on
    Empirical Methods in Natural Language Processing*, 2737–47\. Copenhagen, Denmark:
    Association for Computational Linguistics. [https://doi.org/10.18653/v1/D17-1290](https://doi.org/10.18653/v1/D17-1290).Silge,
    Julia, and David Robinson. 2016\. “tidytext: Text Mining and Analysis Using Tidy
    Data Principles in R.” *The Journal of Open Source Software* 1 (3). [https://doi.org/10.21105/joss.00037](https://doi.org/10.21105/joss.00037).Steyvers,
    Mark, and Tom Griffiths. 2006\. “Probabilistic Topic Models.” In *Latent Semantic
    Analysis: A Road to Meaning*, edited by T. Landauer, D McNamara, S. Dennis, and
    W. Kintsch. [https://cocosci.princeton.edu/tom/papers/SteyversGriffiths.pdf](https://cocosci.princeton.edu/tom/papers/SteyversGriffiths.pdf).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).***********'
  prefs: []
  type: TYPE_NORMAL
