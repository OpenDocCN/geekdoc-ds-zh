- en: 3.3\. Optimality conditions#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.3\. 最优性条件#
- en: 原文：[https://mmids-textbook.github.io/chap03_opt/03_optimality/roch-mmids-opt-optimality.html](https://mmids-textbook.github.io/chap03_opt/03_optimality/roch-mmids-opt-optimality.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap03_opt/03_optimality/roch-mmids-opt-optimality.html](https://mmids-textbook.github.io/chap03_opt/03_optimality/roch-mmids-opt-optimality.html)
- en: In this section, we derive optimality conditions for unconstrained continuous
    optimization problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们推导无约束连续优化问题的最优性条件。
- en: 'We will be interested in unconstrained optimization of the form:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注以下形式的无约束优化：
- en: \[ \min_{\mathbf{x} \in \mathbb{R}^d} f(\mathbf{x}) \]
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\mathbf{x} \in \mathbb{R}^d} f(\mathbf{x}) \]
- en: 'where \(f : \mathbb{R}^d \to \mathbb{R}\). In this subsection, we define several
    notions of solution and derive characterizations.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 \(f : \mathbb{R}^d \to \mathbb{R}\)。在本小节中，我们定义了几种解的概念并推导了它们的特征。'
- en: We have observed before that, in general, finding a global minimizer and certifying
    that one has been found can be difficult unless some special structure is present.
    Therefore weaker notions of solution are needed. We previously introduced the
    concept of a local minimizer. In words, \(\mathbf{x}^*\) is a local minimizer
    if there is open ball around \(\mathbf{x}^*\) where it attains the minimum value.
    The difference between global and local minimizers is illustrated in the next
    figure.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经观察到，在一般情况下，找到全局最小值并证明已经找到它可能很困难，除非存在某种特殊结构。因此需要更弱的概念。我们之前介绍了局部最小值的概念。换句话说，如果存在一个以
    \(\mathbf{x}^*\) 为中心的开球，使得 \(\mathbf{x}^*\) 在该开球内达到最小值，那么 \(\mathbf{x}^*\) 是一个局部最小值。全局最小值和局部最小值之间的区别在下图中说明。
- en: 3.3.1\. First-order conditions[#](#first-order-conditions "Link to this heading")
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.1\. 一阶条件[#](#first-order-conditions "链接到本标题")
- en: Local minimizers can be characterized in terms of the gradient. We first define
    the concept of directional derivative.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 局部最小值可以通过梯度来描述。我们首先定义方向导数的概念。
- en: '**Directional derivative** Partial derivatives measure the rate of change of
    a function along the axes. More generally:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**方向导数** 偏导数测量函数沿轴的变化率。更一般地：'
- en: '**DEFINITION** **(Directional Derivative)** \(\idx{directional derivative}\xdi\)
    Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\), let \(\mathbf{x}_0
    = (x_{0,1},\ldots,x_{0,d}) \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    = (v_1,\ldots,v_d) \in \mathbb{R}^d\) be a nonzero vector. The directional derivative
    of \(f\) at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(方向导数)** \(\idx{directional derivative}\xdi\) 设 \(f : D \to \mathbb{R}\)
    其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0 = (x_{0,1},\ldots,x_{0,d}) \in
    D\) 是 \(D\) 的一个内点，设 \(\mathbf{v} = (v_1,\ldots,v_d) \in \mathbb{R}^d\) 是一个非零向量。函数
    \(f\) 在 \(\mathbf{x}_0\) 点沿 \(\mathbf{v}\) 方向的方向导数是'
- en: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} &= \lim_{h
    \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}\\ &= \lim_{h
    \to 0} \frac{f(x_{0,1} + h v_1,\ldots,x_{0,d} + h v_d) - f(x_{0,1},\ldots,x_{0,d})}{h}
    \end{align*}\]
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} &= \lim_{h
    \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}\\ &= \lim_{h
    \to 0} \frac{f(x_{0,1} + h v_1,\ldots,x_{0,d} + h v_d) - f(x_{0,1},\ldots,x_{0,d})}{h}
    \end{align*}\]
- en: provided the limit exists. \(\natural\)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设极限存在。 \(\natural\)
- en: Typically, \(\mathbf{v}\) is a unit vector.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，\(\mathbf{v}\) 是一个单位向量。
- en: Note that taking \(\mathbf{v} = \mathbf{e}_i\) recovers the \(i\)-th partial
    derivative
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，取 \(\mathbf{v} = \mathbf{e}_i\) 可以恢复第 \(i\) 个偏导数
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{e}_i} = \lim_{h \to 0}
    \frac{f(\mathbf{x}_0 + h \mathbf{e}_i) - f(\mathbf{x}_0)}{h} = \frac{\partial
    f (\mathbf{x}_0)}{\partial x_i}. \]
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{e}_i} = \lim_{h \to 0}
    \frac{f(\mathbf{x}_0 + h \mathbf{e}_i) - f(\mathbf{x}_0)}{h} = \frac{\partial
    f (\mathbf{x}_0)}{\partial x_i}. \]
- en: Conversely, a general directional derivative can be expressed in terms of the
    partial derivatives.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，一般方向导数可以用偏导数来表示。
- en: '**THEOREM** **(Directional Derivative and Gradient)** \(\idx{directional derivative
    and gradient theorem}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\),
    let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    \in \mathbb{R}^d\) be a vector. Assume that \(f\) is continuously differentiable
    at \(\mathbf{x}_0\). Then the directional derivative of \(f\) at \(\mathbf{x}_0\)
    in the direction \(\mathbf{v}\) is given by'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(方向导数和梯度)** \(\idx{directional derivative and gradient theorem}\xdi\)
    设 \(f : D \to \mathbb{R}\) 其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0 \in
    D\) 是 \(D\) 的一个内点，设 \(\mathbf{v} \in \mathbb{R}^d\) 是一个向量。假设 \(f\) 在 \(\mathbf{x}_0\)
    点是连续可微的。那么 \(f\) 在 \(\mathbf{x}_0\) 点沿 \(\mathbf{v}\) 方向的方向导数由下式给出'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}. \]
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}. \]
- en: \(\sharp\)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: Put differently, when \(\mathbf{v}\) is a unit vector, the directional derivative
    is the length of the orthogonal projection of the gradient onto \(\mathbf{v}\).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，当 \(\mathbf{v}\) 是一个单位向量时，方向导数是梯度在 \(\mathbf{v}\) 上的正交投影的长度。
- en: '*Proof idea:* To bring out the partial derivatives, we re-write the directional
    derivative as the derivative of a composition of \(f\) with an affine function.
    We then use the *Chain Rule*.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 为了突出偏导数，我们将方向导数重新写为 \(f\) 与仿射函数复合的导数。然后我们使用**链式法则**。'
- en: '*Proof:* Consider the composition \(\beta(h) = f(\boldsymbol{\alpha}(h))\)
    where \(\boldsymbol{\alpha}(h) = \mathbf{x}_0 + h \mathbf{v}\). Observe that \(\boldsymbol{\alpha}(0)=
    \mathbf{x}_0\) and \(\beta(0)= f(\mathbf{x}_0)\). Then, by definition of the derivative,'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 考虑复合函数 \(\beta(h) = f(\boldsymbol{\alpha}(h))\)，其中 \(\boldsymbol{\alpha}(h)
    = \mathbf{x}_0 + h \mathbf{v}\)。注意到 \(\boldsymbol{\alpha}(0)= \mathbf{x}_0\) 和
    \(\beta(0)= f(\mathbf{x}_0)\)。然后，根据导数的定义，'
- en: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \lim_{h \to 0} \frac{\beta(h)
    - \beta(0)}{h} = \lim_{h \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}
    = \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}. \]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \lim_{h \to 0} \frac{\beta(h)
    - \beta(0)}{h} = \lim_{h \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}
    = \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}. \]
- en: Applying the *Chain Rule* and the parametric line example from the previous
    section, we arrive at
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 应用上一节中的**链式法则**和参数线示例，我们得到
- en: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \nabla f(\boldsymbol{\alpha}(0))^T
    \boldsymbol{\alpha}'(0) = \nabla f(\mathbf{x}_0)^T \mathbf{v}. \]
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \nabla f(\boldsymbol{\alpha}(0))^T
    \boldsymbol{\alpha}'(0) = \nabla f(\mathbf{x}_0)^T \mathbf{v}. \]
- en: \(\square\)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: '![Contour plot of the function . At the point , the gradient and a directional
    derivative are shown (with the help from ChatGPT; converted and adapted from (Source))](../Images/8e2172c7f2d739f2e83162ecdcafe29e.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![函数的等高线图。在点 \(\mathbf{x}_0\)，显示了梯度和一个方向导数（在 ChatGPT 的帮助下转换和改编自（来源）)](../Images/8e2172c7f2d739f2e83162ecdcafe29e.png)'
- en: '**KNOWLEDGE CHECK:** Let \(f : \mathbb{R}^2 \to \mathbb{R}\) be continuously
    differentiable. Suppose that'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查:** 设 \(f : \mathbb{R}^2 \to \mathbb{R}\) 在 \(\mathbb{R}^2\) 上连续可微。假设'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \frac{3}{\sqrt{5}}
    \qquad \text{and} \qquad \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{w}}
    = \frac{5}{\sqrt{5}} \]
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \frac{3}{\sqrt{5}}
    \qquad \text{和} \qquad \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{w}} =
    \frac{5}{\sqrt{5}} \]
- en: where \(\mathbf{v} = (1,2)/\sqrt{5}\) and \(\mathbf{w} = (2,1)/\sqrt{5}\). Compute
    the gradient of \(f\) at \(\mathbf{x}_0\). \(\checkmark\)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{v} = (1,2)/\sqrt{5}\) 和 \(\mathbf{w} = (2,1)/\sqrt{5}\)。计算 \(f\)
    在 \(\mathbf{x}_0\) 处的梯度。 \(\checkmark\)
- en: '**Descent direction** Earlier in the book, we proved a key insight about the
    derivative of a single-variable function \(f\) at a point \(x_0\): it tells us
    where to find smaller values. We generalize the *Descent Direction Lemma* to the
    multivariable case.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**下降方向** 在本书的早期，我们证明了关于单变量函数 \(f\) 在点 \(x_0\) 处的导数的一个关键洞察：它告诉我们如何找到更小的值。我们将**下降方向引理**推广到多变量情况。'
- en: First, we observe that in the continuously differentiable case the directional
    derivative gives a criterion for descent directions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们观察到在连续可微的情况下，方向导数给出了下降方向的判据。
- en: '**LEMMA** **(Descent Direction and Directional Derivative)** \(\idx{descent
    direction and directional derivative lemma}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be continuously differentiable at \(\mathbf{x}_0\). A vector \(\mathbf{v}\) is
    a descent direction for \(f\) at \(\mathbf{x}_0\) if'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(下降方向和方向导数)** \(\idx{下降方向和方向导数引理}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)
    在 \(\mathbf{x}_0\) 处连续可微。如果向量 \(\mathbf{v}\) 是 \(f\) 在 \(\mathbf{x}_0\) 处的下降方向，则'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v} < 0 \]
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v} < 0 \]
- en: that is, if the directional derivative of \(f\) at \(\mathbf{x}_0\) in the direction
    \(\mathbf{v}\) is negative. \(\flat\)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 即，如果 \(f\) 在 \(\mathbf{x}_0\) 处沿 \(\mathbf{v}\) 方向的方向导数是负的。 \(\flat\)
- en: '*Proof idea:* In anticipation of the proof of the second-order condition, we
    use the *Mean Value Theorem* to show that \(f\) takes smaller values in direction
    \(\mathbf{v}\). A simpler proof based on the definition of the directional derivative
    is also possible (Try it!).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路*: 为了证明二阶条件，我们使用**平均值定理**来证明 \(f\) 在方向 \(\mathbf{v}\) 上取更小的值。基于方向导数定义的更简单的证明也是可能的（试一试！）。'
- en: '*Proof:* Suppose there is \(\mathbf{v} \in \mathbb{R}^d\) such that \(\nabla
    f(\mathbf{x}_0)^T \mathbf{v} = -\eta < 0\). For \(\alpha > 0\), the *Mean Value
    Theorem* implies that there is \(\xi_\alpha \in (0,1)\) such that'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 假设存在 \(\mathbf{v} \in \mathbb{R}^d\) 使得 \(\nabla f(\mathbf{x}_0)^T \mathbf{v}
    = -\eta < 0\). 对于 \(\alpha > 0\)，根据**平均值定理**，存在 \(\xi_\alpha \in (0,1)\) 使得'
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v})^T(\alpha \mathbf{v}) = f(\mathbf{x}_0) + \alpha
    \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}. \]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v})^T(\alpha \mathbf{v}) = f(\mathbf{x}_0) + \alpha
    \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}. \]
- en: We want to show that the second term on the right-hand side is negative. We
    cannot immediately apply our condition on \(\mathbf{v}\) as the gradient in the
    previous equation is taken at \(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}\),
    not \(\mathbf{x}_0\).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想证明右侧的第二项是负的。我们不能立即应用我们对 \(\mathbf{v}\) 的条件，因为前一个方程中的梯度是在 \(\mathbf{x}_0 +
    \xi_\alpha \alpha \mathbf{v}\) 处取的，而不是在 \(\mathbf{x}_0\) 处。
- en: The gradient is continuous (in the sense that all its components are continuous).
    In particular, the function \(\nabla f(\mathbf{x})^T \mathbf{v}\) is continuous
    as a linear combination of continuous functions. By the definition of continuity,
    for any \(\epsilon > 0\) – say \(\epsilon = \eta/2\) – there is \(\delta > 0\)
    small enough such that all \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\) satisfy
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度是连续的（在所有分量都是连续的意义上）。特别是，函数 \(\nabla f(\mathbf{x})^T \mathbf{v}\) 作为连续函数的线性组合是连续的。根据连续性的定义，对于任意
    \(\epsilon > 0\) – 例如 \(\epsilon = \eta/2\) – 存在 \(\delta > 0\) 足够小，使得所有 \(\mathbf{x}
    \in B_\delta(\mathbf{x}_0)\) 满足
- en: \[\begin{align*} \left|\nabla f(\mathbf{x})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\,\right| &< \epsilon = \eta/2. \end{align*}\]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left|\nabla f(\mathbf{x})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\,\right| &< \epsilon = \eta/2. \end{align*}\]
- en: Take \(\alpha^* > 0\) small enough that \(\mathbf{x}_0 + \alpha^* \mathbf{v}
    \in B_\delta(\mathbf{x}_0)\). Then, for all \(\alpha \in (0,\alpha^*)\), whatever
    \(\xi_\alpha \in (0,1)\) is, it holds that \(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v} \in B_\delta(\mathbf{x}_0)\). Hence,
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\alpha^* > 0\) 足够小，使得 \(\mathbf{x}_0 + \alpha^* \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。然后，对于所有
    \(\alpha \in (0,\alpha^*)\)，无论 \(\xi_\alpha \in (0,1)\) 是什么，都有 \(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。因此，
- en: \[\begin{align*} \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}
    &= \nabla f(\mathbf{x}_0)^T \mathbf{v} + (\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v})\\ &\leq \nabla
    f(\mathbf{x}_0)^T \mathbf{v} + \left|\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\,\right|\\ &< -\eta
    + \eta/2\\ &= - \eta/2 < 0. \end{align*}\]
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}
    &= \nabla f(\mathbf{x}_0)^T \mathbf{v} + (\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v})\\ &\leq \nabla
    f(\mathbf{x}_0)^T \mathbf{v} + \left|\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\,\right|\\ &< -\eta
    + \eta/2\\ &= - \eta/2 < 0. \end{align*}\]
- en: by definition of \(\eta\). That implies
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义的 \(\eta\)。这表明
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha \eta/2 < f(\mathbf{x}_0),
    \quad \forall \alpha \in (0,\alpha^*) \]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha \eta/2 < f(\mathbf{x}_0),
    \quad \forall \alpha \in (0,\alpha^*) \]
- en: and proves the claim. \(\square\)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 并证明了该命题。 \(\square\)
- en: '**LEMMA** **(Descent Direction)** \(\idx{descent direction lemma}\xdi\) Let
    \(f : \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable at \(\mathbf{x}_0\)
    and assume that \(\nabla f(\mathbf{x}_0) \neq 0\). Then \(f\) has a descent direction
    at \(\mathbf{x}_0\). \(\flat\)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(下降方向)** \(\idx{descent direction lemma}\xdi\) 设 \(f : \mathbb{R}^d
    \to \mathbb{R}\) 在 \(\mathbf{x}_0\) 处连续可微，并假设 \(\nabla f(\mathbf{x}_0) \neq 0\)。那么
    \(f\) 在 \(\mathbf{x}_0\) 处有一个下降方向。 \(\flat\)'
- en: '*Proof:* Take \(\mathbf{v} = - \nabla f(\mathbf{x}_0)\). Then \(\nabla f(\mathbf{x}_0)^T
    \mathbf{v} = - \|\nabla f(\mathbf{x}_0)\|^2 < 0\) since \(\nabla f(\mathbf{x}_0)
    \neq \mathbf{0}\). \(\square\)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 取 \(\mathbf{v} = - \nabla f(\mathbf{x}_0)\)。那么 \(\nabla f(\mathbf{x}_0)^T
    \mathbf{v} = - \|\nabla f(\mathbf{x}_0)\|^2 < 0\)，因为 \(\nabla f(\mathbf{x}_0)
    \neq \mathbf{0}\)。 \(\square\)'
- en: This leads to the following fundamental result.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下基本结果。
- en: '**THEOREM** **(First-Order Necessary Optimality Condition)** \(\idx{first-order
    necessary optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be continuously differentiable on \(\mathbb{R}^d\). If \(\mathbf{x}_0\) is a local
    minimizer, then \(\nabla f(\mathbf{x}_0) = \mathbf{0}\). \(\sharp\)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理:** **(一阶必要最优性条件)** \(\idx{first-order necessary optimality condition}\xdi\)
    设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbb{R}^d\) 上是连续可微的。如果 \(\mathbf{x}_0\)
    是一个局部极小值点，那么 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。 \(\sharp\)'
- en: '*Proof idea:* In a descent direction, \(f\) decreases hence there cannot be
    one at a local minimizer.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 在下降方向上，\(f\) 减小，因此局部极小值点处不可能存在。'
- en: '*Proof:* We argue by contradiction. Suppose that \(\nabla f(\mathbf{x}_0) \neq
    \mathbf{0}\). By the *Descent Direction Lemma*, there is a descent direction \(\mathbf{v}
    \in \mathbb{R}^d\) at \(\mathbf{x}_0\). That implies'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 我们通过反证法进行论证。假设 \(\nabla f(\mathbf{x}_0) \neq \mathbf{0}\)。根据 *下降方向引理*，在
    \(\mathbf{x}_0\) 处存在一个下降方向 \(\mathbf{v} \in \mathbb{R}^d\)。这意味着'
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0), \quad \forall \alpha
    \in (0, \alpha^*) \]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0), \quad \forall \alpha
    \in (0, \alpha^*) \]
- en: for some \(\alpha^* > 0\). So every open ball around \(\mathbf{x}_0\) has a
    point achieving a smaller value than \(f(\mathbf{x}_0)\). Thus \(\mathbf{x}_0\)
    is not a local minimizer, a contradiction. So it must be that \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\). \(\square\)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\alpha^* > 0\)。因此，\(\mathbf{x}_0\) 附近的每一个开球都有一个点比 \(f(\mathbf{x}_0)\)
    的值更小。因此 \(\mathbf{x}_0\) 不是局部极小值点，这是矛盾的。因此，必须 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。
    \(\square\)
- en: A point satisfying the first-order necessary conditions is called a stationary
    point.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 满足一阶必要条件的点称为驻点。
- en: '**DEFINITION** **(Stationary Point)** \(\idx{stationary point}\xdi\) Let \(f
    : D \to \mathbb{R}\) be continuously differentiable on an open set \(D \subseteq
    \mathbb{R}^d\). If \(\nabla f(\mathbf{x}_0) = \mathbf{0}\), we say that \(\mathbf{x}_0
    \in D\) is a stationary point of \(f\). \(\natural\)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义:** **(驻点)** \(\idx{stationary point}\xdi\) 设 \(f : D \to \mathbb{R}\)
    在 \(\mathbb{R}^d\) 中的一个开集 \(D \subseteq \mathbb{R}^d\) 上是连续可微的。如果 \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\)，我们说 \(\mathbf{x}_0 \in D\) 是 \(f\) 的一个驻点。 \(\natural\)'
- en: '**EXAMPLE:** **(Rayleight Quotient)** Let \(A \in \mathbb{R}^{d \times d}\)
    be a symmetric matrix. The associated Rayleigh quotient\(\idx{Rayleigh quotient}\xdi\)
    is'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例:** **(瑞利商)** 设 \(A \in \mathbb{R}^{d \times d}\) 为一个对称矩阵。相关的瑞利商\(\idx{Rayleigh
    quotient}\xdi\) 定义为'
- en: \[ \mathcal{R}_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A \mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} \]
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A \mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} \]
- en: which is defined for any \(\mathbf{u} = (u_1,\ldots,u_d) \neq \mathbf{0}\) in
    \(\mathbb{R}^{d}\). As a function from \(\mathbb{R}^{d} \setminus \{\mathbf{0}\}\)
    to \(\mathbb{R}\), \(\mathcal{R}_A(\mathbf{u})\) is continuously differentiable.
    We find its stationary points.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它对于 \(\mathbb{R}^{d}\) 中的任意 \(\mathbf{u} = (u_1,\ldots,u_d) \neq \mathbf{0}\)
    都有定义。作为一个从 \(\mathbb{R}^{d} \setminus \{\mathbf{0}\}\) 到 \(\mathbb{R}\) 的函数，\(\mathcal{R}_A(\mathbf{u})\)
    是连续可微的。我们找到它的驻点。
- en: We use the [quotient rule](https://en.wikipedia.org/wiki/Quotient_rule) and
    our previous results on the gradient of quadratic functions. Specifically, note
    that (using that \(A\) is symmetric)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 [商法则](https://en.wikipedia.org/wiki/Quotient_rule) 和我们之前关于二次函数梯度的结果。具体来说，注意（使用
    \(A\) 是对称的）
- en: \[\begin{align*} \frac{\partial}{\partial u_i} \mathcal{R}_A(\mathbf{u}) &=
    \frac{\left(\frac{\partial}{\partial u_i} \langle \mathbf{u}, A \mathbf{u} \rangle\right)
    \langle \mathbf{u}, \mathbf{u} \rangle - \langle \mathbf{u}, A \mathbf{u} \rangle
    \left( \frac{\partial}{\partial u_i} \langle \mathbf{u}, \mathbf{u} \rangle\right)}{\langle
    \mathbf{u}, \mathbf{u} \rangle^2}\\ &= \frac{2\left(\frac{\partial}{\partial u_i}
    \frac{1}{2}\mathbf{u}^T A \mathbf{u}\right) \|\mathbf{u}\|^2 - \mathbf{u}^T A
    \mathbf{u} \left( \frac{\partial}{\partial u_i} \sum_{j=1}^d u_j^2\right)}{\|\mathbf{u}\|^4}\\
    &= \frac{2\left(A \mathbf{u}\right)_i \|\mathbf{u}\|^2 - \mathbf{u}^T A \mathbf{u}
    \left( 2 u_i \right)}{\|\mathbf{u}\|^4}\\ &= \frac{2}{\|\mathbf{u}\|^2}\left\{\left(A
    \mathbf{u}\right)_i - \mathcal{R}_A(\mathbf{u}) u_i \right\}. \end{align*}\]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial}{\partial u_i} \mathcal{R}_A(\mathbf{u}) &=
    \frac{\left(\frac{\partial}{\partial u_i} \langle \mathbf{u}, A \mathbf{u} \rangle\right)
    \langle \mathbf{u}, \mathbf{u} \rangle - \langle \mathbf{u}, A \mathbf{u} \rangle
    \left( \frac{\partial}{\partial u_i} \langle \mathbf{u}, \mathbf{u} \rangle\right)}{\langle
    \mathbf{u}, \mathbf{u} \rangle^2}\\ &= \frac{2\left(\frac{\partial}{\partial u_i}
    \frac{1}{2}\mathbf{u}^T A \mathbf{u}\right) \|\mathbf{u}\|^2 - \mathbf{u}^T A
    \mathbf{u} \left( \frac{\partial}{\partial u_i} \sum_{j=1}^d u_j^2\right)}{\|\mathbf{u}\|^4}\\
    &= \frac{2\left(A \mathbf{u}\right)_i \|\mathbf{u}\|^2 - \mathbf{u}^T A \mathbf{u}
    \left( 2 u_i \right)}{\|\mathbf{u}\|^4}\\ &= \frac{2}{\|\mathbf{u}\|^2}\left\{\left(A
    \mathbf{u}\right)_i - \mathcal{R}_A(\mathbf{u}) u_i \right\}. \end{align*}\]
- en: In vector form this is
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以向量形式，这是
- en: \[ \nabla \mathcal{R}_A(\mathbf{u}) = \frac{2}{\|\mathbf{u}\|^2} \left\{A \mathbf{u}
    - \mathcal{R}_A(\mathbf{u}) \,\mathbf{u} \right\}. \]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla \mathcal{R}_A(\mathbf{u}) = \frac{2}{\|\mathbf{u}\|^2} \left\{A \mathbf{u}
    - \mathcal{R}_A(\mathbf{u}) \,\mathbf{u} \right\}. \]
- en: The stationary points satisfy \(\nabla \mathcal{R}_A(\mathbf{u}) = \mathbf{0}\),
    or after getting rid of the denominator and rearranging,
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定点满足 \(\nabla \mathcal{R}_A(\mathbf{u}) = \mathbf{0}\)，或者去掉分母并重新排列后，
- en: \[ A \mathbf{u} = \mathcal{R}_A(\mathbf{u}) \,\mathbf{u}. \]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A \mathbf{u} = \mathcal{R}_A(\mathbf{u}) \,\mathbf{u}. \]
- en: The solutions to this system are eigenvectors of \(A\), that is, they satisfy
    \(A\mathbf{u} = \lambda \mathbf{u}\) for some eigenvalue \(\lambda\). If \(\mathbf{q}_i\)
    is a unit eigenvector of \(A\) with eigenvalue \(\lambda_i\), then we have that
    \(\mathcal{R}_A(\mathbf{q}_i) = \lambda_i\) (Check it!) and
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统的解是 \(A\) 的特征向量，即它们满足 \(A\mathbf{u} = \lambda \mathbf{u}\) 对于某个特征值 \(\lambda\)。如果
    \(\mathbf{q}_i\) 是 \(A\) 的单位特征向量，其特征值为 \(\lambda_i\)，那么我们有 \(\mathcal{R}_A(\mathbf{q}_i)
    = \lambda_i\)（检查一下！）并且
- en: \[ A \mathbf{q}_i = \mathcal{R}_A(\mathbf{q}_i) \,\mathbf{q}_i = \lambda_i \mathbf{q}_i.
    \]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A \mathbf{q}_i = \mathcal{R}_A(\mathbf{q}_i) \,\mathbf{q}_i = \lambda_i \mathbf{q}_i.
    \]
- en: The eigenvectors of \(A\) are not in general local minimizers of its Rayleigh
    quotient. In fact one of them – the largest one – is a global maximizer! \(\lhd\)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \(A\) 的特征向量通常不是其雷利商的局部极小值。事实上，其中之一——最大的一个——是全局最大值！\(\lhd\)
- en: 3.3.2\. Second-order conditions[#](#second-order-conditions "Link to this heading")
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.2\. 第二阶条件[#](#second-order-conditions "链接到这个标题")
- en: Local minimizers can also be characterized in terms of the Hessian.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 局部极小值也可以用 Hessian 来描述。
- en: We will make use of *Taylor’s Theorem*, a generalization of the *Mean Value
    Theorem* that provides polynomial approximations to a function around a point.
    We restrict ourselves to the case of a linear approximation with second-order
    error term, which will suffice for our purposes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用 *泰勒定理*，它是 *平均值定理* 的一种推广，它提供了函数在一点附近的多项式近似。我们限制自己使用带有二阶误差项的线性近似，这足以满足我们的目的。
- en: '**Taylor’s theorem** We begin by reviewing the single-variable case, which
    we will use to prove the general verison.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**泰勒定理** 我们首先回顾单变量情况，我们将用它来证明一般版本。'
- en: '**THEOREM** **(Taylor)** \(\idx{Taylor''s theorem}\xdi\) Let \(f: D \to \mathbb{R}\)
    where \(D \subseteq \mathbb{R}\). Suppose \(f\) has a continuous derivative on
    \([a,b]\) and that its second derivative exists on \((a,b)\). Then for any \(x
    \in [a, b]\)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(泰勒)** \(\idx{泰勒定理}\xdi\) 设 \(f: D \to \mathbb{R}\) 其中 \(D \subseteq
    \mathbb{R}\)。假设 \(f\) 在 \([a,b]\) 上有连续的导数，并且其二阶导数在 \((a,b)\) 上存在。那么对于任何 \(x \in
    [a, b]\)'
- en: \[ f(x) = f(a) + (x-a) f'(a) + \frac{1}{2} (x-a)^2 f''(\xi) \]
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = f(a) + (x-a) f'(a) + \frac{1}{2} (x-a)^2 f''(\xi) \]
- en: for some \(a < \xi < x\). \(\sharp\)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(a < \xi < x\)。\(\sharp\)
- en: The third term on the right-hand side of *Taylor’s Theorem* is called the Lagrange
    remainder. It can be seen as an error term between \(f(x)\) and the linear approximation
    \(f(a) + (x-a) f'(a)\). There are [other forms](https://en.wikipedia.org/wiki/Taylor%27s_theorem#Explicit_formulas_for_the_remainder)
    for the remainder. The form we stated here is useful when one has a bound on the
    second derivative. Here is an example.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*泰勒定理* 右侧的第三项称为拉格朗日余项。它可以看作是 \(f(x)\) 和线性近似 \(f(a) + (x-a) f''(a)\) 之间的误差项。余项有
    [其他形式](https://en.wikipedia.org/wiki/Taylor%27s_theorem#Explicit_formulas_for_the_remainder)。当我们对二阶导数有界时，这里给出的形式是有用的。这里有一个例子。'
- en: '**NUMERICAL CORNER:** Consider \(f(x) = e^x\). Then \(f''(x) = f''''(x) = e^x\).
    Suppose we are interested in approximating \(f\) in the interval \([0,1]\). We
    take \(a=0\) and \(b=1\) in *Taylor’s Theorem*. The linear term is'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 考虑 \(f(x) = e^x\)。那么 \(f''(x) = f''''(x) = e^x\)。假设我们感兴趣的是在区间 \([0,1]\)
    内逼近 \(f\)。我们在 *泰勒定理* 中取 \(a=0\) 和 \(b=1\)。线性项是'
- en: \[ f(a) + (x-a) f'(a) = 1 + x e^0 = 1 + x. \]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(a) + (x-a) f'(a) = 1 + x e^0 = 1 + x. \]
- en: Then for any \(x \in [0,1]\)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于任何 \(x \in [0,1]\)
- en: \[ f(x) = 1 + x + \frac{1}{2}x^2 e^{\xi_x} \]
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = 1 + x + \frac{1}{2}x^2 e^{\xi_x} \]
- en: where \(\xi_x \in (0,1)\) depends on \(x\). We get a uniform bound on the error
    over \([0,1]\) by replacing \(\xi_x\) with its worst possible value over \([0,1]\)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\xi_x \in (0,1)\) 依赖于 \(x\)。通过将 \(\xi_x\) 替换为其在 \([0,1]\) 上的最坏可能值，我们得到对
    \([0,1]\) 上误差的统一界限
- en: \[ |f(x) - (1+x)| \leq \frac{1}{2}x^2 e^{\xi_x} \leq \frac{e}{2} x^2. \]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |f(x) - (1+x)| \leq \frac{1}{2}x^2 e^{\xi_x} \leq \frac{e}{2} x^2. \]
- en: '[PRE0]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If we plot the upper and lower bounds, we see that \(f\) indeed falls within
    them.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制上界和下界，我们会看到 \(f\) 确实落在这个范围内。
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![../../_images/3679f4fd83bc012d44e92e99af6e84eb0f84c2d88f5be251891c9521ea8a7fc9.png](../Images/c339c626ad8f04a3c45b8a598e231b2a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/3679f4fd83bc012d44e92e99af6e84eb0f84c2d88f5be251891c9521ea8a7fc9.png](../Images/c339c626ad8f04a3c45b8a598e231b2a.png)'
- en: \(\unlhd\)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: In the case of several variables, we again restrict ourselves to the second
    order. For the more general version, see e.g. [Wikipedia](https://en.wikipedia.org/wiki/Taylor's_theorem#Taylor's_theorem_for_multivariate_functions).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个变量的情况下，我们再次将自身限制在二阶。对于更一般的情况，请参阅例如 [维基百科](https://en.wikipedia.org/wiki/Taylor's_theorem#Taylor's_theorem_for_multivariate_functions)。
- en: '**THEOREM** **(Taylor)** \(\idx{Taylor''s theorem}\xdi\) Let \(f : D \to \mathbb{R}\)
    where \(D \subseteq \mathbb{R}^d\). Let \(\mathbf{x}_0 \in D\) and \(\delta >
    0\) be such that \(B_\delta(\mathbf{x}_0) \subseteq D\). If \(f\) is twice continuously
    differentiable on \(B_\delta(\mathbf{x}_0)\), then for any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**THEOREM** **(Taylor)** \(\idx{泰勒定理}\xdi\) 设 \(f : D \to \mathbb{R}\) 其中 \(D
    \subseteq \mathbb{R}^d\)。设 \(\mathbf{x}_0 \in D\) 和 \(\delta > 0\) 使得 \(B_\delta(\mathbf{x}_0)
    \subseteq D\)。如果 \(f\) 在 \(B_\delta(\mathbf{x}_0)\) 上是二阶连续可微的，那么对于 \(B_\delta(\mathbf{x}_0)\)
    中的任意 \(\mathbf{x}\)'
- en: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
- en: for some \(\xi \in (0,1)\). \(\sharp\)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\xi \in (0,1)\)。\(\sharp\)
- en: As in the single-variable case, we think of \(f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T
    (\mathbf{x} - \mathbf{x}_0)\) for fixed \(\mathbf{x}_0\) as a linear – or more
    accurately affine – approximation to \(f\) at \(\mathbf{x}_0\). The third term
    on the right-hand side above quantifies the error of this approximation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 与单变量情况类似，我们将 \(f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\)
    视为固定 \(\mathbf{x}_0\) 时 \(f\) 在 \(\mathbf{x}_0\) 处的线性（或更准确地说，仿射）近似。上式中右侧的第三项量化了这个近似的误差。
- en: '*Proof idea:* We apply the single-variable result to \(\phi(t) = f(\boldsymbol{\alpha}(t))\).
    We use the *Chain Rule* to compute the needed derivatives.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们将单变量结果应用于 \(\phi(t) = f(\boldsymbol{\alpha}(t))\)。我们使用 *链式法则* 来计算所需的导数。'
- en: '*Proof:* Let \(\mathbf{p} = \mathbf{x} - \mathbf{x}_0\) and \(\phi(t) = f(\boldsymbol{\alpha}(t))\)
    where \(\boldsymbol{\alpha}(t) = \mathbf{x}_0 + t \mathbf{p}\). Observe that \(\phi(0)
    = f(\mathbf{x}_0)\) and \(\phi(1) = f(\mathbf{x})\). As observed in the proof
    of the *Mean Value Theorem*, \(\phi''(t) = \nabla f(\boldsymbol{\alpha}(t))^T
    \mathbf{p}\). By the *Chain Rule* and our previous *Parametric Line Example*,'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 令 \(\mathbf{p} = \mathbf{x} - \mathbf{x}_0\) 和 \(\phi(t) = f(\boldsymbol{\alpha}(t))\)
    其中 \(\boldsymbol{\alpha}(t) = \mathbf{x}_0 + t \mathbf{p}\)。观察 \(\phi(0) = f(\mathbf{x}_0)\)
    和 \(\phi(1) = f(\mathbf{x})\)。正如在 *平均值定理* 的证明中所观察到的，\(\phi''(t) = \nabla f(\boldsymbol{\alpha}(t))^T
    \mathbf{p}\)。通过 *链式法则* 和我们之前的 *参数线示例*，'
- en: \[\begin{align*} \phi''(t) &= \frac{\mathrm{d}}{\mathrm{d} t} \left[\sum_{i=1}^d
    \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i} p_i \right]\\ &= \sum_{i=1}^d
    \left(\nabla \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i}\right)^T
    \boldsymbol{\alpha}'(t) \,p_i \\ &= \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2
    f(\boldsymbol{\alpha}(t))}{\partial x_j \partial x_i} p_j p_i\\ &= \mathbf{p}^T
    \,\mathbf{H}_f(\mathbf{x}_0 + t \mathbf{p}) \,\mathbf{p}. \end{align*}\]
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \phi''(t) &= \frac{\mathrm{d}}{\mathrm{d} t} \left[\sum_{i=1}^d
    \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i} p_i \right]\\ &= \sum_{i=1}^d
    \left(\nabla \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i}\right)^T
    \boldsymbol{\alpha}'(t) \,p_i \\ &= \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2
    f(\boldsymbol{\alpha}(t))}{\partial x_j \partial x_i} p_j p_i\\ &= \mathbf{p}^T
    \,\mathbf{H}_f(\mathbf{x}_0 + t \mathbf{p}) \,\mathbf{p}. \end{align*}\]
- en: In particular, \(\phi\) has continuous first and second derivatives on \([0,1]\).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，\(\phi\) 在 \([0,1]\) 上具有连续的一阶和二阶导数。
- en: By *Taylor’s Theorem* in the single-variable case
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过单变量情况下的 *泰勒定理*
- en: \[ \phi(t) = \phi(0) + t \phi'(0) + \frac{1}{2} t^2 \phi''(\xi) \]
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi(t) = \phi(0) + t \phi'(0) + \frac{1}{2} t^2 \phi''(\xi) \]
- en: for some \(\xi \in (0,t)\). Plugging in the expressions for \(\phi(0)\), \(\phi'(0)\)
    and \(\phi''(\xi)\) and taking \(t=1\) gives the claim. \(\square\)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\xi \in (0,t)\)。将 \(\phi(0)\)，\(\phi'(0)\) 和 \(\phi''(\xi)\) 的表达式代入，并取
    \(t=1\)，即可得到所声称的。\(\square\)
- en: '**EXAMPLE:** Consider the function \(f(x_1, x_2) = x_1 x_2 + x_1^2 + e^{x_1}
    \cos x_2\). We apply *Taylor’s Theorem* with \(\mathbf{x}_0 = (0, 0)\) and \(\mathbf{x}
    = (x_1, x_2)\). The gradient is'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**EXAMPLE:** 考虑函数 \(f(x_1, x_2) = x_1 x_2 + x_1^2 + e^{x_1} \cos x_2\). 我们应用
    *泰勒定理*，取 \(\mathbf{x}_0 = (0, 0)\) 和 \(\mathbf{x} = (x_1, x_2)\)。梯度为'
- en: \[ \nabla f(x_1, x_2) = (x_2 + 2 x_1 + e^{x_1} \cos x_2, x_1 - e^{x_1} \sin
    x_2 ) \]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(x_1, x_2) = (x_2 + 2 x_1 + e^{x_1} \cos x_2, x_1 - e^{x_1} \sin
    x_2 ) \]
- en: and the Hessian is
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 而Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 + e^{x_1} \cos x_2
    & 1 - e^{x_1} \sin x_2\\ 1 - e^{x_1} \sin x_2 & - e^{x_1} \cos x_2 \end{pmatrix}.
    \end{split}\]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 + e^{x_1} \cos x_2
    & 1 - e^{x_1} \sin x_2\\ 1 - e^{x_1} \sin x_2 & - e^{x_1} \cos x_2 \end{pmatrix}.
    \end{split}\]
- en: So \(f(0,0) = 1\) and \(\nabla f(0,0) = (1, 0)\). Thus, by *Taylor’s Theorem*,
    there is \(\xi \in (0,1)\) such that
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f(0,0) = 1\) 且 \(\nabla f(0,0) = (1, 0)\)。因此，根据 *泰勒定理*，存在 \(\xi \in (0,1)\)
    使得
- en: \[ f(x_1, x_2) = 1 + x_1 + \frac{1}{2}[2 x_1^2 + 2 x_1 x_2 + (x_1^2 - x_2^2)
    \,e^{\xi x_1} \cos(\xi x_2) - 2 x_1 x_2 e^{\xi x_1} \sin(\xi x_2)]. \]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x_1, x_2) = 1 + x_1 + \frac{1}{2}[2 x_1^2 + 2 x_1 x_2 + (x_1^2 - x_2^2)
    \,e^{\xi x_1} \cos(\xi x_2) - 2 x_1 x_2 e^{\xi x_1} \sin(\xi x_2)]. \]
- en: \(\lhd\)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**Second directional derivative** To control the error term in *Taylor’s Theorem*,
    it will be convenient to introduce a notion of second directional derivative.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**二阶方向导数** 为了控制 *泰勒定理* 中的误差项，引入二阶方向导数的概念将很方便。'
- en: '**DEFINITION** **(Second Directional Derivative)** \(\idx{second directional
    derivative}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\),
    let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    \in \mathbb{R}^d\) be a nonzero vector. The second directional derivative of \(f\)
    at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(二阶方向导数)** \(\idx{second directional derivative}\xdi\) 设 \(f : D \to
    \mathbb{R}\) 其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0 \in D\) 是 \(D\)
    的一个内点，设 \(\mathbf{v} \in \mathbb{R}^d\) 是一个非零向量。函数 \(f\) 在 \(\mathbf{x}_0\) 处沿
    \(\mathbf{v}\) 方向的二阶方向导数是'
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \lim_{h \to 0}
    \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial \mathbf{v}}
    - \frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}\right] \]
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \lim_{h \to 0}
    \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial \mathbf{v}}
    - \frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}\right] \]
- en: provided the limit exists. \(\natural\)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 假设极限存在。 \(\natural\)
- en: Typically, \(\mathbf{v}\) is a unit vector.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，\(\mathbf{v}\) 是一个单位向量。
- en: '**THEOREM** **(Second Directional Derivative and Hessian)** \(\idx{second directional
    derivative and Hessian theorem}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq
    \mathbb{R}^d\), let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let
    \(\mathbf{v} \in \mathbb{R}^d\) be a vector. Assume that \(f\) is twice continuously
    differentiable at \(\mathbf{x}_0\). Then the second directional derivative of
    \(f\) at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is given by'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶方向导数与Hessian矩阵)** \(\idx{second directional derivative and Hessian
    theorem}\xdi\) 设 \(f : D \to \mathbb{R}\) 其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0
    \in D\) 是 \(D\) 的一个内点，设 \(\mathbf{v} \in \mathbb{R}^d\) 是一个向量。假设 \(f\) 在 \(\mathbf{x}_0\)
    处是二阶连续可微的。那么 \(f\) 在 \(\mathbf{x}_0\) 处沿 \(\mathbf{v}\) 方向的二阶方向导数由下式给出'
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T
    H_f(\mathbf{x}_0) \,\mathbf{v}. \]
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T
    H_f(\mathbf{x}_0) \,\mathbf{v}. \]
- en: \(\sharp\)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: Note the similarity to the quadratic term in *Taylor’s Theorem*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这与 *泰勒定理* 中的二次项相似。
- en: '*Proof idea:* We have already done this calculation in the proof of *Taylor’s
    Theorem*.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们已经在 *泰勒定理* 的证明中做过这个计算。'
- en: '*Proof:* Then, by definition of the derivative,'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 然后，根据导数的定义，'
- en: \[\begin{align*} \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0
    + h \mathbf{v})}{\partial \mathbf{v}} - \frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}}\right] &= \lim_{h \to 0} \frac{1}{h} \left[\nabla f(\mathbf{x}_0 +
    h \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\right]\\ &= \lim_{h
    \to 0} \frac{1}{h} \sum_{i=1}^n v_i \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}}, \end{align*}\]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0
    + h \mathbf{v})}{\partial \mathbf{v}} - \frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}}\right] &= \lim_{h \to 0} \frac{1}{h} \left[\nabla f(\mathbf{x}_0 +
    h \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\right]\\ &= \lim_{h
    \to 0} \frac{1}{h} \sum_{i=1}^n v_i \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}}, \end{align*}\]
- en: where \(g_i(\mathbf{x}_0) = \frac{\partial f(\mathbf{x}_0)}{\partial x_i}\).
    So
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(g_i(\mathbf{x}_0) = \frac{\partial f(\mathbf{x}_0)}{\partial x_i}\)。因此
- en: \[ \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla g_i(\mathbf{x}_0)^T
    \mathbf{v} = \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial
    x_j} \]
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla g_i(\mathbf{x}_0)^T
    \mathbf{v} = \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial
    x_j} \]
- en: by the *Directional Derivative and Gradient Theorem*. Plugging back above we
    get
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 根据方向导数和梯度定理。将上述结果代入，我们得到
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \sum_{i=1}^n
    v_i \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial x_j}
    = \mathbf{v}^T H_f(\mathbf{x}_0) \,\mathbf{v}. \]
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \sum_{i=1}^n
    v_i \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial x_j}
    = \mathbf{v}^T H_f(\mathbf{x}_0) \,\mathbf{v}. \]
- en: \(\square\)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: So going back to *Taylor’s Theorem*
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此回到 *泰勒定理*
- en: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
- en: we see that the second term on the right-hand side is the directional derivative
    at \(\mathbf{x}_0\) in the direction \(\mathbf{x} - \mathbf{x}_0\) and that the
    third term is half of the second directional derivative at \(\mathbf{x}_0 + \xi
    (\mathbf{x} - \mathbf{x}_0)\) in the same direction.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到等式右边的第二项是 \(\mathbf{x}_0\) 处沿 \(\mathbf{x} - \mathbf{x}_0\) 方向的方向导数，而第三项是
    \(\mathbf{x}_0 + \xi (\mathbf{x} - \mathbf{x}_0)\) 处沿同一方向的二阶方向导数的一半。
- en: '**Necessary condition** When \(f\) is twice continuously differentiable, we
    get a necessary condition based on the Hessian.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**必要条件** 当 \(f\) 在 \(\mathbb{R}^d\) 上连续二阶可微时，我们根据 Hessian 矩阵得到一个必要条件。'
- en: '**THEOREM** **(Second-Order Necessary Optimality Condition)** \(\idx{second-order
    necessary optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be twice continuously differentiable on \(\mathbb{R}^d\). If \(\mathbf{x}_0\)
    is a local minimizer, then \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\)
    is positive semidefinite. \(\sharp\)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶必要最优性条件)** \(\idx{second-order necessary optimality condition}\xdi\)
    设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbb{R}^d\) 上连续二阶可微。如果 \(\mathbf{x}_0\)
    是局部极小值点，那么 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\)
    是正半定的。 \(\sharp\)'
- en: '*Proof idea:* By *Taylor’s Theorem* and the *First-Order Necessary Optimality
    Condition*,'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路：* 通过 *泰勒定理* 和 *一阶必要最优性条件*，'
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}.
    \end{align*}\]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}.
    \end{align*}\]
- en: 'If \(\mathbf{H}_f\) is positive semidefinite in a neighborhood around \(\mathbf{x}_0\),
    then the second term on the right-hand side is nonnegative, which is necessary
    for \(\mathbf{x}_0\) to be a local minimizer. Formally we argue by contradiction:
    indeed, if \(\mathbf{H}_f\) is not positive semidefinite, then there must exists
    a direction in which the second directional derivative is negative; since the
    gradient is \(\mathbf{0}\) at \(\mathbf{x}_0\), intuitively the directional derivative
    must become negative in that direction as well and the function must decrease.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 \(\mathbf{H}_f\) 在 \(\mathbf{x}_0\) 附近的邻域内是正半定的，那么等式右边的第二项是非负的，这是 \(\mathbf{x}_0\)
    成为局部极小值点的必要条件。形式上我们通过反证法来论证：确实，如果 \(\mathbf{H}_f\) 不是正半定的，那么必须存在一个方向，在该方向上二阶方向导数是负的；由于梯度在
    \(\mathbf{x}_0\) 处是 \(\mathbf{0}\)，直观上在该方向上的方向导数也必须变为负，函数必须减小。
- en: '*Proof:* We argue by contradiction. Suppose that \(\mathbf{H}_f(\mathbf{x}_0)\)
    is not positive semidefinite. By definition, there must be a unit vector \(\mathbf{v}\)
    such that'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 我们通过反证法来论证。假设 \(\mathbf{H}_f(\mathbf{x}_0)\) 不是正半定。根据定义，必须存在一个单位向量 \(\mathbf{v}\)
    使得'
- en: \[ \langle \mathbf{v}, \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \rangle = - \eta
    < 0. \]
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{v}, \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \rangle = - \eta
    < 0. \]
- en: That is, \(\mathbf{v}\) is a direction in which the second directional derivative
    is negative.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 即，\(\mathbf{v}\) 是一个二阶方向导数为负的方向。
- en: For \(\alpha > 0\), *Taylor’s Theorem* implies that there is \(\xi_\alpha \in
    (0,1)\) such that
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于\(\alpha > 0\)，*泰勒定理*表明存在\(\xi_\alpha \in (0,1)\)，使得
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2} (\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}
    \alpha^2 \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}
    \end{align*}\]
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2} (\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}
    \alpha^2 \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}
    \end{align*}\]
- en: where we used \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) by the *First-Order Necessary
    Optimality Condition*. We want to show that the second term on the right-hand
    side is negative.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了\(\nabla f(\mathbf{x}_0) = \mathbf{0}\)根据*一阶必要最优性条件*。我们想证明右侧的第二项是负的。
- en: The Hessian is continuous (in the sense that all its entries are continuous
    functions of \(\mathbf{x}\)). In particular, the second directional derivative
    \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v}\) is continuous as a linear
    combination of continuous functions. So, by definition of continuity, for any
    \(\epsilon > 0\) – say \(\epsilon = \eta/2\) – there is \(\delta > 0\) small enough
    that
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 赫essian矩阵是连续的（在所有项都是\(\mathbf{x}\)的连续函数的意义上）。特别是，二阶方向导数\(\mathbf{v}^T \mathbf{H}_f(\mathbf{x})
    \,\mathbf{v}\)作为一个连续函数的线性组合是连续的。因此，根据连续性的定义，对于任何\(\epsilon > 0\)——比如说\(\epsilon
    = \eta/2\)——存在一个足够小的\(\delta > 0\)，
- en: \[\begin{align*} \left| \mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v} -
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \right| &< \eta/2 \end{align*}\]
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left| \mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v} -
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \right| &< \eta/2 \end{align*}\]
- en: for all \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)。
- en: Take \(\alpha^* > 0\) small enough that \(\mathbf{x}_0 + \alpha^* \mathbf{v}
    \in B_\delta(\mathbf{x}_0)\). Then, for all \(\alpha \in (0,\alpha^*)\), whatever
    \(\xi_\alpha \in (0,1)\) is, it holds that \(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v} \in B_\delta(\mathbf{x}_0)\). Hence,
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 取\(\alpha^* > 0\)足够小，使得\(\mathbf{x}_0 + \alpha^* \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。然后，对于所有\(\alpha
    \in (0,\alpha^*)\)，无论\(\xi_\alpha \in (0,1)\)是什么，都有\(\mathbf{x}_0 + \xi_\alpha
    \alpha \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。因此，
- en: \[\begin{align*} \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v}) \,\mathbf{v} &= \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}
    + (\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v}
    - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} )\\ &\leq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} + |\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}|\\ &< -\eta + \eta/2\\ &< - \eta/2 < 0. \end{align*}\]
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v}) \,\mathbf{v} &= \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}
    + (\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v}
    - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} )\\ &\leq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} + |\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}|\\ &< -\eta + \eta/2\\ &< - \eta/2 < 0. \end{align*}\]
- en: by definition of \(\eta\). That implies
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 根据η的定义。这表明
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha^2 \eta/4 <
    f(\mathbf{x}_0). \]
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha^2 \eta/4 <
    f(\mathbf{x}_0). \]
- en: Since this holds for all sufficiently small \(\alpha\), every open ball around
    \(\mathbf{x}_0\) has a point achieving a lower value than \(f(\mathbf{x}_0)\).
    Thus \(\mathbf{x}_0\) is not a local minimizer, a contradiction. So it must be
    that \(\mathbf{H}_f(\mathbf{x}_0) \succeq \mathbf{0}\). \(\square\)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这对于所有足够小的\(\alpha\)都成立，因此\(\mathbf{x}_0\)周围的每一个开球都有一个点，其值低于\(f(\mathbf{x}_0)\)。因此\(\mathbf{x}_0\)不是局部极小值点，这是一个矛盾。所以必须是\(\mathbf{H}_f(\mathbf{x}_0)
    \succeq \mathbf{0}\)。 \(\square\)
- en: '**Sufficient condition** The necessary condition above is not in general sufficient,
    as the following example shows.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**充分条件** 上述必要条件在一般情况下并不充分，以下例子可以说明。'
- en: '**NUMERICAL CORNER:** Let \(f(x) = x^3\). Then \(f''(x) = 3 x^2\) and \(f''''(x)
    = 6 x\) so that \(f''(0) = 0\) and \(f''''(0) \geq 0\). Hence \(x=0\) is a stationary
    point. But \(x=0\) is not a local minimizer. Indeed \(f(0) = 0\) but, for any
    \(\delta > 0\), \(f(-\delta) < 0\).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角:** 令\(f(x) = x^3\)。则\(f''(x) = 3 x^2\)和\(f''''(x) = 6 x\)，因此\(f''(0)
    = 0\)且\(f''''(0) \geq 0\)。因此\(x=0\)是一个驻点。但\(x=0\)不是局部极小值点。实际上\(f(0) = 0\)，但对于任何\(\delta
    > 0\)，\(f(-\delta) < 0\)。'
- en: '[PRE2]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![../../_images/2124857c662385a175abf776e89126ff842e450579382110f506759f09254a95.png](../Images/4a1cd8247ab18de84607516e9c6f7863.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/2124857c662385a175abf776e89126ff842e450579382110f506759f09254a95.png](../Images/4a1cd8247ab18de84607516e9c6f7863.png)'
- en: \(\unlhd\)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: We give sufficient conditions for a point to be a local minimizer.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给出一个点成为局部最小值点的充分条件。
- en: '**THEOREM** **(Second-Order Sufficient Optimality Condition)** \(\idx{second-order
    sufficient optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be twice continuously differentiable on \(\mathbb{R}^d\). If \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\) is positive definite, then \(\mathbf{x}_0\)
    is a strict local minimizer. \(\sharp\)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶充分优化条件)** \(\idx{second-order sufficient optimality condition}\xdi\)
    设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbb{R}^d\) 上是两次连续可微的。如果 \(\nabla
    f(\mathbf{x}_0) = \mathbf{0}\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\)
    是一个严格局部最小值点。\(\sharp\)'
- en: '*Proof idea:* We use *Taylor’s Theorem* again. This time we use the positive
    definiteness of the Hessian to bound the value of the function from below.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们再次使用 *泰勒定理*。这次我们使用 Hessian 的正定性来从下限界定函数的值。'
- en: We will need a lemma.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个引理。
- en: '**LEMMA** **(Quadratic Form and Frobenius Norm)** \(\idx{quadratic form and
    Frobenius norm lemma}\xdi\) Let \(A = (a_{i,j})_{i,j}\) and \(B = (b_{i,j})_{i,j}\)
    be matrices in \(\mathbb{R}^{n \times m}\). For any unit vectors \(\mathbf{u}
    \in \mathbb{R}^n\) and \(\mathbf{v} \in \mathbb{R}^m\)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(二次型和弗罗贝尼乌斯范数)** \(\idx{quadratic form and Frobenius norm lemma}\xdi\)
    设 \(A = (a_{i,j})_{i,j}\) 和 \(B = (b_{i,j})_{i,j}\) 是 \(\mathbb{R}^{n \times m}\)
    中的矩阵。对于任意单位向量 \(\mathbf{u} \in \mathbb{R}^n\) 和 \(\mathbf{v} \in \mathbb{R}^m\)'
- en: \[ \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v} \right|
    \leq \|A - B\|_F. \]
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v} \right|
    \leq \|A - B\|_F. \]
- en: \(\flat\)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof:* By the *Cauchy-Schwarz inequality*,'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 通过 *柯西-施瓦茨不等式*，'
- en: \[\begin{align*} \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v}
    \right| &= \left| \sum_{i=1}^n \sum_{j=1}^m u_i v_j (a_{i,j} - b_{i,j}) \right|\\
    &\leq \sqrt{\sum_{i=1}^n \sum_{j=1}^m u_i^2 v_j^2} \sqrt{\sum_{i=1}^n \sum_{j=1}^m
    (a_{i,j} - b_{i,j})^2}\\ &= \|A - B\|_F, \end{align*}\]
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v}
    \right| &= \left| \sum_{i=1}^n \sum_{j=1}^m u_i v_j (a_{i,j} - b_{i,j}) \right|\\
    &\leq \sqrt{\sum_{i=1}^n \sum_{j=1}^m u_i^2 v_j^2} \sqrt{\sum_{i=1}^n \sum_{j=1}^m
    (a_{i,j} - b_{i,j})^2}\\ &= \|A - B\|_F, \end{align*}\]
- en: where we used that \(\mathbf{u}\) and \(\mathbf{v}\) have unit norm on the last
    line. \(\square\)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们在最后一行使用了 \(\mathbf{u}\) 和 \(\mathbf{v}\) 在最后具有单位范数。\(\square\)
- en: '*Proof:* *(Second-Order Sufficient Optimality Condition)* By *Taylor’s Theorem*,
    for all unit vectors \(\mathbf{v} \in \mathbb{R}^d\) and \(\alpha \in \mathbb{R}\),
    there is \(\xi_{\alpha} \in (0,1)\) such that'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* *(二阶充分优化条件)* 通过 *泰勒定理*，对于所有单位向量 \(\mathbf{v} \in \mathbb{R}^d\) 和 \(\alpha
    \in \mathbb{R}\)，存在 \(\xi_{\alpha} \in (0,1)\) 使得'
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v},
    \end{align*}\]
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v},
    \end{align*}\]
- en: where we used that \(\nabla f(\mathbf{x}_0) = \mathbf{0}\). The second term
    on the last line is \(0\) at \(\mathbf{v} = \mathbf{0}\). Our goal is to show
    that it is strictly positive (except at \(\mathbf{0}\)) in a neighborhood of \(\mathbf{0}\).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。最后一行的第二项在 \(\mathbf{v} = \mathbf{0}\)
    时为 \(0\)。我们的目标是证明它在 \(\mathbf{0}\) 的邻域内严格为正（除了在 \(\mathbf{0}\) 处）。
- en: The set \(\mathbb{S}^{d-1}\) of unit vectors in \(\mathbb{R}^d\) is closed and
    bounded. The expression \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}\),
    viewed as a function of \(\mathbf{v}\), is continuous since it is a polynomial.
    Hence, by the *Extreme Value Theorem*, it attains its minimum on \(\mathbb{S}^{d-1}\).
    By our assumption that \(\mathbf{H}_f(\mathbf{x}_0)\) is positive definite, that
    minimum must be strictly positive, say \(\mu > 0\).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: \(\mathbb{R}^d\) 中的单位向量集合 \(\mathbb{S}^{d-1}\) 是闭且有界的。表达式 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}\)，作为 \(\mathbf{v}\) 的函数，是连续的，因为它是一个多项式。因此，根据 *极值定理*，它在 \(\mathbb{S}^{d-1}\)
    上达到其最小值。根据我们假设 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，这个最小值必须是严格正的，比如说 \(\mu > 0\)。
- en: By the *Quadratic Form and Frobenius Norm Lemma* (ignoring the absolute value),
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 *二次型和弗罗贝尼乌斯范数引理*（忽略绝对值），
- en: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\,\mathbf{v} \leq \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F. \]
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\,\mathbf{v} \leq \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F. \]
- en: The Frobenius norm above is continuous in \(\mathbf{w}\) as a composition of
    continuous functions. Moreover, we have at \(\mathbf{w} = \mathbf{0}\) that this
    Frobenius norm is \(0\). Hence, by definition of continuity, for any \(\epsilon
    > 0\) – say \(\epsilon := \mu/2\) – there is \(\delta > 0\) such that \(\mathbf{w}
    \in B_{\delta}(\mathbf{0})\) implies \(\|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F < \epsilon = \mu/2\).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的 Frobenius 范数作为连续函数的复合是关于 \(\mathbf{w}\) 连续的。此外，在 \(\mathbf{w} = \mathbf{0}\)
    时，这个 Frobenius 范数是 \(0\)。因此，根据连续性的定义，对于任何 \(\epsilon > 0\) - 例如 \(\epsilon :=
    \mu/2\) - 存在 \(\delta > 0\)，使得 \(\mathbf{w} \in B_{\delta}(\mathbf{0})\) 意味着 \(\|\mathbf{H}_f(\mathbf{x}_0)
    - \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\|_F < \epsilon = \mu/2\)。
- en: Since \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} > \mu\), the inequality
    in the previous display implies that
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} > \mu\)，前面的不等式意味着
- en: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\,\mathbf{v} \geq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F > \frac{\mu}{2}. \]
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\,\mathbf{v} \geq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F > \frac{\mu}{2}. \]
- en: This holds for any unit vector \(\mathbf{v}\) and any \(\mathbf{w} \in B_{\delta}(\mathbf{0})\).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这对任何单位向量 \(\mathbf{v}\) 和任何 \(\mathbf{w} \in B_{\delta}(\mathbf{0})\) 都成立。
- en: Going back to our Taylor expansion, for \(\alpha > 0\) small enough (not depending
    on \(\mathbf{v}\); why?), it holds that \(\mathbf{w} = \xi_\alpha \alpha \mathbf{v}
    \in B_{\delta}(\mathbf{0})\) so that we get from the previous inequality
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的泰勒展开，对于足够小的 \(\alpha > 0\)（不依赖于 \(\mathbf{v}\)；为什么？），有 \(\mathbf{w} = \xi_\alpha
    \alpha \mathbf{v} \in B_{\delta}(\mathbf{0})\)，因此从前面的不等式得到
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}\\
    &> f(\mathbf{x}_0) + \frac{1}{4} \alpha^2 \mu \\ &> f(\mathbf{x}_0). \end{align*}\]
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}\\
    &> f(\mathbf{x}_0) + \frac{1}{4} \alpha^2 \mu \\ &> f(\mathbf{x}_0). \end{align*}\]
- en: Therefore \(\mathbf{x}_0\) is a strict local minimizer. \(\square\)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(\mathbf{x}_0\) 是一个严格局部最小化器。\(\square\)
- en: 3.3.3\. Adding equality constraints[#](#adding-equality-constraints "Link to
    this heading")
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.3\. 添加等式约束[#](#adding-equality-constraints "链接到这个标题")
- en: Until now, we have considered *unconstrained* optimization problems, that is,
    the variable \(\mathbf{x}\) can take any value in \(\mathbb{R}^d\). However, it
    is common to impose conditions on \(\mathbf{x}\). Hence, we consider the *constrained*\(\idx{constrained
    optimization}\xdi\) minimization problem
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑的是 *无约束* 优化问题，即变量 \(\mathbf{x}\) 可以取 \(\mathbb{R}^d\) 中的任何值。然而，通常会对
    \(\mathbf{x}\) 施加条件。因此，我们考虑 *约束*\(\idx{约束优化}\xdi\) 最小化问题
- en: \[ \min_{\mathbf{x} \in \mathscr{X}} f(\mathbf{x}) \]
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\mathbf{x} \in \mathscr{X}} f(\mathbf{x}) \]
- en: where \(\mathscr{X} \subset \mathbb{R}^d\).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathscr{X} \subset \mathbb{R}^d\)。
- en: '**EXAMPLE:** For instance, the entries of \(\mathbf{x}\) may have to satisfy
    certain bounds. In that case, we would have'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：例如，\(\mathbf{x}\) 的元素可能必须满足某些界限。在这种情况下，我们将有'
- en: \[ \mathscr{X} = \{\mathbf{x} = (x_1,\ldots,x_d) \in \mathbb{R}^d:x_i \in [a_i,
    b_i], \forall i\} \]
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathscr{X} = \{\mathbf{x} = (x_1,\ldots,x_d) \in \mathbb{R}^d:x_i \in [a_i,
    b_i], \forall i\} \]
- en: for some constants \(a_i < b_i\), \(i=1,\ldots,d\). \(\lhd\)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些常数 \(a_i < b_i\)，\(i=1,\ldots,d\)。\(\lhd\)
- en: In this more general problem, the notion of global and local minimizer can be
    adapted straightforwardly. Note that, for simplicity, we will assume that \(f\)
    is defined over all of \(\mathbb{R}^d\). When \(\mathbf{x} \in \mathscr{X}\),
    it is said to be feasible.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更一般的问题中，全局和局部最小化器的概念可以直接适应。注意，为了简单起见，我们将假设 \(f\) 在整个 \(\mathbb{R}^d\) 上定义。当
    \(\mathbf{x} \in \mathscr{X}\) 时，它被称为可行。
- en: '**DEFINITION** **(Global minimizer)** \(\idx{global minimizer or maximizer}\xdi\)
    Let \(f : \mathbb{R}^d \to \mathbb{R}\). The point \(\mathbf{x}^* \in \mathscr{X}\)
    is a global minimizer of \(f\) over \(\mathscr{X}\) if'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(全局最小化器)** \(\idx{全局最小化器或最大化器}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)。如果点
    \(\mathbf{x}^* \in \mathscr{X}\) 是 \(f\) 在 \(\mathscr{X}\) 上的全局最小化器，'
- en: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in \mathscr{X}.
    \]
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in \mathscr{X}.
    \]
- en: \(\natural\)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: '**DEFINITION** **(Local minimizer)** \(\idx{local minimizer or maximizer}\xdi\)
    Let \(f : \mathbb{R}^d \to \mathbb{R}\). The point \(\mathbf{x}^* \in \mathscr{X}\)
    is a local minimizer of \(f\) over \(\mathscr{X}\) if there is \(\delta > 0\)
    such that'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（局部极小值点）** \(\idx{局部极小值点或极大值点}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)。如果存在
    \(\delta > 0\)，使得 \(\mathbf{x}^* \in \mathscr{X}\) 是 \(f\) 在 \(\mathscr{X}\) 上的局部极小值点，则称
    \(\mathbf{x}^*\) 为 \(f\) 的局部极小值点。'
- en: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in (B_{\delta}(\mathbf{x}^*)
    \setminus \{\mathbf{x}^*\}) \cap \mathscr{X}. \]
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in (B_{\delta}(\mathbf{x}^*)
    \setminus \{\mathbf{x}^*\}) \cap \mathscr{X}. \]
- en: If the inequality is strict, we say that \(\mathbf{x}^*\) is a strict local
    minimizer. \(\natural\)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不等式是严格的，我们称 \(\mathbf{x}^*\) 是严格的局部极小值点。 \(\natural\)
- en: 'In this subsection, we restrict ourselves to one important class of constraints:
    equality constraints. That is, we consider the minimization problem'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们限制自己考虑一类重要的约束：等式约束。也就是说，我们考虑最小化问题
- en: \[\begin{align*} &\text{min} f(\mathbf{x})\\ &\text{s.t.}\ h_i(\mathbf{x}) =
    0,\ \forall i \in [\ell] \end{align*}\]
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\text{最小化} f(\mathbf{x})\\ &\text{约束条件}\ h_i(\mathbf{x}) =
    0,\ \forall i \in [\ell] \end{align*}\]
- en: 'where s.t. stands for “subject to”. In other words, we only allow those \(\mathbf{x}''s\)
    such that \(h_i(\mathbf{x}) = 0\) for all \(i\). Here \(f : \mathbb{R}^d \to \mathbb{R}\)
    and \(h_i : \mathbb{R}^d \to \mathbb{R}\), \(i\in [\ell]\). We will sometimes
    use the notation \(\mathbf{h} : \mathbb{R}^d \to \mathbb{R}^\ell\), where \(\mathbf{h}(\mathbf{x})
    = (h_1(\mathbf{x}), \ldots, h_\ell(\mathbf{x}))\).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 s.t. 表示“在约束条件下”。换句话说，我们只允许那些 \(h_i(\mathbf{x}) = 0\) 的 \(\mathbf{x}''s\)。这里
    \(f : \mathbb{R}^d \to \mathbb{R}\) 和 \(h_i : \mathbb{R}^d \to \mathbb{R}\)，\(i\in
    [\ell]\)。我们有时会使用 \(\mathbf{h} : \mathbb{R}^d \to \mathbb{R}^\ell\) 的记法，其中 \(\mathbf{h}(\mathbf{x})
    = (h_1(\mathbf{x}), \ldots, h_\ell(\mathbf{x}))\).'
- en: '**EXAMPLE:** If we want to minimize \(2 x_1^2 + 3 x_2^2\) over all two-dimensional
    unit vectors \(\mathbf{x} = (x_1, x_2)\), then we can let'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 如果我们想要在所有二维单位向量 \(\mathbf{x} = (x_1, x_2)\) 上最小化 \(2 x_1^2 + 3 x_2^2\)，那么我们可以设'
- en: \[ f(\mathbf{x}) = 2 x_1^2 + 3 x_2^2 \]
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = 2 x_1^2 + 3 x_2^2 \]
- en: and
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ h_1(\mathbf{x}) = 1 - x_1^2 - x_2^2 = 1 - \|\mathbf{x}\|^2. \]
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(\mathbf{x}) = 1 - x_1^2 - x_2^2 = 1 - \|\mathbf{x}\|^2. \]
- en: Observe that we could have chosen a different equality constraint to express
    the same minimization problem. \(\lhd\)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以选择不同的等式约束来表示相同的最小化问题。 \(\lhd\)
- en: The following theorem generalizes the *First-Order Necessary Optimality Condition*.
    The proof is omitted.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下定理推广了**一阶必要最优性条件**。证明从略。
- en: '**THEOREM** **(Lagrange Multipliers)** \(\idx{Lagrange multipliers theorem}\xdi\)
    Assume \(f : \mathbb{R}^d \to \mathbb{R}\) and \(h_i : \mathbb{R}^d \to \mathbb{R}\),
    \(i\in [\ell]\), are continuously differentiable. Let \(\mathbf{x}^*\) be a local
    minimizer of \(f\) s.t. \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\). Assume further
    that the vectors \(\nabla h_i (\mathbf{x}^*)\), \(i \in [\ell]\), are linearly
    independent. Then there exists a unique vector'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **（拉格朗日乘数法）** \(\idx{拉格朗日乘数定理}\xdi\) 假设 \(f : \mathbb{R}^d \to \mathbb{R}\)
    和 \(h_i : \mathbb{R}^d \to \mathbb{R}\)，\(i\in [\ell]\)，是连续可微的。设 \(\mathbf{x}^*\)
    是 \(f\) 的局部极小值点，且满足 \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)。进一步假设向量 \(\nabla h_i
    (\mathbf{x}^*)\)，\(i \in [\ell]\)，是线性无关的。那么存在一个唯一的向量'
- en: \[ \blambda^* = (\lambda_1^*, \ldots, \lambda_\ell^*) \]
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \blambda^* = (\lambda_1^*, \ldots, \lambda_\ell^*) \]
- en: satisfying
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 满足
- en: \[ \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}. \]
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}. \]
- en: \(\sharp\)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: The quantities \(\lambda_1^*, \ldots, \lambda_\ell^*\) are called Lagrange multipliers\(\idx{Lagrange
    multipliers}\xdi\).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 量 \(\lambda_1^*, \ldots, \lambda_\ell^*\) 被称为拉格朗日乘数\(\idx{拉格朗日乘数}\xdi\)。
- en: '**EXAMPLE:** **(continued)** Returning to the previous example,'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** **（继续）** 回到前面的例子，'
- en: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2) \]
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2) \]
- en: and
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
- en: The conditions in the theorem read
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 该定理中的条件表述为
- en: \[\begin{align*} &4 x_1 - 2 \lambda_1 x_1 = 0\\ &6 x_2 - 2 \lambda_1 x_2 = 0.
    \end{align*}\]
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &4 x_1 - 2 \lambda_1 x_1 = 0\\ &6 x_2 - 2 \lambda_1 x_2 = 0.
    \end{align*}\]
- en: The constraint \(x_1^2 + x_2^2 = 1\) must also be satisfied. Observe that the
    linear independence condition is automatically satisfied since there is only one
    constraint.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 约束 \(x_1^2 + x_2^2 = 1\) 也必须满足。观察发现，由于只有一个约束，线性无关条件自动满足。
- en: There are several cases to consider.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种情况需要考虑。
- en: 1- If neither \(x_1\) nor \(x_2\) is \(0\), then the first equation gives \(\lambda_1
    = 2\) while the second one gives \(\lambda_1 = 3\). So that case cannot happen.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 如果 \(x_1\) 和 \(x_2\) 都不是 \(0\)，那么第一个方程给出 \(\lambda_1 = 2\)，而第二个方程给出 \(\lambda_1
    = 3\)。所以这种情况不可能发生。
- en: 2- If \(x_1 = 0\), then \(x_2 = 1\) or \(x_2 = -1\) by the constraint and the
    second equation gives \(\lambda_1 = 3\) in either case.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 如果 \(x_1 = 0\)，那么根据约束条件 \(x_2 = 1\) 或 \(x_2 = -1\)，第二个方程在两种情况下都给出 \(\lambda_1
    = 3\)。
- en: 3- If \(x_2 = 0\), then \(x_1 = 1\) or \(x_1 = -1\) by the constraint and the
    first equation gives \(\lambda_1 = 2\) in either case.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 3- 如果 \(x_2 = 0\)，那么根据约束条件 \(x_1 = 1\) 或 \(x_1 = -1\)，第一个方程在两种情况下都给出 \(\lambda_1
    = 2\)。
- en: Does any of these last four solutions, i.e., \((x_1,x_2,\lambda_1) = (0,1,3)\),
    \((x_1,x_2,\lambda_1) = (0,-1,3)\), \((x_1,x_2,\lambda_1) = (1,0,2)\) and \((x_1,x_2,\lambda_1)
    = (-1,0,2)\), actually correspond to a local minimizer?
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些最后四个解中的任何一个，即 \((x_1,x_2,\lambda_1) = (0,1,3)\)，\((x_1,x_2,\lambda_1) = (0,-1,3)\)，\((x_1,x_2,\lambda_1)
    = (1,0,2)\) 和 \((x_1,x_2,\lambda_1) = (-1,0,2)\)，实际上对应于局部最小值吗？
- en: This problem can be solved manually. Indeed, replace \(x_2^2 = 1 - x_1^2\) into
    the objective function to obtain
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可以通过手工解决。实际上，将 \(x_2^2 = 1 - x_1^2\) 代入目标函数，可以得到
- en: \[ 2 x_1^2 + 3(1 - x_1^2) = -x_1^2 + 3. \]
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 2 x_1^2 + 3(1 - x_1^2) = -x_1^2 + 3. \]
- en: This is minimized for the largest value that \(x_1^2\) can take, namely when
    \(x_1 = 1\) or \(x_1 = -1\). Indeed, we must have \(0 \leq x_1^2 \leq x_1^2 +
    x_2^2 = 1\). So both \((x_1, x_2) = (1,0)\) and \((x_1, x_2) = (-1,0)\) are global
    minimizers. A fortiori, they must be local minimizers.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 \(x_1^2\) 可以取的最大值时最小化的，即当 \(x_1 = 1\) 或 \(x_1 = -1\) 时。确实，我们必须有 \(0 \leq
    x_1^2 \leq x_1^2 + x_2^2 = 1\)。因此，\((x_1, x_2) = (1,0)\) 和 \((x_1, x_2) = (-1,0)\)
    都是全局最小值。更不用说，它们必须是局部最小值。
- en: What about \((x_1,x_2) = (0,1)\) and \((x_1,x_2) = (0,-1)\)? Arguing as above,
    they in fact correspond to global *maximizers* of the objective function. \(\lhd\)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 \((x_1,x_2) = (0,1)\) 和 \((x_1,x_2) = (0,-1)\) 呢？按照上述方式进行论证，它们实际上对应于目标函数的全局**最大化者**。
    \(\lhd\)
- en: Assume \(\mathbf{x}\) is feasible, that is, \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\).
    We let
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 \(\mathbf{x}\) 是可行的，即 \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)。我们让
- en: \[ \mathscr{F}_{\mathbf{h}}(\mathbf{x}) = \left\{ \mathbf{v} \in \mathbb{R}^d
    \,:\, \nabla h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0},\ \forall i \in [\ell]
    \right\} \]
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathscr{F}_{\mathbf{h}}(\mathbf{x}) = \left\{ \mathbf{v} \in \mathbb{R}^d
    \,:\, \nabla h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0},\ \forall i \in [\ell]
    \right\} \]
- en: be the linear subspace of first-order feasible directions\(\idx{first-order
    feasible directions}\xdi\) at \(\mathbf{x}\). To explain the name, note that by
    a first-order Taylor expansion, if \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\)
    then it holds that
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 是 \(\mathbf{x}\) 处的一阶可行方向**一阶可行方向**的线性子空间\(\idx{一阶可行方向}\xdi\)。为了解释这个名称，请注意，通过一阶泰勒展开，如果
    \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\)，那么它满足以下条件
- en: \[ h_i(\mathbf{x} + \delta \mathbf{v}) \approx h_i(\mathbf{x}) + \delta \nabla
    h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0} \]
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_i(\mathbf{x} + \delta \mathbf{v}) \approx h_i(\mathbf{x}) + \delta \nabla
    h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0} \]
- en: for all \(i\).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(i\)。
- en: The theorem says that, if \(\mathbf{x}^*\) is a local minimizer, then the gradient
    of \(f\) is orthogonal to the set of first-order feasible directions at \(\mathbf{x}^*\).
    Indeed, any \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x}^*)\) satisfies
    by the theorem that
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 该定理表明，如果 \(\mathbf{x}^*\) 是局部最小值，那么 \(f\) 的梯度与 \(\mathbf{x}^*\) 处的一阶可行方向集正交。确实，任何
    \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x}^*)\) 都满足定理，即
- en: \[ \nabla f(\mathbf{x}^*)^T \mathbf{v} = \left(- \sum_{i=1}^\ell \lambda^*_i
    \nabla h_i(\mathbf{x}^*)\right)^T \mathbf{v} = - \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*)^T \mathbf{v} = 0. \]
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}^*)^T \mathbf{v} = \left(- \sum_{i=1}^\ell \lambda^*_i
    \nabla h_i(\mathbf{x}^*)\right)^T \mathbf{v} = - \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*)^T \mathbf{v} = 0. \]
- en: Intuitively, following a first-order feasible direction does not alter the objective
    function value up to second-order error
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，沿着第一阶可行方向进行不会改变目标函数值，直到二阶误差。
- en: \[ f(\mathbf{x}^* + \alpha \mathbf{v}) \approx f(\mathbf{x}^*) + \alpha \nabla
    f(\mathbf{x}^*)^T \mathbf{v} = f(\mathbf{x}^*). \]
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}^* + \alpha \mathbf{v}) \approx f(\mathbf{x}^*) + \alpha \nabla
    f(\mathbf{x}^*)^T \mathbf{v} = f(\mathbf{x}^*). \]
- en: '**NUMERICAL CORNER:** Returning to the previous example, the points satisfying
    \(h_1(\mathbf{x}) = 0\) sit on the circle of radius \(1\) around the origin. We
    have already seen that'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 回到先前的例子，满足 \(h_1(\mathbf{x}) = 0\) 的点位于原点半径为 \(1\) 的圆上。我们已经看到'
- en: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
- en: Here is code illustrating the theorem (with help from ChatGPT). We first compute
    the function \(h_1\) at a grid of points using [`numpy.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是说明该定理的代码（在 ChatGPT 的帮助下）。我们首先使用 `numpy.meshgrid` ([numpy.meshgrid](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html))
    在点阵上计算函数 \(h_1\)。
- en: '[PRE3]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We use [`matplotlib.pyplot.contour`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html)
    to plot the constraint set as a [contour line](https://en.wikipedia.org/wiki/Contour_line)
    (for the constant value \(0\)) of \(h_1\). Gradients of \(h_1\) are plotted at
    a collection of `points` with the [`matplotlib.pyplot.quiver`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.quiver.html)
    function, which is used for plotting vectors as arrows. We see that the directions
    of first-order feasible directions are orthogonal to the arrows, and therefore
    are tangent to the constraint set.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `matplotlib.pyplot.contour` ([matplotlib.pyplot.contour](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html))
    来绘制约束集作为 \(h_1\) 的 [等高线](https://en.wikipedia.org/wiki/Contour_line)（对于常数值 \(0\)）。我们使用
    `matplotlib.pyplot.quiver` ([matplotlib.pyplot.quiver](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.quiver.html))
    函数在一系列 `points` 上绘制 \(h_1\) 的梯度，该函数用于以箭头形式绘制向量。我们看到一阶可行方向的向量与箭头垂直，因此它们是约束集的切线。
- en: At those same `points`, we also plot the gradient of \(f\), which recall is
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些相同的 `points` 上，我们还绘制了 \(f\) 的梯度，回忆起来是
- en: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2). \]
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2). \]
- en: We make all gradients into unit vectors.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有梯度转换为单位向量。
- en: '[PRE4]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![../../_images/a5aed8b6b668174566d2d532e4b400fcf5707acf3befc2f4f7b86d23fc3b68a5.png](../Images/b947d14ae52253453dee08ef202017c5.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/a5aed8b6b668174566d2d532e4b400fcf5707acf3befc2f4f7b86d23fc3b68a5.png](../Images/b947d14ae52253453dee08ef202017c5.png)'
- en: We see that, at \((-1,0)\) and \((1,0)\), the gradient is indeed orthogonal
    to the first-order feasible directions.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在 \((-1,0)\) 和 \((1,0)\) 处，梯度确实与一阶可行方向正交。
- en: \(\unlhd\)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: A feasible vector \(\mathbf{x}\) is said to be regular if the vectors \(\nabla
    h_i (\mathbf{x}^*)\), \(i \in [\ell]\), are linearly independent. We re-formulate
    the previous theorem in terms of the Lagrangian function, which is defined as
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果向量 \(\nabla h_i (\mathbf{x}^*)\)（\(i \in [\ell]\)）线性无关，则可行向量 \(\mathbf{x}\)
    被称为正则。我们用拉格朗日函数重新表述先前的定理，该函数定义为
- en: \[ L(\mathbf{x}, \blambda) = f(\mathbf{x}) + \sum_{i=1}^\ell \lambda_i h_i(\mathbf{x}),
    \]
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L(\mathbf{x}, \blambda) = f(\mathbf{x}) + \sum_{i=1}^\ell \lambda_i h_i(\mathbf{x}),
    \]
- en: where \(\blambda = (\lambda_1,\ldots,\lambda_\ell)\). Then, by the theorem,
    a regular local minimizer satisfies
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\blambda = (\lambda_1,\ldots,\lambda_\ell)\)。然后，根据定理，正则局部极小值满足
- en: \[\begin{align*} &\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\\
    &\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}. \end{align*}\]
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\\
    &\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}. \end{align*}\]
- en: Here the notation \(\nabla_{\mathbf{x}}\) (respectively \(\nabla_{\blambda}\))
    indicates that we are taking the vector of partial derivatives with respect to
    only the variables in \(\mathbf{x}\) (respectively \(\blambda\)).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这里符号 \(\nabla_{\mathbf{x}}\)（分别 \(\nabla_{\blambda}\)）表示我们只对 \(\mathbf{x}\)（分别
    \(\blambda\)）中的变量求偏导数的向量。
- en: To see that these equations hold, note that
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 要证明这些方程成立，请注意
- en: \[ \nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \nabla f(\mathbf{x}) + \sum_{i=1}^\ell
    \lambda_i \nabla h_i(\mathbf{x}) \]
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \nabla f(\mathbf{x}) + \sum_{i=1}^\ell
    \lambda_i \nabla h_i(\mathbf{x}) \]
- en: and
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 并且
- en: \[ \nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{h}(\mathbf{x}). \]
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{h}(\mathbf{x}). \]
- en: So \(\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\) is a restatement
    of the Lagrange multipliers condition and \(\nabla_{\blambda} L(\mathbf{x}, \blambda)
    = \mathbf{0}\) is a restatement of feasibility. Together, they form a system of
    \(d + \ell\) equations in \(d + \ell\) variables.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\) 是拉格朗日乘数条件的另一种表述，而
    \(\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}\) 是可行性的另一种表述。它们共同构成了
    \(d + \ell\) 个变量中的 \(d + \ell\) 个方程的系统。
- en: '**EXAMPLE:** Consider the constrained minimization problem on \(\mathbb{R}^3\)
    where the objective function is'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**例题** 考虑在 \(\mathbb{R}^3\) 上的约束最小化问题，其中目标函数是'
- en: \[ f(\mathbf{x}) = \frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \]
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = \frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \]
- en: and the only constraint function is
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的约束函数是
- en: \[ h_1(\mathbf{x}) = 3 - x_1 - x_2 - x_3. \]
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(\mathbf{x}) = 3 - x_1 - x_2 - x_3. \]
- en: The gradients are
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度是
- en: \[ \nabla f(\mathbf{x}) = (x_1, x_2, x_3) \]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = (x_1, x_2, x_3) \]
- en: and
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \nabla h_1(\mathbf{x}) = (-1, -1, -1). \]
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = (-1, -1, -1). \]
- en: In particular, regularity is always satisfied since there is only one non-zero
    vector to consider.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，由于只有一个非零向量需要考虑，所以总是满足正则性。
- en: So we are looking for solutions to the system of equations
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们正在寻找方程组的解
- en: \[\begin{align*} &x_1 - \lambda_1 = 0\\ &x_2 - \lambda_1 = 0\\ &x_3 - \lambda_1
    = 0\\ &3 - x_1 - x_2 - x_3 = 0. \end{align*}\]
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &x_1 - \lambda_1 = 0\\ &x_2 - \lambda_1 = 0\\ &x_3 - \lambda_1
    = 0\\ &3 - x_1 - x_2 - x_3 = 0. \end{align*}\]
- en: The first three equations imply that \(x_1 = x_2 = x_3 = \lambda\). Replacing
    in the fourth equation gives \(3 - 3 \lambda_1 = 0\) so \(\lambda_1 = 1\). Hence,
    \(x_1 = x_2 = x_3 = 1\) and this is the only solution.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个方程意味着 \(x_1 = x_2 = x_3 = \lambda\)。将它们代入第四个方程得到 \(3 - 3 \lambda_1 = 0\)，因此
    \(\lambda_1 = 1\)。因此，\(x_1 = x_2 = x_3 = 1\)，这是唯一的解。
- en: So any local minimizer, if it exists, must be the vector \((1,1,1)\) with Lagrange
    multiplier \(1\). How can we know for sure whether this is the case? \(\lhd\)
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何局部极小值（如果存在），必须是向量 \((1,1,1)\) 与拉格朗日乘数 \(1\)。我们如何确定这是否是这种情况？ \(\lhd\)
- en: As in the unconstrained case, there are *sufficient* conditions. As in that
    case as well, they involve second-order derivatives. We give one such theorem
    next without proof.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 与无约束情况一样，存在*充分*条件。同样，它们涉及二阶导数。我们将在下面给出一个不证明的定理。
- en: '**THEOREM** Assume \(f : \mathbb{R}^d \to \mathbb{R}\) and \(h_i : \mathbb{R}^d
    \to \mathbb{R}\), \(i\in [\ell]\), are twice continuously differentiable. Let
    \(\mathbf{x}^* \in \mathbb{R}^d\) and \(\blambda^* \in \mathbb{R}^\ell\) satisfy'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** 假设 \(f : \mathbb{R}^d \to \mathbb{R}\) 和 \(h_i : \mathbb{R}^d \to \mathbb{R}\)，\(i\in
    [\ell]\)，是二阶连续可微的。令 \(\mathbf{x}^* \in \mathbb{R}^d\) 和 \(\blambda^* \in \mathbb{R}^\ell\)
    满足'
- en: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
- en: and
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} > 0 \]
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} > 0 \]
- en: for all \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\). Then \(\mathbf{x}^*\)
    a strict local minimizer of \(f\) s.t. \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\).
    \(\sharp\)
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\)。因此，\(\mathbf{x}^*\)
    是 \(f\) 的严格局部极小值，使得 \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)。 \(\sharp\)
- en: '**EXAMPLE:** **(continued)** We return to the previous example. We found a
    unique solution'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**例题** **（继续）** 我们回到前面的例子。我们找到了一个唯一解'
- en: \[ (x_1^*, x_2^*, x_3^*, \lambda_1^*) = (1,1,1,1) \]
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (x_1^*, x_2^*, x_3^*, \lambda_1^*) = (1,1,1,1) \]
- en: to the system
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 到系统
- en: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
- en: To check the second-order condition, we need the Hessians. It is straighforward
    to compute the second-order partial derivatives, which do not depend on \(\mathbf{x}\).
    We obtain
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查二阶条件，我们需要Hessian矩阵。计算二阶偏导数是直接的，它们不依赖于 \(\mathbf{x}\)。我们得到
- en: \[ \mathbf{H}_{f}(\mathbf{x}) = I_{3 \times 3} \]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_{f}(\mathbf{x}) = I_{3 \times 3} \]
- en: and
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \mathbf{H}_{h_1}(\mathbf{x}) = \mathbf{0}_{3 \times 3}. \]
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_{h_1}(\mathbf{x}) = \mathbf{0}_{3 \times 3}. \]
- en: So
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 因此
- en: \[ \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \mathbf{H}_{h_i}(\mathbf{x}^*)
    = I_{3 \times 3} \]
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \mathbf{H}_{h_i}(\mathbf{x}^*)
    = I_{3 \times 3} \]
- en: and it follows that
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 并且由此得出
- en: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} = \mathbf{v}^T I_{3 \times 3}
    \mathbf{v} = \|\mathbf{v}\|^2 > 0 \]
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} = \mathbf{v}^T I_{3 \times 3}
    \mathbf{v} = \|\mathbf{v}\|^2 > 0 \]
- en: for any non-zero vector, including those in \(\mathscr{F}_{\mathbf{h}}(\mathbf{x})\).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何非零向量，包括 \(\mathscr{F}_{\mathbf{h}}(\mathbf{x})\) 中的向量。
- en: It follows from the previous theorem that \(\mathbf{x}^*\) is a strict local
    minimizer of the constrained problem. \(\lhd\)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的定理可以得出，\(\mathbf{x}^*\) 是约束问题的严格局部最小值。\(\lhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(在 Claude、Gemini 和 ChatGPT 的帮助下)*'
- en: '**1** Which of the following is the correct definition of a global minimizer
    \(\mathbf{x}^*\) of a function \(f: \mathbb{R}^d \to \mathbb{R}\)?'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 以下哪个是函数 \(f: \mathbb{R}^d \to \mathbb{R}\) 的全局最小值 \(\mathbf{x}^*\) 的正确定义？'
- en: a) \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\) for all \(x\) in some open ball around
    \(\mathbf{x}^*\).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: a) 对于 \(\mathbf{x}^*\) 附近某个开球内的所有 \(x\)，\(f(\mathbf{x}) \geq f(\mathbf{x}^*)\)。
- en: b) \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\) for all \(\mathbf{x} \in \mathbb{R}^d\).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: b) 对于所有 \(\mathbf{x} \in \mathbb{R}^d\)，\(f(\mathbf{x}) \geq f(\mathbf{x}^*)\).
- en: c) \(\nabla f(\mathbf{x}^*) = 0\).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\nabla f(\mathbf{x}^*) = 0\).
- en: d) \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}^*) \mathbf{v} > 0\) for all \(\mathbf{v}
    \in \mathbb{R}^d\).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对于所有 \(\mathbf{v} \in \mathbb{R}^d\)，\(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}^*)
    \mathbf{v} > 0\)。
- en: '**2** Let \(f: \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable
    at \(\mathbf{x}_0\). The directional derivative of \(f\) at \(\mathbf{x}_0\) in
    the direction \(\mathbf{v} \in \mathbb{R}^d\) is NOT given by:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 设 \(f: \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbf{x}_0\) 处连续可微。\(f\) 在
    \(\mathbf{x}_0\) 处沿 \(\mathbb{R}^d\) 中的方向 \(\mathbf{v}\) 的方向导数 NOT 由以下给出：'
- en: a) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\).
- en: b) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \nabla
    f(\mathbf{x}_0)\).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \nabla
    f(\mathbf{x}_0)\)。
- en: c) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\).
- en: d) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \lim_{h \to 0} \frac{f(\mathbf{x}_0
    + h\mathbf{v}) - f(\mathbf{x}_0)}{h}\).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \lim_{h \to 0} \frac{f(\mathbf{x}_0
    + h\mathbf{v}) - f(\mathbf{x}_0)}{h}\).
- en: '**3** Let \(f: \mathbb{R}^d \to \mathbb{R}\) be twice continuously differentiable.
    If \(\nabla f(\mathbf{x}_0) = 0\) and \(\mathbf{H}_f(\mathbf{x}_0)\) is positive
    definite, then \(\mathbf{x}_0\) is:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 设 \(f: \mathbb{R}^d \to \mathbb{R}\) 是二阶连续可微的。如果 \(\nabla f(\mathbf{x}_0)
    = 0\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\) 是：'
- en: a) A global minimizer of \(f\).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(f\) 的全局最小值。
- en: b) A local minimizer of \(f\), but not necessarily a strict local minimizer.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(f\) 的局部最小值，但不一定是严格局部最小值。
- en: c) A strict local minimizer of \(f\).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(f\) 的严格局部最小值。
- en: d) A saddle point of \(f\).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(f\) 的鞍点。
- en: '**4** Consider the optimization problem \(\min_\mathbf{x} f(\mathbf{x})\) subject
    to \(\mathbf{h}(\mathbf{x}) = 0\), where \(f: \mathbb{R}^d \to \mathbb{R}\) and
    \(h: \mathbb{R}^d \to \mathbb{R}^\ell\) are continuously differentiable. Let \(\mathbf{x}^*\)
    be a local minimizer and assume that the vectors \(\nabla h_i(\mathbf{x}^*), i
    \in [\ell]\), are linearly independent. According to the Lagrange Multipliers
    theorem, which of the following must be true?'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 考虑优化问题 \(\min_\mathbf{x} f(\mathbf{x})\) 在约束 \(\mathbf{h}(\mathbf{x})
    = 0\) 下，其中 \(f: \mathbb{R}^d \to \mathbb{R}\) 和 \(h: \mathbb{R}^d \to \mathbb{R}^\ell\)
    是连续可微的。设 \(\mathbf{x}^*\) 是一个局部最小值，并假设向量 \(\nabla h_i(\mathbf{x}^*), i \in [\ell]\)
    是线性无关的。根据拉格朗日乘数法，以下哪个必须成立？'
- en: a) \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)。
- en: b) \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}\) for some \(\lambda^* \in \mathbb{R}^\ell\).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}\) 对于某个 \(\lambda^* \in \mathbb{R}^\ell\).
- en: c) \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\)。
- en: d) Both b and c.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: d) b 和 c 都正确。
- en: '**5** Which of the following is a correct statement of Taylor’s Theorem (to
    second order) for a twice continuously differentiable function \(f: D \to \mathbb{R}\),
    where \(D \subseteq \mathbb{R}^d\), at an interior point \(\mathbf{x}_0 \in D\)?'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪个是关于二阶连续可微函数 \(f: D \to \mathbb{R}\)（其中 \(D \subseteq \mathbb{R}^d\)）在内部点
    \(\mathbf{x}_0 \in D\) 的泰勒定理（二阶）的正确陈述？'
- en: a) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2}(\mathbf{x}
    - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))(\mathbf{x}
    - \mathbf{x}_0)\) for some \(\xi \in (0,1)\).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: a) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2}(\mathbf{x}
    - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))(\mathbf{x}
    - \mathbf{x}_0)\) 对于某个 \(\xi \in (0,1)\).
- en: b) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x} - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x}
    - \mathbf{x}_0))(\mathbf{x} - \mathbf{x}_0)\).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: b) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x} - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x}
    - \mathbf{x}_0))(\mathbf{x} - \mathbf{x}_0)\).
- en: c) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)\).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: c) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)\).
- en: d) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T \mathbf{H}_f(\mathbf{x}_0)(\mathbf{x}_0
    + \xi(\mathbf{x} - \mathbf{x}_0))\).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T \mathbf{H}_f(\mathbf{x}_0)(\mathbf{x}_0
    + \xi(\mathbf{x} - \mathbf{x}_0))\).
- en: 'Answer for Q3.3.1: b. Justification: The text states that “The point \(\mathbf{x}^*
    \in \mathbb{R}^d\) is a global minimizer of \(f\) over \(\mathbb{R}^d\) if \(f(\mathbf{x})
    \geq f(\mathbf{x}^*), \forall \mathbf{x} \in \mathbb{R}^d\).”'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.1的答案：b. 证明：文本中提到，“如果 \(\mathbf{x}^* \in \mathbb{R}^d\) 是 \(f\) 在 \(\mathbb{R}^d\)
    上的全局最小值，那么 \(f(\mathbf{x}) \geq f(\mathbf{x}^*), \forall \mathbf{x} \in \mathbb{R}^d\).”
- en: 'Answer for Q3.3.7: c. Justification: The text states the Directional Derivative
    from Gradient theorem: “Assume that \(f\) is continuously differentiable at \(\mathbf{x}_0\).
    Then the directional derivative of \(f\) at \(\mathbf{x}_0\) in the direction
    \(\mathbf{v}\) is given by \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}
    = \nabla f(\mathbf{x}_0)^T \mathbf{v}\).”'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.7的答案：c. 证明：文本中陈述了梯度定理的方向导数：“假设 \(f\) 在 \(\mathbf{x}_0\) 处连续可微。那么 \(f\)
    在 \(\mathbf{x}_0\) 处沿方向 \(\mathbf{v}\) 的方向导数为 \(\frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}} = \nabla f(\mathbf{x}_0)^T \mathbf{v}\).”
- en: 'Answer for Q3.3.9: c. Justification: The text states the Second-Order Sufficient
    Condition theorem: “If \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\)
    is positive definite, then \(\mathbf{x}_0\) is a strict local minimizer.”'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.9的答案：c. 证明：文本中陈述了二阶充分条件定理：“如果 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) 且
    \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\) 是一个严格局部最小值。”
- en: 'Answer for Q3.3.12: d. Justification: The Lagrange Multipliers theorem states
    that under the given conditions, there exists a unique vector \(\boldsymbol{\lambda}^*
    = (\lambda_1^*, \ldots, \lambda_\ell^*)\) satisfying \(\nabla f(\mathbf{x}^*)
    + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*) = \mathbf{0}\) and \(\mathbf{h}(\mathbf{x}^*)
    = \mathbf{0}\).'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.12的答案：d. 证明：拉格朗日乘数法定理表明，在给定条件下，存在一个唯一的向量 \(\boldsymbol{\lambda}^* = (\lambda_1^*,
    \ldots, \lambda_\ell^*)\) 满足 \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^*
    \nabla h_i(\mathbf{x}^*) = \mathbf{0}\) 和 \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\).
- en: 'Answer for Q3.3.14: a. Justification: This is the statement of Taylor’s Theorem
    as presented in the text.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.14的答案：a. 证明：这是文本中呈现的泰勒定理的陈述。
- en: 3.3.1\. First-order conditions[#](#first-order-conditions "Link to this heading")
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.1\. 一阶条件[#](#first-order-conditions "链接到这个标题")
- en: Local minimizers can be characterized in terms of the gradient. We first define
    the concept of directional derivative.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 局部最小值可以用梯度来描述。我们首先定义方向导数的概念。
- en: '**Directional derivative** Partial derivatives measure the rate of change of
    a function along the axes. More generally:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '**方向导数** 偏导数测量函数沿轴的变化率。更一般地：'
- en: '**DEFINITION** **(Directional Derivative)** \(\idx{directional derivative}\xdi\)
    Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\), let \(\mathbf{x}_0
    = (x_{0,1},\ldots,x_{0,d}) \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    = (v_1,\ldots,v_d) \in \mathbb{R}^d\) be a nonzero vector. The directional derivative
    of \(f\) at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(方向导数)** \(\idx{directional derivative}\xdi\) 设\(f : D \to \mathbb{R}\)，其中\(D
    \subseteq \mathbb{R}^d\)，设\(\mathbf{x}_0 = (x_{0,1},\ldots,x_{0,d}) \in D\)是\(D\)的内点，设\(\mathbf{v}
    = (v_1,\ldots,v_d) \in \mathbb{R}^d\)是一个非零向量。\(f\)在\(\mathbf{x}_0\)沿\(\mathbf{v}\)方向的方向导数是'
- en: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} &= \lim_{h
    \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}\\ &= \lim_{h
    \to 0} \frac{f(x_{0,1} + h v_1,\ldots,x_{0,d} + h v_d) - f(x_{0,1},\ldots,x_{0,d})}{h}
    \end{align*}\]
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} &= \lim_{h
    \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}\\ &= \lim_{h
    \to 0} \frac{f(x_{0,1} + h v_1,\ldots,x_{0,d} + h v_d) - f(x_{0,1},\ldots,x_{0,d})}{h}
    \end{align*}\]
- en: provided the limit exists. \(\natural\)
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 假设极限存在。 \(\natural\)
- en: Typically, \(\mathbf{v}\) is a unit vector.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，\(\mathbf{v}\)是一个单位向量。
- en: Note that taking \(\mathbf{v} = \mathbf{e}_i\) recovers the \(i\)-th partial
    derivative
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，取\(\mathbf{v} = \mathbf{e}_i\)可以恢复第\(i\)个偏导数
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{e}_i} = \lim_{h \to 0}
    \frac{f(\mathbf{x}_0 + h \mathbf{e}_i) - f(\mathbf{x}_0)}{h} = \frac{\partial
    f (\mathbf{x}_0)}{\partial x_i}. \]
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{e}_i} = \lim_{h \to 0}
    \frac{f(\mathbf{x}_0 + h \mathbf{e}_i) - f(\mathbf{x}_0)}{h} = \frac{\partial
    f (\mathbf{x}_0)}{\partial x_i}. \]
- en: Conversely, a general directional derivative can be expressed in terms of the
    partial derivatives.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，一般方向导数可以用偏导数来表示。
- en: '**THEOREM** **(Directional Derivative and Gradient)** \(\idx{directional derivative
    and gradient theorem}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\),
    let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    \in \mathbb{R}^d\) be a vector. Assume that \(f\) is continuously differentiable
    at \(\mathbf{x}_0\). Then the directional derivative of \(f\) at \(\mathbf{x}_0\)
    in the direction \(\mathbf{v}\) is given by'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(方向导数与梯度)** \(\idx{directional derivative and gradient theorem}\xdi\)
    设\(f : D \to \mathbb{R}\)，其中\(D \subseteq \mathbb{R}^d\)，设\(\mathbf{x}_0 \in D\)是\(D\)的内点，设\(\mathbf{v}
    \in \mathbb{R}^d\)是一个向量。假设\(f\)在\(\mathbf{x}_0\)处是连续可微的。那么\(f\)在\(\mathbf{x}_0\)沿\(\mathbf{v}\)方向的方向导数由下式给出'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}. \]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}. \]
- en: \(\sharp\)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: Put differently, when \(\mathbf{v}\) is a unit vector, the directional derivative
    is the length of the orthogonal projection of the gradient onto \(\mathbf{v}\).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，当\(\mathbf{v}\)是单位向量时，方向导数是梯度在\(\mathbf{v}\)上的正交投影的长度。
- en: '*Proof idea:* To bring out the partial derivatives, we re-write the directional
    derivative as the derivative of a composition of \(f\) with an affine function.
    We then use the *Chain Rule*.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明思路**：为了突出偏导数，我们将方向导数重新写为函数\(f\)与仿射函数复合的导数。然后我们使用**链式法则**。'
- en: '*Proof:* Consider the composition \(\beta(h) = f(\boldsymbol{\alpha}(h))\)
    where \(\boldsymbol{\alpha}(h) = \mathbf{x}_0 + h \mathbf{v}\). Observe that \(\boldsymbol{\alpha}(0)=
    \mathbf{x}_0\) and \(\beta(0)= f(\mathbf{x}_0)\). Then, by definition of the derivative,'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明**：考虑复合函数\(\beta(h) = f(\boldsymbol{\alpha}(h))\)，其中\(\boldsymbol{\alpha}(h)
    = \mathbf{x}_0 + h \mathbf{v}\)。观察\(\boldsymbol{\alpha}(0)= \mathbf{x}_0\)和\(\beta(0)=
    f(\mathbf{x}_0)\)。然后，根据导数的定义，'
- en: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \lim_{h \to 0} \frac{\beta(h)
    - \beta(0)}{h} = \lim_{h \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}
    = \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}. \]
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \lim_{h \to 0} \frac{\beta(h)
    - \beta(0)}{h} = \lim_{h \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{v}) - f(\mathbf{x}_0)}{h}
    = \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}. \]
- en: Applying the *Chain Rule* and the parametric line example from the previous
    section, we arrive at
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 应用**链式法则**和上一节中的参数线示例，我们得到
- en: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \nabla f(\boldsymbol{\alpha}(0))^T
    \boldsymbol{\alpha}'(0) = \nabla f(\mathbf{x}_0)^T \mathbf{v}. \]
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\mathrm{d} \beta(0)}{\mathrm{d} h} = \nabla f(\boldsymbol{\alpha}(0))^T
    \boldsymbol{\alpha}'(0) = \nabla f(\mathbf{x}_0)^T \mathbf{v}. \]
- en: \(\square\)
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: '![Contour plot of the function . At the point , the gradient and a directional
    derivative are shown (with the help from ChatGPT; converted and adapted from (Source))](../Images/8e2172c7f2d739f2e83162ecdcafe29e.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![函数的等高线图。在点 \(\mathbf{x}_0\)，显示了梯度和一个方向导数（借助 ChatGPT；从（来源）转换和改编）](../Images/8e2172c7f2d739f2e83162ecdcafe29e.png)'
- en: '**KNOWLEDGE CHECK:** Let \(f : \mathbb{R}^2 \to \mathbb{R}\) be continuously
    differentiable. Suppose that'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查:** 设 \(f : \mathbb{R}^2 \to \mathbb{R}\) 在 \(\mathbb{R}^2\) 上连续可微。假设'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \frac{3}{\sqrt{5}}
    \qquad \text{and} \qquad \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{w}}
    = \frac{5}{\sqrt{5}} \]
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \frac{3}{\sqrt{5}}
    \qquad \text{和} \qquad \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{w}} =
    \frac{5}{\sqrt{5}} \]
- en: where \(\mathbf{v} = (1,2)/\sqrt{5}\) and \(\mathbf{w} = (2,1)/\sqrt{5}\). Compute
    the gradient of \(f\) at \(\mathbf{x}_0\). \(\checkmark\)
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{v} = (1,2)/\sqrt{5}\) 和 \(\mathbf{w} = (2,1)/\sqrt{5}\)。计算 \(f\)
    在 \(\mathbf{x}_0\) 处的梯度。 \(\checkmark\)
- en: '**Descent direction** Earlier in the book, we proved a key insight about the
    derivative of a single-variable function \(f\) at a point \(x_0\): it tells us
    where to find smaller values. We generalize the *Descent Direction Lemma* to the
    multivariable case.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '**下降方向** 在本书的早期，我们证明了关于单变量函数 \(f\) 在点 \(x_0\) 的导数的一个关键洞察：它告诉我们在哪里可以找到更小的值。我们将**下降方向引理**推广到多变量情况。'
- en: First, we observe that in the continuously differentiable case the directional
    derivative gives a criterion for descent directions.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们观察到在连续可微的情况下，方向导数给出了下降方向的判据。
- en: '**LEMMA** **(Descent Direction and Directional Derivative)** \(\idx{descent
    direction and directional derivative lemma}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be continuously differentiable at \(\mathbf{x}_0\). A vector \(\mathbf{v}\) is
    a descent direction for \(f\) at \(\mathbf{x}_0\) if'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(下降方向和方向导数)** \(\idx{下降方向和方向导数引理}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)
    在 \(\mathbf{x}_0\) 处连续可微。如果向量 \(\mathbf{v}\) 是 \(f\) 在 \(\mathbf{x}_0\) 处的下降方向，则'
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v} < 0 \]
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v} < 0 \]
- en: that is, if the directional derivative of \(f\) at \(\mathbf{x}_0\) in the direction
    \(\mathbf{v}\) is negative. \(\flat\)
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 即，如果 \(f\) 在 \(\mathbf{x}_0\) 处沿方向 \(\mathbf{v}\) 的方向导数是负的。 \(\flat\)
- en: '*Proof idea:* In anticipation of the proof of the second-order condition, we
    use the *Mean Value Theorem* to show that \(f\) takes smaller values in direction
    \(\mathbf{v}\). A simpler proof based on the definition of the directional derivative
    is also possible (Try it!).'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 为了证明二阶条件，我们使用**平均值定理**来证明 \(f\) 在方向 \(\mathbf{v}\) 上取更小的值。也可以基于方向导数的定义进行一个更简单的证明（试试看！）。'
- en: '*Proof:* Suppose there is \(\mathbf{v} \in \mathbb{R}^d\) such that \(\nabla
    f(\mathbf{x}_0)^T \mathbf{v} = -\eta < 0\). For \(\alpha > 0\), the *Mean Value
    Theorem* implies that there is \(\xi_\alpha \in (0,1)\) such that'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 假设存在 \(\mathbf{v} \in \mathbb{R}^d\) 使得 \(\nabla f(\mathbf{x}_0)^T \mathbf{v}
    = -\eta < 0\)。对于 \(\alpha > 0\)，**平均值定理**意味着存在 \(\xi_\alpha \in (0,1)\) 使得'
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v})^T(\alpha \mathbf{v}) = f(\mathbf{x}_0) + \alpha
    \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}. \]
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v})^T(\alpha \mathbf{v}) = f(\mathbf{x}_0) + \alpha
    \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}. \]
- en: We want to show that the second term on the right-hand side is negative. We
    cannot immediately apply our condition on \(\mathbf{v}\) as the gradient in the
    previous equation is taken at \(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}\),
    not \(\mathbf{x}_0\).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要证明的是右手边的第二项是负的。我们不能立即应用我们对 \(\mathbf{v}\) 的条件，因为前一个方程中的梯度是在 \(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}\) 处取的，而不是在 \(\mathbf{x}_0\) 处。
- en: The gradient is continuous (in the sense that all its components are continuous).
    In particular, the function \(\nabla f(\mathbf{x})^T \mathbf{v}\) is continuous
    as a linear combination of continuous functions. By the definition of continuity,
    for any \(\epsilon > 0\) – say \(\epsilon = \eta/2\) – there is \(\delta > 0\)
    small enough such that all \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\) satisfy
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度是连续的（在所有分量都是连续的意义上）。特别是，函数 \(\nabla f(\mathbf{x})^T \mathbf{v}\) 作为连续函数的线性组合是连续的。根据连续性的定义，对于任意
    \(\epsilon > 0\) – 例如 \(\epsilon = \eta/2\) – 存在 \(\delta > 0\) 足够小，使得所有 \(\mathbf{x}
    \in B_\delta(\mathbf{x}_0)\) 满足
- en: \[\begin{align*} \left|\nabla f(\mathbf{x})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\,\right| &< \epsilon = \eta/2. \end{align*}\]
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left|\nabla f(\mathbf{x})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\,\right| &< \epsilon = \eta/2. \end{align*}\]
- en: Take \(\alpha^* > 0\) small enough that \(\mathbf{x}_0 + \alpha^* \mathbf{v}
    \in B_\delta(\mathbf{x}_0)\). Then, for all \(\alpha \in (0,\alpha^*)\), whatever
    \(\xi_\alpha \in (0,1)\) is, it holds that \(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v} \in B_\delta(\mathbf{x}_0)\). Hence,
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\alpha^* > 0\) 足够小，使得 \(\mathbf{x}_0 + \alpha^* \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。然后，对于所有
    \(\alpha \in (0,\alpha^*)\)，无论 \(\xi_\alpha \in (0,1)\) 是什么，都有 \(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。因此，
- en: \[\begin{align*} \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}
    &= \nabla f(\mathbf{x}_0)^T \mathbf{v} + (\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v})\\ &\leq \nabla
    f(\mathbf{x}_0)^T \mathbf{v} + \left|\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\,\right|\\ &< -\eta
    + \eta/2\\ &= - \eta/2 < 0. \end{align*}\]
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})^T \mathbf{v}
    &= \nabla f(\mathbf{x}_0)^T \mathbf{v} + (\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v})\\ &\leq \nabla
    f(\mathbf{x}_0)^T \mathbf{v} + \left|\nabla f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\,\right|\\ &< -\eta
    + \eta/2\\ &= - \eta/2 < 0. \end{align*}\]
- en: by definition of \(\eta\). That implies
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义的 \(\eta\)。这意味着
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha \eta/2 < f(\mathbf{x}_0),
    \quad \forall \alpha \in (0,\alpha^*) \]
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha \eta/2 < f(\mathbf{x}_0),
    \quad \forall \alpha \in (0,\alpha^*) \]
- en: and proves the claim. \(\square\)
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 并证明了该命题。 \(\square\)
- en: '**LEMMA** **(Descent Direction)** \(\idx{descent direction lemma}\xdi\) Let
    \(f : \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable at \(\mathbf{x}_0\)
    and assume that \(\nabla f(\mathbf{x}_0) \neq 0\). Then \(f\) has a descent direction
    at \(\mathbf{x}_0\). \(\flat\)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(下降方向)** \(\idx{descent direction lemma}\xdi\) 设 \(f : \mathbb{R}^d
    \to \mathbb{R}\) 在 \(\mathbf{x}_0\) 处连续可微，并假设 \(\nabla f(\mathbf{x}_0) \neq 0\)。那么
    \(f\) 在 \(\mathbf{x}_0\) 处有一个下降方向。 \(\flat\)'
- en: '*Proof:* Take \(\mathbf{v} = - \nabla f(\mathbf{x}_0)\). Then \(\nabla f(\mathbf{x}_0)^T
    \mathbf{v} = - \|\nabla f(\mathbf{x}_0)\|^2 < 0\) since \(\nabla f(\mathbf{x}_0)
    \neq \mathbf{0}\). \(\square\)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*：取 \(\mathbf{v} = - \nabla f(\mathbf{x}_0)\)。那么 \(\nabla f(\mathbf{x}_0)^T
    \mathbf{v} = - \|\nabla f(\mathbf{x}_0)\|^2 < 0\)，因为 \(\nabla f(\mathbf{x}_0)
    \neq \mathbf{0}\)。 \(\square\)'
- en: This leads to the following fundamental result.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下基本结果。
- en: '**THEOREM** **(First-Order Necessary Optimality Condition)** \(\idx{first-order
    necessary optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be continuously differentiable on \(\mathbb{R}^d\). If \(\mathbf{x}_0\) is a local
    minimizer, then \(\nabla f(\mathbf{x}_0) = \mathbf{0}\). \(\sharp\)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(一阶必要最优性条件)** \(\idx{first-order necessary optimality condition}\xdi\)
    设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbb{R}^d\) 上连续可微。如果 \(\mathbf{x}_0\)
    是局部极小值点，那么 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。 \(\sharp\)'
- en: '*Proof idea:* In a descent direction, \(f\) decreases hence there cannot be
    one at a local minimizer.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路*：在下降方向上，\(f\) 减小，因此在局部极小值点处不可能存在下降方向。'
- en: '*Proof:* We argue by contradiction. Suppose that \(\nabla f(\mathbf{x}_0) \neq
    \mathbf{0}\). By the *Descent Direction Lemma*, there is a descent direction \(\mathbf{v}
    \in \mathbb{R}^d\) at \(\mathbf{x}_0\). That implies'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*：我们通过反证法进行论证。假设 \(\nabla f(\mathbf{x}_0) \neq \mathbf{0}\)。根据 *下降方向引理*，在
    \(\mathbf{x}_0\) 处存在一个下降方向 \(\mathbf{v} \in \mathbb{R}^d\)。这意味着'
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0), \quad \forall \alpha
    \in (0, \alpha^*) \]
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0), \quad \forall \alpha
    \in (0, \alpha^*) \]
- en: for some \(\alpha^* > 0\). So every open ball around \(\mathbf{x}_0\) has a
    point achieving a smaller value than \(f(\mathbf{x}_0)\). Thus \(\mathbf{x}_0\)
    is not a local minimizer, a contradiction. So it must be that \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\). \(\square\)
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\alpha^* > 0\)。所以 \(\mathbf{x}_0\) 附近的每一个开球都存在一个点，其函数值比 \(f(\mathbf{x}_0)\)
    更小。因此 \(\mathbf{x}_0\) 不是局部极小值点，这与假设矛盾。所以必须有 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。
    \(\square\)
- en: A point satisfying the first-order necessary conditions is called a stationary
    point.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 满足一阶必要条件的点称为驻点。
- en: '**DEFINITION** **(Stationary Point)** \(\idx{stationary point}\xdi\) Let \(f
    : D \to \mathbb{R}\) be continuously differentiable on an open set \(D \subseteq
    \mathbb{R}^d\). If \(\nabla f(\mathbf{x}_0) = \mathbf{0}\), we say that \(\mathbf{x}_0
    \in D\) is a stationary point of \(f\). \(\natural\)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(驻点)** \(\idx{stationary point}\xdi\) 设 \(f : D \to \mathbb{R}\) 在
    \(\mathbb{R}^d\) 的开集 \(D \subseteq \mathbb{R}^d\) 上连续可微。如果 \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\)，则称 \(\mathbf{x}_0 \in D\) 是 \(f\) 的驻点。 \(\natural\)'
- en: '**EXAMPLE:** **(Rayleight Quotient)** Let \(A \in \mathbb{R}^{d \times d}\)
    be a symmetric matrix. The associated Rayleigh quotient\(\idx{Rayleigh quotient}\xdi\)
    is'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** **（雷利商）** 设 \(A \in \mathbb{R}^{d \times d}\) 为一个对称矩阵。相关的雷利商\(\idx{雷利商}\xdi\)是'
- en: \[ \mathcal{R}_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A \mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} \]
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A \mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} \]
- en: which is defined for any \(\mathbf{u} = (u_1,\ldots,u_d) \neq \mathbf{0}\) in
    \(\mathbb{R}^{d}\). As a function from \(\mathbb{R}^{d} \setminus \{\mathbf{0}\}\)
    to \(\mathbb{R}\), \(\mathcal{R}_A(\mathbf{u})\) is continuously differentiable.
    We find its stationary points.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 \(\mathbb{R}^{d}\) 中对任何 \(\mathbf{u} = (u_1,\ldots,u_d) \neq \mathbf{0}\)
    定义的。作为一个从 \(\mathbb{R}^{d} \setminus \{\mathbf{0}\}\) 到 \(\mathbb{R}\) 的函数，\(\mathcal{R}_A(\mathbf{u})\)
    是连续可微的。我们找到它的驻点。
- en: We use the [quotient rule](https://en.wikipedia.org/wiki/Quotient_rule) and
    our previous results on the gradient of quadratic functions. Specifically, note
    that (using that \(A\) is symmetric)
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用[商规则](https://en.wikipedia.org/wiki/Quotient_rule)和我们对二次函数梯度的先前结果。具体来说，注意（使用
    \(A\) 是对称的）
- en: \[\begin{align*} \frac{\partial}{\partial u_i} \mathcal{R}_A(\mathbf{u}) &=
    \frac{\left(\frac{\partial}{\partial u_i} \langle \mathbf{u}, A \mathbf{u} \rangle\right)
    \langle \mathbf{u}, \mathbf{u} \rangle - \langle \mathbf{u}, A \mathbf{u} \rangle
    \left( \frac{\partial}{\partial u_i} \langle \mathbf{u}, \mathbf{u} \rangle\right)}{\langle
    \mathbf{u}, \mathbf{u} \rangle^2}\\ &= \frac{2\left(\frac{\partial}{\partial u_i}
    \frac{1}{2}\mathbf{u}^T A \mathbf{u}\right) \|\mathbf{u}\|^2 - \mathbf{u}^T A
    \mathbf{u} \left( \frac{\partial}{\partial u_i} \sum_{j=1}^d u_j^2\right)}{\|\mathbf{u}\|^4}\\
    &= \frac{2\left(A \mathbf{u}\right)_i \|\mathbf{u}\|^2 - \mathbf{u}^T A \mathbf{u}
    \left( 2 u_i \right)}{\|\mathbf{u}\|^4}\\ &= \frac{2}{\|\mathbf{u}\|^2}\left\{\left(A
    \mathbf{u}\right)_i - \mathcal{R}_A(\mathbf{u}) u_i \right\}. \end{align*}\]
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial}{\partial u_i} \mathcal{R}_A(\mathbf{u}) &=
    \frac{\left(\frac{\partial}{\partial u_i} \langle \mathbf{u}, A \mathbf{u} \rangle\right)
    \langle \mathbf{u}, \mathbf{u} \rangle - \langle \mathbf{u}, A \mathbf{u} \rangle
    \left( \frac{\partial}{\partial u_i} \langle \mathbf{u}, \mathbf{u} \rangle\right)}{\langle
    \mathbf{u}, \mathbf{u} \rangle^2}\\ &= \frac{2\left(\frac{\partial}{\partial u_i}
    \frac{1}{2}\mathbf{u}^T A \mathbf{u}\right) \|\mathbf{u}\|^2 - \mathbf{u}^T A
    \mathbf{u} \left( \frac{\partial}{\partial u_i} \sum_{j=1}^d u_j^2\right)}{\|\mathbf{u}\|^4}\\
    &= \frac{2\left(A \mathbf{u}\right)_i \|\mathbf{u}\|^2 - \mathbf{u}^T A \mathbf{u}
    \left( 2 u_i \right)}{\|\mathbf{u}\|^4}\\ &= \frac{2}{\|\mathbf{u}\|^2}\left\{\left(A
    \mathbf{u}\right)_i - \mathcal{R}_A(\mathbf{u}) u_i \right\}. \end{align*}\]
- en: In vector form this is
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 以向量形式表示为
- en: \[ \nabla \mathcal{R}_A(\mathbf{u}) = \frac{2}{\|\mathbf{u}\|^2} \left\{A \mathbf{u}
    - \mathcal{R}_A(\mathbf{u}) \,\mathbf{u} \right\}. \]
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla \mathcal{R}_A(\mathbf{u}) = \frac{2}{\|\mathbf{u}\|^2} \left\{A \mathbf{u}
    - \mathcal{R}_A(\mathbf{u}) \,\mathbf{u} \right\}. \]
- en: The stationary points satisfy \(\nabla \mathcal{R}_A(\mathbf{u}) = \mathbf{0}\),
    or after getting rid of the denominator and rearranging,
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定点满足 \(\nabla \mathcal{R}_A(\mathbf{u}) = \mathbf{0}\)，或者去掉分母并重新排列后，
- en: \[ A \mathbf{u} = \mathcal{R}_A(\mathbf{u}) \,\mathbf{u}. \]
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A \mathbf{u} = \mathcal{R}_A(\mathbf{u}) \,\mathbf{u}. \]
- en: The solutions to this system are eigenvectors of \(A\), that is, they satisfy
    \(A\mathbf{u} = \lambda \mathbf{u}\) for some eigenvalue \(\lambda\). If \(\mathbf{q}_i\)
    is a unit eigenvector of \(A\) with eigenvalue \(\lambda_i\), then we have that
    \(\mathcal{R}_A(\mathbf{q}_i) = \lambda_i\) (Check it!) and
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统的解是 \(A\) 的特征向量，即它们满足 \(A\mathbf{u} = \lambda \mathbf{u}\) 对于某个特征值 \(\lambda\)。如果
    \(\mathbf{q}_i\) 是 \(A\) 的单位特征向量，其特征值为 \(\lambda_i\)，那么我们有 \(\mathcal{R}_A(\mathbf{q}_i)
    = \lambda_i\)（检查一下！）并且
- en: \[ A \mathbf{q}_i = \mathcal{R}_A(\mathbf{q}_i) \,\mathbf{q}_i = \lambda_i \mathbf{q}_i.
    \]
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A \mathbf{q}_i = \mathcal{R}_A(\mathbf{q}_i) \,\mathbf{q}_i = \lambda_i \mathbf{q}_i.
    \]
- en: The eigenvectors of \(A\) are not in general local minimizers of its Rayleigh
    quotient. In fact one of them – the largest one – is a global maximizer! \(\lhd\)
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: \(A\) 的特征向量通常不是其雷利商的局部极小值。事实上，其中之一——最大的一个——是全局最大值！\(\lhd\)
- en: 3.3.2\. Second-order conditions[#](#second-order-conditions "Link to this heading")
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.2\. 第二阶条件[#](#second-order-conditions "链接到这个标题")
- en: Local minimizers can also be characterized in terms of the Hessian.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 局部极小值也可以用Hessian来描述。
- en: We will make use of *Taylor’s Theorem*, a generalization of the *Mean Value
    Theorem* that provides polynomial approximations to a function around a point.
    We restrict ourselves to the case of a linear approximation with second-order
    error term, which will suffice for our purposes.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用*泰勒定理*，这是*平均值定理*的推广，它提供了函数在一点的多项式近似。我们限制自己使用带有二阶误差项的线性近似，这对于我们的目的足够了。
- en: '**Taylor’s theorem** We begin by reviewing the single-variable case, which
    we will use to prove the general verison.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '**泰勒定理**: 我们首先回顾单变量情况，我们将用它来证明一般形式。'
- en: '**THEOREM** **(Taylor)** \(\idx{Taylor''s theorem}\xdi\) Let \(f: D \to \mathbb{R}\)
    where \(D \subseteq \mathbb{R}\). Suppose \(f\) has a continuous derivative on
    \([a,b]\) and that its second derivative exists on \((a,b)\). Then for any \(x
    \in [a, b]\)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(泰勒)** \(\idx{泰勒定理}\xdi\) 设 \(f: D \to \mathbb{R}\) 其中 \(D \subseteq
    \mathbb{R}\). 假设 \(f\) 在 \([a,b]\) 上具有连续的导数，并且其二阶导数在 \((a,b)\) 上存在。那么对于任何 \(x
    \in [a, b]\)'
- en: \[ f(x) = f(a) + (x-a) f'(a) + \frac{1}{2} (x-a)^2 f''(\xi) \]
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = f(a) + (x-a) f'(a) + \frac{1}{2} (x-a)^2 f''(\xi) \]
- en: for some \(a < \xi < x\). \(\sharp\)
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(a < \xi < x\). \(\sharp\)
- en: The third term on the right-hand side of *Taylor’s Theorem* is called the Lagrange
    remainder. It can be seen as an error term between \(f(x)\) and the linear approximation
    \(f(a) + (x-a) f'(a)\). There are [other forms](https://en.wikipedia.org/wiki/Taylor%27s_theorem#Explicit_formulas_for_the_remainder)
    for the remainder. The form we stated here is useful when one has a bound on the
    second derivative. Here is an example.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 泰勒定理右侧的第三项称为拉格朗日余项。它可以看作是 \(f(x)\) 和线性近似 \(f(a) + (x-a) f'(a)\) 之间的误差项。余项有 [其他形式](https://en.wikipedia.org/wiki/Taylor%27s_theorem#Explicit_formulas_for_the_remainder)。我们这里陈述的形式在二阶导数有界时很有用。这里有一个例子。
- en: '**NUMERICAL CORNER:** Consider \(f(x) = e^x\). Then \(f''(x) = f''''(x) = e^x\).
    Suppose we are interested in approximating \(f\) in the interval \([0,1]\). We
    take \(a=0\) and \(b=1\) in *Taylor’s Theorem*. The linear term is'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 考虑 \(f(x) = e^x\). 然后 \(f''(x) = f''''(x) = e^x\). 假设我们感兴趣的是在区间 \([0,1]\)
    上逼近 \(f\). 我们在 *泰勒定理* 中取 \(a=0\) 和 \(b=1\). 线性项是'
- en: \[ f(a) + (x-a) f'(a) = 1 + x e^0 = 1 + x. \]
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(a) + (x-a) f'(a) = 1 + x e^0 = 1 + x. \]
- en: Then for any \(x \in [0,1]\)
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于任何 \(x \in [0,1]\)
- en: \[ f(x) = 1 + x + \frac{1}{2}x^2 e^{\xi_x} \]
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x) = 1 + x + \frac{1}{2}x^2 e^{\xi_x} \]
- en: where \(\xi_x \in (0,1)\) depends on \(x\). We get a uniform bound on the error
    over \([0,1]\) by replacing \(\xi_x\) with its worst possible value over \([0,1]\)
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\xi_x \in (0,1)\) 依赖于 \(x\)。通过将 \(\xi_x\) 替换为其在 \([0,1]\) 上的最坏可能值，我们得到对误差在
    \([0,1]\) 上的统一界限
- en: \[ |f(x) - (1+x)| \leq \frac{1}{2}x^2 e^{\xi_x} \leq \frac{e}{2} x^2. \]
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |f(x) - (1+x)| \leq \frac{1}{2}x^2 e^{\xi_x} \leq \frac{e}{2} x^2. \]
- en: '[PRE5]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If we plot the upper and lower bounds, we see that \(f\) indeed falls within
    them.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制上界和下界，我们会看到 \(f\) 确实落在这个范围内。
- en: '[PRE6]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![../../_images/3679f4fd83bc012d44e92e99af6e84eb0f84c2d88f5be251891c9521ea8a7fc9.png](../Images/c339c626ad8f04a3c45b8a598e231b2a.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/3679f4fd83bc012d44e92e99af6e84eb0f84c2d88f5be251891c9521ea8a7fc9.png](../Images/c339c626ad8f04a3c45b8a598e231b2a.png)'
- en: \(\unlhd\)
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: In the case of several variables, we again restrict ourselves to the second
    order. For the more general version, see e.g. [Wikipedia](https://en.wikipedia.org/wiki/Taylor's_theorem#Taylor's_theorem_for_multivariate_functions).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个变量的情况下，我们再次将自身限制在二阶。对于更一般的形式，请参见例如 [维基百科](https://en.wikipedia.org/wiki/Taylor's_theorem#Taylor's_theorem_for_multivariate_functions)。
- en: '**THEOREM** **(Taylor)** \(\idx{Taylor''s theorem}\xdi\) Let \(f : D \to \mathbb{R}\)
    where \(D \subseteq \mathbb{R}^d\). Let \(\mathbf{x}_0 \in D\) and \(\delta >
    0\) be such that \(B_\delta(\mathbf{x}_0) \subseteq D\). If \(f\) is twice continuously
    differentiable on \(B_\delta(\mathbf{x}_0)\), then for any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(泰勒)** \(\idx{泰勒定理}\xdi\) 设 \(f : D \to \mathbb{R}\) 其中 \(D \subseteq
    \mathbb{R}^d\)。设 \(\mathbf{x}_0 \in D\) 和 \(\delta > 0\) 使得 \(B_\delta(\mathbf{x}_0)
    \subseteq D\)。如果 \(f\) 在 \(B_\delta(\mathbf{x}_0)\) 上是二阶连续可微的，那么对于任何 \(\mathbf{x}
    \in B_\delta(\mathbf{x}_0)\)'
- en: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
- en: for some \(\xi \in (0,1)\). \(\sharp\)
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\xi \in (0,1)\). \(\sharp\)
- en: As in the single-variable case, we think of \(f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T
    (\mathbf{x} - \mathbf{x}_0)\) for fixed \(\mathbf{x}_0\) as a linear – or more
    accurately affine – approximation to \(f\) at \(\mathbf{x}_0\). The third term
    on the right-hand side above quantifies the error of this approximation.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 与单变量情况一样，我们将 \(f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\)
    对于固定的 \(\mathbf{x}_0\) 视为 \(f\) 在 \(\mathbf{x}_0\) 处的线性近似——或者更准确地说，是仿射近似。上面右侧的第三项量化了这个近似的误差。
- en: '*Proof idea:* We apply the single-variable result to \(\phi(t) = f(\boldsymbol{\alpha}(t))\).
    We use the *Chain Rule* to compute the needed derivatives.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们将单变量结果应用于 \(\phi(t) = f(\boldsymbol{\alpha}(t))\)。我们使用*链式法则*来计算所需的导数。'
- en: '*Proof:* Let \(\mathbf{p} = \mathbf{x} - \mathbf{x}_0\) and \(\phi(t) = f(\boldsymbol{\alpha}(t))\)
    where \(\boldsymbol{\alpha}(t) = \mathbf{x}_0 + t \mathbf{p}\). Observe that \(\phi(0)
    = f(\mathbf{x}_0)\) and \(\phi(1) = f(\mathbf{x})\). As observed in the proof
    of the *Mean Value Theorem*, \(\phi''(t) = \nabla f(\boldsymbol{\alpha}(t))^T
    \mathbf{p}\). By the *Chain Rule* and our previous *Parametric Line Example*,'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 令 \(\mathbf{p} = \mathbf{x} - \mathbf{x}_0\) 和 \(\phi(t) = f(\boldsymbol{\alpha}(t))\)
    其中 \(\boldsymbol{\alpha}(t) = \mathbf{x}_0 + t \mathbf{p}\)。观察 \(\phi(0) = f(\mathbf{x}_0)\)
    和 \(\phi(1) = f(\mathbf{x})\)。正如在*平均值定理*的证明中所观察到的，\(\phi''(t) = \nabla f(\boldsymbol{\alpha}(t))^T
    \mathbf{p}\)。通过*链式法则*和我们的先前*参数线示例*，'
- en: \[\begin{align*} \phi''(t) &= \frac{\mathrm{d}}{\mathrm{d} t} \left[\sum_{i=1}^d
    \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i} p_i \right]\\ &= \sum_{i=1}^d
    \left(\nabla \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i}\right)^T
    \boldsymbol{\alpha}'(t) \,p_i \\ &= \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2
    f(\boldsymbol{\alpha}(t))}{\partial x_j \partial x_i} p_j p_i\\ &= \mathbf{p}^T
    \,\mathbf{H}_f(\mathbf{x}_0 + t \mathbf{p}) \,\mathbf{p}. \end{align*}\]
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \phi''(t) &= \frac{\mathrm{d}}{\mathrm{d} t} \left[\sum_{i=1}^d
    \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i} p_i \right]\\ &= \sum_{i=1}^d
    \left(\nabla \frac{\partial f(\boldsymbol{\alpha}(t))}{\partial x_i}\right)^T
    \boldsymbol{\alpha}'(t) \,p_i \\ &= \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2
    f(\boldsymbol{\alpha}(t))}{\partial x_j \partial x_i} p_j p_i\\ &= \mathbf{p}^T
    \,\mathbf{H}_f(\mathbf{x}_0 + t \mathbf{p}) \,\mathbf{p}. \end{align*}\]
- en: In particular, \(\phi\) has continuous first and second derivatives on \([0,1]\).
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，\(\phi\) 在 \([0,1]\) 上具有连续的一阶和二阶导数。
- en: By *Taylor’s Theorem* in the single-variable case
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在单变量情况下的*泰勒定理*
- en: \[ \phi(t) = \phi(0) + t \phi'(0) + \frac{1}{2} t^2 \phi''(\xi) \]
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi(t) = \phi(0) + t \phi'(0) + \frac{1}{2} t^2 \phi''(\xi) \]
- en: for some \(\xi \in (0,t)\). Plugging in the expressions for \(\phi(0)\), \(\phi'(0)\)
    and \(\phi''(\xi)\) and taking \(t=1\) gives the claim. \(\square\)
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 \(\xi \in (0,t)\)。将 \(\phi(0)\)，\(\phi'(0)\) 和 \(\phi''(\xi)\) 的表达式代入，并取
    \(t=1\)，得到所声称的。 \(\square\)
- en: '**EXAMPLE:** Consider the function \(f(x_1, x_2) = x_1 x_2 + x_1^2 + e^{x_1}
    \cos x_2\). We apply *Taylor’s Theorem* with \(\mathbf{x}_0 = (0, 0)\) and \(\mathbf{x}
    = (x_1, x_2)\). The gradient is'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**例题:** 考虑函数 \(f(x_1, x_2) = x_1 x_2 + x_1^2 + e^{x_1} \cos x_2\)。我们应用 \(\mathbf{x}_0
    = (0, 0)\) 和 \(\mathbf{x} = (x_1, x_2)\) 的*泰勒定理*。梯度是'
- en: \[ \nabla f(x_1, x_2) = (x_2 + 2 x_1 + e^{x_1} \cos x_2, x_1 - e^{x_1} \sin
    x_2 ) \]
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(x_1, x_2) = (x_2 + 2 x_1 + e^{x_1} \cos x_2, x_1 - e^{x_1} \sin
    x_2 ) \]
- en: and the Hessian is
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 和Hessian矩阵存在的情况下。
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 + e^{x_1} \cos x_2
    & 1 - e^{x_1} \sin x_2\\ 1 - e^{x_1} \sin x_2 & - e^{x_1} \cos x_2 \end{pmatrix}.
    \end{split}\]
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 + e^{x_1} \cos x_2
    & 1 - e^{x_1} \sin x_2\\ 1 - e^{x_1} \sin x_2 & - e^{x_1} \cos x_2 \end{pmatrix}.
    \end{split}\]
- en: So \(f(0,0) = 1\) and \(\nabla f(0,0) = (1, 0)\). Thus, by *Taylor’s Theorem*,
    there is \(\xi \in (0,1)\) such that
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(f(0,0) = 1\) 和 \(\nabla f(0,0) = (1, 0)\)。因此，根据*泰勒定理*，存在 \(\xi \in (0,1)\)
    使得
- en: \[ f(x_1, x_2) = 1 + x_1 + \frac{1}{2}[2 x_1^2 + 2 x_1 x_2 + (x_1^2 - x_2^2)
    \,e^{\xi x_1} \cos(\xi x_2) - 2 x_1 x_2 e^{\xi x_1} \sin(\xi x_2)]. \]
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(x_1, x_2) = 1 + x_1 + \frac{1}{2}[2 x_1^2 + 2 x_1 x_2 + (x_1^2 - x_2^2)
    \,e^{\xi x_1} \cos(\xi x_2) - 2 x_1 x_2 e^{\xi x_1} \sin(\xi x_2)]. \]
- en: \(\lhd\)
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**Second directional derivative** To control the error term in *Taylor’s Theorem*,
    it will be convenient to introduce a notion of second directional derivative.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二个方向导数** 为了控制*泰勒定理*中的误差项，引入第二个方向导数的概念将是有用的。'
- en: '**DEFINITION** **(Second Directional Derivative)** \(\idx{second directional
    derivative}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq \mathbb{R}^d\),
    let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let \(\mathbf{v}
    \in \mathbb{R}^d\) be a nonzero vector. The second directional derivative of \(f\)
    at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(第二个方向导数)** \(\idx{second directional derivative}\xdi\) 设 \(f : D
    \to \mathbb{R}\) 其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0 \in D\) 是 \(D\)
    的一个内点，设 \(\mathbf{v} \in \mathbb{R}^d\) 是一个非零向量。\(f\) 在 \(\mathbf{x}_0\) 处沿 \(\mathbf{v}\)
    方向的第二个方向导数是'
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \lim_{h \to 0}
    \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial \mathbf{v}}
    - \frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}\right] \]
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \lim_{h \to 0}
    \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial \mathbf{v}}
    - \frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}\right] \]
- en: provided the limit exists. \(\natural\)
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: Typically, \(\mathbf{v}\) is a unit vector.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，\(\mathbf{v}\) 是一个单位向量。
- en: '**THEOREM** **(Second Directional Derivative and Hessian)** \(\idx{second directional
    derivative and Hessian theorem}\xdi\) Let \(f : D \to \mathbb{R}\) where \(D \subseteq
    \mathbb{R}^d\), let \(\mathbf{x}_0 \in D\) be an interior point of \(D\) and let
    \(\mathbf{v} \in \mathbb{R}^d\) be a vector. Assume that \(f\) is twice continuously
    differentiable at \(\mathbf{x}_0\). Then the second directional derivative of
    \(f\) at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is given by'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶方向导数和海森矩阵)** \(\idx{second directional derivative and Hessian theorem}\xdi\)
    设 \(f : D \to \mathbb{R}\) 其中 \(D \subseteq \mathbb{R}^d\)，设 \(\mathbf{x}_0 \in
    D\) 是 \(D\) 的一个内点，设 \(\mathbf{v} \in \mathbb{R}^d\) 是一个向量。假设 \(f\) 在 \(\mathbf{x}_0\)
    处是二阶连续可微的。那么 \(f\) 在 \(\mathbf{x}_0\) 处沿 \(\mathbf{v}\) 方向的二阶方向导数由下式给出'
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T
    H_f(\mathbf{x}_0) \,\mathbf{v}. \]
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T
    H_f(\mathbf{x}_0) \,\mathbf{v}. \]
- en: \(\sharp\)
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: Note the similarity to the quadratic term in *Taylor’s Theorem*.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这与**泰勒定理**中的二次项的相似性。
- en: '*Proof idea:* We have already done this calculation in the proof of *Taylor’s
    Theorem*.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明思路：** 我们已经在**泰勒定理**的证明中完成了这个计算。'
- en: '*Proof:* Then, by definition of the derivative,'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明：** 然后，根据导数的定义，'
- en: \[\begin{align*} \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0
    + h \mathbf{v})}{\partial \mathbf{v}} - \frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}}\right] &= \lim_{h \to 0} \frac{1}{h} \left[\nabla f(\mathbf{x}_0 +
    h \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\right]\\ &= \lim_{h
    \to 0} \frac{1}{h} \sum_{i=1}^n v_i \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}}, \end{align*}\]
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0
    + h \mathbf{v})}{\partial \mathbf{v}} - \frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}}\right] &= \lim_{h \to 0} \frac{1}{h} \left[\nabla f(\mathbf{x}_0 +
    h \mathbf{v})^T \mathbf{v} - \nabla f(\mathbf{x}_0)^T \mathbf{v}\right]\\ &= \lim_{h
    \to 0} \frac{1}{h} \sum_{i=1}^n v_i \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \lim_{h \to 0} \frac{1}{h} \left[\frac{\partial f(\mathbf{x}_0 + h \mathbf{v})}{\partial
    x_i} - \frac{\partial f(\mathbf{x}_0)}{\partial x_i} \right]\\ &= \sum_{i=1}^n
    v_i \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}}, \end{align*}\]
- en: where \(g_i(\mathbf{x}_0) = \frac{\partial f(\mathbf{x}_0)}{\partial x_i}\).
    So
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(g_i(\mathbf{x}_0) = \frac{\partial f(\mathbf{x}_0)}{\partial x_i}\)。因此
- en: \[ \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla g_i(\mathbf{x}_0)^T
    \mathbf{v} = \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial
    x_j} \]
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial g_i (\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla g_i(\mathbf{x}_0)^T
    \mathbf{v} = \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial
    x_j} \]
- en: by the *Directional Derivative and Gradient Theorem*. Plugging back above we
    get
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**方向导数和梯度定理**。将上述内容代入，我们得到
- en: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \sum_{i=1}^n
    v_i \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial x_j}
    = \mathbf{v}^T H_f(\mathbf{x}_0) \,\mathbf{v}. \]
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f (\mathbf{x}_0)}{\partial \mathbf{v}^2} = \sum_{i=1}^n
    v_i \sum_{j=1}^n v_j \frac{\partial^2 f(\mathbf{x}_0)}{\partial x_i\partial x_j}
    = \mathbf{v}^T H_f(\mathbf{x}_0) \,\mathbf{v}. \]
- en: \(\square\)
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: So going back to *Taylor’s Theorem*
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，回到**泰勒定理**
- en: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} -
    \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \,\mathbf{H}_f(\mathbf{x}_0
    + \xi (\mathbf{x} - \mathbf{x}_0)) \,(\mathbf{x} - \mathbf{x}_0), \]
- en: we see that the second term on the right-hand side is the directional derivative
    at \(\mathbf{x}_0\) in the direction \(\mathbf{x} - \mathbf{x}_0\) and that the
    third term is half of the second directional derivative at \(\mathbf{x}_0 + \xi
    (\mathbf{x} - \mathbf{x}_0)\) in the same direction.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到等式右侧的第二项是 \(\mathbf{x}_0\) 点沿 \(\mathbf{x} - \mathbf{x}_0\) 方向的方向导数，而第三项是
    \(\mathbf{x}_0 + \xi (\mathbf{x} - \mathbf{x}_0)\) 点沿相同方向的第二方向导数的一半。
- en: '**Necessary condition** When \(f\) is twice continuously differentiable, we
    get a necessary condition based on the Hessian.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '**必要条件** 当 \(f\) 是二阶连续可微时，我们根据海森矩阵得到一个必要条件。'
- en: '**THEOREM** **(Second-Order Necessary Optimality Condition)** \(\idx{second-order
    necessary optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be twice continuously differentiable on \(\mathbb{R}^d\). If \(\mathbf{x}_0\)
    is a local minimizer, then \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\)
    is positive semidefinite. \(\sharp\)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶必要最优性条件)** **(second-order necessary optimality condition)** \(\idx{second-order
    necessary optimality condition}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在
    \(\mathbb{R}^d\) 上是两次连续可微的。如果 \(\mathbf{x}_0\) 是局部极小值点，那么 \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正半定的。 \(\sharp\)'
- en: '*Proof idea:* By *Taylor’s Theorem* and the *First-Order Necessary Optimality
    Condition*,'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 通过 *泰勒定理* 和 *一阶必要最优性条件*，'
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}.
    \end{align*}\]
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}.
    \end{align*}\]
- en: 'If \(\mathbf{H}_f\) is positive semidefinite in a neighborhood around \(\mathbf{x}_0\),
    then the second term on the right-hand side is nonnegative, which is necessary
    for \(\mathbf{x}_0\) to be a local minimizer. Formally we argue by contradiction:
    indeed, if \(\mathbf{H}_f\) is not positive semidefinite, then there must exists
    a direction in which the second directional derivative is negative; since the
    gradient is \(\mathbf{0}\) at \(\mathbf{x}_0\), intuitively the directional derivative
    must become negative in that direction as well and the function must decrease.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在 \(\mathbf{x}_0\) 附近的邻域内 \(\mathbf{H}_f\) 是正半定的，那么右侧的第二项是非负的，这对于 \(\mathbf{x}_0\)
    成为局部极小值点是必要的。形式上，我们通过反证法来论证：确实，如果 \(\mathbf{H}_f\) 不是正半定的，那么必须存在一个方向，在该方向上二阶方向导数是负的；由于梯度在
    \(\mathbf{x}_0\) 处是 \(\mathbf{0}\)，直观上，在该方向上的方向导数也必须变为负，并且函数必须减小。
- en: '*Proof:* We argue by contradiction. Suppose that \(\mathbf{H}_f(\mathbf{x}_0)\)
    is not positive semidefinite. By definition, there must be a unit vector \(\mathbf{v}\)
    such that'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 我们通过反证法来论证。假设 \(\mathbf{H}_f(\mathbf{x}_0)\) 不是正半定的。根据定义，必须存在一个单位向量 \(\mathbf{v}\)
    使得'
- en: \[ \langle \mathbf{v}, \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \rangle = - \eta
    < 0. \]
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{v}, \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \rangle = - \eta
    < 0. \]
- en: That is, \(\mathbf{v}\) is a direction in which the second directional derivative
    is negative.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 \(\mathbf{v}\) 是一个二阶方向导数为负的方向。
- en: For \(\alpha > 0\), *Taylor’s Theorem* implies that there is \(\xi_\alpha \in
    (0,1)\) such that
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\alpha > 0\)，*泰勒定理* 意味着存在 \(\xi_\alpha \in (0,1)\)，
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2} (\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}
    \alpha^2 \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}
    \end{align*}\]
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2} (\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}
    \alpha^2 \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}
    \end{align*}\]
- en: where we used \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) by the *First-Order Necessary
    Optimality Condition*. We want to show that the second term on the right-hand
    side is negative.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了由 *一阶必要最优性条件* 得出的 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。我们想要证明右侧的第二项是负的。
- en: The Hessian is continuous (in the sense that all its entries are continuous
    functions of \(\mathbf{x}\)). In particular, the second directional derivative
    \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v}\) is continuous as a linear
    combination of continuous functions. So, by definition of continuity, for any
    \(\epsilon > 0\) – say \(\epsilon = \eta/2\) – there is \(\delta > 0\) small enough
    that
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 赫essian 矩阵是连续的（在所有项都是 \(\mathbf{x}\) 的连续函数的意义上）。特别是，二阶方向导数 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x})
    \,\mathbf{v}\) 作为连续函数的线性组合是连续的。因此，根据连续性的定义，对于任何 \(\epsilon > 0\) ——比如说 \(\epsilon
    = \eta/2\) ——存在一个足够小的 \(\delta > 0\)，使得
- en: \[\begin{align*} \left| \mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v} -
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \right| &< \eta/2 \end{align*}\]
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left| \mathbf{v}^T \mathbf{H}_f(\mathbf{x}) \,\mathbf{v} -
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} \right| &< \eta/2 \end{align*}\]
- en: for all \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\).
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)。
- en: Take \(\alpha^* > 0\) small enough that \(\mathbf{x}_0 + \alpha^* \mathbf{v}
    \in B_\delta(\mathbf{x}_0)\). Then, for all \(\alpha \in (0,\alpha^*)\), whatever
    \(\xi_\alpha \in (0,1)\) is, it holds that \(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v} \in B_\delta(\mathbf{x}_0)\). Hence,
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\alpha^* > 0\) 足够小，使得 \(\mathbf{x}_0 + \alpha^* \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。然后，对于所有
    \(\alpha \in (0,\alpha^*)\)，无论 \(\xi_\alpha \in (0,1)\) 是什么，都有 \(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v} \in B_\delta(\mathbf{x}_0)\)。因此，
- en: \[\begin{align*} \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v}) \,\mathbf{v} &= \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}
    + (\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v}
    - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} )\\ &\leq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} + |\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}|\\ &< -\eta + \eta/2\\ &< - \eta/2 < 0. \end{align*}\]
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha
    \mathbf{v}) \,\mathbf{v} &= \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}
    + (\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v}
    - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} )\\ &\leq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} + |\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}|\\ &< -\eta + \eta/2\\ &< - \eta/2 < 0. \end{align*}\]
- en: by definition of \(\eta\). That implies
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，\(\eta\)。这表明
- en: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha^2 \eta/4 <
    f(\mathbf{x}_0). \]
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}_0 + \alpha \mathbf{v}) < f(\mathbf{x}_0) - \alpha^2 \eta/4 <
    f(\mathbf{x}_0). \]
- en: Since this holds for all sufficiently small \(\alpha\), every open ball around
    \(\mathbf{x}_0\) has a point achieving a lower value than \(f(\mathbf{x}_0)\).
    Thus \(\mathbf{x}_0\) is not a local minimizer, a contradiction. So it must be
    that \(\mathbf{H}_f(\mathbf{x}_0) \succeq \mathbf{0}\). \(\square\)
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这对所有足够小的 \(\alpha\) 都成立，\(\mathbf{x}_0\) 附近的每一个开球都有一个点比 \(f(\mathbf{x}_0)\)
    的值更低。因此，\(\mathbf{x}_0\) 不是一个局部极小值点，这与假设矛盾。因此，必须有 \(\mathbf{H}_f(\mathbf{x}_0)
    \succeq \mathbf{0}\)。 \(\square\)
- en: '**Sufficient condition** The necessary condition above is not in general sufficient,
    as the following example shows.'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '**充分条件** 上述必要条件在一般情况下并不充分，如下例所示。'
- en: '**NUMERICAL CORNER:** Let \(f(x) = x^3\). Then \(f''(x) = 3 x^2\) and \(f''''(x)
    = 6 x\) so that \(f''(0) = 0\) and \(f''''(0) \geq 0\). Hence \(x=0\) is a stationary
    point. But \(x=0\) is not a local minimizer. Indeed \(f(0) = 0\) but, for any
    \(\delta > 0\), \(f(-\delta) < 0\).'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**：设 \(f(x) = x^3\)。那么 \(f''(x) = 3 x^2\) 和 \(f''''(x) = 6 x\)，所以 \(f''(0)
    = 0\) 和 \(f''''(0) \geq 0\)。因此 \(x=0\) 是一个驻点。但 \(x=0\) 不是一个局部极小值点。实际上 \(f(0) =
    0\)，但对于任何 \(\delta > 0\)，\(f(-\delta) < 0\)。'
- en: '[PRE7]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![../../_images/2124857c662385a175abf776e89126ff842e450579382110f506759f09254a95.png](../Images/4a1cd8247ab18de84607516e9c6f7863.png)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/2124857c662385a175abf776e89126ff842e450579382110f506759f09254a95.png](../Images/4a1cd8247ab18de84607516e9c6f7863.png)'
- en: \(\unlhd\)
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: We give sufficient conditions for a point to be a local minimizer.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给出了一个点成为局部极小值的充分条件。
- en: '**THEOREM** **(Second-Order Sufficient Optimality Condition)** \(\idx{second-order
    sufficient optimality condition}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\)
    be twice continuously differentiable on \(\mathbb{R}^d\). If \(\nabla f(\mathbf{x}_0)
    = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\) is positive definite, then \(\mathbf{x}_0\)
    is a strict local minimizer. \(\sharp\)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(二阶充分最优性条件)** \(\idx{second-order sufficient optimality condition}\xdi\)
    设 \(f : \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbb{R}^d\) 上是二阶连续可微的。如果 \(\nabla
    f(\mathbf{x}_0) = \mathbf{0}\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\)
    是一个严格局部极小值点。 \(\sharp\)'
- en: '*Proof idea:* We use *Taylor’s Theorem* again. This time we use the positive
    definiteness of the Hessian to bound the value of the function from below.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路* 我们再次使用 *泰勒定理*。这次我们使用Hessian的正定性来从下限约束函数的值。'
- en: We will need a lemma.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要一条引理。
- en: '**LEMMA** **(Quadratic Form and Frobenius Norm)** \(\idx{quadratic form and
    Frobenius norm lemma}\xdi\) Let \(A = (a_{i,j})_{i,j}\) and \(B = (b_{i,j})_{i,j}\)
    be matrices in \(\mathbb{R}^{n \times m}\). For any unit vectors \(\mathbf{u}
    \in \mathbb{R}^n\) and \(\mathbf{v} \in \mathbb{R}^m\)'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(二次型和Frobenius范数)** \(\idx{quadratic form and Frobenius norm lemma}\xdi\)
    设 \(A = (a_{i,j})_{i,j}\) 和 \(B = (b_{i,j})_{i,j}\) 是 \(\mathbb{R}^{n \times m}\)
    中的矩阵。对于任意的单位向量 \(\mathbf{u} \in \mathbb{R}^n\) 和 \(\mathbf{v} \in \mathbb{R}^m\)'
- en: \[ \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v} \right|
    \leq \|A - B\|_F. \]
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v} \right|
    \leq \|A - B\|_F. \]
- en: \(\flat\)
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof:* By the *Cauchy-Schwarz inequality*,'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明* 通过 *柯西-施瓦茨不等式*，'
- en: \[\begin{align*} \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v}
    \right| &= \left| \sum_{i=1}^n \sum_{j=1}^m u_i v_j (a_{i,j} - b_{i,j}) \right|\\
    &\leq \sqrt{\sum_{i=1}^n \sum_{j=1}^m u_i^2 v_j^2} \sqrt{\sum_{i=1}^n \sum_{j=1}^m
    (a_{i,j} - b_{i,j})^2}\\ &= \|A - B\|_F, \end{align*}\]
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \left| \mathbf{u}^T A \,\mathbf{v} - \mathbf{u}^T B \,\mathbf{v}
    \right| &= \left| \sum_{i=1}^n \sum_{j=1}^m u_i v_j (a_{i,j} - b_{i,j}) \right|\\
    &\leq \sqrt{\sum_{i=1}^n \sum_{j=1}^m u_i^2 v_j^2} \sqrt{\sum_{i=1}^n \sum_{j=1}^m
    (a_{i,j} - b_{i,j})^2}\\ &= \|A - B\|_F, \end{align*}\]
- en: where we used that \(\mathbf{u}\) and \(\mathbf{v}\) have unit norm on the last
    line. \(\square\)
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了在最后一行 \(\mathbf{u}\) 和 \(\mathbf{v}\) 具有单位范数。 \(\square\)
- en: '*Proof:* *(Second-Order Sufficient Optimality Condition)* By *Taylor’s Theorem*,
    for all unit vectors \(\mathbf{v} \in \mathbb{R}^d\) and \(\alpha \in \mathbb{R}\),
    there is \(\xi_{\alpha} \in (0,1)\) such that'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* *(二阶充分优化条件)* 通过 *泰勒定理*，对于所有单位向量 \(\mathbf{v} \in \mathbb{R}^d\) 和 \(\alpha
    \in \mathbb{R}\)，存在 \(\xi_{\alpha} \in (0,1)\) 使得'
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v},
    \end{align*}\]
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \nabla
    f(\mathbf{x}_0)^T(\alpha \mathbf{v}) + \frac{1}{2}(\alpha \mathbf{v})^T \mathbf{H}_f(\mathbf{x}_0
    + \xi_\alpha \alpha \mathbf{v}) (\alpha \mathbf{v})\\ &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v},
    \end{align*}\]
- en: where we used that \(\nabla f(\mathbf{x}_0) = \mathbf{0}\). The second term
    on the last line is \(0\) at \(\mathbf{v} = \mathbf{0}\). Our goal is to show
    that it is strictly positive (except at \(\mathbf{0}\)) in a neighborhood of \(\mathbf{0}\).
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们使用了 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\)。最后一行的第二个项在 \(\mathbf{v} = \mathbf{0}\)
    时为 \(0\)。我们的目标是证明它在 \(\mathbf{0}\) 的邻域内严格为正（除了在 \(\mathbf{0}\) 处）。
- en: The set \(\mathbb{S}^{d-1}\) of unit vectors in \(\mathbb{R}^d\) is closed and
    bounded. The expression \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v}\),
    viewed as a function of \(\mathbf{v}\), is continuous since it is a polynomial.
    Hence, by the *Extreme Value Theorem*, it attains its minimum on \(\mathbb{S}^{d-1}\).
    By our assumption that \(\mathbf{H}_f(\mathbf{x}_0)\) is positive definite, that
    minimum must be strictly positive, say \(\mu > 0\).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: \(\mathbb{R}^d\) 中的单位向量集合 \(\mathbb{S}^{d-1}\) 是闭集且有界。表达式 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \,\mathbf{v}\)，作为 \(\mathbf{v}\) 的函数，是连续的，因为它是一个多项式。因此，根据 *极值定理*，它在 \(\mathbb{S}^{d-1}\)
    上达到其最小值。根据我们假设 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，这个最小值必须是严格正的，比如说 \(\mu > 0\)。
- en: By the *Quadratic Form and Frobenius Norm Lemma* (ignoring the absolute value),
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 根据二次型和 Frobenius 范数引理（忽略绝对值），
- en: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\,\mathbf{v} \leq \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F. \]
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\,\mathbf{v} \leq \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F. \]
- en: The Frobenius norm above is continuous in \(\mathbf{w}\) as a composition of
    continuous functions. Moreover, we have at \(\mathbf{w} = \mathbf{0}\) that this
    Frobenius norm is \(0\). Hence, by definition of continuity, for any \(\epsilon
    > 0\) – say \(\epsilon := \mu/2\) – there is \(\delta > 0\) such that \(\mathbf{w}
    \in B_{\delta}(\mathbf{0})\) implies \(\|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F < \epsilon = \mu/2\).
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的 Frobenius 范数作为连续函数的复合是关于 \(\mathbf{w}\) 连续的。此外，当 \(\mathbf{w} = \mathbf{0}\)
    时，这个 Frobenius 范数为 \(0\)。因此，根据连续性的定义，对于任何 \(\epsilon > 0\) – 比如说 \(\epsilon :=
    \mu/2\) – 存在 \(\delta > 0\)，使得 \(\mathbf{w} \in B_{\delta}(\mathbf{0})\) 意味着 \(\|\mathbf{H}_f(\mathbf{x}_0)
    - \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\|_F < \epsilon = \mu/2\)。
- en: Since \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} > \mu\), the inequality
    in the previous display implies that
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} > \mu\)，上述不等式意味着
- en: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\,\mathbf{v} \geq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F > \frac{\mu}{2}. \]
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \mathbf{w})\,\mathbf{v} \geq \mathbf{v}^T
    \mathbf{H}_f(\mathbf{x}_0) \,\mathbf{v} - \|\mathbf{H}_f(\mathbf{x}_0) - \mathbf{H}_f(\mathbf{x}_0
    + \mathbf{w})\|_F > \frac{\mu}{2}. \]
- en: This holds for any unit vector \(\mathbf{v}\) and any \(\mathbf{w} \in B_{\delta}(\mathbf{0})\).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于任何单位向量 \(\mathbf{v}\) 和任何 \(\mathbf{w} \in B_{\delta}(\mathbf{0})\) 都成立。
- en: Going back to our Taylor expansion, for \(\alpha > 0\) small enough (not depending
    on \(\mathbf{v}\); why?), it holds that \(\mathbf{w} = \xi_\alpha \alpha \mathbf{v}
    \in B_{\delta}(\mathbf{0})\) so that we get from the previous inequality
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的泰勒展开，对于足够小的 \(\alpha > 0\)（不依赖于 \(\mathbf{v}\)；为什么？），有 \(\mathbf{w} = \xi_\alpha
    \alpha \mathbf{v} \in B_{\delta}(\mathbf{0})\)，因此我们可以从前面的不等式得到
- en: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}\\
    &> f(\mathbf{x}_0) + \frac{1}{4} \alpha^2 \mu \\ &> f(\mathbf{x}_0). \end{align*}\]
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} f(\mathbf{x}_0 + \alpha \mathbf{v}) &= f(\mathbf{x}_0) + \frac{1}{2}\alpha^2
    \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0 + \xi_\alpha \alpha \mathbf{v})\,\mathbf{v}\\
    &> f(\mathbf{x}_0) + \frac{1}{4} \alpha^2 \mu \\ &> f(\mathbf{x}_0). \end{align*}\]
- en: Therefore \(\mathbf{x}_0\) is a strict local minimizer. \(\square\)
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(\mathbf{x}_0\) 是一个严格局部极小值点。\(\square\)
- en: 3.3.3\. Adding equality constraints[#](#adding-equality-constraints "Link to
    this heading")
  id: totrans-481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3.3\. 添加等式约束[#](#adding-equality-constraints "链接到本标题")
- en: Until now, we have considered *unconstrained* optimization problems, that is,
    the variable \(\mathbf{x}\) can take any value in \(\mathbb{R}^d\). However, it
    is common to impose conditions on \(\mathbf{x}\). Hence, we consider the *constrained*\(\idx{constrained
    optimization}\xdi\) minimization problem
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑了 *无约束* 最优化问题，即变量 \(\mathbf{x}\) 可以取 \(\mathbb{R}^d\) 中的任何值。然而，对 \(\mathbf{x}\)
    施加条件是很常见的。因此，我们考虑 *约束*\(\idx{约束优化}\xdi\) 最小化问题
- en: \[ \min_{\mathbf{x} \in \mathscr{X}} f(\mathbf{x}) \]
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\mathbf{x} \in \mathscr{X}} f(\mathbf{x}) \]
- en: where \(\mathscr{X} \subset \mathbb{R}^d\).
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathscr{X} \subset \mathbb{R}^d\)。
- en: '**EXAMPLE:** For instance, the entries of \(\mathbf{x}\) may have to satisfy
    certain bounds. In that case, we would have'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 例如，\(\mathbf{x}\) 的元素可能必须满足某些界限。在这种情况下，我们将有'
- en: \[ \mathscr{X} = \{\mathbf{x} = (x_1,\ldots,x_d) \in \mathbb{R}^d:x_i \in [a_i,
    b_i], \forall i\} \]
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathscr{X} = \{\mathbf{x} = (x_1,\ldots,x_d) \in \mathbb{R}^d:x_i \in [a_i,
    b_i], \forall i\} \]
- en: for some constants \(a_i < b_i\), \(i=1,\ldots,d\). \(\lhd\)
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些常数 \(a_i < b_i\)，\(i=1,\ldots,d\)。\(\lhd\)
- en: In this more general problem, the notion of global and local minimizer can be
    adapted straightforwardly. Note that, for simplicity, we will assume that \(f\)
    is defined over all of \(\mathbb{R}^d\). When \(\mathbf{x} \in \mathscr{X}\),
    it is said to be feasible.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个更一般的问题中，全局和局部极小值的概念可以简单地适应。注意，为了简单起见，我们将假设 \(f\) 在整个 \(\mathbb{R}^d\) 上定义。当
    \(\mathbf{x} \in \mathscr{X}\) 时，它被称为可行点。
- en: '**DEFINITION** **(Global minimizer)** \(\idx{global minimizer or maximizer}\xdi\)
    Let \(f : \mathbb{R}^d \to \mathbb{R}\). The point \(\mathbf{x}^* \in \mathscr{X}\)
    is a global minimizer of \(f\) over \(\mathscr{X}\) if'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（全局极小值点）** \(\idx{全局极小值点或极大值点}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)。如果
    \(\mathbf{x}^* \in \mathscr{X}\) 是 \(f\) 在 \(\mathscr{X}\) 上的全局极小值点，'
- en: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in \mathscr{X}.
    \]
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in \mathscr{X}.
    \]
- en: \(\natural\)
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: '**DEFINITION** **(Local minimizer)** \(\idx{local minimizer or maximizer}\xdi\)
    Let \(f : \mathbb{R}^d \to \mathbb{R}\). The point \(\mathbf{x}^* \in \mathscr{X}\)
    is a local minimizer of \(f\) over \(\mathscr{X}\) if there is \(\delta > 0\)
    such that'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（局部极小值点）** \(\idx{局部极小值点或极大值点}\xdi\) 设 \(f : \mathbb{R}^d \to \mathbb{R}\)。如果存在
    \(\delta > 0\)，使得 \(\mathbf{x}^* \in \mathscr{X}\) 是 \(f\) 在 \(\mathscr{X}\) 上的局部极小值点。'
- en: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in (B_{\delta}(\mathbf{x}^*)
    \setminus \{\mathbf{x}^*\}) \cap \mathscr{X}. \]
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) \geq f(\mathbf{x}^*), \quad \forall \mathbf{x} \in (B_{\delta}(\mathbf{x}^*)
    \setminus \{\mathbf{x}^*\}) \cap \mathscr{X}. \]
- en: If the inequality is strict, we say that \(\mathbf{x}^*\) is a strict local
    minimizer. \(\natural\)
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不等式是严格的，我们说 \(\mathbf{x}^*\) 是一个严格局部极小值点。\(\natural\)
- en: 'In this subsection, we restrict ourselves to one important class of constraints:
    equality constraints. That is, we consider the minimization problem'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们限制自己考虑一类重要的约束：等式约束。也就是说，我们考虑最小化问题
- en: \[\begin{align*} &\text{min} f(\mathbf{x})\\ &\text{s.t.}\ h_i(\mathbf{x}) =
    0,\ \forall i \in [\ell] \end{align*}\]
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\text{min} f(\mathbf{x})\\ &\text{s.t.}\ h_i(\mathbf{x}) =
    0,\ \forall i \in [\ell] \end{align*}\]
- en: 'where s.t. stands for “subject to”. In other words, we only allow those \(\mathbf{x}''s\)
    such that \(h_i(\mathbf{x}) = 0\) for all \(i\). Here \(f : \mathbb{R}^d \to \mathbb{R}\)
    and \(h_i : \mathbb{R}^d \to \mathbb{R}\), \(i\in [\ell]\). We will sometimes
    use the notation \(\mathbf{h} : \mathbb{R}^d \to \mathbb{R}^\ell\), where \(\mathbf{h}(\mathbf{x})
    = (h_1(\mathbf{x}), \ldots, h_\ell(\mathbf{x}))\).'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 s.t. 表示“受限于”。换句话说，我们只允许那些 \(\mathbf{x}''s\) 满足 \(h_i(\mathbf{x}) = 0\) 对于所有
    \(i\)。这里 \(f : \mathbb{R}^d \to \mathbb{R}\) 和 \(h_i : \mathbb{R}^d \to \mathbb{R}\)，\(i\in
    [\ell]\)。我们有时会使用符号 \(\mathbf{h} : \mathbb{R}^d \to \mathbb{R}^\ell\)，其中 \(\mathbf{h}(\mathbf{x})
    = (h_1(\mathbf{x}), \ldots, h_\ell(\mathbf{x}))\).'
- en: '**EXAMPLE:** If we want to minimize \(2 x_1^2 + 3 x_2^2\) over all two-dimensional
    unit vectors \(\mathbf{x} = (x_1, x_2)\), then we can let'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：如果我们想要在所有二维单位向量 \(\mathbf{x} = (x_1, x_2)\) 上最小化 \(2 x_1^2 + 3 x_2^2\)，那么我们可以设'
- en: \[ f(\mathbf{x}) = 2 x_1^2 + 3 x_2^2 \]
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = 2 x_1^2 + 3 x_2^2 \]
- en: and
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ h_1(\mathbf{x}) = 1 - x_1^2 - x_2^2 = 1 - \|\mathbf{x}\|^2. \]
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(\mathbf{x}) = 1 - x_1^2 - x_2^2 = 1 - \|\mathbf{x}\|^2. \]
- en: Observe that we could have chosen a different equality constraint to express
    the same minimization problem. \(\lhd\)
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们可以选择不同的等式约束来表达相同的极小化问题。\(\lhd\)
- en: The following theorem generalizes the *First-Order Necessary Optimality Condition*.
    The proof is omitted.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 以下定理推广了**一阶必要最优性条件**。证明从略。
- en: '**THEOREM** **(Lagrange Multipliers)** \(\idx{Lagrange multipliers theorem}\xdi\)
    Assume \(f : \mathbb{R}^d \to \mathbb{R}\) and \(h_i : \mathbb{R}^d \to \mathbb{R}\),
    \(i\in [\ell]\), are continuously differentiable. Let \(\mathbf{x}^*\) be a local
    minimizer of \(f\) s.t. \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\). Assume further
    that the vectors \(\nabla h_i (\mathbf{x}^*)\), \(i \in [\ell]\), are linearly
    independent. Then there exists a unique vector'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(拉格朗日乘数)** \(\idx{Lagrange multipliers theorem}\xdi\) 假设 \(f : \mathbb{R}^d
    \to \mathbb{R}\) 和 \(h_i : \mathbb{R}^d \to \mathbb{R}\)，\(i\in [\ell]\)，是连续可微的。设
    \(\mathbf{x}^*\) 是 \(f\) 的局部极小值点，且满足 \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)。进一步假设向量
    \(\nabla h_i (\mathbf{x}^*)\)，\(i \in [\ell]\)，是线性无关的。那么存在一个唯一的向量'
- en: \[ \blambda^* = (\lambda_1^*, \ldots, \lambda_\ell^*) \]
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \blambda^* = (\lambda_1^*, \ldots, \lambda_\ell^*) \]
- en: satisfying
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 满足
- en: \[ \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}. \]
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}. \]
- en: \(\sharp\)
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: \(\sharp\)
- en: The quantities \(\lambda_1^*, \ldots, \lambda_\ell^*\) are called Lagrange multipliers\(\idx{Lagrange
    multipliers}\xdi\).
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 量 \(\lambda_1^*, \ldots, \lambda_\ell^*\) 被称为拉格朗日乘数\(\idx{Lagrange multipliers}\xdi\)。
- en: '**EXAMPLE:** **(continued)** Returning to the previous example,'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例** **(继续)** 回到之前的例子，'
- en: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2) \]
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2) \]
- en: and
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
- en: The conditions in the theorem read
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 定理中的条件如下
- en: \[\begin{align*} &4 x_1 - 2 \lambda_1 x_1 = 0\\ &6 x_2 - 2 \lambda_1 x_2 = 0.
    \end{align*}\]
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &4 x_1 - 2 \lambda_1 x_1 = 0\\ &6 x_2 - 2 \lambda_1 x_2 = 0.
    \end{align*}\]
- en: The constraint \(x_1^2 + x_2^2 = 1\) must also be satisfied. Observe that the
    linear independence condition is automatically satisfied since there is only one
    constraint.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 约束 \(x_1^2 + x_2^2 = 1\) 也必须满足。注意到线性无关条件自动满足，因为只有一个约束。
- en: There are several cases to consider.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种情况需要考虑。
- en: 1- If neither \(x_1\) nor \(x_2\) is \(0\), then the first equation gives \(\lambda_1
    = 2\) while the second one gives \(\lambda_1 = 3\). So that case cannot happen.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 如果 \(x_1\) 和 \(x_2\) 都不为 \(0\)，则第一个方程给出 \(\lambda_1 = 2\)，而第二个方程给出 \(\lambda_1
    = 3\)。所以这种情况不可能发生。
- en: 2- If \(x_1 = 0\), then \(x_2 = 1\) or \(x_2 = -1\) by the constraint and the
    second equation gives \(\lambda_1 = 3\) in either case.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 如果 \(x_1 = 0\)，则根据约束条件，\(x_2 = 1\) 或 \(x_2 = -1\)，并且第二个方程在两种情况下都给出 \(\lambda_1
    = 3\)。
- en: 3- If \(x_2 = 0\), then \(x_1 = 1\) or \(x_1 = -1\) by the constraint and the
    first equation gives \(\lambda_1 = 2\) in either case.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 3- 如果 \(x_2 = 0\)，则根据约束条件，\(x_1 = 1\) 或 \(x_1 = -1\)，并且第一个方程在两种情况下都给出 \(\lambda_1
    = 2\)。
- en: Does any of these last four solutions, i.e., \((x_1,x_2,\lambda_1) = (0,1,3)\),
    \((x_1,x_2,\lambda_1) = (0,-1,3)\), \((x_1,x_2,\lambda_1) = (1,0,2)\) and \((x_1,x_2,\lambda_1)
    = (-1,0,2)\), actually correspond to a local minimizer?
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 这些最后的四个解，即 \((x_1,x_2,\lambda_1) = (0,1,3)\)，\((x_1,x_2,\lambda_1) = (0,-1,3)\)，\((x_1,x_2,\lambda_1)
    = (1,0,2)\) 和 \((x_1,x_2,\lambda_1) = (-1,0,2)\)，实际上是否对应于一个局部最小值点？
- en: This problem can be solved manually. Indeed, replace \(x_2^2 = 1 - x_1^2\) into
    the objective function to obtain
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可以通过手工解决。实际上，将 \(x_2^2 = 1 - x_1^2\) 代入目标函数中，可以得到
- en: \[ 2 x_1^2 + 3(1 - x_1^2) = -x_1^2 + 3. \]
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 2 x_1^2 + 3(1 - x_1^2) = -x_1^2 + 3. \]
- en: This is minimized for the largest value that \(x_1^2\) can take, namely when
    \(x_1 = 1\) or \(x_1 = -1\). Indeed, we must have \(0 \leq x_1^2 \leq x_1^2 +
    x_2^2 = 1\). So both \((x_1, x_2) = (1,0)\) and \((x_1, x_2) = (-1,0)\) are global
    minimizers. A fortiori, they must be local minimizers.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(x_1^2\) 取最大值时，这个问题达到最小值，即当 \(x_1 = 1\) 或 \(x_1 = -1\) 时。实际上，我们必须有 \(0 \leq
    x_1^2 \leq x_1^2 + x_2^2 = 1\)。因此，\((x_1, x_2) = (1,0)\) 和 \((x_1, x_2) = (-1,0)\)
    都是全局最小值点。更不用说，它们必须是局部最小值点。
- en: What about \((x_1,x_2) = (0,1)\) and \((x_1,x_2) = (0,-1)\)? Arguing as above,
    they in fact correspond to global *maximizers* of the objective function. \(\lhd\)
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 \((x_1,x_2) = (0,1)\) 和 \((x_1,x_2) = (0,-1)\) 呢？按照上述方式进行论证，它们实际上对应于目标函数的全局**最大化者**。\(\lhd\)
- en: Assume \(\mathbf{x}\) is feasible, that is, \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\).
    We let
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 \(\mathbf{x}\) 是可行的，即 \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)。我们设
- en: \[ \mathscr{F}_{\mathbf{h}}(\mathbf{x}) = \left\{ \mathbf{v} \in \mathbb{R}^d
    \,:\, \nabla h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0},\ \forall i \in [\ell]
    \right\} \]
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathscr{F}_{\mathbf{h}}(\mathbf{x}) = \left\{ \mathbf{v} \in \mathbb{R}^d
    \,:\, \nabla h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0},\ \forall i \in [\ell]
    \right\} \]
- en: be the linear subspace of first-order feasible directions\(\idx{first-order
    feasible directions}\xdi\) at \(\mathbf{x}\). To explain the name, note that by
    a first-order Taylor expansion, if \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\)
    then it holds that
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 为 \(\mathbf{x}\) 处的一阶可行方向**一阶可行方向**的线性子空间。为了解释这个名称，请注意，通过一阶泰勒展开，如果 \(\mathbf{v}
    \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\)，则它满足
- en: \[ h_i(\mathbf{x} + \delta \mathbf{v}) \approx h_i(\mathbf{x}) + \delta \nabla
    h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0} \]
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_i(\mathbf{x} + \delta \mathbf{v}) \approx h_i(\mathbf{x}) + \delta \nabla
    h_i(\mathbf{x})^T \mathbf{v} = \mathbf{0} \]
- en: for all \(i\).
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(i\)。
- en: The theorem says that, if \(\mathbf{x}^*\) is a local minimizer, then the gradient
    of \(f\) is orthogonal to the set of first-order feasible directions at \(\mathbf{x}^*\).
    Indeed, any \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x}^*)\) satisfies
    by the theorem that
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 该定理表明，如果 \(\mathbf{x}^*\) 是一个局部最小值点，那么 \(f\) 的梯度与 \(\mathbf{x}^*\) 处的一阶可行方向集正交。确实，任何
    \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x}^*)\) 都满足定理中的条件，
- en: \[ \nabla f(\mathbf{x}^*)^T \mathbf{v} = \left(- \sum_{i=1}^\ell \lambda^*_i
    \nabla h_i(\mathbf{x}^*)\right)^T \mathbf{v} = - \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*)^T \mathbf{v} = 0. \]
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}^*)^T \mathbf{v} = \left(- \sum_{i=1}^\ell \lambda^*_i
    \nabla h_i(\mathbf{x}^*)\right)^T \mathbf{v} = - \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*)^T \mathbf{v} = 0. \]
- en: Intuitively, following a first-order feasible direction does not alter the objective
    function value up to second-order error
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，沿着一阶可行方向前进不会改变目标函数值，直到二阶误差
- en: \[ f(\mathbf{x}^* + \alpha \mathbf{v}) \approx f(\mathbf{x}^*) + \alpha \nabla
    f(\mathbf{x}^*)^T \mathbf{v} = f(\mathbf{x}^*). \]
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}^* + \alpha \mathbf{v}) \approx f(\mathbf{x}^*) + \alpha \nabla
    f(\mathbf{x}^*)^T \mathbf{v} = f(\mathbf{x}^*). \]
- en: '**NUMERICAL CORNER:** Returning to the previous example, the points satisfying
    \(h_1(\mathbf{x}) = 0\) sit on the circle of radius \(1\) around the origin. We
    have already seen that'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**：回到前面的例子，满足 \(h_1(\mathbf{x}) = 0\) 的点位于原点半径为 \(1\) 的圆上。我们已经看到，'
- en: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = \left( \frac{\partial h_1(\mathbf{x})}{\partial
    x_1}, \frac{\partial h_1(\mathbf{x})}{\partial x_2} \right) = (- 2 x_1, - 2 x_2).
    \]
- en: Here is code illustrating the theorem (with help from ChatGPT). We first compute
    the function \(h_1\) at a grid of points using [`numpy.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html).
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是说明该定理的代码（得益于 ChatGPT 的帮助）。我们首先使用 `numpy.meshgrid` 在一系列点处计算函数 \(h_1\)，[请参阅
    `numpy.meshgrid` 的文档](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html)。
- en: '[PRE8]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We use [`matplotlib.pyplot.contour`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html)
    to plot the constraint set as a [contour line](https://en.wikipedia.org/wiki/Contour_line)
    (for the constant value \(0\)) of \(h_1\). Gradients of \(h_1\) are plotted at
    a collection of `points` with the [`matplotlib.pyplot.quiver`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.quiver.html)
    function, which is used for plotting vectors as arrows. We see that the directions
    of first-order feasible directions are orthogonal to the arrows, and therefore
    are tangent to the constraint set.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `matplotlib.pyplot.contour` 来绘制约束集作为 \(h_1\) 的 [等高线](https://en.wikipedia.org/wiki/Contour_line)（对于常数值
    \(0\)）。使用 `matplotlib.pyplot.quiver` 函数绘制 \(h_1\) 的梯度，该函数用于绘制箭头表示的向量。我们看到一阶可行方向的方向与箭头垂直，因此它们与约束集相切。
- en: At those same `points`, we also plot the gradient of \(f\), which recall is
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在那些相同的 `点上`，我们还绘制了 \(f\) 的梯度，回忆一下它是
- en: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2). \]
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = \left( \frac{\partial f(\mathbf{x})}{\partial x_1},
    \frac{\partial f(\mathbf{x})}{\partial x_2} \right) = (4 x_1, 6 x_2). \]
- en: We make all gradients into unit vectors.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有梯度都转换为单位向量。
- en: '[PRE9]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![../../_images/a5aed8b6b668174566d2d532e4b400fcf5707acf3befc2f4f7b86d23fc3b68a5.png](../Images/b947d14ae52253453dee08ef202017c5.png)'
  id: totrans-544
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/a5aed8b6b668174566d2d532e4b400fcf5707acf3befc2f4f7b86d23fc3b68a5.png](../Images/b947d14ae52253453dee08ef202017c5.png)'
- en: We see that, at \((-1,0)\) and \((1,0)\), the gradient is indeed orthogonal
    to the first-order feasible directions.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在 \((-1,0)\) 和 \((1,0)\) 处，梯度确实垂直于一阶可行方向。
- en: \(\unlhd\)
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: A feasible vector \(\mathbf{x}\) is said to be regular if the vectors \(\nabla
    h_i (\mathbf{x}^*)\), \(i \in [\ell]\), are linearly independent. We re-formulate
    the previous theorem in terms of the Lagrangian function, which is defined as
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 如果向量 \(\nabla h_i (\mathbf{x}^*)\)，\(i \in [\ell]\)，是线性无关的，则称可行向量 \(\mathbf{x}\)
    是正则的。我们用拉格朗日函数重新表述先前的定理，拉格朗日函数定义为
- en: \[ L(\mathbf{x}, \blambda) = f(\mathbf{x}) + \sum_{i=1}^\ell \lambda_i h_i(\mathbf{x}),
    \]
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L(\mathbf{x}, \blambda) = f(\mathbf{x}) + \sum_{i=1}^\ell \lambda_i h_i(\mathbf{x}),
    \]
- en: where \(\blambda = (\lambda_1,\ldots,\lambda_\ell)\). Then, by the theorem,
    a regular local minimizer satisfies
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\blambda = (\lambda_1,\ldots,\lambda_\ell)\)。然后，根据定理，一个正则局部极小值满足
- en: \[\begin{align*} &\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\\
    &\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}. \end{align*}\]
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\\
    &\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}. \end{align*}\]
- en: Here the notation \(\nabla_{\mathbf{x}}\) (respectively \(\nabla_{\blambda}\))
    indicates that we are taking the vector of partial derivatives with respect to
    only the variables in \(\mathbf{x}\) (respectively \(\blambda\)).
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 这里符号 \(\nabla_{\mathbf{x}}\)（分别 \(\nabla_{\blambda}\)）表示我们只对 \(\mathbf{x}\)（分别
    \(\blambda\)）中的变量求偏导数。
- en: To see that these equations hold, note that
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看出这些方程成立，注意
- en: \[ \nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \nabla f(\mathbf{x}) + \sum_{i=1}^\ell
    \lambda_i \nabla h_i(\mathbf{x}) \]
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \nabla f(\mathbf{x}) + \sum_{i=1}^\ell
    \lambda_i \nabla h_i(\mathbf{x}) \]
- en: and
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 并且
- en: \[ \nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{h}(\mathbf{x}). \]
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{h}(\mathbf{x}). \]
- en: So \(\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\) is a restatement
    of the Lagrange multipliers condition and \(\nabla_{\blambda} L(\mathbf{x}, \blambda)
    = \mathbf{0}\) is a restatement of feasibility. Together, they form a system of
    \(d + \ell\) equations in \(d + \ell\) variables.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(\nabla_{\mathbf{x}} L(\mathbf{x}, \blambda) = \mathbf{0}\) 是拉格朗日乘数条件的另一种表述，而
    \(\nabla_{\blambda} L(\mathbf{x}, \blambda) = \mathbf{0}\) 是可行性的另一种表述。它们共同构成一个
    \(d + \ell\) 个变量中的 \(d + \ell\) 个方程的系统。
- en: '**EXAMPLE:** Consider the constrained minimization problem on \(\mathbb{R}^3\)
    where the objective function is'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 考虑在 \(\mathbb{R}^3\) 上的约束最小化问题，其中目标函数是'
- en: \[ f(\mathbf{x}) = \frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \]
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f(\mathbf{x}) = \frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \]
- en: and the only constraint function is
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 并且只有约束函数
- en: \[ h_1(\mathbf{x}) = 3 - x_1 - x_2 - x_3. \]
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_1(\mathbf{x}) = 3 - x_1 - x_2 - x_3. \]
- en: The gradients are
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度是
- en: \[ \nabla f(\mathbf{x}) = (x_1, x_2, x_3) \]
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{x}) = (x_1, x_2, x_3) \]
- en: and
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 并且
- en: \[ \nabla h_1(\mathbf{x}) = (-1, -1, -1). \]
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla h_1(\mathbf{x}) = (-1, -1, -1). \]
- en: In particular, regularity is always satisfied since there is only one non-zero
    vector to consider.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，正则性总是满足的，因为只有一个非零向量需要考虑。
- en: So we are looking for solutions to the system of equations
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: So we are looking for solutions to the system of equations
- en: \[\begin{align*} &x_1 - \lambda_1 = 0\\ &x_2 - \lambda_1 = 0\\ &x_3 - \lambda_1
    = 0\\ &3 - x_1 - x_2 - x_3 = 0. \end{align*}\]
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &x_1 - \lambda_1 = 0\\ &x_2 - \lambda_1 = 0\\ &x_3 - \lambda_1
    = 0\\ &3 - x_1 - x_2 - x_3 = 0. \end{align*}\]
- en: The first three equations imply that \(x_1 = x_2 = x_3 = \lambda\). Replacing
    in the fourth equation gives \(3 - 3 \lambda_1 = 0\) so \(\lambda_1 = 1\). Hence,
    \(x_1 = x_2 = x_3 = 1\) and this is the only solution.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: The first three equations imply that \(x_1 = x_2 = x_3 = \lambda\). Replacing
    in the fourth equation gives \(3 - 3 \lambda_1 = 0\) so \(\lambda_1 = 1\). Hence,
    \(x_1 = x_2 = x_3 = 1\) and this is the only solution.
- en: So any local minimizer, if it exists, must be the vector \((1,1,1)\) with Lagrange
    multiplier \(1\). How can we know for sure whether this is the case? \(\lhd\)
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: So any local minimizer, if it exists, must be the vector \((1,1,1)\) with Lagrange
    multiplier \(1\). How can we know for sure whether this is the case? \(\lhd\)
- en: As in the unconstrained case, there are *sufficient* conditions. As in that
    case as well, they involve second-order derivatives. We give one such theorem
    next without proof.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: As in the unconstrained case, there are *sufficient* conditions. As in that
    case as well, they involve second-order derivatives. We give one such theorem
    next without proof.
- en: '**THEOREM** Assume \(f : \mathbb{R}^d \to \mathbb{R}\) and \(h_i : \mathbb{R}^d
    \to \mathbb{R}\), \(i\in [\ell]\), are twice continuously differentiable. Let
    \(\mathbf{x}^* \in \mathbb{R}^d\) and \(\blambda^* \in \mathbb{R}^\ell\) satisfy'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: '**THEOREM** Assume \(f : \mathbb{R}^d \to \mathbb{R}\) and \(h_i : \mathbb{R}^d
    \to \mathbb{R}\), \(i\in [\ell]\), are twice continuously differentiable. Let
    \(\mathbf{x}^* \in \mathbb{R}^d\) and \(\blambda^* \in \mathbb{R}^\ell\) satisfy'
- en: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
- en: and
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: and
- en: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} > 0 \]
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} > 0 \]
- en: for all \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\). Then \(\mathbf{x}^*\)
    a strict local minimizer of \(f\) s.t. \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\).
    \(\sharp\)
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: for all \(\mathbf{v} \in \mathscr{F}_{\mathbf{h}}(\mathbf{x})\). Then \(\mathbf{x}^*\)
    a strict local minimizer of \(f\) s.t. \(\mathbf{h}(\mathbf{x}) = \mathbf{0}\).
    \(\sharp\)
- en: '**EXAMPLE:** **(continued)** We return to the previous example. We found a
    unique solution'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '**EXAMPLE:** **(continued)** We return to the previous example. We found a
    unique solution'
- en: \[ (x_1^*, x_2^*, x_3^*, \lambda_1^*) = (1,1,1,1) \]
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (x_1^*, x_2^*, x_3^*, \lambda_1^*) = (1,1,1,1) \]
- en: to the system
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: to the system
- en: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \nabla
    h_i(\mathbf{x}^*) &= \mathbf{0}\\ \mathbf{h}(\mathbf{x}^*) &= \mathbf{0} \end{align*}\]
- en: To check the second-order condition, we need the Hessians. It is straighforward
    to compute the second-order partial derivatives, which do not depend on \(\mathbf{x}\).
    We obtain
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: To check the second-order condition, we need the Hessians. It is straighforward
    to compute the second-order partial derivatives, which do not depend on \(\mathbf{x}\).
    We obtain
- en: \[ \mathbf{H}_{f}(\mathbf{x}) = I_{3 \times 3} \]
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_{f}(\mathbf{x}) = I_{3 \times 3} \]
- en: and
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: and
- en: \[ \mathbf{H}_{h_1}(\mathbf{x}) = \mathbf{0}_{3 \times 3}. \]
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_{h_1}(\mathbf{x}) = \mathbf{0}_{3 \times 3}. \]
- en: So
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: So
- en: \[ \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \mathbf{H}_{h_i}(\mathbf{x}^*)
    = I_{3 \times 3} \]
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i \mathbf{H}_{h_i}(\mathbf{x}^*)
    = I_{3 \times 3} \]
- en: and it follows that
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: and it follows that
- en: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} = \mathbf{v}^T I_{3 \times 3}
    \mathbf{v} = \|\mathbf{v}\|^2 > 0 \]
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v}^T\left( \mathbf{H}_f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda^*_i
    \mathbf{H}_{h_i}(\mathbf{x}^*) \right) \mathbf{v} = \mathbf{v}^T I_{3 \times 3}
    \mathbf{v} = \|\mathbf{v}\|^2 > 0 \]
- en: for any non-zero vector, including those in \(\mathscr{F}_{\mathbf{h}}(\mathbf{x})\).
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: for any non-zero vector, including those in \(\mathscr{F}_{\mathbf{h}}(\mathbf{x})\).
- en: It follows from the previous theorem that \(\mathbf{x}^*\) is a strict local
    minimizer of the constrained problem. \(\lhd\)
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: It follows from the previous theorem that \(\mathbf{x}^*\) is a strict local
    minimizer of the constrained problem. \(\lhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
- en: '**1** Which of the following is the correct definition of a global minimizer
    \(\mathbf{x}^*\) of a function \(f: \mathbb{R}^d \to \mathbb{R}\)?'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** Which of the following is the correct definition of a global minimizer
    \(\mathbf{x}^*\) of a function \(f: \mathbb{R}^d \to \mathbb{R}\)?'
- en: a) \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\) for all \(x\) in some open ball around
    \(\mathbf{x}^*\).
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\) for all \(x\) in some open ball around
    \(\mathbf{x}^*\).
- en: b) \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\) for all \(\mathbf{x} \in \mathbb{R}^d\).
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: b) 对于所有 \(\mathbf{x} \in \mathbb{R}^d\)，有 \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\)。
- en: c) \(\nabla f(\mathbf{x}^*) = 0\).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\nabla f(\mathbf{x}^*) = 0\)。
- en: d) \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}^*) \mathbf{v} > 0\) for all \(\mathbf{v}
    \in \mathbb{R}^d\).
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对于所有 \(\mathbf{v} \in \mathbb{R}^d\)，有 \(\mathbf{v}^T \mathbf{H}_f(\mathbf{x}^*)
    \mathbf{v} > 0\).
- en: '**2** Let \(f: \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable
    at \(\mathbf{x}_0\). The directional derivative of \(f\) at \(\mathbf{x}_0\) in
    the direction \(\mathbf{v} \in \mathbb{R}^d\) is NOT given by:'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 设 \(f: \mathbb{R}^d \to \mathbb{R}\) 在 \(\mathbf{x}_0\) 处连续可微。函数 \(f\)
    在 \(\mathbf{x}_0\) 处沿方向 \(\mathbf{v} \in \mathbb{R}^d\) 的方向导数不是以下哪个表达式：'
- en: a) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\).
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \nabla f(\mathbf{x}_0)^T
    \mathbf{v}\).
- en: b) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \nabla
    f(\mathbf{x}_0)\).
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \nabla
    f(\mathbf{x}_0)\)。
- en: c) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\).
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\)。
- en: d) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \lim_{h \to 0} \frac{f(\mathbf{x}_0
    + h\mathbf{v}) - f(\mathbf{x}_0)}{h}\).
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}} = \lim_{h \to 0} \frac{f(\mathbf{x}_0
    + h\mathbf{v}) - f(\mathbf{x}_0)}{h}\).
- en: '**3** Let \(f: \mathbb{R}^d \to \mathbb{R}\) be twice continuously differentiable.
    If \(\nabla f(\mathbf{x}_0) = 0\) and \(\mathbf{H}_f(\mathbf{x}_0)\) is positive
    definite, then \(\mathbf{x}_0\) is:'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 设 \(f: \mathbb{R}^d \to \mathbb{R}\) 是二阶连续可微的。如果 \(\nabla f(\mathbf{x}_0)
    = 0\) 且 \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\) 是：'
- en: a) A global minimizer of \(f\).
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(f\) 的全局最小值。
- en: b) A local minimizer of \(f\), but not necessarily a strict local minimizer.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(f\) 的局部最小值，但不一定是严格局部最小值。
- en: c) A strict local minimizer of \(f\).
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(f\) 的严格局部最小值。
- en: d) A saddle point of \(f\).
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(f\) 的鞍点。
- en: '**4** Consider the optimization problem \(\min_\mathbf{x} f(\mathbf{x})\) subject
    to \(\mathbf{h}(\mathbf{x}) = 0\), where \(f: \mathbb{R}^d \to \mathbb{R}\) and
    \(h: \mathbb{R}^d \to \mathbb{R}^\ell\) are continuously differentiable. Let \(\mathbf{x}^*\)
    be a local minimizer and assume that the vectors \(\nabla h_i(\mathbf{x}^*), i
    \in [\ell]\), are linearly independent. According to the Lagrange Multipliers
    theorem, which of the following must be true?'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 考虑优化问题 \(\min_\mathbf{x} f(\mathbf{x})\)，受约束于 \(\mathbf{h}(\mathbf{x})
    = 0\)，其中 \(f: \mathbb{R}^d \to \mathbb{R}\) 和 \(h: \mathbb{R}^d \to \mathbb{R}^\ell\)
    是连续可微的。设 \(\mathbf{x}^*\) 是一个局部最小值点，并且假设向量 \(\nabla h_i(\mathbf{x}^*), i \in [\ell]\)
    是线性无关的。根据拉格朗日乘数法，以下哪个必须成立？'
- en: a) \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)。
- en: b) \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}\) for some \(\lambda^* \in \mathbb{R}^\ell\).
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*)
    = \mathbf{0}\) 对于某个 \(\lambda^* \in \mathbb{R}^\ell\)。
- en: c) \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\).
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\).
- en: d) Both b and c.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: d) b 和 c 都成立。
- en: '**5** Which of the following is a correct statement of Taylor’s Theorem (to
    second order) for a twice continuously differentiable function \(f: D \to \mathbb{R}\),
    where \(D \subseteq \mathbb{R}^d\), at an interior point \(\mathbf{x}_0 \in D\)?'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪个是关于二阶泰勒定理的正确陈述，适用于在 \(\mathbb{R}^d\) 内部点 \(\mathbf{x}_0 \in D\) 的二阶连续可微函数
    \(f: D \to \mathbb{R}\)？'
- en: a) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2}(\mathbf{x}
    - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))(\mathbf{x}
    - \mathbf{x}_0)\) for some \(\xi \in (0,1)\).
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: a) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，有 \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2}(\mathbf{x}
    - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))(\mathbf{x}
    - \mathbf{x}_0)\)，其中 \(\xi \in (0,1)\).
- en: b) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x} - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x}
    - \mathbf{x}_0))(\mathbf{x} - \mathbf{x}_0)\).
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: b) 对于任何 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，有 \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x} - \mathbf{x}_0)^T \mathbf{H}_f(\mathbf{x}_0 + \xi(\mathbf{x}
    - \mathbf{x}_0))(\mathbf{x} - \mathbf{x}_0)\).
- en: c) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)\).
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: c) 对于任意 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \nabla f(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T (\mathbf{x} - \mathbf{x}_0)\)。
- en: d) For any \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\), \(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T \mathbf{H}_f(\mathbf{x}_0)(\mathbf{x}_0
    + \xi(\mathbf{x} - \mathbf{x}_0))\).
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对于任意 \(\mathbf{x} \in B_\delta(\mathbf{x}_0)\)，\(f(\mathbf{x}) = f(\mathbf{x}_0)
    + \frac{1}{2}(\mathbf{x}_0 + \xi(\mathbf{x} - \mathbf{x}_0))^T \mathbf{H}_f(\mathbf{x}_0)(\mathbf{x}_0
    + \xi(\mathbf{x} - \mathbf{x}_0))\)。
- en: 'Answer for Q3.3.1: b. Justification: The text states that “The point \(\mathbf{x}^*
    \in \mathbb{R}^d\) is a global minimizer of \(f\) over \(\mathbb{R}^d\) if \(f(\mathbf{x})
    \geq f(\mathbf{x}^*), \forall \mathbf{x} \in \mathbb{R}^d\).”'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.1的答案：b. 证明：文本中提到，“如果 \(\mathbf{x}^* \in \mathbb{R}^d\) 是 \(f\) 在 \(\mathbb{R}^d\)
    上的全局最小值，那么对于所有 \(\mathbf{x} \in \mathbb{R}^d\)，都有 \(f(\mathbf{x}) \geq f(\mathbf{x}^*)\)。”
- en: 'Answer for Q3.3.7: c. Justification: The text states the Directional Derivative
    from Gradient theorem: “Assume that \(f\) is continuously differentiable at \(\mathbf{x}_0\).
    Then the directional derivative of \(f\) at \(\mathbf{x}_0\) in the direction
    \(\mathbf{v}\) is given by \(\frac{\partial f(\mathbf{x}_0)}{\partial \mathbf{v}}
    = \nabla f(\mathbf{x}_0)^T \mathbf{v}\).”'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.7的答案：c. 证明：文本中陈述了梯度方向导数定理：“假设 \(f\) 在 \(\mathbf{x}_0\) 处连续可微。那么 \(f\) 在
    \(\mathbf{x}_0\) 处沿 \(\mathbf{v}\) 方向的方向导数为 \(\frac{\partial f(\mathbf{x}_0)}{\partial
    \mathbf{v}} = \nabla f(\mathbf{x}_0)^T \mathbf{v}\)。”
- en: 'Answer for Q3.3.9: c. Justification: The text states the Second-Order Sufficient
    Condition theorem: “If \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) and \(\mathbf{H}_f(\mathbf{x}_0)\)
    is positive definite, then \(\mathbf{x}_0\) is a strict local minimizer.”'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.9的答案：c. 证明：文本中陈述了二阶充分条件定理：“如果 \(\nabla f(\mathbf{x}_0) = \mathbf{0}\) 并且
    \(\mathbf{H}_f(\mathbf{x}_0)\) 是正定的，那么 \(\mathbf{x}_0\) 是一个严格局部最小值。”
- en: 'Answer for Q3.3.12: d. Justification: The Lagrange Multipliers theorem states
    that under the given conditions, there exists a unique vector \(\boldsymbol{\lambda}^*
    = (\lambda_1^*, \ldots, \lambda_\ell^*)\) satisfying \(\nabla f(\mathbf{x}^*)
    + \sum_{i=1}^\ell \lambda_i^* \nabla h_i(\mathbf{x}^*) = \mathbf{0}\) and \(\mathbf{h}(\mathbf{x}^*)
    = \mathbf{0}\).'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.12的答案：d. 证明：拉格朗日乘数定理表明，在给定条件下，存在一个唯一的向量 \(\boldsymbol{\lambda}^* = (\lambda_1^*,
    \ldots, \lambda_\ell^*)\)，满足 \(\nabla f(\mathbf{x}^*) + \sum_{i=1}^\ell \lambda_i^*
    \nabla h_i(\mathbf{x}^*) = \mathbf{0}\) 和 \(\mathbf{h}(\mathbf{x}^*) = \mathbf{0}\)。
- en: 'Answer for Q3.3.14: a. Justification: This is the statement of Taylor’s Theorem
    as presented in the text.'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: Q3.3.14的答案：a. 证明：这是文本中呈现的泰勒定理的陈述。
