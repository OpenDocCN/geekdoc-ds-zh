- en: Instruction-Level Parallelism
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指令级并行性
- en: 原文：[https://en.algorithmica.org/hpc/pipelining/](https://en.algorithmica.org/hpc/pipelining/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/pipelining/](https://en.algorithmica.org/hpc/pipelining/)
- en: When programmers hear the word *parallelism*, they mostly think about *multi-core
    parallelism*, the practice of explicitly splitting a computation into semi-independent
    *threads* that work together to solve a common problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序员听到*并行性*这个词时，他们主要想到的是*多核并行性*，这是一种将计算显式地分割成半独立的*线程*，这些线程共同工作来解决共同问题的实践。
- en: This type of parallelism is mainly about reducing *latency* and achieving *scalability*,
    but not about improving *efficiency*. You can solve a problem ten times as big
    with a parallel algorithm, but it would take at least ten times as many computational
    resources. Although parallel hardware is becoming [ever more abundant](/hpc/complexity/hardware)
    and parallel algorithm design is becoming an increasingly important area, for
    now, we will limit ourselves to considering only a single CPU core.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的并行性主要是为了减少*延迟*和实现*可扩展性*，而不是提高*效率*。你可以用并行算法解决十倍大的问题，但至少需要十倍的计算资源。尽管并行硬件变得越来越[丰富](/hpc/complexity/hardware)且并行算法设计正变得越来越重要的领域，但到目前为止，我们将仅限于考虑单个CPU核心。
- en: But there are other types of parallelism, already existing inside a CPU core,
    that you can use *for free*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有其他类型的并行性，已经存在于CPU核心内部，你可以免费使用。
- en: Instruction Pipelining
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指令流水线
- en: 'To execute *any* instruction, processors need to do a lot of preparatory work
    first, which includes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行*任何*指令，处理器首先需要做大量的准备工作，这包括：
- en: '**fetching** a chunk of machine code from memory,'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从内存中**获取一段机器代码，'
- en: '**decoding** it and splitting into instructions,'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码**它并将其拆分为指令，'
- en: '**executing** these instructions, which may involve doing some **memory** operations,
    and'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**这些指令，这可能涉及一些**内存**操作，以及'
- en: '**writing** the results back into registers.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将结果写回寄存器**。'
- en: 'This whole sequence of operations is *long*. It takes up to 15-20 CPU cycles
    even for something simple like `add`-ing two register-stored values together.
    To hide this latency, modern CPUs use *pipelining*: after an instruction passes
    through the first stage, they start processing the next one right away, without
    waiting for the previous one to fully complete.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 整个操作序列非常长。即使是像将两个寄存器存储的值相加这样简单的操作，也需要15-20个CPU周期。为了隐藏这种延迟，现代CPU使用*流水线*：一旦一个指令通过了第一个阶段，它们就会立即开始处理下一个指令，而不必等待前一个指令完全完成。
- en: '![](../Images/ab79c0739d474372c291c29182fdb6b9.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ab79c0739d474372c291c29182fdb6b9.png)'
- en: Pipelining does not reduce *actual* latency but functionally makes it seem like
    if it was composed of only the execution and memory stage. You still need to pay
    these 15-20 cycles, but you only need to do it once after you’ve found the sequence
    of instructions you are going to execute.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线并不减少*实际*延迟，但功能上使其看起来就像它只由执行和内存阶段组成。你仍然需要支付这些15-20个周期，但一旦你找到了将要执行的指令序列，你只需要做一次。
- en: Having this in mind, hardware manufacturers prefer to use *cycles per instruction*
    (CPI) instead of something like “average instruction latency” as the main performance
    indicator for CPU designs. It is a [pretty good metric](/hpc/profiling/benchmarking)
    for algorithm designs too, if we only consider *useful* instructions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，硬件制造商更喜欢使用*每条指令周期数*（CPI）而不是像“平均指令延迟”这样的指标作为CPU设计的性能指标。如果我们只考虑*有用的*指令，它也是算法设计的一个相当好的指标。
- en: The CPI of a perfectly pipelined processor should tend to one, but it can actually
    be even lower if we make each stage of the pipeline “wider” by duplicating it,
    so that more than one instruction can be processed at a time. Because the cache
    and most of the ALU can be shared, this ends up being cheaper than adding a fully
    separate core. Such architectures, capable of executing more than one instruction
    per cycle, are called *superscalar*, and most modern CPUs are.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 完美流水线处理器的CPI应该接近于1，但如果我们通过复制每个流水线阶段使其“更宽”，那么一次可以处理多个指令，这样实际上CPI甚至可以更低。由于缓存和大多数ALU可以共享，这最终比添加一个完全独立的内核更便宜。这种每周期可以执行多个指令的架构被称为*超标量*，而大多数现代CPU都是这样的。
- en: You can only take advantage of superscalar processing if the stream of instructions
    contains groups of logically independent operations that can be processed separately.
    The instructions don’t always arrive in the most convenient order, so, when possible,
    modern CPUs can execute them *out of order* to improve overall utilization and
    minimize pipeline stalls. How this magic works is a topic for a more advanced
    discussion, but for now, you can assume that the CPU maintains a buffer of pending
    instructions up to some distance in the future, and executes them as soon as the
    values of its operands are computed and there is an execution unit available.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当指令流包含逻辑上独立的操作组，这些操作可以单独处理时，你才能利用超标量处理。指令不一定总是以最方便的顺序到达，因此，当可能时，现代CPU可以以乱序执行它们，以提高整体利用率和最小化流水线停顿。这种魔法是如何工作的，是一个更高级讨论的话题，但到目前为止，你可以假设CPU维护一个未来某个距离的待处理指令缓冲区，一旦其操作数的值被计算出来并且有可用的执行单元，就立即执行这些指令。
- en: An Education Analogy
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 教育类比
- en: 'Consider how our education system works:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下我们的教育系统是如何运作的：
- en: Topics are taught to groups of students instead of individuals as broadcasting
    the same things to everyone at once is more efficient.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 课程内容是以小组形式教授给学生，而不是个人，因为一次性向所有人广播相同的内容更有效率。
- en: An intake of students is split into groups led by different teachers; assignments
    and other course materials are shared between groups.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学生入学后被分成由不同教师领导的小组；作业和其他课程材料在小组之间共享。
- en: Each year the same course is taught to a new intake so that the teachers are
    kept busy.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每年都会对新一届学生教授相同的课程，这样教师就能保持忙碌。
- en: These innovations greatly increase the *throughput* of the whole system, although
    the *latency* (time to graduation for a particular student) remains unchanged
    (and maybe increases a little bit because personalized tutoring is more effective).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些创新大大提高了整个系统的*吞吐量*，尽管*延迟*（特定学生的毕业时间）保持不变（并且可能略有增加，因为个性化辅导更有效）。
- en: 'You can find many analogies with modern CPUs:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在现代CPU中找到许多类比：
- en: CPUs use [SIMD parallelism](/hpc/simd) to execute the same operation on a block
    of different data points (comprised of 16, 32, or 64 bytes).
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU使用[单指令多数据（SIMD）并行性](/hpc/simd)在数据块的不同数据点上执行相同的操作（由16、32或64字节组成）。
- en: There are multiple execution units that can process these instructions simultaneously
    while sharing other CPU facilities (usually 2-4 execution units).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有多个执行单元可以同时处理这些指令，同时共享其他CPU资源（通常为2-4个执行单元）。
- en: Instructions are processed in pipelined fashion (saving roughly the same number
    of cycles as the number of years between kindergarten and PhD).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指令以流水线方式处理（节省的周期数大致等于从幼儿园到博士之间的年数）。
- en: 'In addition to that, several other aspects also match:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有其他几个方面也相匹配：
- en: Execution paths become more divergent with time and need different execution
    units.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着时间的推移，执行路径变得更加分歧，需要不同的执行单元。
- en: Some instructions may be stalled for various reasons.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些指令可能由于各种原因而停滞。
- en: Some instructions are even speculated (executed ahead of time), but then discarded.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些指令甚至被预测（提前执行），但随后被丢弃。
- en: Some instructions may be split in several distinct micro-operations that can
    proceed on their own.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些指令可能被分成几个不同的微操作，这些微操作可以独立进行。
- en: Programming pipelined and superscalar processors presents its own challenges,
    which we are going to address in this chapter.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 编程流水线和超标量处理器有其自身的挑战，我们将在本章中解决这些问题。
- en: '[← Machine Code Layout](https://en.algorithmica.org/hpc/architecture/layout/)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[← 机器代码布局](https://en.algorithmica.org/hpc/architecture/layout/)'
- en: '[← ../Computer Architecture](https://en.algorithmica.org/hpc/architecture/)[Pipeline
    Hazards →](https://en.algorithmica.org/hpc/pipelining/hazards/)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[← ../计算机架构](https://en.algorithmica.org/hpc/architecture/)[流水线冒险 →](https://en.algorithmica.org/hpc/pipelining/hazards/)'
- en: '[../Compilation →](https://en.algorithmica.org/hpc/compilation/)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[../编译 →](https://en.algorithmica.org/hpc/compilation/)'
