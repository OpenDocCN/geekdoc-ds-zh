- en: '24'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '24'
- en: A QUICK LOOK AT MACHINE LEARNING
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习速览
- en: The amount of digital data in the world has been growing at a rate that defies
    human comprehension. The world's data storage capacity has doubled about every
    three years since the 1980s. During the time it will take you to read this chapter,
    approximately `10`^(18) bits of data will be added to the world's store. It's
    not easy to relate to a number that large. One way to think about it is that `10`^(18)
    Canadian pennies would have a surface area roughly twice that of the earth.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 世界上的数字数据量以难以人类理解的速度增长。自1980年代以来，世界的数据存储能力每三年大约翻一番。在你阅读本章所需的时间里，世界上的数据存储将增加约`10`^(18)位。这么大的数字不容易理解。可以这样想：`10`^(18)个加元便士的表面积大约是地球的两倍。
- en: Of course, more data does not always lead to more useful information. Evolution
    is a slow process, and the ability of the human mind to assimilate data does not,
    alas, double every three years. One approach that the world is using to attempt
    to wring more useful information from “big data” is **statistical machine learning**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，更多的数据并不总是意味着更有用的信息。进化是一个缓慢的过程，人类心智同化数据的能力并不会每三年翻倍。世界正在使用的一种方法，以期从“大数据”中提取更多有用信息，就是**统计机器学习**。
- en: Machine learning is hard to define. In some sense, every useful program learns
    something. For example, an implementation of Newton's method learns the roots
    of a polynomial. One of the earliest definitions was proposed by the American
    electrical engineer and computer scientist Arthur Samuel,[^(181)](#c24-fn-0001)
    who defined it as a “field of study that gives computers the ability to learn
    without being explicitly programmed.”
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习很难定义。从某种意义上说，每个有用的程序都会学习一些东西。例如，牛顿法的实现学习一个多项式的根。美国电气工程师和计算机科学家阿瑟·萨缪尔提出的最早定义之一是，它是一个“使计算机能够在没有明确编程的情况下学习的研究领域”。
- en: Humans learn in two ways—memorization and generalization. We use memorization
    to accumulate individual facts. In England, for example, primary school students
    might learn a list of English monarchs. Humans use **generalization** to deduce
    new facts from old facts. A student of political science, for example, might observe
    the behavior of a large number of politicians, and generalize from those observations
    to conclude that all politicians lie when campaigning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人类通过两种方式学习——记忆和概括。我们利用记忆来积累个别事实。例如，在英国，小学生可能会学习一份英王列表。人类使用**概括**从旧事实推导出新事实。例如，政治学学生可能会观察大量政治家的行为，并从这些观察中推导出所有政治家在竞选时都撒谎。
- en: When computer scientists speak about machine learning, they most often mean
    the discipline of writing programs that automatically learn to make useful inferences
    from implicit patterns in data. For example, linear regression (see Chapter 20)
    learns a curve that is a model of a collection of examples. That model can then
    be used to make predictions about previously unseen examples. The basic paradigm
    is
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机科学家谈论机器学习时，他们最常指的是编写程序的学科，这些程序自动学习从数据中的隐含模式中得出有用的推论。例如，线性回归（见第20章）学习一条曲线，该曲线是一组示例的模型。然后可以使用该模型对以前未见过的示例进行预测。基本范式是
- en: 1\. Observe a set of examples, frequently called the **training data**, that
    represents incomplete information about some statistical phenomenon.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1\. 观察一组示例，通常称为**训练数据**，它表示有关某些统计现象的不完整信息。
- en: 2\. Use inference techniques to create a model of a process that could have
    generated the observed examples.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2\. 使用推理技术创建一个可能生成所观察示例的过程模型。
- en: 3\. Use that model to make predictions about previously unseen examples.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3\. 使用该模型对以前未见过的示例进行预测。
- en: Suppose, for example, you were given the two sets of names in [Figure 24-1](#c24-fig-0001)
    and the **feature vectors** in [Figure 24-2](#c24-fig-0002).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，例如，你获得了[图24-1](#c24-fig-0001)中的两个名称集合和[图24-2](#c24-fig-0002)中的**特征向量**。
- en: '![c24-fig-0001.jpg](../images/c24-fig-0001.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0001.jpg](../images/c24-fig-0001.jpg)'
- en: '[Figure 24-1](#c24-fig-0001a) Two sets of names'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[图24-1](#c24-fig-0001a) 两个名称集合'
- en: '![c24-fig-0002.jpg](../images/c24-fig-0002.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0002.jpg](../images/c24-fig-0002.jpg)'
- en: '[Figure 24-2](#c24-fig-0002a) Associating a feature vector with each name'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[图24-2](#c24-fig-0002a) 将特征向量与每个名称关联'
- en: Each element of a vector corresponds to some aspect (i.e., feature) of the person.
    Based on this limited information about these historical figures, you might infer
    that the process assigning either the label `A` or the label `B` to each example
    was intended to separate tall presidents from shorter ones.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的每个元素对应于某个方面（即特征）。基于对这些历史人物的有限信息，你可能推断出将标签`A`或标签`B`分配给每个示例的过程是为了将高个子总统与矮个子总统区分开来。
- en: 'There are many approaches to machine learning, but all try to learn a model
    that is a generalization of the provided examples. All have three components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有许多方法，但所有方法都试图学习一个提供示例的概括模型。所有方法都有三个组成部分：
- en: A representation of the model
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的一个表示
- en: An objective function for assessing the goodness of the model
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于评估模型优劣的目标函数
- en: An optimization method for learning a model that minimizes or maximizes the
    value of the objective function
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种优化方法，用于学习最小化或最大化目标函数值的模型
- en: Broadly speaking, machine learning algorithms can be thought of as either supervised
    or unsupervised.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 广义来说，机器学习算法可以分为有监督和无监督两种。
- en: In **supervised learning**, we start with a set of feature vector/value pairs.
    The goal is to derive from these pairs a rule that predicts the value associated
    with a previously unseen feature vector. **Regression models** associate a real
    number with each feature vector. **Classification models** associate one of a
    finite number of **labels** with each feature vector.[^(182)](#c24-fn-0002)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在**有监督学习**中，我们从一组特征向量/值对开始。目标是从这些对中推导出一个规则，以预测与先前未见的特征向量相关联的值。**回归模型**将一个实数与每个特征向量关联。**分类模型**将有限数量的**标签**中的一个与每个特征向量关联。[^(182)](#c24-fn-0002)
- en: In Chapter 20, we looked at one kind of regression model, linear regression.
    Each feature vector was an x-coordinate, and the value associated with it was
    the corresponding y-coordinate. From the set of feature vector/value pairs we
    learned a model that could be used to predict the y-coordinate associated with
    any x-coordinate.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在第20章中，我们看了一种回归模型，即线性回归。每个特征向量是一个x坐标，与之相关的值是对应的y坐标。通过特征向量/值对的集合，我们学习了一个模型，可以用来预测与任何x坐标相关联的y坐标。
- en: Now, let's look at a simple classification model. Given the sets of presidents
    we labeled `A` and `B` in [Figure 24-1](#c24-fig-0001) and the feature vectors
    in [Figure 24-2](#c24-fig-0002), we can generate the feature vector/label pairs
    in [Figure 24-3](#c24-fig-0003).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一个简单的分类模型。给定我们在[图 24-1](#c24-fig-0001)中标记的总统集合`A`和`B`以及[图 24-2](#c24-fig-0002)中的特征向量，我们可以生成[图
    24-3](#c24-fig-0003)中的特征向量/标签对。
- en: '![c24-fig-0003.jpg](../images/c24-fig-0003.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0003.jpg](../images/c24-fig-0003.jpg)'
- en: '[Figure 24-3](#c24-fig-0003a) Feature vector/label pairs for presidents'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-3](#c24-fig-0003a) 总统的特征向量/标签对'
- en: From these labeled examples, a learning algorithm might infer that all tall
    presidents should be labeled `A` and all short presidents labeled `B`. When asked
    to assign a label to
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些标记的示例中，学习算法可能推断出所有高个子总统应该标记为`A`，所有矮个子总统标记为`B`。当被要求为
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: it would use the rule it had learned to choose label `A`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 它会使用它所学到的规则来选择标签`A`。
- en: Supervised machine learning is broadly used for such tasks as detecting fraudulent
    use of credit cards and recommending movies to people.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有监督机器学习广泛应用于诸如检测信用卡欺诈使用和向人们推荐电影等任务。
- en: In **unsupervised learning**, we are given a set of feature vectors but no labels.
    The goal of unsupervised learning is to uncover latent structure in the set of
    feature vectors. For example, given the set of presidential feature vectors, an
    unsupervised learning algorithm might separate the presidents into tall and short,
    or perhaps into American and French. Approaches to unsupervised machine learning
    can be categorized as either methods for clustering or methods for learning latent
    variable models.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在**无监督学习**中，我们获得一组特征向量，但没有标签。无监督学习的目标是揭示特征向量集合中的潜在结构。例如，给定总统特征向量的集合，无监督学习算法可能会将总统分为高个子和矮个子，或者可能分为美国人和法国人。无监督机器学习的方法可以分为聚类方法或学习潜变量模型的方法。
- en: A **latent variable** is a variable whose value is not directly observed but
    can be inferred from the values of variables that are observed. Admissions officers
    at universities, for example, try to infer the probability of an applicant being
    a successful student (the latent variable), based on a set of observable values
    such as secondary school grades and performance on standardized tests. There is
    a rich set of methods for learning latent variable models, but we do not cover
    them in this book.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**潜变量**是一个其值不是直接观察到的变量，但可以从观察到的变量值中推断出来。例如，大学的招生官员试图根据一组可观察的值（如中学成绩和标准化测试成绩）推断申请者成为成功学生的概率（即潜变量）。有许多丰富的方法用于学习潜变量模型，但我们在本书中不讨论这些。'
- en: '**Clustering** partitions a set of examples into groups (called clusters) such
    that examples in the same group are more similar to each other than they are to
    examples in other groups. Geneticists, for example, use clustering to find groups
    of related genes. Many popular clustering methods are surprisingly simple.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**将一组实例划分为多个组（称为簇），使得同一组中的实例彼此之间更相似，而与其他组中的实例则相对不相似。例如，遗传学家使用聚类来寻找相关基因的群体。许多流行的聚类方法出人意料地简单。'
- en: We present a widely used clustering algorithm in Chapter 25, and several approaches
    to supervised learning in Chapter 26\. In the remainder of this chapter, we discuss
    the process of building feature vectors and different ways of calculating the
    similarity between two feature vectors.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第25章介绍了一种广泛使用的聚类算法，并在第26章讨论了几种监督学习的方法。在本章的其余部分，我们讨论了构建特征向量的过程以及计算两个特征向量之间相似性的不同方法。
- en: 24.1 Feature Vectors
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 24.1 特征向量
- en: The concept of **signal-to-noise ratio** (**SNR**) is used in many branches
    of engineering and science. The precise definition varies across applications,
    but the basic idea is simple. Think of it as the ratio of useful input to irrelevant
    input. In a restaurant, the signal might be the voice of your dinner date, and
    the noise the voices of the other diners.[^(184)](#c24-fn-0004) If we were trying
    to predict which students would do well in a programming course, previous programming
    experience and mathematical aptitude would be part of the signal, but hair color
    merely noise. Separating the signal from the noise is not always easy. When it
    is done poorly, the noise can be a distraction that obscures the truth in the
    signal.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**信噪比**（**SNR**）的概念在许多工程和科学领域中使用。确切的定义在不同应用中有所不同，但基本思想很简单。将其视为有用输入与无关输入的比率。在餐厅里，信号可能是你约会对象的声音，而噪声则是其他
    diners 的声音。如果我们试图预测哪些学生在编程课程中表现良好，之前的编程经验和数学能力将是信号的一部分，而发色则仅仅是噪声。将信号与噪声分离并不总是容易。当做得不够好时，噪声可能会干扰，掩盖信号中的真相。'
- en: The purpose of **feature engineering** is to separate those features in the
    available data that contribute to the signal from those that are merely noise.
    Failure to do an adequate job of this can lead to a bad model. The danger is particularly
    high when the **dimensionality** of the data (i.e., the number of different features)
    is large relative to the number of samples.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**的目的是将可用数据中对信号有贡献的特征与仅仅是噪声的特征分开。如果未能做好这项工作，可能导致模型表现不佳。当数据的**维度**（即不同特征的数量）相对于样本数量较大时，风险特别高。'
- en: Successful feature engineering reduces the vast amount of information that might
    be available to information from which it will be productive to generalize. Imagine,
    for example, that your goal is to learn a model that will predict whether a person
    is likely to suffer a heart attack. Some features, such as their age, are likely
    to be highly relevant. Other features, such as whether they are left-handed, are
    less likely to be relevant.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 成功的特征工程能够减少可用信息的庞大数量，使其成为有助于推广的有用信息。例如，想象一下，你的目标是学习一个模型，以预测一个人是否可能会发生心脏病发作。一些特征，比如他们的年龄，可能非常相关。其他特征，比如他们是否是左撇子，可能不太相关。
- en: '**Feature selection** techniques can be used to automatically identify which
    features in a given set of features are most likely to be helpful. For example,
    in the context of supervised learning, we can select those features that are most
    strongly correlated with the labels of the examples.[^(185)](#c24-fn-0005) However,
    these feature selection techniques are of little help if relevant features are
    not there to start with. Suppose that our original feature set for the heart attack
    example includes height and weight. It might be the case that while neither height
    nor weight is highly predictive of a heart attack, body mass index (BMI) is. While
    BMI can be computed from height and weight, the relationship (weight in kilograms
    divided by the square of height in meters) is too complicated to be automatically
    found by typical machine learning techniques. Successful machine learning often
    involves the design of features by those with domain expertise.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征选择**技术可以自动识别在给定特征集合中哪些特征最有可能是有帮助的。例如，在监督学习的背景下，我们可以选择与样本标签最强相关的特征。[^(185)](#c24-fn-0005)然而，如果没有相关特征，这些特征选择技术帮助不大。假设我们心脏病发作示例的原始特征集合包括身高和体重。尽管身高和体重都不是心脏病发作的强预测因素，但身体质量指数（BMI）可能是。虽然BMI可以通过身高和体重计算得出，但其关系（体重以千克为单位除以身高以米为单位的平方）过于复杂，无法通过典型的机器学习技术自动发现。成功的机器学习通常涉及领域专家设计特征。'
- en: In unsupervised learning, the problem is even harder. Typically, we choose features
    based upon our intuition about which features might be relevant to the kinds of
    structure we would like to find. However, relying on intuition about the potential
    relevance of features is problematic. How good is your intuition about whether
    someone's dental history is a useful predictor of a future heart attack?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，问题甚至更困难。通常，我们根据对哪些特征可能与我们希望发现的结构相关的直觉来选择特征。然而，依赖于对特征潜在相关性的直觉是有问题的。你对某人的牙齿历史是否是未来心脏病发作的有用预测因素的直觉有多好？
- en: Consider [Figure 24-4](#c24-fig-0004), which contains a table of feature vectors
    and the label (reptile or not) with which each vector is associated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑[图24-4](#c24-fig-0004)，其中包含特征向量的表格和每个向量相关的标签（爬行动物或非爬行动物）。
- en: '![c24-fig-0004.jpg](../images/c24-fig-0004.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0004.jpg](../images/c24-fig-0004.jpg)'
- en: '[Figure 24-4](#c24-fig-0004a) Name, features, and labels for assorted animals'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[图24-4](#c24-fig-0004a) 各种动物的名称、特征和标签'
- en: A supervised machine learning algorithm (or a human) given only the information
    about cobras—i.e., only the first row of the table—cannot do much more than to
    remember the fact that a cobra is a reptile. Now, let's add the information about
    rattlesnakes. We can begin to generalize and might infer the rule that an animal
    is a reptile if it lays eggs, has scales, is poisonous, is cold-blooded, and has
    no legs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅通过有关眼镜蛇的信息（即，仅表格的第一行），一个监督机器学习算法（或人类）几乎只能记住眼镜蛇是爬行动物这一事实。现在，让我们添加有关响尾蛇的信息。我们可以开始进行概括，并可能推断出一个规则：如果动物下蛋、有鳞、是毒性、是冷血动物，并且没有腿，则它是爬行动物。
- en: Now, suppose we are asked to decide if a boa constrictor is a reptile. We might
    answer “no,” because a boa constrictor is neither poisonous nor egg-laying. But
    this would be the wrong answer. Of course, it is hardly surprising that attempting
    to generalize from two examples might lead us astray. Once we include the boa
    constrictor in our training data, we might formulate the new rule that an animal
    is a reptile if it has scales, is cold-blooded, and is legless. In doing so, we
    are discarding the features `egg-laying` and `poisonous` as irrelevant to the
    classification problem.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们被要求决定一条巨蟒是否是爬行动物。我们可能会回答“不是”，因为巨蟒既不是毒性动物，也不是下蛋的。然而，这将是错误的答案。当然，试图从两个示例中进行概括而导致错误也并不令人惊讶。一旦我们将巨蟒纳入我们的训练数据，我们可能会形成新的规则：如果动物有鳞、是冷血动物，并且没有腿，则它是爬行动物。在这样做的过程中，我们将特征`下蛋`和`毒性`视为与分类问题无关而丢弃。
- en: If we use the new rule to classify the alligator, we conclude incorrectly that
    since it has legs it is not a reptile. Once we include the alligator in the training
    data, we reformulate the rule to allow reptiles to have either none or four legs.
    When we look at the dart frog, we correctly conclude that it is not a reptile,
    since it is not cold-blooded. However, when we use our current rule to classify
    the salmon, we incorrectly conclude that a salmon is a reptile. We can add yet
    more complexity to our rule to separate salmon from alligators, but it's a losing
    battle. There is no way to modify our rule so that it will correctly classify
    both salmon and pythons, since the feature vectors of these two species are identical.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用新规则来分类鳄鱼，我们错误地得出结论，认为因为它有腿，所以不是爬行动物。一旦我们将鳄鱼纳入训练数据，我们就重新制定规则，允许爬行动物没有腿或有四条腿。当我们观察飞镖蛙时，我们正确得出结论，它不是爬行动物，因为它不是冷血的。然而，当我们用目前的规则来分类鲑鱼时，我们错误地得出结论，认为鲑鱼是爬行动物。我们可以为我们的规则增加更多复杂性，以将鲑鱼与鳄鱼区分开来，但这是徒劳的。没有办法修改我们的规则，使其能够正确分类鲑鱼和蟒蛇，因为这两种物种的特征向量是相同的。
- en: This kind of problem is more common than not in machine learning. It is rare
    to have feature vectors that contain enough information to classify things perfectly.
    In this case, the problem is that we don't have enough features.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种问题在机器学习中比比皆是。特征向量中包含足够信息以完美分类的情况非常罕见。在这种情况下，问题在于我们没有足够的特征。
- en: If we had included the fact that reptile eggs have amnios,[^(186)](#c24-fn-0006)
    we could devise a rule that separates reptiles from fish. Unfortunately, in most
    practical applications of machine learning it is not possible to construct feature
    vectors that allow for perfect discrimination.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑到爬行动物的卵有羊膜，我们可以制定出一个将爬行动物与鱼类分开的规则。不幸的是，在大多数机器学习的实际应用中，构造允许完美区分的特征向量是不可能的。
- en: Does this mean that we should give up because all of the available features
    are mere noise? No. In this case, the features `scales` and `cold-blooded` are
    necessary conditions for being a reptile, but not sufficient conditions. The rule
    that an animal is a reptile if it has scales and is cold-blooded will not yield
    any false negatives, i.e., any animal classified as a non-reptile will indeed
    not be a reptile. However, the rule will yield some false positives, i.e., some
    of the animals classified as reptiles will not be reptiles.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着我们应该放弃，因为所有可用的特征只是噪声？不。在这种情况下，特征`鳞片`和`冷血`是成为爬行动物的必要条件，但不是充分条件。如果动物有鳞片且是冷血的，就不可能产生假阴性，即，任何被分类为非爬行动物的动物确实不会是爬行动物。然而，这条规则会产生一些假阳性，即，一些被分类为爬行动物的动物实际上并不是爬行动物。
- en: 24.2 Distance Metrics
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 24.2 距离度量
- en: In [Figure 24-4](#c24-fig-0004) we described animals using four binary features
    and one integer feature. Suppose we want to use these features to evaluate the
    similarity of two animals, for example, to ask whether a rattlesnake is more similar
    to a boa constrictor or to a dart frog.[^(187)](#c24-fn-0007)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图24-4](#c24-fig-0004)中，我们使用四个二元特征和一个整数特征描述了动物。假设我们想用这些特征来评估两种动物的相似性，例如，询问响尾蛇与蚺蛇或飞镖蛙更相似。
- en: 'The first step in doing this kind of comparison is converting the features
    for each animal into a sequence of numbers. If we say `True = 1` and `False =
    0`, we get the following feature vectors:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这种比较的第一步是将每种动物的特征转换为数字序列。如果我们说`True = 1`和`False = 0`，我们会得到以下特征向量：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are many ways to compare the similarity of vectors of numbers. The most
    commonly used metrics for comparing equal-length vectors are based on the **Minkowski
    distance**:[^(188)](#c24-fn-0008)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 比较数字向量相似性的方法有很多。比较相同长度向量时最常用的度量基于**闵可夫斯基距离**：
- en: '![c24-fig-5001.jpg](../images/c24-fig-5001.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-5001.jpg](../images/c24-fig-5001.jpg)'
- en: where *len* is the length of the vectors.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*len*是向量的长度。
- en: The parameter `p`, which must be at least 1, defines the kinds of paths that
    can be followed in traversing the distance between the vectors *V* and *W*.[^(189)](#c24-fn-0009)
    This can be easily visualized if the vectors are of length two, and can therefore
    be represented using Cartesian coordinates. Consider the picture in [Figure 24-5](#c24-fig-0006).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`p`，至少为1，定义了在遍历向量*V*和*W*之间的距离时可以遵循的路径类型。这在向量长度为二时可以很容易地可视化，因此可以使用笛卡尔坐标表示。请考虑[图24-5](#c24-fig-0006)中的图像。
- en: '![c24-fig-0005.jpg](../images/c24-fig-0005.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0005.jpg](../images/c24-fig-0005.jpg)'
- en: '[Figure 24-5](#c24-fig-0006a) Visualizing distance metrics'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-5](#c24-fig-0006a) 可视化距离度量'
- en: Is the circle in the bottom-left corner closer to the cross or closer to the
    star? It depends. If we can travel in a straight line, the cross is closer. The
    Pythagorean Theorem tells us that the cross is the square root of `8` units from
    the circle, about `2.8` units, whereas we can easily see that the star is `3`
    units from the circle. These distances are called **Euclidean distances**, and
    correspond to using the Minkowski distance with `p = 2`. But imagine that the
    lines in the picture correspond to streets, and that we have to stay on the streets
    to get from one place to another. The star remains `3` units from the circle,
    but the cross is now `4` units away. These distances are called **Manhattan**
    **distances**,[^(190)](#c24-fn-0010) and they correspond to using the Minkowski
    distance with `p = 1`. [Figure 24-6](#c24-fig-0007) contains a function implementing
    the Minkowski distance.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 左下角的圆形更接近十字还是更接近星形？这要看情况。如果我们可以直线行走，十字更近。毕达哥拉斯定理告诉我们，十字距离圆形`8`单位的平方根，大约是`2.8`单位，而星形距离圆形`3`单位。这些距离被称为**欧几里得距离**，对应于使用闵可夫斯基距离时`p
    = 2`。但想象一下，图中的线条对应于街道，我们必须沿街道从一个地方到另一个地方。星形仍然距离圆形`3`单位，但十字现在距离`4`单位。这些距离被称为**曼哈顿**
    **距离**，[^(190)](#c24-fn-0010)，它们对应于使用闵可夫斯基距离时`p = 1`。[图 24-6](#c24-fig-0007)包含一个实现闵可夫斯基距离的函数。
- en: '![c24-fig-0006.jpg](../images/c24-fig-0006.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0006.jpg](../images/c24-fig-0006.jpg)'
- en: '[Figure 24-6](#c24-fig-0007a) Minkowski distance'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-6](#c24-fig-0007) 闵可夫斯基距离'
- en: '[Figure 24-7](#c24-fig-0008) contains class `Animal`. It defines the distance
    between two animals as the Euclidean distance between the feature vectors associated
    with the animals.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-7](#c24-fig-0008)包含类`Animal`。它将两只动物之间的距离定义为与动物相关的特征向量之间的欧几里得距离。'
- en: '![c24-fig-0007.jpg](../images/c24-fig-0007.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0007.jpg](../images/c24-fig-0007.jpg)'
- en: '[Figure 24-7](#c24-fig-0008a) Class `Animal`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-7](#c24-fig-0008a) 类`Animal`'
- en: '[Figure 24-8](#c24-fig-0009) contains a function that compares a list of animals
    to each other and produces a table showing the pairwise distances. The code uses
    a Matplotlib plotting facility that we have not previously used: `table`.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-8](#c24-fig-0009)包含一个比较动物列表的函数，并生成一张显示成对距离的表格。代码使用了我们之前未使用的 Matplotlib
    绘图工具：`table`。'
- en: The `table` function produces a plot that (surprise!) looks like a table. The
    keyword arguments `rowLabels` and `colLabels` are used to supply the labels (in
    this example the names of the animals) for the rows and columns. The keyword argument
    `cellText` is used to supply the values appearing in the cells of the table. In
    the example, `cellText` is bound to `table_vals`, which is a list of lists of
    strings. Each element in `table_vals` is a list of the values for the cells in
    one row of the table. The keyword argument `cellLoc` is used to specify where
    in each cell the text should appear, and the keyword argument `loc` is used to
    specify where in the figure the table itself should appear. The last keyword parameter
    used in the example is `colWidths`. It is bound to a list of floats giving the
    width (in inches) of each column in the table. The code `table.scale(1, 2.5)`
    instructs Matplotlib to leave the horizontal width of the cells unchanged, but
    to increase the height of the cells by a factor of `2.5` (so the tables look prettier).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`table`函数生成一个（惊喜！）看起来像表格的图。关键字参数`rowLabels`和`colLabels`用于提供行和列的标签（在本例中是动物的名称）。关键字参数`cellText`用于提供表格单元格中出现的值。在该示例中，`cellText`绑定到`table_vals`，这是一个字符串列表的列表。`table_vals`中的每个元素都是表格一行中单元格值的列表。关键字参数`cellLoc`用于指定文本在每个单元格中的位置，关键字参数`loc`用于指定表格本身在图中的位置。示例中使用的最后一个关键字参数是`colWidths`。它绑定到一个浮点数列表，给出表格中每一列的宽度（以英寸为单位）。代码`table.scale(1,
    2.5)`指示 Matplotlib 保持单元格的水平宽度不变，但将单元格的高度增加`2.5`倍（使表格看起来更美观）。'
- en: '![c24-fig-0008.jpg](../images/c24-fig-0008.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0008.jpg](../images/c24-fig-0008.jpg)'
- en: '[Figure 24-8](#c24-fig-0009a) Build table of distances between pairs of animals'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 24-8](#c24-fig-0009a) 建立动物对之间的距离表'
- en: If we run the code
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行代码
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: it produces the table in [Figure 24-9](#c24-fig-0010).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 它生成了[图 24-9](#c24-fig-0010)中的表格。
- en: As you probably expected, the distance between the rattlesnake and the boa constrictor
    is less than that between either of the snakes and the dart frog. Notice, by the
    way, that the dart frog is a bit closer to the rattlesnake than to the boa constrictor.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能预期的，响尾蛇与蟒蛇之间的距离小于任何一条蛇与飞蛙之间的距离。顺便提一下，飞蛙离响尾蛇稍微近一点，而不是蟒蛇。
- en: '![c24-fig-0009.jpg](../images/c24-fig-0009.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0009.jpg](../images/c24-fig-0009.jpg)'
- en: '[Figure 24-9](#c24-fig-0010a) Distances between three animals'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[图24-9](#c24-fig-0010a) 三种动物之间的距离'
- en: Now, let's insert before the last line of the above code the lines
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在上述代码的最后一行之前插入以下行
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It produces the table in [Figure 24-10](#c24-fig-0011).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 它生成了[图24-10](#c24-fig-0011)中的表格。
- en: '![c24-fig-0010.jpg](../images/c24-fig-0010.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0010.jpg](../images/c24-fig-0010.jpg)'
- en: '[Figure 24-10](#c24-fig-0011a) Distances between four animals'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[图24-10](#c24-fig-0011a) 四种动物之间的距离'
- en: Perhaps you're surprised that the alligator is considerably closer to the dart
    frog than to either the rattlesnake or the boa constrictor. Take a minute to think
    about why.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会惊讶于鳄鱼与飞蛙之间的距离明显小于与响尾蛇或蟒蛇之间的距离。花点时间思考一下为什么。
- en: 'The feature vector for the alligator differs from that of the rattlesnake in
    two places: whether it is poisonous and the number of legs. The feature vector
    for the alligator differs from that of the dart frog in three places: whether
    it is poisonous, whether it has scales, and whether it is cold-blooded. Yet, according
    to our Euclidean distance metric, the alligator is more like the dart frog than
    like the rattlesnake. What''s going on?'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 鳄鱼的特征向量与响尾蛇的特征向量在两个地方不同：是否有毒和腿的数量。鳄鱼的特征向量与飞蛙的特征向量在三个地方不同：是否有毒、是否有鳞片，以及是否是冷血动物。然而，根据我们的欧几里得距离度量，鳄鱼与飞蛙更相似，而非响尾蛇。这是怎么回事？
- en: The root of the problem is that the different features have different ranges
    of values. All but one of the features range between `0` and `1`, but the number
    of legs ranges from `0` to `4`. This means that when we calculate the Euclidean
    distance, the number of legs gets disproportionate weight. Let's see what happens
    if we turn the feature into a binary feature, with a value of `0` if the animal
    is legless and `1` otherwise.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的根源在于不同特征具有不同的值范围。除了一个特征，其他特征的范围均在`0`和`1`之间，但腿的数量则在`0`到`4`之间。这意味着当我们计算欧几里得距离时，腿的数量权重不成比例。让我们看看如果将特征变为二元特征，若动物无腿则值为`0`，否则为`1`会发生什么。
- en: '![c24-fig-0011.jpg](../images/c24-fig-0011.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![c24-fig-0011.jpg](../images/c24-fig-0011.jpg)'
- en: Figure 24-11 Distances using a different feature representation
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图24-11 使用不同特征表示的距离
- en: This looks a lot more plausible.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来更合理了。
- en: Of course, it is not always convenient to use only binary features. In Section
    25.4, we will present a more general approach to dealing with differences in scale
    among features.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，仅使用二元特征并不总是方便。在第25.4节中，我们将介绍一种更通用的方法来处理特征之间的规模差异。
- en: 24.3 Terms Introduced in Chapter
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 24.3 本章介绍的术语
- en: statistical machine learning
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计机器学习
- en: generalization
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泛化
- en: training data
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据
- en: feature vector
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征向量
- en: supervised learning
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: regression models
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归模型
- en: classification models
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类模型
- en: label
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签
- en: unsupervised learning
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: latent variable
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在变量
- en: clustering
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: signal-to-noise ratio (SNR)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信噪比（SNR）
- en: feature engineering
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: dimensionality (of data)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的维度
- en: feature selection
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征选择
- en: Minkowski distance
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 闵可夫斯基距离
- en: triangle inequality
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三角不等式
- en: Euclidean distance
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: Manhattan distance
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿距离
