- en: '22'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LIES, DAMNED LIES, AND STATISTICS
  prefs: []
  type: TYPE_NORMAL
- en: '*“If you can''t prove what you want to prove, demonstrate something else and
    pretend they are the same thing. In the daze that follows the collision of statistics
    with the human mind, hardly anyone will notice the difference.”*[*^(163)*](#c22-fn-0001)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Anyone can lie by simply making up fake statistics. Telling fibs with accurate
    statistics is more challenging, but still not difficult.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-5001.jpg](../images/c22-fig-5001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Statistical thinking is a relatively new invention. For most of recorded history,
    things were assessed qualitatively rather than quantitatively. People must have
    had an intuitive sense of some statistical facts (e.g., that women are usually
    shorter than men), but they had no mathematical tools that would allow them to
    proceed from anecdotal evidence to statistical conclusions. This started to change
    in the middle of the seventeenth century, most notably with the publication of
    John Graunt's *Natural and Political Observations Made Upon the Bills of Mortality*.
    This pioneering work used statistical analysis to estimate the population of London
    from death rolls and attempted to provide a model that could be used to predict
    the spread of plague.
  prefs: []
  type: TYPE_NORMAL
- en: Alas, since that time people have used statistics as much to mislead as to inform.
    Some have willfully used statistics to mislead; others have merely been incompetent.
    In this chapter we discuss some of the ways people can be led into drawing inappropriate
    inferences from statistical data. We trust that you will use this information
    only for good—to become a better consumer and a more honest purveyor of statistical
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 22.1 Garbage In Garbage Out (GIGO)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*“On two occasions I have been asked [by members of Parliament], ‘Pray, Mr.
    Babbage, if you put into the machine wrong figures, will the right answers come
    out?’ I am not able rightly to apprehend the kind of confusion of ideas that could
    provoke such a question.” — Charles Babbage*[*^(164)*](#c22-fn-0002)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The message here is a simple one. If the input data is seriously flawed, no
    amount of statistical massaging will produce a meaningful result.
  prefs: []
  type: TYPE_NORMAL
- en: The 1840 United States census showed that insanity among free blacks and mulattoes
    was roughly ten times more common than among enslaved blacks and mulattoes. The
    conclusion was obvious. As U.S. Senator (and former Vice President and future
    Secretary of State) John C. Calhoun put it, “The data on insanity revealed in
    this census is unimpeachable. From it our nation must conclude that the abolition
    of slavery would be to the African a curse.” Never mind that it was soon clear
    that the census was riddled with errors. As Calhoun reportedly explained to John
    Quincy Adams, “There were so many errors they balanced one another, and led to
    the same conclusion as if they were all correct.”
  prefs: []
  type: TYPE_NORMAL
- en: Calhoun's (perhaps willfully) spurious response to Adams was based on a classical
    error, the **assumption of independence**. Were he more sophisticated mathematically,
    he might have said something like, “I believe that the measurement errors are
    unbiased and independent of each other, and therefore evenly distributed on either
    side of the mean.” In fact, later analysis showed that the errors were so heavily
    biased that no statistically valid conclusions could be drawn.[^(165)](#c22-fn-0003)
  prefs: []
  type: TYPE_NORMAL
- en: GIGO is a particularly pernicious problem in the scientific literature—because
    it can be hard to detect. In May 2020, one of the world's most prestigious medical
    journals (*Lancet*) published a paper about the then raging Covid-19 pandemic.
    The paper relied on data about 96,000 patients collected from nearly 700 hospitals
    on six continents. During the review process, the reviewers checked the soundness
    of the analyses reported in the paper, but not the soundness of the data on which
    the analyses were based. Less than a month after publication, the paper was retracted
    based upon the discovery that the data on which it was based were flawed.
  prefs: []
  type: TYPE_NORMAL
- en: 22.2 Tests Are Imperfect
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every experiment should be viewed as a potentially flawed test. We can perform
    a test for a chemical, a phenomenon, a disease, etc. However, the event for which
    we are testing is not necessarily the same as the result of the test. Professors
    design exams with the goal of understanding how well a student has mastered some
    subject matter, but the result of the exam should not be confused with how much
    a student actually understands. Every test has some inherent error rate. Imagine
    that a student learning a second language has been asked to learn the meaning
    of `100` words, but has learned the meaning of only 80 of them. His rate of understanding
    is `80%`, but the probability that he will score 80% on a test with `20` words
    is certainly not `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Tests can have both false negatives and false positives. As we saw in Section
    21.7, a negative mammogram does not guarantee absence of breast cancer, and a
    positive mammogram doesn't guarantee its presence. Furthermore, the test probability
    and the event probability are not the same thing. This is especially relevant
    when testing for a rare event, e.g., the presence of a rare disease. If the cost
    of a false negative is high (e.g., missing the presence of a serious but curable
    disease), the test should be designed to be highly sensitive, even at the cost
    of many false positives.
  prefs: []
  type: TYPE_NORMAL
- en: 22.3 Pictures Can Be Deceiving
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There can be no doubt about the utility of graphics for quickly conveying information.
    However, when used carelessly (or maliciously), a plot can be highly misleading.
    Consider, for example, the charts in [Figure 22-1](#c22-fig-0002) depicting housing
    prices in the U.S. midwestern states.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0001.jpg](../images/c22-fig-0001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-1](#c22-fig-0002a) Housing prices in the U.S. Midwest'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the chart on the left of [Figure 22-1](#c22-fig-0002), it seems as
    if housing prices were pretty stable during the period 2006-2009\. But wait a
    minute! Wasn't there a collapse of U.S. residential real estate followed by a
    global financial crisis in late 2008? There was indeed, as shown in the chart
    on the right.
  prefs: []
  type: TYPE_NORMAL
- en: These two charts show exactly the same data, but convey very different impressions.
    The chart on the left was designed to give the impression that housing prices
    had been stable. On the y-axis, the designer used a scale ranging from the absurdly
    low average price for a house of `$1,000` to the improbably high average price
    of `$500,000`. This minimized the amount of space devoted to the area where prices
    are changing, giving the impression that the changes were relatively small. The
    chart on the right was designed to give the impression that housing prices moved
    erratically, and then crashed. The designer used a narrow range of prices, so
    the sizes of the changes were exaggerated.
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Figure 22-2](#c22-fig-0003) produces the two plots we looked at
    above and a plot intended to give an accurate impression of the movement of housing
    prices. It uses two plotting facilities that we have not yet seen.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0002.jpg](../images/c22-fig-0002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-2](#c22-fig-0003a) Plotting housing prices'
  prefs: []
  type: TYPE_NORMAL
- en: The call `plt.bar(quarters, prices, width)` produces a **bar chart** with bars
    of the given width. The left edges of the bars are the values of the elements
    of the list `quarters`, and the heights of the bars are the values of the corresponding
    elements of the list `prices`. The function call `plt.xticks(quarters+width/2,
    labels)` describes the labels to be associated with the bars. The first argument
    specifies the placement of each label and the second argument the text of the
    labels. The function `yticks` behaves analogously. The call `plot_housing('fair')`
    produces the plot in [Figure 22-3](#c22-fig-0004).
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0003.jpg](../images/c22-fig-0003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-3](#c22-fig-0004a) A different view of housing prices'
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: It is sometimes illuminating to plot things relative to
    a baseline, as seen in [Figure 22-4](#c22-fig-0005). Modify `plot_housing` to
    produce such plots. The bars below the baseline should be in red. Hint: use the
    `bottom` keyword argument to `plt.bar`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0004.jpg](../images/c22-fig-0004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-4](#c22-fig-0005a) Housing prices relative to $200,000'
  prefs: []
  type: TYPE_NORMAL
- en: A logarithmic y-axis provides a wonderful tool for making deceptive plots. Consider
    the bar graphs in [Figure 22-5](#c22-fig-0006). The plot on the left provides
    a more accurate impression of the difference in the number of people following
    khemric and katyperry. The presence of the sparsely followed jguttag in the plot
    on the right forces the y-axis to devote a larger proportion of its length to
    smaller values, thus leaving less distance to distinguish between the number of
    followers of khemric and katyperry.[^(166)](#c22-fn-0004)
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0005.jpg](../images/c22-fig-0005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-5](#c22-fig-0006a) Comparing number of Instagram followers'
  prefs: []
  type: TYPE_NORMAL
- en: 22.4 Cum Hoc Ergo Propter Hoc[^(167)](#c22-fn-0005)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It has been shown that college students who regularly attend class have higher
    average grades than students who attend class only sporadically. Those of us who
    teach these classes would like to believe that this is because the students learn
    something from the classes we teach. Of course, it is at least equally likely
    that those students get better grades because students who are more likely to
    attend classes are also more likely to study hard.
  prefs: []
  type: TYPE_NORMAL
- en: '**Correlation** is a measure of the degree to which two variables move in the
    same direction. If `x` moves in the same direction as y, the variables are positively
    correlated. If they move in opposite directions, they are negatively correlated.
    If there is no relationship, the correlation is `0`. People''s heights are positively
    correlated with the heights of their parents. The correlation between smoking
    and life span is negative.'
  prefs: []
  type: TYPE_NORMAL
- en: When two things are correlated, there is a temptation to assume that one has
    caused the other. Consider the incidence of flu in North America. The number of
    cases rises and falls in a predictable pattern. There are almost no cases in the
    summer; the number of cases starts to rise in the early fall and then starts dropping
    as summer approaches. Now consider the number of children attending school. There
    are very few children in school in the summer; enrollment starts to rise in the
    early fall and then drops as summer approaches.
  prefs: []
  type: TYPE_NORMAL
- en: The correlation between the opening of schools and the rise in the incidence
    of flu is inarguable. This has led some to conclude that going to school is an
    important causative factor in the spread of flu. That might be true, but we cannot
    conclude it based simply on the correlation. Correlation does not imply causation!
    After all, the correlation could be used just as easily to justify the belief
    that flu outbreaks cause schools to be in session. Or perhaps there is no causal
    relationship in either direction, and some **lurking variable** we have not considered
    causes each. In fact, as it happens, the flu virus survives considerably longer
    in cool dry air than it does in warm wet air, and in North America both the flu
    season and school sessions are correlated with cooler and dryer weather.
  prefs: []
  type: TYPE_NORMAL
- en: Given enough retrospective data, it is always possible to find two variables
    that are correlated, as illustrated by the chart in [Figure 22-6](#c22-fig-0007).[^(168)](#c22-fn-0006)
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0006.jpg](../images/c22-fig-0006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-6](#c22-fig-0007a) Do Mexican lemons save lives?'
  prefs: []
  type: TYPE_NORMAL
- en: When such correlations are found, the first thing to do is to ask whether there
    is a plausible theory explaining the correlation.
  prefs: []
  type: TYPE_NORMAL
- en: Falling prey to the *cum hoc ergo propter hoc* fallacy can be quite dangerous.
    At the start of 2002, roughly six million American women were being prescribed
    hormone replacement therapy (HRT) in the belief that it would substantially lower
    their risk of cardiovascular disease. That belief was supported by several highly
    reputable published studies that demonstrated a reduced incidence of cardiovascular
    death among women using HRT.
  prefs: []
  type: TYPE_NORMAL
- en: Many women, and their physicians, were taken by surprise when the *Journal of
    the American Medical Society* published an article asserting that HRT in fact
    increased the risk of cardiovascular disease.[^(169)](#c22-fn-0007) How could
    this have happened?
  prefs: []
  type: TYPE_NORMAL
- en: Reanalysis of some of the earlier studies showed that women undertaking HRT
    were likely to be from groups with better than average diet and exercise regimes.
    Perhaps the women undertaking HRT were on average more health conscious than the
    other women in the study, so that taking HRT and improved cardiac health were
    coincident effects of a common cause.
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: Over the last 100 years, the number of deaths per year
    in Canada was positively correlated with the amount of meat consumed per year
    in Canada. What lurking variable might explain this?'
  prefs: []
  type: TYPE_NORMAL
- en: 22.5 Statistical Measures Don't Tell the Whole Story
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An enormous number of different statistics can be extracted from a data set.
    By carefully choosing among these, it is possible to convey differing impressions
    about the same data. A good antidote is to look at the data set itself.
  prefs: []
  type: TYPE_NORMAL
- en: In 1973, the statistician F.J. Anscombe published a paper with the table in
    [Figure 22-7](#c22-fig-0008), often called Anscombe's quartet. It contains the
    `<x, y>` coordinates of points from each of four data sets. Each of the four data
    sets has the same mean value for `x` (`9.0`), the same mean value for `y` (`7.5`),
    the same variance for `x` (`10.0`), the same variance for `y` (`3.75`), and the
    same correlation between `x` and `y` (`0.816`). And if we use linear regression
    to fit a line to each, we get the same result for each, `y = 0.5x + 3`.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0007.jpg](../images/c22-fig-0007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-7](#c22-fig-0008a) Statistics for Anscombe''s quartet'
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that there is no obvious way to distinguish these data sets from
    each other? No. We simply need to plot the data to see that the data sets are
    not alike ([Figure 22-8](#c22-fig-0009)).
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0008.jpg](../images/c22-fig-0008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-8](#c22-fig-0009a) Data for Anscombe''s quartet'
  prefs: []
  type: TYPE_NORMAL
- en: 'The moral is simple: if possible, always take a look at some representation
    of the raw data.'
  prefs: []
  type: TYPE_NORMAL
- en: 22.6 Sampling Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: During World War II, whenever an Allied plane returned from a mission over Europe,
    the plane was inspected to see where the flak from antiaircraft artillery had
    impacted. Based upon this data, mechanics reinforced those areas of the planes
    that seemed most likely to be hit by flak.
  prefs: []
  type: TYPE_NORMAL
- en: What's wrong with this? They did not inspect the planes that failed to return
    from missions because they had been downed by flak. Perhaps these unexamined planes
    failed to return precisely because they were hit in the places where the flak
    would do the most damage. This particular error is called **non-response bias**.
    It is quite common in surveys. At many universities, for example, students are
    asked during one of the lectures late in the term to fill out a form rating the
    quality of the professor's lectures. Though the results of such surveys are often
    unflattering, they could be worse. Those students who think that the lectures
    are so bad that they aren't worth attending are not included in the survey.[^(170)](#c22-fn-0008)
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in Chapter 19, all statistical techniques are based upon the assumption
    that by sampling a subset of a population we can infer things about the population
    as a whole. If random sampling is used, we can make precise mathematical statements
    about the expected relationship of the sample to the entire population. Unfortunately,
    many studies, particularly in the social sciences, are based on what is called
    **convenience** (or **accidental**) **sampling**. This involves choosing samples
    based on how easy they are to procure. Why do so many psychological studies use
    populations of undergraduates? Because they are easy to find on college campuses.
    A convenience sample *might* be representative, but there is no way of knowing
    whether it actually *is* representative.
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: The **infection-fatality rate** for a disease is the number
    of people who contract the disease divided by the number of those people who die
    from the disease. The **case-fatality rate** for a disease is the number of people
    who are diagnosed with the disease divided by the number of those people who die
    from the disease. Which of these is easier to estimate accurately, and why?'
  prefs: []
  type: TYPE_NORMAL
- en: 22.7 Context Matters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is easy to read more into the data than it actually implies, especially when
    viewing the data out of context. On April 29, 2009, CNN reported that, “Mexican
    health officials suspect that the swine flu outbreak has caused more than `159`
    deaths and roughly `2,500` illnesses.” Pretty scary stuff—until we compare it
    to the approximately `36,000` deaths attributable annually to the seasonal flu
    in the U.S.
  prefs: []
  type: TYPE_NORMAL
- en: An often quoted, and accurate, statistic is that most auto accidents happen
    within `10` miles of home. So what? Most driving is done within `10` miles of
    home! Besides, what does “home” mean in this context? The statistic is computed
    using the address at which the automobile is registered as “home.” Might you reduce
    the probability of getting into an accident by merely registering your car in
    some distant place?
  prefs: []
  type: TYPE_NORMAL
- en: Opponents of government initiatives to reduce the prevalence of guns in the
    United States are fond of quoting the statistic that roughly `99.8%` of the firearms
    in the U.S. will not be used to commit a violent crime in any given year. But
    without some context, it's hard to know what that implies. Does it imply that
    there is not much gun violence in the U.S.? The National Rifle Association reports
    that there are roughly `300` million privately owned firearms in the U.S.—`0.2%`
    of `300` million is `600,000`!
  prefs: []
  type: TYPE_NORMAL
- en: 22.8 Comparing Apples to Oranges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Take a quick look at the image in [Figure 22-9](#c22-fig-0010).
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0009.jpg](../images/c22-fig-0009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-9](#c22-fig-0010a) Welfare vs. full-time jobs'
  prefs: []
  type: TYPE_NORMAL
- en: What impression does it leave you with? Are many more Americans on welfare than
    working?
  prefs: []
  type: TYPE_NORMAL
- en: The bar on the left is about 500% taller than the bar on the right. However,
    the numbers on the bars tell us that the y-axis has been truncated. If it had
    not been, the bar on the left would have been only 6.8% higher. Still, it is kind
    of shocking to think that 6.8% more people are on welfare than working. Shocking,
    and misleading.
  prefs: []
  type: TYPE_NORMAL
- en: The “people on welfare” number is derived from the U.S. Census Bureau's tally
    of people participating in means-tested programs. This tally includes anyone residing
    in a household where at least one person received any benefit. Consider, for example,
    a household containing two parents and three children in which one parent has
    a full-time job and the other a part-time job. If that household received food
    stamps, the household would add five people to the tally of “people on welfare”
    and one to the tally of full-time jobs.
  prefs: []
  type: TYPE_NORMAL
- en: Both numbers are “correct,” but they are not comparable. It's like concluding
    that Olga is a better farmer than Mark because she grows 20 tons of potatoes per
    acre whereas Mark grows only 3 tons of blueberries per acre.
  prefs: []
  type: TYPE_NORMAL
- en: 22.9 Picking Cherries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While we are on the subject of fruit, picking cherries is just as bad as comparing
    apples and oranges. **Cherry picking** involves choosing specific pieces of data,
    and ignoring others, for the purpose of supporting some position.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the plot in [Figure 22-10](#c22-fig-0011). The trend is pretty clear,
    but if we wish to argue that the planet is not warming using this data, we can
    cite the fact that there was more ice in April 2013 than in April of 1988, and
    ignore the rest of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0010.jpg](../images/c22-fig-0010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-10](#c22-fig-0011a) Sea ice in the Arctic'
  prefs: []
  type: TYPE_NORMAL
- en: 22.10 Beware of Extrapolation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is all too easy to extrapolate from data. We did that in Section 20.1.1 when
    we extended fits derived from linear regression beyond the data used in the regression.
    Extrapolation should be done only when you have a sound theoretical justification
    for doing so. Be especially wary of straight-line extrapolations.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the plot on the left in [Figure 22-11](#c22-fig-0012). It shows the
    growth of Internet usage in the United States from 1994 to 2000\. As you can see,
    a straight line provides a pretty good fit.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0011.jpg](../images/c22-fig-0011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-11](#c22-fig-0012a) Growth of Internet usage in U.S.'
  prefs: []
  type: TYPE_NORMAL
- en: The plot on the right of [Figure 22-11](#c22-fig-0012) uses this fit to project
    the percentage of the U.S. population using the Internet in following years. The
    projection is hard to believe. It seems unlikely that by 2009 everybody in the
    U.S. was using the Internet, and even less likely that by 2015 more than `140%`
    of the U.S. population was using the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: 22.11 The Texas Sharpshooter Fallacy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine that you are driving down a country road in Texas. You see a barn that
    has six targets painted on it, and a bullet hole at the very center of each target.
    “Yes sir,” says the owner of the barn, “I never miss.” “That's right,” says his
    spouse, “there ain't a man in the state of Texas who's more accurate with a paint
    brush.” Got it? He fired the six shots, and then painted the targets around them.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0012.jpg](../images/c22-fig-0012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 22-12 Professor puzzles over students' chalk-throwing accuracy
  prefs: []
  type: TYPE_NORMAL
- en: A classic of the genre appeared in 2001.[^(171)](#c22-fn-0009) It reported that
    a research team at the Royal Cornhill Hospital in Aberdeen had discovered that
    “anorexic women are most likely to have been born in the spring or early summer…
    Between March and June there were `13%` more anorexics born than average, and
    `30%` more in June itself.”
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at that worrisome statistic for those women born in June. The team
    studied `446` women who had been diagnosed as anorexic, so the mean number of
    births per month was slightly more than `37`. This suggests that the number born
    in June was `48 (37`*`1.3)`. Let's write a short program ([Figure 22-13](#c22-fig-0014))
    to estimate the probability that this occurred purely by chance.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0013.jpg](../images/c22-fig-0013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-13](#c22-fig-0014a) Probability of 48 anorexics being born in June'
  prefs: []
  type: TYPE_NORMAL
- en: When we ran `june_prob(10000)` it printed
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It looks as if the probability of at least `48` babies being born in June purely
    by chance is around `4.25%`. So perhaps those researchers in Aberdeen are on to
    something. Well, they might have been on to something had they started with the
    hypothesis that more babies who will become anorexic are born in June, and then
    run a study designed to check that hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: But that is not what they did. Instead, they looked at the data and then, imitating
    the Texas sharpshooter, drew a circle around June. The right statistical question
    to have asked is what is the probability that in at least one month (out of `12`)
    at least `48` babies were born. The program in [Figure 22-14](#c22-fig-0015) answers
    that question.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-0014.jpg](../images/c22-fig-0014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 22-14](#c22-fig-0015a) Probability of 48 anorexics being born in some
    month'
  prefs: []
  type: TYPE_NORMAL
- en: The call `any_prob(10000)` printed
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It appears that it is not so unlikely after all that the results reported in
    the study reflect a chance occurrence rather a real association between birth
    month and anorexia. One doesn't have to come from Texas to fall victim to the
    Texas Sharpshooter Fallacy.
  prefs: []
  type: TYPE_NORMAL
- en: The statistical significance of a result depends upon the way the experiment
    was conducted. If the Aberdeen group had started out with the hypothesis that
    more anorexics are born in June, their result would be worth considering. But
    if they started with the hypothesis that there exists a month in which an unusually
    large proportion of anorexics are born, their result is not very compelling. In
    effect, they were testing multiple hypotheses and cherry-picking a result. They
    probably should have applied a Bonferroni correction (see Section 21.6).
  prefs: []
  type: TYPE_NORMAL
- en: What next steps might the Aberdeen group have taken to test their newfound hypothesis?
    One possibility is to conduct a **prospective study**. In a prospective study,
    one starts with a set of hypotheses, recruits subjects before they have developed
    the outcome of interest (anorexia in this case), and then follows the subjects
    for a period of time. If the group had conducted a prospective study with a specific
    hypothesis and gotten similar results, we might be convinced.
  prefs: []
  type: TYPE_NORMAL
- en: Prospective studies can be expensive and time-consuming to perform. In a **retrospective
    study**, existing data must be analyzed in ways that reduce the likelihood of
    getting misleading results. One common technique, as discussed in Section 20.4,
    is to split the data into a training set and a held out test set. For example,
    they could have chosen `446/2` women at random from their data (the training set)
    and tallied the number of births for each month. They could have then compared
    that to the number of births each month for the remaining women (the holdout set).
  prefs: []
  type: TYPE_NORMAL
- en: 22.12 Percentages Can Confuse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An investment advisor called a client to report that the value of his stock
    portfolio had risen `16%` over the last month. The advisor admitted that there
    had been some ups and downs over the year but was pleased to report that the average
    monthly change was `+0.5%`. Imagine the client's surprise when he got his statement
    for the year and observed that the value of his portfolio had declined over the
    year.
  prefs: []
  type: TYPE_NORMAL
- en: He called his advisor and accused him of being a liar. “It looks to me,” he
    said, “like my portfolio declined by about `8%`, and you told me that it went
    up by `0.5%` a month.” “I did not,” the financial advisor replied. “I told you
    that the average monthly change was `+0.5%`.” When he examined his monthly statements,
    the investor realized that he had not been lied to, just misled. His portfolio
    went down by `15%` in each month during the first half of the year, and then went
    up by `16%` in each month during the second half of the year.
  prefs: []
  type: TYPE_NORMAL
- en: When thinking about percentages, we always need to pay attention to the basis
    on which the percentage is computed. In this case, the `15%` declines were on
    a higher average basis than the `16%` increases.
  prefs: []
  type: TYPE_NORMAL
- en: Percentages can be particularly misleading when applied to a small basis. You
    might read about a drug that has a side effect of increasing the incidence of
    some illness by `200%`. But if the base incidence of the disease is very low,
    say one in `1,000,000`, you might decide that the risk of taking the drug is more
    than counterbalanced by the drug's positive effects.
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: On May 19, 2020, the *New York Times* reported a 123%
    increase in U.S. air travel in a single month (from 95,161 passengers to 212,508
    passengers). It also reported that this increase followed a recent 96% drop in
    air travel. What was the total net percentage change?'
  prefs: []
  type: TYPE_NORMAL
- en: 22.13 The Regressive Fallacy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **regressive fallacy** occurs when people fail to account for the natural
    fluctuations of events.
  prefs: []
  type: TYPE_NORMAL
- en: All athletes have good days and bad days. When they have good days, they try
    not to change anything. When they have a series of unusually bad days, however,
    they often try to make changes. Even if the changes are not actually helpful,
    regression to the mean (Section 17.3) makes it likely that over the next few days
    the athlete's performance will be better than the unusually poor performances
    preceding the changes. This may mislead the athlete into assuming that there is
    a **treatment effect**, i.e., attributing the improved performance to the changes
    he or she made.
  prefs: []
  type: TYPE_NORMAL
- en: The Nobel prize-winning psychologist Daniel Kahneman tells a story about an
    Israeli Air Force flight instructor who rejected Kahneman's assertion that “rewards
    for improved performance work better than punishment for mistakes.” The instructor's
    argument was “On many occasions I have praised flights cadets for clean execution
    of some aerobatic maneuver. The next time they try the same maneuver they usually
    do worse. On the other hand, I have often screamed into a cadet's earphone for
    bad execution, and in general he does better on the next try.” [^(172)](#c22-fn-0010)
    It is natural for humans to imagine a treatment effect, because we like to think
    causally. But sometimes it is simply a matter of luck.
  prefs: []
  type: TYPE_NORMAL
- en: Imagining a treatment effect when there is none can be dangerous. It can lead
    to the belief that vaccinations are harmful, that snake oil cures all aches and
    pains, or that investing exclusively in funds that “beat the market” last year
    is a good strategy.
  prefs: []
  type: TYPE_NORMAL
- en: '![c22-fig-5002.jpg](../images/c22-fig-5002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 22.14 Statistically Significant Differences Can Be Insignificant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An admissions officer at the Maui Institute of Technology (MIT), wishing to
    convince the world that MIT's admissions process is “gender-blind,” trumpeted,
    “At MIT, there is no significant difference between the grade point averages of
    men and women.” The same day, an ardent female chauvinist proclaimed that “At
    MIT, the women have a significantly higher grade point average than the men.”
    A puzzled reporter at the student newspaper decided to examine the data and expose
    the liar. But when she finally managed to pry the data out of the university,
    she concluded that both were telling the truth.
  prefs: []
  type: TYPE_NORMAL
- en: What does the sentence “At MIT, the women have a significantly higher grade
    point average than the men,” actually mean? People who have not studied statistics
    (most of the population) would probably conclude that there is a “meaningful”
    difference between the GPAs of women and men attending MIT. In contrast, those
    who have recently studied statistics might conclude only that 1) the average GPA
    of women is higher than that of men, and 2) the null hypothesis that the difference
    in GPA can be attributed to randomness can be rejected at the `5%` level.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose, for example, that `2,500` women and `2,500` men were studying at MIT.
    Suppose further that the mean GPA of men was `3.5`, the mean GPA of women was
    `3.51`, and the standard deviation of the GPA for both men and women was `0.25`.
    Most sensible people would consider the difference in GPAs “insignificant.” However,
    from a statistical point of view the difference is “significant” at close to the
    `2%` level. What is the root of this strange dichotomy? As we showed in Section
    21.5, when a study has enough power—i.e., enough examples—even insignificant differences
    can be statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: A related problem arises when a study is very small. Suppose you flipped a coin
    twice and it came up heads both times. Now, let's use the two-tailed one-sample
    t-test we saw in Section 21.3 to test the null hypothesis that the coin is fair.
    If we assume that the value of heads is `1` and the value of tails is `0`, we
    can get the p-value using the code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It returns a p-value of `0`, indicating that if the coin is fair, the probability
    of getting two consecutive heads is nil. We would have gotten a different answer
    if we had taken a Bayesian approach starting with the prior that the coin is fair.
  prefs: []
  type: TYPE_NORMAL
- en: 22.15 Just Beware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It would be easy, and fun, to fill a few hundred pages with a history of statistical
    abuses. But by now you probably got the message: It''s just as easy to lie with
    numbers as it is to lie with words. Make sure that you understand what is actually
    being measured and how those “statistically significant” results were computed
    before you jump to conclusions. As the Nobel Prize winning economist Ronald Coase
    said, “If you torture the data long enough, it will confess to anything.”'
  prefs: []
  type: TYPE_NORMAL
- en: 22.16 Terms Introduced in Chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GIGO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: assumption of independence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: bar chart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: correlation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: causation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: lurking variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: non-response bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: convenience (accidental) sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: infection-fatality rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: case-fatality rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cherry picking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: prospective study
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: retrospective study
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: regressive fallacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: treatment effect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
