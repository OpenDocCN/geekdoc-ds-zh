- en: 15Â Halloween AnalysisğŸ”—
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15Â ä¸‡åœ£èŠ‚åˆ†æğŸ”—
- en: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/amortized-analysis.html](https://dcic-world.org/2025-08-27/amortized-analysis.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/amortized-analysis.html](https://dcic-world.org/2025-08-27/amortized-analysis.html)
- en: '| Â Â Â Â [15.1Â A First Example](#%28part._.A_.First_.Example%29) |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â [15.1Â ç¬¬ä¸€ä¸ªä¾‹å­](#%28part._.A_.First_.Example%29) |'
- en: '| Â Â Â Â [15.2Â The New Form of Analysis](#%28part._.The_.New_.Form_of_.Analysis%29)
    |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â [15.2Â æ–°çš„åˆ†ææ–¹æ³•](#(part._.The_.New_.Form_of_.Analysis%29) |'
- en: '| Â Â Â Â [15.3Â An Example: Queues from Lists](#%28part._queue-data-structure%29)
    |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â [15.3Â ä¸€ä¸ªä¾‹å­ï¼šä»åˆ—è¡¨åˆ°é˜Ÿåˆ—](#%28part._queue-data-structure%29) |'
- en: '| Â Â Â Â Â Â [15.3.1Â List Representations](#%28part._.List_.Representations%29)
    |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â Â Â [15.3.1Â åˆ—è¡¨è¡¨ç¤º](#%28part._.List_.Representations%29) |'
- en: '| Â Â Â Â Â Â [15.3.2Â A First Analysis](#%28part._.A_.First_.Analysis%29) |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â Â Â [15.3.2Â ç¬¬ä¸€æ¬¡åˆ†æ](#%28part._.A_.First_.Analysis%29) |'
- en: '| Â Â Â Â Â Â [15.3.3Â More Liberal Sequences of Operations](#%28part._.More_.Liberal_.Sequences_of_.Operations%29)
    |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â Â Â [15.3.3Â æ›´è‡ªç”±çš„æ“ä½œåºåˆ—](#%28part._.More_.Liberal_.Sequences_of_.Operations%29)
    |'
- en: '| Â Â Â Â Â Â [15.3.4Â A Second Analysis](#%28part._.A_.Second_.Analysis%29) |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â Â Â [15.3.4Â ç¬¬äºŒæ¬¡åˆ†æ](#(part._.A_.Second_.Analysis%29) |'
- en: '| Â Â Â Â Â Â [15.3.5Â Amortization Versus Individual Operations](#%28part._worst-case-ops-amort%29)
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â Â Â [15.3.5Â æ‘Šé”€ä¸å•ä¸ªæ“ä½œ](#(part._worst-case-ops-amort%29) |'
- en: '| Â Â Â Â [15.4Â Reading More](#%28part._.Reading_.More%29) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| Â Â Â Â [15.4Â é˜…è¯»æ›´å¤š](#%28part._.Reading_.More%29) |'
- en: In [Predicting Growth](predicting-growth.html), we introduced the idea of big-Oh
    complexity to measure the worst-case time of a computation. As we see in [Choosing
    Between Representations](sets-from-lists.html#%28part._choosing-set-reps%29),
    however, this is sometimes too coarse a bound when the complexity is heavily dependent
    on the exact sequence of operations run. Now, we will consider a different style
    of complexity analysis that better accommodates operation sequences.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [é¢„æµ‹å¢é•¿](predicting-growth.html) ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¤§Oå¤æ‚åº¦çš„æ¦‚å¿µï¼Œç”¨äºè¡¡é‡è®¡ç®—çš„æœ€åæƒ…å†µæ—¶é—´ã€‚ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ [é€‰æ‹©è¡¨ç¤ºå½¢å¼](sets-from-lists.html#%28part._choosing-set-reps%29)
    ä¸­çœ‹åˆ°çš„ï¼Œå½“å¤æ‚æ€§é«˜åº¦ä¾èµ–äºæ“ä½œçš„ç²¾ç¡®åºåˆ—æ—¶ï¼Œè¿™æœ‰æ—¶æ˜¯ä¸€ä¸ªè¿‡äºç²—ç•¥çš„ç•Œé™ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä¸€ç§ä¸åŒçš„å¤æ‚æ€§åˆ†ææ–¹æ³•ï¼Œå®ƒæ›´å¥½åœ°é€‚åº”æ“ä½œåºåˆ—ã€‚
- en: 15.1Â A First Example[ğŸ”—](#(part._.A_.First_.Example) "Link to here")
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1Â ç¬¬ä¸€ä¸ªä¾‹å­[ğŸ”—](#(part._.A_.First_.Example) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Consider, for instance, a set that starts out empty, followed by a sequence
    of \(k\) insertions and then \(k\) membership tests, and suppose we are using
    the representation without duplicates. Insertion time is proportional to the size
    of the set (and list); this is initially \(0\), then \(1\), and so on, until it
    reaches size \(k\). Therefore, the total cost of the sequence of insertions is
    \(k \cdot (k+1) / 2\). The membership tests cost \(k\) each in the worst case,
    because weâ€™ve inserted up to \(k\) distinct elements into the set. The total time
    is then
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ï¼Œä¾‹å¦‚ï¼Œä¸€ä¸ªå¼€å§‹ä¸ºç©ºçš„é›†åˆï¼Œç„¶åæ˜¯ \(k\) æ¬¡æ’å…¥å’Œ \(k\) æ¬¡æˆå‘˜èµ„æ ¼æµ‹è¯•çš„åºåˆ—ï¼Œå‡è®¾æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æ— é‡å¤çš„è¡¨ç¤ºã€‚æ’å…¥æ—¶é—´ä¸é›†åˆï¼ˆå’Œåˆ—è¡¨ï¼‰çš„å¤§å°æˆæ¯”ä¾‹ï¼›æœ€åˆæ˜¯
    \(0\)ï¼Œç„¶åæ˜¯ \(1\)ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°è¾¾åˆ°å¤§å° \(k\)ã€‚å› æ­¤ï¼Œæ’å…¥åºåˆ—çš„æ€»æˆæœ¬æ˜¯ \(k \cdot (k+1) / 2\)ã€‚æœ€åæƒ…å†µä¸‹çš„æˆå‘˜èµ„æ ¼æµ‹è¯•æˆæœ¬ä¸º
    \(k\)ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å°†æœ€å¤š \(k\) ä¸ªä¸åŒçš„å…ƒç´ æ’å…¥åˆ°é›†åˆä¸­ã€‚å› æ­¤ï¼Œæ€»æ—¶é—´æ˜¯
- en: \begin{equation*}k^2 / 2 + k / 2 + k^2\end{equation*}
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation*}k^2 / 2 + k / 2 + k^2\end{equation*}
- en: for a total of \(2k\) operations, yielding an average of
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»å…± \(2k\) æ¬¡æ“ä½œï¼Œå¹³å‡ä¸º
- en: \begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}
- en: steps per operation in the worst case.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åæƒ…å†µä¸‹çš„æ¯ä¸ªæ“ä½œæ­¥éª¤ã€‚
- en: 15.2Â The New Form of Analysis[ğŸ”—](#(part._.The_.New_.Form_of_.Analysis) "Link
    to here")
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.2Â æ–°çš„åˆ†ææ–¹æ³•[ğŸ”—](#(part._.The_.New_.Form_of_.Analysis) "é“¾æ¥åˆ°æ­¤å¤„")
- en: What have we computed? We are still computing a worst case cost, because we
    have taken the cost of each operation in the sequence in the worst case. We are
    then computing the average cost per operation. Therefore, this is a average of
    worst cases.Importantly, this is different from what is known as average-case
    analysis, which uses probability theory to compute the estimated cost of the computation.
    We have not used any probability here. Note that because this is an average per
    operation, it does not say anything about how bad any one operation can be (which,
    as we will see [[Amortization Versus Individual Operations](#%28part._worst-case-ops-amort%29)],
    can be quite a bit worse); it only says what their average is.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¡ç®—äº†ä»€ä¹ˆï¼Ÿæˆ‘ä»¬ä»åœ¨è®¡ç®—æœ€åæƒ…å†µä¸‹çš„æˆæœ¬ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æŒ‰ç…§æœ€åæƒ…å†µè€ƒè™‘äº†åºåˆ—ä¸­æ¯ä¸ªæ“ä½œçš„æˆæœ¬ã€‚ç„¶åæˆ‘ä»¬è®¡ç®—æ¯ä¸ªæ“ä½œçš„å¹³å‡æˆæœ¬ã€‚å› æ­¤ï¼Œè¿™æ˜¯æœ€åæƒ…å†µä¸‹çš„å¹³å‡å€¼ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™ä¸æ‰€è°“çš„å¹³å‡æƒ…å†µåˆ†æä¸åŒï¼Œåè€…ä½¿ç”¨æ¦‚ç‡è®ºæ¥è®¡ç®—è®¡ç®—çš„ä¼°è®¡æˆæœ¬ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ä»»ä½•æ¦‚ç‡ã€‚è¯·æ³¨æ„ï¼Œå› ä¸ºè¿™æ˜¯æ¯ä¸ªæ“ä½œçš„å¹³å‡å€¼ï¼Œå®ƒå¹¶æ²¡æœ‰è¯´æ˜ä»»ä½•å•ä¸ªæ“ä½œå¯èƒ½æœ‰å¤šç³Ÿç³•ï¼ˆæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„
    [[æ‘Šé”€ä¸å•ä¸ªæ“ä½œ](#(part._worst-case-ops-amort%29)]ï¼Œå¯èƒ½ç›¸å½“ç³Ÿç³•ï¼‰ï¼›å®ƒåªè¯´æ˜äº†å®ƒä»¬çš„å¹³å‡å€¼ã€‚
- en: In the above case, this new analysis did not yield any big surprises. We have
    found that on average we spend about \(k\) steps per operation; a big-Oh analysis
    would have told us that weâ€™re performing \(2k\) operations with a cost of \(O([k
    \rightarrow k])\) each in the number of distinct elements; per operation, then,
    we are performing roughly linear work in the worst-case number of set elements.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°æƒ…å†µä¸‹ï¼Œè¿™ç§æ–°çš„åˆ†æå¹¶æ²¡æœ‰å¸¦æ¥ä»»ä½•å¤§çš„æƒŠå–œã€‚æˆ‘ä»¬å‘ç°å¹³å‡æ¯æ¬¡æ“ä½œæˆ‘ä»¬èŠ±è´¹å¤§çº¦\(k\)æ­¥ï¼›å¤§Oåˆ†æä¼šå‘Šè¯‰æˆ‘ä»¬æˆ‘ä»¬åœ¨æ¯ä¸ªä¸åŒå…ƒç´ ä¸Šæ‰§è¡Œäº†\(2k\)æ¬¡æ“ä½œï¼Œæ¯æ¬¡æ“ä½œçš„æˆæœ¬ä¸º\(O([k
    \rightarrow k])\)ï¼›å› æ­¤ï¼Œæ¯æ¬¡æ“ä½œï¼Œæˆ‘ä»¬åœ¨æœ€åæƒ…å†µä¸‹é›†åˆå…ƒç´ çš„æ•°é‡ä¸Šæ‰§è¡Œçš„å·¥ä½œå¤§è‡´æ˜¯çº¿æ€§çš„ã€‚
- en: 'As we will soon see, however, this wonâ€™t always be the case: this new analysis
    can cough up pleasant surprises.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°çš„ï¼Œè¿™å¹¶ä¸æ€»æ˜¯æƒ…å†µï¼šè¿™ç§æ–°çš„åˆ†æå¯èƒ½ä¼šå¸¦æ¥æ„æƒ³ä¸åˆ°çš„æƒŠå–œã€‚
- en: Before we proceed, we should give this analysis its name. Formally, it is called
    amortized analysis. Amortization is the process of spreading a payment out over
    an extended but fixed term. In the same way, we spread out the cost of a computation
    over a fixed sequence, then determine how much each payment will be.We have given
    it a whimsical name because [Halloween](http://en.wikipedia.org/wiki/Halloween)
    is a(n American) holiday devoted to ghosts, ghouls, and other symbols of death.
    Amortization comes from the Latin root mort-, which means death, because an amortized
    analysis is one conducted â€œat the deathâ€, i.e., at the end of a fixed sequence
    of operations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥ç»™è¿™ç§åˆ†æèµ·ä¸€ä¸ªåå­—ã€‚æ­£å¼æ¥è¯´ï¼Œå®ƒè¢«ç§°ä¸ºæ‘Šé”€åˆ†æã€‚æ‘Šé”€æ˜¯å°†æ”¯ä»˜åˆ†æ•£åˆ°å»¶é•¿ä½†å›ºå®šæœŸé™çš„è¿‡ç¨‹ã€‚åŒæ ·ï¼Œæˆ‘ä»¬å°†è®¡ç®—çš„æˆæœ¬åˆ†æ•£åˆ°å›ºå®šåºåˆ—ä¸­ï¼Œç„¶åç¡®å®šæ¯æ¬¡æ”¯ä»˜çš„é‡‘é¢ã€‚æˆ‘ä»¬ç»™å®ƒèµ·äº†ä¸€ä¸ªå¤æ€ªçš„åå­—ï¼Œå› ä¸º[ä¸‡åœ£èŠ‚](http://en.wikipedia.org/wiki/Halloween)æ˜¯ä¸€ä¸ªï¼ˆç¾å›½çš„ï¼‰èŠ‚æ—¥ï¼Œè‡´åŠ›äºé¬¼é­‚ã€æ¶é­”å’Œå…¶ä»–æ­»äº¡è±¡å¾ã€‚æ‘Šé”€æ¥è‡ªæ‹‰ä¸è¯­è¯æ ¹mort-ï¼Œæ„ä¸ºæ­»äº¡ï¼Œå› ä¸ºæ‘Šé”€åˆ†ææ˜¯åœ¨â€œæ­»äº¡â€æ—¶è¿›è¡Œçš„ï¼Œå³åœ¨å›ºå®šæ“ä½œåºåˆ—çš„æœ«å°¾ã€‚
- en: '15.3Â An Example: Queues from Lists[ğŸ”—](#(part._queue-data-structure) "Link to
    here")'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3Â ä¸€ä¸ªä¾‹å­ï¼šä»åˆ—è¡¨ä¸­åˆ›å»ºé˜Ÿåˆ—[ğŸ”—](#(part._queue-data-structure) "é“¾æ¥è‡³æ­¤")
- en: 'We have seen lists [[From Tables to Lists](tables-to-lists.html)] and sets
    [[Several Variations on Sets](part_sets.html)]. Here we focus on queues, which
    too can be represented as lists: [Queues from Lists](queues-from-lists.html).
    If you have not read that material, itâ€™s worth reading at least the early portions
    now. In this section, we will ignore the various programming niceties discussed
    there, and focus on raw list representations to make an algorithmic point.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†åˆ—è¡¨[[ä»è¡¨æ ¼åˆ°åˆ—è¡¨](tables-to-lists.html)]å’Œé›†åˆ[[é›†åˆçš„å‡ ç§å˜ä½“](part_sets.html)]ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸“æ³¨äºé˜Ÿåˆ—ï¼Œé˜Ÿåˆ—ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºåˆ—è¡¨ï¼š[ä»åˆ—è¡¨ä¸­åˆ›å»ºé˜Ÿåˆ—](queues-from-lists.html)ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰é˜…è¯»é‚£éƒ¨åˆ†å†…å®¹ï¼Œç°åœ¨è‡³å°‘é˜…è¯»å‰é¢çš„éƒ¨åˆ†æ˜¯å€¼å¾—çš„ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¿½ç•¥é‚£é‡Œè®¨è®ºçš„å„ç§ç¼–ç¨‹ç»†èŠ‚ï¼Œå¹¶ä¸“æ³¨äºåŸå§‹åˆ—è¡¨è¡¨ç¤ºæ¥é˜è¿°ç®—æ³•è§‚ç‚¹ã€‚
- en: 15.3.1Â List Representations[ğŸ”—](#(part._.List_.Representations) "Link to here")
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.1Â åˆ—è¡¨è¡¨ç¤º[ğŸ”—](#(part._.List_.Representations) "é“¾æ¥è‡³æ­¤")
- en: 'Consider two natural ways of defining queues using lists. One is that every
    enqueue is implemented with `link`, while every dequeue requires traversing the
    whole list until its end. Conversely, we could make enqueuing traverse to the
    end, and dequeuing correspond to `.rest`. Either way, one of these operations
    will take constant time while the other will be linear in the length of the list
    representing the queue. (This should be loosely reminiscent of trade-offs we ran
    into when representing sets as lists: [Representing Sets as Lists](sets-from-lists.html).)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä¸¤ç§ä½¿ç”¨åˆ—è¡¨å®šä¹‰é˜Ÿåˆ—çš„è‡ªç„¶æ–¹æ³•ã€‚ä¸€ç§æ–¹æ³•æ˜¯åœ¨æ¯æ¬¡å…¥é˜Ÿæ“ä½œä¸­ä½¿ç”¨`link`ï¼Œè€Œæ¯æ¬¡å‡ºé˜Ÿæ“ä½œåˆ™éœ€è¦éå†æ•´ä¸ªåˆ—è¡¨ç›´åˆ°å…¶æœ«å°¾ã€‚ç›¸åï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®©å…¥é˜Ÿæ“ä½œéå†åˆ°æœ«å°¾ï¼Œè€Œå‡ºé˜Ÿæ“ä½œå¯¹åº”äº`.rest`ã€‚æ— è®ºå“ªç§æ–¹å¼ï¼Œè¿™äº›æ“ä½œä¸­çš„ä¸€ç§å°†éœ€è¦å¸¸æ•°æ—¶é—´ï¼Œè€Œå¦ä¸€ç§å°†çº¿æ€§ä¾èµ–äºè¡¨ç¤ºé˜Ÿåˆ—çš„åˆ—è¡¨é•¿åº¦ã€‚ï¼ˆè¿™åº”è¯¥ä¼šè®©äººè”æƒ³åˆ°æˆ‘ä»¬åœ¨å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨æ—¶é‡åˆ°çš„æƒè¡¡ï¼š[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)ã€‚ï¼‰
- en: In fact, however, the above paragraph contains a key insight that will let us
    do better.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œäº‹å®ä¸Šï¼Œä¸Šè¿°æ®µè½åŒ…å«äº†ä¸€ä¸ªå…³é”®çš„æ´è§ï¼Œè¿™å°†ä½¿æˆ‘ä»¬åšå¾—æ›´å¥½ã€‚
- en: Observe that if we store the queue in a list with most-recently-enqueued element
    first, enqueuing is cheap (constant time). In contrast, if we store the queue
    in the reverse order, then dequeuing is constant time. It would be wonderful if
    we could have both, but once we pick an order we must give up one or the other.
    Unless, that is, we pick...both.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬ä»¥æœ€è¿‘å…¥é˜Ÿçš„å…ƒç´ ä¸ºé¦–ä½å­˜å‚¨é˜Ÿåˆ—åˆ°åˆ—è¡¨ä¸­ï¼Œå…¥é˜Ÿæ“ä½œå°†éå¸¸ä¾¿å®œï¼ˆå¸¸æ•°æ—¶é—´ï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬ä»¥ç›¸åçš„é¡ºåºå­˜å‚¨é˜Ÿåˆ—ï¼Œé‚£ä¹ˆå‡ºé˜Ÿæ“ä½œå°†æ˜¯å¸¸æ•°æ—¶é—´ã€‚å¦‚æœæˆ‘ä»¬å¯ä»¥åŒæ—¶æ‹¥æœ‰è¿™ä¸¤ç§æƒ…å†µï¼Œé‚£å°†æ˜¯æå¥½çš„ï¼Œä½†ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†ä¸€ç§é¡ºåºï¼Œæˆ‘ä»¬å°±å¿…é¡»æ”¾å¼ƒå…¶ä¸­ä¹‹ä¸€ã€‚é™¤éï¼Œé‚£å°±æ˜¯ï¼Œæˆ‘ä»¬é€‰æ‹©â€¦â€¦ä¸¤è€…ã€‚
- en: 'One half of this is easy. We simply enqueue elements into a list with the most
    recent addition first. Now for the (first) crucial insight: when we need to dequeue,
    we reverse the list. Now, dequeuing also takes constant time.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€åŠå¾ˆç®€å•ã€‚æˆ‘ä»¬åªéœ€å°†å…ƒç´ å…¥é˜Ÿåˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œæœ€æ–°çš„æ·»åŠ åœ¨ç¬¬ä¸€ä¸ªä½ç½®ã€‚ç°åœ¨ï¼Œå¯¹äºï¼ˆç¬¬ä¸€æ¬¡ï¼‰å…³é”®çš„æ´è§ï¼šå½“æˆ‘ä»¬éœ€è¦å‡ºé˜Ÿæ—¶ï¼Œæˆ‘ä»¬åè½¬åˆ—è¡¨ã€‚ç°åœ¨ï¼Œå‡ºé˜Ÿæ“ä½œä¹Ÿä¿æŒæ’å®šæ—¶é—´ã€‚
- en: 15.3.2Â A First Analysis[ğŸ”—](#(part._.A_.First_.Analysis) "Link to here")
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.2Â åˆæ­¥åˆ†æ[ğŸ”—](#(part._.A_.First_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: Of course, to fully analyze the complexity of this data structure, we must also
    account for the reversal. In the worst case, we might argue that any operation
    might reverse (because it might be the first dequeue); therefore, the worst-case
    time of any operation is the time it takes to reverse, which is linear in the
    length of the list (which corresponds to the elements of the queue).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä¸ºäº†å®Œå…¨åˆ†æè¿™ä¸ªæ•°æ®ç»“æ„çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘åè½¬æ“ä½œã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥äº‰è®ºä»»ä½•æ“ä½œéƒ½å¯èƒ½åè½¬ï¼ˆå› ä¸ºå®ƒå¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡å‡ºé˜Ÿï¼‰ï¼›å› æ­¤ï¼Œä»»ä½•æ“ä½œçš„æœ€åæƒ…å†µæ—¶é—´å°±æ˜¯åè½¬æ‰€éœ€çš„æ—¶é—´ï¼Œè¿™æ˜¯ä¸åˆ—è¡¨é•¿åº¦æˆçº¿æ€§å…³ç³»çš„ï¼ˆå¯¹åº”äºé˜Ÿåˆ—çš„å…ƒç´ ï¼‰ã€‚
- en: However, this answer should be unsatisfying. If we perform \(k\) enqueues followed
    by \(k\) dequeues, then each of the enqueues takes one step; each of the last
    \(k-1\) dequeues takes one step; and only the first dequeue requires a reversal,
    which takes steps proportional to the number of elements in the list, which at
    that point is \(k\). Thus, the total cost of operations for this sequence is \(k
    \cdot 1 + k + (k-1) \cdot 1 = 3k-1\) for a total of \(2k\) operations, giving
    an amortized complexity of effectively constant time per operation!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ä¸ªç­”æ¡ˆå¯èƒ½ä¸ä¼šä»¤äººæ»¡æ„ã€‚å¦‚æœæˆ‘ä»¬æ‰§è¡Œ \(k\) æ¬¡å…¥é˜Ÿæ“ä½œï¼Œç„¶åæ‰§è¡Œ \(k\) æ¬¡å‡ºé˜Ÿæ“ä½œï¼Œé‚£ä¹ˆæ¯æ¬¡å…¥é˜Ÿæ“ä½œéœ€è¦ä¸€æ­¥ï¼›æœ€å \(k-1\)
    æ¬¡å‡ºé˜Ÿæ“ä½œæ¯æ¬¡ä¹Ÿéœ€è¦ä¸€æ­¥ï¼›åªæœ‰ç¬¬ä¸€æ¬¡å‡ºé˜Ÿéœ€è¦åè½¬ï¼Œè¿™éœ€è¦ä¸åˆ—è¡¨ä¸­å…ƒç´ æ•°é‡æˆæ¯”ä¾‹çš„æ­¥éª¤ï¼Œåœ¨é‚£ä¸ªæ—¶åˆ»æ˜¯ \(k\)ã€‚å› æ­¤ï¼Œè¿™ä¸ªæ“ä½œåºåˆ—çš„æ€»æˆæœ¬æ˜¯ \(k \cdot
    1 + k + (k-1) \cdot 1 = 3k-1\)ï¼Œæ€»å…± \(2k\) æ¬¡æ“ä½œï¼Œç»™å‡ºæ¯æ“ä½œå¹³å‡æ’å®šæ—¶é—´çš„å¤æ‚åº¦ï¼
- en: 15.3.3Â More Liberal Sequences of Operations[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations)
    "Link to here")
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.3Â æ›´è‡ªç”±çš„æ“ä½œåºåˆ—[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations) "é“¾æ¥è‡³æ­¤")
- en: 'In the process of this, however, weâ€™ve quietly glossed over something that
    you may not have picked up on: in our candidate sequence all dequeues followed
    all enqueues. What happens on the next enqueue? Because the list is now reversed,
    it will have to take a linear amount of time! So we have only partially solved
    the problem.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é»˜é»˜åœ°å¿½ç•¥äº†ä¸€äº›ä½ å¯èƒ½æ²¡æœ‰æ³¨æ„åˆ°çš„äº‹æƒ…ï¼šåœ¨æˆ‘ä»¬çš„å€™é€‰åºåˆ—ä¸­ï¼Œæ‰€æœ‰çš„å‡ºé˜Ÿæ“ä½œéƒ½è·Ÿéšç€æ‰€æœ‰çš„å…¥é˜Ÿæ“ä½œã€‚ä¸‹ä¸€ä¸ªå…¥é˜Ÿæ“ä½œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå› ä¸ºåˆ—è¡¨ç°åœ¨è¢«åè½¬äº†ï¼Œå®ƒå°†éœ€è¦çº¿æ€§æ—¶é—´ï¼æ‰€ä»¥ï¼Œæˆ‘ä»¬åªæ˜¯éƒ¨åˆ†è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: 'Now we can introduce the second insight: have two lists instead of one. One
    of them will be the tail of the queue, where new elements get enqueued; the other
    will be the head of the queue, where they get dequeued:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼•å…¥ç¬¬äºŒä¸ªæ´è§ï¼šæœ‰ä¸¤ä¸ªåˆ—è¡¨è€Œä¸æ˜¯ä¸€ä¸ªã€‚å…¶ä¸­ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å°¾éƒ¨ï¼Œæ–°å…ƒç´ åœ¨è¿™é‡Œå…¥é˜Ÿï¼›å¦ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å¤´éƒ¨ï¼Œå…ƒç´ åœ¨è¿™é‡Œå‡ºé˜Ÿï¼š
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Provided the tail is stored so that the most recent element is the first, then
    enqueuing takes constant time:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å°¾éƒ¨å­˜å‚¨çš„æ–¹å¼æ˜¯æœ€æ–°çš„å…ƒç´ åœ¨ç¬¬ä¸€ä¸ªä½ç½®ï¼Œé‚£ä¹ˆå…¥é˜Ÿæ“ä½œå°†ä¿æŒæ’å®šæ—¶é—´ï¼š
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For dequeuing to take constant time, the head of the queue must be stored in
    the reverse direction. However, how does any element ever get from the tail to
    the head? Easy: when we try to dequeue and find no elements in the head, we reverse
    the (entire) tail into the head (resulting in an empty tail). We will first define
    a datatype to represent the response from dequeuing:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿å‡ºé˜Ÿæ“ä½œçš„æ—¶é—´ä¿æŒæ’å®šï¼Œé˜Ÿåˆ—çš„å¤´éƒ¨å¿…é¡»ä»¥ç›¸åçš„æ–¹å‘å­˜å‚¨ã€‚ç„¶è€Œï¼Œä»»ä½•å…ƒç´ æ˜¯å¦‚ä½•ä»å°¾éƒ¨åˆ°è¾¾å¤´éƒ¨çš„å‘¢ï¼Ÿç®€å•ï¼šå½“æˆ‘ä»¬å°è¯•å‡ºé˜Ÿä½†å¤´éƒ¨æ²¡æœ‰å…ƒç´ æ—¶ï¼Œæˆ‘ä»¬å°†ï¼ˆæ•´ä¸ªï¼‰å°¾éƒ¨åè½¬åˆ°å¤´éƒ¨ï¼ˆä»è€Œäº§ç”Ÿä¸€ä¸ªç©ºå°¾éƒ¨ï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ªæ•°æ®ç±»å‹æ¥è¡¨ç¤ºå‡ºé˜Ÿæ“ä½œçš„å“åº”ï¼š
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now for the implementation of `dequeue`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¥å®ç°`dequeue`ï¼š
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 15.3.4Â A Second Analysis[ğŸ”—](#(part._.A_.Second_.Analysis) "Link to here")
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.4Â ç¬¬äºŒæ¬¡åˆ†æ[ğŸ”—](#(part._.A_.Second_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: We can now reason about sequences of operations as we did before, by adding
    up costs and averaging. However, another way to think of it is this. Letâ€™s give
    each element in the queue three â€œcreditsâ€. Each credit can be used for one constant-time
    operation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥åƒä»¥å‰ä¸€æ ·æ¨ç†æ“ä½œåºåˆ—ï¼Œé€šè¿‡ç´¯åŠ æˆæœ¬å¹¶å–å¹³å‡å€¼ã€‚ç„¶è€Œï¼Œå¦ä¸€ç§æ€è€ƒæ–¹å¼æ˜¯è¿™æ ·çš„ã€‚è®©æˆ‘ä»¬ç»™é˜Ÿåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ åˆ†é…ä¸‰ä¸ªâ€œä¿¡ç”¨â€ã€‚æ¯ä¸ªä¿¡ç”¨å¯ä»¥ç”¨äºä¸€ä¸ªæ’å®šæ—¶é—´çš„æ“ä½œã€‚
- en: One credit gets used up in enqueuing. So long as the element stays in the tail
    list, it still has two credits to spare. When it needs to be moved to the head
    list, it spends one more credit in the link step of reversal. Finally, the dequeuing
    operation performs one operation too.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å…¥é˜Ÿæ“ä½œä¼šæ¶ˆè€—ä¸€ä¸ªä¿¡ç”¨ã€‚åªè¦å…ƒç´ ä¿æŒåœ¨å°¾åˆ—è¡¨ä¸­ï¼Œå®ƒä»ç„¶æœ‰é¢å¤–çš„ä¸¤ä¸ªä¿¡ç”¨ã€‚å½“å®ƒéœ€è¦ç§»åŠ¨åˆ°å¤´åˆ—è¡¨æ—¶ï¼Œå®ƒä¼šåœ¨åè½¬æ­¥éª¤ä¸­å†æ¶ˆè€—ä¸€ä¸ªä¿¡ç”¨ã€‚æœ€åï¼Œå‡ºé˜Ÿæ“ä½œæ‰§è¡Œä¸€ä¸ªé¢å¤–çš„æ“ä½œã€‚
- en: Because the element does not run out of credits, we know it must have had enough.
    These credits reflect the cost of operations on that element. From this (very
    informal) analysis, we can conclude that in the worst case, any permutation of
    enqueues and dequeues will still cost only a constant amount of amortized time.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå…ƒç´ æ²¡æœ‰è€—å°½ä¿¡ç”¨ï¼Œæˆ‘ä»¬çŸ¥é“å®ƒå¿…é¡»æœ‰è¶³å¤Ÿçš„ä¿¡ç”¨ã€‚è¿™äº›ä¿¡ç”¨åæ˜ äº†å¯¹è¯¥å…ƒç´ çš„æ“ä½œæˆæœ¬ã€‚ä»è¿™ä¸ªï¼ˆéå¸¸éæ­£å¼çš„ï¼‰åˆ†æä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œåœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œä»»ä½•å…¥é˜Ÿå’Œå‡ºé˜Ÿçš„æ’åˆ—éƒ½å°†ä»…èŠ±è´¹å¸¸æ•°æ‘Šé”€æ—¶é—´ã€‚
- en: 15.3.5Â Amortization Versus Individual Operations[ğŸ”—](#(part._worst-case-ops-amort)
    "Link to here")
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.5Â æ‘Šé”€ä¸å•ä¸ªæ“ä½œ[ğŸ”—](#(part._worst-case-ops-amort) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Note, however, that the constant represents an average across the sequence of
    operations. It does not put a bound on the cost of any one operation. Indeed,
    as we have seen above, when dequeue finds the head list empty it reverses the
    tail, which takes time linear in the size of the tailâ€”<wbr>not constant at all!
    Therefore, we should be careful to not assume that every step in the sequence
    will is bounded. Nevertheless, an amortized analysis sometimes gives us a much
    more nuanced understanding of the real behavior of a data structure than a worst-case
    analysis does on its own.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªå¸¸æ•°ä»£è¡¨çš„æ˜¯æ“ä½œåºåˆ—çš„å¹³å‡å€¼ã€‚å®ƒå¹¶ä¸å¯¹ä»»ä½•å•ä¸ªæ“ä½œçš„æˆæœ¬æ–½åŠ é™åˆ¶ã€‚å®é™…ä¸Šï¼Œæ­£å¦‚æˆ‘ä»¬ä¸Šé¢æ‰€çœ‹åˆ°çš„ï¼Œå½“å‡ºåˆ—æ“ä½œå‘ç°å¤´åˆ—è¡¨ä¸ºç©ºæ—¶ï¼Œå®ƒä¼šåè½¬å°¾ï¼Œè¿™éœ€è¦ä¸å°¾çš„å¤§å°æˆçº¿æ€§å…³ç³»çš„æ—¶é—´â€”â€”æ ¹æœ¬ä¸æ˜¯å¸¸æ•°ï¼å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥å°å¿ƒï¼Œä¸è¦å‡è®¾åºåˆ—ä¸­çš„æ¯ä¸€æ­¥éƒ½ä¼šå—åˆ°é™åˆ¶ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ‘Šé”€åˆ†ææœ‰æ—¶èƒ½è®©æˆ‘ä»¬æ¯”å•ç‹¬çš„æœ€åæƒ…å†µåˆ†ææ›´æ·±å…¥åœ°ç†è§£æ•°æ®ç»“æ„çš„å®é™…è¡Œä¸ºã€‚
- en: 15.4Â Reading More[ğŸ”—](#(part._.Reading_.More) "Link to here")
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4Â é˜…è¯»æ›´å¤š[ğŸ”—](#(part._.Reading_.More) "é“¾æ¥åˆ°æ­¤å¤„")
- en: At this point we have only briefly touched on the subject of amortized analysis.
    A very nice [tutorial by Rebecca Fiebrink](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)
    provides much more information. The authoritative book on algorithms, Introduction
    to Algorithms by Cormen, Leiserson, Rivest, and Stein, covers amortized analysis
    in extensive detail.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬åªæ˜¯ç®€è¦åœ°è§¦åŠäº†æ‘Šé”€åˆ†æçš„ä¸»é¢˜ã€‚Rebecca Fiebrinkçš„ä¸€ä¸ªéå¸¸å¥½çš„[æ•™ç¨‹](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)æä¾›äº†æ›´å¤šä¿¡æ¯ã€‚å…³äºç®—æ³•çš„æƒå¨ä¹¦ç±ï¼ŒCormenã€Leisersonã€Rivestå’ŒSteinåˆè‘—çš„ã€Šç®—æ³•å¯¼è®ºã€‹ï¼Œè¯¦ç»†ä»‹ç»äº†æ‘Šé”€åˆ†æã€‚
- en: 15.1Â A First Example[ğŸ”—](#(part._.A_.First_.Example) "Link to here")
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1Â ç¬¬ä¸€ä¸ªä¾‹å­[ğŸ”—](#(part._.A_.First_.Example) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Consider, for instance, a set that starts out empty, followed by a sequence
    of \(k\) insertions and then \(k\) membership tests, and suppose we are using
    the representation without duplicates. Insertion time is proportional to the size
    of the set (and list); this is initially \(0\), then \(1\), and so on, until it
    reaches size \(k\). Therefore, the total cost of the sequence of insertions is
    \(k \cdot (k+1) / 2\). The membership tests cost \(k\) each in the worst case,
    because weâ€™ve inserted up to \(k\) distinct elements into the set. The total time
    is then
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªå¼€å§‹ä¸ºç©ºçš„é›†åˆï¼Œç„¶åæ˜¯\(k\)æ¬¡æ’å…¥å’Œ\(k\)æ¬¡æˆå‘˜èµ„æ ¼æµ‹è¯•çš„åºåˆ—ï¼Œå¹¶ä¸”å‡è®¾æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æ— é‡å¤çš„è¡¨ç¤ºã€‚æ’å…¥æ—¶é—´ä¸é›†åˆï¼ˆå’Œåˆ—è¡¨ï¼‰çš„å¤§å°æˆæ¯”ä¾‹ï¼›è¿™æœ€åˆæ˜¯\(0\)ï¼Œç„¶åæ˜¯\(1\)ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°è¾¾åˆ°å¤§å°\(k\)ã€‚å› æ­¤ï¼Œæ’å…¥åºåˆ—çš„æ€»æˆæœ¬æ˜¯\(k
    \cdot (k+1) / 2\)ã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæˆå‘˜èµ„æ ¼æµ‹è¯•çš„æˆæœ¬æ˜¯\(k\)ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å°†å¤šè¾¾\(k\)ä¸ªä¸åŒçš„å…ƒç´ æ’å…¥åˆ°é›†åˆä¸­ã€‚å› æ­¤ï¼Œæ€»æ—¶é—´æ˜¯
- en: \begin{equation*}k^2 / 2 + k / 2 + k^2\end{equation*}
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation*}k^2 / 2 + k / 2 + k^2\end{equation*}
- en: for a total of \(2k\) operations, yielding an average of
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»å…±\(2k\)æ¬¡æ“ä½œï¼Œå¹³å‡æ¯æ¬¡æ“ä½œ
- en: \begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: \begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}
- en: steps per operation in the worst case.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤æ•°åœ¨æœ€åæƒ…å†µä¸‹ã€‚
- en: 15.2Â The New Form of Analysis[ğŸ”—](#(part._.The_.New_.Form_of_.Analysis) "Link
    to here")
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.2Â æ–°çš„åˆ†ææ–¹æ³•[ğŸ”—](#(part._.The_.New_.Form_of_.Analysis) "é“¾æ¥åˆ°æ­¤å¤„")
- en: What have we computed? We are still computing a worst case cost, because we
    have taken the cost of each operation in the sequence in the worst case. We are
    then computing the average cost per operation. Therefore, this is a average of
    worst cases.Importantly, this is different from what is known as average-case
    analysis, which uses probability theory to compute the estimated cost of the computation.
    We have not used any probability here. Note that because this is an average per
    operation, it does not say anything about how bad any one operation can be (which,
    as we will see [[Amortization Versus Individual Operations](#%28part._worst-case-ops-amort%29)],
    can be quite a bit worse); it only says what their average is.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¡ç®—äº†ä»€ä¹ˆï¼Ÿæˆ‘ä»¬ä»åœ¨è®¡ç®—æœ€åæƒ…å†µæˆæœ¬ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»è€ƒè™‘äº†åºåˆ—ä¸­æ¯ä¸ªæ“ä½œçš„æœ€åæƒ…å†µæˆæœ¬ã€‚ç„¶åæˆ‘ä»¬è®¡ç®—æ¯ä¸ªæ“ä½œçš„å¹³å‡æˆæœ¬ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ€åæƒ…å†µçš„å¹³å‡å€¼ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™ä¸æ‰€è°“çš„å¹³å‡æƒ…å†µåˆ†æä¸åŒï¼Œåè€…ä½¿ç”¨æ¦‚ç‡è®ºæ¥è®¡ç®—è®¡ç®—çš„ä¼°è®¡æˆæœ¬ã€‚æˆ‘ä»¬æ²¡æœ‰åœ¨è¿™é‡Œä½¿ç”¨ä»»ä½•æ¦‚ç‡ã€‚è¯·æ³¨æ„ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªæ¯ä¸ªæ“ä½œçš„å¹³å‡å€¼ï¼Œå®ƒå¹¶æ²¡æœ‰è¯´æ˜ä»»ä½•å•ä¸ªæ“ä½œå¯èƒ½æœ‰å¤šç³Ÿç³•ï¼ˆæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„
    [[æ‘Šé”€ä¸å•ä¸ªæ“ä½œ](#%28part._worst-case-ops-amort%29)]ï¼Œå¯èƒ½ç›¸å½“ç³Ÿç³•ï¼‰ï¼›å®ƒåªè¯´æ˜äº†å®ƒä»¬çš„å¹³å‡å€¼ã€‚
- en: In the above case, this new analysis did not yield any big surprises. We have
    found that on average we spend about \(k\) steps per operation; a big-Oh analysis
    would have told us that weâ€™re performing \(2k\) operations with a cost of \(O([k
    \rightarrow k])\) each in the number of distinct elements; per operation, then,
    we are performing roughly linear work in the worst-case number of set elements.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°æƒ…å†µä¸‹ï¼Œè¿™é¡¹æ–°çš„åˆ†æå¹¶æ²¡æœ‰å¸¦æ¥ä»»ä½•å¤§çš„æƒŠå–œã€‚æˆ‘ä»¬å‘ç°ï¼Œå¹³å‡è€Œè¨€ï¼Œæˆ‘ä»¬æ¯ä¸ªæ“ä½œèŠ±è´¹å¤§çº¦ \(k\) æ­¥ï¼›ä¸€ä¸ªå¤§ O åˆ†æä¼šå‘Šè¯‰æˆ‘ä»¬ï¼Œæˆ‘ä»¬æ‰§è¡Œäº† \(2k\)
    ä¸ªæ“ä½œï¼Œæ¯ä¸ªæ“ä½œçš„æˆæœ¬ä¸º \(O([k \rightarrow k])\) çš„ä¸åŒå…ƒç´ æ•°é‡ï¼›å› æ­¤ï¼Œæ¯ä¸ªæ“ä½œï¼Œæˆ‘ä»¬åœ¨æœ€åæƒ…å†µä¸‹å¯¹é›†åˆå…ƒç´ çš„æ•°é‡æ‰§è¡Œäº†å¤§è‡´çº¿æ€§çš„å·¥ä½œã€‚
- en: 'As we will soon see, however, this wonâ€™t always be the case: this new analysis
    can cough up pleasant surprises.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°çš„ï¼Œæƒ…å†µå¹¶ä¸æ€»æ˜¯è¿™æ ·ï¼šè¿™é¡¹æ–°çš„åˆ†æå¯èƒ½ä¼šå¸¦æ¥ä»¤äººæ„‰å¿«çš„æƒŠå–œã€‚
- en: Before we proceed, we should give this analysis its name. Formally, it is called
    amortized analysis. Amortization is the process of spreading a payment out over
    an extended but fixed term. In the same way, we spread out the cost of a computation
    over a fixed sequence, then determine how much each payment will be.We have given
    it a whimsical name because [Halloween](http://en.wikipedia.org/wiki/Halloween)
    is a(n American) holiday devoted to ghosts, ghouls, and other symbols of death.
    Amortization comes from the Latin root mort-, which means death, because an amortized
    analysis is one conducted â€œat the deathâ€, i.e., at the end of a fixed sequence
    of operations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œæˆ‘ä»¬åº”è¯¥ç»™è¿™é¡¹åˆ†æèµ·ä¸€ä¸ªåå­—ã€‚æ­£å¼æ¥è¯´ï¼Œå®ƒè¢«ç§°ä¸ºæ‘Šé”€åˆ†æã€‚æ‘Šé”€æ˜¯å°†æ”¯ä»˜åˆ†æ•£åˆ°å»¶é•¿ä½†å›ºå®šæœŸé™çš„è¿‡ç¨‹ã€‚åŒæ ·ï¼Œæˆ‘ä»¬å°†è®¡ç®—çš„æˆæœ¬åˆ†æ•£åˆ°å›ºå®šåºåˆ—ä¸­ï¼Œç„¶åç¡®å®šæ¯æ¬¡æ”¯ä»˜çš„é‡‘é¢ã€‚æˆ‘ä»¬ç»™å®ƒèµ·äº†ä¸€ä¸ªå¤æ€ªçš„åå­—ï¼Œå› ä¸º
    [ä¸‡åœ£èŠ‚](http://en.wikipedia.org/wiki/Halloween) æ˜¯ä¸€ä¸ªï¼ˆç¾å›½çš„ï¼‰èŠ‚æ—¥ï¼Œè‡´åŠ›äºé¬¼é­‚ã€æ¶é­”å’Œå…¶ä»–æ­»äº¡è±¡å¾ã€‚æ‘Šé”€æ¥è‡ªæ‹‰ä¸è¯­è¯æ ¹
    mort-ï¼Œæ„ä¸ºæ­»äº¡ï¼Œå› ä¸ºæ‘Šé”€åˆ†ææ˜¯åœ¨â€œæ­»äº¡â€æ—¶è¿›è¡Œçš„ï¼Œå³åœ¨å›ºå®šæ“ä½œåºåˆ—çš„æœ«å°¾ã€‚
- en: '15.3Â An Example: Queues from Lists[ğŸ”—](#(part._queue-data-structure) "Link to
    here")'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3 åˆ—è¡¨ä¸­çš„ç¤ºä¾‹ï¼šé˜Ÿåˆ—[ğŸ”—](#(part._queue-data-structure) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: 'We have seen lists [[From Tables to Lists](tables-to-lists.html)] and sets
    [[Several Variations on Sets](part_sets.html)]. Here we focus on queues, which
    too can be represented as lists: [Queues from Lists](queues-from-lists.html).
    If you have not read that material, itâ€™s worth reading at least the early portions
    now. In this section, we will ignore the various programming niceties discussed
    there, and focus on raw list representations to make an algorithmic point.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†åˆ—è¡¨ [[ä»è¡¨æ ¼åˆ°åˆ—è¡¨](tables-to-lists.html)] å’Œé›†åˆ [[é›†åˆçš„å‡ ç§å˜ä½“](part_sets.html)]ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å…³æ³¨é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºåˆ—è¡¨ï¼š[ä»åˆ—è¡¨åˆ°é˜Ÿåˆ—](queues-from-lists.html)ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰é˜…è¯»é‚£éƒ¨åˆ†å†…å®¹ï¼Œç°åœ¨è‡³å°‘åº”è¯¥é˜…è¯»å‰é¢çš„éƒ¨åˆ†ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¿½ç•¥é‚£é‡Œè®¨è®ºçš„å„ç§ç¼–ç¨‹ç»†èŠ‚ï¼Œä¸“æ³¨äºåŸå§‹åˆ—è¡¨è¡¨ç¤ºæ¥é˜è¿°ç®—æ³•è§‚ç‚¹ã€‚
- en: 15.3.1Â List Representations[ğŸ”—](#(part._.List_.Representations) "Link to here")
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.1 åˆ—è¡¨è¡¨ç¤º[ğŸ”—](#(part._.List_.Representations) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: 'Consider two natural ways of defining queues using lists. One is that every
    enqueue is implemented with `link`, while every dequeue requires traversing the
    whole list until its end. Conversely, we could make enqueuing traverse to the
    end, and dequeuing correspond to `.rest`. Either way, one of these operations
    will take constant time while the other will be linear in the length of the list
    representing the queue. (This should be loosely reminiscent of trade-offs we ran
    into when representing sets as lists: [Representing Sets as Lists](sets-from-lists.html).)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä½¿ç”¨åˆ—è¡¨å®šä¹‰é˜Ÿåˆ—çš„ä¸¤ç§è‡ªç„¶æ–¹å¼ã€‚ä¸€ç§æ–¹å¼æ˜¯æ¯ä¸ªå…¥é˜Ÿæ“ä½œéƒ½ä½¿ç”¨`link`å®ç°ï¼Œè€Œæ¯ä¸ªå‡ºé˜Ÿæ“ä½œéƒ½éœ€è¦éå†æ•´ä¸ªåˆ—è¡¨ç›´åˆ°å…¶æœ«å°¾ã€‚ç›¸åï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®©å…¥é˜Ÿæ“ä½œéå†åˆ°æœ«å°¾ï¼Œè€Œå‡ºé˜Ÿæ“ä½œå¯¹åº”äº`.rest`ã€‚æ— è®ºå“ªç§æ–¹å¼ï¼Œè¿™äº›æ“ä½œä¸­çš„ä¸€ç§å°†èŠ±è´¹å¸¸æ•°æ—¶é—´ï¼Œè€Œå¦ä¸€ç§å°†çº¿æ€§äºè¡¨ç¤ºé˜Ÿåˆ—çš„åˆ—è¡¨é•¿åº¦ã€‚
    (è¿™åº”è¯¥ä¼šè®©äººè”æƒ³åˆ°æˆ‘ä»¬åœ¨å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨æ—¶é‡åˆ°çš„æƒè¡¡ï¼š[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)ã€‚)
- en: In fact, however, the above paragraph contains a key insight that will let us
    do better.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œäº‹å®ä¸Šï¼Œä¸Šè¿°æ®µè½ä¸­åŒ…å«äº†ä¸€ä¸ªå…³é”®çš„æ´è§ï¼Œè¿™å°†ä½¿æˆ‘ä»¬åšå¾—æ›´å¥½ã€‚
- en: Observe that if we store the queue in a list with most-recently-enqueued element
    first, enqueuing is cheap (constant time). In contrast, if we store the queue
    in the reverse order, then dequeuing is constant time. It would be wonderful if
    we could have both, but once we pick an order we must give up one or the other.
    Unless, that is, we pick...both.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬ä»¥æœ€è¿‘å…¥é˜Ÿçš„å…ƒç´ ä¸ºé¦–ä½å°†é˜Ÿåˆ—å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œå…¥é˜Ÿæ“ä½œçš„æˆæœ¬å¾ˆä½ï¼ˆå¸¸æ•°æ—¶é—´ï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¦‚æœæˆ‘ä»¬ä»¥ç›¸åçš„é¡ºåºå­˜å‚¨é˜Ÿåˆ—ï¼Œåˆ™å‡ºé˜Ÿæ“ä½œæ˜¯å¸¸æ•°æ—¶é—´ã€‚å¦‚æœèƒ½åŒæ—¶æ‹¥æœ‰è¿™ä¸¤ç§æ“ä½œé‚£å°±å¤ªå¥½äº†ï¼Œä½†ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†é¡ºåºï¼Œå°±å¿…é¡»æ”¾å¼ƒå…¶ä¸­ä¹‹ä¸€ã€‚é™¤éï¼Œé‚£å°±æ˜¯ï¼Œæˆ‘ä»¬é€‰æ‹©â€¦â€¦ä¸¤è€…éƒ½è¦ã€‚
- en: 'One half of this is easy. We simply enqueue elements into a list with the most
    recent addition first. Now for the (first) crucial insight: when we need to dequeue,
    we reverse the list. Now, dequeuing also takes constant time.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€åŠæ˜¯å®¹æ˜“çš„ã€‚æˆ‘ä»¬åªéœ€å°†å…ƒç´ ä»¥æœ€è¿‘æ·»åŠ çš„é¡ºåºå…¥é˜Ÿåˆ°åˆ—è¡¨ä¸­ã€‚ç°åœ¨ï¼Œå¯¹äºï¼ˆç¬¬ä¸€æ¬¡ï¼‰å…³é”®æ´è§ï¼šå½“æˆ‘ä»¬éœ€è¦å‡ºé˜Ÿæ—¶ï¼Œæˆ‘ä»¬åè½¬åˆ—è¡¨ã€‚ç°åœ¨ï¼Œå‡ºé˜Ÿæ“ä½œä¹ŸèŠ±è´¹å¸¸æ•°æ—¶é—´ã€‚
- en: 15.3.2Â A First Analysis[ğŸ”—](#(part._.A_.First_.Analysis) "Link to here")
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.2Â åˆæ­¥åˆ†æ[ğŸ”—](#(part._.A_.First_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: Of course, to fully analyze the complexity of this data structure, we must also
    account for the reversal. In the worst case, we might argue that any operation
    might reverse (because it might be the first dequeue); therefore, the worst-case
    time of any operation is the time it takes to reverse, which is linear in the
    length of the list (which corresponds to the elements of the queue).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä¸ºäº†å®Œå…¨åˆ†æè¿™ç§æ•°æ®ç»“æ„çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘åè½¬æ“ä½œã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®¤ä¸ºä»»ä½•æ“ä½œéƒ½å¯èƒ½éœ€è¦åè½¬ï¼ˆå› ä¸ºå®ƒå¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡å‡ºé˜Ÿï¼‰ï¼›å› æ­¤ï¼Œä»»ä½•æ“ä½œçš„æœ€åæƒ…å†µæ—¶é—´éƒ½æ˜¯åè½¬æ‰€éœ€çš„æ—¶é—´ï¼Œè¿™æ˜¯çº¿æ€§äºåˆ—è¡¨é•¿åº¦çš„ï¼ˆå¯¹åº”äºé˜Ÿåˆ—çš„å…ƒç´ ï¼‰ã€‚
- en: However, this answer should be unsatisfying. If we perform \(k\) enqueues followed
    by \(k\) dequeues, then each of the enqueues takes one step; each of the last
    \(k-1\) dequeues takes one step; and only the first dequeue requires a reversal,
    which takes steps proportional to the number of elements in the list, which at
    that point is \(k\). Thus, the total cost of operations for this sequence is \(k
    \cdot 1 + k + (k-1) \cdot 1 = 3k-1\) for a total of \(2k\) operations, giving
    an amortized complexity of effectively constant time per operation!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ä¸ªç­”æ¡ˆå¯èƒ½ä¸ä¼šä»¤äººæ»¡æ„ã€‚å¦‚æœæˆ‘ä»¬æ‰§è¡Œ \(k\) æ¬¡å…¥é˜Ÿæ“ä½œï¼Œç„¶åæ‰§è¡Œ \(k\) æ¬¡å‡ºé˜Ÿæ“ä½œï¼Œé‚£ä¹ˆæ¯æ¬¡å…¥é˜Ÿæ“ä½œèŠ±è´¹ä¸€æ­¥ï¼›æœ€å \(k-1\)
    æ¬¡å‡ºé˜Ÿæ“ä½œæ¯æ¬¡ä¹ŸèŠ±è´¹ä¸€æ­¥ï¼›è€Œåªæœ‰ç¬¬ä¸€æ¬¡å‡ºé˜Ÿéœ€è¦åè½¬ï¼Œè¿™éœ€è¦ä¸åˆ—è¡¨ä¸­å…ƒç´ æ•°é‡æˆæ¯”ä¾‹çš„æ­¥éª¤ï¼Œåœ¨é‚£ä¸ªæ—¶åˆ»æ˜¯ \(k\)ã€‚å› æ­¤ï¼Œè¿™ä¸ªæ“ä½œåºåˆ—çš„æ€»æˆæœ¬æ˜¯ \(k \cdot
    1 + k + (k-1) \cdot 1 = 3k-1\)ï¼Œæ€»å…± \(2k\) æ¬¡æ“ä½œï¼Œç»™å‡ºæ¯ä¸ªæ“ä½œå¹³å‡ä¸ºå¸¸æ•°æ—¶é—´çš„å¤æ‚åº¦ï¼
- en: 15.3.3Â More Liberal Sequences of Operations[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations)
    "Link to here")
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.3Â æ›´è‡ªç”±çš„æ“ä½œåºåˆ—[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations) "é“¾æ¥è‡³æ­¤")
- en: 'In the process of this, however, weâ€™ve quietly glossed over something that
    you may not have picked up on: in our candidate sequence all dequeues followed
    all enqueues. What happens on the next enqueue? Because the list is now reversed,
    it will have to take a linear amount of time! So we have only partially solved
    the problem.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å´æ‚„æ‚„åœ°å¿½ç•¥äº†ä½ å¯èƒ½æ²¡æœ‰æ³¨æ„åˆ°çš„äº‹æƒ…ï¼šåœ¨æˆ‘ä»¬çš„å€™é€‰åºåˆ—ä¸­ï¼Œæ‰€æœ‰å‡ºé˜Ÿæ“ä½œéƒ½è·Ÿéšç€æ‰€æœ‰å…¥é˜Ÿæ“ä½œã€‚ä¸‹ä¸€æ¬¡å…¥é˜Ÿä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå› ä¸ºåˆ—è¡¨ç°åœ¨æ˜¯åè½¬çš„ï¼Œå®ƒå°†éœ€è¦çº¿æ€§æ—¶é—´ï¼æ‰€ä»¥ï¼Œæˆ‘ä»¬åªéƒ¨åˆ†è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: 'Now we can introduce the second insight: have two lists instead of one. One
    of them will be the tail of the queue, where new elements get enqueued; the other
    will be the head of the queue, where they get dequeued:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼•å…¥ç¬¬äºŒä¸ªæ´è§ï¼šä½¿ç”¨ä¸¤ä¸ªåˆ—è¡¨è€Œä¸æ˜¯ä¸€ä¸ªã€‚å…¶ä¸­ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å°¾éƒ¨ï¼Œæ–°å…ƒç´ å°†åœ¨è¿™é‡Œå…¥é˜Ÿï¼›å¦ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å¤´éƒ¨ï¼Œå…ƒç´ å°†åœ¨è¿™é‡Œå‡ºé˜Ÿï¼š
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Provided the tail is stored so that the most recent element is the first, then
    enqueuing takes constant time:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å°¾éƒ¨çš„å­˜å‚¨æ–¹å¼ä½¿å¾—æœ€æ–°å…ƒç´ æ˜¯ç¬¬ä¸€ä¸ªï¼Œé‚£ä¹ˆå…¥é˜Ÿæ“ä½œå°†èŠ±è´¹å¸¸æ•°æ—¶é—´ï¼š
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For dequeuing to take constant time, the head of the queue must be stored in
    the reverse direction. However, how does any element ever get from the tail to
    the head? Easy: when we try to dequeue and find no elements in the head, we reverse
    the (entire) tail into the head (resulting in an empty tail). We will first define
    a datatype to represent the response from dequeuing:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿å‡ºé˜Ÿæ“ä½œèŠ±è´¹å¸¸æ•°æ—¶é—´ï¼Œé˜Ÿåˆ—çš„å¤´éƒ¨å¿…é¡»ä»¥ç›¸åçš„æ–¹å‘å­˜å‚¨ã€‚ç„¶è€Œï¼Œä»»ä½•å…ƒç´ æ˜¯å¦‚ä½•ä»å°¾éƒ¨ç§»åŠ¨åˆ°å¤´éƒ¨çš„å‘¢ï¼Ÿç®€å•ï¼šå½“æˆ‘ä»¬å°è¯•å‡ºé˜Ÿå¹¶ä¸”å‘ç°å¤´éƒ¨æ²¡æœ‰å…ƒç´ æ—¶ï¼Œæˆ‘ä»¬å°†ï¼ˆæ•´ä¸ªï¼‰å°¾éƒ¨åè½¬åˆ°å¤´éƒ¨ï¼ˆå¯¼è‡´å°¾éƒ¨ä¸ºç©ºï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ªæ•°æ®ç±»å‹æ¥è¡¨ç¤ºå‡ºé˜Ÿæ“ä½œçš„å“åº”ï¼š
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now for the implementation of `dequeue`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¥çœ‹`dequeue`çš„å®ç°ï¼š
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 15.3.4Â A Second Analysis[ğŸ”—](#(part._.A_.Second_.Analysis) "Link to here")
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.4Â ç¬¬äºŒæ¬¡åˆ†æ[ğŸ”—](#(part._.A_.Second_.Analysis) "é“¾æ¥åˆ°æ­¤å¤„")
- en: We can now reason about sequences of operations as we did before, by adding
    up costs and averaging. However, another way to think of it is this. Letâ€™s give
    each element in the queue three â€œcreditsâ€. Each credit can be used for one constant-time
    operation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥åƒä»¥å‰ä¸€æ ·æ¨ç†æ“ä½œåºåˆ—ï¼Œé€šè¿‡ç´¯åŠ æˆæœ¬å¹¶å–å¹³å‡å€¼ã€‚ç„¶è€Œï¼Œå¦ä¸€ç§æ€è€ƒæ–¹å¼æ˜¯è¿™æ ·çš„ã€‚è®©æˆ‘ä»¬ç»™é˜Ÿåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ åˆ†é…ä¸‰ä¸ªâ€œä¿¡ç”¨â€ã€‚æ¯ä¸ªä¿¡ç”¨å¯ä»¥ç”¨äºä¸€ä¸ªå¸¸æ•°æ—¶é—´çš„æ“ä½œã€‚
- en: One credit gets used up in enqueuing. So long as the element stays in the tail
    list, it still has two credits to spare. When it needs to be moved to the head
    list, it spends one more credit in the link step of reversal. Finally, the dequeuing
    operation performs one operation too.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å…¥é˜Ÿæ“ä½œä¼šæ¶ˆè€—ä¸€ä¸ªä¿¡ç”¨ã€‚åªè¦å…ƒç´ ä¿æŒåœ¨å°¾éƒ¨åˆ—è¡¨ä¸­ï¼Œå®ƒä»ç„¶æœ‰é¢å¤–çš„ä¸¤ä¸ªä¿¡ç”¨ã€‚å½“å®ƒéœ€è¦ç§»åŠ¨åˆ°å¤´éƒ¨åˆ—è¡¨æ—¶ï¼Œå®ƒä¼šåœ¨åè½¬æ­¥éª¤ä¸­å†æ¶ˆè€—ä¸€ä¸ªä¿¡ç”¨ã€‚æœ€åï¼Œå‡ºé˜Ÿæ“ä½œæ‰§è¡Œä¸€ä¸ªé¢å¤–çš„æ“ä½œã€‚
- en: Because the element does not run out of credits, we know it must have had enough.
    These credits reflect the cost of operations on that element. From this (very
    informal) analysis, we can conclude that in the worst case, any permutation of
    enqueues and dequeues will still cost only a constant amount of amortized time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå…ƒç´ æ²¡æœ‰è€—å°½ä¿¡ç”¨ï¼Œæˆ‘ä»¬çŸ¥é“å®ƒå¿…é¡»æœ‰è¶³å¤Ÿçš„ä¿¡ç”¨ã€‚è¿™äº›ä¿¡ç”¨åæ˜ äº†åœ¨è¯¥å…ƒç´ ä¸Šæ“ä½œçš„æˆæœ¬ã€‚ä»è¿™ä¸ªï¼ˆéå¸¸éæ­£å¼çš„ï¼‰åˆ†æä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œåœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œä»»ä½•å…¥é˜Ÿå’Œå‡ºé˜Ÿçš„æ’åˆ—ç»„åˆéƒ½å°†ä»…èŠ±è´¹å¸¸æ•°æ—¶é—´çš„æ‘Šé”€æ—¶é—´ã€‚
- en: 15.3.5Â Amortization Versus Individual Operations[ğŸ”—](#(part._worst-case-ops-amort)
    "Link to here")
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.5Â æ‘Šé”€æ—¶é—´ä¸å•ä¸ªæ“ä½œ[ğŸ”—](#(part._worst-case-ops-amort) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Note, however, that the constant represents an average across the sequence of
    operations. It does not put a bound on the cost of any one operation. Indeed,
    as we have seen above, when dequeue finds the head list empty it reverses the
    tail, which takes time linear in the size of the tailâ€”<wbr>not constant at all!
    Therefore, we should be careful to not assume that every step in the sequence
    will is bounded. Nevertheless, an amortized analysis sometimes gives us a much
    more nuanced understanding of the real behavior of a data structure than a worst-case
    analysis does on its own.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¯·æ³¨æ„ï¼Œè¿™ä¸ªå¸¸æ•°ä»£è¡¨äº†ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å€¼ã€‚å®ƒå¹¶æ²¡æœ‰å¯¹ä»»ä½•å•ä¸ªæ“ä½œçš„æˆæœ¬è®¾å®šç•Œé™ã€‚ç¡®å®ï¼Œæ­£å¦‚æˆ‘ä»¬ä¸Šé¢æ‰€çœ‹åˆ°çš„ï¼Œå½“å‡ºé˜Ÿæ“ä½œå‘ç°å¤´éƒ¨åˆ—è¡¨ä¸ºç©ºæ—¶ï¼Œå®ƒä¼šåè½¬å°¾éƒ¨ï¼Œè¿™éœ€è¦ä¸å°¾éƒ¨å¤§å°æˆçº¿æ€§å…³ç³»çš„æ“ä½œæ—¶é—´â€”â€”ç»å¯¹ä¸æ˜¯å¸¸æ•°ï¼å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥å°å¿ƒï¼Œä¸è¦å‡è®¾åºåˆ—ä¸­çš„æ¯ä¸€æ­¥éƒ½æ˜¯æœ‰é™çš„ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ‘Šé”€åˆ†ææœ‰æ—¶èƒ½æ¯”å•ç‹¬çš„æœ€åæƒ…å†µåˆ†ææ›´ç»†è‡´åœ°ç†è§£æ•°æ®ç»“æ„çš„å®é™…è¡Œä¸ºã€‚
- en: 15.3.1Â List Representations[ğŸ”—](#(part._.List_.Representations) "Link to here")
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.1Â åˆ—è¡¨è¡¨ç¤º[ğŸ”—](#(part._.List_.Representations) "é“¾æ¥åˆ°æ­¤å¤„")
- en: 'Consider two natural ways of defining queues using lists. One is that every
    enqueue is implemented with `link`, while every dequeue requires traversing the
    whole list until its end. Conversely, we could make enqueuing traverse to the
    end, and dequeuing correspond to `.rest`. Either way, one of these operations
    will take constant time while the other will be linear in the length of the list
    representing the queue. (This should be loosely reminiscent of trade-offs we ran
    into when representing sets as lists: [Representing Sets as Lists](sets-from-lists.html).)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä½¿ç”¨åˆ—è¡¨å®šä¹‰é˜Ÿåˆ—çš„ä¸¤ç§è‡ªç„¶æ–¹å¼ã€‚ä¸€ç§æ–¹å¼æ˜¯æ¯ä¸ªå…¥é˜Ÿæ“ä½œéƒ½ä½¿ç”¨`link`å®ç°ï¼Œè€Œæ¯ä¸ªå‡ºé˜Ÿæ“ä½œéƒ½éœ€è¦éå†æ•´ä¸ªåˆ—è¡¨ç›´åˆ°å…¶æœ«å°¾ã€‚ç›¸åï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿å…¥é˜Ÿæ“ä½œéå†åˆ°æœ«å°¾ï¼Œè€Œå‡ºé˜Ÿæ“ä½œå¯¹åº”äº`.rest`ã€‚æ— è®ºå“ªç§æ–¹å¼ï¼Œè¿™äº›æ“ä½œä¸­çš„ä¸€ç§å°†èŠ±è´¹å¸¸æ•°æ—¶é—´ï¼Œè€Œå¦ä¸€ç§å°†çº¿æ€§äºè¡¨ç¤ºé˜Ÿåˆ—çš„åˆ—è¡¨é•¿åº¦ã€‚
    (è¿™åº”è¯¥ä¼šè®©äººè”æƒ³åˆ°æˆ‘ä»¬åœ¨å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨æ—¶é‡åˆ°çš„æƒè¡¡ï¼š[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)ã€‚)
- en: In fact, however, the above paragraph contains a key insight that will let us
    do better.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹å®ä¸Šï¼Œç„¶è€Œï¼Œä¸Šè¿°æ®µè½åŒ…å«äº†ä¸€ä¸ªå…³é”®æ´è§ï¼Œè¿™å°†ä½¿æˆ‘ä»¬åšå¾—æ›´å¥½ã€‚
- en: Observe that if we store the queue in a list with most-recently-enqueued element
    first, enqueuing is cheap (constant time). In contrast, if we store the queue
    in the reverse order, then dequeuing is constant time. It would be wonderful if
    we could have both, but once we pick an order we must give up one or the other.
    Unless, that is, we pick...both.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬ä»¥æœ€æ–°å…¥é˜Ÿå…ƒç´ åœ¨å‰çš„é¡ºåºå°†é˜Ÿåˆ—å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œå…¥é˜Ÿæ“ä½œçš„æˆæœ¬å¾ˆä½ï¼ˆæ’å®šæ—¶é—´ï¼‰ã€‚ç›¸åï¼Œå¦‚æœæˆ‘ä»¬ä»¥ç›¸åçš„é¡ºåºå­˜å‚¨é˜Ÿåˆ—ï¼Œé‚£ä¹ˆå‡ºé˜Ÿæ“ä½œæ˜¯æ’å®šæ—¶é—´çš„ã€‚å¦‚æœæˆ‘ä»¬å¯ä»¥åŒæ—¶æ‹¥æœ‰ä¸¤è€…ï¼Œé‚£å°†æ˜¯æå¥½çš„ï¼Œä½†ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†é¡ºåºï¼Œæˆ‘ä»¬å°±å¿…é¡»æ”¾å¼ƒå…¶ä¸­ä¸€ä¸ªã€‚é™¤éï¼Œæˆ‘ä»¬é€‰æ‹©â€¦â€¦ä¸¤è€…ã€‚
- en: 'One half of this is easy. We simply enqueue elements into a list with the most
    recent addition first. Now for the (first) crucial insight: when we need to dequeue,
    we reverse the list. Now, dequeuing also takes constant time.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å…¶ä¸­çš„ä¸€åŠæ˜¯å®¹æ˜“çš„ã€‚æˆ‘ä»¬åªéœ€å°†å…ƒç´ ä»¥æœ€æ–°æ·»åŠ çš„é¡ºåºå…¥é˜Ÿåˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚ç°åœ¨ï¼Œå¯¹äºï¼ˆç¬¬ä¸€ä¸ªï¼‰å…³é”®æ´è§ï¼šå½“æˆ‘ä»¬éœ€è¦å‡ºé˜Ÿæ—¶ï¼Œæˆ‘ä»¬åè½¬åˆ—è¡¨ã€‚ç°åœ¨ï¼Œå‡ºé˜Ÿæ“ä½œä¹Ÿå˜æˆäº†æ’å®šæ—¶é—´ã€‚
- en: 15.3.2Â A First Analysis[ğŸ”—](#(part._.A_.First_.Analysis) "Link to here")
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.2Â åˆæ­¥åˆ†æ[ğŸ”—](#(part._.A_.First_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: Of course, to fully analyze the complexity of this data structure, we must also
    account for the reversal. In the worst case, we might argue that any operation
    might reverse (because it might be the first dequeue); therefore, the worst-case
    time of any operation is the time it takes to reverse, which is linear in the
    length of the list (which corresponds to the elements of the queue).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä¸ºäº†å®Œå…¨åˆ†æè¿™ä¸ªæ•°æ®ç»“æ„çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å¿…é¡»ä¹Ÿè€ƒè™‘åè½¬æ“ä½œã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®¤ä¸ºä»»ä½•æ“ä½œéƒ½å¯èƒ½éœ€è¦åè½¬ï¼ˆå› ä¸ºå®ƒå¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡å‡ºé˜Ÿï¼‰ï¼›å› æ­¤ï¼Œä»»ä½•æ“ä½œçš„æœ€åæƒ…å†µæ—¶é—´å°±æ˜¯åè½¬æ‰€éœ€çš„æ—¶é—´ï¼Œè¿™æ˜¯ä¸åˆ—è¡¨é•¿åº¦æˆçº¿æ€§å…³ç³»çš„ï¼ˆå¯¹åº”äºé˜Ÿåˆ—çš„å…ƒç´ ï¼‰ã€‚
- en: However, this answer should be unsatisfying. If we perform \(k\) enqueues followed
    by \(k\) dequeues, then each of the enqueues takes one step; each of the last
    \(k-1\) dequeues takes one step; and only the first dequeue requires a reversal,
    which takes steps proportional to the number of elements in the list, which at
    that point is \(k\). Thus, the total cost of operations for this sequence is \(k
    \cdot 1 + k + (k-1) \cdot 1 = 3k-1\) for a total of \(2k\) operations, giving
    an amortized complexity of effectively constant time per operation!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ä¸ªç­”æ¡ˆå¯èƒ½ä¸ä¼šä»¤äººæ»¡æ„ã€‚å¦‚æœæˆ‘ä»¬æ‰§è¡Œ\(k\)æ¬¡å…¥é˜Ÿæ“ä½œï¼Œç„¶åæ‰§è¡Œ\(k\)æ¬¡å‡ºé˜Ÿæ“ä½œï¼Œé‚£ä¹ˆæ¯æ¬¡å…¥é˜Ÿæ“ä½œéœ€è¦ä¸€æ­¥ï¼›æœ€å\(k-1\)æ¬¡å‡ºé˜Ÿæ“ä½œæ¯æ¬¡ä¹Ÿéœ€è¦ä¸€æ­¥ï¼›åªæœ‰ç¬¬ä¸€æ¬¡å‡ºé˜Ÿéœ€è¦åè½¬ï¼Œè¿™éœ€è¦ä¸åˆ—è¡¨ä¸­å…ƒç´ æ•°é‡æˆæ¯”ä¾‹çš„æ­¥éª¤ï¼Œåœ¨é‚£ä¸ªæ—¶åˆ»æ˜¯\(k\)ã€‚å› æ­¤ï¼Œè¿™ä¸ªæ“ä½œåºåˆ—çš„æ€»æˆæœ¬æ˜¯\(k
    \cdot 1 + k + (k-1) \cdot 1 = 3k-1\)ï¼Œæ€»å…±æ˜¯\(2k\)æ¬¡æ“ä½œï¼Œç»™å‡ºäº†æ¯ä¸ªæ“ä½œå¹³å‡æ’å®šæ—¶é—´çš„å¤æ‚åº¦ï¼
- en: 15.3.3Â More Liberal Sequences of Operations[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations)
    "Link to here")
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.3Â æ›´è‡ªç”±çš„æ“ä½œåºåˆ—[ğŸ”—](#(part._.More_.Liberal_.Sequences_of_.Operations) "é“¾æ¥è‡³æ­¤")
- en: 'In the process of this, however, weâ€™ve quietly glossed over something that
    you may not have picked up on: in our candidate sequence all dequeues followed
    all enqueues. What happens on the next enqueue? Because the list is now reversed,
    it will have to take a linear amount of time! So we have only partially solved
    the problem.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å´æ‚„æ‚„åœ°å¿½ç•¥äº†ä¸€äº›ä½ å¯èƒ½æ²¡æœ‰æ³¨æ„åˆ°çš„äº‹æƒ…ï¼šåœ¨æˆ‘ä»¬çš„å€™é€‰åºåˆ—ä¸­ï¼Œæ‰€æœ‰çš„å‡ºé˜Ÿæ“ä½œéƒ½è·Ÿéšç€æ‰€æœ‰çš„å…¥é˜Ÿæ“ä½œã€‚ä¸‹ä¸€ä¸ªå…¥é˜Ÿæ“ä½œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå› ä¸ºåˆ—è¡¨ç°åœ¨è¢«åè½¬äº†ï¼Œå®ƒå°†éœ€è¦çº¿æ€§æ—¶é—´ï¼æ‰€ä»¥ï¼Œæˆ‘ä»¬åªéƒ¨åˆ†è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: 'Now we can introduce the second insight: have two lists instead of one. One
    of them will be the tail of the queue, where new elements get enqueued; the other
    will be the head of the queue, where they get dequeued:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ä»‹ç»ç¬¬äºŒä¸ªæ´è§ï¼šæœ‰ä¸¤ä¸ªåˆ—è¡¨è€Œä¸æ˜¯ä¸€ä¸ªã€‚å…¶ä¸­ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å°¾éƒ¨ï¼Œæ–°å…ƒç´ å°†åœ¨è¿™é‡Œå…¥é˜Ÿï¼›å¦ä¸€ä¸ªå°†æ˜¯é˜Ÿåˆ—çš„å¤´éƒ¨ï¼Œå…ƒç´ å°†åœ¨è¿™é‡Œå‡ºé˜Ÿï¼š
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Provided the tail is stored so that the most recent element is the first, then
    enqueuing takes constant time:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å°¾éƒ¨å­˜å‚¨çš„æ–¹å¼æ˜¯æœ€æ–°çš„å…ƒç´ åœ¨ç¬¬ä¸€ä¸ªä½ç½®ï¼Œé‚£ä¹ˆå…¥é˜Ÿæ“ä½œçš„æ—¶é—´æ˜¯æ’å®šçš„ï¼š
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For dequeuing to take constant time, the head of the queue must be stored in
    the reverse direction. However, how does any element ever get from the tail to
    the head? Easy: when we try to dequeue and find no elements in the head, we reverse
    the (entire) tail into the head (resulting in an empty tail). We will first define
    a datatype to represent the response from dequeuing:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿å‡ºé˜Ÿæ“ä½œçš„æ—¶é—´ä¿æŒæ’å®šï¼Œé˜Ÿåˆ—çš„å¤´éƒ¨å¿…é¡»ä»¥ç›¸åçš„æ–¹å‘å­˜å‚¨ã€‚ç„¶è€Œï¼Œä»»ä½•å…ƒç´ æ˜¯å¦‚ä½•ä»å°¾éƒ¨åˆ°è¾¾å¤´éƒ¨çš„å‘¢ï¼Ÿç®€å•ï¼šå½“æˆ‘ä»¬å°è¯•å‡ºé˜Ÿä½†å¤´éƒ¨æ²¡æœ‰å…ƒç´ æ—¶ï¼Œæˆ‘ä»¬å°†ï¼ˆæ•´ä¸ªï¼‰å°¾éƒ¨åè½¬åˆ°å¤´éƒ¨ï¼ˆä»è€Œäº§ç”Ÿä¸€ä¸ªç©ºå°¾éƒ¨ï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ªæ•°æ®ç±»å‹æ¥è¡¨ç¤ºå‡ºé˜Ÿæ“ä½œçš„å“åº”ï¼š
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now for the implementation of `dequeue`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯`dequeue`å®ç°çš„æ­¥éª¤ï¼š
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 15.3.4Â A Second Analysis[ğŸ”—](#(part._.A_.Second_.Analysis) "Link to here")
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.4Â ç¬¬äºŒæ¬¡åˆ†æ[ğŸ”—](#(part._.A_.Second_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: We can now reason about sequences of operations as we did before, by adding
    up costs and averaging. However, another way to think of it is this. Letâ€™s give
    each element in the queue three â€œcreditsâ€. Each credit can be used for one constant-time
    operation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥åƒä»¥å‰ä¸€æ ·ï¼Œé€šè¿‡ç´¯åŠ æˆæœ¬å’Œå¹³å‡æ¥æ¨ç†æ“ä½œåºåˆ—ã€‚ç„¶è€Œï¼Œå¦ä¸€ç§æ€è€ƒæ–¹å¼æ˜¯è¿™æ ·çš„ã€‚è®©æˆ‘ä»¬ç»™é˜Ÿåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ åˆ†é…ä¸‰ä¸ªâ€œä¿¡ç”¨é¢åº¦â€ã€‚æ¯ä¸ªä¿¡ç”¨é¢åº¦å¯ä»¥ç”¨äºä¸€æ¬¡å¸¸æ•°æ—¶é—´çš„æ“ä½œã€‚
- en: One credit gets used up in enqueuing. So long as the element stays in the tail
    list, it still has two credits to spare. When it needs to be moved to the head
    list, it spends one more credit in the link step of reversal. Finally, the dequeuing
    operation performs one operation too.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¿¡ç”¨é¢åº¦åœ¨å…¥é˜Ÿæ—¶è¢«æ¶ˆè€—ã€‚åªè¦å…ƒç´ ä¿æŒåœ¨å°¾åˆ—è¡¨ä¸­ï¼Œå®ƒä»ç„¶æœ‰å‰©ä½™ä¸¤ä¸ªä¿¡ç”¨é¢åº¦ã€‚å½“å®ƒéœ€è¦ç§»åŠ¨åˆ°å¤´åˆ—è¡¨æ—¶ï¼Œå®ƒåœ¨åè½¬é“¾æ¥æ­¥éª¤ä¸­å†æ¶ˆè€—ä¸€ä¸ªä¿¡ç”¨é¢åº¦ã€‚æœ€åï¼Œå‡ºé˜Ÿæ“ä½œæ‰§è¡Œäº†ä¸€ä¸ªé¢å¤–çš„æ“ä½œã€‚
- en: Because the element does not run out of credits, we know it must have had enough.
    These credits reflect the cost of operations on that element. From this (very
    informal) analysis, we can conclude that in the worst case, any permutation of
    enqueues and dequeues will still cost only a constant amount of amortized time.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå…ƒç´ æ²¡æœ‰è€—å°½ä¿¡ç”¨é¢åº¦ï¼Œæˆ‘ä»¬çŸ¥é“å®ƒä¸€å®šæœ‰è¶³å¤Ÿçš„ã€‚è¿™äº›ä¿¡ç”¨é¢åº¦åæ˜ äº†åœ¨è¯¥å…ƒç´ ä¸Šæ“ä½œçš„æˆæœ¬ã€‚ä»è¿™ä¸ªï¼ˆéå¸¸éæ­£å¼çš„ï¼‰åˆ†æä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œåœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œä»»ä½•å…¥é˜Ÿå’Œå‡ºé˜Ÿçš„æ’åˆ—ç»„åˆéƒ½å°†ä»…èŠ±è´¹å¸¸æ•°é‡çš„æ‘Šé”€æ—¶é—´ã€‚
- en: 15.3.5Â Amortization Versus Individual Operations[ğŸ”—](#(part._worst-case-ops-amort)
    "Link to here")
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15.3.5 æ‘Šé”€ä¸å•ä¸ªæ“ä½œ[ğŸ”—](#(part._worst-case-ops-amort) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Note, however, that the constant represents an average across the sequence of
    operations. It does not put a bound on the cost of any one operation. Indeed,
    as we have seen above, when dequeue finds the head list empty it reverses the
    tail, which takes time linear in the size of the tailâ€”<wbr>not constant at all!
    Therefore, we should be careful to not assume that every step in the sequence
    will is bounded. Nevertheless, an amortized analysis sometimes gives us a much
    more nuanced understanding of the real behavior of a data structure than a worst-case
    analysis does on its own.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç„¶è€Œï¼Œè¯·æ³¨æ„ï¼Œè¿™ä¸ªå¸¸æ•°ä»£è¡¨çš„æ˜¯æ“ä½œåºåˆ—çš„å¹³å‡å€¼ã€‚å®ƒå¹¶ä¸å¯¹ä»»ä½•å•ä¸ªæ“ä½œçš„æˆæœ¬æ–½åŠ é™åˆ¶ã€‚ç¡®å®ï¼Œæ­£å¦‚æˆ‘ä»¬ä¸Šé¢æ‰€çœ‹åˆ°çš„ï¼Œå½“å‡ºé˜Ÿå‘ç°å¤´åˆ—è¡¨ä¸ºç©ºæ—¶ï¼Œå®ƒä¼šåè½¬å°¾ï¼Œè¿™éœ€è¦ä¸å°¾çš„å¤§å°æˆçº¿æ€§å…³ç³»çš„æ—¶é—´â€”â€”æ ¹æœ¬ä¸æ˜¯å¸¸æ•°ï¼å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥å°å¿ƒä¸è¦å‡è®¾åºåˆ—ä¸­çš„æ¯ä¸€æ­¥éƒ½æ˜¯æœ‰é™çš„ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ‘Šé”€åˆ†ææœ‰æ—¶èƒ½è®©æˆ‘ä»¬æ¯”å•ç‹¬çš„æœ€åæƒ…å†µåˆ†ææ›´æ·±å…¥åœ°ç†è§£æ•°æ®ç»“æ„çš„å®é™…è¡Œä¸ºã€‚ '
- en: 15.4Â Reading More[ğŸ”—](#(part._.Reading_.More) "Link to here")
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.4 é˜…è¯»æ›´å¤š[ğŸ”—](#(part._.Reading_.More) "é“¾æ¥åˆ°æ­¤å¤„")
- en: At this point we have only briefly touched on the subject of amortized analysis.
    A very nice [tutorial by Rebecca Fiebrink](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)
    provides much more information. The authoritative book on algorithms, Introduction
    to Algorithms by Cormen, Leiserson, Rivest, and Stein, covers amortized analysis
    in extensive detail.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªæ˜¯ç®€è¦åœ°æåˆ°äº†æ‘Šé”€åˆ†æçš„ä¸»é¢˜ã€‚Rebecca Fiebrinkçš„ä¸€ä¸ªéå¸¸å¥½çš„[æ•™ç¨‹](https://web.archive.org/web/20131020020356/http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)æä¾›äº†æ›´å¤šä¿¡æ¯ã€‚å…³äºç®—æ³•çš„æƒå¨ä¹¦ç±ï¼ŒCormenã€Leisersonã€Rivestå’ŒSteinåˆè‘—çš„ã€Šç®—æ³•å¯¼è®ºã€‹ï¼Œè¯¦ç»†ä»‹ç»äº†æ‘Šé”€åˆ†æã€‚
