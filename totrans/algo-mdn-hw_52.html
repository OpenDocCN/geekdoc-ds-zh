<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>RAM & CPU Caches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>RAM & CPU Caches</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/cpu-cache/">https://en.algorithmica.org/hpc/cpu-cache/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>In the <a href="../external-memory">previous chapter</a>, we studied computer memory from a theoretical standpoint, using the <a href="../external-memory/model">external memory model</a> to estimate the performance of memory-bound algorithms.</p><p>While the external memory model is more or less accurate for computations involving HDDs and network storage, where cost of arithmetic operations on in-memory values is negligible compared to external I/O operations, it is too imprecise for lower levels in the cache hierarchy, where the costs of these operations become comparable.</p><p>To perform more fine-grained optimization of in-memory algorithms, we have to start taking into account the many specific details of the CPU cache system. And instead of studying loads of boring Intel documents with dry specs and theoretically achievable limits, we will estimate these parameters experimentally by running numerous small benchmark programs with access patterns that resemble the ones that often occur in practical code.</p><h3>Experimental Setup</h3><p>As before, I will be running all experiments on Ryzen 7 4700U, which is a “Zen 2” CPU with the following main cache-related specs:</p><ul><li>8 physical cores (without hyper-threading) clocked at 2GHz (and 4.1GHz in boost mode — <a href="/hpc/profiling/noise">which we disable</a>);</li><li>256K of 8-way set associative L1 data cache or 32K per core;</li><li>4M of 8-way set associative L2 cache or 512K per core;</li><li>8M of 16-way set associative L3 cache, <a href="sharing">shared</a> between 8 cores;</li><li>16GB (2x8G) of DDR4 RAM @ 2667MHz.</li></ul><p>You can compare it with your own hardware by running <code>dmidecode -t cache</code> or <code>lshw -class memory</code> on Linux or by installing <a href="https://en.wikipedia.org/wiki/CPU-Z">CPU-Z</a> on Windows. You can also find additional details about the CPU on <a href="https://en.wikichip.org/wiki/amd/ryzen_7/4700u">WikiChip</a> and <a href="https://www.7-cpu.com/cpu/Zen2.html">7-CPU</a>. Not all conclusions will generalize to every CPU platform in existence.</p><p>Due to difficulties in <a href="/hpc/profiling/noise/">preventing the compiler from optimizing away unused values</a>, the code snippets in this article are slightly simplified for exposition purposes. Check the <a href="https://github.com/sslotin/amh-code/tree/main/cpu-cache">code repository</a> if you want to reproduce them yourself.</p><h3>Acknowledgements</h3><p>This chapter is inspired by “<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects</a>” by Igor Ostrovsky and “<a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">What Every Programmer Should Know About Memory</a>” by Ulrich Drepper, both of which can serve as good accompanying readings.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/external-memory/locality/" id="prev-article">← Spatial and Temporal Locality</a><br/><a href="https://en.algorithmica.org/hpc/external-memory/">← ../External Memory</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/cpu-cache/bandwidth/" id="next-article">Memory Bandwidth →</a><br/><a href="https://en.algorithmica.org/hpc/simd/">../SIMD Parallelism →</a></div></div>    
</body>
</html>