<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Number Theory</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Number Theory</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/number-theory/">https://en.algorithmica.org/hpc/number-theory/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>In 1940, a British mathematician <a href="https://en.wikipedia.org/wiki/G._H._Hardy">G. H. Hardy</a> published a famous essay titled “<a href="https://en.wikipedia.org/wiki/A_Mathematician%27s_Apology">A Mathematician’s Apology</a>” discussing the notion that mathematics should be pursued for its own sake rather than for the sake of its applications.</p><p>Similar to mathematics, the various fields of computer science also form a spectrum, with mathematical logic and computability theory on one end and web programming and application development on the other. I assume that you, the reader, is more on the applied side: this book was written to show that there are way too few people working on practical algorithm design instead of theoretical computer science — and since you got to Chapter 7, you probably also believe in that statement.</p><p>But, regardless of the personal views on the matter, one can see where Hardy is coming from. Being 62 years old at the date of writing, he witnessed the devastation caused by the First and the ongoing Second World War — which was greatly amplified by the weaponization of science. As a number theorist, Hardy finds calm working in a “useless” field and not having to face any moral dilemmas, writing:</p><blockquote><p>No one has yet discovered any warlike purpose to be served by the theory of numbers or relativity, and it seems unlikely that anyone will do so for many years.</p></blockquote><p>Ironically, this statement was proved very wrong just 5 years later with the development of the atomic bomb, which would not have been possible without the <a href="https://en.wikipedia.org/wiki/Einstein%E2%80%93Szil%C3%A1rd_letter">understanding</a> of relativity, and the inception of computer-era cryptography, which extensively builds on number theory — the computational aspect of which is the main topic of this chapter.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/arithmetic/division/" id="prev-article">← Integer Division</a><br/><a href="https://en.algorithmica.org/hpc/arithmetic/">← ../Arithmetic</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/number-theory/modular/" id="next-article">Modular Arithmetic →</a><br/><a href="https://en.algorithmica.org/hpc/external-memory/">../External Memory →</a></div></div>    
</body>
</html>