- en: '**Chapter 1 Why CUDA? Why Now?**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**第1章 为什么选择CUDA？为什么是现在？**'
- en: There was a time in the not-so-distant past when parallel computing was looked
    upon as an “exotic” pursuit and typically got compartmentalized as a specialty
    within the field of computer science. This perception has changed in profound
    ways in recent years. The computing world has shifted to the point where, far
    from being an esoteric pursuit, nearly every aspiring programmer *needs* training
    in parallel programming to be fully effective in computer science. Perhaps you’ve
    picked this book up unconvinced about the importance of parallel programming in
    the computing world today and the increasingly large role it will play in the
    years to come. This introductory chapter will examine recent trends in the hardware
    that does the heavy lifting for the software that we as programmers write. In
    doing so, we hope to convince you that the parallel computing revolution has *already*
    happened and that, by learning CUDA C, you’ll be well positioned to write high-performance
    applications for heterogeneous platforms that contain both central and graphics
    processing units.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 曾几何时，在不太遥远的过去，并行计算被视为一种“异国情调”的追求，通常被视为计算机科学中的一种专业领域。这种看法近年来发生了深刻变化。计算世界已经发生了转变，现在并行计算不仅仅是一个深奥的领域，几乎每个有抱负的程序员都*需要*学习并行编程，才能在计算机科学领域发挥最大的效能。也许你拿起这本书时，对于并行编程在今天计算世界中的重要性以及它在未来几年将扮演的日益重要的角色心存疑虑。本章将回顾近年来支撑我们编写的软件的硬件发展趋势。通过这一过程，我们希望说服你，並行计算的革命*已经*发生，而且通过学习CUDA
    C，你将能够为包含中央处理单元和图形处理单元的异构平台编写高性能应用程序。
- en: '**1.1 Chapter Objectives**'
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.1 章节目标**'
- en: 'Through the course of this chapter, you will accomplish the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将完成以下内容：
- en: • You will learn about the increasingly important role of parallel computing.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将了解并行计算日益重要的作用。
- en: • You will learn a brief history of GPU computing and CUDA.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习GPU计算和CUDA的简要历史。
- en: • You will learn about some successful applications that use CUDA C.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将了解一些成功应用CUDA C的案例。
- en: '**1.2 The Age of Parallel Processing**'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.2 并行处理的时代**'
- en: In recent years, much has been made of the computing industry’s widespread shift
    to parallel computing. Nearly all consumer computers in the year 2010 will ship
    with multicore central processors. From the introduction of dual-core, low-end
    netbook machines to 8- and 16-core workstation computers, no longer will parallel
    computing be relegated to exotic supercomputers or mainframes. Moreover, electronic
    devices such as mobile phones and portable music players have begun to incorporate
    parallel computing capabilities in an effort to provide functionality well beyond
    those of their predecessors.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，计算行业的广泛转向并行计算已经成为热议话题。到2010年，几乎所有的消费者计算机都将配备多核中央处理器。从双核低端上网本到8核和16核工作站计算机，並行计算将不再仅限于异国情调的超级计算机或大型机。此外，像手机和便携式音乐播放器这样的电子设备，已开始融入并行计算能力，旨在提供远超其前身的功能。
- en: More and more, software developers will need to cope with a variety of parallel
    computing platforms and technologies in order to provide novel and rich experiences
    for an increasingly sophisticated base of users. Command prompts are out; multithreaded
    graphical interfaces are in. Cellular phones that only make calls are out; phones
    that can simultaneously play music, browse the Web, and provide GPS services are
    in.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发人员将越来越需要应对各种并行计算平台和技术，以为日益复杂的用户群体提供新颖且丰富的体验。命令提示符逐渐被淘汰；多线程图形界面成为主流。仅能打电话的手机已经过时；能够同时播放音乐、浏览网页并提供
    GPS 服务的手机才是未来。
- en: '**1.2.1 Central Processing Units**'
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.2.1 中央处理单元**'
- en: For 30 years, one of the important methods for improving the performance of
    consumer computing devices has been to increase the speed at which the processor’s
    clock operated. Starting with the first personal computers of the early 1980s,
    consumer central processing units (CPUs) ran with internal clocks operating around
    1MHz. About 30 years later, most desktop processors have clock speeds between
    1GHz and 4GHz, nearly 1,000 times faster than the clock on the original personal
    computer. Although increasing the CPU clock speed is certainly not the only method
    by which computing performance has been improved, it has always been a reliable
    source for improved performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的30年中，提高消费计算设备性能的一个重要方法就是提高处理器时钟的运行速度。从20世纪80年代初期的第一批个人电脑开始，消费级中央处理单元（CPU）内部时钟大约在1MHz左右。大约30年后，大多数桌面处理器的时钟速度在1GHz到4GHz之间，比最初个人电脑的时钟速度快了近1000倍。尽管提高CPU时钟速度显然不是唯一提升计算性能的方法，但它一直是提高性能的可靠途径。
- en: In recent years, however, manufacturers have been forced to look for alternatives
    to this traditional source of increased computational power. Because of various
    fundamental limitations in the fabrication of integrated circuits, it is no longer
    feasible to rely on upward-spiraling processor clock speeds as a means for extracting
    additional power from existing architectures. Because of power and heat restrictions
    as well as a rapidly approaching physical limit to transistor size, researchers
    and manufacturers have begun to look elsewhere.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，近年来，制造商被迫寻找替代传统计算能力提升来源的方法。由于集成电路制造的各种基本限制，依赖处理器时钟速度不断上升来提取额外的处理能力已不再可行。由于功耗和热量限制，以及晶体管尺寸逼近物理极限，研究人员和制造商开始寻求其他解决方案。
- en: Outside the world of consumer computing, supercomputers have for decades extracted
    massive performance gains in similar ways. The performance of a processor used
    in a supercomputer has climbed astronomically, similar to the improvements in
    the personal computer CPU. However, in addition to dramatic improvements in the
    performance of a single processor, supercomputer manufacturers have also extracted
    massive leaps in performance by steadily increasing the *number* of processors.
    It is not uncommon for the fastest supercomputers to have tens or hundreds of
    thousands of processor cores working in tandem.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费计算领域之外，超级计算机数十年来通过类似的方式实现了巨大的性能提升。超级计算机中使用的处理器性能已飞跃式上升，类似于个人电脑CPU的提升。然而，除了单个处理器性能的显著提高外，超级计算机制造商还通过稳步增加*处理器数量*，实现了巨大的性能飞跃。最快的超级计算机往往拥有成千上万甚至数十万的处理核心并行工作，这并不罕见。
- en: 'In the search for additional processing power for personal computers, the improvement
    in supercomputers raises a very good question: Rather than solely looking to increase
    the performance of a single processing core, why not put more than one in a personal
    computer? In this way, personal computers could continue to improve in performance
    without the need for continuing increases in processor clock speed.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在寻求个人电脑额外处理能力的过程中，超级计算机的提升提出了一个很好的问题：与其仅仅提高单个处理核心的性能，为什么不在个人电脑中放入多个处理核心呢？通过这种方式，个人电脑可以在不需要继续提高处理器时钟速度的情况下，持续提升性能。
- en: In 2005, faced with an increasingly competitive marketplace and few alternatives,
    leading CPU manufacturers began offering processors with two computing cores instead
    of one. Over the following years, they followed this development with the release
    of three-, four-, six-, and eight-core central processor units. Sometimes referred
    to as the *multicore revolution*, this trend has marked a huge shift in the evolution
    of the consumer computing market.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 2005年，面对日益竞争激烈的市场和有限的选择，领先的CPU制造商开始提供具有两个计算核心的处理器，而非一个。随后几年，他们跟进发布了三核、四核、六核和八核的中央处理单元。这一趋势有时被称为*多核革命*，标志着消费计算市场演变中的一次巨大转折。
- en: Today, it is relatively challenging to purchase a desktop computer with a CPU
    containing but a single computing core. Even low-end, low-power central processors
    ship with two or more cores per die. Leading CPU manufacturers have already announced
    plans for 12- and 16-core CPUs, further confirming that parallel computing has
    arrived for good.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，购买一台仅含一个计算核心的桌面计算机已经相对困难。即使是低端、低功耗的中央处理器（CPU）也通常配备两个或更多核心。领先的CPU制造商已经宣布了12核和16核CPU的计划，进一步确认了并行计算已经成为现实。
- en: '**1.3 The Rise of GPU Computing**'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.3 GPU计算的崛起**'
- en: In comparison to the central processor’s traditional data processing pipeline,
    performing general-purpose computations on a graphics processing unit (GPU) is
    a new concept. In fact, the GPU itself is relatively new compared to the computing
    field at large. However, the idea of computing on graphics processors is not as
    new as you might believe.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与中央处理器传统的数据处理管道相比，在图形处理单元（GPU）上执行通用计算是一个全新的概念。实际上，GPU本身相较于整个计算领域来说是相对较新的技术。然而，在图形处理器上进行计算的想法并不像你想象的那样新。
- en: '**1.3.1 A Brief History of GPUs**'
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.3.1 GPU的简史**'
- en: We have already looked at how central processors evolved in both clock speeds
    and core count. In the meantime, the state of graphics processing underwent a
    dramatic revolution. In the late 1980s and early 1990s, the growth in popularity
    of graphically driven operating systems such as Microsoft Windows helped create
    a market for a new type of processor. In the early 1990s, users began purchasing
    2D display accelerators for their personal computers. These display accelerators
    offered hardware-assisted bitmap operations to assist in the display and usability
    of graphical operating systems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经研究过中央处理器在时钟速度和核心数量方面的演变。与此同时，图形处理的状态经历了剧烈的变革。在1980年代末和1990年代初，图形驱动操作系统如微软Windows的流行促成了新型处理器市场的诞生。在1990年代初，用户开始为个人计算机购买2D显示加速器。这些显示加速器提供了硬件支持的位图操作，帮助提高图形操作系统的显示效果和可用性。
- en: Around the same time, in the world of professional computing, a company by the
    name of Silicon Graphics spent the 1980s popularizing the use of three-dimensional
    graphics in a variety of markets, including government and defense applications
    and scientific and technical visualization, as well as providing the tools to
    create stunning cinematic effects. In 1992, Silicon Graphics opened the programming
    interface to its hardware by releasing the OpenGL library. Silicon Graphics intended
    OpenGL to be used as a standardized, platform-independent method for writing 3D
    graphics applications. As with parallel processing and CPUs, it would only be
    a matter of time before the technologies found their way into consumer applications.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一时期，在专业计算领域，一家公司名为Silicon Graphics的公司在1980年代致力于推广三维图形在多个市场中的应用，包括政府和国防领域、科学和技术可视化，以及提供创造惊艳电影特效的工具。1992年，Silicon
    Graphics通过发布OpenGL库向硬件开放了编程接口。Silicon Graphics希望OpenGL成为一种标准化、平台独立的3D图形应用编写方法。正如并行处理和CPU一样，这些技术最终也会进入消费级应用中，只是时间问题。
- en: By the mid-1990s, the demand for consumer applications employing 3D graphics
    had escalated rapidly, setting the stage for two fairly significant developments.
    First, the release of immersive, first-person games such as Doom, Duke Nukem 3D,
    and Quake helped ignite a quest to create progressively more realistic 3D environments
    for PC gaming. Although 3D graphics would eventually work their way into nearly
    all computer games, the popularity of the nascent first-person shooter genre would
    significantly accelerate the adoption of 3D graphics in consumer computing. At
    the same time, companies such as NVIDIA, ATI Technologies, and 3dfx Interactive
    began releasing graphics accelerators that were affordable enough to attract widespread
    attention. These developments cemented 3D graphics as a technology that would
    figure prominently for years to come.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 到了1990年代中期，消费者应用中使用3D图形的需求迅速上升，为两个相当重要的发展奠定了基础。首先，像《Doom》、《Duke Nukem 3D》和《Quake》这样的沉浸式第一人称游戏的发布，激发了人们创造越来越逼真的PC游戏3D环境的热情。尽管3D图形最终会进入几乎所有计算机游戏中，但新兴的第一人称射击游戏类型的流行显著加速了3D图形在消费计算中的普及。与此同时，像NVIDIA、ATI
    Technologies和3dfx Interactive等公司开始发布足够负担得起的图形加速器，引起了广泛关注。这些发展巩固了3D图形作为一种将在未来多年占据重要地位的技术。
- en: The release of NVIDIA’s GeForce 256 further pushed the capabilities of consumer
    graphics hardware. For the first time, transform and lighting computations could
    be performed directly on the graphics processor, thereby enhancing the potential
    for even more visually interesting applications. Since transform and lighting
    were already integral parts of the OpenGL graphics pipeline, the GeForce 256 marked
    the beginning of a natural progression where increasingly more of the graphics
    pipeline would be implemented directly on the graphics processor.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA的GeForce 256的发布进一步推动了消费级图形硬件的能力。首次，变换和光照计算可以直接在图形处理器上进行，从而增强了更具视觉吸引力的应用的潜力。由于变换和光照已经是OpenGL图形管线的核心部分，GeForce
    256标志着图形管线越来越多地直接在图形处理器上实现的自然进程的开始。
- en: From a parallel-computing standpoint, NVIDIA’s release of the GeForce 3 series
    in 2001 represents arguably the most important breakthrough in GPU technology.
    The GeForce 3 series was the computing industry’s first chip to implement Microsoft’s
    then-new DirectX 8.0 standard. This standard required that compliant hardware
    contain both programmable vertex and programmable pixel shading stages. For the
    first time, developers had some control over the exact computations that would
    be performed on their GPUs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从并行计算的角度来看，NVIDIA于2001年发布的GeForce 3系列无疑代表了GPU技术的最重要突破。GeForce 3系列是计算行业首个实现微软当时新发布的DirectX
    8.0标准的芯片。该标准要求符合标准的硬件包含可编程的顶点着色和可编程的像素着色阶段。开发人员首次可以控制GPU上执行的具体计算。
- en: '**1.3.2 Early GPU Computing**'
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.3.2 早期GPU计算**'
- en: The release of GPUs that possessed programmable pipelines attracted many researchers
    to the possibility of using graphics hardware for more than simply OpenGL- or
    DirectX-based rendering. The general approach in the early days of GPU computing
    was extraordinarily convoluted. Because standard graphics APIs such as OpenGL
    and DirectX were still the only way to interact with a GPU, any attempt to perform
    arbitrary computations on a GPU would still be subject to the constraints of programming
    within a graphics API. Because of this, researchers explored general-purpose computation
    through graphics APIs by trying to make their problems appear to the GPU to be
    traditional rendering.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有可编程管线的GPU发布吸引了许多研究人员探索将图形硬件用于超越OpenGL或DirectX渲染的可能性。GPU计算的早期方法极为复杂。因为像OpenGL和DirectX这样的标准图形API仍然是与GPU交互的唯一方式，所以任何试图在GPU上执行任意计算的尝试，仍然会受到在图形API内编程的限制。因此，研究人员通过尝试使他们的问题在GPU看来像传统渲染那样，探索通过图形API进行通用计算。
- en: Essentially, the GPUs of the early 2000s were designed to produce a color for
    every pixel on the screen using programmable arithmetic units known as *pixel
    shaders*. In general, a pixel shader uses its `(x,y)` position on the screen as
    well as some additional information to combine various inputs in computing a final
    color. The additional information could be input colors, texture coordinates,
    or other attributes that would be passed to the shader when it ran. But because
    the arithmetic being performed on the input colors and textures was completely
    controlled by the programmer, researchers observed that these input “colors” could
    actually be *any* data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，2000年代初的GPU设计用于通过可编程算术单元（称为*像素着色器*）为屏幕上的每个像素生成颜色。一般来说，像素着色器使用其在屏幕上的`(x,y)`位置以及一些附加信息，通过计算最终颜色来结合各种输入。这些附加信息可能是输入颜色、纹理坐标或其他在着色器运行时传递给它的属性。但由于对输入颜色和纹理的算术操作完全由程序员控制，研究人员观察到，这些输入的“颜色”实际上可以是*任何*数据。
- en: So if the inputs were actually numerical data signifying something other than
    color, programmers could then program the pixel shaders to perform arbitrary computations
    on this data. The results would be handed back to the GPU as the final pixel “color,”
    although the colors would simply be the result of whatever computations the programmer
    had instructed the GPU to perform on their inputs. This data could be read back
    by the researchers, and the GPU would never be the wiser. In essence, the GPU
    was being tricked into performing nonrendering tasks by making those tasks appear
    as if they were a standard rendering. This trickery was very clever but also very
    convoluted.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果输入实际上是表示除颜色以外的数字数据，程序员可以编写像素着色器来对这些数据进行任意计算。结果将作为最终像素的“颜色”返回给GPU，尽管这些颜色只是程序员指示GPU对其输入执行计算的结果。研究人员可以读取这些数据，而GPU则对此一无所知。从本质上讲，GPU被通过让这些任务看起来像是标准的渲染任务而被“欺骗”来执行非渲染任务。这种技巧非常巧妙，但也相当复杂。
- en: Because of the high arithmetic throughput of GPUs, initial results from these
    experiments promised a bright future for GPU computing. However, the programming
    model was still far too restrictive for any critical mass of developers to form.
    There were tight resource constraints, since programs could receive input data
    only from a handful of input colors and a handful of texture units. There were
    serious limitations on how and where the programmer could write results to memory,
    so algorithms requiring the ability to write to arbitrary locations in memory
    (scatter) could not run on a GPU. Moreover, it was nearly impossible to predict
    how your particular GPU would deal with floating-point data, if it handled floating-point
    data at all, so most scientific computations would be unable to use a GPU. Finally,
    when the program inevitably computed the incorrect results, failed to terminate,
    or simply hung the machine, there existed no reasonably good method to debug any
    code that was being executed on the GPU.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPU具有较高的算术吞吐量，这些实验的初步结果为GPU计算的光明未来带来了希望。然而，编程模型仍然过于限制，无法形成足够的开发者群体。由于程序只能从少数几个输入颜色和少数几个纹理单元中接收输入数据，因此存在严格的资源限制。程序员在内存中写入结果的方式和位置也存在严重限制，因此需要向任意内存位置写入数据（散射）的算法无法在GPU上运行。此外，几乎无法预测特定GPU如何处理浮点数据，甚至它是否能处理浮点数据，因此大多数科学计算无法使用GPU。最后，当程序不可避免地计算出错误结果、无法终止或直接挂起机器时，几乎没有有效的调试方法来调试GPU上执行的任何代码。
- en: As if the limitations weren’t severe enough, anyone who *still* wanted to use
    a GPU to perform general-purpose computations would need to learn OpenGL or DirectX
    since these remained the only means by which one could interact with a GPU. Not
    only did this mean storing data in graphics textures and executing computations
    by calling OpenGL or DirectX functions, but it meant writing the computations
    themselves in special graphics-only programming languages known as *shading languages*.
    Asking researchers to both cope with severe resource and programming restrictions
    as well as to learn computer graphics and shading languages before attempting
    to harness the computing power of their GPU proved too large a hurdle for wide
    acceptance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 就在这些限制已经足够严峻的情况下，任何*仍然*希望使用GPU进行通用计算的人员，都需要学习OpenGL或DirectX，因为这仍然是与GPU交互的唯一方式。这不仅意味着需要将数据存储在图形纹理中，并通过调用OpenGL或DirectX函数来执行计算，还意味着必须使用专门的图形编程语言来编写计算，这些语言被称为*着色语言*。要求研究人员在应对严重的资源和编程限制的同时，还要学习计算机图形学和着色语言，然后才能尝试利用GPU的计算能力，这对于广泛接受而言，显然是一个过于庞大的障碍。
- en: '**1.4 CUDA**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.4 CUDA**'
- en: It would not be until five years after the release of the GeForce 3 series that
    GPU computing would be ready for prime time. In November 2006, NVIDIA unveiled
    the industry’s first DirectX 10 GPU, the GeForce 8800 GTX. The GeForce 8800 GTX
    was also the first GPU to be built with NVIDIA’s CUDA Architecture. This architecture
    included several new components designed strictly for GPU computing and aimed
    to alleviate many of the limitations that prevented previous graphics processors
    from being legitimately useful for general-purpose computation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 直到GeForce 3系列发布五年后，GPU计算才准备好迎接主流市场。2006年11月，NVIDIA发布了业界首款DirectX 10 GPU——GeForce
    8800 GTX。GeForce 8800 GTX还是第一款采用NVIDIA CUDA架构的GPU。该架构包括几个全新的组件，专门用于GPU计算，旨在缓解以前的图形处理器无法真正用于通用计算的多种限制。
- en: '**1.4.1 What Is the CUDA Architecture?**'
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.4.1 什么是CUDA架构？**'
- en: Unlike previous generations that partitioned computing resources into vertex
    and pixel shaders, the CUDA Architecture included a unified shader pipeline, allowing
    each and every arithmetic logic unit (ALU) on the chip to be marshaled by a program
    intending to perform general-purpose computations. Because NVIDIA intended this
    new family of graphics processors to be used for general-purpose computing, these
    ALUs were built to comply with IEEE requirements for single-precision floating-point
    arithmetic and were designed to use an instruction set tailored for general computation
    rather than specifically for graphics. Furthermore, the execution units on the
    GPU were allowed arbitrary read and write access to memory as well as access to
    a software-managed cache known as *shared memory*. All of these features of the
    CUDA Architecture were added in order to create a GPU that would excel at computation
    in addition to performing well at traditional graphics tasks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与以往将计算资源划分为顶点着色器和像素着色器的架构不同，CUDA架构包括了一个统一的着色器流水线，允许每个算术逻辑单元（ALU）都可以被程序调度，用于执行通用计算任务。由于NVIDIA打算将这代图形处理器用于通用计算，这些ALU被设计为符合IEEE单精度浮点运算要求，并采用了为通用计算而非专门针对图形设计的指令集。此外，GPU上的执行单元允许对内存进行任意的读写访问，并可以访问一个由软件管理的缓存，称为*共享内存*。所有这些CUDA架构的特性都是为了创建一款在计算方面表现优异的GPU，同时也能很好地完成传统的图形任务。
- en: '**1.4.2 Using the CUDA Architecture**'
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.4.2 使用CUDA架构**'
- en: The effort by NVIDIA to provide consumers with a product for both computation
    and graphics could not stop at producing hardware incorporating the CUDA Architecture,
    though. Regardless of how many features NVIDIA added to its chips to facilitate
    computing, there continued to be no way to access these features without using
    OpenGL or DirectX. Not only would this have required users to continue to disguise
    their computations as graphics problems, but they would have needed to continue
    writing their computations in a graphics-oriented shading language such as OpenGL’s
    GLSL or Microsoft’s HLSL.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，NVIDIA为了向消费者提供既能进行计算又能进行图形处理的产品，其努力并不能仅仅停留在生产包含CUDA架构的硬件上。无论NVIDIA在其芯片上增加了多少功能来促进计算，仍然没有办法在不使用OpenGL或DirectX的情况下访问这些功能。这不仅要求用户继续将计算任务伪装成图形问题，而且还需要继续使用图形导向的着色语言（如OpenGL的GLSL或Microsoft的HLSL）来编写计算任务。
- en: To reach the maximum number of developers possible, NVIDIA took industry-standard
    C and added a relatively small number of keywords in order to harness some of
    the special features of the CUDA Architecture. A few months after the launch of
    the GeForce 8800 GTX, NVIDIA made public a compiler for this language, CUDA C.
    And with that, CUDA C became the first language specifically designed by a GPU
    company to facilitate general-purpose computing on GPUs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够覆盖尽可能多的开发者，NVIDIA在行业标准C语言的基础上添加了一小部分关键字，以便利用CUDA架构的一些特殊功能。在GeForce 8800
    GTX发布几个月后，NVIDIA公开了这门语言的编译器——CUDA C。由此，CUDA C成为了GPU公司专门为促进GPU上的通用计算而设计的首个语言。
- en: In addition to creating a language to write code for the GPU, NVIDIA also provides
    a specialized hardware driver to exploit the CUDA Architecture’s massive computational
    power. Users are no longer required to have any knowledge of the OpenGL or DirectX
    graphics programming interfaces, nor are they required to force their problem
    to look like a computer graphics task.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建一种用于编写GPU代码的语言外，NVIDIA还提供了一个专门的硬件驱动程序，以充分利用CUDA架构强大的计算能力。用户不再需要了解OpenGL或DirectX图形编程接口，也不需要强迫自己的问题看起来像计算机图形任务。
- en: '**1.5 Applications of CUDA**'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.5 CUDA的应用**'
- en: Since its debut in early 2007, a variety of industries and applications have
    enjoyed a great deal of success by choosing to build applications in CUDA C. These
    benefits often include orders-of-magnitude performance improvement over the previous
    state-of-the-art implementations. Furthermore, applications running on NVIDIA
    graphics processors enjoy superior performance per dollar and performance per
    watt than implementations built exclusively on traditional central processing
    technologies. The following represent just a few of the ways in which people have
    put CUDA C and the CUDA Architecture into successful use.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自2007年初首次亮相以来，多个行业和应用通过选择使用CUDA C构建应用程序获得了巨大的成功。这些好处通常包括相较于之前的最先进实现，性能提升了几个数量级。此外，运行在NVIDIA图形处理器上的应用程序，相较于仅基于传统中央处理技术的实现，享有更高的每美元性能和每瓦性能。以下是一些人们将CUDA
    C和CUDA架构成功应用的例子。
- en: '**1.5.1 Medical Imaging**'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.5.1 医学成像**'
- en: The number of people who have been affected by the tragedy of breast cancer
    has dramatically risen over the course of the past 20 years. Thanks in a large
    part to the tireless efforts of many, awareness and research into preventing and
    curing this terrible disease has similarly risen in recent years. Ultimately,
    every case of breast cancer should be caught early enough to prevent the ravaging
    side effects of radiation and chemotherapy, the permanent reminders left by surgery,
    and the deadly consequences in cases that fail to respond to treatment. As a result,
    researchers share a strong desire to find fast, accurate, and minimally invasive
    ways to identify the early signs of breast cancer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 过去20年里，受到乳腺癌悲剧影响的人数大幅增加。在许多人不懈努力的推动下，近年来乳腺癌预防和治疗的意识与研究也有所提升。最终，每一例乳腺癌都应该在足够早的阶段被发现，以防止辐射和化疗带来的剧烈副作用、手术留下的永久性痕迹以及那些未能响应治疗的病例所带来的致命后果。因此，研究人员都渴望找到快速、准确、且微创的方式来识别乳腺癌的早期迹象。
- en: The mammogram, one of the current best techniques for the early detection of
    breast cancer, has several significant limitations. Two or more images need to
    be taken, and the film needs to be developed and read by a skilled doctor to identify
    potential tumors. Additionally, this X-ray procedure carries with it all the risks
    of repeatedly radiating a patient’s chest. After careful study, doctors often
    require further, more specific imaging—and even biopsy—in an attempt to eliminate
    the possibility of cancer. These false positives incur expensive follow-up work
    and cause undue stress to the patient until final conclusions can be drawn.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺X线摄影是目前早期检测乳腺癌的最佳技术之一，但它也存在一些显著的局限性。需要拍摄两张或更多的影像，并且这些影像需要经过熟练的医生开发和读取，才能识别潜在的肿瘤。此外，这种X光检查会带来多次辐射病人胸部的风险。在仔细研究后，医生通常需要进一步进行更为具体的成像检查——甚至活检——以排除癌症的可能性。这些假阳性结果会导致昂贵的后续检查，并给病人带来不必要的压力，直到得出最终结论。
- en: 'Ultrasound imaging is safer than X-ray imaging, so doctors often use it in
    conjunction with mammography to assist in breast cancer care and diagnosis. But
    conventional breast ultrasound has its limitations as well. As a result, TechniScan
    Medical Systems was born. TechniScan has developed a promising, three-dimensional,
    ultrasound imaging method, but its solution had not been put into practice for
    a very simple reason: computation limitations. Simply put, converting the gathered
    ultrasound data into the three-dimensional imagery required computation considered
    prohibitively time-consuming and expensive for practical use.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 超声成像比X光成像更安全，因此医生常常将其与乳腺X线摄影联合使用，以辅助乳腺癌的护理和诊断。但传统的乳腺超声检查也有其局限性。因此，TechniScan
    Medical Systems应运而生。TechniScan开发了一种有前景的三维超声成像方法，但其解决方案未能投入实践的原因非常简单：计算限制。简而言之，将采集到的超声数据转化为三维图像所需的计算被认为过于耗时且昂贵，难以用于实际应用。
- en: The introduction of NVIDIA’s first GPU based on the CUDA Architecture along
    with its CUDA C programming language provided a platform on which TechniScan could
    convert the dreams of its founders into reality. As the name indicates, its Svara
    ultrasound imaging system uses ultrasonic waves to image the patient’s chest.
    The TechniScan Svara system relies on two NVIDIA Tesla C1060 processors in order
    to process the 35GB of data generated by a 15-minute scan. Thanks to the computational
    horsepower of the Tesla C1060, within 20 minutes the doctor can manipulate a highly
    detailed, three-dimensional image of the woman’s breast. TechniScan expects wide
    deployment of its Svara system starting in 2010.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 基于 CUDA 架构的首个 GPU 以及其 CUDA C 编程语言的推出，为 TechniScan 提供了一个平台，使其能够将创始人的梦想变为现实。顾名思义，Svara
    超声影像系统利用超声波对患者胸部进行成像。TechniScan Svara 系统依赖两颗 NVIDIA Tesla C1060 处理器来处理 15 分钟扫描生成的
    35GB 数据。得益于 Tesla C1060 的强大计算能力，医生可以在 20 分钟内操作出女性乳房的高度详细、三维图像。TechniScan 预计从 2010
    年开始，Svara 系统将广泛部署。
- en: '**1.5.2 Computational Fluid Dynamics**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.5.2 计算流体力学**'
- en: For many years, the design of highly efficient rotors and blades remained a
    black art of sorts. The astonishingly complex movement of air and fluids around
    these devices cannot be effectively modeled by simple formulations, so accurate
    simulations prove far too computationally expensive to be realistic. Only the
    largest supercomputers in the world could hope to offer computational resources
    on par with the sophisticated numerical models required to develop and validate
    designs. Since few have access to such machines, innovation in the design of such
    machines continued to stagnate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，高效转子和叶片的设计一直是一种近乎神秘的技术。这些设备周围空气和流体的复杂运动无法通过简单的公式有效建模，因此准确的仿真往往在计算上过于昂贵，不具备现实性。只有世界上最大型的超级计算机才能提供与开发和验证设计所需的复杂数值模型相匹配的计算资源。由于很少有人能够使用这样的计算机，这类机器的设计创新继续停滞不前。
- en: The University of Cambridge, in a great tradition started by Charles Babbage,
    is home to active research into advanced parallel computing. Dr. Graham Pullan
    and Dr. Tobias Brandvik of the “many-core group” correctly identified the potential
    in NVIDIA’s CUDA Architecture to accelerate computational fluid dynamics to unprecedented
    levels. Their initial investigations indicated that acceptable levels of performance
    could be delivered by GPU-powered, personal workstations. Later, the use of a
    small GPU cluster easily outperformed their much more costly supercomputers and
    further confirmed their suspicions that the capabilities of NVIDIA’s GPU matched
    extremely well with the problems they wanted to solve.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 剑桥大学，继查尔斯·巴贝奇开创的伟大传统之后，一直致力于先进并行计算的积极研究。来自“多核小组”的格雷厄姆·普兰博士和托比亚斯·布兰德维克博士正确地识别了
    NVIDIA CUDA 架构在加速计算流体力学方面的潜力，达到了前所未有的水平。他们最初的研究表明，GPU 驱动的个人工作站能够提供可接受的性能水平。随后，使用小型
    GPU 集群轻松超越了他们更为昂贵的超级计算机，进一步确认了他们的猜想，即 NVIDIA GPU 的能力与他们想要解决的问题高度契合。
- en: For the researchers at Cambridge, the massive performance gains offered by CUDA
    C represent more than a simple, incremental boost to their supercomputing resources.
    The availability of copious amounts of low-cost GPU computation empowered the
    Cambridge researchers to perform rapid experimentation. Receiving experimental
    results within seconds streamlined the feedback process on which researchers rely
    in order to arrive at breakthroughs. As a result, the use of GPU clusters has
    fundamentally transformed the way they approach their research. Nearly interactive
    simulation has unleashed new opportunities for innovation and creativity in a
    previously stifled field of research.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于剑桥的研究人员来说，CUDA C 提供的巨大性能提升不仅仅是对其超级计算资源的简单、渐进性的增强。大量低成本 GPU 计算资源的可用性使得剑桥的研究人员能够进行快速实验。在几秒钟内获得实验结果简化了研究人员依赖的反馈过程，从而帮助他们实现突破性进展。因此，GPU
    集群的使用从根本上改变了他们进行研究的方式。近乎交互式的仿真为以前受限的研究领域释放了新的创新和创意机会。
- en: '**1.5.3 Environmental Science**'
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**1.5.3 环境科学**'
- en: The increasing need for environmentally sound consumer goods has arisen as a
    natural consequence of the rapidly escalating industrialization of the global
    economy. Growing concerns over climate change, the spiraling prices of fuel, and
    the growing level of pollutants in our air and water have brought into sharp relief
    the collateral damage of such successful advances in industrial output. Detergents
    and cleaning agents have long been some of the most necessary yet potentially
    calamitous consumer products in regular use. As a result, many scientists have
    begun exploring methods for reducing the environmental impact of such detergents
    without reducing their efficacy. Gaining something for nothing can be a tricky
    proposition, however.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对环境友好型消费品需求的增加是全球经济快速工业化的自然结果。对气候变化的日益关注、燃料价格的不断上涨以及空气和水中污染物水平的不断增加，使得这种工业化进步的副作用变得尤为明显。洗涤剂和清洁剂长期以来一直是日常使用中最必要但也可能带来灾难性后果的消费品。因此，许多科学家开始探索在不降低其效能的情况下减少此类洗涤剂环境影响的方法。然而，要在不付出代价的情况下获得一些好处，可不是一件容易的事。
- en: The key components to cleaning agents are known as *surfactants*. Surfactant
    molecules determine the cleaning capacity and texture of detergents and shampoos,
    but they are often implicated as the most environmentally devastating component
    of cleaning products. These molecules attach themselves to dirt and then mix with
    water such that the surfactants can be rinsed away along with the dirt. Traditionally,
    measuring the cleaning value of a new surfactant would require extensive laboratory
    testing involving numerous combinations of materials and impurities to be cleaned.
    This process, not surprisingly, can be very slow and expensive.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 清洁剂的关键成分被称为*表面活性剂*。表面活性剂分子决定了洗涤剂和洗发水的清洁能力和质地，但它们通常被认为是清洁产品中最具环境破坏性的成分。这些分子附着在污垢上，然后与水混合，使得表面活性剂能够与污垢一起被冲洗掉。传统上，衡量新表面活性剂的清洁价值需要大量的实验室测试，涉及到多种材料和杂质的组合。这一过程，毫不意外，通常非常缓慢且昂贵。
- en: Temple University has been working with industry leader Procter & Gamble to
    use molecular simulation of surfactant interactions with dirt, water, and other
    materials. The introduction of computer simulations serves not just to accelerate
    a traditional lab approach, but it extends the breadth of testing to numerous
    variants of environmental conditions, far more than could be practically tested
    in the past. Temple researchers used the GPU-accelerated Highly Optimized Object-oriented
    Many-particle Dynamics (HOOMD) simulation software written by the Department of
    Energy’s Ames Laboratory. By splitting their simulation across two NVIDIA Tesla
    GPUs, they were able to achieve equivalent performance to the 128 CPU cores of
    the Cray XT3 and to the 1024 CPUs of an IBM BlueGene/L machine. By increasing
    the number of Tesla GPUs in their solution, they are already simulating surfactant
    interactions at 16 times the performance of previous platforms. Since NVIDIA’s
    CUDA has reduced the time to complete such comprehensive simulations from several
    weeks to a few hours, the years to come should offer a dramatic rise in products
    that have both increased effectiveness and reduced environmental impact.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 天普大学一直在与行业领导者宝洁公司合作，利用分子模拟来研究表面活性剂与污垢、水和其他材料的相互作用。计算机模拟的引入不仅加速了传统实验室方法，还将测试的范围扩展到了多种环境条件的变体，远远超过了过去在实际测试中能覆盖的范围。天普大学的研究人员使用了由美国能源部阿梅斯实验室编写的GPU加速高度优化面向对象的多粒子动力学（HOOMD）模拟软件。通过将模拟分布到两块NVIDIA
    Tesla GPU上，他们成功地达到了与Cray XT3的128个CPU核心和IBM BlueGene/L机器的1024个CPU的相当性能。通过增加Tesla
    GPU的数量，他们的解决方案已经能够以比以往平台快16倍的性能模拟表面活性剂的相互作用。由于NVIDIA的CUDA技术将完成此类综合模拟的时间从几周缩短至几小时，未来几年应会大幅提高那些既高效又能减少环境影响的产品的出现。
- en: '**1.6 Chapter Review**'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1.6 章节回顾**'
- en: The computing industry is at the precipice of a parallel computing revolution,
    and NVIDIA’s CUDA C has thus far been one of the most successful languages ever
    designed for parallel computing. Throughout the course of this book, we will help
    you learn how to write your own code in CUDA C. We will help you learn the special
    extensions to C and the application programming interfaces that NVIDIA has created
    in service of GPU computing. You are *not* expected to know OpenGL or DirectX,
    nor are you expected to have any background in computer graphics.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 计算行业正处于并行计算革命的边缘，而NVIDIA的CUDA C迄今为止已经成为并行计算领域最成功的语言之一。在本书的学习过程中，我们将帮助你学习如何用CUDA
    C编写自己的代码。我们将帮助你了解NVIDIA为GPU计算开发的C语言扩展和应用程序接口。你*不需要*了解OpenGL或DirectX，也不需要具备计算机图形学方面的背景。
- en: We will not be covering the basics of programming in C, so we do not recommend
    this book to people completely new to computer programming. Some familiarity with
    parallel programming might help, although we do not *expect* you to have done
    any parallel programming. Any terms or concepts related to parallel programming
    that you will need to understand will be explained in the text. In fact, there
    may be some occasions when you find that knowledge of traditional parallel programming
    will cause you to make assumptions about GPU computing that prove untrue. So in
    reality, a moderate amount of experience with C or C++ programming is the only
    prerequisite to making it through this book.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会涉及C语言编程的基础内容，因此我们不推荐完全没有计算机编程经验的人阅读本书。对并行编程有一些了解会有所帮助，尽管我们并不*期望*你有并行编程经验。本书中将会解释你需要理解的与并行编程相关的术语或概念。事实上，有时候你可能会发现，传统的并行编程知识会让你对GPU计算产生错误的假设。所以，实际上，具备一定的C或C++编程经验是完成本书学习的唯一前提。
- en: In the next chapter, we will help you set up your machine for GPU computing,
    ensuring that you have both the hardware and the software components necessary
    get started. After that, you’ll be ready to get your hands dirty with CUDA C.
    If you already have some experience with CUDA C or you’re sure that your system
    has been properly set up to do development in CUDA C, you can skip to [Chapter
    3](ch03.html#ch03).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将帮助你为GPU计算配置机器，确保你拥有开始所需的硬件和软件组件。之后，你就可以开始动手实践CUDA C了。如果你已经有一些CUDA C的经验，或者确定你的系统已经正确配置，可以直接跳到[第3章](ch03.html#ch03)。
