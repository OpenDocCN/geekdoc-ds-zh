- en: External Memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/external-memory/](https://en.algorithmica.org/hpc/external-memory/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How long does it take to add two numbers together? Being one of the most frequently
    used instructions, `add` by itself only takes one cycle to execute. So, if the
    data is already loaded into registers, it takes one just cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'But in the general case (`*c = *a + *b`), we need to fetch its operands from
    memory first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: When you fetch anything from memory, there is always some latency before the
    data arrives. Moreover, the request doesn’t go directly to its ultimate storage
    location, but it first goes through a complex system of address translation units
    and caching layers designed to both help in memory management and reduce latency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the only correct answer to this question is “it depends” — primarily
    on where the operands are stored:'
  prefs: []
  type: TYPE_NORMAL
- en: If the data is stored in the main memory (RAM), it will take around ~100ns,
    or about 200 cycles, to fetch it, and then another 200 cycles to write it back.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it was accessed recently, it is probably *cached* and will take less than
    that to fetch, depending on how long ago it was accessed — it could be ~50 cycles
    for the slowest layer of cache and around 4-5 cycles for the fastest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But it could also be stored on some type of *external memory* such as a hard
    drive, and in this case, it will take around 5ms, or roughly $10^7$ cycles (!)
    to access it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such a high variance of memory performance is caused by the fact that memory
    hardware doesn’t follow the same [laws of silicon scaling](/hpc/complexity/hardware)
    as CPU chips do. Memory is still improving through other means, but if 50 years
    ago memory timings were roughly on the same scale with the instruction latencies,
    nowadays they lag far behind.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45a70362bd76c5497d92f72512eb0c4a.png)'
  prefs: []
  type: TYPE_IMG
- en: To be less of a limiting factor, modern memory systems are becoming increasingly
    [hierarchical](hierarchy), where the higher layers trade off some of their capacity
    for reduced latency. As these characteristics may change in the orders of magnitude
    between the layers — especially in the case of external memory types — it became
    crucial for many memory-intensive algorithms to optimize their I/O operations
    before anything else.
  prefs: []
  type: TYPE_NORMAL
- en: This prompted the creation of a new cost model, called the *external memory
    model*, whose only primitive operations are block reads and writes, and everything
    else has zero cost as long as it only involves data stored in a limited-sized
    local memory. It spawned an exciting new field of *external memory algorithms*,
    which we will study in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '[← Montgomery Multiplication](https://en.algorithmica.org/hpc/number-theory/montgomery/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[← ../Number Theory](https://en.algorithmica.org/hpc/number-theory/)[Memory
    Hierarchy →](https://en.algorithmica.org/hpc/external-memory/hierarchy/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[../RAM & CPU Caches →](https://en.algorithmica.org/hpc/cpu-cache/)'
  prefs: []
  type: TYPE_NORMAL
