- en: '7.4\. Limit behavior 2: convergence to equilibrium#'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html](https://mmids-textbook.github.io/chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We continue our study of the long-term behavior of a chain. Again, we restrict
    ourselves to finite-space discrete-time Markov chains that are also time-homogeneous.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.1\. Definitions[#](#definitions "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have established the existence and uniqueness of a stationary distribution
    (at least in the irreducible case), it remains to justify its relevance. As we
    indicated before, the fixed-point nature of the stationary distribution definition
    suggests that it arises as a limit of repeatedly applying \(P\). Indeed it can
    be shown that, starting from any distribution, the state distribution at time
    \(t\) converges to the stationary distribution as \(t \to +\infty\) – under an
    additional assumption.
  prefs: []
  type: TYPE_NORMAL
- en: The additional assumption involves issues of periodicity. The following example
    will suffice to illustrate.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Periodic Chain)** Consider a two-state Markov chain with
    transition matrix'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} P =\begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix}. \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Note that this chain is irreducible. Its unique stationary distribution is \(\bpi
    = (1/2, 1/2)^T\) since indeed
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bpi P = (1/2, 1/2)^T \begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix}
    = (1/2, 1/2)^T = \bpi. \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: We compute the distribution at time \(t\), started from state \(1\). That is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu = (1, 0)^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu P = (0, 1)^T, \]\[ \bmu P^2 = (1,0)^T, \]\[ \bmu P^3 = (0,1)^T, \]
  prefs: []
  type: TYPE_NORMAL
- en: and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In general, by induction,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bmu P^k = \begin{cases} (1,0)^T & \text{if $k$ is even}\\ (0,1)^T
    & \text{if $k$ is odd}. \end{cases} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Clearly the distribution is not converging. Note however that the time average
    does
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} \frac{1}{t}\sum_{k \leq t} \bmu P^k = (1/2, 1/2)^T =
    \bpi. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: We will need the following definition.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Aperiodic)** \(\idx{aperiodic}\xdi\) Let \((X_t)_{t \geq
    0}\) be a Markov chain over a finite state space \(\mathcal{S}\). We say that
    state \(i \in \mathcal{S}\) is aperiodic if'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i\,|\,X_0 = i] > 0, \]
  prefs: []
  type: TYPE_NORMAL
- en: for all sufficiently large \(t\). A chain is aperiodic if all its states are.
    \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Periodic Chain, continued)** Going back to the two-state
    chain above, we note that neither state is aperiodic. For state \(1\), we have
    shown that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = 1\,|\, X_0 = 1] = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: for all \(t\) odd. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: We will not need to explore this definition in great details here. Instead we
    give a simple *sufficient* condition that is typically good enough for data science
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Lazy)** \(\idx{lazy}\xdi\) We say that a Markov chain \((X_t)_{t
    \geq 0}\) is lazy if every state \(i\) satisfies'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_1 = i\,|\,X_0 = i] > 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, all entries on the diagonal of the transition matrix are strictly
    positive. \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: Graphically, the chain has self-loops\(\idx{self-loop}\xdi\) on each vertex.
    This terminology (which is not entirely standard) emphasizes the idea that the
    chain can “lazily” stay in its current state rather than always transitioning
    to a different one.
  prefs: []
  type: TYPE_NORMAL
- en: We check that a lazy chain is necessarily aperiodic. For any state \(i \in \mathcal{S}\)
    and any \(t\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i\,|\,X_0 = i] \geq \prod_{s = 1}^t \P[X_{s} = i\,|\,X_{s-1} = i]
    = (\P[X_1 = i\,|\,X_0 = i])^t > 0, \]
  prefs: []
  type: TYPE_NORMAL
- en: by assumption. In words, the probability of being at \(i\) at time \(t\) given
    that we started at \(i\) is at least the probability that we never left.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** Any Markov chain can be modified to be lazy by adding self-loops
    to all vertices. Specifically, let \(P = (p_{i,j})_{i,j} \in \mathbb{R}^{n \times
    n}\) be the transition matrix of a Markov chain on \([n]\). Consider the modified
    transition matrix \(Q = (q_{i,j})_{i,j}\) defined as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ Q = \frac{1}{2}(I_{n \times n} + P). \]
  prefs: []
  type: TYPE_NORMAL
- en: We check that this is indeed a stochastic matrix. For each \(i, j \in [n]\),
    we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ q_{i,j} = \frac{1}{2} \mathbf{1}_{i = j} + \frac{1}{2} p_{i,j} \geq \frac{1}{2}
    p_{i,j} \geq 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{\ell=1}^n q_{i,\ell} = \sum_{\ell=1}^n \left[\frac{1}{2} \mathbf{1}_{i
    = \ell} + \frac{1}{2} p_{i,\ell}\right] = \frac{1}{2} \sum_{\ell=1}^n \mathbf{1}_{i
    = \ell} + \frac{1}{2} \sum_{\ell=1}^n p_{i,\ell} = \frac{1}{2} + \frac{1}{2} =
    1. \]
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we note that \(Q\) is lazy since
  prefs: []
  type: TYPE_NORMAL
- en: \[ q_{i,i} = \frac{1}{2} \mathbf{1}_{i = i} + \frac{1}{2} p_{i,i} = \frac{1}{2}
    + \frac{1}{2} p_{i,i} \geq \frac{1}{2} > 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: The chain \(Q\) is often referred to as the “lazy version” of \(P\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.2\. Convergence theorems[#](#convergence-theorems "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are ready to state two key theorems.
  prefs: []
  type: TYPE_NORMAL
- en: First, the *Convergence to Equilibrium Theorem* applies to irreducible and aperiodic
    chains. Such chains have a unique stationary distribution. The theorem says that,
    started from any initial distribution, the distribution at time \(t\) converges
    to the stationary distribution as \(t \to +\infty\).
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence to Equilibrium)** \(\idx{convergence to equilibrium
    theorem}\xdi\) Let \((X_t)_{t\geq 0}\) be a finite, irreducible and aperiodic
    Markov chain with unique stationary distribution \(\bpi\). Then for any initial
    distribution \(\bmu\) and any state \(i\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i] \to \pi_i, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, this theorem should look familiar. Using the formula \((\bmu
    P^t)_i\) for the probability that the state is \(i\) at time \(t\), we can rephrase
    the theorem in matrix form as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu P^t \to \bpi, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). This is highly reminiscent of the *Power Iteration Lemma*.
    Here repeated multiplication by \(P\) starting from an arbitrary distribution
    converges to \(\bpi\), which recall is a left eigenvector of \(P\) with eigenvalue
    \(1\). Unlike the *Power Iteration Lemma*, there is no need to normalize here.
    This is because we implicitly work with the \(\ell_1\)-norm and \(P\) is stochastic,
    thereby preserving the norm.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the *Ergodic Theorem* applies to irreducible (but not necessarily aperiodic)
    chains. Again such have a unique stationary distribution. The theorem says that,
    started from any initial distribution, the frequency of visits to any state \(i\)
    converges to the stationary distribution. Below, we use the notation \(\mathbf{1}[X_s
    = i]\) which is \(1\) when \(X_s = i\) and \(0\) otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Ergodic)** \(\idx{ergodic theorem}\xdi\) Let \((X_t)_{t\geq
    0}\) be a finite and irreducible Markov chain with unique stationary distribution
    \(\bpi\). Then for any initial distribution \(\bmu\) and any state \(i\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{t} \sum_{s = 0}^t \mathbf{1}[X_s = i] \to \pi_i, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Above, \(\sum_{s = 0}^t \mathbf{1}[X_s = i]\) is the number of visits to \(i\)
    up to time \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: Note that neither of these two theorems immediately implies the other. They
    are both useful in their own way.
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** The *Convergence to Equilibrium Theorem* implies that
    we can use power iteration to compute the unique stationary diistribution in the
    irreducible case. We revisit the *Robot Vaccum Example*. We initialize with the
    uniform distribution, then repeatedly multiply by \(P\).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We repeat, say, \(10\) more times and compare to the truth `pi_robot`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We see that a small number of iterations sufficed to get an accurate answer.
    In general, the speed of convergence depends on the eigenvalues of \(P\) that
    are strictly smaller than \(1\) in absolute value.
  prefs: []
  type: TYPE_NORMAL
- en: We can also check the *Ergodic Theorem* through simulation. We generate a long
    sample path and compare the state visit frequencies to `pi_robot`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** The mixing time is an important quantity in the study of Markov
    chains. Ask your favorite AI chatbot to define this concept and discuss its relevance
    to the convergence of Markov chains. Explore some bounds on the mixing time for
    specific classes of Markov chains. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following is a sufficient condition for a Markov chain to
    be aperiodic?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The chain is irreducible.
  prefs: []
  type: TYPE_NORMAL
- en: b) The chain has a unique stationary distribution.
  prefs: []
  type: TYPE_NORMAL
- en: c) The chain is lazy.
  prefs: []
  type: TYPE_NORMAL
- en: d) The chain has a finite state space.
  prefs: []
  type: TYPE_NORMAL
- en: '**2** In a Markov chain with state space \(S\) and transition matrix \(P\),
    what does it mean if the chain is lazy?'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\mathbb{E}[X_t] = 0\) for all \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: b) \(P_{ii} > 0\) for all \(i \in S\).
  prefs: []
  type: TYPE_NORMAL
- en: c) \(P_{ij} = 0\) for all \(i \ne j\).
  prefs: []
  type: TYPE_NORMAL
- en: d) \(\mathrm{Var}(X_t) = 1\) for all \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: '**3** The Convergence to Equilibrium Theorem applies to which type of Markov
    chains?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Irreducible and aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: b) Irreducible and periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: c) Reducible and aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: d) Reducible and periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: '**4** The Ergodic Theorem applies to which type of Markov chains?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Irreducible chains
  prefs: []
  type: TYPE_NORMAL
- en: b) Aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: c) Reducible chains
  prefs: []
  type: TYPE_NORMAL
- en: d) Periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: '**5** Which of the following describes a key difference between the Convergence
    to Equilibrium Theorem and the Ergodic Theorem?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The Convergence to Equilibrium Theorem applies to periodic chains, while
    the Ergodic Theorem applies to aperiodic chains.
  prefs: []
  type: TYPE_NORMAL
- en: b) The Convergence to Equilibrium Theorem concerns the state distribution, while
    the Ergodic Theorem concerns the frequency of state visits.
  prefs: []
  type: TYPE_NORMAL
- en: c) The Convergence to Equilibrium Theorem requires a diagonal transition matrix,
    while the Ergodic Theorem does not.
  prefs: []
  type: TYPE_NORMAL
- en: d) The Convergence to Equilibrium Theorem is applicable only to finite Markov
    chains, while the Ergodic Theorem is not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: c. Justification: The text states, “We check that a lazy chain
    is necessarily aperiodic.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: A weakly lazy Markov chain is defined as having
    all diagonal entries of the transition matrix strictly positive, i.e., \(P_{ii}
    > 0\) for all \(i \in S\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: a. Justification: The text states, “First, the Convergence to
    Equilibrium Theorem applies to irreducible and aperiodic chains.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: The text states, “Second, the Ergodic Theorem
    applies to irreducible (but not necessarily aperiodic) chains.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: b. Justification: The Convergence to Equilibrium Theorem addresses
    the convergence of the state distribution to the stationary distribution, while
    the Ergodic Theorem focuses on the frequency of visits to any state converging
    to the stationary distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.1\. Definitions[#](#definitions "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have established the existence and uniqueness of a stationary distribution
    (at least in the irreducible case), it remains to justify its relevance. As we
    indicated before, the fixed-point nature of the stationary distribution definition
    suggests that it arises as a limit of repeatedly applying \(P\). Indeed it can
    be shown that, starting from any distribution, the state distribution at time
    \(t\) converges to the stationary distribution as \(t \to +\infty\) – under an
    additional assumption.
  prefs: []
  type: TYPE_NORMAL
- en: The additional assumption involves issues of periodicity. The following example
    will suffice to illustrate.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Periodic Chain)** Consider a two-state Markov chain with
    transition matrix'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} P =\begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix}. \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Note that this chain is irreducible. Its unique stationary distribution is \(\bpi
    = (1/2, 1/2)^T\) since indeed
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bpi P = (1/2, 1/2)^T \begin{pmatrix} 0 & 1\\ 1 & 0 \end{pmatrix}
    = (1/2, 1/2)^T = \bpi. \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: We compute the distribution at time \(t\), started from state \(1\). That is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu = (1, 0)^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu P = (0, 1)^T, \]\[ \bmu P^2 = (1,0)^T, \]\[ \bmu P^3 = (0,1)^T, \]
  prefs: []
  type: TYPE_NORMAL
- en: and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In general, by induction,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bmu P^k = \begin{cases} (1,0)^T & \text{if $k$ is even}\\ (0,1)^T
    & \text{if $k$ is odd}. \end{cases} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: Clearly the distribution is not converging. Note however that the time average
    does
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} \frac{1}{t}\sum_{k \leq t} \bmu P^k = (1/2, 1/2)^T =
    \bpi. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: We will need the following definition.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Aperiodic)** \(\idx{aperiodic}\xdi\) Let \((X_t)_{t \geq
    0}\) be a Markov chain over a finite state space \(\mathcal{S}\). We say that
    state \(i \in \mathcal{S}\) is aperiodic if'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i\,|\,X_0 = i] > 0, \]
  prefs: []
  type: TYPE_NORMAL
- en: for all sufficiently large \(t\). A chain is aperiodic if all its states are.
    \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Periodic Chain, continued)** Going back to the two-state
    chain above, we note that neither state is aperiodic. For state \(1\), we have
    shown that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = 1\,|\, X_0 = 1] = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: for all \(t\) odd. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: We will not need to explore this definition in great details here. Instead we
    give a simple *sufficient* condition that is typically good enough for data science
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Lazy)** \(\idx{lazy}\xdi\) We say that a Markov chain \((X_t)_{t
    \geq 0}\) is lazy if every state \(i\) satisfies'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_1 = i\,|\,X_0 = i] > 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, all entries on the diagonal of the transition matrix are strictly
    positive. \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: Graphically, the chain has self-loops\(\idx{self-loop}\xdi\) on each vertex.
    This terminology (which is not entirely standard) emphasizes the idea that the
    chain can “lazily” stay in its current state rather than always transitioning
    to a different one.
  prefs: []
  type: TYPE_NORMAL
- en: We check that a lazy chain is necessarily aperiodic. For any state \(i \in \mathcal{S}\)
    and any \(t\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i\,|\,X_0 = i] \geq \prod_{s = 1}^t \P[X_{s} = i\,|\,X_{s-1} = i]
    = (\P[X_1 = i\,|\,X_0 = i])^t > 0, \]
  prefs: []
  type: TYPE_NORMAL
- en: by assumption. In words, the probability of being at \(i\) at time \(t\) given
    that we started at \(i\) is at least the probability that we never left.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** Any Markov chain can be modified to be lazy by adding self-loops
    to all vertices. Specifically, let \(P = (p_{i,j})_{i,j} \in \mathbb{R}^{n \times
    n}\) be the transition matrix of a Markov chain on \([n]\). Consider the modified
    transition matrix \(Q = (q_{i,j})_{i,j}\) defined as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ Q = \frac{1}{2}(I_{n \times n} + P). \]
  prefs: []
  type: TYPE_NORMAL
- en: We check that this is indeed a stochastic matrix. For each \(i, j \in [n]\),
    we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ q_{i,j} = \frac{1}{2} \mathbf{1}_{i = j} + \frac{1}{2} p_{i,j} \geq \frac{1}{2}
    p_{i,j} \geq 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{\ell=1}^n q_{i,\ell} = \sum_{\ell=1}^n \left[\frac{1}{2} \mathbf{1}_{i
    = \ell} + \frac{1}{2} p_{i,\ell}\right] = \frac{1}{2} \sum_{\ell=1}^n \mathbf{1}_{i
    = \ell} + \frac{1}{2} \sum_{\ell=1}^n p_{i,\ell} = \frac{1}{2} + \frac{1}{2} =
    1. \]
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we note that \(Q\) is lazy since
  prefs: []
  type: TYPE_NORMAL
- en: \[ q_{i,i} = \frac{1}{2} \mathbf{1}_{i = i} + \frac{1}{2} p_{i,i} = \frac{1}{2}
    + \frac{1}{2} p_{i,i} \geq \frac{1}{2} > 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: The chain \(Q\) is often referred to as the “lazy version” of \(P\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.2\. Convergence theorems[#](#convergence-theorems "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are ready to state two key theorems.
  prefs: []
  type: TYPE_NORMAL
- en: First, the *Convergence to Equilibrium Theorem* applies to irreducible and aperiodic
    chains. Such chains have a unique stationary distribution. The theorem says that,
    started from any initial distribution, the distribution at time \(t\) converges
    to the stationary distribution as \(t \to +\infty\).
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence to Equilibrium)** \(\idx{convergence to equilibrium
    theorem}\xdi\) Let \((X_t)_{t\geq 0}\) be a finite, irreducible and aperiodic
    Markov chain with unique stationary distribution \(\bpi\). Then for any initial
    distribution \(\bmu\) and any state \(i\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \P[X_t = i] \to \pi_i, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, this theorem should look familiar. Using the formula \((\bmu
    P^t)_i\) for the probability that the state is \(i\) at time \(t\), we can rephrase
    the theorem in matrix form as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bmu P^t \to \bpi, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). This is highly reminiscent of the *Power Iteration Lemma*.
    Here repeated multiplication by \(P\) starting from an arbitrary distribution
    converges to \(\bpi\), which recall is a left eigenvector of \(P\) with eigenvalue
    \(1\). Unlike the *Power Iteration Lemma*, there is no need to normalize here.
    This is because we implicitly work with the \(\ell_1\)-norm and \(P\) is stochastic,
    thereby preserving the norm.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the *Ergodic Theorem* applies to irreducible (but not necessarily aperiodic)
    chains. Again such have a unique stationary distribution. The theorem says that,
    started from any initial distribution, the frequency of visits to any state \(i\)
    converges to the stationary distribution. Below, we use the notation \(\mathbf{1}[X_s
    = i]\) which is \(1\) when \(X_s = i\) and \(0\) otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Ergodic)** \(\idx{ergodic theorem}\xdi\) Let \((X_t)_{t\geq
    0}\) be a finite and irreducible Markov chain with unique stationary distribution
    \(\bpi\). Then for any initial distribution \(\bmu\) and any state \(i\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{t} \sum_{s = 0}^t \mathbf{1}[X_s = i] \to \pi_i, \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(t \to +\infty\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Above, \(\sum_{s = 0}^t \mathbf{1}[X_s = i]\) is the number of visits to \(i\)
    up to time \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: Note that neither of these two theorems immediately implies the other. They
    are both useful in their own way.
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** The *Convergence to Equilibrium Theorem* implies that
    we can use power iteration to compute the unique stationary diistribution in the
    irreducible case. We revisit the *Robot Vaccum Example*. We initialize with the
    uniform distribution, then repeatedly multiply by \(P\).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We repeat, say, \(10\) more times and compare to the truth `pi_robot`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We see that a small number of iterations sufficed to get an accurate answer.
    In general, the speed of convergence depends on the eigenvalues of \(P\) that
    are strictly smaller than \(1\) in absolute value.
  prefs: []
  type: TYPE_NORMAL
- en: We can also check the *Ergodic Theorem* through simulation. We generate a long
    sample path and compare the state visit frequencies to `pi_robot`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** The mixing time is an important quantity in the study of Markov
    chains. Ask your favorite AI chatbot to define this concept and discuss its relevance
    to the convergence of Markov chains. Explore some bounds on the mixing time for
    specific classes of Markov chains. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following is a sufficient condition for a Markov chain to
    be aperiodic?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The chain is irreducible.
  prefs: []
  type: TYPE_NORMAL
- en: b) The chain has a unique stationary distribution.
  prefs: []
  type: TYPE_NORMAL
- en: c) The chain is lazy.
  prefs: []
  type: TYPE_NORMAL
- en: d) The chain has a finite state space.
  prefs: []
  type: TYPE_NORMAL
- en: '**2** In a Markov chain with state space \(S\) and transition matrix \(P\),
    what does it mean if the chain is lazy?'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\mathbb{E}[X_t] = 0\) for all \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: b) \(P_{ii} > 0\) for all \(i \in S\).
  prefs: []
  type: TYPE_NORMAL
- en: c) \(P_{ij} = 0\) for all \(i \ne j\).
  prefs: []
  type: TYPE_NORMAL
- en: d) \(\mathrm{Var}(X_t) = 1\) for all \(t\).
  prefs: []
  type: TYPE_NORMAL
- en: '**3** The Convergence to Equilibrium Theorem applies to which type of Markov
    chains?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Irreducible and aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: b) Irreducible and periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: c) Reducible and aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: d) Reducible and periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: '**4** The Ergodic Theorem applies to which type of Markov chains?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Irreducible chains
  prefs: []
  type: TYPE_NORMAL
- en: b) Aperiodic chains
  prefs: []
  type: TYPE_NORMAL
- en: c) Reducible chains
  prefs: []
  type: TYPE_NORMAL
- en: d) Periodic chains
  prefs: []
  type: TYPE_NORMAL
- en: '**5** Which of the following describes a key difference between the Convergence
    to Equilibrium Theorem and the Ergodic Theorem?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The Convergence to Equilibrium Theorem applies to periodic chains, while
    the Ergodic Theorem applies to aperiodic chains.
  prefs: []
  type: TYPE_NORMAL
- en: b) The Convergence to Equilibrium Theorem concerns the state distribution, while
    the Ergodic Theorem concerns the frequency of state visits.
  prefs: []
  type: TYPE_NORMAL
- en: c) The Convergence to Equilibrium Theorem requires a diagonal transition matrix,
    while the Ergodic Theorem does not.
  prefs: []
  type: TYPE_NORMAL
- en: d) The Convergence to Equilibrium Theorem is applicable only to finite Markov
    chains, while the Ergodic Theorem is not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: c. Justification: The text states, “We check that a lazy chain
    is necessarily aperiodic.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: A weakly lazy Markov chain is defined as having
    all diagonal entries of the transition matrix strictly positive, i.e., \(P_{ii}
    > 0\) for all \(i \in S\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: a. Justification: The text states, “First, the Convergence to
    Equilibrium Theorem applies to irreducible and aperiodic chains.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: The text states, “Second, the Ergodic Theorem
    applies to irreducible (but not necessarily aperiodic) chains.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: b. Justification: The Convergence to Equilibrium Theorem addresses
    the convergence of the state distribution to the stationary distribution, while
    the Ergodic Theorem focuses on the frequency of visits to any state converging
    to the stationary distribution.'
  prefs: []
  type: TYPE_NORMAL
