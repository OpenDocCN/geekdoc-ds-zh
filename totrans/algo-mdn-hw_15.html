<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Instruction Tables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Instruction Tables</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/pipelining/tables/">https://en.algorithmica.org/hpc/pipelining/tables/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>Interleaving the stages of execution is a general idea in digital electronics, and it is applied not only in the main CPU pipeline, but also on the level of separate instructions and <a href="/hpc/cpu-cache/mlp">memory</a>. Most execution units have their own little pipelines and can take another instruction just one or two cycles after the previous one.</p><p>In this context, it makes sense to use two different “<a href="/hpc/complexity">costs</a>” for instructions:</p><ul><li><em>Latency</em>: how many cycles are needed to receive the results of an instruction.</li><li><em>Throughput</em>: how many instructions can be, on average, executed per cycle.</li></ul><p>You can get latency and throughput numbers for a specific architecture from special documents called <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction tables</a>. Here are some sample values for my Zen 2 (all specified for 32-bit operands, if there is any difference):</p><table><thead><tr><th>Instruction</th><th>Latency</th><th style="text-align:left">RThroughput</th></tr></thead><tbody><tr><td><code>jmp</code></td><td>-</td><td style="text-align:left">2</td></tr><tr><td><code>mov r, r</code></td><td>-</td><td style="text-align:left">1/4</td></tr><tr><td><code>mov r, m</code></td><td>4</td><td style="text-align:left">1/2</td></tr><tr><td><code>mov m, r</code></td><td>3</td><td style="text-align:left">1</td></tr><tr><td><code>add</code></td><td>1</td><td style="text-align:left">1/3</td></tr><tr><td><code>cmp</code></td><td>1</td><td style="text-align:left">1/4</td></tr><tr><td><code>popcnt</code></td><td>1</td><td style="text-align:left">1/4</td></tr><tr><td><code>mul</code></td><td>3</td><td style="text-align:left">1</td></tr><tr><td><code>div</code></td><td>13-28</td><td style="text-align:left">13-28</td></tr></tbody></table><p>Some comments:</p><ul><li>Because our minds are so used to the cost model where “more” means “worse,” people mostly use <em>reciprocals</em> of throughput instead of throughput.</li><li>If a certain instruction is especially frequent, its execution unit could be duplicated to increase its throughput — possibly to even more than one, but not higher than the <a href="/hpc/architecture/layout">decode width</a>.</li><li>Some instructions have a latency of 0. This means that these instruction are used to control the scheduler and don’t reach the execution stage. They still have non-zero reciprocal throughput because the <a href="/hpc/architecture/layout">CPU front-end</a> still needs to process them.</li><li>Most instructions are pipelined, and if they have the reciprocal throughput of $n$, this usually means that their execution unit can take another instruction after $n$ cycles (and if it is below 1, this means that there are multiple execution units, all capable of taking another instruction on the next cycle). One notable exception is <a href="/hpc/arithmetic/division">integer division</a>: it is either very poorly pipelined or not pipelined at all.</li><li>Some instructions have variable latency, depending on not only the size, but also the values of the operands. For memory operations (including fused ones like <code>add</code>), the latency is usually specified for the best case (an L1 cache hit).</li></ul><p>There are many more important little details, but this mental model will suffice for now.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/pipelining/branchless/" id="prev-article">← Branchless Programming</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/pipelining/throughput/" id="next-article">Throughput Computing →</a></div></div>    
</body>
</html>