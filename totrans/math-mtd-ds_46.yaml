- en: '6.2\. Background: introduction to parametric families and maximum likelihood
    estimation#'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap06_prob/02_parametric/roch-mmids-prob-parametric.html](https://mmids-textbook.github.io/chap06_prob/02_parametric/roch-mmids-prob-parametric.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this section, we introduce some fundamental concepts used to construct probabilistic
    models for statistical purposes. We also define a common family of distributions,
    the exponential family.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this topic, all formal proofs are done under the assumption of a
    discrete distribution with finite support to avoid unnecessary technicalities
    and focus on the concepts. But everything we discuss can be adapted to continuous
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Parametric families\(\idx{parametric family}\xdi\) of probability distributions
    serve as basic building blocks for more complex models. By a parametric family,
    we mean a collection \(\{p_{\btheta}:\btheta \in \Theta\}\), where \(p_{\btheta}\)
    is a probability distribution over a set \(\S_{\btheta}\) and \(\btheta\) is a
    vector-valued parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Bernoulli)** The random variable \(X\) is Bernoulli\(\idx{Bernoulli}\xdi\)
    with parameter \(q \in [0,1]\), denoted \(X \sim \mathrm{Ber}(q)\), if it takes
    values in \(\S_X = \{0,1\}\) and \(\P[X=1] = q\). Varying \(q\) produces the family
    of Bernoulli distributions. \(\lhd\)'
  prefs: []
  type: TYPE_NORMAL
- en: Here we focus on exponential families, which include many common distributions
    (including the Bernoulli distribution).
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1\. Exponential family[#](#exponential-family "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One particularly useful class of probability distributions in data science is
    the [exponential family](https://en.wikipedia.org/wiki/Exponential_family#Vector_parameter),
    which includes many well-known cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Exponential Family - Discrete Case)** \(\idx{exponential
    family}\xdi\) A parametric collection of probability distributions \(\{p_{\btheta}:\btheta
    \in \Theta\}\) over a discrete space \(\S\) is an exponential family if it can
    be written in the form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = \frac{1}{Z(\btheta)} h(\mathbf{x}) \exp\left(\btheta^T
    \bphi(\mathbf{x})\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'where \(\btheta \in \mathbb{R}^m\) are the canonical parameters, \(\bphi :
    \S \to \mathbb{R}^m\) are the sufficient statistics and \(Z(\btheta)\) is the
    partition function\(\idx{partition function}\xdi\). It is often convenient to
    introduce the log-partition function\(\idx{log-partition function}\xdi\) \(A(\btheta)
    = \log Z(\btheta)\) and re-write'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Bernoulli, continued)** For \(x \in \{0,1\}\), the \(\mathrm{Ber}(q)\)
    distribution for \(0 < q < 1\) can be written as'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} q^{x} (1-q)^{1-x} &= (1-q) \left(\frac{q}{1-q}\right)^x\\ &=
    (1-q) \exp\left[x \log \left(\frac{q}{1-q}\right)\right]\\ &= \frac{1}{Z(\theta)}
    h(x) \exp(\theta \,\phi(x)) \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we define \(h(x) \equiv 1\), \(\phi(x) = x\), \(\theta = \log \left(\frac{q}{1-q}\right)\)
    and, since \(Z(\theta)\) serves as the normalization constant in \(p_\theta\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ Z(\theta) = \sum_{x \in \{0,1\}} h(x) \exp(\theta \,\phi(x)) = 1 + e^\theta.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: The following is an important generalization. Recall that i.i.d. is the abbreviation
    for independent and identically distributed. We use the convention \(0! = 1\).
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Categorical and Multinomial)** A categorical variable\(\idx{categorical}\xdi\)
    \(\mathbf{Y}\) takes \(K \geq 2\) possible values. A standard choice is to use
    one-hot encoding\(\idx{one-hot encoding}\xdi\) \(\S = \{\mathbf{e}_i : i=1,\ldots,K\}\)
    where \(\mathbf{e}_i\) is the \(i\)-th canonical basis in \(\mathbb{R}^K\). The
    distribution is specified by setting the probabilities \(\bpi = (\pi_1,\ldots,\pi_K)\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \pi_i = \P[\mathbf{Y} = \mathbf{e}_i]. \]
  prefs: []
  type: TYPE_NORMAL
- en: We denote this \(\mathbf{Y} \sim \mathrm{Cat}(\bpi)\) and we assume \(\pi_i
    > 0\) for all \(i\).
  prefs: []
  type: TYPE_NORMAL
- en: To see that this is an exponential family, write the probability mass function
    at \(\mathbf{x} = (x_1,\ldots,x_K)\) as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \prod_{i=1}^K \pi_i^{x_i} = \exp\left(\sum_{i=1}^K x_i \log \pi_i \right).
    \]
  prefs: []
  type: TYPE_NORMAL
- en: So we can take \(h(\mathbf{x}) \equiv 1\), \(\btheta = (\log \pi_i)_{i=1}^K\),
    \(\bphi(\mathbf{x}) = (x_i)_{i=1}^K\) and \(Z(\btheta) \equiv 1\).
  prefs: []
  type: TYPE_NORMAL
- en: The [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution)\(\idx{multinomial}\xdi\)
    arises as a sum of independent categorical variables. Let \(n \geq 1\) be the
    number of trials (or samples) and let \(\mathbf{Y}_1,\ldots,\mathbf{Y}_n\) be
    i.i.d. \(\mathrm{Cat}(\bpi)\). Define \(\mathbf{X} = \sum_{i=1}^n \mathbf{Y}_i\).
    The probability mass function of \(\mathbf{X}\) at
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \mathbf{x} = (x_1,\ldots,x_K) \in \left\{ \mathbf{x} \in \{0,1,\ldots,n\}^K
    : \sum_{i=1}^K x_i = n \right\}=: \S \]'
  prefs: []
  type: TYPE_NORMAL
- en: is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{n!}{x_1!\cdots x_K!} \prod_{i=1}^K \pi_i^{x_i} = \frac{n!}{x_1!\cdots
    x_K!} \exp\left(\sum_{i=1}^K x_i \log \pi_i\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: and we can take \(h(\mathbf{x}) = \frac{n!}{x_1!\cdots x_K!}\), \(\btheta =
    (\log \pi_i)_{i=1}^K\), \(\bphi(\mathbf{x}) = (x_i)_{i=1}^K\) and \(Z(\btheta)
    \equiv 1\). This is an exponential family if we think of \(n\) as fixed.
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation \(\mathbf{X} \sim \mathrm{Mult}(n, \bpi)\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: While we have focused so far on discrete distributions, one can adapt the definitions
    above by replacing mass functions with density functions. We give two important
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: We need some definitions for our first example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [trace](https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29)\(\idx{trace}\xdi\)
    of a square matrix \(A \in \mathbb{R}^{d \times d}\), denoted \(\mathrm{tr}(A)\),
    is the sum of its diagonal entries. We will need the following trace identity
    whose proof we leave as an exercise: \(\mathrm{tr}(ABC) = \mathrm{tr}(CAB) = \mathrm{tr}(BCA)\)
    for any matrices \(A, B, C\) for which \(AB\), \(BC\) and \(CA\) are well-defined.'
  prefs: []
  type: TYPE_NORMAL
- en: The [determinant](https://en.wikipedia.org/wiki/Determinant)\(\idx{determinant}\xdi\)
    of a square matrix \(A\) is denoted by \(|A|\). For our purposes, it will be enough
    to consider symmetric, positive semidefinite matrices for which the determinant
    is the product of the eigenvalues (with repeats). Recall that we proved that the
    sequence of eigenvalues (with repeats) of a symmetric matrix is unique (in the
    sense that any two spectral decomposition have the same sequence of eigenvalues).
  prefs: []
  type: TYPE_NORMAL
- en: A symmetric, positive definite matrix \(A \in \mathbb{R}^{d \times d}\) is necessarily
    invertible. Indeed, it has a spectral decomposition
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = Q \Lambda Q^T = \sum_{i=1}^d \lambda_i \mathbf{q}_i \mathbf{q}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\lambda_1 \geq \cdots \geq \lambda_d > 0\) and \(\mathbf{q}_1, \ldots,
    \mathbf{q}_d\) are orthonormal. Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^{-1} = Q \Lambda^{-1} Q^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: To see this, note that
  prefs: []
  type: TYPE_NORMAL
- en: \[ A A^{-1} = Q \Lambda Q^T Q \Lambda^{-1} Q^T = Q Q^T = I_{d \times d}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The last equality follows from the fact that \(Q Q^T\) is the orthogonal projection
    on the orthonormal basis \(\mathbf{q}_1,\ldots,\mathbf{q}_d\). Similarly, \(A^{-1}
    A = I_{d \times d}\).
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Multivariate Gaussian)** \(\idx{multivariate normal}\xdi\)
    A multivariate Gaussian\(\idx{multivariate Gaussian}\xdi\) vector \(\mathbf{X}
    = (X_1,\ldots,X_d)\) on \(\mathbb{R}^d\) with mean \(\bmu \in \mathbb{R}^d\) and
    positive definite covariance matrix \(\bSigma \in \mathbb{R}^{d \times d}\) has
    probability density function'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\bmu, \bSigma}(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} \,|\bSigma|^{1/2}}
    \exp\left(-\frac{1}{2}(\mathbf{x} - \bmu)^T \bSigma^{-1} (\mathbf{x} - \bmu)\right).
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation \(\mathbf{X} \sim N_d(\bmu, \bSigma)\).
  prefs: []
  type: TYPE_NORMAL
- en: It can be shown that indeed the mean is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X}] = \bmu \]
  prefs: []
  type: TYPE_NORMAL
- en: and the covariance matrix is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[(\mathbf{X} - \bmu)(\mathbf{X} - \bmu)^T] = \E[\mathbf{X} \mathbf{X}^T]
    - \bmu \bmu^T = \bSigma. \]
  prefs: []
  type: TYPE_NORMAL
- en: In the bivariate\(\idx{bivariate Gaussian}\xdi\) case (i.e., when \(d = 2\))\(\idx{bivariate
    normal}\xdi\), the covariance matrix reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bSigma = \begin{bmatrix} \sigma_1^2 & \rho \sigma_1 \sigma_2
    \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma_1^2\) and \(\sigma_2^2\) are the respective variances of \(X_1\)
    and \(X_2\), and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \rho = \frac{\mathrm{Cov}[X_1,X_2]}{\sigma_1 \sigma_2} \]
  prefs: []
  type: TYPE_NORMAL
- en: is the correlation coefficient. Recall that, by the *Cauchy-Schwarz inequality*,
    it lies in \([-1,1]\).
  prefs: []
  type: TYPE_NORMAL
- en: Rewriting the density as
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\bmu, \bSigma}(\mathbf{x}) = \frac{e^{-(1/2) \bmu^T \bSigma^{-1} \bmu}}{(2\pi)^{d/2}
    \,|\bSigma|^{1/2}} \exp\left(- \mathbf{x}^T \bSigma^{-1}\bmu - \frac{1}{2} \mathrm{tr}\left(\mathbf{x}
    \mathbf{x}^T \bSigma^{-1}\right)\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used the symmetric nature of \(\bSigma^{-1}\) in the first term of
    the exponential and the previous trace identity in the second term. The expression
    in parentheses is linear in the entries of \(\mathbf{x}\) and \(\mathbf{x} \mathbf{x}^T\),
    which can then be taken as sufficient statistics (formally, using [vectorization](https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29)).
    Indeed note that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{x}^T \bSigma^{-1}\bmu = \sum_{i=1}^d x_i (\bSigma^{-1}\bmu)_i \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{tr}\left(\mathbf{x} \mathbf{x}^T \bSigma^{-1}\right) = \sum_{i =
    1}^d \left(\sum_{j=1}^d (\mathbf{x} \mathbf{x}^T)_{i,j} (\bSigma^{-1})_{j,i}\right)
    = \sum_{i = 1}^d \sum_{j=1}^d x_i x_j (\bSigma^{-1})_{j,i}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So we can take
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bphi(\mathbf{x}) = (x_1,\ldots,x_d, x_1 x_1, \ldots, x_d x_1, x_1 x_2, \ldots,
    x_d x_2, \ldots, x_1 x_d, \ldots, x_d x_d) \]\[\begin{align*} \btheta &= \bigg(-(\bSigma^{-1}\bmu)_1,\ldots,-(\bSigma^{-1}\bmu)_d,\\
    &\qquad - \frac{1}{2}(\bSigma^{-1})_{1,1}, \ldots, - \frac{1}{2}(\bSigma^{-1})_{1,d},\\
    &\qquad - \frac{1}{2}(\bSigma^{-1})_{2,1}, \ldots, - \frac{1}{2}(\bSigma^{-1})_{2,d},\\
    &\qquad \ldots, - \frac{1}{2}(\bSigma^{-1})_{d,1}, \ldots,- \frac{1}{2}(\bSigma^{-1})_{d,d}\bigg)
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and \(h (\mathbf{x}) \equiv 1\). Expressing \(Z(\btheta)\) explicitly is not
    straightforward. But note that \(\btheta\) includes all entries of \(\bSigma^{-1}\),
    from which \(\bSigma\) can be computed (e.g., from [Cramer’s rule](https://en.wikipedia.org/wiki/Cramer%27s_rule#Finding_inverse_matrix)),
    and in turn from which \(\bmu\) can be extracted out of the entries of \(\bSigma^{-1}\bmu\)
    in \(\btheta\). So the normalizing factor \(\frac{(2\pi)^{d/2} \,|\bSigma|^{1/2}}{e^{-(1/2)
    \bmu^T \bSigma^{-1} \bmu}}\) can in principle be expressed in terms of \(\btheta\).
  prefs: []
  type: TYPE_NORMAL
- en: This shows that the multivariate normal is an exponential family.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix \(\bLambda = \bSigma^{-1}\) is also known as the precision matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, let \(\mathbf{Z}\) be a standard normal \(d\)-vector, let \(\bmu
    \in \mathbb{R}^d\) and let \(\bSigma \in \mathbb{R}^{d \times d}\) be positive
    definite. Then the transformed random variable \(\mathbf{X} = \bmu + \bSigma \mathbf{Z}\)
    is a multivariate Gaussian with mean \(\bmu\) and covariance matrix \(\bSigma\).
    This can be proved using the [change of variables formula](https://en.wikipedia.org/wiki/Probability_density_function#Function_of_random_variables_and_change_of_variables_in_the_probability_density_function)
    (try it!). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** The following code, which plots the density in the bivariate
    case, was adapted from [gauss_plot_2d.ipynb](https://github.com/probml/pyprobml/blob/master/notebooks/book1/03/gauss_plot_2d.ipynb)
    by ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Ask your favorite AI chatbot to explain the code! Try different
    covariance matrices. ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We plot the density for mean \((0,0)\) with two different covariance matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bSigma_1 = \begin{bmatrix} 1.0 & 0 \\ 0 & 1.0 \end{bmatrix}
    \quad \text{and} \quad \bSigma_2 = \begin{bmatrix} \sigma_1^2 & \rho \sigma_1
    \sigma_2 \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma_1 = 1.5\), \(\sigma_2 = 0.5\) and \(\rho = -0.75\).
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]</details> ![../../_images/aa8a076cd17782940f0aa5ed62929716a9ad484853e0e195abb9808dc5430649.png](../Images/bd4d757f39ffc955469d96c6ccc28859.png)<details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]</details> ![../../_images/4a907efb3af995445fe3feb6f564880bfd1d84078a5876676a3758260bc699c8.png](../Images/38909f679dda3fe6c8703a40390160ef.png)'
  prefs: []
  type: TYPE_NORMAL
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: The [Dirichlet distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution),
    which we describe next, is a natural probability distribution over probability
    distributions. In particular, it is used in [Bayesian data analysis](https://en.wikipedia.org/wiki/Bayesian_statistics)
    as a [prior](https://en.wikipedia.org/wiki/Prior_probability) on the parameters
    of categorical and multinomial distribution, largely because of a property known
    as [conjuguacy](https://en.wikipedia.org/wiki/Conjugate_prior). We will not describe
    Bayesian approaches here.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Dirichlet)** \(\idx{Dirichlet}\xdi\) The Dirichlet distribution
    is a distribution over the \((K-1)\)-simplex'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \S = \Delta_{K} := \left\{ \mathbf{x} = (x_1, \ldots, x_K) : \mathbf{x}
    \geq \mathbf{0},\ \sum_{i=1}^K x_i = 1 \right\}. \]'
  prefs: []
  type: TYPE_NORMAL
- en: Its parameters are \(\balpha = (\alpha_1, \ldots, \alpha_K) \in \mathbb{R}\)
    and the density is
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\balpha}(\mathbf{x}) = \frac{1}{B(\balpha)} \prod_{i=1}^K x_i^{\alpha_i-1},
    \quad \mathbf{x} \in \Delta_{K} \]
  prefs: []
  type: TYPE_NORMAL
- en: where the normalizing constant \(B(\balpha)\) is the [multivariate Beta function](https://en.wikipedia.org/wiki/Beta_function#Multivariate_beta_function).
  prefs: []
  type: TYPE_NORMAL
- en: Rewriting the density as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{B(\balpha)} \prod_{i=1}^K x_i^{\alpha_i-1} = \frac{1}{B(\balpha)}
    \frac{1}{\prod_{i=1}^K x_i} \exp\left(\sum_{i=1}^K \alpha_i \log x_i\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: shows that this is an exponential family with the canonical parameters \(\balpha\)
    and sufficient statistics \((\log x_i)_{i=1}^K\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: See [here](https://en.wikipedia.org/wiki/Exponential_family#Table_of_distributions)
    for many more examples. Observe, in particular, that the same distribution can
    have several representations as an exponential family.
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** In NumPy, as we have seen before, the module [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html)
    provides a way to sample from a variety of standard distributions. We first initialize
    the [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator)\(\idx{pseudorandom
    number generator}\xdi\) with a [random seed](https://en.wikipedia.org/wiki/Random_seed).
    Recall that it allows the results to be reproducible: using the same seed produces
    the same results again.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here’s are lists of available [probability distributions](https://numpy.org/doc/stable/reference/random/generator.html#distributions).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here are a few other examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**KNOWLEDGE CHECK:** The Weibull distribution with known shape parameter \(k
    > 0\) takes the following form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(x; \lambda) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k},
    \]
  prefs: []
  type: TYPE_NORMAL
- en: for \(x \geq 0\), where \(\lambda > 0\).
  prefs: []
  type: TYPE_NORMAL
- en: What is the sufficient statistic of its exponential family form?
  prefs: []
  type: TYPE_NORMAL
- en: a) \(x\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\log x\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(x^{k-1}\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(x^k\)
  prefs: []
  type: TYPE_NORMAL
- en: e) \((\log x, x^k)\)
  prefs: []
  type: TYPE_NORMAL
- en: \(\checkmark\)
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2\. Parameter estimation[#](#parameter-estimation "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When modeling data via a parametric family of distributions, the parameters
    must be determined from the data itself. In a typical setting, we assume that
    the data comprises \(n\) independent samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\)
    from a parametric family \(p_{\btheta}\) with unknown \(\btheta \in \Theta\).
    Many methods exist for estimating \(\btheta\), depending on the context. Here
    we focus on [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation).
    It has many [good theoretical properties](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties)
    which we will not describe here, as well as [drawbacks](https://stats.stackexchange.com/questions/261056/why-does-maximum-likelihood-estimation-have-issues-with-over-fitting).
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea behind maximum likelihood estimation is simple and intuitive: we choose
    the parameter that maximizes the probability of observing the data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Maximum likelihood estimator)** \(\idx{maximum likelihood}\xdi\)
    Assume that \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) are \(n\) independent samples
    from a parametric family \(p_{\btheta^*}\) with unknown \(\btheta^* \in \Theta\).
    The maximum likelihood estimator of \(\btheta\) is defined as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\btheta_{\mathrm{MLE}} \in \arg\max\left\{ \prod_{i=1}^n p_{\btheta}(\mathbf{X}_i)
    \,:\, \btheta \in \Theta \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: It is often useful to work with the negative log-likelihood (NLL)\(\idx{negative
    log-likelihood}\xdi\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = - \sum_{i=1}^n \log p_{\btheta}(\mathbf{X}_i),
    \]
  prefs: []
  type: TYPE_NORMAL
- en: in which case we are minimizing. \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Biased coin)** Suppose we observe \(n\) coin flips \(X_1,\ldots,
    X_n \in \{0,1\}\) from a biased coin with an unknown probability \(\theta^*\)
    of producing \(1\). We assume the flips are independent. We compute the MLE of
    the parameter \(\theta\).'
  prefs: []
  type: TYPE_NORMAL
- en: The definition is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} \in \arg\min\left\{ L_n(\theta; \{X_i\}_{i=1}^n)
    \,:\, \theta \in \Theta = [0,1] \right\} \]
  prefs: []
  type: TYPE_NORMAL
- en: where, using our previous Bernoulli example, the NLL is
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\theta; \{X_i\}_{i=1}^n) &= - \sum_{i=1}^n \log p_{\theta}(X_i)\\
    &= - \sum_{i=1}^n \log \left[\theta^{X_i} (1- \theta)^{1 -X_i}\right]\\ &= - \sum_{i=1}^n
    \left[ X_i \log \theta + (1 -X_i) \log (1- \theta)\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: 'We compute the first and second derivatives of \(L_n(\theta; \{X_i\}_{i=1}^n)\)
    as a function of \(\theta\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\mathrm{d}}{\mathrm{d} \theta}L_n(\theta; \{X_i\}_{i=1}^n)
    &= - \sum_{i=1}^n \left[ \frac{X_i}{\theta} - \frac{1 -X_i}{1- \theta}\right]\\
    &= - \frac{\sum_{i=1}^n X_i}{\theta} + \frac{n - \sum_{i=1}^n X_i}{1- \theta}
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\mathrm{d}^2}{\mathrm{d} \theta^2}L_n(\theta; \{X_i\}_{i=1}^n)
    &= \frac{\sum_{i=1}^n X_i}{\theta^2} + \frac{n - \sum_{i=1}^n X_i}{(1- \theta)^2}.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The second derivative is non-negative and therefore the NLL is convex. To find
    a global minimizer, it suffices to find a stationary point.
  prefs: []
  type: TYPE_NORMAL
- en: We make the derivative of the NLL equal to \(0\)
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} &0 = - \frac{\sum_{i=1}^n X_i}{\theta} + \frac{n - \sum_{i=1}^n
    X_i}{1- \theta}\\ & \iff \frac{\sum_{i=1}^n X_i}{\theta} = \frac{n - \sum_{i=1}^n
    X_i}{1- \theta}\\ & \iff (1- \theta)\sum_{i=1}^n X_i = \theta \left(n - \sum_{i=1}^n
    X_i \right)\\ & \iff \sum_{i=1}^n X_i = \theta n. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: So
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \frac{\sum_{i=1}^n X_i}{n}. \]
  prefs: []
  type: TYPE_NORMAL
- en: 'This is in fact a natural estimator: the empirical frequency of \(1\)s. \(\lhd\)'
  prefs: []
  type: TYPE_NORMAL
- en: We give an alternative perspective on the maximum likelihood estimator. Assume
    that \(p_{\btheta}\) is supported on a fixed finite set \(\X\) for all \(\btheta
    \in \Theta\). Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\), for each \(\mathbf{x}
    \in \X\), let
  prefs: []
  type: TYPE_NORMAL
- en: \[ N_\mathbf{x} = \sum_{i=1}^n \mathbf{1}_{\{\mathbf{X}_i = \mathbf{x}\}} \]
  prefs: []
  type: TYPE_NORMAL
- en: count the number of times \(\mathbf{x}\) is observed in the data and let
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\mu_n(\mathbf{x}) = \frac{N_\mathbf{x}}{n} \]
  prefs: []
  type: TYPE_NORMAL
- en: be the empirical frequency of \(\mathbf{x}\) in the sample. Observe that \(\hat\mu_n\)
    is a probability distribution over \(\X\).
  prefs: []
  type: TYPE_NORMAL
- en: The following theorem characterizes the maximum likelihood estimator in terms
    of the [Kullback-Liebler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)\(\idx{Kullback-Liebler
    divergence}\xdi\), which was introduced in a previous section.
  prefs: []
  type: TYPE_NORMAL
- en: For two probability distributions
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{p}, \mathbf{q} \in \Delta_K := \left\{ (p_1,\ldots,p_K) \in [0,1]^K
    \,:\, \sum_{k=1}^K p_k = 1 \right\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: it is defined as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) = \sum_{i=1}^K p_i \log \frac{p_i}{q_i}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where it will suffice to restrict ourselves to the case \(\mathbf{q} > \mathbf{0}\)
    and where we use the convention \(0 \log 0 = 0\) (so that terms with \(p_i = 0\)
    contribute \(0\) to the sum).
  prefs: []
  type: TYPE_NORMAL
- en: Notice that \(\mathbf{p} = \mathbf{q}\) implies \(\mathrm{KL}(\mathbf{p} \|
    \mathbf{q}) = 0\). We show that \(\mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0\),
    a result known as *Gibbs’ inequality*.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Gibbs)** \(\idx{Gibbs'' inequality}\xdi\) For any \(\mathbf{p},
    \mathbf{q} \in \Delta_K\) with \(\mathbf{q} > \mathbf{0}\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* Let \(I\) be the set of indices \(i\) such that \(p_i > 0\). Hence'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) = \sum_{i \in I} p_i \log \frac{p_i}{q_i}.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: It can be proved that \(\log x \leq x - 1\) for all \(x > 0\) (Try it!). So
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \mathrm{KL}(\mathbf{p} \| \mathbf{q}) &= - \sum_{i \in I} p_i
    \log \frac{q_i}{p_i}\\ &\geq - \sum_{i \in I} p_i \left(\frac{q_i}{p_i} - 1\right)\\
    &= - \sum_{i \in I} q_i + \sum_{i \in I} p_i\\ &= - \sum_{i \in I} q_i + 1\\ &\geq
    0 \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(\log z^{-1} = - \log z\) on the first line and the fact
    that \(p_i = 0\) for all \(i \notin I\) on the fourth line. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(MLE via KL)** \(\idx{MLE via KL theorem}\xdi\) Assume that,
    for all \(\btheta \in \Theta\), \(p_{\btheta}\) is supported on a fixed finite
    set \(\X\) and that \(p_{\btheta}(\mathbf{x}) > 0\) for all \(\mathbf{x} \in \X\).
    Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) from \(p_{\btheta^*}\), let
    \(\{\hat\mu_n(\mathbf{x})\}_{\mathbf{x} \in \X}\) be the corresponding empirical
    frequencies. Then the maximum likelihood estimator \(\hat\btheta_{\mathrm{MLE}}\)
    of \(\btheta\) is also a solution to'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\btheta_{\mathrm{MLE}} \in \arg\min\left\{ \mathrm{KL}(\hat{\mu}_n \|
    p_{\btheta}) \,:\, \btheta \in \Theta \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* Manipulate the negative log-likelihood to bring out its relationship
    to the Kullback-Liebler divergence.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* We can re-write the negative log-likelihood as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = - \sum_{i=1}^n \log p_{\btheta}(\mathbf{X}_i)
    = - \sum_{\mathbf{x} \in \X} N_{\mathbf{x}} \log p_{\btheta}(\mathbf{x}). \]
  prefs: []
  type: TYPE_NORMAL
- en: To bring out the Kullback-Liebler divergence, we further transform the previous
    equation into
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{1}{n} L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) &= - \frac{1}{n}
    \sum_{\mathbf{x} \in \X} N_{\mathbf{x}} \log p_{\btheta}(\mathbf{x})\\ &= \sum_{\mathbf{x}
    \in \X} (N_{\mathbf{x}}/n) \log \frac{N_{\mathbf{x}}/n}{p_{\btheta}(\mathbf{x})}
    - \sum_{\mathbf{x} \in \X} (N_{\mathbf{x}}/n) \log (N_{\mathbf{x}}/n)\\ &= \sum_{\mathbf{x}
    \in \X} \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{p_{\btheta}(\mathbf{x})}
    - \sum_{\mathbf{x} \in \X} \hat\mu_n(\mathbf{x}) \log \hat\mu_n(\mathbf{x})\\
    &= \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) + \mathrm{H}(\hat\mu_n), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where the second term is referred to as the [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory))\(\idx{entropy}\xdi\)
    of \(\hat\mu_n\).
  prefs: []
  type: TYPE_NORMAL
- en: Because \(\mathrm{H}(\hat\mu_n)\) does not depend on \(\btheta\), minimizing
    \(L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\) is equivalent to minimizing \(\mathrm{KL}(\hat{\mu}_n
    \| p_{\btheta})\) as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: 'In words, the maximum likelihood estimator chooses the parametric distribution
    that is closest to \(\hat\mu_n\) in Kullback-Liebler divergence. One can think
    of this as “projecting” \(\hat\mu_n\) onto the space \(\{p_{\btheta} : \btheta
    \in \Theta\}\) under the Kullback-Liebler notion of distance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Special case)** One special case is where \(\X\) is finite,
    \(\btheta = (\theta_\mathbf{x})_{\mathbf{x} \in \X}\) is a probability distribution
    over \(\X\), and \(p_{\btheta} = \btheta\). That is, we consider the class of
    all probability distributions over \(\X\). Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\)
    from \(p_{\btheta^*}\), in this case we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = \sum_{\mathbf{x} \in \X} \hat\mu_n(\mathbf{x})
    \log \frac{\hat\mu_n(\mathbf{x})}{p_{\btheta}(\mathbf{x})} = \sum_{\mathbf{x}
    \in \X} \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}},
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where recall that, by convention, if \(\hat\mu_n(\mathbf{x}) = 0\) then \(\hat\mu_n(\mathbf{x})
    \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}} = 0\) for any \(\theta_\mathbf{x}\).
    So, letting \(\mathbb{X}_n = \{\mathbf{X}_1,\ldots,\mathbf{X}_n\}\) be the set
    of distinct values encountered in the sample (ignoring repetitions), we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = \sum_{\mathbf{x} \in \mathbb{X}_n}
    \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: Note that \(\sum_{\mathbf{x} \in \mathbb{X}_n} \hat\mu_n(\mathbf{x}) = 1\).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have previously established *Gibbs’ inequality* which says that: for any
    \(\mathbf{p}, \mathbf{q} \in \Delta_K\) with \(\mathbf{q} > \mathbf{0}\), it holds
    that \(\mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0\).'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum \(\mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = 0\) can be achieved
    by setting \(\btheta_{\mathbf{x}} = \hat\mu_n(\mathbf{x})\) for all \(\mathbf{x}
    \in \mathbb{X}_n\) and \(\btheta_{\mathbf{x}} = 0\) for all \(\mathbf{x} \notin
    \mathbb{X}_n\). The condition
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{\mathbf{x} \in \X} \btheta_{\mathbf{x}} = \sum_{\mathbf{x} \in \mathbb{X}_n}
    \btheta_{\mathbf{x}} + \sum_{\mathbf{x} \notin \mathbb{X}_n} \btheta_{\mathbf{x}}
    = \sum_{\mathbf{x} \in \mathbb{X}_n} \hat\mu_n(\mathbf{x}) = 1, \]
  prefs: []
  type: TYPE_NORMAL
- en: is then satisfied.
  prefs: []
  type: TYPE_NORMAL
- en: So in this case \(\hat\mu_n\) is a maximum likelihood estimator.
  prefs: []
  type: TYPE_NORMAL
- en: A special case of this is the *biased coin* example. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Explore the concept of Bayesian parameter estimation. Ask
    your favorite AI chatbot how Bayesian parameter estimation differs from maximum
    likelihood estimation and discuss their relative strengths and weaknesses. Here
    are some possible follow-ups. (1) Get an example implementation using a simple
    dataset. (2) The categorical and multinomial distributions are related to the
    Dirichlet distribution. Ask about relationship and how the Dirichlet distribution
    is used in Bayesian inference for these distributions. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3\. Parameter estimation for exponential families[#](#parameter-estimation-for-exponential-families
    "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For exponential families, maximum likelihood estimation takes a particularly
    natural form. We provide details in the discrete case.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Maximum Likelihood Estimator for Exponential Families)** \(\idx{maximum
    likelihood estimator for exponential families}\xdi\) Assume that \(p_{\btheta}\)
    takes the exponential family form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: that the support \(\S\) is finite, and that \(A\) is twice continuously differentiable
    over the open set \(\Theta\). Let \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) be \(n\)
    independent samples from a parametric family \(p_{\btheta^*}\) with unknown \(\btheta^*
    \in \Theta\). Then \(L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\), as a function of
    \(\btheta\), is convex and the maximum likelihood estimator of \(\btheta\) – if
    it exists – solves the system of moment-matching equations
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\bphi(\mathbf{X})] = \frac{1}{n} \sum_{i=1}^n \bphi(\mathbf{X}_i), \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\hat\btheta_{\mathrm{MLE}}}\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the covariance matrix of a random vector \(\mathbf{Z}\) taking values
    in \(\mathbb{R}^m\) whose components have finite variances is defined as \(\mathrm{K}_{\mathbf{Z},
    \mathbf{Z}} = \E[(\mathbf{Z} - \E[\mathbf{Z}])(\mathbf{Z} - \E[\mathbf{Z}])^T]\)
    and is a positive semidefinite matrix. It is also sometimes denoted as \(\bSigma_\mathbf{Z}\).
  prefs: []
  type: TYPE_NORMAL
- en: The function \(A\) has properties worth highlighting that will be used in the
    proof.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Derivatives of \(A\))** Assume that \(p_{\btheta}\) takes the
    exponential family form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: that the support \(\S\) is finite, and that \(A\) is twice continuously differentiable
    over the open set \(\Theta\). Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla A(\btheta) = \E[\bphi(\mathbf{X})] \qquad \text{and} \qquad \mathbf{H}_A
    (\btheta) = \mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}, \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\btheta}\). \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* Follows from a direct calculation.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* We observe first that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A(\btheta) = \log Z(\btheta) = \log\left(\sum_{\mathbf{x} \in \S} h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}))\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used the fact that, by definition, \(Z(\btheta)\) is the normalization
    constant of \(p_{\btheta}\). In particular, as the logarithm of a finite, weighted
    sum of exponentials, the function \(A(\btheta)\) is continuously differentiable.
    Hence so is \(p_{\btheta}(\mathbf{x})\) as a function of \(\btheta\).
  prefs: []
  type: TYPE_NORMAL
- en: From the formula above and the basic rules of calculus,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial}{\partial \theta_j} A(\btheta) &= \frac{\partial}{\partial
    \theta_j} \log\left(\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}))\right)\\
    &= \frac{\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \,\phi_j(\mathbf{x}) \exp(\btheta^T
    \bphi(\mathbf{x}))}{\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}))}\\
    &= \sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x}) \frac{1}{Z(\btheta)} h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}))\\ &= \sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\\ &= \E[\phi_j(\mathbf{X})],
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\btheta}\).
  prefs: []
  type: TYPE_NORMAL
- en: Differentiating again, this time with respect to \(\theta_i\), we obtain
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial^2}{\partial \theta_i \partial \theta_j} A(\btheta)
    &= \frac{\partial}{\partial \theta_i} \left\{\sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\right\}\\ &= \sum_{\mathbf{x}
    \in \S} \phi_j(\mathbf{x}) h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))
    \left\{\phi_i(\mathbf{x}) - \frac{\partial}{\partial \theta_i} A(\btheta) \right\}\\
    &= \sum_{\mathbf{x} \in \S} \phi_i(\mathbf{x}) \phi_j(\mathbf{x}) h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\\ & \qquad - \left(\sum_{\mathbf{x}
    \in \S} \phi_i(\mathbf{x}) h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))
    \right)\\ & \qquad\qquad \times \left(\sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta)) \right)\\ &= \E[\phi_i(\mathbf{X})\phi_j(\mathbf{X})]
    - \E[\phi_i(\mathbf{X})]\E[\phi_j(\mathbf{X})], \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where again \(\mathbf{X} \sim p_{\btheta}\). That concludes the proof. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to the prove the main theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Maximum Likelihood Estimator for Exponential Families)* We begin
    by computing the stationary points of the negative log-likelihood, for which we
    need the gradient with respect to \(\btheta \in \mathbb{R}^m\). We will also need
    the second-order derivatives to establish convexity. We have'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial}{\partial \theta_j} \{- \log p_{\btheta}(\mathbf{x})\}
    &= \frac{\partial}{\partial \theta_j} \left\{- \log h(\mathbf{x}) - \btheta^T
    \bphi(\mathbf{x}) + A(\btheta)\right\}\\ &= - \phi_j(\mathbf{x}) + \frac{\partial}{\partial
    \theta_j} A(\btheta). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial^2}{\partial \theta_i \partial \theta_j} \{-
    \log p_{\btheta}(\mathbf{x})\} &= \frac{\partial}{\partial \theta_i} \left\{-
    \phi_j(\mathbf{x}) + \frac{\partial}{\partial \theta_j} A(\btheta)\right\}\\ &=
    \frac{\partial^2}{\partial \theta_i \partial \theta_j} A(\btheta). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: We use the expressions for the derivatives of \(A\) obtained above.
  prefs: []
  type: TYPE_NORMAL
- en: Plugging into the formula for the minus log-likelihood (as a function of \(\btheta\)),
    we get for the gradient with respect to \(\btheta\)
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\btheta L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) &= -
    \sum_{i=1}^n \nabla_\btheta \log p_{\btheta}(\mathbf{X}_i)\\ &= \sum_{i=1}^n \{-
    \bphi(\mathbf{X}_i) + \nabla_\btheta A(\btheta)\}\\ &= \sum_{i=1}^n \{- \bphi(\mathbf{X}_i)
    + \E[\bphi(\mathbf{X})]\}. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This is also known in statistics as the [score](https://en.wikipedia.org/wiki/Score_(statistics)).
  prefs: []
  type: TYPE_NORMAL
- en: For the Hessian with respect to \(\btheta\), we get
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \mathbf{H}_{L_n}(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = \sum_{i=1}^n
    \mathbf{H}_A (\btheta) = n \,\mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This is also known in statistics as the [observed information](https://en.wikipedia.org/wiki/Observed_information).
    (In fact, in this case, it reduces to the [Fisher information](https://en.wikipedia.org/wiki/Fisher_information).)
    Since \(\mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}\) is positive semidefinite,
    so is \(\mathbf{H}_{L_n}(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\).
  prefs: []
  type: TYPE_NORMAL
- en: Hence, a stationary point \(\hat\btheta_{\mathrm{MLE}}\) must satisfy
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{0} = \nabla L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = \sum_{i=1}^n
    \{- \bphi(\mathbf{X}_i) + \E[\bphi(\mathbf{X})]\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\hat\btheta_{\mathrm{MLE}}}\) or, after re-arranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\bphi(\mathbf{X})] = \frac{1}{n} \sum_{i=1}^n \bphi(\mathbf{X}_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: Because \(L_n\) is convex, a stationary point – if it exists – is necessarily
    a global minimum (and vice versa). \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Bernoulli/biased coin, continued)** For \(x \in \{0,1\}\),
    recall that the \(\mathrm{Ber}(q)\) distribution can be written as'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(x) &= \frac{1}{Z(\theta)} h(x) \exp(\theta \,\phi(x))
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we define \(h(x) \equiv 1\), \(\phi(x) = x\), \(\theta = \log \left(\frac{q}{1-q}\right)\)
    and \(Z(\theta) = 1 + e^\theta\). Let \(X_1,\ldots,X_n\) be independent samples
    from \(p_{\theta^*}\).
  prefs: []
  type: TYPE_NORMAL
- en: For \(X \sim p_{\hat\theta_{\mathrm{MLE}}}\), the moment-matching equations
    reduce to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat{q}_{\mathrm{MLE}} := \E[X] = \E[\phi(X)] = \frac{1}{n} \sum_{i=1}^n
    \phi(X_i) = \frac{1}{n} \sum_{i=1}^n X_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: To compute the left-hand side in terms of \(\hat\theta_{\mathrm{MLE}}\) we use
    the relationship \(\theta = \log \left(\frac{q}{1-q}\right)\), that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \log \left(\frac{\frac{1}{n} \sum_{i=1}^n X_i}{1-\frac{1}{n}
    \sum_{i=1}^n X_i}\right). \]
  prefs: []
  type: TYPE_NORMAL
- en: Hence, \(\hat\theta_{\mathrm{MLE}}\) is well-defined when \(\frac{1}{n} \sum_{i=1}^n
    X_i \neq 0, 1\).
  prefs: []
  type: TYPE_NORMAL
- en: Define \(q^*\) as the solution to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \theta^* = \log \left(\frac{q^*}{1-q^*}\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ q^* = \frac{e^{\theta^*}}{1+e^{\theta^*}} = \frac{1}{1 + e^{-\theta*}} =
    \sigma(\theta^*), \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma\) is the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: By the law of large numbers, as \(n \to +\infty\), we get the convergence
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{n} \sum_{i=1}^n X_i \to q^*, \]
  prefs: []
  type: TYPE_NORMAL
- en: with probability one.
  prefs: []
  type: TYPE_NORMAL
- en: Because the function \(\log \left(\frac{q}{1-q}\right)\) is continuous for \(q
    \in (0,1)\), we have furthermore
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \log \left(\frac{\frac{1}{n} \sum_{i=1}^n X_i}{1-\frac{1}{n}
    \sum_{i=1}^n X_i}\right) \to \log \left(\frac{q^*}{1-q^*}\right) = \theta^*. \]
  prefs: []
  type: TYPE_NORMAL
- en: In words, the maximum likelihood estimator \(\hat\theta_{\mathrm{MLE}}\) is
    guaranteed to converge to the true parameter \(\theta^*\) when the number of samples
    grows. This fundamental property is known as [statistical consistency](https://en.wikipedia.org/wiki/Consistent_estimator)\(\idx{statistical
    consistency}\xdi\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: Statistical consistency holds more generally for the maximum likelihood estimator
    under exponential families, provided certain technical conditions hold. We will
    not provide further details here.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the previous example, one does not always have an explicit formula for
    the maximum likelihood estimator under exponential families. Instead, optimization
    methods, for instance [Newton’s method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization),
    are used in such cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Multivariate Gaussian)** We established the theorem for finite
    \(\mathcal{S}\), but it holds more generally. Consider the multivariate Gaussian
    case. Here the sufficient statistics are'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bphi(\mathbf{x}) = (x_1,\ldots,x_d, x_1 x_1, \ldots, x_d x_1, x_1 x_2, \ldots,
    x_d x_2, \ldots, x_1 x_d, \ldots, x_d x_d) \]
  prefs: []
  type: TYPE_NORMAL
- en: which is simply the vector \(\mathbf{x}\) itself stacked with the vectorized
    form of the matrix \(\mathbf{x} \mathbf{x}^T\). So the moment-matching equations
    boil down to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X}] = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X} \mathbf{X}^T ] = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \mathbf{X}_i^T.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: The first equation says to choose \(\bmu = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i\).
    The second one says to take
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bSigma = \E[\mathbf{X} \mathbf{X}^T] - \E[\mathbf{X}]\,\E[\mathbf{X}]^T
    = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \mathbf{X}_i^T - \left(\frac{1}{n} \sum_{i=1}^n
    \mathbf{X}_i\right) \left(\frac{1}{n} \sum_{i=1}^n \mathbf{X}_i^T \right). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**KNOWLEDGE CHECK:** Consider again the Weibull distribution with known shape
    parameter \(k > 0\).'
  prefs: []
  type: TYPE_NORMAL
- en: a) Compute \(\E[X^k]\). [*Hint:* Perform a change of variables.]
  prefs: []
  type: TYPE_NORMAL
- en: b) What is the MLE of \(\lambda\)?
  prefs: []
  type: TYPE_NORMAL
- en: \(\checkmark\)
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.4\. Generalized linear models[#](#generalized-linear-models "Link to this
    heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generalized linear models\(\idx{generalized linear model}\xdi\) (GLM) provide
    a broad generalization of linear regression using exponential families. Quoting
    from [Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model), the
    context in which they arise is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Ordinary linear regression predicts the expected value of a given unknown quantity
    (the response variable, a random variable) as a linear combination of a set of
    observed values (predictors). This implies that a constant change in a predictor
    leads to a constant change in the response variable (i.e. a linear-response model).
    This is appropriate when the response variable can vary, to a good approximation,
    indefinitely in either direction, or more generally for any quantity that only
    varies by a relatively small amount compared to the variation in the predictive
    variables, e.g. human heights. However, these assumptions are inappropriate for
    some types of response variables. For example, in cases where the response variable
    is expected to be always positive and varying over a wide range, constant input
    changes lead to geometrically (i.e. exponentially) varying, rather than constantly
    varying, output changes. […] Similarly, a model that predicts a probability of
    making a yes/no choice (a Bernoulli variable) is even less suitable as a linear-response
    model, since probabilities are bounded on both ends (they must be between 0 and
    1). […] Generalized linear models cover all these situations by allowing for response
    variables that have arbitrary distributions (rather than simply normal distributions),
    and for an arbitrary function of the response variable (the link function) to
    vary linearly with the predicted values (rather than assuming that the response
    itself must vary linearly).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In its simplest form, a generalized linear model assumes that an outcome variable
    \(y \in \mathbb{R}\) is generated from an exponential family \(p_\theta\), where
    \(\theta \in \mathbb{R}\) is a linear combination of the predictor variables \(\mathbf{x}
    \in \mathbb{R}^d\). That is, we assume that \(\theta = \mathbf{w}^T \mathbf{x}\)
    for unknown \(\mathbf{w} \in \mathbb{R}^d\) and the probability distribution of
    \(y\) is of the form
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\mathbf{w}^T \mathbf{x}}(y) = h(y) \exp\left((\mathbf{w}^T\mathbf{x})
    \,\phi(y) - A(\mathbf{w}^T \mathbf{x})\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: for some sufficient statistic \(\phi(y)\). We further assume that \(A\) is twice
    continuously differentiable over \(\mathbb{R}\).
  prefs: []
  type: TYPE_NORMAL
- en: Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), the model is fitted using
    maximum likelihood as follows. Under independence of the samples, the likelihood
    of the data is \(\prod_{i=1}^n p_{\mathbf{w}^T \mathbf{x}_i}(y_i)\), which we
    seek to maximize over \(\mathbf{w}\) (which is different from maximizing over
    \(\theta\)!). As before, we work with the negative log-likelihood, which we denote
    as (with a slight abuse of notation)
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = - \sum_{i=1}^n \log p_{\mathbf{w}^T
    \mathbf{x}_i}(y_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: The gradient with respect to \(\mathbf{w}\) is given by
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})
    &= - \sum_{i=1}^n \nabla_\mathbf{w} \log\left[ h(y_i) \exp\left(\mathbf{w}^T \mathbf{x}_i
    \phi(y_i) - A(\mathbf{w}^T \mathbf{x}_i)\right)\right]\\ &= - \sum_{i=1}^n \nabla_\mathbf{w}
    \left[\log h(y_i) + \mathbf{w}^T \mathbf{x}_i \phi(y_i) - A(\mathbf{w}^T \mathbf{x}_i)\right]\\
    &= - \sum_{i=1}^n \left[ \mathbf{x}_i \phi(y_i) - \nabla_\mathbf{w} A(\mathbf{w}^T
    \mathbf{x}_i)\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: By the *Chain Rule* and our previous formulas,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla_\mathbf{w} A(\mathbf{w}^T \mathbf{x}_i) = A'(\mathbf{w}^T \mathbf{x}_i)
    \,\mathbf{x}_i = \mu(\mathbf{w}; \mathbf{x}_i) \,\mathbf{x}_i \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{w}^T
    \mathbf{x}_i}\). That is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = - \sum_{i=1}^n
    \mathbf{x}_i (\phi(y_i) - \mu(\mathbf{w}; \mathbf{x}_i)). \]
  prefs: []
  type: TYPE_NORMAL
- en: The Hessian of \(A(\mathbf{w}^T \mathbf{x}_i)\), again by the *Chain Rule* and
    our previous formulas, is
  prefs: []
  type: TYPE_NORMAL
- en: \[ A''(\mathbf{w}^T \mathbf{x}_i) \,\mathbf{x}_i \mathbf{x}_i^T = \sigma^2 (\mathbf{w};
    \mathbf{x}_i) \,\mathbf{x}_i \mathbf{x}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma^2(\mathbf{w}; \mathbf{x}_i) = \mathrm{K}_{\phi(Y_i), \phi(Y_i)}
    = \var[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{w}^T \mathbf{x}_i}\). So the Hessian
    of the negative log-likelihood is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{H}_{L_n}(\mathbf{w}) = \sum_{i=1}^n \sigma^2(\mathbf{w}; \mathbf{x}_i)
    \,\mathbf{x}_i \mathbf{x}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: which is positive semidefinite (prove it!).
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the negative log-likelihood is convex and the maximum likelihood
    estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation \(\nabla_\mathbf{w}
    L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = \mathbf{0}\), that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: We revisit linear and logistic regression next.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Linear regression)** \(\idx{linear regression}\xdi\) Consider
    the case where \(p_\theta\) is a univariate Gaussian with mean \(\theta\) and
    fixed variance \(1\). That is,'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(y) &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{(y
    - \theta)^2}{2}\right)\\ &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{1}{2}[y^2
    - 2 y \theta + \theta^2]\right)\\ &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{y^2}{2}\right)
    \exp\left(\theta y - \frac{\theta^2}{2}\right)\\ &= h(y) \exp\left(\theta \phi(y)
    - A(\theta)\right), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\phi(y) = y\) and \(A(\theta) = \theta^2/2\). We now assume that \(\theta
    = \mathbf{x}^T \mathbf{w}\) to obtain the corresponding generalized linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), recall that the maximum likelihood
    estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{x}_i^T
    \mathbf{w}}\). Here \(\E[\phi(Y_i)] = \E[Y_i] = \mathbf{x}_i^T \mathbf{w}\). So
    the equation reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^T \mathbf{w} = \sum_{i=1}^n \mathbf{x}_i
    y_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: You may not recognize this equation, but we have encountered it before in a
    different form. Let \(A\) be the matrix with row \(i\) equal to \(\mathbf{x}_i\)
    and let \(\mathbf{y}\) be the vector with \(i\)-th entry equal to \(y_i\). Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^T = A^T A \qquad \text{and} \qquad
    \sum_{i=1}^n \mathbf{x}_i y_i = A^T \mathbf{y} \]
  prefs: []
  type: TYPE_NORMAL
- en: as can be checked entry by entry or by using our previous characterizations
    of matrix-matrix products (in outer-product form) and matrix-vector products (as
    linear combinations of columns). Therefore, the equation above is equivalent to
    \(A^T A \mathbf{w} = A^T \mathbf{y}\) - the normal equations of linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: To make sense of this finding, we look back at the minus log-likelihood
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) &= - \sum_{i=1}^n
    \log p_{\mathbf{x}_i^T \mathbf{w}}(y_i)\\ &= - \sum_{i=1}^n \log \left(\frac{1}{\sqrt{2
    \pi}} \exp\left(- \frac{(y_i - \mathbf{x}_i^T \mathbf{w})^2}{2}\right)\right)\\
    &= - \log (\sqrt{2 \pi}) + \frac{1}{2} \sum_{i=1}^n (y_i - \mathbf{x}_i^T \mathbf{w})^2.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Observe that minimizing this expression over \(\mathbf{w}\) is equivalent to
    solving the least-squares problem as the first term does not depend on \(\mathbf{w}\)
    and the factor of \(1/2\) does not affect the optimum.
  prefs: []
  type: TYPE_NORMAL
- en: While we have rederived the least squares problem from a probabilistic model,
    it should be noted that the Gaussian assumption is not in fact required for linear
    regression to be warranted. Rather, it gives a different perspective on the same
    problem. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Logistic regression)** \(\idx{logistic regression}\xdi\) Consider
    the case where \(p_{\theta}\) is a Bernoulli distribution. That is, for \(y \in
    \{0,1\}\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(y) &= h(y) \exp(\theta \,\phi(y) - A(\theta)), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(h(y) \equiv 1\), \(\phi(y) = y\) and \(A(\theta) = \log(1 + e^\theta)\).
    We assume that \(\theta = \mathbf{x}^T \mathbf{w}\) to obtain the corresponding
    generalized linear model. Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), the
    maximum likelihood estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{x}_i^T
    \mathbf{w}}\). Here, by our formula for the gradient of \(A\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\phi(Y_i)] = \E[Y_i] = A'(\mathbf{x}_i^T \mathbf{w}) = \frac{e^{\mathbf{x}_i^T
    \mathbf{w}}}{1 + e^{\mathbf{x}_i^T \mathbf{w}}} = \sigma(\mathbf{x}_i^T \mathbf{w}),
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma\) is the sigmoid function. So the equation reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \sigma(\mathbf{x}_i^T \mathbf{w}) = \sum_{i=1}^n
    \mathbf{x}_i y_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: The equation in this case cannot be solved explicitly. Instead we can use gradient
    descent, or a variant, to minimize the negative log-likelihood directly. The lattter
    is
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) &= - \sum_{i=1}^n
    \log p_{\mathbf{x}_i^T \mathbf{w}}(y_i)\\ &= - \sum_{i=1}^n \log \left(\exp((\mathbf{x}_i^T
    \mathbf{w}) y_i - \log(1 + e^{\mathbf{x}_i^T \mathbf{w}}))\right)\\ &= - \sum_{i=1}^n
    \left[(\mathbf{x}_i^T \mathbf{w}) y_i - \log(1 + e^{\mathbf{x}_i^T \mathbf{w}})\right]\\
    &= - \sum_{i=1}^n \left[y_i \log(e^{\mathbf{x}_i^T \mathbf{w}}) - (y_i + (1-y_i))\log(1
    + e^{\mathbf{x}_i^T \mathbf{w}})\right]\\ &= - \sum_{i=1}^n \left[y_i \log(\sigma(\mathbf{x}_i^T
    \mathbf{w})) + (1-y_i) \log(1 -\sigma(\mathbf{x}_i^T \mathbf{w}))\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing \(L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})\) is equivalent
    to logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: To use gradient descent, we compute
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})
    &= - \sum_{i=1}^n \mathbf{x}_i (\phi(y_i) - \mu(\mathbf{w}; \mathbf{x}_i))\\ &=
    - \sum_{i=1}^n \mathbf{x}_i (y_i - \sigma(\mathbf{x}_i^T \mathbf{w})). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This expression is indeed consistent with what we previously derived for logistic
    regression. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Generalized linear models can be extended to handle more complex
    data structures. Ask your favorite AI chatbot to explain what generalized additive
    models (GAMs) are and how they differ from generalized linear models. Also, ask
    about some common applications of GAMs. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following is NOT an example of an exponential family of
    distributions?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Bernoulli
  prefs: []
  type: TYPE_NORMAL
- en: b) Categorical
  prefs: []
  type: TYPE_NORMAL
- en: c) Uniform
  prefs: []
  type: TYPE_NORMAL
- en: d) Multivariate Gaussian
  prefs: []
  type: TYPE_NORMAL
- en: '**2** In the exponential family form \(p_{\boldsymbol{\theta}}(\mathbf{x})
    = h(\mathbf{x}) \exp(\boldsymbol{\theta}^T \boldsymbol{\phi}(\mathbf{x}) - A(\boldsymbol{\theta}))\),
    what does \(A(\boldsymbol{\theta})\) represent?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The sufficient statistic
  prefs: []
  type: TYPE_NORMAL
- en: b) The log-partition function
  prefs: []
  type: TYPE_NORMAL
- en: c) The canonical parameter
  prefs: []
  type: TYPE_NORMAL
- en: d) The base measure
  prefs: []
  type: TYPE_NORMAL
- en: '**3** Given \(n\) independent samples \(X_1, \ldots, X_n\) from a parametric
    family \(p_{\boldsymbol{\theta}^*}\) with unknown \(\boldsymbol{\theta}^* \in
    \Theta\), the maximum likelihood estimator \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}}\)
    is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'a) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max \left\{ \prod_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'b) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\min \left\{ \prod_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'c) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max \left\{ \sum_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\min \left\{ \sum_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: '**4** In a generalized linear model, the maximum likelihood estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\)
    solves the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n
    \mathbf{x}_i \phi(y_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n
    y_i \phi(\mathbf{x}_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(\sum_{i=1}^n \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \phi(y_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(\sum_{i=1}^n \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n y_i\)
  prefs: []
  type: TYPE_NORMAL
- en: '**5** In logistic regression, which distribution is used for the outcome variable?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Normal distribution
  prefs: []
  type: TYPE_NORMAL
- en: b) Poisson distribution
  prefs: []
  type: TYPE_NORMAL
- en: c) Bernoulli distribution
  prefs: []
  type: TYPE_NORMAL
- en: d) Exponential distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: c. Justification: The text provides examples of Bernoulli, categorical,
    and multivariate Gaussian distributions as members of the exponential family.
    The uniform distribution, however, does not fit the exponential family form.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: The text states that \(A(\boldsymbol{\theta})
    = \log Z(\boldsymbol{\theta})\), where \(Z(\boldsymbol{\theta})\) is referred
    to as the partition function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: a. Justification: The text provides the definition of the maximum
    likelihood estimator as \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max
    \left\{ \prod_{i=1}^n p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta
    \right\}\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: The text derives the equation \(\sum_{i=1}^n
    \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i \phi(y_i)\)
    as the one that the maximum likelihood estimator solves in a generalized linear
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: c. Justification: The text describes logistic regression as a
    GLM where the outcome variable is assumed to follow a Bernoulli distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1\. Exponential family[#](#exponential-family "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One particularly useful class of probability distributions in data science is
    the [exponential family](https://en.wikipedia.org/wiki/Exponential_family#Vector_parameter),
    which includes many well-known cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Exponential Family - Discrete Case)** \(\idx{exponential
    family}\xdi\) A parametric collection of probability distributions \(\{p_{\btheta}:\btheta
    \in \Theta\}\) over a discrete space \(\S\) is an exponential family if it can
    be written in the form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = \frac{1}{Z(\btheta)} h(\mathbf{x}) \exp\left(\btheta^T
    \bphi(\mathbf{x})\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'where \(\btheta \in \mathbb{R}^m\) are the canonical parameters, \(\bphi :
    \S \to \mathbb{R}^m\) are the sufficient statistics and \(Z(\btheta)\) is the
    partition function\(\idx{partition function}\xdi\). It is often convenient to
    introduce the log-partition function\(\idx{log-partition function}\xdi\) \(A(\btheta)
    = \log Z(\btheta)\) and re-write'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Bernoulli, continued)** For \(x \in \{0,1\}\), the \(\mathrm{Ber}(q)\)
    distribution for \(0 < q < 1\) can be written as'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} q^{x} (1-q)^{1-x} &= (1-q) \left(\frac{q}{1-q}\right)^x\\ &=
    (1-q) \exp\left[x \log \left(\frac{q}{1-q}\right)\right]\\ &= \frac{1}{Z(\theta)}
    h(x) \exp(\theta \,\phi(x)) \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we define \(h(x) \equiv 1\), \(\phi(x) = x\), \(\theta = \log \left(\frac{q}{1-q}\right)\)
    and, since \(Z(\theta)\) serves as the normalization constant in \(p_\theta\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ Z(\theta) = \sum_{x \in \{0,1\}} h(x) \exp(\theta \,\phi(x)) = 1 + e^\theta.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: The following is an important generalization. Recall that i.i.d. is the abbreviation
    for independent and identically distributed. We use the convention \(0! = 1\).
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Categorical and Multinomial)** A categorical variable\(\idx{categorical}\xdi\)
    \(\mathbf{Y}\) takes \(K \geq 2\) possible values. A standard choice is to use
    one-hot encoding\(\idx{one-hot encoding}\xdi\) \(\S = \{\mathbf{e}_i : i=1,\ldots,K\}\)
    where \(\mathbf{e}_i\) is the \(i\)-th canonical basis in \(\mathbb{R}^K\). The
    distribution is specified by setting the probabilities \(\bpi = (\pi_1,\ldots,\pi_K)\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \pi_i = \P[\mathbf{Y} = \mathbf{e}_i]. \]
  prefs: []
  type: TYPE_NORMAL
- en: We denote this \(\mathbf{Y} \sim \mathrm{Cat}(\bpi)\) and we assume \(\pi_i
    > 0\) for all \(i\).
  prefs: []
  type: TYPE_NORMAL
- en: To see that this is an exponential family, write the probability mass function
    at \(\mathbf{x} = (x_1,\ldots,x_K)\) as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \prod_{i=1}^K \pi_i^{x_i} = \exp\left(\sum_{i=1}^K x_i \log \pi_i \right).
    \]
  prefs: []
  type: TYPE_NORMAL
- en: So we can take \(h(\mathbf{x}) \equiv 1\), \(\btheta = (\log \pi_i)_{i=1}^K\),
    \(\bphi(\mathbf{x}) = (x_i)_{i=1}^K\) and \(Z(\btheta) \equiv 1\).
  prefs: []
  type: TYPE_NORMAL
- en: The [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution)\(\idx{multinomial}\xdi\)
    arises as a sum of independent categorical variables. Let \(n \geq 1\) be the
    number of trials (or samples) and let \(\mathbf{Y}_1,\ldots,\mathbf{Y}_n\) be
    i.i.d. \(\mathrm{Cat}(\bpi)\). Define \(\mathbf{X} = \sum_{i=1}^n \mathbf{Y}_i\).
    The probability mass function of \(\mathbf{X}\) at
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \mathbf{x} = (x_1,\ldots,x_K) \in \left\{ \mathbf{x} \in \{0,1,\ldots,n\}^K
    : \sum_{i=1}^K x_i = n \right\}=: \S \]'
  prefs: []
  type: TYPE_NORMAL
- en: is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{n!}{x_1!\cdots x_K!} \prod_{i=1}^K \pi_i^{x_i} = \frac{n!}{x_1!\cdots
    x_K!} \exp\left(\sum_{i=1}^K x_i \log \pi_i\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: and we can take \(h(\mathbf{x}) = \frac{n!}{x_1!\cdots x_K!}\), \(\btheta =
    (\log \pi_i)_{i=1}^K\), \(\bphi(\mathbf{x}) = (x_i)_{i=1}^K\) and \(Z(\btheta)
    \equiv 1\). This is an exponential family if we think of \(n\) as fixed.
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation \(\mathbf{X} \sim \mathrm{Mult}(n, \bpi)\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: While we have focused so far on discrete distributions, one can adapt the definitions
    above by replacing mass functions with density functions. We give two important
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: We need some definitions for our first example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [trace](https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29)\(\idx{trace}\xdi\)
    of a square matrix \(A \in \mathbb{R}^{d \times d}\), denoted \(\mathrm{tr}(A)\),
    is the sum of its diagonal entries. We will need the following trace identity
    whose proof we leave as an exercise: \(\mathrm{tr}(ABC) = \mathrm{tr}(CAB) = \mathrm{tr}(BCA)\)
    for any matrices \(A, B, C\) for which \(AB\), \(BC\) and \(CA\) are well-defined.'
  prefs: []
  type: TYPE_NORMAL
- en: The [determinant](https://en.wikipedia.org/wiki/Determinant)\(\idx{determinant}\xdi\)
    of a square matrix \(A\) is denoted by \(|A|\). For our purposes, it will be enough
    to consider symmetric, positive semidefinite matrices for which the determinant
    is the product of the eigenvalues (with repeats). Recall that we proved that the
    sequence of eigenvalues (with repeats) of a symmetric matrix is unique (in the
    sense that any two spectral decomposition have the same sequence of eigenvalues).
  prefs: []
  type: TYPE_NORMAL
- en: A symmetric, positive definite matrix \(A \in \mathbb{R}^{d \times d}\) is necessarily
    invertible. Indeed, it has a spectral decomposition
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = Q \Lambda Q^T = \sum_{i=1}^d \lambda_i \mathbf{q}_i \mathbf{q}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\lambda_1 \geq \cdots \geq \lambda_d > 0\) and \(\mathbf{q}_1, \ldots,
    \mathbf{q}_d\) are orthonormal. Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^{-1} = Q \Lambda^{-1} Q^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: To see this, note that
  prefs: []
  type: TYPE_NORMAL
- en: \[ A A^{-1} = Q \Lambda Q^T Q \Lambda^{-1} Q^T = Q Q^T = I_{d \times d}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The last equality follows from the fact that \(Q Q^T\) is the orthogonal projection
    on the orthonormal basis \(\mathbf{q}_1,\ldots,\mathbf{q}_d\). Similarly, \(A^{-1}
    A = I_{d \times d}\).
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Multivariate Gaussian)** \(\idx{multivariate normal}\xdi\)
    A multivariate Gaussian\(\idx{multivariate Gaussian}\xdi\) vector \(\mathbf{X}
    = (X_1,\ldots,X_d)\) on \(\mathbb{R}^d\) with mean \(\bmu \in \mathbb{R}^d\) and
    positive definite covariance matrix \(\bSigma \in \mathbb{R}^{d \times d}\) has
    probability density function'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\bmu, \bSigma}(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} \,|\bSigma|^{1/2}}
    \exp\left(-\frac{1}{2}(\mathbf{x} - \bmu)^T \bSigma^{-1} (\mathbf{x} - \bmu)\right).
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation \(\mathbf{X} \sim N_d(\bmu, \bSigma)\).
  prefs: []
  type: TYPE_NORMAL
- en: It can be shown that indeed the mean is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X}] = \bmu \]
  prefs: []
  type: TYPE_NORMAL
- en: and the covariance matrix is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[(\mathbf{X} - \bmu)(\mathbf{X} - \bmu)^T] = \E[\mathbf{X} \mathbf{X}^T]
    - \bmu \bmu^T = \bSigma. \]
  prefs: []
  type: TYPE_NORMAL
- en: In the bivariate\(\idx{bivariate Gaussian}\xdi\) case (i.e., when \(d = 2\))\(\idx{bivariate
    normal}\xdi\), the covariance matrix reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bSigma = \begin{bmatrix} \sigma_1^2 & \rho \sigma_1 \sigma_2
    \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma_1^2\) and \(\sigma_2^2\) are the respective variances of \(X_1\)
    and \(X_2\), and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \rho = \frac{\mathrm{Cov}[X_1,X_2]}{\sigma_1 \sigma_2} \]
  prefs: []
  type: TYPE_NORMAL
- en: is the correlation coefficient. Recall that, by the *Cauchy-Schwarz inequality*,
    it lies in \([-1,1]\).
  prefs: []
  type: TYPE_NORMAL
- en: Rewriting the density as
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\bmu, \bSigma}(\mathbf{x}) = \frac{e^{-(1/2) \bmu^T \bSigma^{-1} \bmu}}{(2\pi)^{d/2}
    \,|\bSigma|^{1/2}} \exp\left(- \mathbf{x}^T \bSigma^{-1}\bmu - \frac{1}{2} \mathrm{tr}\left(\mathbf{x}
    \mathbf{x}^T \bSigma^{-1}\right)\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used the symmetric nature of \(\bSigma^{-1}\) in the first term of
    the exponential and the previous trace identity in the second term. The expression
    in parentheses is linear in the entries of \(\mathbf{x}\) and \(\mathbf{x} \mathbf{x}^T\),
    which can then be taken as sufficient statistics (formally, using [vectorization](https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29)).
    Indeed note that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{x}^T \bSigma^{-1}\bmu = \sum_{i=1}^d x_i (\bSigma^{-1}\bmu)_i \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{tr}\left(\mathbf{x} \mathbf{x}^T \bSigma^{-1}\right) = \sum_{i =
    1}^d \left(\sum_{j=1}^d (\mathbf{x} \mathbf{x}^T)_{i,j} (\bSigma^{-1})_{j,i}\right)
    = \sum_{i = 1}^d \sum_{j=1}^d x_i x_j (\bSigma^{-1})_{j,i}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So we can take
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bphi(\mathbf{x}) = (x_1,\ldots,x_d, x_1 x_1, \ldots, x_d x_1, x_1 x_2, \ldots,
    x_d x_2, \ldots, x_1 x_d, \ldots, x_d x_d) \]\[\begin{align*} \btheta &= \bigg(-(\bSigma^{-1}\bmu)_1,\ldots,-(\bSigma^{-1}\bmu)_d,\\
    &\qquad - \frac{1}{2}(\bSigma^{-1})_{1,1}, \ldots, - \frac{1}{2}(\bSigma^{-1})_{1,d},\\
    &\qquad - \frac{1}{2}(\bSigma^{-1})_{2,1}, \ldots, - \frac{1}{2}(\bSigma^{-1})_{2,d},\\
    &\qquad \ldots, - \frac{1}{2}(\bSigma^{-1})_{d,1}, \ldots,- \frac{1}{2}(\bSigma^{-1})_{d,d}\bigg)
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and \(h (\mathbf{x}) \equiv 1\). Expressing \(Z(\btheta)\) explicitly is not
    straightforward. But note that \(\btheta\) includes all entries of \(\bSigma^{-1}\),
    from which \(\bSigma\) can be computed (e.g., from [Cramer’s rule](https://en.wikipedia.org/wiki/Cramer%27s_rule#Finding_inverse_matrix)),
    and in turn from which \(\bmu\) can be extracted out of the entries of \(\bSigma^{-1}\bmu\)
    in \(\btheta\). So the normalizing factor \(\frac{(2\pi)^{d/2} \,|\bSigma|^{1/2}}{e^{-(1/2)
    \bmu^T \bSigma^{-1} \bmu}}\) can in principle be expressed in terms of \(\btheta\).
  prefs: []
  type: TYPE_NORMAL
- en: This shows that the multivariate normal is an exponential family.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix \(\bLambda = \bSigma^{-1}\) is also known as the precision matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, let \(\mathbf{Z}\) be a standard normal \(d\)-vector, let \(\bmu
    \in \mathbb{R}^d\) and let \(\bSigma \in \mathbb{R}^{d \times d}\) be positive
    definite. Then the transformed random variable \(\mathbf{X} = \bmu + \bSigma \mathbf{Z}\)
    is a multivariate Gaussian with mean \(\bmu\) and covariance matrix \(\bSigma\).
    This can be proved using the [change of variables formula](https://en.wikipedia.org/wiki/Probability_density_function#Function_of_random_variables_and_change_of_variables_in_the_probability_density_function)
    (try it!). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** The following code, which plots the density in the bivariate
    case, was adapted from [gauss_plot_2d.ipynb](https://github.com/probml/pyprobml/blob/master/notebooks/book1/03/gauss_plot_2d.ipynb)
    by ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Ask your favorite AI chatbot to explain the code! Try different
    covariance matrices. ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We plot the density for mean \((0,0)\) with two different covariance matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{split} \bSigma_1 = \begin{bmatrix} 1.0 & 0 \\ 0 & 1.0 \end{bmatrix}
    \quad \text{and} \quad \bSigma_2 = \begin{bmatrix} \sigma_1^2 & \rho \sigma_1
    \sigma_2 \\ \rho \sigma_1 \sigma_2 & \sigma_2^2 \end{bmatrix} \end{split}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma_1 = 1.5\), \(\sigma_2 = 0.5\) and \(\rho = -0.75\).
  prefs: []
  type: TYPE_NORMAL
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]</details> ![../../_images/aa8a076cd17782940f0aa5ed62929716a9ad484853e0e195abb9808dc5430649.png](../Images/bd4d757f39ffc955469d96c6ccc28859.png)<details
    class="hide above-input"><summary aria-label="Toggle hidden content">Show code
    cell source Hide code cell source</summary>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]</details> ![../../_images/4a907efb3af995445fe3feb6f564880bfd1d84078a5876676a3758260bc699c8.png](../Images/38909f679dda3fe6c8703a40390160ef.png)'
  prefs: []
  type: TYPE_NORMAL
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: The [Dirichlet distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution),
    which we describe next, is a natural probability distribution over probability
    distributions. In particular, it is used in [Bayesian data analysis](https://en.wikipedia.org/wiki/Bayesian_statistics)
    as a [prior](https://en.wikipedia.org/wiki/Prior_probability) on the parameters
    of categorical and multinomial distribution, largely because of a property known
    as [conjuguacy](https://en.wikipedia.org/wiki/Conjugate_prior). We will not describe
    Bayesian approaches here.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Dirichlet)** \(\idx{Dirichlet}\xdi\) The Dirichlet distribution
    is a distribution over the \((K-1)\)-simplex'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \S = \Delta_{K} := \left\{ \mathbf{x} = (x_1, \ldots, x_K) : \mathbf{x}
    \geq \mathbf{0},\ \sum_{i=1}^K x_i = 1 \right\}. \]'
  prefs: []
  type: TYPE_NORMAL
- en: Its parameters are \(\balpha = (\alpha_1, \ldots, \alpha_K) \in \mathbb{R}\)
    and the density is
  prefs: []
  type: TYPE_NORMAL
- en: \[ f_{\balpha}(\mathbf{x}) = \frac{1}{B(\balpha)} \prod_{i=1}^K x_i^{\alpha_i-1},
    \quad \mathbf{x} \in \Delta_{K} \]
  prefs: []
  type: TYPE_NORMAL
- en: where the normalizing constant \(B(\balpha)\) is the [multivariate Beta function](https://en.wikipedia.org/wiki/Beta_function#Multivariate_beta_function).
  prefs: []
  type: TYPE_NORMAL
- en: Rewriting the density as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{B(\balpha)} \prod_{i=1}^K x_i^{\alpha_i-1} = \frac{1}{B(\balpha)}
    \frac{1}{\prod_{i=1}^K x_i} \exp\left(\sum_{i=1}^K \alpha_i \log x_i\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: shows that this is an exponential family with the canonical parameters \(\balpha\)
    and sufficient statistics \((\log x_i)_{i=1}^K\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: See [here](https://en.wikipedia.org/wiki/Exponential_family#Table_of_distributions)
    for many more examples. Observe, in particular, that the same distribution can
    have several representations as an exponential family.
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** In NumPy, as we have seen before, the module [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html)
    provides a way to sample from a variety of standard distributions. We first initialize
    the [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator)\(\idx{pseudorandom
    number generator}\xdi\) with a [random seed](https://en.wikipedia.org/wiki/Random_seed).
    Recall that it allows the results to be reproducible: using the same seed produces
    the same results again.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here’s are lists of available [probability distributions](https://numpy.org/doc/stable/reference/random/generator.html#distributions).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here are a few other examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**KNOWLEDGE CHECK:** The Weibull distribution with known shape parameter \(k
    > 0\) takes the following form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(x; \lambda) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k},
    \]
  prefs: []
  type: TYPE_NORMAL
- en: for \(x \geq 0\), where \(\lambda > 0\).
  prefs: []
  type: TYPE_NORMAL
- en: What is the sufficient statistic of its exponential family form?
  prefs: []
  type: TYPE_NORMAL
- en: a) \(x\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\log x\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(x^{k-1}\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(x^k\)
  prefs: []
  type: TYPE_NORMAL
- en: e) \((\log x, x^k)\)
  prefs: []
  type: TYPE_NORMAL
- en: \(\checkmark\)
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2\. Parameter estimation[#](#parameter-estimation "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When modeling data via a parametric family of distributions, the parameters
    must be determined from the data itself. In a typical setting, we assume that
    the data comprises \(n\) independent samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\)
    from a parametric family \(p_{\btheta}\) with unknown \(\btheta \in \Theta\).
    Many methods exist for estimating \(\btheta\), depending on the context. Here
    we focus on [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation).
    It has many [good theoretical properties](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties)
    which we will not describe here, as well as [drawbacks](https://stats.stackexchange.com/questions/261056/why-does-maximum-likelihood-estimation-have-issues-with-over-fitting).
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea behind maximum likelihood estimation is simple and intuitive: we choose
    the parameter that maximizes the probability of observing the data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Maximum likelihood estimator)** \(\idx{maximum likelihood}\xdi\)
    Assume that \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) are \(n\) independent samples
    from a parametric family \(p_{\btheta^*}\) with unknown \(\btheta^* \in \Theta\).
    The maximum likelihood estimator of \(\btheta\) is defined as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\btheta_{\mathrm{MLE}} \in \arg\max\left\{ \prod_{i=1}^n p_{\btheta}(\mathbf{X}_i)
    \,:\, \btheta \in \Theta \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: It is often useful to work with the negative log-likelihood (NLL)\(\idx{negative
    log-likelihood}\xdi\)
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = - \sum_{i=1}^n \log p_{\btheta}(\mathbf{X}_i),
    \]
  prefs: []
  type: TYPE_NORMAL
- en: in which case we are minimizing. \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Biased coin)** Suppose we observe \(n\) coin flips \(X_1,\ldots,
    X_n \in \{0,1\}\) from a biased coin with an unknown probability \(\theta^*\)
    of producing \(1\). We assume the flips are independent. We compute the MLE of
    the parameter \(\theta\).'
  prefs: []
  type: TYPE_NORMAL
- en: The definition is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} \in \arg\min\left\{ L_n(\theta; \{X_i\}_{i=1}^n)
    \,:\, \theta \in \Theta = [0,1] \right\} \]
  prefs: []
  type: TYPE_NORMAL
- en: where, using our previous Bernoulli example, the NLL is
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\theta; \{X_i\}_{i=1}^n) &= - \sum_{i=1}^n \log p_{\theta}(X_i)\\
    &= - \sum_{i=1}^n \log \left[\theta^{X_i} (1- \theta)^{1 -X_i}\right]\\ &= - \sum_{i=1}^n
    \left[ X_i \log \theta + (1 -X_i) \log (1- \theta)\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: 'We compute the first and second derivatives of \(L_n(\theta; \{X_i\}_{i=1}^n)\)
    as a function of \(\theta\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\mathrm{d}}{\mathrm{d} \theta}L_n(\theta; \{X_i\}_{i=1}^n)
    &= - \sum_{i=1}^n \left[ \frac{X_i}{\theta} - \frac{1 -X_i}{1- \theta}\right]\\
    &= - \frac{\sum_{i=1}^n X_i}{\theta} + \frac{n - \sum_{i=1}^n X_i}{1- \theta}
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\mathrm{d}^2}{\mathrm{d} \theta^2}L_n(\theta; \{X_i\}_{i=1}^n)
    &= \frac{\sum_{i=1}^n X_i}{\theta^2} + \frac{n - \sum_{i=1}^n X_i}{(1- \theta)^2}.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The second derivative is non-negative and therefore the NLL is convex. To find
    a global minimizer, it suffices to find a stationary point.
  prefs: []
  type: TYPE_NORMAL
- en: We make the derivative of the NLL equal to \(0\)
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} &0 = - \frac{\sum_{i=1}^n X_i}{\theta} + \frac{n - \sum_{i=1}^n
    X_i}{1- \theta}\\ & \iff \frac{\sum_{i=1}^n X_i}{\theta} = \frac{n - \sum_{i=1}^n
    X_i}{1- \theta}\\ & \iff (1- \theta)\sum_{i=1}^n X_i = \theta \left(n - \sum_{i=1}^n
    X_i \right)\\ & \iff \sum_{i=1}^n X_i = \theta n. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: So
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \frac{\sum_{i=1}^n X_i}{n}. \]
  prefs: []
  type: TYPE_NORMAL
- en: 'This is in fact a natural estimator: the empirical frequency of \(1\)s. \(\lhd\)'
  prefs: []
  type: TYPE_NORMAL
- en: We give an alternative perspective on the maximum likelihood estimator. Assume
    that \(p_{\btheta}\) is supported on a fixed finite set \(\X\) for all \(\btheta
    \in \Theta\). Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\), for each \(\mathbf{x}
    \in \X\), let
  prefs: []
  type: TYPE_NORMAL
- en: \[ N_\mathbf{x} = \sum_{i=1}^n \mathbf{1}_{\{\mathbf{X}_i = \mathbf{x}\}} \]
  prefs: []
  type: TYPE_NORMAL
- en: count the number of times \(\mathbf{x}\) is observed in the data and let
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\mu_n(\mathbf{x}) = \frac{N_\mathbf{x}}{n} \]
  prefs: []
  type: TYPE_NORMAL
- en: be the empirical frequency of \(\mathbf{x}\) in the sample. Observe that \(\hat\mu_n\)
    is a probability distribution over \(\X\).
  prefs: []
  type: TYPE_NORMAL
- en: The following theorem characterizes the maximum likelihood estimator in terms
    of the [Kullback-Liebler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)\(\idx{Kullback-Liebler
    divergence}\xdi\), which was introduced in a previous section.
  prefs: []
  type: TYPE_NORMAL
- en: For two probability distributions
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{p}, \mathbf{q} \in \Delta_K := \left\{ (p_1,\ldots,p_K) \in [0,1]^K
    \,:\, \sum_{k=1}^K p_k = 1 \right\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: it is defined as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) = \sum_{i=1}^K p_i \log \frac{p_i}{q_i}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where it will suffice to restrict ourselves to the case \(\mathbf{q} > \mathbf{0}\)
    and where we use the convention \(0 \log 0 = 0\) (so that terms with \(p_i = 0\)
    contribute \(0\) to the sum).
  prefs: []
  type: TYPE_NORMAL
- en: Notice that \(\mathbf{p} = \mathbf{q}\) implies \(\mathrm{KL}(\mathbf{p} \|
    \mathbf{q}) = 0\). We show that \(\mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0\),
    a result known as *Gibbs’ inequality*.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Gibbs)** \(\idx{Gibbs'' inequality}\xdi\) For any \(\mathbf{p},
    \mathbf{q} \in \Delta_K\) with \(\mathbf{q} > \mathbf{0}\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* Let \(I\) be the set of indices \(i\) such that \(p_i > 0\). Hence'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\mathbf{p} \| \mathbf{q}) = \sum_{i \in I} p_i \log \frac{p_i}{q_i}.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: It can be proved that \(\log x \leq x - 1\) for all \(x > 0\) (Try it!). So
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \mathrm{KL}(\mathbf{p} \| \mathbf{q}) &= - \sum_{i \in I} p_i
    \log \frac{q_i}{p_i}\\ &\geq - \sum_{i \in I} p_i \left(\frac{q_i}{p_i} - 1\right)\\
    &= - \sum_{i \in I} q_i + \sum_{i \in I} p_i\\ &= - \sum_{i \in I} q_i + 1\\ &\geq
    0 \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(\log z^{-1} = - \log z\) on the first line and the fact
    that \(p_i = 0\) for all \(i \notin I\) on the fourth line. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(MLE via KL)** \(\idx{MLE via KL theorem}\xdi\) Assume that,
    for all \(\btheta \in \Theta\), \(p_{\btheta}\) is supported on a fixed finite
    set \(\X\) and that \(p_{\btheta}(\mathbf{x}) > 0\) for all \(\mathbf{x} \in \X\).
    Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) from \(p_{\btheta^*}\), let
    \(\{\hat\mu_n(\mathbf{x})\}_{\mathbf{x} \in \X}\) be the corresponding empirical
    frequencies. Then the maximum likelihood estimator \(\hat\btheta_{\mathrm{MLE}}\)
    of \(\btheta\) is also a solution to'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\btheta_{\mathrm{MLE}} \in \arg\min\left\{ \mathrm{KL}(\hat{\mu}_n \|
    p_{\btheta}) \,:\, \btheta \in \Theta \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* Manipulate the negative log-likelihood to bring out its relationship
    to the Kullback-Liebler divergence.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* We can re-write the negative log-likelihood as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = - \sum_{i=1}^n \log p_{\btheta}(\mathbf{X}_i)
    = - \sum_{\mathbf{x} \in \X} N_{\mathbf{x}} \log p_{\btheta}(\mathbf{x}). \]
  prefs: []
  type: TYPE_NORMAL
- en: To bring out the Kullback-Liebler divergence, we further transform the previous
    equation into
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{1}{n} L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) &= - \frac{1}{n}
    \sum_{\mathbf{x} \in \X} N_{\mathbf{x}} \log p_{\btheta}(\mathbf{x})\\ &= \sum_{\mathbf{x}
    \in \X} (N_{\mathbf{x}}/n) \log \frac{N_{\mathbf{x}}/n}{p_{\btheta}(\mathbf{x})}
    - \sum_{\mathbf{x} \in \X} (N_{\mathbf{x}}/n) \log (N_{\mathbf{x}}/n)\\ &= \sum_{\mathbf{x}
    \in \X} \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{p_{\btheta}(\mathbf{x})}
    - \sum_{\mathbf{x} \in \X} \hat\mu_n(\mathbf{x}) \log \hat\mu_n(\mathbf{x})\\
    &= \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) + \mathrm{H}(\hat\mu_n), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where the second term is referred to as the [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory))\(\idx{entropy}\xdi\)
    of \(\hat\mu_n\).
  prefs: []
  type: TYPE_NORMAL
- en: Because \(\mathrm{H}(\hat\mu_n)\) does not depend on \(\btheta\), minimizing
    \(L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\) is equivalent to minimizing \(\mathrm{KL}(\hat{\mu}_n
    \| p_{\btheta})\) as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: 'In words, the maximum likelihood estimator chooses the parametric distribution
    that is closest to \(\hat\mu_n\) in Kullback-Liebler divergence. One can think
    of this as “projecting” \(\hat\mu_n\) onto the space \(\{p_{\btheta} : \btheta
    \in \Theta\}\) under the Kullback-Liebler notion of distance.'
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Special case)** One special case is where \(\X\) is finite,
    \(\btheta = (\theta_\mathbf{x})_{\mathbf{x} \in \X}\) is a probability distribution
    over \(\X\), and \(p_{\btheta} = \btheta\). That is, we consider the class of
    all probability distributions over \(\X\). Given samples \(\mathbf{X}_1,\ldots,\mathbf{X}_n\)
    from \(p_{\btheta^*}\), in this case we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = \sum_{\mathbf{x} \in \X} \hat\mu_n(\mathbf{x})
    \log \frac{\hat\mu_n(\mathbf{x})}{p_{\btheta}(\mathbf{x})} = \sum_{\mathbf{x}
    \in \X} \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}},
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where recall that, by convention, if \(\hat\mu_n(\mathbf{x}) = 0\) then \(\hat\mu_n(\mathbf{x})
    \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}} = 0\) for any \(\theta_\mathbf{x}\).
    So, letting \(\mathbb{X}_n = \{\mathbf{X}_1,\ldots,\mathbf{X}_n\}\) be the set
    of distinct values encountered in the sample (ignoring repetitions), we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = \sum_{\mathbf{x} \in \mathbb{X}_n}
    \hat\mu_n(\mathbf{x}) \log \frac{\hat\mu_n(\mathbf{x})}{\theta_\mathbf{x}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: Note that \(\sum_{\mathbf{x} \in \mathbb{X}_n} \hat\mu_n(\mathbf{x}) = 1\).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have previously established *Gibbs’ inequality* which says that: for any
    \(\mathbf{p}, \mathbf{q} \in \Delta_K\) with \(\mathbf{q} > \mathbf{0}\), it holds
    that \(\mathrm{KL}(\mathbf{p} \| \mathbf{q}) \geq 0\).'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum \(\mathrm{KL}(\hat{\mu}_n \| p_{\btheta}) = 0\) can be achieved
    by setting \(\btheta_{\mathbf{x}} = \hat\mu_n(\mathbf{x})\) for all \(\mathbf{x}
    \in \mathbb{X}_n\) and \(\btheta_{\mathbf{x}} = 0\) for all \(\mathbf{x} \notin
    \mathbb{X}_n\). The condition
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{\mathbf{x} \in \X} \btheta_{\mathbf{x}} = \sum_{\mathbf{x} \in \mathbb{X}_n}
    \btheta_{\mathbf{x}} + \sum_{\mathbf{x} \notin \mathbb{X}_n} \btheta_{\mathbf{x}}
    = \sum_{\mathbf{x} \in \mathbb{X}_n} \hat\mu_n(\mathbf{x}) = 1, \]
  prefs: []
  type: TYPE_NORMAL
- en: is then satisfied.
  prefs: []
  type: TYPE_NORMAL
- en: So in this case \(\hat\mu_n\) is a maximum likelihood estimator.
  prefs: []
  type: TYPE_NORMAL
- en: A special case of this is the *biased coin* example. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Explore the concept of Bayesian parameter estimation. Ask
    your favorite AI chatbot how Bayesian parameter estimation differs from maximum
    likelihood estimation and discuss their relative strengths and weaknesses. Here
    are some possible follow-ups. (1) Get an example implementation using a simple
    dataset. (2) The categorical and multinomial distributions are related to the
    Dirichlet distribution. Ask about relationship and how the Dirichlet distribution
    is used in Bayesian inference for these distributions. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3\. Parameter estimation for exponential families[#](#parameter-estimation-for-exponential-families
    "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For exponential families, maximum likelihood estimation takes a particularly
    natural form. We provide details in the discrete case.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Maximum Likelihood Estimator for Exponential Families)** \(\idx{maximum
    likelihood estimator for exponential families}\xdi\) Assume that \(p_{\btheta}\)
    takes the exponential family form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: that the support \(\S\) is finite, and that \(A\) is twice continuously differentiable
    over the open set \(\Theta\). Let \(\mathbf{X}_1,\ldots,\mathbf{X}_n\) be \(n\)
    independent samples from a parametric family \(p_{\btheta^*}\) with unknown \(\btheta^*
    \in \Theta\). Then \(L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\), as a function of
    \(\btheta\), is convex and the maximum likelihood estimator of \(\btheta\) – if
    it exists – solves the system of moment-matching equations
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\bphi(\mathbf{X})] = \frac{1}{n} \sum_{i=1}^n \bphi(\mathbf{X}_i), \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\hat\btheta_{\mathrm{MLE}}}\). \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the covariance matrix of a random vector \(\mathbf{Z}\) taking values
    in \(\mathbb{R}^m\) whose components have finite variances is defined as \(\mathrm{K}_{\mathbf{Z},
    \mathbf{Z}} = \E[(\mathbf{Z} - \E[\mathbf{Z}])(\mathbf{Z} - \E[\mathbf{Z}])^T]\)
    and is a positive semidefinite matrix. It is also sometimes denoted as \(\bSigma_\mathbf{Z}\).
  prefs: []
  type: TYPE_NORMAL
- en: The function \(A\) has properties worth highlighting that will be used in the
    proof.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Derivatives of \(A\))** Assume that \(p_{\btheta}\) takes the
    exponential family form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\btheta}(\mathbf{x}) = h(\mathbf{x}) \exp\left(\btheta^T \bphi(\mathbf{x})
    - A(\btheta)\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: that the support \(\S\) is finite, and that \(A\) is twice continuously differentiable
    over the open set \(\Theta\). Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla A(\btheta) = \E[\bphi(\mathbf{X})] \qquad \text{and} \qquad \mathbf{H}_A
    (\btheta) = \mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}, \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\btheta}\). \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* Follows from a direct calculation.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* We observe first that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A(\btheta) = \log Z(\btheta) = \log\left(\sum_{\mathbf{x} \in \S} h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}))\right), \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used the fact that, by definition, \(Z(\btheta)\) is the normalization
    constant of \(p_{\btheta}\). In particular, as the logarithm of a finite, weighted
    sum of exponentials, the function \(A(\btheta)\) is continuously differentiable.
    Hence so is \(p_{\btheta}(\mathbf{x})\) as a function of \(\btheta\).
  prefs: []
  type: TYPE_NORMAL
- en: From the formula above and the basic rules of calculus,
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial}{\partial \theta_j} A(\btheta) &= \frac{\partial}{\partial
    \theta_j} \log\left(\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}))\right)\\
    &= \frac{\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \,\phi_j(\mathbf{x}) \exp(\btheta^T
    \bphi(\mathbf{x}))}{\sum_{\mathbf{x} \in \S} h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}))}\\
    &= \sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x}) \frac{1}{Z(\btheta)} h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}))\\ &= \sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\\ &= \E[\phi_j(\mathbf{X})],
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\btheta}\).
  prefs: []
  type: TYPE_NORMAL
- en: Differentiating again, this time with respect to \(\theta_i\), we obtain
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial^2}{\partial \theta_i \partial \theta_j} A(\btheta)
    &= \frac{\partial}{\partial \theta_i} \left\{\sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\right\}\\ &= \sum_{\mathbf{x}
    \in \S} \phi_j(\mathbf{x}) h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))
    \left\{\phi_i(\mathbf{x}) - \frac{\partial}{\partial \theta_i} A(\btheta) \right\}\\
    &= \sum_{\mathbf{x} \in \S} \phi_i(\mathbf{x}) \phi_j(\mathbf{x}) h(\mathbf{x})
    \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))\\ & \qquad - \left(\sum_{\mathbf{x}
    \in \S} \phi_i(\mathbf{x}) h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta))
    \right)\\ & \qquad\qquad \times \left(\sum_{\mathbf{x} \in \S} \phi_j(\mathbf{x})
    h(\mathbf{x}) \exp(\btheta^T \bphi(\mathbf{x}) - A(\btheta)) \right)\\ &= \E[\phi_i(\mathbf{X})\phi_j(\mathbf{X})]
    - \E[\phi_i(\mathbf{X})]\E[\phi_j(\mathbf{X})], \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where again \(\mathbf{X} \sim p_{\btheta}\). That concludes the proof. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to the prove the main theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Maximum Likelihood Estimator for Exponential Families)* We begin
    by computing the stationary points of the negative log-likelihood, for which we
    need the gradient with respect to \(\btheta \in \mathbb{R}^m\). We will also need
    the second-order derivatives to establish convexity. We have'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial}{\partial \theta_j} \{- \log p_{\btheta}(\mathbf{x})\}
    &= \frac{\partial}{\partial \theta_j} \left\{- \log h(\mathbf{x}) - \btheta^T
    \bphi(\mathbf{x}) + A(\btheta)\right\}\\ &= - \phi_j(\mathbf{x}) + \frac{\partial}{\partial
    \theta_j} A(\btheta). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial^2}{\partial \theta_i \partial \theta_j} \{-
    \log p_{\btheta}(\mathbf{x})\} &= \frac{\partial}{\partial \theta_i} \left\{-
    \phi_j(\mathbf{x}) + \frac{\partial}{\partial \theta_j} A(\btheta)\right\}\\ &=
    \frac{\partial^2}{\partial \theta_i \partial \theta_j} A(\btheta). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: We use the expressions for the derivatives of \(A\) obtained above.
  prefs: []
  type: TYPE_NORMAL
- en: Plugging into the formula for the minus log-likelihood (as a function of \(\btheta\)),
    we get for the gradient with respect to \(\btheta\)
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\btheta L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) &= -
    \sum_{i=1}^n \nabla_\btheta \log p_{\btheta}(\mathbf{X}_i)\\ &= \sum_{i=1}^n \{-
    \bphi(\mathbf{X}_i) + \nabla_\btheta A(\btheta)\}\\ &= \sum_{i=1}^n \{- \bphi(\mathbf{X}_i)
    + \E[\bphi(\mathbf{X})]\}. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This is also known in statistics as the [score](https://en.wikipedia.org/wiki/Score_(statistics)).
  prefs: []
  type: TYPE_NORMAL
- en: For the Hessian with respect to \(\btheta\), we get
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \mathbf{H}_{L_n}(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = \sum_{i=1}^n
    \mathbf{H}_A (\btheta) = n \,\mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This is also known in statistics as the [observed information](https://en.wikipedia.org/wiki/Observed_information).
    (In fact, in this case, it reduces to the [Fisher information](https://en.wikipedia.org/wiki/Fisher_information).)
    Since \(\mathrm{K}_{\bphi(\mathbf{X}), \bphi(\mathbf{X})}\) is positive semidefinite,
    so is \(\mathbf{H}_{L_n}(\btheta; \{\mathbf{X}_i\}_{i=1}^n)\).
  prefs: []
  type: TYPE_NORMAL
- en: Hence, a stationary point \(\hat\btheta_{\mathrm{MLE}}\) must satisfy
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{0} = \nabla L_n(\btheta; \{\mathbf{X}_i\}_{i=1}^n) = \sum_{i=1}^n
    \{- \bphi(\mathbf{X}_i) + \E[\bphi(\mathbf{X})]\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{X} \sim p_{\hat\btheta_{\mathrm{MLE}}}\) or, after re-arranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\bphi(\mathbf{X})] = \frac{1}{n} \sum_{i=1}^n \bphi(\mathbf{X}_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: Because \(L_n\) is convex, a stationary point – if it exists – is necessarily
    a global minimum (and vice versa). \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Bernoulli/biased coin, continued)** For \(x \in \{0,1\}\),
    recall that the \(\mathrm{Ber}(q)\) distribution can be written as'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(x) &= \frac{1}{Z(\theta)} h(x) \exp(\theta \,\phi(x))
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we define \(h(x) \equiv 1\), \(\phi(x) = x\), \(\theta = \log \left(\frac{q}{1-q}\right)\)
    and \(Z(\theta) = 1 + e^\theta\). Let \(X_1,\ldots,X_n\) be independent samples
    from \(p_{\theta^*}\).
  prefs: []
  type: TYPE_NORMAL
- en: For \(X \sim p_{\hat\theta_{\mathrm{MLE}}}\), the moment-matching equations
    reduce to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat{q}_{\mathrm{MLE}} := \E[X] = \E[\phi(X)] = \frac{1}{n} \sum_{i=1}^n
    \phi(X_i) = \frac{1}{n} \sum_{i=1}^n X_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: To compute the left-hand side in terms of \(\hat\theta_{\mathrm{MLE}}\) we use
    the relationship \(\theta = \log \left(\frac{q}{1-q}\right)\), that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \log \left(\frac{\frac{1}{n} \sum_{i=1}^n X_i}{1-\frac{1}{n}
    \sum_{i=1}^n X_i}\right). \]
  prefs: []
  type: TYPE_NORMAL
- en: Hence, \(\hat\theta_{\mathrm{MLE}}\) is well-defined when \(\frac{1}{n} \sum_{i=1}^n
    X_i \neq 0, 1\).
  prefs: []
  type: TYPE_NORMAL
- en: Define \(q^*\) as the solution to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \theta^* = \log \left(\frac{q^*}{1-q^*}\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ q^* = \frac{e^{\theta^*}}{1+e^{\theta^*}} = \frac{1}{1 + e^{-\theta*}} =
    \sigma(\theta^*), \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma\) is the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: By the law of large numbers, as \(n \to +\infty\), we get the convergence
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{1}{n} \sum_{i=1}^n X_i \to q^*, \]
  prefs: []
  type: TYPE_NORMAL
- en: with probability one.
  prefs: []
  type: TYPE_NORMAL
- en: Because the function \(\log \left(\frac{q}{1-q}\right)\) is continuous for \(q
    \in (0,1)\), we have furthermore
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat\theta_{\mathrm{MLE}} = \log \left(\frac{\frac{1}{n} \sum_{i=1}^n X_i}{1-\frac{1}{n}
    \sum_{i=1}^n X_i}\right) \to \log \left(\frac{q^*}{1-q^*}\right) = \theta^*. \]
  prefs: []
  type: TYPE_NORMAL
- en: In words, the maximum likelihood estimator \(\hat\theta_{\mathrm{MLE}}\) is
    guaranteed to converge to the true parameter \(\theta^*\) when the number of samples
    grows. This fundamental property is known as [statistical consistency](https://en.wikipedia.org/wiki/Consistent_estimator)\(\idx{statistical
    consistency}\xdi\). \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: Statistical consistency holds more generally for the maximum likelihood estimator
    under exponential families, provided certain technical conditions hold. We will
    not provide further details here.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the previous example, one does not always have an explicit formula for
    the maximum likelihood estimator under exponential families. Instead, optimization
    methods, for instance [Newton’s method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization),
    are used in such cases.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Multivariate Gaussian)** We established the theorem for finite
    \(\mathcal{S}\), but it holds more generally. Consider the multivariate Gaussian
    case. Here the sufficient statistics are'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bphi(\mathbf{x}) = (x_1,\ldots,x_d, x_1 x_1, \ldots, x_d x_1, x_1 x_2, \ldots,
    x_d x_2, \ldots, x_1 x_d, \ldots, x_d x_d) \]
  prefs: []
  type: TYPE_NORMAL
- en: which is simply the vector \(\mathbf{x}\) itself stacked with the vectorized
    form of the matrix \(\mathbf{x} \mathbf{x}^T\). So the moment-matching equations
    boil down to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X}] = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\mathbf{X} \mathbf{X}^T ] = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \mathbf{X}_i^T.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: The first equation says to choose \(\bmu = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i\).
    The second one says to take
  prefs: []
  type: TYPE_NORMAL
- en: \[ \bSigma = \E[\mathbf{X} \mathbf{X}^T] - \E[\mathbf{X}]\,\E[\mathbf{X}]^T
    = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i \mathbf{X}_i^T - \left(\frac{1}{n} \sum_{i=1}^n
    \mathbf{X}_i\right) \left(\frac{1}{n} \sum_{i=1}^n \mathbf{X}_i^T \right). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**KNOWLEDGE CHECK:** Consider again the Weibull distribution with known shape
    parameter \(k > 0\).'
  prefs: []
  type: TYPE_NORMAL
- en: a) Compute \(\E[X^k]\). [*Hint:* Perform a change of variables.]
  prefs: []
  type: TYPE_NORMAL
- en: b) What is the MLE of \(\lambda\)?
  prefs: []
  type: TYPE_NORMAL
- en: \(\checkmark\)
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.4\. Generalized linear models[#](#generalized-linear-models "Link to this
    heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generalized linear models\(\idx{generalized linear model}\xdi\) (GLM) provide
    a broad generalization of linear regression using exponential families. Quoting
    from [Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model), the
    context in which they arise is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Ordinary linear regression predicts the expected value of a given unknown quantity
    (the response variable, a random variable) as a linear combination of a set of
    observed values (predictors). This implies that a constant change in a predictor
    leads to a constant change in the response variable (i.e. a linear-response model).
    This is appropriate when the response variable can vary, to a good approximation,
    indefinitely in either direction, or more generally for any quantity that only
    varies by a relatively small amount compared to the variation in the predictive
    variables, e.g. human heights. However, these assumptions are inappropriate for
    some types of response variables. For example, in cases where the response variable
    is expected to be always positive and varying over a wide range, constant input
    changes lead to geometrically (i.e. exponentially) varying, rather than constantly
    varying, output changes. […] Similarly, a model that predicts a probability of
    making a yes/no choice (a Bernoulli variable) is even less suitable as a linear-response
    model, since probabilities are bounded on both ends (they must be between 0 and
    1). […] Generalized linear models cover all these situations by allowing for response
    variables that have arbitrary distributions (rather than simply normal distributions),
    and for an arbitrary function of the response variable (the link function) to
    vary linearly with the predicted values (rather than assuming that the response
    itself must vary linearly).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In its simplest form, a generalized linear model assumes that an outcome variable
    \(y \in \mathbb{R}\) is generated from an exponential family \(p_\theta\), where
    \(\theta \in \mathbb{R}\) is a linear combination of the predictor variables \(\mathbf{x}
    \in \mathbb{R}^d\). That is, we assume that \(\theta = \mathbf{w}^T \mathbf{x}\)
    for unknown \(\mathbf{w} \in \mathbb{R}^d\) and the probability distribution of
    \(y\) is of the form
  prefs: []
  type: TYPE_NORMAL
- en: \[ p_{\mathbf{w}^T \mathbf{x}}(y) = h(y) \exp\left((\mathbf{w}^T\mathbf{x})
    \,\phi(y) - A(\mathbf{w}^T \mathbf{x})\right) \]
  prefs: []
  type: TYPE_NORMAL
- en: for some sufficient statistic \(\phi(y)\). We further assume that \(A\) is twice
    continuously differentiable over \(\mathbb{R}\).
  prefs: []
  type: TYPE_NORMAL
- en: Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), the model is fitted using
    maximum likelihood as follows. Under independence of the samples, the likelihood
    of the data is \(\prod_{i=1}^n p_{\mathbf{w}^T \mathbf{x}_i}(y_i)\), which we
    seek to maximize over \(\mathbf{w}\) (which is different from maximizing over
    \(\theta\)!). As before, we work with the negative log-likelihood, which we denote
    as (with a slight abuse of notation)
  prefs: []
  type: TYPE_NORMAL
- en: \[ L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = - \sum_{i=1}^n \log p_{\mathbf{w}^T
    \mathbf{x}_i}(y_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: The gradient with respect to \(\mathbf{w}\) is given by
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})
    &= - \sum_{i=1}^n \nabla_\mathbf{w} \log\left[ h(y_i) \exp\left(\mathbf{w}^T \mathbf{x}_i
    \phi(y_i) - A(\mathbf{w}^T \mathbf{x}_i)\right)\right]\\ &= - \sum_{i=1}^n \nabla_\mathbf{w}
    \left[\log h(y_i) + \mathbf{w}^T \mathbf{x}_i \phi(y_i) - A(\mathbf{w}^T \mathbf{x}_i)\right]\\
    &= - \sum_{i=1}^n \left[ \mathbf{x}_i \phi(y_i) - \nabla_\mathbf{w} A(\mathbf{w}^T
    \mathbf{x}_i)\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: By the *Chain Rule* and our previous formulas,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla_\mathbf{w} A(\mathbf{w}^T \mathbf{x}_i) = A'(\mathbf{w}^T \mathbf{x}_i)
    \,\mathbf{x}_i = \mu(\mathbf{w}; \mathbf{x}_i) \,\mathbf{x}_i \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{w}^T
    \mathbf{x}_i}\). That is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = - \sum_{i=1}^n
    \mathbf{x}_i (\phi(y_i) - \mu(\mathbf{w}; \mathbf{x}_i)). \]
  prefs: []
  type: TYPE_NORMAL
- en: The Hessian of \(A(\mathbf{w}^T \mathbf{x}_i)\), again by the *Chain Rule* and
    our previous formulas, is
  prefs: []
  type: TYPE_NORMAL
- en: \[ A''(\mathbf{w}^T \mathbf{x}_i) \,\mathbf{x}_i \mathbf{x}_i^T = \sigma^2 (\mathbf{w};
    \mathbf{x}_i) \,\mathbf{x}_i \mathbf{x}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma^2(\mathbf{w}; \mathbf{x}_i) = \mathrm{K}_{\phi(Y_i), \phi(Y_i)}
    = \var[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{w}^T \mathbf{x}_i}\). So the Hessian
    of the negative log-likelihood is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{H}_{L_n}(\mathbf{w}) = \sum_{i=1}^n \sigma^2(\mathbf{w}; \mathbf{x}_i)
    \,\mathbf{x}_i \mathbf{x}_i^T \]
  prefs: []
  type: TYPE_NORMAL
- en: which is positive semidefinite (prove it!).
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the negative log-likelihood is convex and the maximum likelihood
    estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation \(\nabla_\mathbf{w}
    L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) = \mathbf{0}\), that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i). \]
  prefs: []
  type: TYPE_NORMAL
- en: We revisit linear and logistic regression next.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Linear regression)** \(\idx{linear regression}\xdi\) Consider
    the case where \(p_\theta\) is a univariate Gaussian with mean \(\theta\) and
    fixed variance \(1\). That is,'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(y) &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{(y
    - \theta)^2}{2}\right)\\ &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{1}{2}[y^2
    - 2 y \theta + \theta^2]\right)\\ &= \frac{1}{\sqrt{2 \pi}} \exp\left(- \frac{y^2}{2}\right)
    \exp\left(\theta y - \frac{\theta^2}{2}\right)\\ &= h(y) \exp\left(\theta \phi(y)
    - A(\theta)\right), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\phi(y) = y\) and \(A(\theta) = \theta^2/2\). We now assume that \(\theta
    = \mathbf{x}^T \mathbf{w}\) to obtain the corresponding generalized linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), recall that the maximum likelihood
    estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{x}_i^T
    \mathbf{w}}\). Here \(\E[\phi(Y_i)] = \E[Y_i] = \mathbf{x}_i^T \mathbf{w}\). So
    the equation reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^T \mathbf{w} = \sum_{i=1}^n \mathbf{x}_i
    y_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: You may not recognize this equation, but we have encountered it before in a
    different form. Let \(A\) be the matrix with row \(i\) equal to \(\mathbf{x}_i\)
    and let \(\mathbf{y}\) be the vector with \(i\)-th entry equal to \(y_i\). Then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^T = A^T A \qquad \text{and} \qquad
    \sum_{i=1}^n \mathbf{x}_i y_i = A^T \mathbf{y} \]
  prefs: []
  type: TYPE_NORMAL
- en: as can be checked entry by entry or by using our previous characterizations
    of matrix-matrix products (in outer-product form) and matrix-vector products (as
    linear combinations of columns). Therefore, the equation above is equivalent to
    \(A^T A \mathbf{w} = A^T \mathbf{y}\) - the normal equations of linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: To make sense of this finding, we look back at the minus log-likelihood
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) &= - \sum_{i=1}^n
    \log p_{\mathbf{x}_i^T \mathbf{w}}(y_i)\\ &= - \sum_{i=1}^n \log \left(\frac{1}{\sqrt{2
    \pi}} \exp\left(- \frac{(y_i - \mathbf{x}_i^T \mathbf{w})^2}{2}\right)\right)\\
    &= - \log (\sqrt{2 \pi}) + \frac{1}{2} \sum_{i=1}^n (y_i - \mathbf{x}_i^T \mathbf{w})^2.
    \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Observe that minimizing this expression over \(\mathbf{w}\) is equivalent to
    solving the least-squares problem as the first term does not depend on \(\mathbf{w}\)
    and the factor of \(1/2\) does not affect the optimum.
  prefs: []
  type: TYPE_NORMAL
- en: While we have rederived the least squares problem from a probabilistic model,
    it should be noted that the Gaussian assumption is not in fact required for linear
    regression to be warranted. Rather, it gives a different perspective on the same
    problem. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Logistic regression)** \(\idx{logistic regression}\xdi\) Consider
    the case where \(p_{\theta}\) is a Bernoulli distribution. That is, for \(y \in
    \{0,1\}\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} p_{\theta}(y) &= h(y) \exp(\theta \,\phi(y) - A(\theta)), \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(h(y) \equiv 1\), \(\phi(y) = y\) and \(A(\theta) = \log(1 + e^\theta)\).
    We assume that \(\theta = \mathbf{x}^T \mathbf{w}\) to obtain the corresponding
    generalized linear model. Given data points \((\mathbf{x}_i,y_i)_{i=1}^n\), the
    maximum likelihood estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\) solves the equation
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i
    \phi(y_i) \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mu(\mathbf{w}; \mathbf{x}_i) = \E[\phi(Y_i)]\) with \(Y_i \sim p_{\mathbf{x}_i^T
    \mathbf{w}}\). Here, by our formula for the gradient of \(A\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \E[\phi(Y_i)] = \E[Y_i] = A'(\mathbf{x}_i^T \mathbf{w}) = \frac{e^{\mathbf{x}_i^T
    \mathbf{w}}}{1 + e^{\mathbf{x}_i^T \mathbf{w}}} = \sigma(\mathbf{x}_i^T \mathbf{w}),
    \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma\) is the sigmoid function. So the equation reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{i=1}^n \mathbf{x}_i \sigma(\mathbf{x}_i^T \mathbf{w}) = \sum_{i=1}^n
    \mathbf{x}_i y_i. \]
  prefs: []
  type: TYPE_NORMAL
- en: The equation in this case cannot be solved explicitly. Instead we can use gradient
    descent, or a variant, to minimize the negative log-likelihood directly. The lattter
    is
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\}) &= - \sum_{i=1}^n
    \log p_{\mathbf{x}_i^T \mathbf{w}}(y_i)\\ &= - \sum_{i=1}^n \log \left(\exp((\mathbf{x}_i^T
    \mathbf{w}) y_i - \log(1 + e^{\mathbf{x}_i^T \mathbf{w}}))\right)\\ &= - \sum_{i=1}^n
    \left[(\mathbf{x}_i^T \mathbf{w}) y_i - \log(1 + e^{\mathbf{x}_i^T \mathbf{w}})\right]\\
    &= - \sum_{i=1}^n \left[y_i \log(e^{\mathbf{x}_i^T \mathbf{w}}) - (y_i + (1-y_i))\log(1
    + e^{\mathbf{x}_i^T \mathbf{w}})\right]\\ &= - \sum_{i=1}^n \left[y_i \log(\sigma(\mathbf{x}_i^T
    \mathbf{w})) + (1-y_i) \log(1 -\sigma(\mathbf{x}_i^T \mathbf{w}))\right]. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing \(L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})\) is equivalent
    to logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: To use gradient descent, we compute
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \nabla_\mathbf{w} L_n(\mathbf{w};\{(\mathbf{x}_i,y_i)_{i=1}^n\})
    &= - \sum_{i=1}^n \mathbf{x}_i (\phi(y_i) - \mu(\mathbf{w}; \mathbf{x}_i))\\ &=
    - \sum_{i=1}^n \mathbf{x}_i (y_i - \sigma(\mathbf{x}_i^T \mathbf{w})). \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This expression is indeed consistent with what we previously derived for logistic
    regression. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Generalized linear models can be extended to handle more complex
    data structures. Ask your favorite AI chatbot to explain what generalized additive
    models (GAMs) are and how they differ from generalized linear models. Also, ask
    about some common applications of GAMs. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following is NOT an example of an exponential family of
    distributions?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Bernoulli
  prefs: []
  type: TYPE_NORMAL
- en: b) Categorical
  prefs: []
  type: TYPE_NORMAL
- en: c) Uniform
  prefs: []
  type: TYPE_NORMAL
- en: d) Multivariate Gaussian
  prefs: []
  type: TYPE_NORMAL
- en: '**2** In the exponential family form \(p_{\boldsymbol{\theta}}(\mathbf{x})
    = h(\mathbf{x}) \exp(\boldsymbol{\theta}^T \boldsymbol{\phi}(\mathbf{x}) - A(\boldsymbol{\theta}))\),
    what does \(A(\boldsymbol{\theta})\) represent?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The sufficient statistic
  prefs: []
  type: TYPE_NORMAL
- en: b) The log-partition function
  prefs: []
  type: TYPE_NORMAL
- en: c) The canonical parameter
  prefs: []
  type: TYPE_NORMAL
- en: d) The base measure
  prefs: []
  type: TYPE_NORMAL
- en: '**3** Given \(n\) independent samples \(X_1, \ldots, X_n\) from a parametric
    family \(p_{\boldsymbol{\theta}^*}\) with unknown \(\boldsymbol{\theta}^* \in
    \Theta\), the maximum likelihood estimator \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}}\)
    is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'a) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max \left\{ \prod_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'b) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\min \left\{ \prod_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'c) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max \left\{ \sum_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\min \left\{ \sum_{i=1}^n
    p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta \right\}\)'
  prefs: []
  type: TYPE_NORMAL
- en: '**4** In a generalized linear model, the maximum likelihood estimator \(\hat{\mathbf{w}}_{\mathrm{MLE}}\)
    solves the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n
    \mathbf{x}_i \phi(y_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\sum_{i=1}^n \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n
    y_i \phi(\mathbf{x}_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(\sum_{i=1}^n \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \phi(y_i)\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(\sum_{i=1}^n \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n y_i\)
  prefs: []
  type: TYPE_NORMAL
- en: '**5** In logistic regression, which distribution is used for the outcome variable?'
  prefs: []
  type: TYPE_NORMAL
- en: a) Normal distribution
  prefs: []
  type: TYPE_NORMAL
- en: b) Poisson distribution
  prefs: []
  type: TYPE_NORMAL
- en: c) Bernoulli distribution
  prefs: []
  type: TYPE_NORMAL
- en: d) Exponential distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: c. Justification: The text provides examples of Bernoulli, categorical,
    and multivariate Gaussian distributions as members of the exponential family.
    The uniform distribution, however, does not fit the exponential family form.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: The text states that \(A(\boldsymbol{\theta})
    = \log Z(\boldsymbol{\theta})\), where \(Z(\boldsymbol{\theta})\) is referred
    to as the partition function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: a. Justification: The text provides the definition of the maximum
    likelihood estimator as \(\hat{\boldsymbol{\theta}}_{\mathrm{MLE}} \in \arg\max
    \left\{ \prod_{i=1}^n p_{\boldsymbol{\theta}}(X_i) : \boldsymbol{\theta} \in \Theta
    \right\}\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: The text derives the equation \(\sum_{i=1}^n
    \mathbf{x}_i \mu(\mathbf{w}; \mathbf{x}_i) = \sum_{i=1}^n \mathbf{x}_i \phi(y_i)\)
    as the one that the maximum likelihood estimator solves in a generalized linear
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: c. Justification: The text describes logistic regression as a
    GLM where the outcome variable is assumed to follow a Bernoulli distribution.'
  prefs: []
  type: TYPE_NORMAL
