- en: Statistical Profiling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计配置
- en: 原文：[https://en.algorithmica.org/hpc/profiling/events/](https://en.algorithmica.org/hpc/profiling/events/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/profiling/events/](https://en.algorithmica.org/hpc/profiling/events/)
- en: '[Instrumentation](../instrumentation) is a rather tedious way of doing profiling,
    especially if you are interested in multiple small sections of the program. And
    even if it can be partially automated by the tooling, it still won’t help you
    gather some fine-grained statistics because of its inherent overhead.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[配置](../instrumentation)是一种相当繁琐的配置方法，尤其是如果你对程序中的多个小部分感兴趣。即使可以通过工具部分自动化，它仍然无法帮助你收集一些细粒度的统计数据，因为它固有的开销。'
- en: Another, less invasive approach to profiling is to interrupt the execution of
    a program at random intervals and look where the instruction pointer is. The number
    of times the pointer stopped in each function’s block would be roughly proportional
    to the total time spent executing these functions. You can also get some other
    useful information this way, like finding out which functions are called by which
    functions by inspecting [the call stack](/hpc/architecture/functions).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种对程序进行配置的较少侵入性方法是随机地在程序执行过程中中断其执行，并查看指令指针的位置。指针在每个函数块中停止的次数将与执行这些函数所花费的总时间大致成比例。通过这种方式，你还可以获取一些其他有用的信息，例如通过检查[调用栈](/hpc/architecture/functions)来找出哪些函数被哪些函数调用。
- en: This could, in principle, be done by just running a program with `gdb` and `ctrl+c`‘ing
    it at random intervals but modern CPUs and operating systems provide special utilities
    for this type of profiling.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这原则上可以通过仅用 `gdb` 和 `ctrl+c` 在随机间隔停止程序来完成，但现代CPU和操作系统提供了用于此类配置的特殊实用程序。
- en: '### [#](https://en.algorithmica.org/hpc/profiling/events/#hardware-events)Hardware
    Events'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/profiling/events/#hardware-events)硬件事件'
- en: Hardware *performance counters* are special registers built into microprocessors
    that can store the counts of certain hardware-related activities. They are cheap
    to add on a microchip, as they are basically just binary counters with an activation
    wire connected to them.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件 *性能计数器* 是集成到微处理器中的特殊寄存器，可以存储某些与硬件相关的活动的计数。由于它们基本上只是连接有激活线的二进制计数器，因此它们在微芯片上添加成本低廉。
- en: Each performance counter is connected to a large subset of circuitry and can
    be configured to be incremented on a particular hardware event, such as a branch
    mispredict or a cache miss. You can reset a counter at the start of a program,
    run it, and output its stored value at the end, and it will be equal to the exact
    number of times a certain event has been triggered throughout the execution.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每个性能计数器都连接到电路的一个大子集，并且可以配置为在特定的硬件事件上增加，例如分支预测错误或缓存未命中。你可以在程序开始时重置计数器，运行程序，并在结束时输出其存储的值，它将等于在整个执行过程中触发某个事件的精确次数。
- en: You can also keep track of multiple events by multiplexing between them, that
    is, stopping the program in even intervals and reconfiguring the counters. The
    result in this case will not be exact, but a statistical approximation. One nuance
    here is that its accuracy can’t be improved by simply increasing the sampling
    frequency because it would affect the performance too much and thus skew the distribution,
    so to collect multiple statistics, you would need to run the program for longer
    periods of time.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过在它们之间进行多路复用来跟踪多个事件，也就是说，在偶数间隔停止程序并重新配置计数器。在这种情况下，结果将不会是精确的，而是一个统计近似。这里的一个细微差别是，仅仅通过增加采样频率来提高其准确性是不可行的，因为这会过多地影响性能，从而扭曲分布，因此为了收集多个统计数据，你需要运行程序更长的时间。
- en: Overall, event-driven statistical profiling is usually the most effective and
    easy way to diagnose performance issues.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，事件驱动的统计配置通常是诊断性能问题的最有效和最简单的方法。
- en: '### [#](https://en.algorithmica.org/hpc/profiling/events/#profiling-with-perf)Profiling
    with perf'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/profiling/events/#profiling-with-perf)使用
    perf 进行配置'
- en: Performance analysis tools that rely on the event sampling techniques described
    above are called *statistical profilers*. There are many of them, but the one
    we will mainly use in this book is [perf](https://perf.wiki.kernel.org/), which
    is a statistical profiler shipped with the Linux kernel. On non-Linux systems,
    you can use [VTune](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html#gs.cuc0ks)
    from Intel, which provides roughly the same functionality for our purposes. It
    is available for free, although it is proprietary, and you need to refresh your
    community license every 90 days, while perf is free as in freedom.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于上述描述的事件采样技术的性能分析工具被称为 *统计分析器*。有很多这样的工具，但在这本书中我们将主要使用的是 [perf](https://perf.wiki.kernel.org/)，它是随
    Linux 内核一起提供的统计分析器。在非 Linux 系统上，您可以使用英特尔提供的 [VTune](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html#gs.cuc0ks)，它为我们提供了类似的功能。虽然它是专有软件，但可以免费使用，并且您需要每
    90 天更新一次社区许可证，而 perf 则是自由免费的。
- en: Perf is a command-line application that generates reports based on the live
    execution of programs. It does not need the source and can profile a very wide
    range of applications, even those that involve multiple processes and interaction
    with the operating system.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Perf 是一个基于命令行的应用程序，它根据程序的实时执行生成报告。它不需要源代码，并且可以分析非常广泛的应用程序，包括涉及多个进程和与操作系统交互的应用程序。
- en: 'For explanation purposes, I have written a small program that creates an array
    of a million random integers, sorts it, and then does a million binary searches
    on it:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释的目的，我编写了一个小程序，它创建了一个包含一百万个随机整数的数组，对其进行排序，然后在上面执行一百万次二分查找：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After compiling it (`g++ -O3 -march=native example.cc -o run`), we can run
    it with `perf stat ./run`, which outputs the counts of basic performance events
    during its execution:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 编译完成后（`g++ -O3 -march=native example.cc -o run`），我们可以使用 `perf stat ./run` 来运行它，该命令会在执行过程中输出基本性能事件的计数：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can see that the execution took 0.53 seconds or 852M cycles at an effective
    1.32 GHz clock rate, over which 479M instructions were executed. There were also
    122.7M branches, and 15.7% of them were mispredicted.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，执行耗时 0.53 秒或 852M 个周期，在有效 1.32 GHz 的时钟频率下，执行了 479M 条指令。还有 122.7M 条分支，其中
    15.7% 被误判。
- en: 'You can get a list of all supported events with `perf list`, and then specify
    a list of specific events you want with the `-e` option. For example, for diagnosing
    binary search, we mostly care about cache misses:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `perf list` 获取所有支持的事件列表，然后使用 `-e` 选项指定您想要的事件列表。例如，为了诊断二分查找，我们主要关心缓存未命中：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By itself, `perf stat` simply sets up performance counters for the whole program.
    It can tell you the total number of branch mispredictions, but it won’t tell you
    *where* they are happening, let alone *why* they are happening.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 单独的 `perf stat` 只是为整个程序设置性能计数器。它可以告诉你分支误判的总数，但不会告诉你它们发生在哪里，更不用说为什么会发生。
- en: To try the stop-the-world approach we discussed previously, we need to use `perf
    record <cmd>`, which records profiling data and dumps it as a `perf.data` file,
    and then call `perf report` to inspect it. I highly advise you to go and try it
    yourselves because the last command is interactive and colorful, but for those
    that can’t do it right now, I’ll try to describe it the best I can.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试我们之前讨论的停止世界方法，我们需要使用 `perf record <cmd>`，它记录分析数据并将其作为 `perf.data` 文件导出，然后调用
    `perf report` 来检查它。我强烈建议您亲自尝试，因为最后一个命令是交互式的，并且具有丰富的色彩，但对于那些现在无法做到的人，我会尽力描述它。
- en: 'When you call `perf report`, it first displays a `top`-like interactive report
    that tells you which functions are taking how much time:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当您调用 `perf report` 时，它首先显示一个类似于 `top` 的交互式报告，告诉您哪些函数花费了多长时间：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note that, for each function, just its *overhead* is listed and not the total
    running time (e.g., `setup` includes `std::__introsort_loop` but only its own
    overhead is accounted as 3.43%). There are tools for constructing [flame graphs](https://www.brendangregg.com/flamegraphs.html)
    out of perf reports to make them more clear. You also need to account for possible
    inlining, which is apparently what happened with `std::lower_bound` here. Perf
    also tracks shared libraries (like `libc`) and, in general, any other spawned
    processes: if you want, you can launch a web browser with perf and see what’s
    happening inside.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于每个函数，只列出了其**开销**，而不是总运行时间（例如，`setup`包括`std::__introsort_loop`，但只计算其自身的开销，为3.43%）。有工具可以将perf报告转换为[火焰图](https://www.brendangregg.com/flamegraphs.html)，使其更清晰。你还需要考虑可能的内联，显然这里发生的就是`std::lower_bound`的内联。Perf还跟踪共享库（如`libc`）以及通常任何其他派生的进程：如果你愿意，可以用perf启动一个网页浏览器，看看里面发生了什么。
- en: 'Next, you can “zoom in” on any of these functions, and, among others things,
    it will offer to show you its disassembly with an associated heatmap. For example,
    here is the assembly for `query`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你可以“放大”查看这些函数中的任何一个，并且除了其他功能之外，它还会提供显示其与相关热图相关的反汇编代码。例如，这里是`query`的反汇编代码：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: On the left column is the fraction of times that the instruction pointer stopped
    on a specific line. You can see that we spend ~65% of the time on the jump instruction
    because it has a comparison operator before it, indicating that the control flow
    waits there for this comparison to be decided.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧列中是指令指针在特定行上停止的频率。你可以看到我们大约65%的时间花在了跳转指令上，因为它前面有一个比较运算符，这表明控制流在这里等待这个比较结果。
- en: Because of intricacies such as [pipelining](/hpc/pipelining) and out-of-order
    execution, “now” is not a well-defined concept in modern CPUs, so the data is
    slightly inaccurate as the instruction pointer drifts a little bit forward. The
    instruction-level data is still useful, but at the individual cycle level, we
    need to switch to [something more precise](../simulation). [← Instrumentation](https://en.algorithmica.org/hpc/profiling/instrumentation/)[Program
    Simulation →](https://en.algorithmica.org/hpc/profiling/simulation/)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于如[流水线](/hpc/pipelining)和乱序执行等复杂性，“现在”在现代CPU中不是一个定义良好的概念，因此数据略有不准确，因为指令指针稍微向前漂移。指令级数据仍然有用，但在单个周期级别，我们需要切换到[更精确的方法](../simulation)。[←
    仪器](https://en.algorithmica.org/hpc/profiling/instrumentation/)[程序模拟 →](https://en.algorithmica.org/hpc/profiling/simulation/)
