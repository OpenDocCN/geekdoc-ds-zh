- en: <title>Ray Tracing in One Weekend</title>
  prefs: []
  type: TYPE_NORMAL
- en: Ray Tracing in One Weekend[Peter Shirley](https://github.com/petershirley),
    [Trevor David Black](https://github.com/trevordblack), [Steve Hollasch](https://github.com/hollasch)Version
    4.0.2, 2025-04-25Copyright 2018-2024 Peter Shirley. All rights reserved.Contents
  prefs: []
  type: TYPE_NORMAL
- en: '[(Top)](#)'
  prefs: []
  type: TYPE_NORMAL
- en: '[1 Overview](#overview)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2 Output an Image](#outputanimage)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2.1 The PPM Image Format](#outputanimage/theppmimageformat)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2.2 Creating an Image File](#outputanimage/creatinganimagefile)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2.3 Adding a Progress Indicator](#outputanimage/addingaprogressindicator)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3 The vec3 Class](#thevec3class)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3.1 Color Utility Functions](#thevec3class/colorutilityfunctions)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4 Rays, a Simple Camera, and Background](#rays,asimplecamera,andbackground)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4.1 The ray Class](#rays,asimplecamera,andbackground/therayclass)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4.2 Sending Rays Into the Scene](#rays,asimplecamera,andbackground/sendingraysintothescene)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5 Adding a Sphere](#addingasphere)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5.1 Ray-Sphere Intersection](#addingasphere/ray-sphereintersection)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5.2 Creating Our First Raytraced Image](#addingasphere/creatingourfirstraytracedimage)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6 Surface Normals and Multiple Objects](#surfacenormalsandmultipleobjects)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.1 Shading with Surface Normals](#surfacenormalsandmultipleobjects/shadingwithsurfacenormals)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.2 Simplifying the Ray-Sphere Intersection Code](#surfacenormalsandmultipleobjects/simplifyingtheray-sphereintersectioncode)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.3 An Abstraction for Hittable Objects](#surfacenormalsandmultipleobjects/anabstractionforhittableobjects)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.4 Front Faces Versus Back Faces](#surfacenormalsandmultipleobjects/frontfacesversusbackfaces)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.5 A List of Hittable Objects](#surfacenormalsandmultipleobjects/alistofhittableobjects)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.6 Some New C++ Features](#surfacenormalsandmultipleobjects/somenewc++features)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.7 Common Constants and Utility Functions](#surfacenormalsandmultipleobjects/commonconstantsandutilityfunctions)'
  prefs: []
  type: TYPE_NORMAL
- en: '[6.8 An Interval Class](#surfacenormalsandmultipleobjects/anintervalclass)'
  prefs: []
  type: TYPE_NORMAL
- en: '[7 Moving Camera Code Into Its Own Class](#movingcameracodeintoitsownclass)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8 Antialiasing](#antialiasing)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8.1 Some Random Number Utilities](#antialiasing/somerandomnumberutilities)'
  prefs: []
  type: TYPE_NORMAL
- en: '[8.2 Generating Pixels with Multiple Samples](#antialiasing/generatingpixelswithmultiplesamples)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9 Diffuse Materials](#diffusematerials)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9.1 A Simple Diffuse Material](#diffusematerials/asimplediffusematerial)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9.2 Limiting the Number of Child Rays](#diffusematerials/limitingthenumberofchildrays)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9.3 Fixing Shadow Acne](#diffusematerials/fixingshadowacne)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9.4 True Lambertian Reflection](#diffusematerials/truelambertianreflection)'
  prefs: []
  type: TYPE_NORMAL
- en: '[9.5 Using Gamma Correction for Accurate Color Intensity](#diffusematerials/usinggammacorrectionforaccuratecolorintensity)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10 Metal](#metal)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.1 An Abstract Class for Materials](#metal/anabstractclassformaterials)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.2 A Data Structure to Describe Ray-Object Intersections](#metal/adatastructuretodescriberay-objectintersections)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.3 Modeling Light Scatter and Reflectance](#metal/modelinglightscatterandreflectance)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.4 Mirrored Light Reflection](#metal/mirroredlightreflection)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.5 A Scene with Metal Spheres](#metal/ascenewithmetalspheres)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10.6 Fuzzy Reflection](#metal/fuzzyreflection)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11 Dielectrics](#dielectrics)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11.1 Refraction](#dielectrics/refraction)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11.2 Snell''s Law](#dielectrics/snell''slaw)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11.3 Total Internal Reflection](#dielectrics/totalinternalreflection)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11.4 Schlick Approximation](#dielectrics/schlickapproximation)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11.5 Modeling a Hollow Glass Sphere](#dielectrics/modelingahollowglasssphere)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12 Positionable Camera](#positionablecamera)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12.1 Camera Viewing Geometry](#positionablecamera/cameraviewinggeometry)'
  prefs: []
  type: TYPE_NORMAL
- en: '[12.2 Positioning and Orienting the Camera](#positionablecamera/positioningandorientingthecamera)'
  prefs: []
  type: TYPE_NORMAL
- en: '[13 Defocus Blur](#defocusblur)'
  prefs: []
  type: TYPE_NORMAL
- en: '[13.1 A Thin Lens Approximation](#defocusblur/athinlensapproximation)'
  prefs: []
  type: TYPE_NORMAL
- en: '[13.2 Generating Sample Rays](#defocusblur/generatingsamplerays)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14 Where Next?](#wherenext?)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14.1 A Final Render](#wherenext?/afinalrender)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14.2 Next Steps](#wherenext?/nextsteps)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14.2.1 Book 2: *Ray Tracing: The Next Week*](#wherenext?/nextsteps/book2:raytracing:thenextweek)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14.2.2 Book 3: *Ray Tracing: The Rest of Your Life*](#wherenext?/nextsteps/book3:raytracing:therestofyourlife)'
  prefs: []
  type: TYPE_NORMAL
- en: '[14.2.3 Other Directions](#wherenext?/nextsteps/otherdirections)'
  prefs: []
  type: TYPE_NORMAL
- en: '[15 Acknowledgments](#acknowledgments)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16 Citing This Book](#citingthisbook)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.1 Basic Data](#citingthisbook/basicdata)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2 Snippets](#citingthisbook/snippets)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.1 Markdown](#citingthisbook/snippets/markdown)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.2 HTML](#citingthisbook/snippets/html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.3 LaTeX and BibTex](#citingthisbook/snippets/latexandbibtex)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.4 BibLaTeX](#citingthisbook/snippets/biblatex)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.5 IEEE](#citingthisbook/snippets/ieee)'
  prefs: []
  type: TYPE_NORMAL
- en: '[16.2.6 MLA:](#citingthisbook/snippets/mla:)'
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I’ve taught many graphics classes over the years. Often I do them in ray tracing,
    because you are forced to write all the code, but you can still get cool images
    with no API. I decided to adapt my course notes into a how-to, to get you to a
    cool program as quickly as possible. It will not be a full-featured ray tracer,
    but it does have the indirect lighting which has made ray tracing a staple in
    movies. Follow these steps, and the architecture of the ray tracer you produce
    will be good for extending to a more extensive ray tracer if you get excited and
    want to pursue that.
  prefs: []
  type: TYPE_NORMAL
- en: When somebody says “ray tracing” it could mean many things. What I am going
    to describe is technically a path tracer, and a fairly general one. While the
    code will be pretty simple (let the computer do the work!) I think you’ll be very
    happy with the images you can make.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll take you through writing a ray tracer in the order I do it, along with
    some debugging tips. By the end, you will have a ray tracer that produces some
    great images. You should be able to do this in a weekend. If you take longer,
    don’t worry about it. I use C++ as the driving language, but you don’t need to.
    However, I suggest you do, because it’s fast, portable, and most production movie
    and video game renderers are written in C++. Note that I avoid most “modern features”
    of C++, but inheritance and operator overloading are too useful for ray tracers
    to pass on.
  prefs: []
  type: TYPE_NORMAL
- en: I do not provide the code online, but the code is real and I show all of it
    except for a few straightforward operators in the `vec3` class. I am a big believer
    in typing in code to learn it, but when code is available I use it, so I only
    practice what I preach when the code is not available. So don’t ask!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I have left that last part in because it is funny what a 180 I have done. Several
    readers ended up with subtle errors that were helped when we compared code. So
    please do type in the code, but you can find the finished source for each book
    in the [RayTracing project on GitHub](https://github.com/RayTracing/raytracing.github.io/).
  prefs: []
  type: TYPE_NORMAL
- en: 'A note on the implementing code for these books — our philosophy for the included
    code prioritizes the following goals:'
  prefs: []
  type: TYPE_NORMAL
- en: The code should implement the concepts covered in the books.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use C++, but as simple as possible. Our programming style is very C-like,
    but we take advantage of modern features where it makes the code easier to use
    or understand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our coding style continues the style established from the original books as
    much as possible, for continuity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Line length is kept to 96 characters per line, to keep lines consistent between
    the codebase and code listings in the books.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code thus provides a baseline implementation, with tons of improvements
    left for the reader to enjoy. There are endless ways one can optimize and modernize
    the code; we prioritize the simple solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We assume a little bit of familiarity with vectors (like dot product and vector
    addition). If you don’t know that, do a little review. If you need that review,
    or to learn it for the first time, check out the online [*Graphics Codex*](https://graphicscodex.com/)
    by Morgan McGuire, *Fundamentals of Computer Graphics* by Steve Marschner and
    Peter Shirley, or *Computer Graphics: Principles and Practice* by J.D. Foley and
    Andy Van Dam.'
  prefs: []
  type: TYPE_NORMAL
- en: See the [project README](../README.md) file for information about this project,
    the repository on GitHub, directory structure, building & running, and how to
    make or reference corrections and contributions.
  prefs: []
  type: TYPE_NORMAL
- en: See [our Further Reading wiki page](https://github.com/RayTracing/raytracing.github.io/wiki/Further-Readings)
    for additional project related resources.
  prefs: []
  type: TYPE_NORMAL
- en: These books have been formatted to print well directly from your browser. We
    also include PDFs of each book [with each release](https://github.com/RayTracing/raytracing.github.io/releases/),
    in the “Assets” section.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to communicate with us, feel free to send us an email at:'
  prefs: []
  type: TYPE_NORMAL
- en: Peter Shirley, [ptrshrl@gmail.com](mailto:ptrshrl@gmail.com)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steve Hollasch, [steve@hollasch.net](mailto:steve@hollasch.net)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trevor David Black, [trevordblack@trevord.black](mailto:trevordblack@trevord.black)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, if you run into problems with your implementation, have general questions,
    or would like to share your own ideas or work, see [the GitHub Discussions forum](https://github.com/RayTracing/raytracing.github.io/discussions/)
    on the GitHub project.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to everyone who lent a hand on this project. You can find them in the
    [acknowledgments](#acknowledgments) section at the end of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get on with it!
  prefs: []
  type: TYPE_NORMAL
- en: Output an Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The PPM Image Format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Whenever you start a renderer, you need a way to see an image. The most straightforward
    way is to write it to a file. The catch is, there are so many formats. Many of
    those are complex. I always start with a plain text ppm file. Here’s a nice description
    from Wikipedia:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.01-ppm.jpg)](https://raytracing.github.io/images/fig-1.01-ppm.jpg)**Figure 1:**
    PPM ExampleLet’s make some C++ code to output such a thing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 1:** `[main.cc]` Creating your first image'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some things to note in this code:'
  prefs: []
  type: TYPE_NORMAL
- en: The pixels are written out in rows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Every row of pixels is written out left to right.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These rows are written out from top to bottom.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By convention, each of the red/green/blue components are represented internally
    by real-valued variables that range from 0.0 to 1.0\. These must be scaled to
    integer values between 0 and 255 before we print them out.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Red goes from fully off (black) to fully on (bright red) from left to right,
    and green goes from fully off at the top (black) to fully on at the bottom (bright
    green). Adding red and green light together make yellow so we should expect the
    bottom right corner to be yellow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating an Image File
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because the file is written to the standard output stream, you'll need to redirect
    it to an image file. Typically this is done from the command-line by using the
    `>` redirection operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'On Windows, you''d get the debug build from CMake running this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then run your newly-built program like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Later, it will be better to run optimized builds for speed. In that case, you
    would build like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'and would run the optimized program like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The examples above assume that you are building with CMake, using the same approach
    as the `CMakeLists.txt` file in the included source. Use whatever build environment
    (and language) you're most comfortable with.
  prefs: []
  type: TYPE_NORMAL
- en: 'On Mac or Linux, release build, you would launch the program like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Complete building and running instructions can be found in the [project README](../README.md).
  prefs: []
  type: TYPE_NORMAL
- en: 'Opening the output file (in `ToyViewer` on my Mac, but try it in your favorite
    image viewer and Google “ppm viewer” if your viewer doesn’t support it) shows
    this result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/img-1.01-first-ppm-image.png)](https://raytracing.github.io/images/img-1.01-first-ppm-image.png)Image
    1: First PPM image'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hooray! This is the graphics “hello world”. If your image doesn’t look like
    that, open the output file in a text editor and see what it looks like. It should
    start something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 2:** First image output'
  prefs: []
  type: TYPE_NORMAL
- en: If your PPM file doesn't look like this, then double-check your formatting code.
    If it *does* look like this but fails to render, then you may have line-ending
    differences or something similar that is confusing your image viewer. To help
    debug this, you can find a file `test.ppm` in the `images` directory of the Github
    project. This should help to ensure that your viewer can handle the PPM format
    and to use as a comparison against your generated PPM file.
  prefs: []
  type: TYPE_NORMAL
- en: Some readers have reported problems viewing their generated files on Windows.
    In this case, the problem is often that the PPM is written out as UTF-16, often
    from PowerShell. If you run into this problem, see [Discussion 1114](https://github.com/RayTracing/raytracing.github.io/discussions/1114)
    for help with this issue.
  prefs: []
  type: TYPE_NORMAL
- en: If everything displays correctly, then you're pretty much done with system and
    IDE issues — everything in the remainder of this series uses this same simple
    mechanism for generated rendered images.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to produce other image formats, I am a fan of `stb_image.h`, a header-only
    image library available on GitHub at [https://github.com/nothings/stb](https://github.com/nothings/stb).
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Progress Indicator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we continue, let's add a progress indicator to our output. This is a
    handy way to track the progress of a long render, and also to possibly identify
    a run that's stalled out due to an infinite loop or other problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our program outputs the image to the standard output stream (`std::cout`),
    so leave that alone and instead write to the logging output stream (`std::clog`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 3:** `[main.cc]` Main render loop with progress reporting'
  prefs: []
  type: TYPE_NORMAL
- en: Now when running, you'll see a running count of the number of scanlines remaining.
    Hopefully this runs so fast that you don't even see it! Don't worry — you'll have
    lots of time in the future to watch a slowly updating progress line as we expand
    our ray tracer.
  prefs: []
  type: TYPE_NORMAL
- en: The vec3 Class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Almost all graphics programs have some class(es) for storing geometric vectors
    and colors. In many systems these vectors are 4D (3D position plus a homogeneous
    coordinate for geometry, or RGB plus an alpha transparency component for colors).
    For our purposes, three coordinates suffice. We’ll use the same class `vec3` for
    colors, locations, directions, offsets, whatever. Some people don’t like this
    because it doesn’t prevent you from doing something silly, like subtracting a
    position from a color. They have a good point, but we’re going to always take
    the “less code” route when not obviously wrong. In spite of this, we do declare
    two aliases for `vec3`: `point3` and `color`. Since these two types are just aliases
    for `vec3`, you won''t get warnings if you pass a `color` to a function expecting
    a `point3`, and nothing is stopping you from adding a `point3` to a `color`, but
    it makes the code a little bit easier to read and to understand.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the `vec3` class in the top half of a new `vec3.h` header file, and
    define a set of useful vector utility functions in the bottom half:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 4:** `[vec3.h]` vec3 definitions and helper functions'
  prefs: []
  type: TYPE_NORMAL
- en: We use `double` here, but some ray tracers use `float`. `double` has greater
    precision and range, but is twice the size compared to `float`. This increase
    in size may be important if you're programming in limited memory conditions (such
    as hardware shaders). Either one is fine — follow your own tastes.
  prefs: []
  type: TYPE_NORMAL
- en: Color Utility Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using our new `vec3` class, we'll create a new `color.h` header file and define
    a utility function that writes a single pixel's color out to the standard output
    stream.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 5:** `[color.h]` color utility functionsNow we can change our main
    to use both of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 6:** `[main.cc]` Final code for the first PPM image'
  prefs: []
  type: TYPE_NORMAL
- en: And you should get the exact same picture as before.
  prefs: []
  type: TYPE_NORMAL
- en: Rays, a Simple Camera, and Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ray Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The one thing that all ray tracers have is a ray class and a computation of
    what color is seen along a ray. Let’s think of a ray as a function <nobr aria-hidden="true">P(t)=A+tb</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo
    stretchy="false">)</mo><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">A</mi></mrow><mo>+</mo><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow>. Here <nobr aria-hidden="true">P</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow> is a 3D position
    along a line in 3D. <nobr aria-hidden="true">A</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">A</mi></mrow> is the ray origin and <nobr aria-hidden="true">b</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow> is the ray direction.
    The ray parameter <nobr aria-hidden="true">t</nobr><mi>t</mi> is a real number
    (`double` in the code). Plug in a different <nobr aria-hidden="true">t</nobr><mi>t</mi>
    and <nobr aria-hidden="true">P(t)</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo
    stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo> moves the point along
    the ray. Add in negative <nobr aria-hidden="true">t</nobr><mi>t</mi> values and
    you can go anywhere on the 3D line. For positive <nobr aria-hidden="true">t</nobr><mi>t</mi>,
    you get only the parts in front of <nobr aria-hidden="true">A</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">A</mi></mrow>, and this is what is often called a half-line
    or a ray.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.02-lerp.jpg)](https://raytracing.github.io/images/fig-1.02-lerp.jpg)**Figure 2:**
    Linear interpolationWe can represent the idea of a ray as a class, and represent
    the function <nobr aria-hidden="true">P(t)</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo>
    as a function that we''ll call `ray::at(t)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 7:** `[ray.h]` The ray class'
  prefs: []
  type: TYPE_NORMAL
- en: (For those unfamiliar with C++, the functions `ray::origin()` and `ray::direction()`
    both return an immutable reference to their members. Callers can either just use
    the reference directly, or make a mutable copy depending on their needs.)
  prefs: []
  type: TYPE_NORMAL
- en: Sending Rays Into the Scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we are ready to turn the corner and make a ray tracer. At its core, a ray
    tracer sends rays through pixels and computes the color seen in the direction
    of those rays. The involved steps are
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the ray from the “eye” through the pixel,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine which objects the ray intersects, and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute a color for the closest intersection point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When first developing a ray tracer, I always do a simple camera for getting
    the code up and running.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve often gotten into trouble using square images for debugging because I transpose
    <nobr aria-hidden="true">x</nobr><mi>x</mi> and <nobr aria-hidden="true">y</nobr><mi>y</mi>
    too often, so we’ll use a non-square image. A square image has a 1∶1 aspect ratio,
    because its width is the same as its height. Since we want a non-square image,
    we'll choose 16∶9 because it's so common. A 16∶9 aspect ratio means that the ratio
    of image width to image height is 16∶9\. Put another way, given an image with
    a 16∶9 aspect ratio,
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">width/height=16/9=1.7778</nobr><mtext>width</mtext><mrow
    class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mtext>height</mtext><mo>=</mo><mn>16</mn><mrow
    class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>9</mn><mo>=</mo><mn>1.7778</mn>
  prefs: []
  type: TYPE_NORMAL
- en: For a practical example, an image 800 pixels wide by 400 pixels high has a 2∶1
    aspect ratio.
  prefs: []
  type: TYPE_NORMAL
- en: The image's aspect ratio can be determined from the ratio of its width to its
    height. However, since we have a given aspect ratio in mind, it's easier to set
    the image's width and the aspect ratio, and then using this to calculate for its
    height. This way, we can scale up or down the image by changing the image width,
    and it won't throw off our desired aspect ratio. We do have to make sure that
    when we solve for the image height the resulting height is at least 1.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to setting up the pixel dimensions for the rendered image, we also
    need to set up a virtual *viewport* through which to pass our scene rays. The
    viewport is a virtual rectangle in the 3D world that contains the grid of image
    pixel locations. If pixels are spaced the same distance horizontally as they are
    vertically, the viewport that bounds them will have the same aspect ratio as the
    rendered image. The distance between two adjacent pixels is called the pixel spacing,
    and square pixels is the standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start things off, we''ll choose an arbitrary viewport height of 2.0, and
    scale the viewport width to give us the desired aspect ratio. Here''s a snippet
    of what this code will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 8:** Rendered image setup'
  prefs: []
  type: TYPE_NORMAL
- en: If you're wondering why we don't just use `aspect_ratio` when computing `viewport_width`,
    it's because the value set to `aspect_ratio` is the ideal ratio, it may not be
    the *actual* ratio between `image_width` and `image_height`. If `image_height`
    was allowed to be real valued—rather than just an integer—then it would be fine
    to use `aspect_ratio`. But the *actual* ratio between `image_width` and `image_height`
    can vary based on two parts of the code. First, `image_height` is rounded down
    to the nearest integer, which can increase the ratio. Second, we don't allow `image_height`
    to be less than one, which can also change the actual aspect ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `aspect_ratio` is an ideal ratio, which we approximate as best as
    possible with the integer-based ratio of image width over image height. In order
    for our viewport proportions to exactly match our image proportions, we use the
    calculated image aspect ratio to determine our final viewport width.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we will define the camera center: a point in 3D space from which all scene
    rays will originate (this is also commonly referred to as the *eye point*). The
    vector from the camera center to the viewport center will be orthogonal to the
    viewport. We''ll initially set the distance between the viewport and the camera
    center point to be one unit. This distance is often referred to as the *focal
    length*.'
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity we'll start with the camera center at <nobr aria-hidden="true">(0,0,0)</nobr><mo
    stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo>.
    We'll also have the y-axis go up, the x-axis to the right, and the negative z-axis
    pointing in the viewing direction. (This is commonly referred to as *right-handed
    coordinates*.)
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.03-cam-geom.jpg)](https://raytracing.github.io/images/fig-1.03-cam-geom.jpg)**Figure 3:**
    Camera geometry'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now the inevitable tricky part. While our 3D space has the conventions above,
    this conflicts with our image coordinates, where we want to have the zeroth pixel
    in the top-left and work our way down to the last pixel at the bottom right. This
    means that our image coordinate Y-axis is inverted: Y increases going down the
    image.'
  prefs: []
  type: TYPE_NORMAL
- en: As we scan our image, we will start at the upper left pixel (pixel <nobr aria-hidden="true">0,0</nobr><mn>0</mn><mo>,</mo><mn>0</mn>),
    scan left-to-right across each row, and then scan row-by-row, top-to-bottom. To
    help navigate the pixel grid, we'll use a vector from the left edge to the right
    edge (<nobr aria-hidden="true">Vu</nobr><mrow class="MJX-TeXAtom-ORD"><msub><mi
    mathvariant="bold">V</mi><mi mathvariant="bold">u</mi></msub></mrow>), and a vector
    from the upper edge to the lower edge (<nobr aria-hidden="true">Vv</nobr><mrow
    class="MJX-TeXAtom-ORD"><msub><mi mathvariant="bold">V</mi><mi mathvariant="bold">v</mi></msub></mrow>).
  prefs: []
  type: TYPE_NORMAL
- en: 'Our pixel grid will be inset from the viewport edges by half the pixel-to-pixel
    distance. This way, our viewport area is evenly divided into width × height identical
    regions. Here''s what our viewport and pixel grid look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.04-pixel-grid.jpg)](https://raytracing.github.io/images/fig-1.04-pixel-grid.jpg)**Figure 4:**
    Viewport and pixel grid'
  prefs: []
  type: TYPE_NORMAL
- en: In this figure, we have the viewport, the pixel grid for a 7×5 resolution image,
    the viewport upper left corner <nobr aria-hidden="true">Q</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow>, the pixel <nobr aria-hidden="true">P0,0</nobr><mrow
    class="MJX-TeXAtom-ORD"><msub><mi mathvariant="bold">P</mi><mrow class="MJX-TeXAtom-ORD"><mn
    mathvariant="bold">0</mn><mo mathvariant="bold">,</mo><mn mathvariant="bold">0</mn></mrow></msub></mrow>
    location, the viewport vector <nobr aria-hidden="true">Vu</nobr><mrow class="MJX-TeXAtom-ORD"><msub><mi
    mathvariant="bold">V</mi><mi mathvariant="bold">u</mi></msub></mrow> (`viewport_u`),
    the viewport vector <nobr aria-hidden="true">Vv</nobr><mrow class="MJX-TeXAtom-ORD"><msub><mi
    mathvariant="bold">V</mi><mi mathvariant="bold">v</mi></msub></mrow> (`viewport_v`),
    and the pixel delta vectors <nobr aria-hidden="true">Δu</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Δ</mi><mi mathvariant="bold">u</mi></mrow> and <nobr aria-hidden="true">Δv</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Δ</mi><mi mathvariant="bold">v</mi></mrow>.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing from all of this, here's the code that implements the camera. We'll
    stub in a function `ray_color(const ray& r)` that returns the color for a given
    scene ray — which we'll set to always return black for now.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 9:** `[main.cc]` Creating scene rays'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in the code above, I didn't make `ray_direction` a unit vector,
    because I think not doing that makes for simpler and slightly faster code.
  prefs: []
  type: TYPE_NORMAL
- en: Now we'll fill in the `ray_color(ray)` function to implement a simple gradient.
    This function will linearly blend white and blue depending on the height of the
    <nobr aria-hidden="true">y</nobr><mi>y</mi> coordinate *after* scaling the ray
    direction to unit length (so <nobr aria-hidden="true">−1.0<y<1.0</nobr><mo>−</mo><mn>1.0</mn><mo><</mo><mi>y</mi><mo><</mo><mn>1.0</mn>).
    Because we're looking at the <nobr aria-hidden="true">y</nobr><mi>y</mi> height
    after normalizing the vector, you'll notice a horizontal gradient to the color
    in addition to the vertical gradient.
  prefs: []
  type: TYPE_NORMAL
- en: I'll use a standard graphics trick to linearly scale <nobr aria-hidden="true">0.0≤a≤1.0</nobr><mn>0.0</mn><mo>≤</mo><mi>a</mi><mo>≤</mo><mn>1.0</mn>.
    When <nobr aria-hidden="true">a=1.0</nobr><mi>a</mi><mo>=</mo><mn>1.0</mn>, I
    want blue. When <nobr aria-hidden="true">a=0.0</nobr><mi>a</mi><mo>=</mo><mn>0.0</mn>,
    I want white. In between, I want a blend. This forms a “linear blend”, or “linear
    interpolation”. This is commonly referred to as a *lerp* between two values. A
    lerp is always of the form
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">blendedValue=(1−a)⋅startValue+a⋅endValue,</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">b</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">l</mi><mi class="MJX-tex-mathit" mathvariant="italic">e</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">n</mi><mi class="MJX-tex-mathit" mathvariant="italic">d</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi><mi class="MJX-tex-mathit" mathvariant="italic">d</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">V</mi><mi class="MJX-tex-mathit" mathvariant="italic">a</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">l</mi><mi class="MJX-tex-mathit" mathvariant="italic">u</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi></mrow><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>a</mi><mo
    stretchy="false">)</mo><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit"
    mathvariant="italic">s</mi><mi class="MJX-tex-mathit" mathvariant="italic">t</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi><mi class="MJX-tex-mathit" mathvariant="italic">r</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">t</mi><mi class="MJX-tex-mathit" mathvariant="italic">V</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi><mi class="MJX-tex-mathit" mathvariant="italic">l</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">u</mi><mi class="MJX-tex-mathit" mathvariant="italic">e</mi></mrow><mo>+</mo><mi>a</mi><mo>⋅</mo><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">e</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">n</mi><mi class="MJX-tex-mathit" mathvariant="italic">d</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">V</mi><mi class="MJX-tex-mathit" mathvariant="italic">a</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">l</mi><mi class="MJX-tex-mathit" mathvariant="italic">u</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi></mrow><mo>,</mo>
  prefs: []
  type: TYPE_NORMAL
- en: with <nobr aria-hidden="true">a</nobr><mi>a</mi> going from zero to one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting all this together, here''s what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 10:** `[main.cc]` Rendering a blue-to-white gradientIn our case this
    produces:[![](https://raytracing.github.io/images/img-1.02-blue-to-white.png)](https://raytracing.github.io/images/img-1.02-blue-to-white.png)Image
    2: A blue-to-white gradient depending on ray Y coordinate'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Sphere
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s add a single object to our ray tracer. People often use spheres in ray
    tracers because calculating whether a ray hits a sphere is relatively simple.
  prefs: []
  type: TYPE_NORMAL
- en: Ray-Sphere Intersection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The equation for a sphere of radius <nobr aria-hidden="true">r</nobr><mi>r</mi>
    that is centered at the origin is an important mathematical equation:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">x2+y2+z2=r2</nobr><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: You can also think of this as saying that if a given point <nobr aria-hidden="true">(x,y,z)</nobr><mo
    stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false">)</mo>
    is on the surface of the sphere, then <nobr aria-hidden="true">x2+y2+z2=r2</nobr><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>.
    If a given point <nobr aria-hidden="true">(x,y,z)</nobr><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo
    stretchy="false">)</mo> is *inside* the sphere, then <nobr aria-hidden="true">x2+y2+z2<r2</nobr><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup><mo><</mo><msup><mi>r</mi><mn>2</mn></msup>,
    and if a given point <nobr aria-hidden="true">(x,y,z)</nobr><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo
    stretchy="false">)</mo> is *outside* the sphere, then <nobr aria-hidden="true">x2+y2+z2>r2</nobr><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup><mo>></mo><msup><mi>r</mi><mn>2</mn></msup>.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to allow the sphere center to be at an arbitrary point <nobr aria-hidden="true">(Cx,Cy,Cz)</nobr><mo
    stretchy="false">(</mo><msub><mi>C</mi><mi>x</mi></msub><mo>,</mo><msub><mi>C</mi><mi>y</mi></msub><mo>,</mo><msub><mi>C</mi><mi>z</mi></msub><mo
    stretchy="false">)</mo>, then the equation becomes a lot less nice:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(Cx−x)2+(Cy−y)2+(Cz−z)2=r2</nobr><mo stretchy="false">(</mo><msub><mi>C</mi><mi>x</mi></msub><mo>−</mo><mi>x</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>y</mi></msub><mo>−</mo><mi>y</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>z</mi></msub><mo>−</mo><mi>z</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: In graphics, you almost always want your formulas to be in terms of vectors
    so that all the <nobr aria-hidden="true">x</nobr><mi>x</mi>/<nobr aria-hidden="true">y</nobr><mi>y</mi>/<nobr
    aria-hidden="true">z</nobr><mi>z</mi> stuff can be simply represented using a
    `vec3` class. You might note that the vector from point <nobr aria-hidden="true">P=(x,y,z)</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo
    stretchy="false">)</mo> to center <nobr aria-hidden="true">C=(Cx,Cy,Cz)</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>=</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>x</mi></msub><mo>,</mo><msub><mi>C</mi><mi>y</mi></msub><mo>,</mo><msub><mi>C</mi><mi>z</mi></msub><mo
    stretchy="false">)</mo> is <nobr aria-hidden="true">(C−P)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo>.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the definition of the dot product:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(C−P)⋅(C−P)=(Cx−x)2+(Cy−y)2+(Cz−z)2</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>x</mi></msub><mo>−</mo><mi>x</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>y</mi></msub><mo>−</mo><mi>y</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi>C</mi><mi>z</mi></msub><mo>−</mo><mi>z</mi><msup><mo
    stretchy="false">)</mo><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we can rewrite the equation of the sphere in vector form as:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(C−P)⋅(C−P)=r2</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'We can read this as “any point <nobr aria-hidden="true">P</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow> that satisfies this equation is on the sphere”.
    We want to know if our ray <nobr aria-hidden="true">P(t)=Q+td</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo>+</mo><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow> ever hits the sphere
    anywhere. If it does hit the sphere, there is some <nobr aria-hidden="true">t</nobr><mi>t</mi>
    for which <nobr aria-hidden="true">P(t)</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo>
    satisfies the sphere equation. So we are looking for any <nobr aria-hidden="true">t</nobr><mi>t</mi>
    where this is true:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(C−P(t))⋅(C−P(t))=r2</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo
    stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'which can be found by replacing <nobr aria-hidden="true">P(t)</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo>
    with its expanded form:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(C−(Q+td))⋅(C−(Q+td))=r2</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo>+</mo><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow><mo>+</mo><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three vectors on the left dotted by three vectors on the right. If
    we solved for the full dot product we would get nine vectors. You can definitely
    go through and write everything out, but we don''t need to work that hard. If
    you remember, we want to solve for <nobr aria-hidden="true">t</nobr><mi>t</mi>,
    so we''ll separate the terms based on whether there is a <nobr aria-hidden="true">t</nobr><mi>t</mi>
    or not:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">(−td+(C−Q))⋅(−td+(C−Q))=r2</nobr><mo stretchy="false">(</mo><mo>−</mo><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>+</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>⋅</mo><mo
    stretchy="false">(</mo><mo>−</mo><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>+</mo><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><mo
    stretchy="false">)</mo><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'And now we follow the rules of vector algebra to distribute the dot product:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">t2d⋅d−2td⋅(C−Q)+(C−Q)⋅(C−Q)=r2</nobr><msup><mi>t</mi><mn>2</mn></msup><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo>−</mo><mn>2</mn><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>=</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'Move the square of the radius over to the left hand side:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">t2d⋅d−2td⋅(C−Q)+(C−Q)⋅(C−Q)−r2=0</nobr><msup><mi>t</mi><mn>2</mn></msup><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo>−</mo><mn>2</mn><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo
    stretchy="false">)</mo><mo>−</mo><msup><mi>r</mi><mn>2</mn></msup><mo>=</mo><mn>0</mn>
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s hard to make out what exactly this equation is, but the vectors and <nobr
    aria-hidden="true">r</nobr><mi>r</mi> in that equation are all constant and known.
    Furthermore, the only vectors that we have are reduced to scalars by dot product.
    The only unknown is <nobr aria-hidden="true">t</nobr><mi>t</mi>, and we have a
    <nobr aria-hidden="true">t2</nobr><msup><mi>t</mi><mn>2</mn></msup>, which means
    that this equation is quadratic. You can solve for a quadratic equation <nobr
    aria-hidden="true">ax2+bx+c=0</nobr><mi>a</mi><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mi>b</mi><mi>x</mi><mo>+</mo><mi>c</mi><mo>=</mo><mn>0</mn>
    by using the quadratic formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">−b±b2−4ac−−−−−−−√2a</nobr><mfrac><mrow><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></msqrt></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac>
  prefs: []
  type: TYPE_NORMAL
- en: 'So solving for <nobr aria-hidden="true">t</nobr><mi>t</mi> in the ray-sphere
    intersection equation gives us these values for <nobr aria-hidden="true">a</nobr><mi>a</mi>,
    <nobr aria-hidden="true">b</nobr><mi>b</mi>, and <nobr aria-hidden="true">c</nobr><mi>c</mi>:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">a=d⋅d</nobr><mi>a</mi><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">d</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><nobr
    aria-hidden="true">b=−2d⋅(C−Q)</nobr><mi>b</mi><mo>=</mo><mo>−</mo><mn>2</mn><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>⋅</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><nobr aria-hidden="true">c=(C−Q)⋅(C−Q)−r2</nobr><mi>c</mi><mo>=</mo><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><mo>⋅</mo><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><mo>−</mo><msup><mi>r</mi><mn>2</mn></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'Using all of the above you can solve for <nobr aria-hidden="true">t</nobr><mi>t</mi>,
    but there is a square root part that can be either positive (meaning two real
    solutions), negative (meaning no real solutions), or zero (meaning one real solution).
    In graphics, the algebra almost always relates very directly to the geometry.
    What we have is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.05-ray-sphere.jpg)](https://raytracing.github.io/images/fig-1.05-ray-sphere.jpg)**Figure 5:**
    Ray-sphere intersection results'
  prefs: []
  type: TYPE_NORMAL
- en: Creating Our First Raytraced Image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we take that math and hard-code it into our program, we can test our code
    by placing a small sphere at −1 on the z-axis and then coloring red any pixel
    that intersects it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 11:** `[main.cc]` Rendering a red sphereWhat we get is this:[![](https://raytracing.github.io/images/img-1.03-red-sphere.png)](https://raytracing.github.io/images/img-1.03-red-sphere.png)Image
    3: A simple red sphere'
  prefs: []
  type: TYPE_NORMAL
- en: Now this lacks all sorts of things — like shading, reflection rays, and more
    than one object — but we are closer to halfway done than we are to our start!
    One thing to be aware of is that we are testing to see if a ray intersects with
    the sphere by solving the quadratic equation and seeing if a solution exists,
    but solutions with negative values of <nobr aria-hidden="true">t</nobr><mi>t</mi>
    work just fine. If you change your sphere center to <nobr aria-hidden="true">z=+1</nobr><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn>
    you will get exactly the same picture because this solution doesn't distinguish
    between objects *in front of the camera* and objects *behind the camera*. This
    is not a feature! We’ll fix those issues next.
  prefs: []
  type: TYPE_NORMAL
- en: Surface Normals and Multiple Objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shading with Surface Normals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s get ourselves a surface normal so we can shade. This is a vector
    that is perpendicular to the surface at the point of intersection.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a key design decision to make for normal vectors in our code: whether
    normal vectors will have an arbitrary length, or will be normalized to unit length.'
  prefs: []
  type: TYPE_NORMAL
- en: It is tempting to skip the expensive square root operation involved in normalizing
    the vector, in case it's not needed. In practice, however, there are three important
    observations. First, if a unit-length normal vector is *ever* required, then you
    might as well do it up front once, instead of over and over again “just in case”
    for every location where unit-length is required. Second, we *do* require unit-length
    normal vectors in several places. Third, if you require normal vectors to be unit
    length, then you can often efficiently generate that vector with an understanding
    of the specific geometry class, in its constructor, or in the `hit()` function.
    For example, sphere normals can be made unit length simply by dividing by the
    sphere radius, avoiding the square root entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Given all of this, we will adopt the policy that all normal vectors will be
    of unit length.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a sphere, the outward normal is in the direction of the hit point minus
    the center:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.06-sphere-normal.jpg)](https://raytracing.github.io/images/fig-1.06-sphere-normal.jpg)**Figure 6:**
    Sphere surface-normal geometry'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the earth, this means that the vector from the earth’s center to you points
    straight up. Let’s throw that into the code now, and shade it. We don’t have any
    lights or anything yet, so let’s just visualize the normals with a color map.
    A common trick used for visualizing normals (because it’s easy and somewhat intuitive
    to assume <nobr aria-hidden="true">n</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>
    is a unit length vector — so each component is between −1 and 1) is to map each
    component to the interval from 0 to 1, and then map <nobr aria-hidden="true">(x,y,z)</nobr><mo
    stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false">)</mo>
    to <nobr aria-hidden="true">(red,green,blue)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">r</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi><mi class="MJX-tex-mathit" mathvariant="italic">d</mi></mrow><mo>,</mo><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">g</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">r</mi><mi class="MJX-tex-mathit" mathvariant="italic">e</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi><mi class="MJX-tex-mathit" mathvariant="italic">n</mi></mrow><mo>,</mo><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">b</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">l</mi><mi class="MJX-tex-mathit" mathvariant="italic">u</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">e</mi></mrow><mo stretchy="false">)</mo>.
    For the normal, we need the hit point, not just whether we hit or not (which is
    all we''re calculating at the moment). We only have one sphere in the scene, and
    it''s directly in front of the camera, so we won''t worry about negative values
    of <nobr aria-hidden="true">t</nobr><mi>t</mi> yet. We''ll just assume the closest
    hit point (smallest <nobr aria-hidden="true">t</nobr><mi>t</mi>) is the one that
    we want. These changes in the code let us compute and visualize <nobr aria-hidden="true">n</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 12:** `[main.cc]` Rendering surface normals on a sphereAnd that yields
    this picture:[![](https://raytracing.github.io/images/img-1.04-normals-sphere.png)](https://raytracing.github.io/images/img-1.04-normals-sphere.png)Image
    4: A sphere colored according to its normal vectors'
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying the Ray-Sphere Intersection Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s revisit the ray-sphere function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 13:** `[main.cc]` Ray-sphere intersection code (before)'
  prefs: []
  type: TYPE_NORMAL
- en: First, recall that a vector dotted with itself is equal to the squared length
    of that vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, notice how the equation for `b` has a factor of negative two in it.
    Consider what happens to the quadratic equation if <nobr aria-hidden="true">b=−2h</nobr><mi>b</mi><mo>=</mo><mo>−</mo><mn>2</mn><mi>h</mi>:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">−b±b2−4ac−−−−−−−√2a</nobr><mfrac><mrow><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></msqrt></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac><nobr
    aria-hidden="true">=−(−2h)±(−2h)2−4ac−−−−−−−−−−−√2a</nobr><mo>=</mo><mfrac><mrow><mo>−</mo><mo
    stretchy="false">(</mo><mo>−</mo><mn>2</mn><mi>h</mi><mo stretchy="false">)</mo><mo>±</mo><msqrt><mo
    stretchy="false">(</mo><mo>−</mo><mn>2</mn><mi>h</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></msqrt></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac><nobr
    aria-hidden="true">=2h±2h2−ac−−−−−−√2a</nobr><mo>=</mo><mfrac><mrow><mn>2</mn><mi>h</mi><mo>±</mo><mn>2</mn><msqrt><msup><mi>h</mi><mn>2</mn></msup><mo>−</mo><mi>a</mi><mi>c</mi></msqrt></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac><nobr
    aria-hidden="true">=h±h2−ac−−−−−−√a</nobr><mo>=</mo><mfrac><mrow><mi>h</mi><mo>±</mo><msqrt><msup><mi>h</mi><mn>2</mn></msup><mo>−</mo><mi>a</mi><mi>c</mi></msqrt></mrow><mi>a</mi></mfrac>
  prefs: []
  type: TYPE_NORMAL
- en: 'This simplifies nicely, so we''ll use it. So solving for <nobr aria-hidden="true">h</nobr><mi>h</mi>:'
  prefs: []
  type: TYPE_NORMAL
- en: '<nobr aria-hidden="true">b=−2d⋅(C−Q)</nobr><mi>b</mi><mo>=</mo><mo>−</mo><mn>2</mn><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>⋅</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo><nobr aria-hidden="true">b=−2h</nobr><mi>b</mi><mo>=</mo><mo>−</mo><mn>2</mn><mi>h</mi><nobr
    aria-hidden="true">h=b−2=d⋅(C−Q)</nobr><mi>h</mi><mo>=</mo><mfrac><mi>b</mi><mrow><mo>−</mo><mn>2</mn></mrow></mfrac><mo>=</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">d</mi></mrow><mo>⋅</mo><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">C</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">Q</mi></mrow><mo stretchy="false">)</mo>Using these observations,
    we can now simplify the sphere-intersection code to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 14:** `[main.cc]` Ray-sphere intersection code (after)'
  prefs: []
  type: TYPE_NORMAL
- en: An Abstraction for Hittable Objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, how about more than one sphere? While it is tempting to have an array of
    spheres, a very clean solution is to make an “abstract class” for anything a ray
    might hit, and make both a sphere and a list of spheres just something that can
    be hit. What that class should be called is something of a quandary — calling
    it an “object” would be good if not for “object oriented” programming. “Surface”
    is often used, with the weakness being maybe we will want volumes (fog, clouds,
    stuff like that). “hittable” emphasizes the member function that unites them.
    I don’t love any of these, but we'll go with “hittable”.
  prefs: []
  type: TYPE_NORMAL
- en: 'This `hittable` abstract class will have a `hit` function that takes in a ray.
    Most ray tracers have found it convenient to add a valid interval for hits <nobr
    aria-hidden="true">tmin</nobr><msub><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">m</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">i</mi><mi class="MJX-tex-mathit" mathvariant="italic">n</mi></mrow></mrow></msub>
    to <nobr aria-hidden="true">tmax</nobr><msub><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">m</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi><mi class="MJX-tex-mathit" mathvariant="italic">x</mi></mrow></mrow></msub>,
    so the hit only “counts” if <nobr aria-hidden="true">tmin<t<tmax</nobr><msub><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit"
    mathvariant="italic">m</mi><mi class="MJX-tex-mathit" mathvariant="italic">i</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">n</mi></mrow></mrow></msub><mo><</mo><mi>t</mi><mo><</mo><msub><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit"
    mathvariant="italic">m</mi><mi class="MJX-tex-mathit" mathvariant="italic">a</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">x</mi></mrow></mrow></msub>. For the
    initial rays this is positive <nobr aria-hidden="true">t</nobr><mi>t</mi>, but
    as we will see, it can simplify our code to have an interval <nobr aria-hidden="true">tmin</nobr><msub><mi>t</mi><mrow
    class="MJX-TeXAtom-ORD"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit"
    mathvariant="italic">m</mi><mi class="MJX-tex-mathit" mathvariant="italic">i</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">n</mi></mrow></mrow></msub> to <nobr
    aria-hidden="true">tmax</nobr><msub><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mrow
    class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit" mathvariant="italic">m</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi><mi class="MJX-tex-mathit" mathvariant="italic">x</mi></mrow></mrow></msub>.
    One design question is whether to do things like compute the normal if we hit
    something. We might end up hitting something closer as we do our search, and we
    will only need the normal of the closest thing. I will go with the simple solution
    and compute a bundle of stuff I will store in some structure. Here’s the abstract
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 15:** `[hittable.h]` The hittable classAnd here’s the sphere:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 16:** `[sphere.h]` The sphere class'
  prefs: []
  type: TYPE_NORMAL
- en: (Note here that we use the C++ standard function `std::fmax()`, which returns
    the maximum of the two floating-point arguments. Similarly, we will later use
    `std::fmin()`, which returns the minimum of the two floating-point arguments.)
  prefs: []
  type: TYPE_NORMAL
- en: Front Faces Versus Back Faces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second design decision for normals is whether they should always point out.
    At present, the normal found will always be in the direction of the center to
    the intersection point (the normal points out). If the ray intersects the sphere
    from the outside, the normal points against the ray. If the ray intersects the
    sphere from the inside, the normal (which always points out) points with the ray.
    Alternatively, we can have the normal always point against the ray. If the ray
    is outside the sphere, the normal will point outward, but if the ray is inside
    the sphere, the normal will point inward.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.07-normal-sides.jpg)](https://raytracing.github.io/images/fig-1.07-normal-sides.jpg)**Figure 7:**
    Possible directions for sphere surface-normal geometry'
  prefs: []
  type: TYPE_NORMAL
- en: We need to choose one of these possibilities because we will eventually want
    to determine which side of the surface that the ray is coming from. This is important
    for objects that are rendered differently on each side, like the text on a two-sided
    sheet of paper, or for objects that have an inside and an outside, like glass
    balls.
  prefs: []
  type: TYPE_NORMAL
- en: If we decide to have the normals always point out, then we will need to determine
    which side the ray is on when we color it. We can figure this out by comparing
    the ray with the normal. If the ray and the normal face in the same direction,
    the ray is inside the object, if the ray and the normal face in the opposite direction,
    then the ray is outside the object. This can be determined by taking the dot product
    of the two vectors, where if their dot is positive, the ray is inside the sphere.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 17:** Comparing the ray and the normalIf we decide to have the normals
    always point against the ray, we won''t be able to use the dot product to determine
    which side of the surface the ray is on. Instead, we would need to store that
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 18:** Remembering the side of the surface'
  prefs: []
  type: TYPE_NORMAL
- en: We can set things up so that normals always point “outward” from the surface,
    or always point against the incident ray. This decision is determined by whether
    you want to determine the side of the surface at the time of geometry intersection
    or at the time of coloring. In this book we have more material types than we have
    geometry types, so we'll go for less work and put the determination at geometry
    time. This is simply a matter of preference, and you'll see both implementations
    in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: 'We add the `front_face` bool to the `hit_record` class. We''ll also add a function
    to solve this calculation for us: `set_face_normal()`. For convenience we will
    assume that the vector passed to the new `set_face_normal()` function is of unit
    length. We could always normalize the parameter explicitly, but it''s more efficient
    if the geometry code does this, as it''s usually easier when you know more about
    the specific geometry.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 19:** `[hittable.h]` Adding front-face tracking to hit_recordAnd
    then we add the surface side determination to the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 20:** `[sphere.h]` The sphere class with normal determination'
  prefs: []
  type: TYPE_NORMAL
- en: A List of Hittable Objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have a generic object called a `hittable` that the ray can intersect with.
    We now add a class that stores a list of `hittable`s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 21:** `[hittable_list.h]` The hittable_list class'
  prefs: []
  type: TYPE_NORMAL
- en: Some New C++ Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `hittable_list` class code uses some C++ features that may trip you up
    if you''re not normally a C++ programmer: `vector`, `shared_ptr`, and `make_shared`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`shared_ptr<type>` is a pointer to some allocated type, with reference-counting
    semantics. Every time you assign its value to another shared pointer (usually
    with a simple assignment), the reference count is incremented. As shared pointers
    go out of scope (like at the end of a block or function), the reference count
    is decremented. Once the count goes to zero, the object is safely deleted.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, a shared pointer is first initialized with a newly-allocated object,
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 22:** An example allocation using shared_ptr'
  prefs: []
  type: TYPE_NORMAL
- en: '`make_shared<thing>(thing_constructor_params ...)` allocates a new instance
    of type `thing`, using the constructor parameters. It returns a `shared_ptr<thing>`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the type can be automatically deduced by the return type of `make_shared<type>(...)`,
    the above lines can be more simply expressed using C++''s `auto` type specifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 23:** An example allocation using shared_ptr with auto type'
  prefs: []
  type: TYPE_NORMAL
- en: We'll use shared pointers in our code, because it allows multiple geometries
    to share a common instance (for example, a bunch of spheres that all use the same
    color material), and because it makes memory management automatic and easier to
    reason about.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::shared_ptr` is included with the `<memory>` header.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second C++ feature you may be unfamiliar with is `std::vector`. This is
    a generic array-like collection of an arbitrary type. Above, we use a collection
    of pointers to `hittable`. `std::vector` automatically grows as more values are
    added: `objects.push_back(object)` adds a value to the end of the `std::vector`
    member variable `objects`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`std::vector` is included with the `<vector>` header.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `using` statements in [listing 21](#listing_hittable-list-initial)
    tell the compiler that we'll be getting `shared_ptr` and `make_shared` from the
    `std` library, so we don't need to prefix these with `std::` every time we reference
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Common Constants and Utility Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need some math constants that we conveniently define in their own header
    file. For now we only need infinity, but we will also throw our own definition
    of pi in there, which we will need later. We'll also throw common useful constants
    and future utility functions in here. This new header, `rtweekend.h`, will be
    our general main header file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 24:** `[rtweekend.h]` The rtweekend.h common header'
  prefs: []
  type: TYPE_NORMAL
- en: Program files will include `rtweekend.h` first, so all other header files (where
    the bulk of our code will reside) can implicitly assume that `rtweekend.h` has
    already been included. Header files still need to explicitly include any other
    necessary header files. We'll make some updates with these assumptions in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 25:** `[color.h]` Assume rtweekend.h inclusion for color.h'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 26:** `[hittable.h]` Assume rtweekend.h inclusion for hittable.h'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 27:** `[hittable_list.h]` Assume rtweekend.h inclusion for hittable_list.h'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 28:** `[sphere.h]` Assume rtweekend.h inclusion for sphere.h'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 29:** `[vec3.h]` Assume rtweekend.h inclusion for vec3.hAnd now the
    new main:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 30:** `[main.cc]` The new main with hittables'
  prefs: []
  type: TYPE_NORMAL
- en: This yields a picture that is really just a visualization of where the spheres
    are located along with their surface normal. This is often a great way to view
    any flaws or specific characteristics of a geometric model.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/img-1.05-normals-sphere-ground.png)](https://raytracing.github.io/images/img-1.05-normals-sphere-ground.png)Image
    5: Resulting render of normals-colored sphere with ground'
  prefs: []
  type: TYPE_NORMAL
- en: An Interval Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we continue, we'll implement an interval class to manage real-valued
    intervals with a minimum and a maximum. We'll end up using this class quite often
    as we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 31:** `[interval.h]` Introducing the new interval class'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 32:** `[rtweekend.h]` Including the new interval class'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 33:** `[hittable.h]` hittable::hit() using interval'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 34:** `[hittable_list.h]` hittable_list::hit() using interval'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 35:** `[sphere.h]` sphere using interval'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 36:** `[main.cc]` The new main using interval'
  prefs: []
  type: TYPE_NORMAL
- en: Moving Camera Code Into Its Own Class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before continuing, now is a good time to consolidate our camera and scene-render
    code into a single new class: the `camera` class. The camera class will be responsible
    for two important jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: Construct and dispatch rays into the world.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the results of these rays to construct the rendered image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this refactoring, we'll collect the `ray_color()` function, along with the
    image, camera, and render sections of our main program. The new camera class will
    contain two public methods `initialize()` and `render()`, plus two private helper
    methods `get_ray()` and `ray_color()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, the camera will follow the simplest usage pattern that we could
    think of: it will be default constructed no arguments, then the owning code will
    modify the camera''s public variables through simple assignment, and finally everything
    is initialized by a call to the `initialize()` function. This pattern is chosen
    instead of the owner calling a constructor with a ton of parameters or by defining
    and calling a bunch of setter methods. Instead, the owning code only needs to
    set what it explicitly cares about. Finally, we could either have the owning code
    call `initialize()`, or just have the camera call this function automatically
    at the start of `render()`. We''ll use the second approach.'
  prefs: []
  type: TYPE_NORMAL
- en: After main creates a camera and sets default values, it will call the `render()`
    method. The `render()` method will prepare the camera for rendering and then execute
    the render loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the skeleton of our new `camera` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 37:** `[camera.h]` The camera class skeletonTo begin with, let''s
    fill in the `ray_color()` function from `main.cc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 38:** `[camera.h]` The camera::ray_color functionNow we move almost
    everything from the `main()` function into our new camera class. The only thing
    remaining in the `main()` function is the world construction. Here''s the camera
    class with newly migrated code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 39:** `[camera.h]` The working camera classAnd here''s the much reduced
    main:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 40:** `[main.cc]` The new main, using the new camera'
  prefs: []
  type: TYPE_NORMAL
- en: Running this newly refactored program should give us the same rendered image
    as before.
  prefs: []
  type: TYPE_NORMAL
- en: Antialiasing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you zoom into the rendered images so far, you might notice the harsh “stair
    step” nature of edges in our rendered images. This stair-stepping is commonly
    referred to as “aliasing”, or “jaggies”. When a real camera takes a picture, there
    are usually no jaggies along edges, because the edge pixels are a blend of some
    foreground and some background. Consider that unlike our rendered images, a true
    image of the world is continuous. Put another way, the world (and any true image
    of it) has effectively infinite resolution. We can get the same effect by averaging
    a bunch of samples for each pixel.
  prefs: []
  type: TYPE_NORMAL
- en: 'With a single ray through the center of each pixel, we are performing what
    is commonly called *point sampling*. The problem with point sampling can be illustrated
    by rendering a small checkerboard far away. If this checkerboard consists of an
    8×8 grid of black and white tiles, but only four rays hit it, then all four rays
    might intersect only white tiles, or only black, or some odd combination. In the
    real world, when we perceive a checkerboard far away with our eyes, we perceive
    it as a gray color, instead of sharp points of black and white. That''s because
    our eyes are naturally doing what we want our ray tracer to do: integrate the
    (continuous function of) light falling on a particular (discrete) region of our
    rendered image.'
  prefs: []
  type: TYPE_NORMAL
- en: Clearly we don't gain anything by just resampling the same ray through the pixel
    center multiple times — we'd just get the same result each time. Instead, we want
    to sample the light falling *around* the pixel, and then integrate those samples
    to approximate the true continuous result. So, how do we integrate the light falling
    around the pixel?
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll adopt the simplest model: sampling the square region centered at the
    pixel that extends halfway to each of the four neighboring pixels. This is not
    the optimal approach, but it is the most straight-forward. (See [*A Pixel is Not
    a Little Square*](https://www.researchgate.net/publication/244986797) for a deeper
    dive into this topic.)'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.08-pixel-samples.jpg)](https://raytracing.github.io/images/fig-1.08-pixel-samples.jpg)**Figure 8:**
    Pixel samples'
  prefs: []
  type: TYPE_NORMAL
- en: Some Random Number Utilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We're going to need a random number generator that returns real random numbers.
    This function should return a canonical random number, which by convention falls
    in the range <nobr aria-hidden="true">0≤n<1</nobr><mn>0</mn><mo>≤</mo><mi>n</mi><mo><</mo><mn>1</mn>.
    The “less than” before the 1 is important, as we will sometimes take advantage
    of that.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple approach to this is to use the `std::rand()` function that can be
    found in `<cstdlib>`, which returns a random integer in the range 0 and `RAND_MAX`.
    Hence we can get a real random number as desired with the following code snippet,
    added to `rtweekend.h`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 41:** `[rtweekend.h]` random_double() functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'C++ did not traditionally have a standard random number generator, but newer
    versions of C++ have addressed this issue with the `<random>` header (if imperfectly
    according to some experts). If you want to use this, you can obtain a random number
    with the conditions we need as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 42:** `[rtweekend.h]` random_double(), alternate implementation'
  prefs: []
  type: TYPE_NORMAL
- en: Generating Pixels with Multiple Samples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a single pixel composed of multiple samples, we'll select samples from the
    area surrounding the pixel and average the resulting light (color) values together.
  prefs: []
  type: TYPE_NORMAL
- en: 'First we''ll update the `write_color()` function to account for the number
    of samples we use: we need to find the average across all of the samples that
    we take. To do this, we''ll add the full color from each iteration, and then finish
    with a single division (by the number of samples) at the end, before writing out
    the color. To ensure that the color components of the final result remain within
    the proper <nobr aria-hidden="true">[0,1]</nobr><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo
    stretchy="false">]</mo> bounds, we''ll add and use a small helper function: `interval::clamp(x)`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 43:** `[interval.h]` The interval::clamp() utility function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the updated `write_color()` function that incorporates the interval
    clamping function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 44:** `[color.h]` The multi-sample write_color() function'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's update the camera class to define and use a new `camera::get_ray(i,j)`
    function, which will generate different samples for each pixel. This function
    will use a new helper function `sample_square()` that generates a random sample
    point within the unit square centered at the origin. We then transform the random
    sample from this ideal square back to the particular pixel we're currently sampling.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 45:** `[camera.h]` Camera with samples-per-pixel parameter'
  prefs: []
  type: TYPE_NORMAL
- en: (In addition to the new `sample_square()` function above, you'll also find the
    function `sample_disk()` in the Github source code. This is included in case you'd
    like to experiment with non-square pixels, but we won't be using it in this book.
    `sample_disk()` depends on the function `random_in_unit_disk()` which is defined
    later on.)
  prefs: []
  type: TYPE_NORMAL
- en: Main is updated to set the new camera parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 46:** `[main.cc]` Setting the new samples-per-pixel parameterZooming
    into the image that is produced, we can see the difference in edge pixels.[![](https://raytracing.github.io/images/img-1.06-antialias-before-after.png)](https://raytracing.github.io/images/img-1.06-antialias-before-after.png)Image
    6: Before and after antialiasing'
  prefs: []
  type: TYPE_NORMAL
- en: Diffuse Materials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have objects and multiple rays per pixel, we can make some realistic
    looking materials. We’ll start with diffuse materials (also called *matte*). One
    question is whether we mix and match geometry and materials (so that we can assign
    a material to multiple spheres, or vice versa) or if geometry and materials are
    tightly bound (which could be useful for procedural objects where the geometry
    and material are linked). We’ll go with separate — which is usual in most renderers
    — but do be aware that there are alternative approaches.
  prefs: []
  type: TYPE_NORMAL
- en: A Simple Diffuse Material
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Diffuse objects that don’t emit their own light merely take on the color of
    their surroundings, but they do modulate that with their own intrinsic color.
    Light that reflects off a diffuse surface has its direction randomized, so, if
    we send three rays into a crack between two diffuse surfaces they will each have
    different random behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.09-light-bounce.jpg)](https://raytracing.github.io/images/fig-1.09-light-bounce.jpg)**Figure 9:**
    Light ray bounces'
  prefs: []
  type: TYPE_NORMAL
- en: 'They might also be absorbed rather than reflected. The darker the surface,
    the more likely the ray is absorbed (that’s why it''s dark!). Really any algorithm
    that randomizes direction will produce surfaces that look matte. Let''s start
    with the most intuitive: a surface that randomly bounces a ray equally in all
    directions. For this material, a ray that hits the surface has an equal probability
    of bouncing in any direction away from the surface.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.10-random-vec-horizon.jpg)](https://raytracing.github.io/images/fig-1.10-random-vec-horizon.jpg)**Figure 10:**
    Equal reflection above the horizon'
  prefs: []
  type: TYPE_NORMAL
- en: 'This very intuitive material is the simplest kind of diffuse and — indeed —
    many of the first raytracing papers used this diffuse method (before adopting
    a more accurate method that we''ll be implementing a little bit later). We don''t
    currently have a way to randomly reflect a ray, so we''ll need to add a few functions
    to our vector utility header. The first thing we need is the ability to generate
    arbitrary random vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 47:** `[vec3.h]` vec3 random utility functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we need to figure out how to manipulate a random vector so that we only
    get results that are on the surface of a hemisphere. There are analytical methods
    of doing this, but they are actually surprisingly complicated to understand, and
    quite a bit complicated to implement. Instead, we''ll use what is typically the
    easiest algorithm: A rejection method. A rejection method works by repeatedly
    generating random samples until we produce a sample that meets the desired criteria.
    In other words, keep rejecting bad samples until you find a good one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many equally valid ways of generating a random vector on a hemisphere
    using the rejection method, but for our purposes we will go with the simplest,
    which is:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a random vector inside the unit sphere
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalize this vector to extend it to the sphere surface
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invert the normalized vector if it falls onto the wrong hemisphere
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, we will use a rejection method to generate the random vector inside the
    unit sphere (that is, a sphere of radius 1). Pick a random point inside the cube
    enclosing the unit sphere (that is, where <nobr aria-hidden="true">x</nobr><mi>x</mi>,
    <nobr aria-hidden="true">y</nobr><mi>y</mi>, and <nobr aria-hidden="true">z</nobr><mi>z</mi>
    are all in the range <nobr aria-hidden="true">[−1,+1]</nobr><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mo>+</mo><mn>1</mn><mo
    stretchy="false">]</mo>). If this point lies outside the unit sphere, then generate
    a new one until we find one that lies inside or on the unit sphere. [![](https://raytracing.github.io/images/fig-1.11-sphere-vec.jpg)](https://raytracing.github.io/images/fig-1.11-sphere-vec.jpg)**Figure 11:**
    Two vectors were rejected before finding a good one (pre-normalization) [![](https://raytracing.github.io/images/fig-1.12-sphere-unit-vec.jpg)](https://raytracing.github.io/images/fig-1.12-sphere-unit-vec.jpg)**Figure 12:**
    The accepted random vector is normalized to produce a unit vector
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s our first draft of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 48:** `[vec3.h]` The random_unit_vector() function, version one'
  prefs: []
  type: TYPE_NORMAL
- en: Sadly, we have a small floating-point abstraction leak to deal with. Since floating-point
    numbers have finite precision, a very small value can underflow to zero when squared.
    So if all three coordinates are small enough (that is, very near the center of
    the sphere), the norm of the vector will be zero, and thus normalizing will yield
    the bogus vector <nobr aria-hidden="true">[±∞,±∞,±∞]</nobr><mo stretchy="false">[</mo><mo>±</mo><mi
    mathvariant="normal">∞</mi><mo>,</mo><mo>±</mo><mi mathvariant="normal">∞</mi><mo>,</mo><mo>±</mo><mi
    mathvariant="normal">∞</mi><mo stretchy="false">]</mo>. To fix this, we'll also
    reject points that lie inside this “black hole” around the center. With double
    precision (64-bit floats), we can safely support values greater than <nobr aria-hidden="true">10−160</nobr><msup><mn>10</mn><mrow
    class="MJX-TeXAtom-ORD"><mo>−</mo><mn>160</mn></mrow></msup>.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s our more robust function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 49:** `[vec3.h]` The random_unit_vector() function, version twoNow
    that we have a random unit vector, we can determine if it is on the correct hemisphere
    by comparing against the surface normal: [![](https://raytracing.github.io/images/fig-1.13-surface-normal.jpg)](https://raytracing.github.io/images/fig-1.13-surface-normal.jpg)**Figure 13:**
    The normal vector tells us which hemisphere we needWe can take the dot product
    of the surface normal and our random vector to determine if it''s in the correct
    hemisphere. If the dot product is positive, then the vector is in the correct
    hemisphere. If the dot product is negative, then we need to invert the vector.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 50:** `[vec3.h]` The random_on_hemisphere() function'
  prefs: []
  type: TYPE_NORMAL
- en: If a ray bounces off of a material and keeps 100% of its color, then we say
    that the material is *white*. If a ray bounces off of a material and keeps 0%
    of its color, then we say that the material is black. As a first demonstration
    of our new diffuse material we'll set the `ray_color` function to return 50% of
    the color from a bounce. We should expect to get a nice gray color.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 51:** `[camera.h]` ray_color() using a random ray direction... Indeed
    we do get rather nice gray spheres:[![](https://raytracing.github.io/images/img-1.07-first-diffuse.png)](https://raytracing.github.io/images/img-1.07-first-diffuse.png)Image
    7: First render of a diffuse sphere'
  prefs: []
  type: TYPE_NORMAL
- en: Limiting the Number of Child Rays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There''s one potential problem lurking here. Notice that the `ray_color` function
    is recursive. When will it stop recursing? When it fails to hit anything. In some
    cases, however, that may be a long time — long enough to blow the stack. To guard
    against that, let''s limit the maximum recursion depth, returning no light contribution
    at the maximum depth:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 52:** `[camera.h]` camera::ray_color() with depth limitingUpdate
    the main() function to use this new depth limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 53:** `[main.cc]` Using the new ray depth limitingFor this very simple
    scene we should get basically the same result:[![](https://raytracing.github.io/images/img-1.08-second-diffuse.png)](https://raytracing.github.io/images/img-1.08-second-diffuse.png)Image
    8: Second render of a diffuse sphere with limited bounces'
  prefs: []
  type: TYPE_NORMAL
- en: Fixing Shadow Acne
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There’s also a subtle bug that we need to address. A ray will attempt to accurately
    calculate the intersection point when it intersects with a surface. Unfortunately
    for us, this calculation is susceptible to floating point rounding errors which
    can cause the intersection point to be ever so slightly off. This means that the
    origin of the next ray, the ray that is randomly scattered off of the surface,
    is unlikely to be perfectly flush with the surface. It might be just above the
    surface. It might be just below the surface. If the ray''s origin is just below
    the surface then it could intersect with that surface again. Which means that
    it will find the nearest surface at <nobr aria-hidden="true">t=0.00000001</nobr><mi>t</mi><mo>=</mo><mn>0.00000001</mn>
    or whatever floating point approximation the hit function gives us. The simplest
    hack to address this is just to ignore hits that are very close to the calculated
    intersection point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 54:** `[camera.h]` Calculating reflected ray origins with toleranceThis
    gets rid of the shadow acne problem. Yes it is really called that. Here''s the
    result:[![](https://raytracing.github.io/images/img-1.09-no-acne.png)](https://raytracing.github.io/images/img-1.09-no-acne.png)Image
    9: Diffuse sphere with no shadow acne'
  prefs: []
  type: TYPE_NORMAL
- en: True Lambertian Reflection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scattering reflected rays evenly about the hemisphere produces a nice soft diffuse
    model, but we can definitely do better. A more accurate representation of real
    diffuse objects is the *Lambertian* distribution. This distribution scatters reflected
    rays in a manner that is proportional to <nobr aria-hidden="true">cos(ϕ)</nobr><mi>cos</mi><mo>⁡</mo><mo
    stretchy="false">(</mo><mi>ϕ</mi><mo stretchy="false">)</mo>, where <nobr aria-hidden="true">ϕ</nobr><mi>ϕ</mi>
    is the angle between the reflected ray and the surface normal. This means that
    a reflected ray is most likely to scatter in a direction near the surface normal,
    and less likely to scatter in directions away from the normal. This non-uniform
    Lambertian distribution does a better job of modeling material reflection in the
    real world than our previous uniform scattering.
  prefs: []
  type: TYPE_NORMAL
- en: We can create this distribution by adding a random unit vector to the normal
    vector. At the point of intersection on a surface there is the hit point, <nobr
    aria-hidden="true">p</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">p</mi></mrow>,
    and there is the normal of the surface, <nobr aria-hidden="true">n</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>. At the point of
    intersection, this surface has exactly two sides, so there can only be two unique
    unit spheres tangent to any intersection point (one unique sphere for each side
    of the surface). These two unit spheres will be displaced from the surface by
    the length of their radius, which is exactly one for a unit sphere.
  prefs: []
  type: TYPE_NORMAL
- en: One sphere will be displaced in the direction of the surface's normal (<nobr
    aria-hidden="true">n</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>)
    and one sphere will be displaced in the opposite direction (<nobr aria-hidden="true">−n</nobr><mrow
    class="MJX-TeXAtom-ORD"><mo mathvariant="bold">−</mo><mi mathvariant="bold">n</mi></mrow>).
    This leaves us with two spheres of unit size that will only be *just* touching
    the surface at the intersection point. From this, one of the spheres will have
    its center at <nobr aria-hidden="true">(P+n)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo>+</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow><mo stretchy="false">)</mo> and the other sphere
    will have its center at <nobr aria-hidden="true">(P−n)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow><mo stretchy="false">)</mo>. The sphere with a
    center at <nobr aria-hidden="true">(P−n)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow><mo stretchy="false">)</mo> is considered *inside*
    the surface, whereas the sphere with center <nobr aria-hidden="true">(P+n)</nobr><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow><mo>+</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow><mo stretchy="false">)</mo>
    is considered *outside* the surface.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to select the tangent unit sphere that is on the same side of the surface
    as the ray origin. Pick a random point <nobr aria-hidden="true">S</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">S</mi></mrow> on this unit radius
    sphere and send a ray from the hit point <nobr aria-hidden="true">P</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">P</mi></mrow> to the random point
    <nobr aria-hidden="true">S</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">S</mi></mrow>
    (this is the vector <nobr aria-hidden="true">(S−P)</nobr><mo stretchy="false">(</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">S</mi></mrow><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">P</mi></mrow><mo stretchy="false">)</mo>):'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.14-rand-unitvec.jpg)](https://raytracing.github.io/images/fig-1.14-rand-unitvec.jpg)**Figure 14:**
    Randomly generating a vector according to Lambertian distributionThe change is
    actually fairly minimal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 55:** `[camera.h]` ray_color() with replacement diffuseAfter rendering
    we get a similar image:[![](https://raytracing.github.io/images/img-1.10-correct-lambertian.png)](https://raytracing.github.io/images/img-1.10-correct-lambertian.png)Image
    10: Correct rendering of Lambertian spheres'
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s hard to tell the difference between these two diffuse methods, given
    that our scene of two spheres is so simple, but you should be able to notice two
    important visual differences:'
  prefs: []
  type: TYPE_NORMAL
- en: The shadows are more pronounced after the change
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both spheres are tinted blue from the sky after the change
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both of these changes are due to the less uniform scattering of the light rays—more
    rays are scattering toward the normal. This means that for diffuse objects, they
    will appear *darker* because less light bounces toward the camera. For the shadows,
    more light bounces straight-up, so the area underneath the sphere is darker.
  prefs: []
  type: TYPE_NORMAL
- en: Not a lot of common, everyday objects are perfectly diffuse, so our visual intuition
    of how these objects behave under light can be poorly formed. As scenes become
    more complicated over the course of the book, you are encouraged to switch between
    the different diffuse renderers presented here. Most scenes of interest will contain
    a large amount of diffuse materials. You can gain valuable insight by understanding
    the effect of different diffuse methods on the lighting of a scene.
  prefs: []
  type: TYPE_NORMAL
- en: Using Gamma Correction for Accurate Color Intensity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Note the shadowing under the sphere. The picture is very dark, but our spheres
    only absorb half the energy of each bounce, so they are 50% reflectors. The spheres
    should look pretty bright (in real life, a light grey) but they appear to be rather
    dark. We can see this more clearly if we walk through the full brightness gamut
    for our diffuse material. We start by setting the reflectance of the `ray_color`
    function from `0.5` (50%) to `0.1` (10%):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 56:** `[camera.h]` ray_color() with 10% reflectance'
  prefs: []
  type: TYPE_NORMAL
- en: 'We render out at this new 10% reflectance. We then set reflectance to 30% and
    render again. We repeat for 50%, 70%, and finally 90%. You can overlay these images
    from left to right in the photo editor of your choice and you should get a very
    nice visual representation of the increasing brightness of your chosen gamut.
    This is the one that we''ve been working with so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/img-1.11-linear-gamut.png)](https://raytracing.github.io/images/img-1.11-linear-gamut.png)Image
    11: The gamut of our renderer so far'
  prefs: []
  type: TYPE_NORMAL
- en: If you look closely, or if you use a color picker, you should notice that the
    50% reflectance render (the one in the middle) is far too dark to be half-way
    between white and black (middle-gray). Indeed, the 70% reflector is closer to
    middle-gray. The reason for this is that almost all computer programs assume that
    an image is “gamma corrected” before being written into an image file. This means
    that the 0 to 1 values have some transform applied before being stored as a byte.
    Images with data that are written without being transformed are said to be in
    *linear space*, whereas images that are transformed are said to be in *gamma space*.
    It is likely that the image viewer you are using is expecting an image in gamma
    space, but we are giving it an image in linear space. This is the reason why our
    image appears inaccurately dark.
  prefs: []
  type: TYPE_NORMAL
- en: There are many good reasons for why images should be stored in gamma space,
    but for our purposes we just need to be aware of it. We are going to transform
    our data into gamma space so that our image viewer can more accurately display
    our image. As a simple approximation, we can use “gamma 2” as our transform, which
    is the power that you use when going from gamma space to linear space. We need
    to go from linear space to gamma space, which means taking the inverse of “gamma
    2", which means an exponent of <nobr aria-hidden="true">1/gamma</nobr><mn>1</mn><mrow
    class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-mathit"
    mathvariant="italic">g</mi><mi class="MJX-tex-mathit" mathvariant="italic">a</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">m</mi><mi class="MJX-tex-mathit" mathvariant="italic">m</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi></mrow>, which is just the square-root.
    We'll also want to ensure that we robustly handle negative inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 57:** `[color.h]` write_color(), with gamma correctionUsing this
    gamma correction, we now get a much more consistent ramp from darkness to lightness:[![](https://raytracing.github.io/images/img-1.12-gamma-gamut.png)](https://raytracing.github.io/images/img-1.12-gamma-gamut.png)Image
    12: The gamut of our renderer, gamma-corrected'
  prefs: []
  type: TYPE_NORMAL
- en: Metal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Abstract Class for Materials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we want different objects to have different materials, we have a design
    decision. We could have a universal material type with lots of parameters so any
    individual material type could just ignore the parameters that don''t affect it.
    This is not a bad approach. Or we could have an abstract material class that encapsulates
    unique behavior. I am a fan of the latter approach. For our program the material
    needs to do two things:'
  prefs: []
  type: TYPE_NORMAL
- en: Produce a scattered ray (or say it absorbed the incident ray).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If scattered, say how much the ray should be attenuated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This suggests the abstract class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 58:** `[material.h]` The material class'
  prefs: []
  type: TYPE_NORMAL
- en: A Data Structure to Describe Ray-Object Intersections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `hit_record` is to avoid a bunch of arguments so we can stuff whatever info
    we want in there. You can use arguments instead of an encapsulated type, it’s
    just a matter of taste. Hittables and materials need to be able to reference the
    other's type in code so there is some circularity of the references. In C++ we
    add the line `class material;` to tell the compiler that `material` is a class
    that will be defined later. Since we're just specifying a pointer to the class,
    the compiler doesn't need to know the details of the class, solving the circular
    reference issue.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 59:** `[hittable.h]` Hit record with added material pointer'
  prefs: []
  type: TYPE_NORMAL
- en: '`hit_record` is just a way to stuff a bunch of arguments into a class so we
    can send them as a group. When a ray hits a surface (a particular sphere for example),
    the material pointer in the `hit_record` will be set to point at the material
    pointer the sphere was given when it was set up in `main()` when we start. When
    the `ray_color()` routine gets the `hit_record` it can call member functions of
    the material pointer to find out what ray, if any, is scattered.'
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, `hit_record` needs to be told the material that is assigned
    to the sphere.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 60:** `[sphere.h]` Ray-sphere intersection with added material information'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling Light Scatter and Reflectance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here and throughout these books we will use the term *albedo* (Latin for “whiteness”).
    Albedo is a precise technical term in some disciplines, but in all cases it is
    used to define some form of *fractional reflectance*. Albedo will vary with material
    color and (as we will later implement for glass materials) can also vary with
    incident viewing direction (the direction of the incoming ray).
  prefs: []
  type: TYPE_NORMAL
- en: 'Lambertian (diffuse) reflectance can either always scatter and attenuate light
    according to its reflectance <nobr aria-hidden="true">R</nobr><mi>R</mi>, or it
    can sometimes scatter (with probability <nobr aria-hidden="true">1−R</nobr><mn>1</mn><mo>−</mo><mi>R</mi>)
    with no attenuation (where a ray that isn''t scattered is just absorbed into the
    material). It could also be a mixture of both those strategies. We will choose
    to always scatter, so implementing Lambertian materials becomes a simple task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 61:** `[material.h]` The new lambertian material class'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the third option: we could scatter with some fixed probability <nobr aria-hidden="true">p</nobr><mi>p</mi>
    and have attenuation be <nobr aria-hidden="true">albedo/p</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    class="MJX-tex-mathit" mathvariant="italic">a</mi><mi class="MJX-tex-mathit" mathvariant="italic">l</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">b</mi><mi class="MJX-tex-mathit" mathvariant="italic">e</mi><mi
    class="MJX-tex-mathit" mathvariant="italic">d</mi><mi class="MJX-tex-mathit" mathvariant="italic">o</mi></mrow><mrow
    class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mi>p</mi>. Your choice.'
  prefs: []
  type: TYPE_NORMAL
- en: If you read the code above carefully, you'll notice a small chance of mischief.
    If the random unit vector we generate is exactly opposite the normal vector, the
    two will sum to zero, which will result in a zero scatter direction vector. This
    leads to bad scenarios later on (infinities and NaNs), so we need to intercept
    the condition before we pass it on.
  prefs: []
  type: TYPE_NORMAL
- en: In service of this, we'll create a new vector method — `vec3::near_zero()` —
    that returns true if the vector is very close to zero in all dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: The following changes will use the C++ standard library function `std::fabs`,
    which returns the absolute value of its input.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 62:** `[vec3.h]` The vec3::near_zero() method'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 63:** `[material.h]` Lambertian scatter, bullet-proof'
  prefs: []
  type: TYPE_NORMAL
- en: Mirrored Light Reflection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For polished metals the ray won’t be randomly scattered. The key question is:
    How does a ray get reflected from a metal mirror? Vector math is our friend here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.15-reflection.jpg)](https://raytracing.github.io/images/fig-1.15-reflection.jpg)**Figure 15:**
    Ray reflection'
  prefs: []
  type: TYPE_NORMAL
- en: The reflected ray direction in red is just <nobr aria-hidden="true">v+2b</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">v</mi></mrow><mo>+</mo><mn>2</mn><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow>. In our design, <nobr
    aria-hidden="true">n</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>
    is a unit vector (length one), but <nobr aria-hidden="true">v</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">v</mi></mrow> may not be. To get the vector <nobr aria-hidden="true">b</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow>, we scale the normal
    vector by the length of the projection of <nobr aria-hidden="true">v</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">v</mi></mrow> onto <nobr aria-hidden="true">n</nobr><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>, which is given by
    the dot product <nobr aria-hidden="true">v⋅n</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">v</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>.
    (If <nobr aria-hidden="true">n</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>
    were not a unit vector, we would also need to divide this dot product by the length
    of <nobr aria-hidden="true">n</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow>.)
    Finally, because <nobr aria-hidden="true">v</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">v</mi></mrow> points *into* the surface, and we want <nobr
    aria-hidden="true">b</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow>
    to point *out* of the surface, we need to negate this projection length.
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting everything together, we get the following computation of the reflected
    vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 64:** `[vec3.h]` vec3 reflection functionThe metal material just
    reflects rays using that formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 65:** `[material.h]` Metal material with reflectance functionWe need
    to modify the `ray_color()` function for all of our changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 66:** `[camera.h]` Ray color with scattered reflectance'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we''ll update the `sphere` constructor to initialize the material pointer
    `mat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 67:** `[sphere.h]` Initializing sphere with a material'
  prefs: []
  type: TYPE_NORMAL
- en: A Scene with Metal Spheres
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s add some metal spheres to our scene:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 68:** `[main.cc]` Scene with metal spheresWhich gives:[![](https://raytracing.github.io/images/img-1.13-metal-shiny.png)](https://raytracing.github.io/images/img-1.13-metal-shiny.png)Image
    13: Shiny metal'
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Reflection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also randomize the reflected direction by using a small sphere and choosing
    a new endpoint for the ray. We'll use a random point from the surface of a sphere
    centered on the original endpoint, scaled by the fuzz factor.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.16-reflect-fuzzy.jpg)](https://raytracing.github.io/images/fig-1.16-reflect-fuzzy.jpg)**Figure 16:**
    Generating fuzzed reflection rays'
  prefs: []
  type: TYPE_NORMAL
- en: The bigger the fuzz sphere, the fuzzier the reflections will be. This suggests
    adding a fuzziness parameter that is just the radius of the sphere (so zero is
    no perturbation). The catch is that for big spheres or grazing rays, we may scatter
    below the surface. We can just have the surface absorb those.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that in order for the fuzz sphere to make sense, it needs to be consistently
    scaled compared to the reflection vector, which can vary in length arbitrarily.
    To address this, we need to normalize the reflected ray.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 69:** `[material.h]` Metal material fuzzinessWe can try that out
    by adding fuzziness 0.3 and 1.0 to the metals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 70:** `[main.cc]` Metal spheres with fuzziness[![](https://raytracing.github.io/images/img-1.14-metal-fuzz.png)](https://raytracing.github.io/images/img-1.14-metal-fuzz.png)Image
    14: Fuzzed metal'
  prefs: []
  type: TYPE_NORMAL
- en: Dielectrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clear materials such as water, glass, and diamond are dielectrics. When a light
    ray hits them, it splits into a reflected ray and a refracted (transmitted) ray.
    We’ll handle that by randomly choosing between reflection and refraction, only
    generating one scattered ray per interaction.
  prefs: []
  type: TYPE_NORMAL
- en: As a quick review of terms, a *reflected* ray hits a surface and then “bounces”
    off in a new direction.
  prefs: []
  type: TYPE_NORMAL
- en: A *refracted* ray bends as it transitions from a material's surroundings into
    the material itself (as with glass or water). This is why a pencil looks bent
    when partially inserted in water.
  prefs: []
  type: TYPE_NORMAL
- en: The amount that a refracted ray bends is determined by the material's *refractive
    index*. Generally, this is a single value that describes how much light bends
    when entering a material from a vacuum. Glass has a refractive index of something
    like 1.5–1.7, diamond is around 2.4, and air has a small refractive index of 1.000293.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a transparent material is embedded in a different transparent material,
    you can describe the refraction with a relative refraction index: the refractive
    index of the object''s material divided by the refractive index of the surrounding
    material. For example, if you want to render a glass ball under water, then the
    glass ball would have an effective refractive index of 1.125\. This is given by
    the refractive index of glass (1.5) divided by the refractive index of water (1.333).'
  prefs: []
  type: TYPE_NORMAL
- en: You can find the refractive index of most common materials with a quick internet
    search.
  prefs: []
  type: TYPE_NORMAL
- en: Refraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The hardest part to debug is the refracted ray. I usually first just have all
    the light refract if there is a refraction ray at all. For this project, I tried
    to put two glass balls in our scene, and I got this (I have not told you how to
    do this right or wrong yet, but soon!):'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/img-1.15-glass-first.png)](https://raytracing.github.io/images/img-1.15-glass-first.png)Image
    15: Glass first'
  prefs: []
  type: TYPE_NORMAL
- en: Is that right? Glass balls look odd in real life. But no, it isn’t right. The
    world should be flipped upside down and no weird black stuff. I just printed out
    the ray straight through the middle of the image and it was clearly wrong. That
    often does the job.
  prefs: []
  type: TYPE_NORMAL
- en: Snell's Law
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The refraction is described by Snell’s law:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">η⋅sinθ=η′⋅sinθ′</nobr><mi>η</mi><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi><mo>=</mo><msup><mi>η</mi><mo>′</mo></msup><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup>
  prefs: []
  type: TYPE_NORMAL
- en: 'Where <nobr aria-hidden="true">θ</nobr><mi>θ</mi> and <nobr aria-hidden="true">θ′</nobr><msup><mi>θ</mi><mo>′</mo></msup>
    are the angles from the normal, and <nobr aria-hidden="true">η</nobr><mi>η</mi>
    and <nobr aria-hidden="true">η′</nobr><msup><mi>η</mi><mo>′</mo></msup> (pronounced
    “eta” and “eta prime”) are the refractive indices. The geometry is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.17-refraction.jpg)](https://raytracing.github.io/images/fig-1.17-refraction.jpg)**Figure 17:**
    Ray refraction'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to determine the direction of the refracted ray, we have to solve
    for <nobr aria-hidden="true">sinθ′</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup>:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">sinθ′=ηη′⋅sinθ</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup><mo>=</mo><mfrac><mi>η</mi><msup><mi>η</mi><mo>′</mo></msup></mfrac><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi>
  prefs: []
  type: TYPE_NORMAL
- en: 'On the refracted side of the surface there is a refracted ray <nobr aria-hidden="true">R′</nobr><mrow
    class="MJX-TeXAtom-ORD"><msup><mi mathvariant="bold">R</mi><mo>′</mo></msup></mrow>
    and a normal <nobr aria-hidden="true">n′</nobr><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">n</mi><mo>′</mo></msup></mrow>, and there exists an angle,
    <nobr aria-hidden="true">θ′</nobr><msup><mi>θ</mi><mo>′</mo></msup>, between them.
    We can split <nobr aria-hidden="true">R′</nobr><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow> into the parts of the ray that
    are perpendicular to <nobr aria-hidden="true">n′</nobr><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">n</mi><mo>′</mo></msup></mrow> and parallel to <nobr aria-hidden="true">n′</nobr><mrow
    class="MJX-TeXAtom-ORD"><msup><mi mathvariant="bold">n</mi><mo>′</mo></msup></mrow>:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">R′=R′⊥+R′∥</nobr><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mo>=</mo><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub><mo>+</mo><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mo>∥</mo></mrow></msub>
  prefs: []
  type: TYPE_NORMAL
- en: 'If we solve for <nobr aria-hidden="true">R′⊥</nobr><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub> and <nobr aria-hidden="true">R′∥</nobr><msub><mrow
    class="MJX-TeXAtom-ORD"><msup><mi mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow
    class="MJX-TeXAtom-ORD"><mo>∥</mo></mrow></msub> we get:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">R′⊥=ηη′(R+|R|cos(θ)n)</nobr><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub><mo>=</mo><mfrac><mi>η</mi><msup><mi>η</mi><mo>′</mo></msup></mfrac><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">R</mi></mrow><mo>+</mo><mrow
    class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">R</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>cos</mi><mo>⁡</mo><mo
    stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow><mo stretchy="false">)</mo><nobr aria-hidden="true">R′∥=−1−|R′⊥|2−−−−−−−−√n</nobr><msub><mrow
    class="MJX-TeXAtom-ORD"><msup><mi mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow
    class="MJX-TeXAtom-ORD"><mo>∥</mo></mrow></msub><mo>=</mo><mo>−</mo><msqrt><mn>1</mn><mo>−</mo><mrow
    class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub><msup><mrow class="MJX-TeXAtom-ORD"><mo
    stretchy="false">|</mo></mrow><mn>2</mn></msup></msqrt><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow>
  prefs: []
  type: TYPE_NORMAL
- en: You can go ahead and prove this for yourself if you want, but we will treat
    it as fact and move on. The rest of the book will not require you to understand
    the proof.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know the value of every term on the right-hand side except for <nobr aria-hidden="true">cosθ</nobr><mi>cos</mi><mo>⁡</mo><mi>θ</mi>.
    It is well known that the dot product of two vectors can be explained in terms
    of the cosine of the angle between them:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">a⋅b=|a||b|cosθ</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">a</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow><mo>=</mo><mrow
    class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">a</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow
    class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">b</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>cos</mi><mo>⁡</mo><mi>θ</mi>
  prefs: []
  type: TYPE_NORMAL
- en: 'If we restrict <nobr aria-hidden="true">a</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">a</mi></mrow> and <nobr aria-hidden="true">b</nobr><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">b</mi></mrow> to be unit vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">a⋅b=cosθ</nobr><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">a</mi></mrow><mo>⋅</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">b</mi></mrow><mo>=</mo><mi>cos</mi><mo>⁡</mo><mi>θ</mi>
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now rewrite <nobr aria-hidden="true">R′⊥</nobr><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub> in terms of known quantities:'
  prefs: []
  type: TYPE_NORMAL
- en: '<nobr aria-hidden="true">R′⊥=ηη′(R+(−R⋅n)n)</nobr><msub><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="normal">⊥</mi></mrow></msub><mo>=</mo><mfrac><mi>η</mi><msup><mi>η</mi><mo>′</mo></msup></mfrac><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">R</mi></mrow><mo>+</mo><mo
    stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mo mathvariant="bold">−</mo><mi
    mathvariant="bold">R</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow><mo
    stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">n</mi></mrow><mo
    stretchy="false">)</mo>When we combine them back together, we can write a function
    to calculate <nobr aria-hidden="true">R′</nobr><mrow class="MJX-TeXAtom-ORD"><msup><mi
    mathvariant="bold">R</mi><mo>′</mo></msup></mrow>:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 71:** `[vec3.h]` Refraction functionAnd the dielectric material that
    always refracts is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 72:** `[material.h]` Dielectric material class that always refractsNow
    we''ll update the scene to illustrate refraction by changing the left sphere to
    glass, which has an index of refraction of approximately 1.5.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 73:** `[main.cc]` Changing the left sphere to glassThis gives us
    the following result:[![](https://raytracing.github.io/images/img-1.16-glass-always-refract.png)](https://raytracing.github.io/images/img-1.16-glass-always-refract.png)Image
    16: Glass sphere that always refracts'
  prefs: []
  type: TYPE_NORMAL
- en: Total Internal Reflection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One troublesome practical issue with refraction is that there are ray angles
    for which no solution is possible using Snell''s law. When a ray enters a medium
    of lower index of refraction at a sufficiently glancing angle, it can refract
    with an angle greater than 90°. If we refer back to Snell''s law and the derivation
    of <nobr aria-hidden="true">sinθ′</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup>:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">sinθ′=ηη′⋅sinθ</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup><mo>=</mo><mfrac><mi>η</mi><msup><mi>η</mi><mo>′</mo></msup></mfrac><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi>
  prefs: []
  type: TYPE_NORMAL
- en: 'If the ray is inside glass and outside is air (<nobr aria-hidden="true">η=1.5</nobr><mi>η</mi><mo>=</mo><mn>1.5</mn>
    and <nobr aria-hidden="true">η′=1.0</nobr><msup><mi>η</mi><mo>′</mo></msup><mo>=</mo><mn>1.0</mn>):'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">sinθ′=1.51.0⋅sinθ</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup><mo>=</mo><mfrac><mn>1.5</mn><mn>1.0</mn></mfrac><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi>The
    value of <nobr aria-hidden="true">sinθ′</nobr><mi>sin</mi><mo>⁡</mo><msup><mi>θ</mi><mo>′</mo></msup>
    cannot be greater than 1\. So, if,<nobr aria-hidden="true">1.51.0⋅sinθ>1.0</nobr><mfrac><mn>1.5</mn><mn>1.0</mn></mfrac><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mi>θ</mi><mo>></mo><mn>1.0</mn>
  prefs: []
  type: TYPE_NORMAL
- en: 'the equality between the two sides of the equation is broken, and a solution
    cannot exist. If a solution does not exist, the glass cannot refract, and therefore
    must reflect the ray:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 74:** `[material.h]` Determining if the ray can refract'
  prefs: []
  type: TYPE_NORMAL
- en: Here all the light is reflected, and because in practice that is usually inside
    solid objects, it is called *total internal reflection*. This is why sometimes
    the water-to-air boundary acts as a perfect mirror when you are submerged — if
    you're under water looking up, you can see things above the water, but when you
    are close to the surface and looking sideways, the water surface looks like a
    mirror.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can solve for `sin_theta` using the trigonometric identities:'
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">sinθ=1−cos2θ−−−−−−−−√</nobr><mi>sin</mi><mo>⁡</mo><mi>θ</mi><mo>=</mo><msqrt><mn>1</mn><mo>−</mo><msup><mi>cos</mi><mn>2</mn></msup><mo>⁡</mo><mi>θ</mi></msqrt>
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">cosθ=R⋅n</nobr><mi>cos</mi><mo>⁡</mo><mi>θ</mi><mo>=</mo><mrow
    class="MJX-TeXAtom-ORD"><mi mathvariant="bold">R</mi></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mi
    mathvariant="bold">n</mi></mrow>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 75:** `[material.h]` Determining if the ray can refractAnd the dielectric
    material that always refracts (when possible) is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 76:** `[material.h]` Dielectric material class with reflection'
  prefs: []
  type: TYPE_NORMAL
- en: Attenuation is always 1 — the glass surface absorbs nothing.
  prefs: []
  type: TYPE_NORMAL
- en: If we render the prior scene with the new `dielectric::scatter()` function,
    we see … no change. Huh?
  prefs: []
  type: TYPE_NORMAL
- en: Well, it turns out that given a sphere of material with an index of refraction
    greater than air, there's no incident angle that will yield total internal reflection
    — neither at the ray-sphere entrance point nor at the ray exit. This is due to
    the geometry of spheres, as a grazing incoming ray will always be bent to a smaller
    angle, and then bent back to the original angle on exit.
  prefs: []
  type: TYPE_NORMAL
- en: So how can we illustrate total internal reflection? Well, if the sphere has
    an index of refraction *less* than the medium it's in, then we can hit it with
    shallow grazing angles, getting total *external* reflection. That should be good
    enough to observe the effect.
  prefs: []
  type: TYPE_NORMAL
- en: We'll model a world filled with water (index of refraction approximately 1.33),
    and change the sphere material to air (index of refraction 1.00) — an air bubble!
    To do this, change the left sphere material's index of refraction to
  prefs: []
  type: TYPE_NORMAL
- en: <nobr aria-hidden="true">index of refraction of airindex of refraction of water</nobr><mfrac><mtext>index
    of refraction of air</mtext><mtext>index of refraction of water</mtext></mfrac>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 77:** `[main.cc]` Left sphere is an air bubble in waterThis change
    yields the following render:[![](https://raytracing.github.io/images/img-1.17-air-bubble-total-reflection.png)](https://raytracing.github.io/images/img-1.17-air-bubble-total-reflection.png)Image
    17: Air bubble sometimes refracts, sometimes reflects'
  prefs: []
  type: TYPE_NORMAL
- en: Here you can see that more-or-less direct rays refract, while glancing rays
    reflect.
  prefs: []
  type: TYPE_NORMAL
- en: Schlick Approximation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now real glass has reflectivity that varies with angle — look at a window at
    a steep angle and it becomes a mirror. There is a big ugly equation for that,
    but almost everybody uses a cheap and surprisingly accurate polynomial approximation
    by Christophe Schlick. This yields our full glass material:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 78:** `[material.h]` Full glass material'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling a Hollow Glass Sphere
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's model a hollow glass sphere. This is a sphere of some thickness with another
    sphere of air inside it. If you think about the path of a ray going through such
    an object, it will hit the outer sphere, refract, hit the inner sphere (assuming
    we do hit it), refract a second time, and travel through the air inside. Then
    it will continue on, hit the inside surface of the inner sphere, refract back,
    then hit the inside surface of the outer sphere, and finally refract and exit
    back into the scene atmosphere.
  prefs: []
  type: TYPE_NORMAL
- en: The outer sphere is just modeled with a standard glass sphere, with a refractive
    index of around 1.50 (modeling a refraction from the outside air into glass).
    The inner sphere is a bit different because *its* refractive index should be relative
    to the material of the surrounding outer sphere, thus modeling a transition from
    glass into the inner air.
  prefs: []
  type: TYPE_NORMAL
- en: This is actually simple to specify, as the `refraction_index` parameter to the
    dielectric material can be interpreted as the *ratio* of the refractive index
    of the object divided by the refractive index of the enclosing medium. In this
    case, the inner sphere would have an refractive index of air (the inner sphere
    material) over the index of refraction of glass (the enclosing medium), or <nobr
    aria-hidden="true">1.00/1.50=0.67</nobr><mn>1.00</mn><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>1.50</mn><mo>=</mo><mn>0.67</mn>.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 79:** `[main.cc]` Scene with hollow glass sphereAnd here''s the result:[![](https://raytracing.github.io/images/img-1.18-glass-hollow.png)](https://raytracing.github.io/images/img-1.18-glass-hollow.png)Image
    18: A hollow glass sphere'
  prefs: []
  type: TYPE_NORMAL
- en: Positionable Camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cameras, like dielectrics, are a pain to debug, so I always develop mine incrementally.
    First, let’s allow for an adjustable field of view (*fov*). This is the visual
    angle from edge to edge of the rendered image. Since our image is not square,
    the fov is different horizontally and vertically. I always use vertical fov. I
    also usually specify it in degrees and change to radians inside a constructor
    — a matter of personal taste.
  prefs: []
  type: TYPE_NORMAL
- en: Camera Viewing Geometry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we''ll keep the rays coming from the origin and heading to the <nobr
    aria-hidden="true">z=−1</nobr><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn> plane.
    We could make it the <nobr aria-hidden="true">z=−2</nobr><mi>z</mi><mo>=</mo><mo>−</mo><mn>2</mn>
    plane, or whatever, as long as we made <nobr aria-hidden="true">h</nobr><mi>h</mi>
    a ratio to that distance. Here is our setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.18-cam-view-geom.jpg)](https://raytracing.github.io/images/fig-1.18-cam-view-geom.jpg)**Figure 18:**
    Camera viewing geometry (from the side)This implies <nobr aria-hidden="true">h=tan(θ2)</nobr><mi>h</mi><mo>=</mo><mi>tan</mi><mo>⁡</mo><mo
    stretchy="false">(</mo><mfrac><mi>θ</mi><mn>2</mn></mfrac><mo stretchy="false">)</mo>.
    Our camera now becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 80:** `[camera.h]` Camera with adjustable field-of-view (fov)We''ll
    test out these changes with a simple scene of two touching spheres, using a 90°
    field of view.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 81:** `[main.cc]` Scene with wide-angle cameraThis gives us the rendering:[![](https://raytracing.github.io/images/img-1.19-wide-view.png)](https://raytracing.github.io/images/img-1.19-wide-view.png)Image
    19: A wide-angle view'
  prefs: []
  type: TYPE_NORMAL
- en: Positioning and Orienting the Camera
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get an arbitrary viewpoint, let’s first name the points we care about. We’ll
    call the position where we place the camera *lookfrom*, and the point we look
    at *lookat*. (Later, if you want, you could define a direction to look in instead
    of a point to look at.)
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need a way to specify the roll, or sideways tilt, of the camera: the
    rotation around the lookat-lookfrom axis. Another way to think about it is that
    even if you keep `lookfrom` and `lookat` constant, you can still rotate your head
    around your nose. What we need is a way to specify an “up” vector for the camera.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.19-cam-view-dir.jpg)](https://raytracing.github.io/images/fig-1.19-cam-view-dir.jpg)**Figure 19:**
    Camera view direction'
  prefs: []
  type: TYPE_NORMAL
- en: We can specify any up vector we want, as long as it's not parallel to the view
    direction. Project this up vector onto the plane orthogonal to the view direction
    to get a camera-relative up vector. I use the common convention of naming this
    the “view up” (*vup*) vector. After a few cross products and vector normalizations,
    we now have a complete orthonormal basis <nobr aria-hidden="true">(u,v,w)</nobr><mo
    stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>,</mo><mi>w</mi><mo stretchy="false">)</mo>
    to describe our camera’s orientation. <nobr aria-hidden="true">u</nobr><mi>u</mi>
    will be the unit vector pointing to camera right, <nobr aria-hidden="true">v</nobr><mi>v</mi>
    is the unit vector pointing to camera up, <nobr aria-hidden="true">w</nobr><mi>w</mi>
    is the unit vector pointing opposite the view direction (since we use right-hand
    coordinates), and the camera center is at the origin.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.20-cam-view-up.jpg)](https://raytracing.github.io/images/fig-1.20-cam-view-up.jpg)**Figure 20:**
    Camera view up direction'
  prefs: []
  type: TYPE_NORMAL
- en: Like before, when our fixed camera faced <nobr aria-hidden="true">−Z</nobr><mo>−</mo><mi>Z</mi>,
    our arbitrary view camera faces <nobr aria-hidden="true">−w</nobr><mo>−</mo><mi>w</mi>.
    Keep in mind that we can — but we don’t have to — use world up <nobr aria-hidden="true">(0,1,0)</nobr><mo
    stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo>
    to specify vup. This is convenient and will naturally keep your camera horizontally
    level until you decide to experiment with crazy camera angles.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 82:** `[camera.h]` Positionable and orientable cameraWe''ll change
    back to the prior scene, and use the new viewpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 83:** `[main.cc]` Scene with alternate viewpointto get:[![](https://raytracing.github.io/images/img-1.20-view-distant.png)](https://raytracing.github.io/images/img-1.20-view-distant.png)Image
    20: A distant viewAnd we can change field of view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 84:** `[main.cc]` Change field of viewto get:[![](https://raytracing.github.io/images/img-1.21-view-zoom.png)](https://raytracing.github.io/images/img-1.21-view-zoom.png)Image
    21: Zooming in'
  prefs: []
  type: TYPE_NORMAL
- en: Defocus Blur
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now our final feature: *defocus blur*. Note, photographers call this *depth
    of field*, so be sure to only use the term *defocus blur* among your raytracing
    friends.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason we have defocus blur in real cameras is because they need a big
    hole (rather than just a pinhole) through which to gather light. A large hole
    would defocus everything, but if we stick a lens in front of the film/sensor,
    there will be a certain distance at which everything is in focus. Objects placed
    at that distance will appear in focus and will linearly appear blurrier the further
    they are from that distance. You can think of a lens this way: all light rays
    coming *from* a specific point at the focus distance — and that hit the lens —
    will be bent back *to* a single point on the image sensor.'
  prefs: []
  type: TYPE_NORMAL
- en: We call the distance between the camera center and the plane where everything
    is in perfect focus the *focus distance*. Be aware that the focus distance is
    not usually the same as the focal length — the *focal length* is the distance
    between the camera center and the image plane. For our model, however, these two
    will have the same value, as we will put our pixel grid right on the focus plane,
    which is *focus distance* away from the camera center.
  prefs: []
  type: TYPE_NORMAL
- en: In a physical camera, the focus distance is controlled by the distance between
    the lens and the film/sensor. That is why you see the lens move relative to the
    camera when you change what is in focus (that may happen in your phone camera
    too, but the sensor moves). The “aperture” is a hole to control how big the lens
    is effectively. For a real camera, if you need more light you make the aperture
    bigger, and will get more blur for objects away from the focus distance. For our
    virtual camera, we can have a perfect sensor and never need more light, so we
    only use an aperture when we want defocus blur.
  prefs: []
  type: TYPE_NORMAL
- en: A Thin Lens Approximation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A real camera has a complicated compound lens. For our code, we could simulate
    the order: sensor, then lens, then aperture. Then we could figure out where to
    send the rays, and flip the image after it''s computed (the image is projected
    upside down on the film). Graphics people, however, usually use a thin lens approximation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.21-cam-lens.jpg)](https://raytracing.github.io/images/fig-1.21-cam-lens.jpg)**Figure 21:**
    Camera lens model'
  prefs: []
  type: TYPE_NORMAL
- en: We don’t need to simulate any of the inside of the camera — for the purposes
    of rendering an image outside the camera, that would be unnecessary complexity.
    Instead, I usually start rays from an infinitely thin circular “lens”, and send
    them toward the pixel of interest on the focus plane (`focal_length` away from
    the lens), where everything on that plane in the 3D world is in perfect focus.
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, we accomplish this by placing the viewport in this plane. Putting
    everything together:'
  prefs: []
  type: TYPE_NORMAL
- en: The focus plane is orthogonal to the camera view direction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The focus distance is the distance between the camera center and the focus plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The viewport lies on the focus plane, centered on the camera view direction
    vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The grid of pixel locations lies inside the viewport (located in the 3D world).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Random image sample locations are chosen from the region around the current
    pixel location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The camera fires rays from random points on the lens through the current image
    sample location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[![](https://raytracing.github.io/images/fig-1.22-cam-film-plane.jpg)](https://raytracing.github.io/images/fig-1.22-cam-film-plane.jpg)**Figure 22:**
    Camera focus plane'
  prefs: []
  type: TYPE_NORMAL
- en: Generating Sample Rays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without defocus blur, all scene rays originate from the camera center (or `lookfrom`).
    In order to accomplish defocus blur, we construct a disk centered at the camera
    center. The larger the radius, the greater the defocus blur. You can think of
    our original camera as having a defocus disk of radius zero (no blur at all),
    so all rays originated at the disk center (`lookfrom`).
  prefs: []
  type: TYPE_NORMAL
- en: So, how large should the defocus disk be? Since the size of this disk controls
    how much defocus blur we get, that should be a parameter of the camera class.
    We could just take the radius of the disk as a camera parameter, but the blur
    would vary depending on the projection distance. A slightly easier parameter is
    to specify the angle of the cone with apex at viewport center and base (defocus
    disk) at the camera center. This should give you more consistent results as you
    vary the focus distance for a given shot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we''ll be choosing random points from the defocus disk, we''ll need a
    function to do that: `random_in_unit_disk()`. This function works using the same
    kind of method we use in `random_unit_vector()`, just for two dimensions.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 85:** `[vec3.h]` Generate random point inside unit disk'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s update the camera to originate rays from the defocus disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 86:** `[camera.h]` Camera with adjustable depth-of-fieldUsing a large
    aperture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 87:** `[main.cc]` Scene camera with depth-of-fieldWe get:[![](https://raytracing.github.io/images/img-1.22-depth-of-field.png)](https://raytracing.github.io/images/img-1.22-depth-of-field.png)Image
    22: Spheres with depth-of-field'
  prefs: []
  type: TYPE_NORMAL
- en: Where Next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Final Render
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s make the image on the cover of this book — lots of random spheres.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 88:** `[main.cc]` Final scene'
  prefs: []
  type: TYPE_NORMAL
- en: '(Note that the code above differs slightly from the project sample code: the
    `samples_per_pixel` is set to 500 above for a high-quality image that will take
    quite a while to render. The project source code uses a value of 10 in the interest
    of reasonable run times while developing and validating.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives:[![](https://raytracing.github.io/images/img-1.23-book1-final.jpg)](https://raytracing.github.io/images/img-1.23-book1-final.jpg)Image
    23: Final scene'
  prefs: []
  type: TYPE_NORMAL
- en: An interesting thing you might note is the glass balls don’t really have shadows
    which makes them look like they are floating. This is not a bug — you don’t see
    glass balls much in real life, where they also look a bit strange, and indeed
    seem to float on cloudy days. A point on the big sphere under a glass ball still
    has lots of light hitting it because the sky is re-ordered rather than blocked.
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You now have a cool ray tracer! What next?
  prefs: []
  type: TYPE_NORMAL
- en: 'Book 2: *Ray Tracing: The Next Week*'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The second book in this series builds on the ray tracer you''ve developed here.
    This includes new features such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Motion blur — Realistically render moving objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bounding volume hierarchies — speeding up the rendering of complex scenes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Texture maps — placing images on objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perlin noise — a random noise generator very useful for many techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quadrilaterals — something to render besides spheres! Also, the foundation to
    implement disks, triangles, rings or just about any other 2D primitive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lights — add sources of light to your scene.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforms — useful for placing and rotating objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumetric rendering — render smoke, clouds and other gaseous volumes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Book 3: *Ray Tracing: The Rest of Your Life*'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This book expands again on the content from the second book. A lot of this book
    is about improving both the rendered image quality and the renderer performance,
    and focuses on generating the *right* rays and accumulating them appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: This book is for the reader seriously interested in writing professional-level
    ray tracers, and/or interested in the foundation to implement advanced effects
    like subsurface scattering or nested dielectrics.
  prefs: []
  type: TYPE_NORMAL
- en: Other Directions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are so many additional directions you can take from here, including techniques
    we haven''t (yet?) covered in this series. These include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Triangles** — Most cool models are in triangle form. The model I/O is the
    worst and almost everybody tries to get somebody else’s code to do this. This
    also includes efficiently handling large *meshes* of triangles, which present
    their own challenges.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Parallelism** — Run <nobr aria-hidden="true">N</nobr><mi>N</mi> copies of
    your code on <nobr aria-hidden="true">N</nobr><mi>N</mi> cores with different
    random seeds. Average the <nobr aria-hidden="true">N</nobr><mi>N</mi> runs. This
    averaging can also be done hierarchically where <nobr aria-hidden="true">N/2</nobr><mi>N</mi><mrow
    class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>2</mn> pairs can be averaged to get
    <nobr aria-hidden="true">N/4</nobr><mi>N</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>4</mn>
    images, and pairs of those can be averaged. That method of parallelism should
    extend well into the thousands of cores with very little coding.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shadow Rays** — When firing rays at light sources, you can determine exactly
    how a particular point is shadowed. With this, you can render crisp or soft shadows,
    adding another degreee of realism to your scenes.'
  prefs: []
  type: TYPE_NORMAL
- en: Have fun, and please send me your cool images!
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Original Manuscript Help**'
  prefs: []
  type: TYPE_NORMAL
- en: Dave Hart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jean Buckley
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web Release**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Berna Kabadayı](https://github.com/bernakabadayi)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lorenzo Mancini](https://github.com/lmancini)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lori Whippler Hollasch](https://github.com/lorihollasch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ronald Wotzlaw](https://github.com/ronaldfw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Corrections and Improvements**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Aaryaman Vasishta](https://github.com/jammm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrew Kensler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Antonio Gamiz](https://github.com/antoniogamiz)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apoorva Joshi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Aras Pranckevičius](https://github.com/aras-p)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arman Uguray](https://github.com/armansito)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Becker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ben Kerl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benjamin Summerton
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bennett Hardwick
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Benny Tsang](https://bthtsang.github.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dan Drummond
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[David Chambers](https://github.com/dafhi)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: David Hart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dimitry Ishenko](https://github.com/dimitry-ishenko)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dmitry Lomov](https://github.com/mu-lambda)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Eric Haines](https://github.com/erich666)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fabio Sancinetti
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filipe Scur
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frank He
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gareth Martin](https://github.com/TheThief)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gerrit Wessendorf](https://github.com/celeph)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grue Debry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gustaf Waldemarson](https://github.com/xaldew)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ingo Wald
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jason Stone
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[JC-ProgJava](https://github.com/JC-ProgJava)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jean Buckley
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Jeff Smith](https://github.com/whydoubt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joey Cho
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[John Kilpatrick](https://github.com/rjkilpatrick)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaan Eraslan](https://github.com/D-K-E)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lorenzo Mancini](https://github.com/lmancini)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Manas Kale](https://github.com/manas96)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marcus Ottosson
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mark Craig](https://github.com/mrmcsoftware)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markus Boos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matthew Heimlich
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nakata Daisuke
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nate Rupsis](https://github.com/rupsis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Niccolò Tiezzi](https://github.com/niccolot)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paul Melis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phil Cristensen
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LollipopFt](https://github.com/LollipopFt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ronald Wotzlaw](https://github.com/ronaldfw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Shaun P. Lee](https://github.com/shaunplee)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Shota Kawajiri](https://github.com/estshorter)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tatsuya Ogawa
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thiago Ize
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Thien Tran](https://github.com/gau-nernst)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vahan Sosoyan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WANG Lei](https://github.com/wlbksy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Yann Herklotz](https://github.com/ymherklotz)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ZeHao Chen](https://github.com/oxine)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Special Thanks**Thanks to the team at [Limnu](https://limnu.com/) for help
    on the figures.'
  prefs: []
  type: TYPE_NORMAL
- en: These books are entirely written in Morgan McGuire's fantastic and free [Markdeep](https://casual-effects.com/markdeep/)
    library. To see what this looks like, view the page source from your browser.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to [Helen Hu](https://github.com/hhu) for graciously donating her [https://github.com/RayTracing/](https://github.com/RayTracing/)
    GitHub organization to this project.
  prefs: []
  type: TYPE_NORMAL
- en: <link rel="stylesheet" href="https://raytracing.github.io/books/../style/book.css">
  prefs: []
  type: TYPE_NORMAL
- en: Citing This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consistent citations make it easier to identify the source, location and versions
    of this work. If you are citing this book, we ask that you try to use one of the
    following forms if possible.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Title (series)**: “Ray Tracing in One Weekend Series”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Title (book)**: “Ray Tracing in One Weekend”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Author**: Peter Shirley, Trevor David Black, Steve Hollasch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version/Edition**: v4.0.2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Date**: 2025-04-25'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**URL (series)**: [https://raytracing.github.io](https://raytracing.github.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**URL (book)**: [https://raytracing.github.io/books/raytracinginoneweekend.html](https://raytracing.github.io/books/raytracinginoneweekend.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snippets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Markdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: HTML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: LaTeX and BibTex
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: BibLaTeX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: IEEE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'MLA:'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: <link rel="stylesheet" href="../style/book.css">
  prefs: []
  type: TYPE_NORMAL
