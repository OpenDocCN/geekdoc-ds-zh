- en: External Sorting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/external-memory/sorting/](https://en.algorithmica.org/hpc/external-memory/sorting/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now, let’s try to design some actually useful algorithms for the new [external
    memory model](../model). Our goal in this section is to slowly build up more complex
    things and eventually get to *external sorting* and its interesting applications.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm will be based on the standard merge sorting algorithm, so we need
    to derive its main primitive first.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/external-memory/sorting/#merge)Merge'
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem.** Given two sorted arrays $a$ and $b$ of lengths $N$ and $M$, produce
    a single sorted array $c$ of length $N + M$ containing all of their elements.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard two-pointer technique for merging sorted arrays looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In terms of memory operations, we just linearly read all elements of $a$ and
    $b$ and linearly write all elements of $c$. Since these reads and writes can be
    buffered, it works in $SCAN(N+M)$ I/O operations.
  prefs: []
  type: TYPE_NORMAL
- en: So far the examples have been simple, and their analysis doesn’t differ too
    much from the RAM model, except that we divide the final answer by the block size
    $B$. But here is a case where this is not so.
  prefs: []
  type: TYPE_NORMAL
- en: '**$k$-way merging.** Consider the modification of this algorithm where we need
    to merge not just two arrays, but $k$ arrays of total size $N$ — by likewise looking
    at $k$ values, choosing the minimum between them, writing it into $c$, and incrementing
    one of the iterators.'
  prefs: []
  type: TYPE_NORMAL
- en: In the standard RAM model, the asymptotic complexity would be multiplied $k$,
    since we would need to perform $O(k)$ comparisons to fill each next element. But
    in the external memory model, since everything we do in-memory doesn’t cost us
    anything, its asymptotic complexity would not change as long as we can fit $(k+1)$
    full blocks in memory, that is, if $k = O(\frac{M}{B})$.
  prefs: []
  type: TYPE_NORMAL
- en: Remember [the $M \gg B$ assumption](../model) when we introduced the computational
    model? If we have $M \geq B^{1+ε}$ for $\epsilon > 0$, then we can fit any sub-polynomial
    number of blocks in memory, certainly including $O(\frac{M}{B})$. This condition
    is called *tall cache assumption*, and it is usually required in many other external
    memory algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/external-memory/sorting/#merge-sorting)Merge
    Sorting'
  prefs: []
  type: TYPE_NORMAL
- en: 'The “normal” complexity of the standard mergesort algorithm is $O(N \log_2
    N)$: on each of its $O(\log_2 N)$ “layers,” the algorithms need to go through
    all $N$ elements in total and merge them in linear time.'
  prefs: []
  type: TYPE_NORMAL
- en: In the external memory model, when we read a block of size $M$, we can sort
    its elements “for free,” since they are already in memory. This way we can split
    the arrays into $O(\frac{N}{M})$ blocks of consecutive elements and sort them
    separately as the base step, and only then merge them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4434bb57f07289c2f870ab1d0b2b9e4c.png)'
  prefs: []
  type: TYPE_IMG
- en: This effectively means that, in terms of I/O operations, the first $O(\log M)$
    layers of mergesort are free, and there are only $O(\log_2 \frac{N}{M})$ non-zero-cost
    layers, each mergeable in $O(\frac{N}{B})$ IOPS in total. This brings total I/O
    complexity to
  prefs: []
  type: TYPE_NORMAL
- en: $$ O\left(\frac{N}{B} \log_2 \frac{N}{M}\right) $$
  prefs: []
  type: TYPE_NORMAL
- en: This is quite fast. If we have 1GB of memory and 10GB of data, this essentially
    means that we need a little bit more than 3 times the effort than just reading
    the data to sort it. Interestingly enough, we can do better.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/external-memory/sorting/#k-way-mergesort)$k$-way
    Mergesort'
  prefs: []
  type: TYPE_NORMAL
- en: Half of a page ago we have learned that in the external memory model, we can
    merge $k$ arrays just as easily as two arrays — at the cost of reading them. Why
    don’t we apply this fact here?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s sort each block of size $M$ in-memory just as we did before, but during
    each merge stage, we will split sorted blocks not just in pairs to be merged,
    but take as many blocks we can fit into our memory during a $k$-way merge. This
    way the height of the merge tree would be greatly reduced, while each layer would
    still be done in $O(\frac{N}{B})$ IOPS.
  prefs: []
  type: TYPE_NORMAL
- en: How many sorted arrays can we merge at once? Exactly $k = \frac{M}{B}$, since
    we need memory for one block for each array. Since the total number of layers
    will be reduced to $\log_{\frac{M}{B}} \frac{N}{M}$, the total complexity will
    be reduced to
  prefs: []
  type: TYPE_NORMAL
- en: $$ SORT(N) \stackrel{\text{def}}{=} O\left(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{M}
    \right) $$
  prefs: []
  type: TYPE_NORMAL
- en: Note that, in our example, we have 10GB of data, 1GB of memory, and the block
    size is around 1MB for HDD. This makes $\frac{M}{B} = 1000$ and $\frac{N}{M} =
    10$, and so the logarithm is less than one (namely, $\log_{1000} 10 = \frac{1}{3}$).
    Of course, we can’t sort an array faster than reading it, so this analysis applies
    to the cases when we have a very large dataset, small memory, and/or large block
    sizes, which rarely happens in real life these days.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/external-memory/sorting/#practical-implementation)Practical
    Implementation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Under more realistic constraints, instead of using $\log_{\frac{M}{B}} \frac{N}{M}$
    layers, we can use just two: one for sorting data in blocks of $M$ elements, and
    another one for merging all of them at once. This way, from the I/O operations
    perspective, we just loop around our dataset twice. And with a gigabyte of RAM
    and a block size of 1MB, this way can sort arrays up to a terabyte in size.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the first phase looks in C++. This program opens a multi-gigabyte
    binary file with unsorted integers, reads it in blocks of 256MB, sorts them in
    memory, and then writes them back in files named `part-000.bin`, `part-001.bin`,
    `part-002.bin`, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'What is left now is to merge them together. The bandwidth of modern HDDs can
    be quite high, and there may be a lot of parts to merge, so the I/O efficiency
    of this stage is not our only concern: we also need a faster way to merge $k$
    arrays than by finding minima with $O(k)$ comparisons. We can do that in $O(\log
    k)$ time per element if we maintain a min-heap for these $k$ elements, in a manner
    almost identical to heapsort.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to implement it. First, we are going to need a heap (`priority_queue`
    in C++):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to allocate and fill the buffers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we just need to pop elements from the heap into the result file until it
    is empty, carefully writing and reading elements in batches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This implementation is not particularly effective or safe-looking (well, this
    is basically plain C), but is a good educational example of how to work with low-level
    memory APIs.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/external-memory/sorting/#joining)Joining'
  prefs: []
  type: TYPE_NORMAL
- en: Sorting is mainly used not by itself, but as an intermediate step for other
    operations. One important real-world use case of external sorting is joining (as
    in “SQL join”), used in databases and other data processing applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem.** Given two lists of tuples $(x_i, a_{x_i})$ and $(y_i, b_{y_i})$,
    output a list $(k, a_{x_k}, b_{y_k})$ such that $x_k = y_k$'
  prefs: []
  type: TYPE_NORMAL
- en: The optimal solution would be to sort the two lists and then use the standard
    two-pointer technique to merge them. The I/O complexity here would be the same
    as sorting, and just $O(\frac{N}{B})$ if the arrays are already sorted. This is
    why most data processing applications (databases, MapReduce systems) like to keep
    their tables at least partially sorted.
  prefs: []
  type: TYPE_NORMAL
- en: '**Other approaches.** Note that this analysis is only applicable in the external
    memory setting — that is, if you don’t have the memory to read the entire dataset.
    In the real world, alternative methods may be faster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest of them is probably *hash join*, which goes something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In external memory, joining two lists with a hash table would be unfeasible,
    as it would involve doing $O(M)$ block reads, even though only one element is
    used in each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Another method is to use alternative sorting algorithms such as radix sort.
    In particular, radix sort would work in $O(\frac{N}{B} \cdot w)$ block reads if
    enough memory is available to maintain buffers for all possible keys, and it could
    be faster in the case of small keys and large datasets. [← External Memory Model](https://en.algorithmica.org/hpc/external-memory/model/)[List
    Ranking →](https://en.algorithmica.org/hpc/external-memory/list-ranking/)
  prefs: []
  type: TYPE_NORMAL
