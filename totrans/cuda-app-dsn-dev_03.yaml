- en: Chapter 2\. CUDA for Machine Learning and OptimizationGPGPUs are powerful tools
    that are well-suited to unraveling complex real-world problems. Using only the
    simple CUDA capabilities introduced in [Chapter 1](B978012388426800001X.xhtml#B978-0-12-388426-8.00001-X),
    this chapter demonstrates how to greatly accelerate nonlinear optimization problems
    using the derivative-free Nelder-Mead and Levenberg-Marquardt optimization algorithms.
    Single- and double-precision application performance will be measured and compared
    between an Intel Xeon e5630 processor and an NVIDIA C2070 GPU as well as an older
    10-series NVIDIA GTX 280 gaming GPU. Working example code is provided that can
    train the classic nonlinear XOR machine-learning problem 85 times faster than
    a modern quad-core Intel Xeon processor (341 times faster than single-core performance)
    under Linux with comparable performance under Windows 7.**Keywords**Functor, Machine
    learning, Order of Magnitude, Optimization, Computational universal, Nelder-Mead,
    Levenburg-Marquardt, Curse of dimensionality, neural networkGPGPUs are powerful
    tools that are well-suited to unraveling complex real-world problems. Using only
    the simple CUDA capabilities introduced in [Chapter 1](B978012388426800001X.xhtml#B978-0-12-388426-8.00001-X),
    this chapter demonstrates how to greatly accelerate nonlinear optimization problems
    using the derivative-free Nelder-Mead and Levenberg-Marquardt optimization algorithms.
    Single- and double-precision application performance will be measured and compared
    between an Intel Xeon e5630 processor and an NVIDIA C2070 GPU as well as an older
    10-series NVIDIA GTX 280 gaming GPU. Working example code is provided that can
    train the classic nonlinear XOR machine-learning problem 85 times faster than
    a modern quad-core Intel Xeon processor (341 times faster than single-core performance)
    under Linux with comparable performance under Windows 7.At the end of the chapter,
    the reader will have a basic understanding of:■ Two popular optimization techniques,
    including GPU scalability limitations of the Levenberg-Marquardt algorithm■ How
    a CUDA-literate programmer can make significant contributions to modeling and
    data-mining efforts■ Machine learning and why the XOR problem is important to
    computationally universal devices■ C++ functors and how to write a single Thrust
    functor using **__host__** and **__device__** qualifiers that can run on both
    host and GPGPU devices■ Some example programs that demonstrate orders-of-magnitude
    increased performance over a conventional processor on techniques that can be
    applied to problems in machine learning, signal processing, statistics, and many
    other fields
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '第2章 CUDA在机器学习与优化中的应用  '
- en: Modeling and Simulation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模与仿真
- en: Mathematical modeling and numerical simulation are two important, distinct,
    and closely linked aspects of applied mathematics. A mathematical model is an
    abstraction of reality that can be used for analysis and prediction. Numerical
    simulation is based on applications that map mathematical models onto the computer.
    In combination, modeling and simulation are powerful techniques to advance human
    understanding of complex phenomena.This book does not attempt to duplicate or
    shed new insight on the tremendous volume of work that has already been published
    concerning modeling and simulation. Depending on your particular area of interest,
    there are a number of excellent texts available that provide both precise and
    detailed introductions. Our focus is to provide the tools needed to exploit massively
    parallel hardware with CUDA so that readers can make their own contributions in
    their field of choice.Two general approaches are utilized to create models:1\.
    Human-derived models based on first-principle analysis and other techniquesWhen
    available, these models provide deep insight into the phenomena being investigated.
    A literate CUDA programmer can contribute by efficiently mapping the calculations
    to the parallel hardware to achieve the highest performance and scale to the largest
    number of processing elements possible. The literature shows that a well-designed
    and written CUDA application can provide two orders of magnitude increased performance
    ([Hwu, 2011](B978012388426800015X.xhtml#ref72); [Stone et al., 2010](B978012388426800015X.xhtml#ref123)).
    Such performance is disruptive, as simulations that previously would have taken
    a year can finish in a few days. Greater simulation accuracy is also possible
    as more accurate and detailed approximations can be utilized. Nonlinear problems
    particularly benefit from the NVIDIA Special Function Units (SFU) that calculate
    several transcendental functions (such as **log**(), **exp**(), **sin()**, **cos**(),
    and others) approximately 25 times faster than conventional processors.2\. Parameterized
    models derived by fitting dataComputationally derived models from data are relatively
    simple to construct compared to human-derived models. Many techniques exist that
    can create accurate models that generalize well. Neural networks are one example
    ([Lapedes & Farber, 1987b](B978012388426800015X.xhtml#ref84)). In general, the
    process of fitting a model to data is a computationally expensive process, with
    runtimes that grow by O(*N*²) and higher, where *N* is the number of data items.
    Parallelism can make many of these methods tractable and even interactive by reducing
    the runtime by some factor close to the number of processing elements. Containing
    hundreds of processing elements, a single GPU has the potential to reduce runtimes
    by two or more orders of magnitude. Clever partitioning of the problem across
    multiple GPUs can scale the number of available processing element by the number
    of GPUs.Particular challenges arise when modeling systems that exhibit *nonlinear*
    behavior. A nonlinear system does not always respond proportionally to an input
    stimulus, which means their behavior cannot be modeled solely on the basis of
    some linear combination of the input or system stimulus. Although challenging,
    nonlinear systems give rise to many interesting phenomena including self-organizing
    systems, chaotic behavior, and life.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数学建模和数值模拟是应用数学中两个重要、独立但又紧密联系的方面。数学模型是现实的抽象，可用于分析和预测。数值模拟基于将数学模型映射到计算机应用中。结合起来，建模和模拟是推进人类对复杂现象理解的强大技术。本书不打算复制或为已经发表的大量建模和模拟工作提供新的洞见。根据你的特定兴趣领域，有许多优秀的文献提供精确和详细的介绍。我们的重点是提供利用CUDA进行大规模并行硬件的工具，以便读者在自己选择的领域做出贡献。创建模型有两种通用方法：1.
    基于第一原理分析和其他技术的人类派生模型，当这些模型可用时，它们能够深入了解正在研究的现象，一位通晓CUDA编程的人可以通过将计算高效映射到并行硬件来提高性能，并能扩展到尽可能多的处理单元。文献显示，设计良好且编写良好的CUDA应用程序能够提供两个数量级的性能增加（[Hwu,
    2011](B978012388426800015X.xhtml#ref72); [Stone et al., 2010](B978012388426800015X.xhtml#ref123)）。这样的性能是颠覆性的，以前需要一年才能完成的模拟现在可以在几天内完成。通过使用更准确和详细的逼近可以实现更高的模拟精度，尤其是非线性问题可以从NVIDIA的特殊功能单元（SFU）中获益，这些单元计算几个超越函数（例如**log**()、**exp**()、**sin()**、**cos**()等）的速度约为传统处理器的25倍。2.
    参数化模型通过拟合数据推导的参数化模型比人类派生模型构建起来要简单得多，有许多技术可以创建能够很好概括的准确模型，神经网络就是一个例子（[Lapedes &
    Farber, 1987b](B978012388426800015X.xhtml#ref84)）。总的来说，将模型拟合到数据的过程是一个计算成本昂贵的过程，其运行时间按O(*N*²)及更高速度增长，其中*N*是数据项的数量。并行处理可以使许多这些方法变得可行，甚至通过将运行时间减少到接近处理单元数量的因子，使其具有交互性。包含数百个处理单元的单个GPU有可能将运行时间减少两个以上数量级。通过在多个GPU上巧妙地分割问题，可以按GPU数量扩展可用处理单元的数量。在建模表现非线性行为的系统时会遇到特定挑战。非线性系统不总是按照输入刺激成比例地响应，这意味着其行为不能仅基于某些输入或系统刺激的线性组合建模。尽管具有挑战性，非线性系统引发许多有趣的现象，包括自组织系统、混沌行为和生命现象。
- en: Fitting Parameterized Models
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合参数化模型
- en: Model fitting can be phrased as a form of function optimization in which a set
    of model parameters, *P*, are adjusted to fit some data set with a minimum error.
    The error is determined by an *objective function*, sometimes called a *cost function*,
    which evaluates how well a model fits a data set for some set of model parameters.
    A common technique is to fit a curve to a set of *N* data points to minimize the
    sum of the squares of the distances between the predicted and known points on
    the curve. See [Equation 2.1](#fm0010), “Sum of squares of differences error.”(2.1)![B9780123884268000021/si1.gif
    is missing](B9780123884268000021/si1.gif)Because the sum of the squares of the
    differences is always positive, a perfect fit will result in a zero error. Unfortunately,
    this rarely occurs because most numerical techniques are subject to *local minima*,
    which means that the numerical technique somehow gets stuck at a low point in
    the cost function from which it cannot escape. As a result, no guarantee can be
    made that the *global minimum* or best overall fit has been found.There are a
    number of popular libraries and tools that can be used to find the minimum of
    a function over many variables. The book *Numerical Recipes* is an excellent source
    of information ([Press et al., 2007](B978012388426800015X.xhtml#ref106)), which
    also provides working source code. [¹](#fn0010) Many free and licensed numerical
    toolkits are available, including SLATEC, NAG (Numerical Algorithms Group), MINPACK,
    the GNU scientific library, MATLAB, Octave, scipy, gnuplot, SAS, Maple, Mathematica,
    STATLIB, and a plethora of others.¹The *Numerical Recipes* source code is copyrighted
    and will not be used, as we prefer to provide complete working examples.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 模型拟合可以被表述为一种函数优化形式，其中一组模型参数，*P*，会被调整以最小化误差并拟合某个数据集。误差由*目标函数*确定，有时也称为*代价函数*，它评估模型对于一组模型参数在数据集上的拟合程度。一种常见的技术是将曲线拟合到一组*N*数据点，以最小化预测点与已知点在曲线上的距离的平方和。参见[公式
    2.1](#fm0010)，“差异平方和误差”。(2.1)![B9780123884268000021/si1.gif is missing](B9780123884268000021/si1.gif)由于差异的平方和始终是正数，因此完美拟合将导致零误差。不幸的是，这种情况很少发生，因为大多数数值技术都容易受到*局部最小值*的影响，这意味着数值方法可能会在代价函数的某个低点处停滞，无法逃脱。因此，无法保证找到*全局最小值*或最佳整体拟合。许多流行的库和工具可以用来寻找多变量函数的最小值。书籍《数值方法》是一个极好的信息来源（[Press
    等人, 2007](B978012388426800015X.xhtml#ref106)），它还提供了可工作的源代码。[¹](#fn0010)有许多免费的和授权的数值工具包可用，包括SLATEC、NAG（数值算法组）、MINPACK、GNU科学库、MATLAB、Octave、scipy、gnuplot、SAS、Maple、Mathematica、STATLIB等大量工具包。¹《数值方法》的源代码是受版权保护的，因此我们不会使用它，因为我们更倾向于提供完整的工作示例。
- en: Nelder-Mead Method
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nelder-Mead 方法
- en: The Nelder-Mead method is a commonly used *direct search* nonlinear optimization
    technique ([Nelder & Mead, 1965](B978012388426800015X.xhtml#ref101)). The algorithm
    performs a search using a *simplex*, which is a generalized triangle in *N* dimensions.
    The method evaluates a user-provided function at each of the vertices and then
    iteratively shrinks the simplex as better points are found. The method terminates
    when a desired bound or other termination condition is reached.With some limitations
    ([McKinnon & McKinnon, 1999](B978012388426800015X.xhtml#ref93); [Kolda, Lewis,
    & Torczon, 2007](B978012388426800015X.xhtml#ref80)), the Nelder-Mead method has
    proven to be effective over time plus it is computationally compact. The original
    FORTRAN implementation was made available through STATLIB. John Burkhardt created
    a clean C-language implementation that he made freely available on his website.
    [²](#fn0015) The C++ template adaption of his code at the end of this chapter
    allows easy comparison of both single- and double-precision host and GPU performance.²[http://people.sc.fsu.edu/~jburkardt/cpp_src/asa047/asa047.html](http://people.sc.fsu.edu/~jburkardt/cpp_src/asa047/asa047.html).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Nelder-Mead 方法是一种常用的*直接搜索*非线性优化技术（[Nelder & Mead, 1965](B978012388426800015X.xhtml#ref101)）。该算法使用一个*单纯形*进行搜索，单纯形是*N*维空间中的一种广义三角形。该方法在每个顶点上评估用户提供的函数，然后在找到更好的点时逐步缩小单纯形。当达到所需的边界或其他终止条件时，方法终止。尽管存在一些限制（[McKinnon
    & McKinnon, 1999](B978012388426800015X.xhtml#ref93)；[Kolda, Lewis, & Torczon,
    2007](B978012388426800015X.xhtml#ref80)），Nelder-Mead 方法随着时间的推移被证明是有效的，并且计算上非常紧凑。原始的
    FORTRAN 实现通过 STATLIB 提供。John Burkhardt 创建了一个简洁的 C 语言实现，并将其免费提供在他的网站上。[²](#fn0015)
    本章末尾的 C++ 模板改编允许轻松比较单精度和双精度主机与 GPU 的性能。²[http://people.sc.fsu.edu/~jburkardt/cpp_src/asa047/asa047.html](http://people.sc.fsu.edu/~jburkardt/cpp_src/asa047/asa047.html)。
- en: Levenberg-Marquardt Method
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Levenberg-Marquardt 方法
- en: The Levenberg-Marquardt algorithm (LMA) is a popular *trust region* algorithm
    that is used to find a minimum of a function (either linear or nonlinear) over
    a space of parameters. Essentially, a trusted region of the objective function
    is internally modeled with some function such as a quadratic. When an adequate
    fit is found, the trust region is expanded. As with many numerical techniques,
    the Levenberg-Marquardt method can be sensitive to the initial starting parameters.
    An excellent technical overview on the Levenberg-Marquardt with references is
    on the levmar website. [³](#fn0020) Another excellent resource is *Numerical Recipes*.³[http://www.ics.forth.gr/~lourakis/levmar/index.html#download](http://www.ics.forth.gr/~lourakis/levmar/index.html#download).In
    traditional Levenberg-Marquardt implementations, *finite differences* are used
    to approximate the *Jacobian*. The Jacobian is a matrix of all first-order partial
    derivatives of the function being optimized. This matrix is convenient, as the
    user need only supply a single function to the library.The original FORTRAN public
    domain MINPACK routine lmdif has proven to be a reliable piece of software over
    the decades—so much so that a variety of implementations has been created in many
    computer languages. Two excellent C/C++ implementations are levmar and lmfit.For
    comparison purposes, the levmar library has been used in the examples because
    it provides both single- and double-precision routines. The reader will have to
    download and install the levmar package to run those examples. The levmar website
    provides installation instructions for both Microsoft and UNIX-based systems.To
    support both single- and double-precision performance testing, wrappers were created
    that utilize C++ *polymorphism* to make the appropriate library call depending
    on type of the parameters passed to the wrapper. These wrappers also provide the
    necessary interface to pass an objective function to the levmar library, which
    expects a pointer to a function. See [Example 2.1](#tb0010), “Using a Wrapper
    to Account for Variable Type.”`//wrapper around the levmar single- and double-precision
    calls``inline int levmar_dif( void (*func)(float *, float *, int, int, void *),``float
    *p, float *x, int m, int n, int itmax,``float *opts, float *info, float *work,
    float *covar, void* data)``{``return slevmar_dif(func, p, x, m, n, itmax, opts,
    info, work, covar, data);``}``inline int levmar_dif( void (*func)(double *, double
    *, int, int, void *),``double *p, double *x, int m, int n, int itmax,``double
    *opts, double *info, double *work, double *covar, void* data)``{``return dlevmar_dif(func,
    p, x, m, n, itmax, opts, info, work, covar, data);``}`
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Levenberg-Marquardt 算法（LMA）是一种流行的*信赖区域*算法，用于在参数空间中寻找一个函数（无论是线性还是非线性）的最小值。实质上，目标函数的信赖区域通过某种函数（例如二次函数）进行内建建模。当找到合适的拟合时，信赖区域会被扩展。与许多数值技术一样，Levenberg-Marquardt
    方法可能对初始参数敏感。有关 Levenberg-Marquardt 的优秀技术概述以及参考资料可以在 levmar 网站上找到。[³](#fn0020)
    另一个优秀的资源是*Numerical Recipes*。³[http://www.ics.forth.gr/~lourakis/levmar/index.html#download](http://www.ics.forth.gr/~lourakis/levmar/index.html#download)。在传统的
    Levenberg-Marquardt 实现中，*有限差分*被用来近似*雅可比矩阵*。雅可比矩阵是一个包含被优化函数所有一阶偏导数的矩阵。这个矩阵非常方便，因为用户只需提供一个函数给库即可。原始的
    FORTRAN 公共领域 MINPACK 例程 lmdif 多年来证明是一个可靠的软件——甚至已经被多种编程语言实现。两个优秀的 C/C++ 实现是 levmar
    和 lmfit。为了比较目的，示例中使用了 levmar 库，因为它提供了单精度和双精度例程。读者需要下载并安装 levmar 包才能运行这些示例。levmar
    网站提供了适用于 Microsoft 和 UNIX 系统的安装说明。为了支持单精度和双精度性能测试，创建了利用 C++ *多态性* 的包装器，根据传递给包装器的参数类型，调用适当的库函数。这些包装器还提供了必要的接口，以将目标函数传递给
    levmar 库，后者期望一个指向函数的指针。请参见[示例 2.1](#tb0010)，“使用包装器考虑变量类型。”`//包装器，用于 levmar 的单精度和双精度调用``inline
    int levmar_dif( void (*func)(float *, float *, int, int, void *),``float *p, float
    *x, int m, int n, int itmax,``float *opts, float *info, float *work, float *covar,
    void* data)``{``return slevmar_dif(func, p, x, m, n, itmax, opts, info, work,
    covar, data);``}``inline int levmar_dif( void (*func)(double *, double *, int,
    int, void *),``double *p, double *x, int m, int n, int itmax,``double *opts, double
    *info, double *work, double *covar, void* data)``{``return dlevmar_dif(func, p,
    x, m, n, itmax, opts, info, work, covar, data);``}``
- en: Algorithmic Speedups
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 算法加速
- en: For the purposes of this book, only the evaluation of the objective function
    will be discussed. The reader should note that approximating the gradient numerically
    can impose a time to solution penalty.Many optimization techniques, such as conjugate
    gradient, can greatly accelerate the process of finding a minimum by using a function,
    **dfunc()**, that calculates the derivative of the objective function. Saunders,
    Simon, and Yip pointed out that conjugate gradient is guaranteed to terminate
    after a finite number of steps (in exact arithmetic), that some measure of the
    error is decreased at every step of the method, and that the computational requirements
    for each step are constant ([Saunders, Simon, & Yip, 1988](B978012388426800015X.xhtml#ref111)).
    In practice, accumulated floating-point roundoff errors cause a gradual loss of
    accuracy, which affects the convergence rate. Even so, conjugate gradient is widely
    used for problems that are out of reach of exact algorithms.Many symbolic differentiation
    tools exist to help the programmer write or automatically generate derivatives
    using symbolic math. One example is GiNaC (GiNaC stands for GiNaC is Not a CAS,
    where CAS stands for Computer Algebra System). GiNaC is a freely downloadable
    C++ library that programmers can use to incorporate symbolic math into their applications.
    Unlike other symbolic mathematical packages, GiNaC takes C++ as input. The programmer
    can then use the algebraic capabilities of the library to perform useful tasks
    such as symbolic differentiation. The GiNaC website ([http://www.gniac.de](http://www.gniac.de))
    claims it was designed to be a drop-in replacement for the symbolic math engine
    that powers the popular Maple CAS. Other packages include Maple and Mathematica.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书仅讨论目标函数的评估。读者应注意，数值近似梯度可能会带来求解时间的惩罚。许多优化技术，如共轭梯度法，通过使用计算目标函数导数的函数**dfunc()**，能够大大加速找到最小值的过程。Saunders、Simon和Yip指出，共轭梯度法在有限步数后保证终止（在精确算术下），并且该方法每一步都会减少某种误差度量，而且每步的计算要求是恒定的（[Saunders,
    Simon, & Yip, 1988](B978012388426800015X.xhtml#ref111)）。在实践中，累积的浮点数舍入误差会导致精度逐渐丧失，从而影响收敛速度。尽管如此，共轭梯度法仍广泛应用于无法使用精确算法解决的问题。许多符号微分工具存在，帮助程序员编写或自动生成使用符号数学的导数。例如GiNaC（GiNaC代表GiNaC
    is Not a CAS，其中CAS代表计算机代数系统）。GiNaC是一个可以自由下载的C++库，程序员可以将其用于将符号数学集成到他们的应用程序中。与其他符号数学包不同，GiNaC将C++作为输入。程序员可以利用该库的代数功能执行有用的任务，如符号微分。GiNaC网站（[http://www.gniac.de](http://www.gniac.de)）声称它被设计为替代流行的Maple
    CAS背后的符号数学引擎。其他的包还包括Maple和Mathematica。
- en: Machine Learning and Neural Networks
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与神经网络
- en: Artificial Neural Networks (ANN) is a machine-learning technique that infers
    a function (a form of parameterized model) based on observed data. *Supervised
    learning* occurs when a teacher associates known values that reflect a desired
    or known outcome with each training example. *Unsupervised learning* occurs when
    a metric of goodness or fit is provided.Functions inferred by neural networks
    have predictive power, meaning they can correctly forecast future values in a
    time series, respond and adapt to complex and unforeseen stimuli, and perform
    classification tasks. A famous early example is nettalk, which trained a neural
    network to read English text aloud ([Sejnowski & Rosenberg, 1987](B978012388426800015X.xhtml#ref117)).
    The nettalk data is still available for download. [⁴](#fn0025)⁴[http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Nettalk+Corpus)](http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Nettalk+Corpus)).Training
    artificial neural networks can be expressed as a function optimization problem
    that seeks to determine the best network parameters (e.g., the internal network
    weights and biases) that will minimize the error on an initial data set. The fitting
    or training process is computationally expensive, as it requires repeatedly calling
    an objective function with sets of parameters that are evaluated over every example
    in the training data. The runtime is O(*N*[param] × *N*[data]) for each objective
    function evaluation. In most cases, the number of parameters is small relative
    to the size of the training data, which means the overall runtime is dominated
    by the size of the data set.During the training process, the neural net is attempting
    to fit a multidimensional surface to the training data ([Lapedes & Farber, 1987a](B978012388426800015X.xhtml#ref84)).
    Unfortunately, *the curse of dimensionality* tells us that the volume of space
    that must be searched, sampled, and modeled increases exponentially with the dimension
    of the data. For example, uniformly sampling a 1D unit interval between 0 and
    1 at steps of 0.01 requires 100 samples, and sampling a 10-dimensional unit hypercube
    would require (100)^(10) or 10^(20) samples. [⁵](#fn0030) Even with sparse sampling,
    smooth high-dimensional surfaces can require many data points. Many interesting
    phenomena require fitting convoluted, bumpy, high-dimensional surfaces, which
    can dramatically increase the amount of training data needed to fit a model that
    can approximate the multidimensional surface with acceptable accuracy.⁵This example
    was adapted from the [Wikipedia.org](http://Wikipedia.org)“Curse of Dimensionality”
    example. [http://en.wikipedia.org/wiki/Curse_of_dimensionality](http://en.wikipedia.org/wiki/Curse_of_dimensionality))Expensive
    objective functions tend to dominate the runtime when using popular optimization
    techniques like Nelder-Mead, Levenberg-Marquardt, Powell's method, conjugate gradient,
    and others. Under these circumstances, it is best to focus on reducing the runtime
    of the objective function. Mapping the problem efficiently to a GPGPU with hundreds
    of parallel threads can potentially reduce the runtime by two orders of magnitude
    over a single-threaded system, as shown by [Equation 2.2](#fm0015), “Parallel
    runtime of an ANN-based objective function.” Conversely, a quad-core processor
    can reduce the runtime only by a factor of 4 at best over a serial implementation.(2.2)![B9780123884268000021/si2.gif
    is missing](B9780123884268000021/si2.gif)The examples in this chapter demonstrate
    that CUDA can reduce the runtime by 50 to 100 times over an implementation that
    runs on a conventional mult-core processor even when taking into account all of
    the GPU communications overhead. Although this is a known result for parallel
    systems in general ([Farber, 1992](B978012388426800015X.xhtml#ref44); [Thearling,
    1995](B978012388426800015X.xhtml#ref132)), it is amazing that this level of performance
    can be achieved even using a gaming GPU.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANN）是一种机器学习技术，它基于观察到的数据推断一个函数（即一种带参数的模型）。当教师将反映期望或已知结果的已知值与每个训练示例相关联时，*监督学习*就发生了。当提供了一个优度或拟合度度量时，*无监督学习*就会发生。由神经网络推断出的函数具有预测能力，这意味着它们能够正确预测时间序列中的未来值，响应并适应复杂和不可预见的刺激，并执行分类任务。一个著名的早期示例是nettalk，它训练了一个神经网络来朗读英语文本（[Sejnowski
    & Rosenberg, 1987](B978012388426800015X.xhtml#ref117)）。nettalk数据仍然可以下载。[⁴](#fn0025)⁴[http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Nettalk+Corpus)](http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Nettalk+Corpus))。训练人工神经网络可以表达为一个函数优化问题，目标是确定最佳的网络参数（例如，内部网络的权重和偏置），以最小化初始数据集上的误差。拟合或训练过程是计算上昂贵的，因为它需要反复调用目标函数，并对训练数据中的每个示例评估参数集。每次目标函数评估的运行时间是O(*N*[param]
    × *N*[data])。在大多数情况下，参数的数量相对于训练数据的大小较小，这意味着总体运行时间主要由数据集的大小决定。在训练过程中，神经网络试图将一个多维表面拟合到训练数据中（[Lapedes
    & Farber, 1987a](B978012388426800015X.xhtml#ref84)）。不幸的是，*维度灾难*告诉我们，随着数据维度的增加，必须搜索、采样和建模的空间体积呈指数增长。例如，在0到1的1维单位区间内以0.01的步长均匀采样需要100个样本，而对一个10维单位超立方体进行采样则需要(100)^(10)或10^(20)个样本。[⁵](#fn0030)
    即使是稀疏采样，平滑的高维表面也可能需要许多数据点。许多有趣的现象需要拟合复杂、崎岖的高维表面，这可能会显著增加所需的训练数据量，从而使得能够以可接受的精度逼近多维表面的模型的训练数据量大幅增加。⁵这个例子改编自[Wikipedia.org](http://Wikipedia.org)的“维度灾难”示例。[http://en.wikipedia.org/wiki/Curse_of_dimensionality](http://en.wikipedia.org/wiki/Curse_of_dimensionality))。当使用像Nelder-Mead、Levenberg-Marquardt、Powell方法、共轭梯度等流行的优化技术时，昂贵的目标函数往往主导运行时间。在这种情况下，最好集中精力减少目标函数的运行时间。将问题高效映射到具有数百个并行线程的GPGPU上，可能会将运行时间减少两个数量级，而在单线程系统中，正如[方程2.2](#fm0015)中所示，“基于ANN的目标函数的并行运行时间。”相反，一个四核处理器最多只能将运行时间减少4倍。（2.2）![B9780123884268000021/si2.gif
    is missing](B9780123884268000021/si2.gif)。本章中的示例表明，即使考虑到所有GPU通信开销，CUDA仍然可以比传统多核处理器上的实现减少50到100倍的运行时间。尽管这是并行系统普遍已知的结果（[Farber,
    1992](B978012388426800015X.xhtml#ref44)；[Thearling, 1995](B978012388426800015X.xhtml#ref132)），但令人惊讶的是，即使使用游戏GPU也能实现如此高水平的性能。
- en: 'XOR: An Important Nonlinear Machine-Learning Problem'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XOR：一个重要的非线性机器学习问题
- en: 'Andreas Weigend noted in *Introduction to the Theory of Neural Computation*:To
    contrast “learning” without generalization from learning with generalization,
    let us consider the widely and wildly celebrated fact that neural networks can
    learn to implement exclusive OR (XOR). But—what kind of learning is this? When
    four out of four cases are specified, no generalization exists! Learning a truth
    table is nothing but rote memorization: learning XOR is as interesting as memorizing
    the phone book. More interesting—and more realistic—are real-world problems, such
    as the prediction of financial data. In forecasting, nobody cares how well a model
    fits the training data—only the quality of future predictions counts, i.e., the
    performance on novel data or the generalization ability. Learning means extracting
    regularities from training examples that transfer to new examples. ([Hertz, Krogh,
    & Palmer, 1991](B978012388426800015X.xhtml#ref61), p. 5)In 1969, a famous book
    entitled *Perceptrons* ([Minsky & Papert, 1969](B978012388426800015X.xhtml#ref96))
    showed that it was not possible for a single-layer network, at that time called
    a *perceptron* ([Figure 2.1](#f0010)), to represent the fundamental XOR logical
    function. The impact was devastating, as funding and interest in the nascent field
    of neural networks evaporated.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Andreas Weigend 在《*神经计算理论导论*》中提到：为了对比“无泛化的学习”和“有泛化的学习”，我们不妨考虑一下广泛而又热烈庆祝的事实，即神经网络可以学习实现异或（XOR）功能。但——这算是哪种学习呢？当四种情况全部明确时，并不存在泛化！学习真值表不过是死记硬背：学习
    XOR 和记住电话簿一样无聊。更有趣——也更现实——的是现实世界中的问题，比如财务数据的预测。在预测中，没人关心模型与训练数据的拟合程度——只有未来预测的质量才重要，即在新数据上的表现或者泛化能力。学习意味着从训练示例中提取规律，这些规律能转移到新的示例上。([Hertz,
    Krogh, & Palmer, 1991](B978012388426800015X.xhtml#ref61), p. 5) 1969年，一本名为《*感知机*》的著作
    ([Minsky & Papert, 1969](B978012388426800015X.xhtml#ref96)) 证明了当时所谓的单层网络——感知机（[图
    2.1](#f0010)）——无法表示基本的 XOR 逻辑功能。这一发现具有毁灭性影响，因为神经网络这一新兴领域的资金和兴趣迅速蒸发。
- en: '| ![B9780123884268000021/f02-01-9780123884268.jpg is missing](B9780123884268000021/f02-01-9780123884268.jpg)
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| ![B9780123884268000021/f02-01-9780123884268.jpg is missing](B9780123884268000021/f02-01-9780123884268.jpg)
    |'
- en: '| **Figure 2.1**An example of a perceptron. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| **图 2.1** 感知机示例。 |'
- en: 'More the ten years passed until neural network research suddenly experienced
    a resurgence of interest. In the mid-1980s, a paper demonstrated that neural models
    could solve the Traveling Salesman Problem ([Hopfield & Tank, 1985](B978012388426800015X.xhtml#ref67)).
    Shortly thereafter, the backpropagation algorithm was created ([Rummelhardt, Hinton,
    & Williams, 1986](B978012388426800015X.xhtml#ref109); [Rummelhart, McClelland,
    & the PDP Research Group, 1987](B978012388426800015X.xhtml#ref110)). A key demonstration
    showed it was possible to train a multilevel ANN to replicate an XOR truth table.
    In the following years, the field of neural network research and other related
    machine-learning fields exploded.The importance of being able to learn and simulate
    the XOR truth table lies in understanding the concept of a *computationally universal*
    device. Universal Turing machines are an example of a computationally universal
    device ([Hopcroft & Ullman, 2006](B978012388426800015X.xhtml#ref66)) because they
    can, in theory, be used to simulate any other computational device.Distinguishing
    ANN from perceptrons, Andreas Weigend observes:The computational power drastically
    increases when an intermediate layer of nonlinear units is inserted between inputs
    and outputs. The example of XOR nicely emphasizes the importance of such hidden
    units: they re-represent the input such that the problem becomes linearly separable.
    Networks without hidden units cannot learn to memorize XOR, whereas networks with
    hidden units can implement any Boolean function. ([Hertz, Krogh, & Palmer, 1991](B978012388426800015X.xhtml#ref61),
    p. 6)In other words, the ability to simulate XOR is essential to making the argument
    that multilayer ANNs are universal computational devices and perceptrons without
    any hidden neurons are limited computational devices. It is the extra nonlinear
    hidden layers that give ANNs the ability to simulate other computational devices.
    In fact, only two layers are required to perform modeling and prediction tasks
    as well as symbolic learning ([Lapedes & Farber, 1987a](B978012388426800015X.xhtml#ref84)).
    However, clever human-aided design can create smaller networks that utilize fewer
    parameters, albeit with more than two hidden layers ([Farber et al., 1993](B978012388426800015X.xhtml#ref45)).
    [Figure 2.2](#f0015) shows an XOR neural network with one hidden neuron that implements
    a sigmoid as shown in [Figure 2.3](#f0020).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 十多年过去，直到神经网络研究突然再次引起兴趣。上世纪80年代中期，一篇论文展示了神经模型可以解决旅行推销员问题（[Hopfield & Tank, 1985](B978012388426800015X.xhtml#ref67)）。不久之后，反向传播算法被创建出来（[Rummelhardt,
    Hinton, & Williams, 1986](B978012388426800015X.xhtml#ref109); [Rummelhart, McClelland,
    & the PDP Research Group, 1987](B978012388426800015X.xhtml#ref110)）。一项关键的演示表明，可以训练多层ANN来复制XOR真值表。在接下来的几年里，神经网络研究领域和其他相关的机器学习领域迅速发展。学会学习和模拟XOR真值表的重要性在于理解*计算通用*设备的概念。图灵机是计算通用设备的一个例子（[Hopcroft
    & Ullman, 2006](B978012388426800015X.xhtml#ref66)），因为它们可以理论上用来模拟任何其他计算设备。区分ANN和感知机，安德烈亚斯·韦根德观察到：在输入和输出之间插入一个非线性单元的中间层时，计算能力显著增加。XOR的例子很好地强调了这种隐藏单元的重要性：它们重新表现输入，使问题变得线性可分。没有隐藏单元的网络无法学习记忆XOR，而具有隐藏单元的网络可以实现任何布尔函数（[Hertz,
    Krogh, & Palmer, 1991](B978012388426800015X.xhtml#ref61)，第6页）。换句话说，模拟XOR的能力对于证明多层ANN是通用计算设备，而没有任何隐藏神经元的感知器是有限的计算设备至关重要。正是额外的非线性隐藏层赋予了ANN模拟其他计算设备的能力。事实上，只需要两层来执行建模和预测任务以及符号学习（[Lapedes
    & Farber, 1987a](B978012388426800015X.xhtml#ref84)）。然而，巧妙的人类辅助设计可以创建利用更少参数的更小网络，尽管有超过两个隐藏层（[Farber
    et al., 1993](B978012388426800015X.xhtml#ref45)）。[图2.2](#f0015)显示了一个带有一个隐藏神经元的XOR神经网络，实现了如[图2.3](#f0020)所示的S形函数。
- en: '| ![B9780123884268000021/f02-02-9780123884268.jpg is missing](B9780123884268000021/f02-02-9780123884268.jpg)
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| ![B9780123884268000021/f02-02-9780123884268.jpg 缺失](B9780123884268000021/f02-02-9780123884268.jpg)
    |'
- en: '| **Figure 2.2**An XOR network. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **图 2.2** 一个XOR网络。 |'
- en: '| ![B9780123884268000021/f02-03-9780123884268.jpg is missing](B9780123884268000021/f02-03-9780123884268.jpg)
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| ![B9780123884268000021/f02-03-9780123884268.jpg 缺失](B9780123884268000021/f02-03-9780123884268.jpg)
    |'
- en: '| **Figure 2.3**An example sigmoidal G function: tanh(x). |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **图 2.3** 一个示例的S型G函数：tanh(x)。 |'
- en: An Example Objective Function
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个示例目标函数
- en: 'The **thrust::transform_reduce** template makes the implementation of an objective
    function both straight-forward and easy. For example, an ANN least means squares
    objective function requires the definition of a transform operator that calculates
    the square of the error that the network makes on each example in the training
    data. A reduction operation then calculates the sum of the squared errors.Thrust
    utilizes *functors* to perform the work of the transform and reduction operations
    as well as other generic methods. In C++, a functor overloads the function call
    operator “()” so that an object may be used in place of an ordinary function.
    This has several important implications:1\. Functors can be passed to generic
    algorithms like **thrust::transform_reduce** much like C-language programmers
    utilize pointers to functions.2\. Passing and using functors is efficient, as
    C++ can inline the functor code. This eliminates function call overhead and allows
    the compiler to perform more extensive optimizations.3\. C++ functors can maintain
    a persistent internal state. As you will see, this approach can be very useful
    when working with different device, GPU, and thread memory spaces.Inlining of
    functors is essential to performance because common functors such as **thrust::plus**
    only perform tiny amounts of computation. Without the ability to inline functors,
    generic methods like **thrust::transform_reduce** would not be possible because
    function call overhead would consume nearly as much (or more) time than the functor
    itself.The Thrust documentation speaks of *kernel fusion*, which combines multiple
    functors into a single kernel. Per our second rule of GPGPU coding, kernel fusion
    increases GPGPU utilization per kernel invocation, which can avoid kernel startup
    latencies. Just as important, many generic methods like the **thrust::transform_reduce**
    template avoid performance robbing storage of intermediate values to memory as
    the functor calculations are performed on the fly. The latter point meets the
    requirements of our third rule of GPGPU programming: focus on data reuse within
    the GPGPU to avoid memory bandwidth limitations. The SAXPY example in the thrust
    Quick Start guide provides a clear and lucid demonstration of the performance
    benefits of kernel fusion.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**thrust::transform_reduce** 模板使得目标函数的实现既直接又简单。例如，人工神经网络的最小二乘目标函数需要定义一个变换操作符，该操作符计算网络在训练数据集中的每个样本上的误差平方。接着，归约操作计算平方误差的总和。Thrust
    使用 *函数对象* 来执行变换和归约操作以及其他通用方法。在 C++ 中，函数对象重载了函数调用运算符“()”，使得一个对象可以替代普通函数使用。这有几个重要的含义：1\.
    函数对象可以像 C 语言程序员使用函数指针一样，传递给通用算法，如 **thrust::transform_reduce**。2\. 传递和使用函数对象非常高效，因为
    C++ 可以将函数对象代码内联。这消除了函数调用开销，并使得编译器能够进行更多的优化。3\. C++ 函数对象可以保持持久的内部状态。正如你将看到的，这种方法在处理不同的设备、GPU
    和线程内存空间时非常有用。函数对象的内联对性能至关重要，因为像 **thrust::plus** 这样的常见函数对象只执行非常小的计算。如果不能内联函数对象，像
    **thrust::transform_reduce** 这样的通用方法将无法实现，因为函数调用开销将消耗几乎与函数对象本身一样多（甚至更多）的时间。Thrust
    文档中提到了 *内核融合*，它将多个函数对象合并为一个内核。根据我们的 GPGPU 编程第二条规则，内核融合增加了每次内核调用的 GPGPU 利用率，这可以避免内核启动延迟。同样重要的是，许多通用方法，如
    **thrust::transform_reduce** 模板，避免了将中间值存储到内存中，这样在执行函数对象计算时无需中间存储。这一点符合我们 GPGPU
    编程的第三条规则：专注于 GPGPU 内的数据重用，以避免内存带宽限制。Thrust 快速入门指南中的 SAXPY 示例清晰明了地展示了内核融合带来的性能优势。'
- en: A Complete Functor for Multiple GPU Devices and the Host Processors
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个用于多个GPU设备和主机处理器的完整函子
- en: 'The following example, [Example 2.2](#tb0015), “An XOR functor for CalcError.h,”
    is a complete XOR functor. The section in bold shows the simplicity to code to
    calculate the XOR neural network illustrated in [Figure 2.2](#f0015) plus error
    for each example in the training set.`// The CalcError functor for XOR``static
    const int nInput = 2;``static const int nH1 = 1;``static const int nOutput = 1;``static
    const int nParam =``(nOutput+nH1) // Neuron Offsets``+ (nInput*nH1) // connections
    from I to H1``+ (nH1*nOutput) // connections from H1 to O``+ (nInput*nOutput);
    // connections from I to O``static const int exLen = nInput + nOutput;``struct
    CalcError {``const Real* examples;``const Real* p;``const int nInput;``const int
    exLen;``CalcError( const Real* _examples, const Real* _p,``const int _nInput,
    const int _exLen)``: examples(_examples), p(_p), nInput(_nInput), exLen(_exLen)
    {};``**__device__ __host__**``**Real operator()(unsigned int tid)**``**{**``**const
    register Real* in = &examples[tid * exLen];**``**register int index=0;**``**register
    Real h1 = p[index++];**``**register Real o = p[index++];**``**h1 += in[0] * p[index++];**``**h1
    += in[1] * p[index++];**``**h1 = G(h1);**``**o += in[0] * p[index++];**``**o +=
    in[1] * p[index++];**``**o += h1 * p[index++];**``**// calculate the square of
    the diffs**``**o -= in[nInput];**``**return o * o;**``**}**``};`The nonlinear
    transfer function, **G**, in the previous example utilizes a hyperbolic **tanh**
    to define a sigmoid as illustrated in [Figure 2.3](#f0020). Other popular sigmoidal
    functions include the logistic function, piece-wise linear, and many others. It
    is easy to change the definition of **G** to experiment with these other functions.It
    is important to note that two CUDA function qualifiers, **__device__** and **__host__**,
    highlighted in the previous code snippet, specify a functor that can run on both
    the host processor and one or more GPU devices. This dual use of the functor makes
    it convenient to create hybrid CPU/GPU applications that can run on all the available
    computing resources in a system. It also makes performance comparisons between
    GPU- and host-based implementations easier.This functor also uses persistence
    to encapsulate the data on the device, which ties the data to the calculation
    and allows work to be distributed across multiple devices and types of devices.
    Of course, the pointers to the vectors used by the functor should also reside
    on the device running the functor or undesired memory transfers will be required.
    CUDA 4.0 provides a unified virtual address space that allows the runtime to identify
    the device that contains a region of memory solely from the memory pointer. Data
    can then be directly transferred among devices. While the direct transfer is efficient,
    it still imposes PCIe bandwidth limitations.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '以下示例，[示例 2.2](#tb0015)，“XOR 函数器 for CalcError.h”，是一个完整的 XOR 函数器。粗体部分展示了计算 XOR
    神经网络的代码简洁性，该神经网络如 [图 2.2](#f0015) 所示，并包含训练集中每个示例的误差。`// XOR 的 CalcError 函数器``static
    const int nInput = 2;``static const int nH1 = 1;``static const int nOutput = 1;``static
    const int nParam =``(nOutput+nH1) // 神经元偏移量``+ (nInput*nH1) // 从 I 到 H1 的连接``+
    (nH1*nOutput) // 从 H1 到 O 的连接``+ (nInput*nOutput); // 从 I 到 O 的连接``static const
    int exLen = nInput + nOutput;``struct CalcError {``const Real* examples;``const
    Real* p;``const int nInput;``const int exLen;``CalcError( const Real* _examples,
    const Real* _p,``const int _nInput, const int _exLen)``: examples(_examples),
    p(_p), nInput(_nInput), exLen(_exLen) {};``**__device__ __host__**``**Real operator()(unsigned
    int tid)**``**{**``**const register Real* in = &examples[tid * exLen];**``**register
    int index=0;**``**register Real h1 = p[index++];**``**register Real o = p[index++];**``**h1
    += in[0] * p[index++];**``**h1 += in[1] * p[index++];**``**h1 = G(h1);**``**o
    += in[0] * p[index++];**``**o += in[1] * p[index++];**``**o += h1 * p[index++];**``**//
    计算差异的平方**``**o -= in[nInput];**``**return o * o;**``**}**``};`前面示例中的非线性传输函数 **G**
    使用双曲正切 **tanh** 来定义一个 S 形曲线，如 [图 2.3](#f0020) 所示。其他常见的 S 形函数包括逻辑函数、分段线性函数等。你可以轻松更改
    **G** 的定义，来尝试这些其他函数。需要注意的是，前面代码片段中突出的两个 CUDA 函数限定符，**__device__** 和 **__host__**，指定了一个函数器可以同时在主机处理器和一个或多个
    GPU 设备上运行。函数器的这种双重使用使得创建混合型的 CPU/GPU 应用程序变得更加方便，这些应用程序可以在系统中所有可用的计算资源上运行。它还使得对
    GPU 和主机实现的性能比较更加容易。这个函数器还使用持久性来封装设备上的数据，这将数据与计算绑定，并允许工作在多个设备和设备类型之间分配。当然，函数器使用的指向向量的指针也应位于运行该函数器的设备上，否则将需要不必要的内存传输。CUDA
    4.0 提供了一个统一的虚拟地址空间，允许运行时仅通过内存指针识别包含内存区域的设备。数据可以直接在设备之间传输。尽管这种直接传输效率较高，但它仍然受到 PCIe
    带宽的限制。'
- en: Brief Discussion of a Complete Nelder-Mead Optimization Code
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整的Nelder-Mead优化代码简要讨论
- en: The following discussion will walk through a complete Nelder-Mead thrust API
    GPU example that provies single- and double-precision object instantiation, data
    generation, runtime configuration of the Nelder-Mead method, and a test function
    to verify that the network trained correctly. If desired, the code snippets in
    this section can be combined to create a complete *xorNM.cu* source file. Alternatively,
    a complete version of this example can be downloaded from the book's website.
    [⁶](#fn0035)⁶[http://booksite.mkp.com/9780123884268](http://booksite.mkp.com/9780123884268)The
    objective function calculates the energy. In this example, the energy is the sum
    of the square of the errors made by the model for a given set of parameters as
    shown in [Equation 2.3](#fm0020).(2.3)![B9780123884268000021/si3.gif is missing](B9780123884268000021/si3.gif)An
    optimization method is utilized to fit the parameters to the data with minimal
    error. In this example, the Nelder-Mead method is utilized, but many other numerical
    techniques can be used, such as Powell's method. If the derivative of the objective
    function can be coded, more efficient numerical algorithms such as conjugate gradient
    can be used to speed the minimization process. Some of these algorithms can, in
    the ideal case, reduce the runtime by a factor equal to the number of parameters.The
    calculation performs three steps as illustrated in [Figure 2.4](#f0025). For generality,
    multiple GPUs are shown, although the example in this chapter will work on only
    one GPU:1\. Broadcast the parameters from the host to the GPU(s).2\. Evaluate
    the objective function on the GPU. If the run utilizes multiple GPUs, then each
    GPU calculates a partial sum of the errors. The data set is initially partitioned
    across all the GPUs, where the number of examples per GPU can be used to load-balance
    across devices with different performance characteristics.3\. The sum (or sum
    of the partial sums in the multi-GPU case) is calculated via a reduce operation.
    In this case, **thrust::transform_reduce** is used to sum the errors in one operation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来的讨论将详细讲解一个完整的Nelder-Mead推力API GPU示例，该示例提供了单精度和双精度对象实例化、数据生成、Nelder-Mead方法的运行时配置，以及一个测试函数，用于验证网络是否正确训练。如果需要，本节中的代码片段可以结合起来，创建一个完整的*xorNM.cu*源文件。或者，可以从本书的官方网站下载该示例的完整版本。[⁶](#fn0035)⁶[http://booksite.mkp.com/9780123884268](http://booksite.mkp.com/9780123884268)目标函数计算能量。在本示例中，能量是模型在给定参数集下产生的误差的平方和，如[公式2.3](#fm0020)所示。(2.3)![B9780123884268000021/si3.gif
    is missing](B9780123884268000021/si3.gif)使用优化方法来使参数与数据拟合，从而最小化误差。在本示例中使用了Nelder-Mead方法，但也可以使用许多其他数值技术，例如Powell方法。如果目标函数的导数可以编写，则可以使用更高效的数值算法，如共轭梯度法，以加速最小化过程。这些算法在理想情况下可以将运行时间缩短为参数数量的倍数。计算过程分为三步，如[图2.4](#f0025)所示。为了通用性，展示了多个GPU，尽管本章中的示例仅在一个GPU上运行：  '
- en: '| ![B9780123884268000021/f02-04-9780123884268.jpg is missing](B9780123884268000021/f02-04-9780123884268.jpg)
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| ![B9780123884268000021/f02-04-9780123884268.jpg 找不到图片](B9780123884268000021/f02-04-9780123884268.jpg)
    |'
- en: '| **Figure 2.4**Optimization mapping. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **图 2.4** 优化映射。 |'
- en: 'The following example source code uses preprocessor conditional statements
    to specify the type of machine and precision of the run, which can be specified
    via the command line at compile time. Though conditional compilation does complicate
    the source code and interfere with code readability, it is a fact of life in real
    applications, as it facilitates code reuse and supporting multiple machine types.
    For this reason, conditional compilation is utilized in this book.The following
    conditionals are utilized in [Example 2.3](#tb0020), “Part 1 of xorNM.cu”:■ **USE_HOST**:
    Selects the code that will run the objective function on the host processor. The
    default is to run on the GPU.■ **USE_DBL**: Specifies that the compiled executable
    will use double-precision variables and arithmetic. The default is to use single-precision
    variables and arithmetic. Note that this is for convenience because C++ templates
    make it easy to have both single- and double-precision tests compiled by the same
    source code.`#include <iostream>``#include <iomanip>``#include <cmath>``#include
    <thrust/host_vector.h>``#include <thrust/device_vector.h>``#include <thrust/copy.h>``//
    define USE_HOST for a host-based version``// define USE_DBL for double precision``using
    namespace std;``#include "nelmin.h"`C++ polymorphism is used to make the appropriate
    single- and double-precision call to **tanh()**. See [Example 2.4](#tb0025), “Part
    2 of xorNM.cu”:`// Define the sigmoidal function``__device__ __host__``inline
    float G(float x) {return(tanhf(x)) ;}``__device__ __host__``inline double G(double
    x) {return(tanh(x));}`For convenience, a simple class, **ObjFunc**, was defined
    to combine the functor with some simple data management methods. [⁷](#fn0040)
    C++ templates are utilized in the example code, so the performance of the functor
    and overall application using single- or double-precision floating point can be
    evaluated. The **CalcError** functor defined previously is included after the
    comment. This use of a C-preprocessor include is not recommended for production
    applications. For training purposes, the functor was purposely isolated to make
    it easy to modify by the reader.⁷C++ objects encapsulate both data and methods
    that operate on the data into a single convenient package.Notice in this code
    section that **CalcError** is called directly in an OpenMP reduction loop when
    running on the host processor when **USE_HOST** is defined, which demonstrates
    the ability of Thrust to generate code for both GPU- and host-based functors.
    See [Example 2.5](#tb0030), “Part 3 of xorNM.cu”:`// This is a convenience class
    to hold all the examples and``// architecture information. Most is boilerplate.
    CalcError``// is where all the work happens.``template<typename Real>``class ObjFunc
    {``private:``double objFuncCallTime;``unsigned int objFuncCallCount;``protected:``int
    nExamples;``#ifdef USE_HOST``thrust::host_vector<Real> h_data;``#else``thrust::device_vector<Real>
    d_data;``#endif``thrust::device_vector<Real> d_param;``public:``**// The CalcError
    functor goes here**``#include "CalcError.h"``// Boilerplate constructor and helper
    classes``ObjFunc() {nExamples = 0; objFuncCallCount=0; objFuncCallTime=0.;}``double
    aveObjFuncWallTime() {return(objFuncCallTime/ objFuncCallCount);}``double totalObjFuncWallTime()
    {return(objFuncCallTime);}``int get_nExamples() {return(nExamples);}``void setExamples(thrust::host_vector<Real>&
    _h_data) {``#ifdef USE_HOST``h_data = _h_data;``#else``d_data = _h_data;``#endif``nExamples
    = _h_data.size()/exLen;``d_param = thrust::device_vector<Real>(nParam);``}``#ifdef
    USE_HOST``Real objFunc(Real *p) {``if(nExamples == 0){cerr << "data not set" <<
    endl; exit(1);}``double startTime=omp_get_wtime();``Real sum = 0.;``CalcError
    getError(&h_data[0], p, nInput, exLen);``#pragma omp parallel for reduction(+
    : sum)``for(int i=0; i < nExamples; ++i) {``Real d = getError(i);``sum += d;``}``objFuncCallTime
    += (omp_get_wtime() - startTime);``objFuncCallCount++;``return(sum);``}``#else``Real
    objFunc(Real *p)``{``if(nExamples == 0){cerr << "data not set" <<endl; exit(1);}``double
    startTime=omp_get_wtime();``thrust::copy(p, p+nParam, d_param.begin());``CalcError
    getError(thrust::raw_pointer_cast(&d_data[0]),``thrust::raw_pointer_cast(&d_param[0]),``nInput,
    exLen);``Real sum = thrust::transform_reduce(``thrust::counting_iterator<unsigned
    int>(0),``thrust::counting_iterator<unsigned int> (nExamples),``getError,``(Real)
    0.,``thrust::plus<Real>());``objFuncCallTime += (omp_get_wtime() - startTime);``objFuncCallCount++;``return(sum);``}``#endif``};`The
    call to the objective function must be wrapped to return the appropriate type
    (e.g., **float** or **double**) as seen in [Example 2.6](#tb0035), “Part 4 of
    xorNM.cu.” C++ *polymorphism* selects the appropriate method depending on type
    of the parameters passed to the wrapper.`// Wrapper so the objective function
    can be called``// as a pointer to function for C-style libraries.``// Note: polymorphism
    allows easy use of``// either float or double types.``void* objFunc_object=NULL;``float
    func(float* param)``{``if(objFunc_object)``return ((ObjFunc<float>*) objFunc_object)->objFunc(param);``return(0.);``}``double
    func(double* param)``{``if(objFunc_object)``return ((ObjFunc<double>*) objFunc_object)->objFunc(param);``return(0.);``}``//
    get a uniform random number between −1 and 1``inline float f_rand() {``return
    2.*(rand()/((float)RAND_MAX)) −1.;``}`A test function is defined to calculate
    the output of the function based on a set of input values. See [Example 2.7](#tb0040),
    “Part 5 of xorNM.cu”:`template <typename Real, int nInput>``void testNN(const
    Real *p, const Real *in, Real *out)``{``int index=0;``Real h1 = p[index++];``Real
    o = p[index++];``h1 += in[0] * p[index++];``h1 += in[1] * p[index++];``h1 = G(h1);``o
    += in[0] * p[index++];``o += in[1] * p[index++];``o += h1 * p[index++];``out[0]=o;``}`For
    simplicity, the XOR truth table is duplicated to verify that the code works with
    large data sets and to provide the basis for a reasonable performance comparison
    between the GPGPU and host processor(s). As shown in the [Example 2.8](#tb0045),
    a small amount of uniformly distributed noise with a variance of 0.01 has been
    added to each training example as most training data sets are noisy.By simply
    defining an alternative functor and data generator, this same code framework will
    be adapted in [Chapter 3](B9780123884268000033.xhtml#B978-0-12-388426-8.00003-3)
    to solve other optimization problems. See [Example 2.8](#tb0045), “Part 6 of xorNM.cu”:`template
    <typename Real>``void genData(thrust::host_vector<Real> &h_data, int nVec, Real
    xVar)``{``// Initialize the data via replication of the XOR truth table``Real
    dat[] = {``0.1, 0.1, 0.1,``0.1, 0.9, 0.9,``0.9, 0.1, 0.9,``0.9, 0.9, 0.1};``for(int
    i=0; i < nVec; i++)``for(int j=0; j < 12; j++) h_data.push_back(dat[j] + xVar
    * f_rand());``}`The **testTraining()** method defined in [Example 2.9](#tb0050),
    “Part 7 of xorNM.cu,” sets up the Nelder-Mead optimization and calls the test
    function to verify the results:`template <typename Real>``void testTraining()``{``ObjFunc<Real>
    testObj;``const int nParam = testObj.nParam;``cout << "nParam" << nParam << endl;``//
    generate the test data``const int nVec=1000 * 1000 * 10;``thrust::host_vector<Real>
    h_data;``genData<Real>(h_data, nVec, 0.01);``testObj.setExamples(h_data);``int
    nExamples = testObj.get_nExamples();``cout << "GB data" << (h_data.size()*sizeof(Real)/1e9)
    << endl;``// set the Nelder-Mead starting conditions``int icount, ifault, numres;``vector<Real>
    start(nParam);``vector<Real> step(nParam,1.);``vector<Real> xmin(nParam);``srand(0);``for(int
    i=0; i < start.size(); i++) start[i] = 0.2 * f_rand();``Real ynewlo = testObj.objFunc(&start[0]);``Real
    reqmin = 1.0E-18;``int konvge = 10;``int kcount = 5000;``objFunc_object = &testObj;``double
    optStartTime=omp_get_wtime();``nelmin<Real> (func, nParam, &start[0], &xmin[0],
    &ynewlo, reqmin, &step[0], konvge, kcount, &icount, &numres, &ifault);``double
    optTime=omp_get_wtime()-optStartTime;``cout << endl <<"Return code IFAULT = "
    << ifault << endl << endl;``cout << "Estimate of minimizing value X*:" << endl
    << endl;``cout << "F(X*) = " << ynewlo << endl;``cout << "Number of iterations
    = " << icount << endl;``cout << "Number of restarts =" << numres << endl << endl;``cout
    << "Average wall time for ObjFunc"``<< testObj.aveObjFuncWallTime() << endl;``cout
    << "Total wall time in optimization method" << optTime << endl;``cout << "Percent
    time in objective function" <<``(100.*(testObj.totalObjFuncWallTime()/optTime))
    << endl;``int index=0, nTest=4;``cout << "pred known" << endl;``thrust::host_vector<Real>
    h_test;``thrust::host_vector<Real> h_in(testObj.nInput);``thrust::host_vector<Real>
    h_out(testObj.nOutput);``genData<Real>(h_test, nTest, 0.0); // note: no variance
    for the test``for(int i=0; i< nTest; i++) {``h_in[0] = h_test[index++];``h_in[1]
    = h_test[index++];``testNN<Real,2>(&xmin[0],&h_in[0],&h_out[0]);``cout << setprecision(1)
    << setw(4)``<< h_out[0] << " "``<< h_test[index] << endl;``index++;``}``}`The
    call to **main()** is very simple; see [Example 2.10](#tb0055), “Part 8 of xorNM.cu”:`int
    main ()``{``#ifdef USE_DBL``testTraining<double> ();``#else``testTraining<float>
    ();``#endif``return 0;``}`Before building, put the Nelder-Mead template from the
    end of this chapter into the file *nelmin.h* in the same directory as the *xorNM.cu*
    source code. Also ensure that *CalcError.h* is in the same directory.Building
    all variants of *xorNM.cu* is straightforward. The option **-use_fast_ math**
    tells the compiler to use native GPU functions such as **exp()** that are fast
    but might not be as accurate as the software routines. Make certain that the file
    *nelmin.h* is in the same directory.Under Linux type the code in [Example 2.11](#tb0060),
    “Compiling xorNM.cu under Linux”:`# single-precision GPU test``nvcc -O3 -Xcompiler
    -fopenmp –use_fast_math xorNM.cu -o xorNM_GPU32``# single-precision HOST test``nvcc
    -D USE_HOST -O3 -Xcompiler -fopenmp xorNM.cu -o xorNM_CPU32``# double-precision
    HOST test``nvcc -D USE_DBL -O3 -Xcompiler -fopenmp –use_fast_math xorNM.cu -o
    xorNM_GPU64``# double-precision HOST test``nvcc -D USE_DBL -D USE_HOST -O3 -Xcompiler
    -fopenmp xorNM.cu -o xorNM_CPU64`Windows- and MacOS-based computers can utilize
    similar commands once **nvcc** is installed and the build environment is correctly
    configured. It is also straightforward to compile this example with Microsoft
    Visual Studio. Please utilize one of the many tutorials available on the Internet
    to import and compile CUDA applications using the Visual Studio GUI (graphical
    user interface).[Example 2.12](#tb0065), “Compiling xorNM.cu under cygwin,” is
    an example command to build a single-precision version of *xorNM.cu* for a 20-series
    GPU under cygwin:`nvcc -arch=sm_20 -Xcompiler "/openmp /O2" –use_fast_math xorNM.cu
    -o xor_gpu32.exe`Running the program shows that an ANN network is indeed trained
    to solve the XOR problem as illustrated by the golden test results highlighted
    in [Example 2.13](#tb0070), “Example Output,” which shows that the XOR truth table
    is correctly predicted using the optimized parameters:`sizeof(Real) 4``Gigabytes
    in training vector 0.48``Return code IFAULT = 2``Estimate of minimizing value
    X*:``F(X*) = 4.55191e-08``Number of iterations = 5001``Number of restarts =0``Average
    wall time for ObjFunc 0.00583164``Total wall time in optimization method 29.5887``Percent
    time in objective function 98.5844``-- XOR Golden test --``**pred known**``**0.1
    0.1**``**0.9 0.9**``**0.9 0.9**``**0.1 0.1**`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '以下示例源代码使用预处理器条件语句来指定机器类型和运行精度，这些可以在编译时通过命令行进行指定。尽管条件编译确实会使源代码复杂化并影响代码的可读性，但在实际应用中这是不可避免的，因为它有助于代码重用和支持多种机器类型。因此，本书中使用了条件编译。以下条件在[示例
    2.3](#tb0020)“xorNM.cu的第1部分”中使用：  '
- en: Performance Results on XOR
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XOR性能结果
- en: '[Table 2.1](#t0010) provides a sorted list of the average time to calculate
    the XOR objective function under a variety of precision, optimization technique,
    and operating system configurations. Performance was measured using a 2.53 GHz
    quad-core Xeon e5630 and an NVIDIA C2070 (with ECC turned off. ECC, or Error Checking
    and Correcting memory, means that the memory subsystem check for memory errors,
    which can slow performance.). The performance of an inexpensive GeForce GTX280
    gaming GPU performing single-precision Nelder-Mead optimization is also shown
    in the table.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2.1](#t0010)提供了在不同精度、优化技术和操作系统配置下计算XOR目标函数的平均时间的排序列表。性能使用2.53 GHz四核Xeon
    e5630和NVIDIA C2070（关闭了ECC，ECC指错误检查和校正内存，意味着内存子系统会检查内存错误，这可能会减慢性能。）进行测量。表中还显示了一款便宜的GeForce
    GTX280游戏GPU在执行单精度Nelder-Mead优化时的性能。'
- en: '**Table 2.1** Observed Timings when Training an XOR Neural Network'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 2.1** 训练XOR神经网络时的观察时间'
- en: '| OS | Machine | Opt Method | Precision | Average Obj Func Time | % Func Time
    | Speedup over Quad-Core | Speedup over Single-Core |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 操作系统 | 机器 | 优化方法 | 精度 | 平均目标函数时间 | 函数时间百分比 | 相比四核加速比 | 相比单核加速比 |'
- en: '| Linux | NVIDIA C2070 | Nelder-Mead | 32 | 0.00532 | 100.0 | 85 | 341 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Linux | NVIDIA C2070 | Nelder-Mead | 32 | 0.00532 | 100.0 | 85 | 341 |'
- en: '| Win7 | NVIDIA C2070 | Nelder-Mead | 32 | 0.00566 | 100.0 | 81 | 323 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Win7 | NVIDIA C2070 | Nelder-Mead | 32 | 0.00566 | 100.0 | 81 | 323 |'
- en: '| Linux | NVIDIA GTX280 | Nelder-Mead | 32 | 0.01109 | 99.2 | 41 | 163 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Linux | NVIDIA GTX280 | Nelder-Mead | 32 | 0.01109 | 99.2 | 41 | 163 |'
- en: '| Linux | NVIDIA C2070 | Nelder-Mead | 64 | 0.01364 | 100.0 | 40 | 158 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Linux | NVIDIA C2070 | Nelder-Mead | 64 | 0.01364 | 100.0 | 40 | 158 |'
- en: '| Win7 | NVIDIA C2070 | Nelder-Mead | 64 | 0.01612 | 100.0 | 22 | 87 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Win7 | NVIDIA C2070 | Nelder-Mead | 64 | 0.01612 | 100.0 | 22 | 87 |'
- en: '| Linux | NVIDIA C2070 | Levenberg-Marquardt | 32 | 0.04313 | 2.7 | 10 | 38
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Linux | NVIDIA C2070 | Levenberg-Marquardt | 32 | 0.04313 | 2.7 | 10 | 38
    |'
- en: '| Linux | NVIDIA C2070 | Levenberg-Marquardt | 64 | 0.08480 | 4.4 | 6 | 23
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| Linux | NVIDIA C2070 | Levenberg-Marquardt | 64 | 0.08480 | 4.4 | 6 | 23
    |'
- en: '| Linux | Intel e5630 | Levenberg-Marquardt | 32 | 0.41512 | 21.1 |  |  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Linux | Intel e5630 | Levenberg-Marquardt | 32 | 0.41512 | 21.1 |  |  |'
- en: '| Linux | Intel e5630 | Levenberg-Marquardt | 64 | 0.49745 | 20.8 |  |  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Linux | Intel e5630 | Levenberg-Marquardt | 64 | 0.49745 | 20.8 |  |  |'
- en: '| Linux | Intel e5630 | Nelder-Mead | 32 | 0.45312 | 100.0 |  |  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| Linux | Intel e5630 | Nelder-Mead | 32 | 0.45312 | 100.0 |  |  |'
- en: '| Linux | Intel e5630 | Nelder-Mead | 64 | 0.53872 | 100.0 |  |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Linux | Intel e5630 | Nelder-Mead | 64 | 0.53872 | 100.0 |  |  |'
- en: Performance Discussion
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能讨论
- en: The average times to calculate the XOR objective function reported in [Table
    2.1](#t0010) are based on *wall clock time* collected with a call to the OpenMP
    **omp_get_wtime()** method. Wall clock time is an unreliable performance measuring
    tool, as any other process running on the host can affect the accuracy of the
    timing. [⁸](#fn0045)[Chapter 3](B9780123884268000033.xhtml#B978-0-12-388426-8.00003-3)
    discusses more advanced CUDA performance analysis tools such as the NVIDIA visual
    profiler for Linux and Parallel Nsight for Windows.⁸It is worth noting that even
    tiny delays incurred by other processes briefly starting and stopping can introduce
    significant performance degradation in large programs running at scale, as discussed
    in the paper “The Case of the Missing Supercomputer Performance” ([Petrini, Kerbyson,
    & Pakin, 2003](B978012388426800015X.xhtml#ref104)). Cloud-based computing environments—especially
    those that utilize virtual machines—are especially sensitive to jitter.All tests
    ran on an idle system to attain the most accurate results. Reported speedups are
    based on the average wall clock time consumed during the calculation of the objective
    function, including all host and GPU data transfers required by the objective
    function. OpenMP was used to multithread the host-only tests to utilize all four
    cores of the Xeon processor.As [Table 2.1](#t0010) shows, the best performance
    was achieved under Linux when running a single-precision test on an NVIDIA C2070
    GPGPU. Improvements in the 20-series Fermi architecture have increased double-precision
    performance within a factor of 2 of single-precision performance, which is significantly
    better than the previous generations of NVIDIA GPGPUs. Still, these older GPUs
    are quite powerful, as demonstrated by the 41-times-faster single-precision performance
    of an NVIDIA 10-series GeForce GTX280 gaming GPU over all four cores of a quad-core
    Xeon processor. This same midlevel gaming GPU also delivers roughly half the single-precision
    performance of the C2070.The Levenberg-Marquardt results are interesting because
    the order of magnitude performance decrease compared to the Nelder-Mead results
    highlights the cost of transferring the measurement vector from the GPU to the
    host, as well as the performance of host-based computations needed by Levenberg-Marquardt.This
    particular partitioning of a Levenberg-Marquardt optimization problem requires
    a large data transfer. The size of the transfer scales with the size of the data
    and thus introduces a scaling barrier that can make it too expensive for larger
    problems and multi-GPU data sets. Still, the Levenberg-Marquardt is a valid technique
    for GPU computing, as it can find good minima when other techniques fail. Counterintuitively,
    it can also run faster because it may find a minimum with just a few function
    calls.In contrast, Nelder-Mead does not impose a scalability limitation, as it
    requires only that the GPU return a single floating-point value. Other optimization
    techniques such as Powell's method and conjugate gradient share this desirable
    characteristic.Using alternative optimization methods such as Powell's method
    and conjugate gradient, variants of this example code have been shown to scale
    to more than 500 GPGPUs on the TACC Longhorn GPGPU cluster and to tens of thousands
    of processors on both the TACC Ranger and Thinking Machines supercomputers ([Farber,
    1992](B978012388426800015X.xhtml#ref44); [Thearling, 1995](B978012388426800015X.xhtml#ref132)).
    [Figure 2.5](#f0030) shows the minimum and maximum speedup observed when running
    on 500 GPUs. It is believed that the network connecting the distributed nodes
    on the Longhorn GPU cluster is responsible for the variation. The benchmark was
    run on an idle system. More about multi-GPU applications will be discussed in
    [Chapter 7](B9780123884268000070.xhtml#B978-0-12-388426-8.00007-0) and the application
    [Chapter 9](B9780123884268000094.xhtml#B978-0-12-388426-8.00009-4), [Chapter 10](B9780123884268000100.xhtml#B978-0-12-388426-8.00010-0),
    [Chapter 11](B9780123884268000112.xhtml#B978-0-12-388426-8.00011-2) and [Chapter
    12](B9780123884268000124.xhtml#B978-0-12-388426-8.00012-4) at the end of this
    book.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 XOR 目标函数的平均时间如 [表 2.1](#t0010) 所示，基于使用 OpenMP **omp_get_wtime()** 方法收集的 *墙钟时间*。墙钟时间是一种不可靠的性能测量工具，因为主机上运行的其他进程可能会影响计时的准确性。[⁸](#fn0045)[第
    3 章](B9780123884268000033.xhtml#B978-0-12-388426-8.00003-3) 讨论了更先进的 CUDA 性能分析工具，如
    Linux 上的 NVIDIA 可视化分析器和 Windows 上的 Parallel Nsight。⁸值得注意的是，其他进程的微小延迟（例如，短暂的启动和停止）可能会导致在大规模运行的程序中出现显著的性能下降，正如论文《失踪的超级计算机性能》（[Petrini,
    Kerbyson, & Pakin, 2003](B978012388426800015X.xhtml#ref104)）中所讨论的那样。基于云的计算环境，尤其是那些使用虚拟机的环境，对抖动特别敏感。所有测试都在空闲系统上进行，以获得最准确的结果。报告的加速比基于目标函数计算过程中消耗的平均墙钟时间，包括目标函数所需的所有主机和
    GPU 数据传输。OpenMP 被用于将主机仅测试进行多线程处理，以利用 Xeon 处理器的四个核心。正如 [表 2.1](#t0010) 所示，在 Linux
    上运行单精度测试时，NVIDIA C2070 GPGPU 实现了最佳性能。20 系列 Fermi 架构的改进将双精度性能提高到了单精度性能的两倍以内，这比之前的
    NVIDIA GPGPU 代数性能要好得多。尽管如此，这些较旧的 GPU 仍然非常强大，正如 NVIDIA 10 系列 GeForce GTX280 游戏
    GPU 在四核 Xeon 处理器上提供的单精度性能比值提高了 41 倍所示。这款中端游戏 GPU 也提供了约 C2070 单精度性能的一半。Levenberg-Marquardt
    的结果很有趣，因为与 Nelder-Mead 结果相比，性能数量级的下降凸显了从 GPU 到主机传输测量向量的成本，以及 Levenberg-Marquardt
    所需的主机计算性能。这个 Levenberg-Marquardt 优化问题的特定分区需要大量数据传输。传输的大小随着数据的增大而增加，因此引入了一个扩展障碍，使得在更大问题和多
    GPU 数据集的情况下可能变得过于昂贵。然而，Levenberg-Marquardt 仍然是 GPU 计算中有效的技术，因为它可以在其他技术失败时找到良好的最小值。反直觉的是，它也可能运行得更快，因为它可能只需要几次函数调用就能找到最小值。相比之下，Nelder-Mead
    不会强加可扩展性限制，因为它仅要求 GPU 返回一个浮动点值。其他优化方法，如 Powell 方法和共轭梯度法，也具有这一理想特性。使用如 Powell 方法和共轭梯度法等替代优化方法，经过改编的此示例代码已被证明能够扩展到
    TACC Longhorn GPGPU 集群上的 500 多个 GPGPU，以及 TACC Ranger 和 Thinking Machines 超级计算机上的数万个处理器（[Farber,
    1992](B978012388426800015X.xhtml#ref44); [Thearling, 1995](B978012388426800015X.xhtml#ref132)）。[图
    2.5](#f0030) 显示了在 500 个 GPU 上运行时观察到的最小和最大加速比。据认为，连接 Longhorn GPU 集群上分布式节点的网络是导致这种变化的原因。基准测试是在空闲系统上运行的。更多关于多
    GPU 应用程序的内容将在本书后面的 [第 7 章](B9780123884268000070.xhtml#B978-0-12-388426-8.00007-0)
    和应用 [第 9 章](B9780123884268000094.xhtml#B978-0-12-388426-8.00009-4)、[第 10 章](B9780123884268000100.xhtml#B978-0-12-388426-8.00010-0)、[第
    11 章](B9780123884268000112.xhtml#B978-0-12-388426-8.00011-2) 以及 [第 12 章](B9780123884268000124.xhtml#B978-0-12-388426-8.00012-4)
    中讨论。
- en: '| ![B9780123884268000021/f02-05-9780123884268.jpg is missing](B9780123884268000021/f02-05-9780123884268.jpg)
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| ![B9780123884268000021/f02-05-9780123884268.jpg 图片缺失](B9780123884268000021/f02-05-9780123884268.jpg)
    |'
- en: '| **Figure 2.5**Scaling results to 500 GPUs. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| **图 2.5** 扩展到500个GPU的结果。 |'
- en: The advantage of the generic approach utilized by many numerical libraries is
    that by simply defining a new function of interest an application programmer can
    use the library to solve many problems. For example, the source code in this chapter
    will be modified in [Chapter 3](B9780123884268000033.xhtml#B978-0-12-388426-8.00003-3)
    to use a different functor that will perform a PCA (Principle Components Analysis).
    PCA along with the nonlinear variant NLPCA (Nonlinear Principle Components Analysis)
    has wide applicability in vision research and handwriting analysis ([Hinton &
    Salakhutdinov, 2006](B978012388426800015X.xhtml#ref63)) [⁹](#fn0050) as well as
    biological modeling ([Scholz, 2011](B978012388426800015X.xhtml#ref115)), financial
    modeling, Internet search, and many other commercial and academic fields.⁹Available
    online at [http://www.cs.toronto.edu/~hinton/science.pdf](http://www.cs.toronto.edu/~hinton/science.pdf).Other
    powerful machine-learning techniques such as Hidden Markov Models (HMM), genetic
    algorithms, Bayesian networks, and many others parallelize very well on GPGPU
    hardware. As with neural networks, each has various strengths and weaknesses.
    By redefining the objective function, this same example code can implement other
    popular techniques such as:■ Optimization■ Locally weighted linear regression
    (LWLR)■ Naive Bayes (NB)■ Gaussian Discriminative Analysis (GDA)■ K-means■ Logistic
    regression (LR)■ Independent component analysis (ICA)■ Expectation maximization
    (EM)■ Support vector machine (SVM)■ Others, such as multidimension scaling (MDS),
    ordinal MDS, and other variants
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数值库采用的通用方法的优点在于，通过简单地定义一个感兴趣的新函数，应用程序员可以利用该库解决许多问题。例如，本章中的源代码将在[第3章](B9780123884268000033.xhtml#B978-0-12-388426-8.00003-3)中进行修改，以使用一个不同的函数对象，该对象将执行主成分分析（PCA，Principal
    Components Analysis）。PCA以及其非线性变体NLPCA（非线性主成分分析）在视觉研究和手写分析中有广泛的应用（[Hinton & Salakhutdinov,
    2006](B978012388426800015X.xhtml#ref63)）[⁹](#fn0050)，以及在生物建模（[Scholz, 2011](B978012388426800015X.xhtml#ref115)）、金融建模、互联网搜索和许多其他商业与学术领域也有应用。⁹可在线访问：[http://www.cs.toronto.edu/~hinton/science.pdf](http://www.cs.toronto.edu/~hinton/science.pdf)。其他强大的机器学习技术，如隐马尔可夫模型（HMM）、遗传算法、贝叶斯网络等，也能在GPGPU硬件上很好地并行化。与神经网络一样，每种技术都有其优缺点。通过重新定义目标函数，相同的示例代码可以实现其他流行的技术，如：■
    优化■ 局部加权线性回归（LWLR）■ 朴素贝叶斯（NB）■ 高斯判别分析（GDA）■ K均值■ 逻辑回归（LR）■ 独立成分分析（ICA）■ 期望最大化（EM）■
    支持向量机（SVM）■ 其他，如多维尺度（MDS）、有序MDS和其他变体
- en: Summary
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: GPGPUs today possess a peak floating-point capability that was beyond the machines
    available in even the most advanced high-performance computing (HPC) centers until
    a Sandia National Laboratory supercomputer performed a trillion floating-point
    operations per second in December 1996\. Many of those proposals for leading-edge
    research using such a teraflop supercomputer can be performed today by students
    anywhere in the world using a few GPGPUs in a workstation combined with a fast
    RAID (Redundant Array of Independent Disks) disk subsystem.The techniques and
    examples discussed in this chapter can be applied to a multitude of data fitting,
    data analysis, dimension reduction, vision, and classification problems. Conveniently,
    they are able to scale from laptops to efficiently utilize the largest supercomputers
    in the world.CUDA-literate programmers can bring this new world of computational
    power to legacy projects. Along with faster application speeds, GPGPU technology
    can advance the state of the art by allowing more accurate approximations and
    computational techniques to be utilized and ultimately to create more accurate
    models.Competition is fierce in both commercial and academic circles, which is
    why GPU computing is making such a huge impact on both commercial products and
    scientific research. The competition is global; this hardware is accessible to
    anyone in the world who wishes to compete, as opposed to the past where competition
    was restricted to a relatively small community of individuals with access to big,
    parallel machines.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的GPGPU拥有的峰值浮点运算能力，甚至超出了即使是最先进的高性能计算（HPC）中心所能提供的机器，直到1996年12月，桑迪亚国家实验室的一台超级计算机每秒执行了万亿次浮点运算。许多利用这种TeraFlop超级计算机进行前沿研究的提案，今天可以通过世界任何地方的学生，在工作站中使用几块GPGPU结合快速RAID（冗余独立磁盘阵列）磁盘子系统来完成。本章讨论的技术和示例可以应用于多种数据拟合、数据分析、维度缩减、视觉和分类问题。方便的是，它们可以从笔记本电脑扩展到有效利用全球最大超级计算机。掌握CUDA的程序员可以将这股新的计算能力带入传统项目中。除了应用速度更快外，GPGPU技术还可以通过利用更准确的近似和计算技术，推动技术的进步，并最终创建更精确的模型。无论在商业还是学术领域，竞争都非常激烈，这也是为什么GPU计算在商业产品和科学研究中产生如此巨大影响的原因。竞争是全球性的；这种硬件对任何有意参与竞争的人都可以访问，而不是像过去那样，仅限于那些能够使用大型并行计算机的相对较小群体。
- en: The C++ Nelder-Mead Template
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: C++ Nelder-Mead模板
- en: '`#ifndef NELMIN_H``#define NELMIN_H``// Nelder-Mead Minimization Algorithm
    ASA047``// from the Applied Statistics Algorithms available``// in STATLIB. Adapted
    from the C version by J. Burkhardt``//`[`http://people.sc.fsu.edu/~jburkardt/c_src/asa047/asa047.html`](http://people.sc.fsu.edu/~jburkardt/c_src/asa047/asa047.html)`template
    <typename Real>``void nelmin ( Real (*fn)(Real*), int n, Real start[], Real xmin[],``Real
    *ynewlo, Real reqmin, Real step[], int konvge, int kcount, int *icount, int *numres,
    int *ifault )``{``const Real ccoeff = 0.5;``const Real ecoeff = 2.0;``const Real
    eps = 0.001;``const Real rcoeff = 1.0;``int ihi,ilo,jcount,l,nn;``Real del,dn,dnn;``Real
    rq,x,y2star,ylo,ystar,z;``//Check the input parameters.``if ( reqmin <= 0.0 )
    { *ifault = 1; return; }``if ( n < 1 ) { *ifault = 1; return; }``if ( konvge <
    1 ) { *ifault = 1; return; }``vector<Real> p(n*(n+1));``vector<Real> pstar(n);``vector<Real>
    p2star(n);``vector<Real> pbar(n);``vector<Real> y(n+1);``*icount = 0;``*numres
    = 0;``jcount = konvge;``dn = ( Real ) ( n );``nn = n + 1;``dnn = ( Real ) ( nn
    );``del = 1.0;``rq = reqmin * dn;``//Initial or restarted loop.``for ( ; ; ) {``for
    (int i = 0; i < n; i++ ) { p[i+n*n] = start[i]; }``y[n] = (*fn)( start );``*icount
    = *icount + 1;``for (int j = 0; j < n; j++ ) {``x = start[j];``start[j] = start[j]
    + step[j] * del;``for (int i = 0; i < n; i++ ) { p[i+j*n] = start[i]; }``y[j]
    = (*fn)( start );``*icount = *icount + 1;``start[j] = x;``}``//The simplex construction
    is complete.``//``//Find highest and lowest Y values.YNEWLO = Y(IHI) indicates``//the
    vertex of the simplex to be replaced.``ylo = y[0];``ilo = 0;``for (int i = 1;
    i < nn; i++ ) {``if ( y[i] < ylo ) { ylo = y[i]; ilo = i; }``}``//Inner loop.``for
    ( ; ; ) {``if ( kcount <= *icount ) {break; }``*ynewlo = y[0];``ihi = 0;``for
    (int i = 1; i < nn; i++ ) {``if ( *ynewlo < y[i] ) { *ynewlo = y[i]; ihi = i;
    }``}``//Calculate PBAR, the centroid of the simplex vertices``//excepting the
    vertex with Y value YNEWLO.``for (int i = 0; i < n; i++ ) {``z = 0.0;``for (int
    j = 0; j < nn; j++ ) { z = z + p[i+j*n]; }``z = z - p[i+ihi*n];``pbar[i] = z /
    dn;``}``//Reflection through the centroid.``for (int i = 0; i < n; i++ ) {``pstar[i]
    = pbar[i] + rcoeff * ( pbar[i] - p[i+ihi*n] );``}``ystar = (*fn)( &pstar[0] );``*icount
    = *icount + 1;``//Successful reflection, so extension.``if ( ystar < ylo ) {``for
    (int i = 0; i < n; i++ ) {``p2star[i] = pbar[i] + ecoeff * ( pstar[i] - pbar[i]
    );``}``y2star = (*fn)( &p2star[0] );``*icount = *icount + 1;``//Check extension.``if
    ( ystar < y2star ) {``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = pstar[i]; }``y[ihi]
    = ystar;``} else { //Retain extension or contraction.``for (int i = 0; i < n;
    i++ ) { p[i+ihi*n] = p2star[i]; }``y[ihi] = y2star;``}``} else { //No extension.``l
    = 0;``for (int i = 0; i < nn; i++ ) {``if ( ystar < y[i] ) l += 1;``}``if ( 1
    < l ) {``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = pstar[i]; }``y[ihi] = ystar;``}``//Contraction
    on the Y(IHI) side of the centroid.``else if ( l == 0 ) {``for (int i = 0; i <
    n; i++ ) {``p2star[i] = pbar[i] + ccoeff * ( p[i+ihi*n] - pbar[i] );``}``y2star
    = (*fn)( &p2star[0] );``*icount = *icount + 1;``//Contract the whole simplex.``if
    ( y[ihi] < y2star ) {``for (int j = 0; j < nn; j++ ) {``for (int i = 0; i < n;
    i++ ) {``p[i+j*n] = ( p[i+j*n] + p[i+ilo*n] ) * 0.5;``xmin[i] = p[i+j*n];``}``y[j]
    = (*fn)( xmin );``*icount = *icount + 1;``}``ylo = y[0];``ilo = 0;``for (int i
    = 1; i < nn; i++ ) {``if ( y[i] < ylo ) { ylo = y[i]; ilo = i; }``}``continue;``}``//Retain
    contraction.``else {``for (int i = 0; i < n; i++ ) {``p[i+ihi*n] = p2star[i];``}``y[ihi]
    = y2star;``}``}``//Contraction on the reflection side of the centroid.``else if
    ( l == 1 ) {``for (int i = 0; i < n; i++ ) {``p2star[i] = pbar[i] + ccoeff * (
    pstar[i] - pbar[i] );``}``y2star = (*fn)( &p2star[0] );``*icount = *icount + 1;``//``//Retain
    reflection?``//``if ( y2star <= ystar ) {``for (int i = 0; i < n; i++ ) { p[i+ihi*n]
    = p2star[i]; }``y[ihi] = y2star;``}``else {``for (int i = 0; i < n; i++ ) { p[i+ihi*n]
    = pstar[i]; }``y[ihi] = ystar;``}``}``}``//Check if YLO improved.``if ( y[ihi]
    < ylo ) { ylo = y[ihi]; ilo = ihi; }``jcount = jcount − 1;``if ( 0 < jcount )
    { continue; }``//Check to see if minimum reached.``if ( *icount <= kcount ) {``jcount
    = konvge;``z = 0.0;``for (int i = 0; i < nn; i++ ) { z = z + y[i]; }``x = z /
    dnn;``z = 0.0;``for (int i = 0; i < nn; i++ ) {``z = z + pow ( y[i] − x, 2 );``}``if
    ( z <= rq ) {break;}``}``}``//Factorial tests to check that YNEWLO is a local
    minimum.``for (int i = 0; i < n; i++ ) { xmin[i] = p[i+ilo*n]; }``*ynewlo = y[ilo];``if
    ( kcount < *icount ) { *ifault = 2; break; }``*ifault = 0;``for (int i = 0; i
    < n; i++ ) {``del = step[i] * eps;``xmin[i] = xmin[i] + del;``z = (*fn)( xmin
    );``*icount = *icount + 1;``if ( z < *ynewlo ) { *ifault = 2; break; }``xmin[i]
    = xmin[i] - del - del;``z = (*fn)( xmin );``*icount = *icount + 1;``if ( z < *ynewlo
    ) { *ifault = 2; break; }``xmin[i] = xmin[i] + del;``}``if ( *ifault == 0 ) {
    break; }``//Restart the procedure.``for (int i = 0; i < n; i++ ) { start[i] =
    xmin[i]; }``del = eps;``*numres = *numres + 1;``}``return;``}``#endif`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`#ifndef NELMIN_H``#define NELMIN_H``// Nelder-Mead 最小化算法 ASA047``// 来自 STATLIB
    中的应用统计算法``// 由 J. Burkhardt 改编自 C 版本``//`[`http://people.sc.fsu.edu/~jburkardt/c_src/asa047/asa047.html`](http://people.sc.fsu.edu/~jburkardt/c_src/asa047/asa047.html)`template
    <typename Real>``void nelmin ( Real (*fn)(Real*), int n, Real start[], Real xmin[],``Real
    *ynewlo, Real reqmin, Real step[], int konvge, int kcount, int *icount, int *numres,
    int *ifault )``{``const Real ccoeff = 0.5;``const Real ecoeff = 2.0;``const Real
    eps = 0.001;``const Real rcoeff = 1.0;``int ihi,ilo,jcount,l,nn;``Real del,dn,dnn;``Real
    rq,x,y2star,ylo,ystar,z;``//检查输入参数。``if ( reqmin <= 0.0 ) { *ifault = 1; return;
    }``if ( n < 1 ) { *ifault = 1; return; }``if ( konvge < 1 ) { *ifault = 1; return;
    }``vector<Real> p(n*(n+1));``vector<Real> pstar(n);``vector<Real> p2star(n);``vector<Real>
    pbar(n);``vector<Real> y(n+1);``*icount = 0;``*numres = 0;``jcount = konvge;``dn
    = ( Real ) ( n );``nn = n + 1;``dnn = ( Real ) ( nn );``del = 1.0;``rq = reqmin
    * dn;``//初始化或重启循环。``for ( ; ; ) {``for (int i = 0; i < n; i++ ) { p[i+n*n] = start[i];
    }``y[n] = (*fn)( start );``*icount = *icount + 1;``for (int j = 0; j < n; j++
    ) {``x = start[j];``start[j] = start[j] + step[j] * del;``for (int i = 0; i <
    n; i++ ) { p[i+j*n] = start[i]; }``y[j] = (*fn)( start );``*icount = *icount +
    1;``start[j] = x;``}``//单纯形构造完成。``//``//查找最高和最低的 Y 值。YNEWLO = Y(IHI) 表示``//将被替换的单纯形顶点。``ylo
    = y[0];``ilo = 0;``for (int i = 1; i < nn; i++ ) {``if ( y[i] < ylo ) { ylo =
    y[i]; ilo = i; }``}``//内部循环。``for ( ; ; ) {``if ( kcount <= *icount ) {break;
    }``*ynewlo = y[0];``ihi = 0;``for (int i = 1; i < nn; i++ ) {``if ( *ynewlo <
    y[i] ) { *ynewlo = y[i]; ihi = i; }``}``//计算 PBAR，单纯形顶点的质心``//排除 Y 值为 YNEWLO 的顶点。``for
    (int i = 0; i < n; i++ ) {``z = 0.0;``for (int j = 0; j < nn; j++ ) { z = z +
    p[i+j*n]; }``z = z - p[i+ihi*n];``pbar[i] = z / dn;``}``//通过质心进行反射。``for (int
    i = 0; i < n; i++ ) {``pstar[i] = pbar[i] + rcoeff * ( pbar[i] - p[i+ihi*n] );``}``ystar
    = (*fn)( &pstar[0] );``*icount = *icount + 1;``//成功反射，因此进行扩展。``if ( ystar < ylo
    ) {``for (int i = 0; i < n; i++ ) {``p2star[i] = pbar[i] + ecoeff * ( pstar[i]
    - pbar[i] );``}``y2star = (*fn)( &p2star[0] );``*icount = *icount + 1;``//检查扩展。``if
    ( ystar < y2star ) {``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = pstar[i]; }``y[ihi]
    = ystar;``} else { //保留扩展或收缩。``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = p2star[i];
    }``y[ihi] = y2star;``}``} else { //没有扩展。``l = 0;``for (int i = 0; i < nn; i++
    ) {``if ( ystar < y[i] ) l += 1;``}``if ( 1 < l ) {``for (int i = 0; i < n; i++
    ) { p[i+ihi*n] = pstar[i]; }``y[ihi] = ystar;``}``//在质心的 Y(IHI) 侧进行收缩。``else if
    ( l == 0 ) {``for (int i = 0; i < n; i++ ) {``p2star[i] = pbar[i] + ccoeff * (
    p[i+ihi*n] - pbar[i] );``}``y2star = (*fn)( &p2star[0] );``*icount = *icount +
    1;``//收缩整个单纯形。``if ( y[ihi] < y2star ) {``for (int j = 0; j < nn; j++ ) {``for
    (int i = 0; i < n; i++ ) {``p[i+j*n] = ( p[i+j*n] + p[i+ilo*n] ) * 0.5;``xmin[i]
    = p[i+j*n];``}``y[j] = (*fn)( xmin );``*icount = *icount + 1;``}``ylo = y[0];``ilo
    = 0;``for (int i = 1; i < nn; i++ ) {``if ( y[i] < ylo ) { ylo = y[i]; ilo = i;
    }``}``continue;``}``//保留收缩。``else {``for (int i = 0; i < n; i++ ) {``p[i+ihi*n]
    = p2star[i];``}``y[ihi] = y2star;``}``}``//在反射侧进行收缩。``else if ( l == 1 ) {``for
    (int i = 0; i < n; i++ ) {``p2star[i] = pbar[i] + ccoeff * ( pstar[i] - pbar[i]
    );``}``y2star = (*fn)( &p2star[0] );``*icount = *icount + 1;``//``//保留反射？``//``if
    ( y2star <= ystar ) {``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = p2star[i];
    }``y[ihi] = y2star;``}``else {``for (int i = 0; i < n; i++ ) { p[i+ihi*n] = pstar[i];
    }``y[ihi] = ystar;``}``}``}``//检查 YLO 是否改进。``if ( y[ihi] < ylo ) { ylo = y[ihi];
    ilo = ihi; }``jcount = jcount − 1;``if ( 0 < jcount ) { continue; }``//检查是否达到最小值。``if
    ( *icount <= kcount ) {``jcount = konvge;``z = 0.0;``for (int i = 0; i < nn; i++
    ) { z = z + y[i]; }``x = z / dnn;``z = 0.0;``for (int i = 0; i < nn; i++ ) {``z
    = z + pow ( y[i] − x, 2 );``}``if ( z <= rq ) {break;}``}``}``//阶乘测试检查 YNEWLO
    是否为局部最小值。``for (int i = 0; i < n; i++ ) { xmin[i] = p[i+ilo*n]; }``*ynewlo = y[ilo];``if
    ( kcount'
