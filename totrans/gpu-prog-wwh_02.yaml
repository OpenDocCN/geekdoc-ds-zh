- en: Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://enccs.github.io/gpu-programming/0-setup/](https://enccs.github.io/gpu-programming/0-setup/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*[GPU programming: why, when and how?](../)* **   Setup'
  prefs: []
  type: TYPE_NORMAL
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/0-setup.rst)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '## Local installation'
  prefs: []
  type: TYPE_NORMAL
- en: Since this lesson is taught using an HPC cluster, no software installation on
    your own computer is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Running on LUMI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Interactive job, 1 node, 1 GPU, 1 hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Exit interactive allocation with `exit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interacive terminal session on compute node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Corresponding batch script `submit.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Submit the job: `sbatch submit.sh`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitor your job: `squeue --me`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kill job: `scancel <JOB_ID>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Julia on LUMI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run Julia with `AMDGPU.jl` on LUMI, we use the following directory
    structure and assume it is our working directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: An example of a `Project.toml` project file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For the `submit.sh` batch script, include additional content to the batch script
    mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: An example of the `script.jl` code is provided below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Running Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### On LUMI'
  prefs: []
  type: TYPE_NORMAL
- en: 'A singularity container containing all the necessary dependencies has been
    created. To launch the container and the `IPython` interpreter within it, do as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Recipe for creating the container
  prefs: []
  type: TYPE_NORMAL
- en: For reference, the following files were used to create the above singularity
    container. First a singularity def file,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: and a bash script to build the container,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also interactively build using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'and finally a `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'LUMI also has official singularity images for Jax. These can be found under
    the path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]  ### On LUMI (only CPU)'
  prefs: []
  type: TYPE_NORMAL
- en: 'On LUMI, you can set up Python distribution as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]  ### On Google Colab'
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory, commonly referred to as “Colab”, is a cloud-based Jupyter
    notebook environment which runs in your web browser. Using it requires login with
    a Google account.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can get access to NVIDIA GPUs on Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://colab.research.google.com/](https://colab.research.google.com/)
    and sign in to your Google account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the menu in front of you, click “New notebook” in the bottom right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the notebook loads, go to the “Runtime” menu at the top and select “Change
    runtime type”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select “GPU” under “Hardware accelerator” and choose an available type of NVIDIA
    GPU (e.g. T4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click “Save”. The runtime takes a few seconds to load - you can see the status
    in the top right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the runtime has loaded, you can type `!nvidia-smi` to see information
    about the GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can now write Python code that runs on GPUs through e.g. the numba library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to code examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some exercises in this lesson rely on source code that you should download
    and modify in your own home directory on the cluster. All code examples are available
    in the same GitHub repository as this lesson itself. To download it you should
    use Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15] [Previous](../ "GPU Programming: When, Why and How?") [Next](../1-gpu-history/
    "Why GPUs?")'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: © Copyright 2023-2024, The contributors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). ## Local installation'
  prefs: []
  type: TYPE_NORMAL
- en: Since this lesson is taught using an HPC cluster, no software installation on
    your own computer is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Running on LUMI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Interactive job, 1 node, 1 GPU, 1 hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Exit interactive allocation with `exit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interacive terminal session on compute node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Corresponding batch script `submit.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Submit the job: `sbatch submit.sh`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitor your job: `squeue --me`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kill job: `scancel <JOB_ID>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Julia on LUMI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run Julia with `AMDGPU.jl` on LUMI, we use the following directory
    structure and assume it is our working directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: An example of a `Project.toml` project file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: For the `submit.sh` batch script, include additional content to the batch script
    mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: An example of the `script.jl` code is provided below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Running Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### On LUMI'
  prefs: []
  type: TYPE_NORMAL
- en: 'A singularity container containing all the necessary dependencies has been
    created. To launch the container and the `IPython` interpreter within it, do as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Recipe for creating the container
  prefs: []
  type: TYPE_NORMAL
- en: For reference, the following files were used to create the above singularity
    container. First a singularity def file,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: and a bash script to build the container,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also interactively build using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'and finally a `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'LUMI also has official singularity images for Jax. These can be found under
    the path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]  ### On LUMI (only CPU)'
  prefs: []
  type: TYPE_NORMAL
- en: 'On LUMI, you can set up Python distribution as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]  ### On Google Colab'
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory, commonly referred to as “Colab”, is a cloud-based Jupyter
    notebook environment which runs in your web browser. Using it requires login with
    a Google account.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can get access to NVIDIA GPUs on Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://colab.research.google.com/](https://colab.research.google.com/)
    and sign in to your Google account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the menu in front of you, click “New notebook” in the bottom right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the notebook loads, go to the “Runtime” menu at the top and select “Change
    runtime type”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select “GPU” under “Hardware accelerator” and choose an available type of NVIDIA
    GPU (e.g. T4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click “Save”. The runtime takes a few seconds to load - you can see the status
    in the top right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the runtime has loaded, you can type `!nvidia-smi` to see information
    about the GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can now write Python code that runs on GPUs through e.g. the numba library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to code examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some exercises in this lesson rely on source code that you should download
    and modify in your own home directory on the cluster. All code examples are available
    in the same GitHub repository as this lesson itself. To download it you should
    use Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Local installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since this lesson is taught using an HPC cluster, no software installation on
    your own computer is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Running on LUMI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Interactive job, 1 node, 1 GPU, 1 hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Exit interactive allocation with `exit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interacive terminal session on compute node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Corresponding batch script `submit.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Submit the job: `sbatch submit.sh`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitor your job: `squeue --me`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kill job: `scancel <JOB_ID>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Julia on LUMI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run Julia with `AMDGPU.jl` on LUMI, we use the following directory
    structure and assume it is our working directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: An example of a `Project.toml` project file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: For the `submit.sh` batch script, include additional content to the batch script
    mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: An example of the `script.jl` code is provided below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Running Julia on LUMI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run Julia with `AMDGPU.jl` on LUMI, we use the following directory
    structure and assume it is our working directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: An example of a `Project.toml` project file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: For the `submit.sh` batch script, include additional content to the batch script
    mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: An example of the `script.jl` code is provided below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Running Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '### On LUMI'
  prefs: []
  type: TYPE_NORMAL
- en: 'A singularity container containing all the necessary dependencies has been
    created. To launch the container and the `IPython` interpreter within it, do as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Recipe for creating the container
  prefs: []
  type: TYPE_NORMAL
- en: For reference, the following files were used to create the above singularity
    container. First a singularity def file,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: and a bash script to build the container,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also interactively build using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'and finally a `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'LUMI also has official singularity images for Jax. These can be found under
    the path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]  ### On LUMI (only CPU)'
  prefs: []
  type: TYPE_NORMAL
- en: 'On LUMI, you can set up Python distribution as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]  ### On Google Colab'
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory, commonly referred to as “Colab”, is a cloud-based Jupyter
    notebook environment which runs in your web browser. Using it requires login with
    a Google account.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can get access to NVIDIA GPUs on Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://colab.research.google.com/](https://colab.research.google.com/)
    and sign in to your Google account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the menu in front of you, click “New notebook” in the bottom right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the notebook loads, go to the “Runtime” menu at the top and select “Change
    runtime type”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select “GPU” under “Hardware accelerator” and choose an available type of NVIDIA
    GPU (e.g. T4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click “Save”. The runtime takes a few seconds to load - you can see the status
    in the top right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the runtime has loaded, you can type `!nvidia-smi` to see information
    about the GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can now write Python code that runs on GPUs through e.g. the numba library.  ###
    On LUMI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A singularity container containing all the necessary dependencies has been
    created. To launch the container and the `IPython` interpreter within it, do as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Recipe for creating the container
  prefs: []
  type: TYPE_NORMAL
- en: For reference, the following files were used to create the above singularity
    container. First a singularity def file,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: and a bash script to build the container,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also interactively build using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'and finally a `requirements.txt` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'LUMI also has official singularity images for Jax. These can be found under
    the path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '### On LUMI (only CPU)'
  prefs: []
  type: TYPE_NORMAL
- en: 'On LUMI, you can set up Python distribution as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '### On Google Colab'
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory, commonly referred to as “Colab”, is a cloud-based Jupyter
    notebook environment which runs in your web browser. Using it requires login with
    a Google account.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can get access to NVIDIA GPUs on Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://colab.research.google.com/](https://colab.research.google.com/)
    and sign in to your Google account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the menu in front of you, click “New notebook” in the bottom right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the notebook loads, go to the “Runtime” menu at the top and select “Change
    runtime type”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select “GPU” under “Hardware accelerator” and choose an available type of NVIDIA
    GPU (e.g. T4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click “Save”. The runtime takes a few seconds to load - you can see the status
    in the top right corner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the runtime has loaded, you can type `!nvidia-smi` to see information
    about the GPU.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can now write Python code that runs on GPUs through e.g. the numba library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to code examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some exercises in this lesson rely on source code that you should download
    and modify in your own home directory on the cluster. All code examples are available
    in the same GitHub repository as this lesson itself. To download it you should
    use Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]*'
  prefs: []
  type: TYPE_NORMAL
