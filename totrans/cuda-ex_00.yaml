- en: '**Foreword**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recent activities of major chip manufacturers such as NVIDIA make it more evident
    than ever that future designs of microprocessors and large HPC systems will be
    hybrid/heterogeneous in nature. These heterogeneous systems will rely on the integration
    of two major types of components in varying proportions:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '• **Multi- and many-core CPU technology**: The number of cores will continue
    to escalate because of the desire to pack more and more components on a chip while
    avoiding the power wall, the instruction-level parallelism wall, and the memory
    wall.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '• **Special-purpose hardware and massively parallel accelerators**: For example,
    GPUs from NVIDIA have outpaced standard CPUs in floating-point performance in
    recent years. Furthermore, they have arguably become as easy, if not easier, to
    program than multicore CPUs.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: The relative balance between these component types in future designs is not
    clear and will likely vary over time. There seems to be no doubt that future generations
    of computer systems, ranging from laptops to supercomputers, will consist of a
    composition of heterogeneous components. Indeed, the *petaflop* (10^(15) floating-point
    operations per second) performance barrier was breached by such a system.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: And yet the problems and the challenges for developers in the new computational
    landscape of hybrid processors remain daunting. Critical parts of the software
    infrastructure are already having a very difficult time keeping up with the pace
    of change. In some cases, performance cannot scale with the number of cores because
    an increasingly large portion of time is spent on data movement rather than arithmetic.
    In other cases, software tuned for performance is delivered years after the hardware
    arrives and so is obsolete on delivery. And in some cases, as on some recent GPUs,
    software will not run at all because programming environments have changed too
    much.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '*CUDA by Example* addresses the heart of the software development challenge
    by leveraging one of the most innovative and powerful solutions to the problem
    of programming the massively parallel accelerators in recent years.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: This book introduces you to programming in CUDA C by providing examples and
    insight into the process of constructing and effectively using NVIDIA GPUs. It
    presents introductory concepts of parallel computing from simple examples to debugging
    (both logical and performance), as well as covers advanced topics and issues related
    to using and building many applications. Throughout the book, programming examples
    reinforce the concepts that have been presented.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The book is required reading for anyone working with accelerator-based computing
    systems. It explores parallel computing in depth and provides an approach to many
    problems that may be encountered. It is especially useful for application developers,
    numerical library writers, and students and teachers of parallel computing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: I have enjoyed and learned from this book, and I feel confident that you will
    as well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '*Jack Dongarra'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*杰克·东加拉'
- en: University Distinguished Professor, University of Tennessee Distinguished Research
    Staff Member, Oak Ridge National Laboratory*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 田纳西大学杰出教授，奥克里奇国家实验室杰出研究员*
