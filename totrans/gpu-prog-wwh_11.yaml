- en: Portable kernel-based models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于内核的可移植模型
- en: 原文：[https://enccs.github.io/gpu-programming/8-portable-kernel-models/](https://enccs.github.io/gpu-programming/8-portable-kernel-models/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://enccs.github.io/gpu-programming/8-portable-kernel-models/](https://enccs.github.io/gpu-programming/8-portable-kernel-models/)'
- en: '*[GPU programming: why, when and how?](../)* **   Portable kernel-based models'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*[GPU编程：为什么、何时以及如何？](../)* **   基于内核的可移植模型'
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/8-portable-kernel-models.rst)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在GitHub上编辑](https://github.com/ENCCS/gpu-programming/blob/main/content/8-portable-kernel-models.rst)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Questions
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: How to program GPUs with alpaka, C++ StdPar, Kokkos, OpenCL, and SYCL?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用alpaka、C++ StdPar、Kokkos、OpenCL和SYCL来编程GPU？
- en: What are the differences between these programming models.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些编程模型之间有什么区别。
- en: Objectives
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Be able to use portable kernel-based models to write simple codes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用基于内核的可移植模型编写简单代码
- en: Understand how different approaches to memory and synchronization in Kokkos
    and SYCL work
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kokkos和SYCL中关于内存和同步的不同方法是如何工作的
- en: Instructor note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 60 min teaching
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 60分钟教学
- en: 30 min exercises
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30分钟练习
- en: The goal of the cross-platform portability ecosystems is to allow the same code
    to run on multiple architectures, therefore reducing code duplication. They are
    usually based on C++, and use function objects/lambda functions to define the
    loop body (i.e., the kernel), which can run on multiple architectures like CPU,
    GPU, and FPGA from different vendors. An exception to this is OpenCL, which originally
    offered only a C API (although currently also C++ API is available), and uses
    a separate-source model for the kernel code. However, unlike in many conventional
    CUDA or HIP implementations, the portability ecosystems require kernels to be
    written only once if one prefers to run it on CPU and GPU for example. Some notable
    cross-platform portability ecosystems are alpaka, Kokkos, OpenCL, RAJA, and SYCL.
    Kokkos, alpaka, and RAJA are individual projects whereas OpenCL and SYCL are standards
    followed by several projects implementing (and extending) them. For example, some
    notable SYCL implementations include [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html),
    [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) (previously known as
    hipSYCL or Open SYCL), [triSYCL](https://github.com/triSYCL/triSYCL), and [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 跨平台可移植生态系统目标是在多个架构上运行相同的代码，从而减少代码重复。它们通常基于C++，并使用函数对象/lambda函数来定义循环体（即内核），这些可以在多个架构上运行，如CPU、GPU和来自不同供应商的FPGA。OpenCL是这一规则的例外，它最初只提供C
    API（尽管目前也提供了C++ API），并为内核代码使用单独的源模型。然而，与许多传统的CUDA或HIP实现不同，可移植生态系统要求如果用户希望它在CPU和GPU上运行，则内核只需编写一次。一些值得注意的跨平台可移植生态系统包括alpaka、Kokkos、OpenCL、RAJA和SYCL。Kokkos、alpaka和RAJA是独立的项目，而OpenCL和SYCL是多个项目遵循的标准，这些项目实现了（并扩展了）它们。例如，一些值得注意的SYCL实现包括[Intel
    oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)、[AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)（之前称为hipSYCL或Open
    SYCL）、[triSYCL](https://github.com/triSYCL/triSYCL)和[ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)。
- en: C++ StdPar
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++ StdPar
- en: In C++17, the initial support for parallel execution of standard algorithms
    has been introduced. Most algorithms available via the standard `<algorithms>`
    header were given an overload accepting with an [*execution policy*](https://en.cppreference.com/w/cpp/algorithm)
    argument which allows the programmer to request parallel execution of the standard
    library function. While the main goal was to allow low-effort, high-level interface
    to run existing algorithms like `std::sort` on many CPU cores, implementations
    are allowed to use other hardware, and functions like `std::for_each` or `std::transform`
    offer great flexibility in writing the algorithm.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++17中，引入了对标准算法并行执行的支持。大多数通过标准 `<algorithms>` 头文件提供的算法都被赋予了接受[*执行策略*](https://en.cppreference.com/w/cpp/algorithm)参数的重载，这使得程序员可以请求并行执行标准库函数。虽然主要目标是允许低成本的、高级接口运行现有的算法，如`std::sort`在多个CPU核心上，但实现允许使用其他硬件，并且函数如`std::for_each`或`std::transform`在编写算法时提供了极大的灵活性。
- en: C++ StdPar, also called Parallel STL or PSTL, could be considered similar to
    directive-based models, as it is very high-level and does not give the programmer
    fine-grained control over data movement or any access to hardware-specific features
    like shared (local) memory. Even the GPU to run on is selected automatically,
    since standard C++ does not have the concept of a *device* (but there are vendor
    extensions allowing the programmer more control) However, for applications that
    already relies on algorithms from C++ standard library, StdPar can be a good way
    to reap the performance benefits of both CPUs and GPUs with minimal code modifications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: C++ StdPar，也称为并行 STL 或 PSTL，可以被认为是类似于指令驱动的模型，因为它非常高级，并且不给予程序员对数据移动或对硬件特定功能（如共享（局部）内存）的精细控制。甚至要运行的
    GPU 也是自动选择的，因为标准 C++ 没有概念上的 *device*（但有一些供应商扩展允许程序员有更多的控制）。然而，对于已经依赖于 C++ 标准库算法的应用程序，StdPar
    可以是一种在最小代码修改的情况下获得 CPU 和 GPU 性能优势的好方法。
- en: 'For GPU programming, all three vendors offer their implementations of StdPar
    with the ability to offload code to the GPU: NVIDIA has `nvc++`, AMD has experimental
    [roc-stdpar](https://github.com/ROCm/roc-stdpar), and Intel offers StdPar offload
    with their oneAPI compiler. [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)
    offers an independent StdPar implementation, able to target devices from all three
    vendors. While being a part of the C++ standard, the level of support and the
    maturity of StdPar implementations varies a lot between different compilers: not
    all compilers support all algorithms, and different heuristics for mapping the
    algorithm to hardware and for managing data movement can have effect on performance.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GPU 编程，所有三个供应商都提供了他们的 StdPar 实现，可以将代码卸载到 GPU 上：NVIDIA 有 `nvc++`，AMD 有实验性的
    [roc-stdpar](https://github.com/ROCm/roc-stdpar)，Intel 通过他们的 oneAPI 编译器提供 StdPar
    卸载。[AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) 提供了一个独立的 StdPar
    实现，能够针对所有三个供应商的设备。虽然 StdPar 是 C++ 标准的一部分，但不同编译器之间对 StdPar 的支持程度和成熟度差异很大：并非所有编译器都支持所有算法，将算法映射到硬件和进行数据移动的不同启发式方法可能会影响性能。
- en: StdPar compilation
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 编译
- en: 'The build process depends a lot on the used compiler:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程很大程度上取决于所使用的编译器：
- en: 'AdaptiveCpp: Add `--acpp-stdpar` flag when calling `acpp`.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AdaptiveCpp：在调用 `acpp` 时添加 `--acpp-stdpar` 标志。
- en: 'Intel oneAPI: Add `-fsycl -fsycl-pstl-offload=gpu` flags when calling `icpx`.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：在调用 `icpx` 时添加 `-fsycl -fsycl-pstl-offload=gpu` 标志。
- en: 'NVIDIA NVC++: Add `-stdpar` flag when calling `nvc++` (not supported with plain
    `nvcc`).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA NVC++：在调用 `nvc++` 时添加 `-stdpar` 标志（不支持使用普通 `nvcc`）。
- en: StdPar programming
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 编程
- en: In its simplest form, using C++ standard parallelism requires including an additional
    `<execution>` header and adding one argument to a supported standard library function.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单的形式中，使用 C++ 标准并行性需要包含一个额外的 `<execution>` 头文件，并将一个参数添加到支持的标准库函数中。
- en: 'For example, let’s look at the following sequential code sorting a vector:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看以下按顺序排序向量的代码：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To make it run sorting on the GPU, only a minor modification is needed:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要使其在 GPU 上运行排序操作，只需要进行微小的修改：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, when compiled with one of the supported compilers, the code will run the
    sorting on a GPU.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当使用支持的编译器编译时，代码将在 GPU 上运行排序操作。
- en: While the can initially seem very limiting, many standard algorithms, such as
    `std::transform`, `std::accumulate`, `std::transform_reduce`, and `std::for_each`
    can run custom functions over an array, thus allowing one to offload an arbitrary
    algorithm, as long as it does not violate typical limitations of GPU kernels,
    such as not throwing any exceptions and not doing system calls.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一开始可能看起来非常有限，但许多标准算法，如 `std::transform`、`std::accumulate`、`std::transform_reduce`
    和 `std::for_each`，可以在数组上运行自定义函数，从而允许将任意算法卸载，只要它不违反 GPU 内核的典型限制，例如不抛出任何异常和不进行系统调用。
- en: StdPar execution policies
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 执行策略
- en: 'In C++, there are four different execution policies to choose from:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在 C++ 中，有四种不同的执行策略可供选择：
- en: '`std::execution::seq`: run algorithm serially, don’t parallelize it.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::seq`: 串行运行算法，不进行并行化。'
- en: '`std::execution::par`: allow parallelizing the algorithm (as if using multiple
    threads),'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par`: 允许并行化算法（类似于使用多个线程），'
- en: '`std::execution::unseq`: allow vectorizing the algorithm (as if using SIMD),'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::unseq`: 允许向量化算法（类似于使用 SIMD），'
- en: '`std::execution::par_unseq`: allow both vectorizing and parallelizing the algorithm.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par_unseq`: 允许同时向量化和平行化算法。'
- en: 'The main difference between `par` and `unseq` is related to thread progress
    and locks: using `unseq` or `par_unseq` requires that the algorithms does not
    contain mutexes and other locks between the processes, while `par` does not have
    this limitation.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`par` 和 `unseq` 之间的主要区别与线程进度和锁有关：使用 `unseq` 或 `par_unseq` 要求算法在进程之间不包含互斥锁和其他锁，而
    `par` 没有这样的限制。'
- en: For GPU, the optimal choice is `par_unseq`, since this places the least requirement
    on the compiler in terms of operation ordering. While `par` is also supported
    in some cases, it is best avoided, both due to limited compiler support and as
    an indication that the algorithm is likely a poor fit for the hardware.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GPU，最佳选择是 `par_unseq`，因为它对编译器在操作顺序方面的要求最低。虽然 `par` 在某些情况下也受到支持，但最好避免使用它，这不仅因为编译器支持有限，而且也表明算法可能不适合硬件。
- en: Kokkos
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kokkos
- en: Kokkos is an open-source performance portability ecosystem for parallelization
    on large heterogeneous hardware architectures of which development has mostly
    taken place on Sandia National Laboratories. The project started in 2011 as a
    parallel C++ programming model, but have since expanded into a more broad ecosystem
    including Kokkos Core (the programming model), Kokkos Kernels (math library),
    and Kokkos Tools (debugging, profiling and tuning tools). By preparing proposals
    for the C++ standard committee, the project also aims to influence the ISO/C++
    language standard such that, eventually, Kokkos capabilities will become native
    to the language standard. A more detailed introduction is found [HERE](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 是一个开源的性能可移植生态系统，用于在大型的异构硬件架构上并行化，其开发主要在桑迪亚国家实验室进行。该项目始于 2011 年，作为一个并行
    C++ 编程模型，但后来扩展成为一个更广泛的生态系统，包括 Kokkos Core（编程模型）、Kokkos Kernels（数学库）和 Kokkos Tools（调试、分析和调优工具）。通过为
    C++ 标准委员会准备提案，该项目还旨在影响 ISO/C++ 语言标准，以便最终 Kokkos 的功能将成为语言标准的原生功能。更详细的介绍可以在[这里](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/)找到。
- en: The Kokkos library provides an abstraction layer for a variety of different
    parallel programming models, currently CUDA, HIP, SYCL, HPX, OpenMP, and C++ threads.
    Therefore, it allows better portability across different hardware manufactured
    by different vendors, but introduces an additional dependency to the software
    stack. For example, when using CUDA, only CUDA installation is required, but when
    using Kokkos with NVIDIA GPUs, Kokkos and CUDA installation are both required.
    Kokkos is not a very popular choice for parallel programming, and therefore, learning
    and using Kokkos can be more difficult compared to more established programming
    models such as CUDA, for which a much larger amount of search results and Stack
    Overflow discussions can be found.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 库为多种不同的并行编程模型提供了一个抽象层，目前包括 CUDA、HIP、SYCL、HPX、OpenMP 和 C++ 线程。因此，它允许在不同厂商制造的硬件之间实现更好的可移植性，但同时也给软件堆栈引入了额外的依赖。例如，当使用
    CUDA 时，只需要 CUDA 安装即可，但当使用 Kokkos 与 NVIDIA GPU 一起时，则需要 Kokkos 和 CUDA 的安装。Kokkos
    并不是并行编程中非常受欢迎的选择，因此，与更成熟的编程模型（如 CUDA）相比，学习和使用 Kokkos 可能会更加困难，因为关于 CUDA 的搜索结果和
    Stack Overflow 讨论的数量要多得多。
- en: Kokkos compilation
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos 编译
- en: Furthermore, one challenge with some cross-platform portability libraries is
    that even on the same system, different projects may require different combinations
    of compilation settings for the portability library. For example, in Kokkos, one
    project may wish the default execution space to be a CUDA device, whereas another
    requires a CPU. Even if the projects prefer the same execution space, one project
    may desire the Unified Memory to be the default memory space and the other may
    wish to use pinned GPU memory. It may be burdensome to maintain a large number
    of library instances on a single system.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些跨平台可移植性库的挑战之一是，即使在同一系统上，不同的项目可能也需要为可移植性库设置不同的编译组合。例如，在 Kokkos 中，一个项目可能希望默认的执行空间是
    CUDA 设备，而另一个项目则可能需要 CPU。即使项目偏好相同的执行空间，一个项目可能希望统一内存成为默认的内存空间，而另一个项目可能希望使用固定 GPU
    内存。在单个系统上维护大量库实例可能会变得很麻烦。
- en: 'However, Kokkos offers a simple way to compile Kokkos library simultaneously
    with the user project. This is achieved by specifying Kokkos compilation settings
    (see [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html))
    and including the Kokkos Makefile in the user Makefile. CMake is also supported.
    This way, the user application and Kokkos library are compiled together. The following
    is an example Makefile for a single-file Kokkos project (hello.cpp) that uses
    CUDA (Volta architecture) as the backend (default execution space) and Unified
    Memory as the default memory space:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Kokkos 提供了一种简单的方法来同时编译 Kokkos 库和用户项目。这是通过指定 Kokkos 编译设置（见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html)）并在用户
    Makefile 中包含 Kokkos Makefile 来实现的。CMake 也受到支持。这样，用户应用程序和 Kokkos 库一起编译。以下是一个使用
    CUDA（Volta 架构）作为后端（默认执行空间）和统一内存作为默认内存空间的单文件 Kokkos 项目（hello.cpp）的示例 Makefile：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To build a **hello.cpp** project with the above Makefile, no steps other than
    cloning the Kokkos project into the current directory is required.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用上述 Makefile 构建 **hello.cpp** 项目，除了将 Kokkos 项目克隆到当前目录外，不需要进行其他步骤。
- en: Kokkos programming
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos 编程
- en: When starting to write a project using Kokkos, the first step is understand
    Kokkos initialization and finalization. Kokkos must be initialized by calling
    `Kokkos::initialize(int& argc, char* argv[])` and finalized by calling `Kokkos::finalize()`.
    More details are given in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始使用 Kokkos 编写项目时，第一步是了解 Kokkos 的初始化和终止。Kokkos 必须通过调用 `Kokkos::initialize(int&
    argc, char* argv[])` 来初始化，并通过调用 `Kokkos::finalize()` 来终止。更多详情请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html)。
- en: Kokkos uses an execution space model to abstract the details of parallel hardware.
    The execution space instances map to the available backend options such as CUDA,
    OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer
    in the source code, the default execution space `Kokkos::DefaultExecutionSpace`
    is used. This is chosen when the Kokkos library is compiled. The Kokkos execution
    space model is described in more detail in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 使用执行空间模型来抽象并行硬件的细节。执行空间实例映射到可用的后端选项，如 CUDA、OpenMP、HIP 或 SYCL。如果程序员在源代码中没有明确选择执行空间，则使用默认的执行空间
    `Kokkos::DefaultExecutionSpace`。这是在编译 Kokkos 库时选择的。Kokkos 的执行空间模型在[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces)有更详细的描述。
- en: Similarly, Kokkos uses a memory space model for different types of memory, such
    as host memory or device memory. If not defined explicitly, Kokkos uses the default
    memory space specified during Kokkos compilation as described [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，Kokkos 使用内存空间模型来处理不同类型的内存，例如主机内存或设备内存。如果没有明确定义，Kokkos 将使用在 Kokkos 编译期间指定的默认内存空间，具体请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces)。
- en: 'The following is an example of a Kokkos program that initializes Kokkos and
    prints the execution space and memory space instances:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个初始化 Kokkos 并打印执行空间和内存空间实例的 Kokkos 程序示例：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With Kokkos, the data can be accessed either through raw pointers or through
    Kokkos Views. With raw pointers, the memory allocation into the default memory
    space can be done using `Kokkos::kokkos_malloc(n * sizeof(int))`. Kokkos Views
    are a data type that provides a way to access data more efficiently in memory
    corresponding to a certain Kokkos memory space, such as host memory or device
    memory. A 1-dimensional view of type int* can be created by `Kokkos::View<int*>
    a("a", n)`, where `"a"` is a label, and `n` is the size of the allocation in the
    number of integers. Kokkos determines the optimal layout for the data at compile
    time for best overall performance as a function of the computer architecture.
    Furthermore, Kokkos handles the deallocation of such memory automatically. More
    details about Kokkos Views are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kokkos，数据可以通过原始指针或通过 Kokkos 视图来访问。使用原始指针时，可以将内存分配到默认内存空间，使用 `Kokkos::kokkos_malloc(n
    * sizeof(int))`。Kokkos 视图是一种数据类型，它提供了一种更有效地访问与特定 Kokkos 内存空间（如主机内存或设备内存）对应的数据的方法。可以通过
    `Kokkos::View<int*> a("a", n)` 创建一个类型为 int* 的一维视图，其中 `"a"` 是标签，`n` 是以整数数量表示的分配大小。Kokkos
    在编译时确定数据的最佳布局，以获得最佳的整体性能，这取决于计算机架构。此外，Kokkos 会自动处理此类内存的释放。有关 Kokkos 视图的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html)。
- en: 'Finally, Kokkos provides three different parallel operations: `parallel_for`,
    `parallel_reduce`, and `parallel_scan`. The `parallel_for` operation is used to
    execute a loop in parallel. The `parallel_reduce` operation is used to execute
    a loop in parallel and reduce the results to a single value. The `parallel_scan`
    operation implements a prefix scan. The usage of `parallel_for` and `parallel_reduce`
    are demonstrated in the examples later in this chapter. More detail about the
    parallel operations are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kokkos 提供了三种不同的并行操作：`parallel_for`、`parallel_reduce` 和 `parallel_scan`。`parallel_for`
    操作用于并行执行循环。`parallel_reduce` 操作用于并行执行循环并将结果归约到单个值。`parallel_scan` 操作实现了前缀扫描。`parallel_for`
    和 `parallel_reduce` 的用法将在本章后面的示例中演示。有关并行操作的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html)。
- en: Run Kokkos hello.cpp example in simple steps
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单步骤运行 Kokkos hello.cpp 示例
- en: The following should work on AMD VEGA90A devices straight out of the box (needs
    ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use
    the variables commented out on the Makefile.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容在 AMD VEGA90A 设备上直接使用应该可以工作（需要 ROCm 安装）。在 NVIDIA Volta V100 设备上（需要 CUDA
    安装），请使用 Makefile 中注释掉的变量。
- en: '`git clone https://github.com/kokkos/kokkos.git`'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`git clone https://github.com/kokkos/kokkos.git`'
- en: Copy the above Makefile into the current folder (make sure the indentation of
    the last line is tab, and not space)
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 Makefile 复制到当前文件夹中（确保最后一行的缩进是制表符，而不是空格）
- en: Copy the above hello.cpp file into the current folder
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 hello.cpp 文件复制到当前文件夹
- en: '`make`'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`make`'
- en: '`./hello`'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`./hello`'
- en: OpenCL
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCL
- en: OpenCL is a cross-platform, open-standard API for writing parallel programs
    that execute across heterogeneous platforms consisting of CPUs, GPUs, FPGAs and
    other devices. The first version of OpenCL (1.0) was released in December 2008,
    and the latest version of OpenCL (3.0) was released in September 2020\. OpenCL
    is supported by a number of vendors, including AMD, ARM, Intel, NVIDIA, and Qualcomm.
    It is a royalty-free standard, and the OpenCL specification is maintained by the
    Khronos Group. OpenCL provides a low-level programming interface initially based
    on C, but more recently also a C++ interface has become available.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 是一个跨平台的开放标准 API，用于编写在由 CPU、GPU、FPGA 和其他设备组成的异构平台上执行的并行程序。OpenCL 的第一个版本（1.0）于
    2008 年 12 月发布，OpenCL 的最新版本（3.0）于 2020 年 9 月发布。OpenCL 获得了包括 AMD、ARM、Intel、NVIDIA
    和 Qualcomm 在内的许多厂商的支持。它是一个免版税标准，OpenCL 规范由 Khronos Group 维护。OpenCL 提供了一个基于 C 的低级编程接口，但最近也提供了一种
    C++ 接口。
- en: OpenCL compilation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL 编译
- en: 'OpenCL supports two modes for compiling the programs: online and offline. Online
    compilation occurs at runtime, when the host program calls a function to compile
    the source code. Online mode allows dynamic generation and loading of kernels,
    but may incur some overhead due to compilation time and possible errors. Offline
    compilation occurs before runtime, when the source code of a kernel is compiled
    into a binary format that can be loaded by the host program. This mode allows
    faster execution and better optimization of kernels, but may limit the portability
    of the program, because the binary can only run on the architectures it was compiled
    for.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 支持两种编译程序的模式：在线和离线。在线编译发生在运行时，当宿主程序调用一个函数来编译源代码时。在线模式允许动态生成和加载内核，但可能会因为编译时间和可能的错误而带来一些开销。离线编译发生在运行之前，当内核的源代码被编译成可以被宿主程序加载的二进制格式时。这种模式允许更快的执行和更好的内核优化，但可能会限制程序的移植性，因为二进制文件只能在编译时指定的架构上运行。
- en: 'OpenCL comes bundled with several parallel programming ecosystems, such as
    NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such
    packages and setting up the environment, one may simply compile an OpenCL program
    by the commands such as `icx cl_devices.c -lOpenCL` (Intel oneAPI) or `nvcc cl_devices.c
    -lOpenCL` (NVIDIA CUDA), where `cl_devices.c` is the compiled file. Unlike most
    other programming models, OpenCL stores kernels as text and compiles them for
    the device in runtime (JIT-compilation), and thus does not require any special
    compiler support: one can compile the code using simply `gcc cl_devices.c -lOpenCL`
    (or `g++` when using C++ API), as long as the required libraries and headers are
    installed in a standard locations.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 随带几个并行编程生态系统，例如 NVIDIA CUDA 和 Intel oneAPI。例如，在成功安装这些包并设置环境之后，可以通过如 `icx
    cl_devices.c -lOpenCL`（Intel oneAPI）或 `nvcc cl_devices.c -lOpenCL`（NVIDIA CUDA）这样的命令简单地编译一个
    OpenCL 程序，其中 `cl_devices.c` 是编译后的文件。与大多数其他编程模型不同，OpenCL 将内核存储为文本，并在运行时（即时编译）为设备编译，因此不需要任何特殊的编译器支持：只要所需的库和头文件安装在了标准位置，就可以使用
    `gcc cl_devices.c -lOpenCL`（或使用 C++ API 时的 `g++`）来编译代码。
- en: 'The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the
    latter with some limitations. To compile a program, you can use the AMD compilers
    on a GPU partition:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 安装在 LUMI 上的 AMD 编译器支持 OpenCL C 和 C++ API，后者有一些限制。要编译程序，您可以使用 GPU 分区的 AMD 编译器：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: OpenCL programming
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL 编程
- en: 'OpenCL programs consist of two parts: a host program that runs on the host
    device (usually a CPU) and one or more kernels that run on compute devices (such
    as GPUs). The host program is responsible for the tasks such as managing the devices
    for the selected platform, allocating memory objects, building and enqueueing
    kernels, and managing memory objects.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 程序由两部分组成：在主机设备（通常是 CPU）上运行的宿主程序和在一个或多个计算设备（如 GPU）上运行的内核。宿主程序负责管理所选平台上的设备、分配内存对象、构建和排队内核以及管理内存对象。
- en: The first steps when writing an OpenCL program are to initialize the OpenCL
    environment by selecting the platform and devices, creating a context or contexts
    associated with the selected device(s), and creating a command queue for each
    device. A simple example of selecting the default device, creating a context and
    a queue associated with the device is show below.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 编写 OpenCL 程序的第一步是初始化 OpenCL 环境，通过选择平台和设备，创建与所选设备关联的上下文或上下文，并为每个设备创建一个命令队列。选择默认设备、创建与设备关联的上下文和队列的简单示例如下。
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'OpenCL provides two main programming models to manage the memory hierarchy
    of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers
    are the traditional memory model of OpenCL, where the host and the devices have
    separate address spaces and the programmer has to explicitly specify the memory
    allocations and how and where the memory is accessed. This can be done with class
    `cl::Buffer` and functions such as `cl::CommandQueue::enqueueReadBuffer()`. Buffers
    are supported since early versions of OpenCL, and work well across different architectures.
    Buffers can also take advantage of device-specific memory features, such as constant
    or local memory.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL提供了两种主要的编程模型来管理主机和加速设备设备的内存层次结构：缓冲区和共享虚拟内存（SVM）。缓冲区是OpenCL的传统内存模型，其中主机和设备有独立的地址空间，程序员必须显式指定内存分配以及如何以及在哪里访问内存。这可以通过`cl::Buffer`类和如`cl::CommandQueue::enqueueReadBuffer()`等函数来完成。缓冲区自OpenCL的早期版本以来就得到了支持，并且在不同架构上运行良好。缓冲区还可以利用特定于设备的内存功能，如常量或局部内存。
- en: SVM is a newer memory model of OpenCL, introduced in version 2.0, where the
    host and the devices share a single virtual address space. Thus, the programmer
    can use the same pointers to access the data from host and devices simplifying
    the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained
    buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow
    using the same pointers across a host and devices, but they differ in their granularity
    and synchronization requirements for the memory regions. Furthermore, the support
    for SVM is not universal across all OpenCL platforms and devices, and for example,
    GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer.
    This level requires explicit synchronization for memory accesses from a host and
    devices (using functions such as `cl::CommandQueue::enqueueMapSVM()` and `cl::CommandQueue::enqueueUnmapSVM()`),
    making the usage of SVM less convenient. It is further noted that this is unlike
    the regular Unified Memory offered by CUDA, which is closer to the fine-grained
    system SVM level in OpenCL.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是OpenCL中的一种较新的内存模型，在2.0版本中引入，其中主机和设备共享单个虚拟地址空间。因此，程序员可以使用相同的指针从主机和设备访问数据，从而简化编程工作。在OpenCL中，SVM有不同级别，如粗粒度缓冲区SVM、细粒度缓冲区SVM和细粒度系统SVM。所有级别都允许在主机和设备之间使用相同的指针，但它们在内存区域的粒度和同步要求上有所不同。此外，SVM的支持并非在所有OpenCL平台和设备上都是通用的，例如，NVIDIA
    V100和A100这样的GPU仅支持粗粒度SVM缓冲区。这一级别需要显式同步从主机和设备对内存的访问（使用如`cl::CommandQueue::enqueueMapSVM()`和`cl::CommandQueue::enqueueUnmapSVM()`等函数），这使得SVM的使用不太方便。值得注意的是，这与CUDA提供的常规统一内存不同，CUDA更接近于OpenCL中的细粒度系统SVM级别。
- en: OpenCL uses a separate-source kernel model where the kernel code is often kept
    in separate files that may be compiled during runtime. The model allows the kernel
    source code to be passed as a string to the OpenCL driver after which the program
    object can be executed on a specific device. Although referred to as the separate-source
    kernel model, the kernels can still be defined as a string in the host program
    compilation units as well, which may be a more convenient approach in some cases.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL使用独立源内核模型，其中内核代码通常保存在单独的文件中，这些文件可以在运行时编译。该模型允许将内核源代码作为字符串传递给OpenCL驱动程序，之后程序对象可以在特定设备上执行。尽管被称为独立源内核模型，但内核也可以在主机程序编译单元中以字符串的形式定义，这在某些情况下可能更方便。
- en: The online compilation with the separate-source kernel model has several advantages
    over the binary model, which requires offline compilation of kernels into device-specific
    binaries that can are loaded by the application at runtime. Online compilation
    preserves the portability and flexibility of OpenCL, as the same kernel source
    code can run on any supported device. Furthermore, dynamic optimization of kernels
    based on runtime information, such as input size, work-group size, or device capabilities,
    is possible. An example of an OpenCL kernel, defined by a string in the host compilation
    unit, and assigning the global thread index into a global device memory is shown
    below.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用独立源内核模型的在线编译相较于需要离线编译内核为特定设备二进制的二进制模型具有多个优势。在线编译保留了OpenCL的可移植性和灵活性，因为相同的内核源代码可以在任何支持的设备上运行。此外，基于运行时信息（如输入大小、工作组大小或设备能力）的内核动态优化也是可能的。以下是一个OpenCL内核的示例，它由主机编译单元中的字符串定义，并将全局线程索引分配到全局设备内存中。
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The above kernel named `dot` and stored in the string `kernel_source` can be
    set to build in the host code as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的名为 `dot` 并存储在字符串 `kernel_source` 中的内核可以设置在主机代码中构建，如下所示：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: SYCL
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SYCL
- en: '[SYCL](https://www.khronos.org/sycl/) is a royalty-free, open-standard C++
    programming model for multi-device programming. It provides a high-level, single-source
    programming model for heterogeneous systems, including GPUs. There are several
    implementations of the standard. For GPU programming, [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    and [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) (also known as
    hipSYCL) are the most popular for desktop and HPC GPUs; [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    is a good choice for embedded devices. The same standard-compliant SYCL code should
    work with any implementation, but they are not binary-compatible.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[SYCL](https://www.khronos.org/sycl/) 是一个免版税的开放标准 C++ 编程模型，用于多设备编程。它为异构系统提供了一种高级、单源编程模型，包括
    GPU。该标准有几个实现。对于 GPU 编程，[Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    和 [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)（也称为 hipSYCL）是桌面和
    HPC GPU 中最受欢迎的；[ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    是嵌入式设备的良好选择。相同的标准兼容 SYCL 代码应该可以与任何实现一起工作，但它们不是二进制兼容的。'
- en: The most recent version of the SYCL standard is SYCL 2020, and it is the version
    we will be using in this course.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: SYCL 标准的最新版本是 SYCL 2020，这是我们将在本课程中使用的版本。
- en: SYCL compilation
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL 编译
- en: Intel oneAPI DPC++
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Intel oneAPI DPC++
- en: For targeting Intel GPUs, it is enough to install [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html).
    Then, the compilation is as simple as `icpx -fsycl file.cpp`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Intel GPU，只需安装 [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html)
    即可。然后，编译就像 `icpx -fsycl file.cpp` 那么简单。
- en: 'It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI
    Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding
    [Codeplay oneAPI plugin](https://codeplay.com/solutions/oneapi/) must be installed.
    Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用 oneAPI 为 NVIDIA 和 AMD GPU。除了 oneAPI Base Toolkit 之外，还需要安装供应商提供的运行时（CUDA
    或 HIP）以及相应的 [Codeplay oneAPI 插件](https://codeplay.com/solutions/oneapi/)。然后，可以使用包含在
    oneAPI 中的 Intel LLVM 编译器编译代码：
- en: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` for targeting CUDA
    8.6 NVIDIA GPU,'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` 用于针对 CUDA 8.6 NVIDIA
    GPU，'
- en: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` for targeting GFX90a AMD GPU.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` 用于针对 GFX90a AMD GPU。'
- en: AdaptiveCpp
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AdaptiveCpp
- en: 'Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed
    first. Then `acpp` can be used for compiling the code, specifying the target devices.
    For example, here is how to compile the program supporting an AMD and an NVIDIA
    device:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AdaptiveCpp 为 NVIDIA 或 AMD GPU 也需要首先安装 CUDA 或 HIP。然后可以使用 `acpp` 编译代码，指定目标设备。例如，以下是如何编译支持
    AMD 和 NVIDIA 设备的程序：
- en: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
- en: Using SYCL on LUMI
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 LUMI 上使用 SYCL
- en: 'LUMI does not have a system-wide installation of any SYCL framework, but a
    recent AdaptiveCpp installation is available in CSC modules:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI 没有系统范围内安装任何 SYCL 框架，但 CSC 模块中有一个最新的 AdaptiveCpp 安装：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The default compilation target is preset to MI250 GPUs, so to compile a single
    C++ file it is enough to call `acpp -O2 file.cpp`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 默认编译目标预设为 MI250 GPU，因此要编译单个 C++ 文件，只需调用 `acpp -O2 file.cpp` 即可。
- en: 'When running applications built with AdaptiveCpp, one can often see the warning
    “dag_direct_scheduler: Detected a requirement that is neither of discard access
    mode”, reflecting the lack of an optimization hint when using buffer-accessor
    model. The warning is harmless and can be ignored.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '当运行使用 AdaptiveCpp 构建的程序时，经常会看到警告“dag_direct_scheduler: Detected a requirement
    that is neither of discard access mode”，这反映了在使用缓冲区访问模型时缺少优化提示。警告是无害的，可以忽略。'
- en: SYCL programming
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL 编程
- en: SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source
    model with kernel lambdas.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，SYCL 与 OpenCL 类似，但像 Kokkos 一样使用具有内核 lambdas 的单源模型。
- en: 'To submit a task to device, first a sycl::queue must be created, which is used
    as a way to manage the task scheduling and execution. In the simplest case, that’s
    all the initialization one needs:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要将任务提交到设备，首先必须创建一个 sycl::queue，它用作管理任务调度和执行的方式。在最简单的情况下，这就是所需的全部初始化：
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If one wants more control, the device can be explicitly specified, or additional
    properties can be passed to a queue:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果想要更多控制，可以显式指定设备，或者可以向队列传递额外的属性：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Memory management can be done in two different ways: *buffer-accessor* model
    and *unified shared memory* (USM). The choice of the memory management models
    also influences how the GPU tasks are synchronized.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理可以通过两种不同的方式完成：*缓冲访问器*模型和*统一共享内存*（USM）。内存管理模型的选择也会影响GPU任务的同步方式。
- en: 'In the *buffer-accessor* model, a `sycl::buffer` objects are used to represent
    arrays of data. A buffer is not mapped to any single one memory space, and can
    be migrated between the GPU and the CPU memory transparently. The data in `sycl::buffer`
    cannot be read or written directly, an accessor must be created. `sycl::accessor`
    objects specify the location of data access (host or a certain GPU kernel) and
    the access mode (read-only, write-only, read-write). Such approach allows optimizing
    task scheduling by building a directed acyclic graph (DAG) of data dependencies:
    if kernel *A* creates a write-only accessor to a buffer, and then kernel *B* is
    submitted with a read-only accessor to the same buffer, and then a host-side read-only
    accessor is requested, then it can be deduced that *A* must complete before *B*
    is launched and also that the results must be copied to the host before the host
    task can proceed, but the host task can run in parallel with kernel *B*. Since
    the dependencies between tasks can be built automatically, by default SYCL uses
    *out-of-order queues*: when two tasks are submitted to the same `sycl::queue`,
    it is not guaranteed that the second one will launch only after the first one
    completes. When launching a kernel, accessors must be created:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在*缓冲访问器*模型中，使用`sycl::buffer`对象来表示数据数组。缓冲区没有映射到任何单一内存空间，并且可以透明地在GPU和CPU内存之间迁移。`sycl::buffer`中的数据不能直接读取或写入，必须创建访问器。`sycl::accessor`对象指定数据访问的位置（主机或某个GPU内核）以及访问模式（只读、只写、读写）。这种方法允许通过构建数据依赖的有向无环图（DAG）来优化任务调度：如果内核*A*创建了一个对缓冲区的只写访问器，然后内核*B*提交了一个对同一缓冲区的只读访问器，然后请求主机端的只读访问器，那么可以推断出*A*必须在*B*启动之前完成，并且结果必须在主机任务可以继续之前复制到主机，但主机任务可以与内核*B*并行运行。由于任务之间的依赖关系可以自动构建，因此默认情况下SYCL使用*乱序队列*：当两个任务提交到同一个`sycl::queue`时，不能保证第二个任务只有在第一个任务完成后才会启动。在启动内核时，必须创建访问器：
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Buffer-accessor model simplifies many aspects of heterogeneous programming and
    prevents many synchronization-related bugs, but it only allows very coarse control
    of data movement and kernel execution.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲访问器模型简化了异构编程的许多方面，并防止了许多与同步相关的错误，但它只允许对数据移动和内核执行进行非常粗略的控制。
- en: 'The *USM* model is similar to how NVIDIA CUDA or AMD HIP manage memory. The
    programmer has to explicitly allocate the memory on the device (`sycl::malloc_device`),
    on the host (`sycl::malloc_host`), or in the shared memory space (`sycl::malloc_shared`).
    Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
    all USM allocations are shared: for example, a memory allocated by `sycl::malloc_device`
    cannot be accessed from the host. The allocation functions return memory pointers
    that can be used directly, without accessors. This means that the programmer have
    to ensure the correct synchronization between host and device tasks to avoid data
    races. With USM, it is often convenient to use *in-order queues* with USM, instead
    of the default *out-of-order* queues. More information on USM can be found in
    the [Section 4.8 of SYCL 2020 specification](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*USM*模型类似于NVIDIA CUDA或AMD HIP管理内存的方式。程序员必须显式地在设备上分配内存（`sycl::malloc_device`）、在主机上（`sycl::malloc_host`）或在共享内存空间中（`sycl::malloc_shared`）。尽管名为统一共享内存，并且与OpenCL的SVM相似，但并非所有USM分配都是共享的：例如，由`sycl::malloc_device`分配的内存不能从主机访问。分配函数返回可以直接使用的内存指针，无需访问器。这意味着程序员必须确保主机和设备任务之间的正确同步，以避免数据竞争。使用USM时，通常更方便使用*顺序队列*而不是默认的*乱序队列*。有关USM的更多信息，请参阅[SYCL
    2020规范的第4.8节](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm)。'
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Exercise
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Implement SAXPY in SYCL'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在SYCL中实现SAXPY
- en: In this exercise we would like to write (fill-in-the-blanks) a simple code doing
    SAXPY (vector addition).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们想要编写（填空）一段简单的代码，用于执行SAXPY（向量加法）。
- en: 'To compile and run the code interactively, first make an allocation and load
    the AdaptiveCpp module:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，首先进行分配并加载 AdaptiveCpp 模块：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以运行一个简单的设备检测实用程序来检查 GPU 是否可用（注意 `srun`）：
- en: '[PRE16]'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE16]'
- en: If you have not done it already, clone the repository using `git clone https://github.com/ENCCS/gpu-programming.git`
    or **update it** using `git pull origin main`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有做，请使用 `git clone https://github.com/ENCCS/gpu-programming.git` 或 **更新**
    它使用 `git pull origin main` 来克隆仓库。
- en: 'Now, let’s look at the example code in `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp` 中的示例代码：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To compile and run the code, use the following command:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The code will not compile as-is! Your task is to fill in missing bits indicated
    by `TODO` comments. You can also test your understanding using the “Bonus questions”
    in the code.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将无法直接编译！你的任务是填写由 `TODO` 注释指示的缺失部分。你还可以通过代码中的“Bonus questions”来测试你的理解。
- en: If you feel stuck, take a look at the `exercise-sycl-saxpy-solution.cpp` file.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感到卡壳，可以查看 `exercise-sycl-saxpy-solution.cpp` 文件。
- en: alpaka
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: alpaka
- en: The [alpaka](https://github.com/alpaka-group/alpaka3) library is an open-source
    header-only C++20 abstraction library for accelerator development.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[alpaka](https://github.com/alpaka-group/alpaka3) 库是一个开源的仅包含头文件的 C++20 抽象库，用于加速器开发。'
- en: Its aim is to provide performance portability across accelerators by abstracting
    the underlying levels of parallelism. The project provides a single-source C++
    API that enables developers to write parallel code once and run it on different
    hardware architectures without modification. The name “alpaka” comes from **A**bstractions
    for **L**evels of **P**arallelism, **A**lgorithms, and **K**ernels for **A**ccelerators.
    The library is platform-independent and supports the concurrent and cooperative
    use of multiple devices, including host CPUs (x86, ARM, and RISC-V) and GPUs from
    different vendors (NVIDIA, AMD, and Intel). A variety of accelerator backends,
    CUDA, HIP, SYCL, OpenMP, and serial execution, are available and can be selected
    based on the target device. Only a single implementation of a user kernel is required,
    expressed as a function object with a standardized interface. This eliminates
    the need to write specialized CUDA, HIP, SYCL, OpenMP, Intel TBB or threading
    code. Moreover, multiple accelerator backends can be combined to target different
    vendor hardware within a single system and even within a single application.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 其目的是通过抽象底层并行级别，在加速器之间提供性能可移植性。该项目提供了一个单一的 C++ API，使开发者能够编写一次并行代码，并在不同的硬件架构上运行而无需修改。名称“alpaka”来自
    **A**bstractions for **L**evels of **P**arallelism, **A**lgorithms, and **K**ernels
    for **A**ccelerators。该库是平台无关的，并支持多个设备的并发和协作使用，包括主机 CPU（x86、ARM 和 RISC-V）以及来自不同厂商的
    GPU（NVIDIA、AMD 和 Intel）。提供了各种加速器后端，如 CUDA、HIP、SYCL、OpenMP 和串行执行，可以根据目标设备进行选择。只需要一个用户内核的实现，以具有标准化接口的函数对象的形式表达。这消除了编写专门的
    CUDA、HIP、SYCL、OpenMP、Intel TBB 或线程代码的需求。此外，可以将多个加速器后端组合起来，以针对单个系统甚至单个应用程序中的不同厂商硬件进行目标定位。
- en: The abstraction is based on a virtual index domain decomposed into equally sized
    chunks called frames. **alpaka** provides a uniform abstraction to traverse these
    frames, independent of the underlying hardware. Algorithms to be parallelized
    map the chunked index domain and native worker threads onto the data, expressing
    the computation as kernels that are executed in parallel threads (SIMT), thereby
    also leveraging SIMD units. Unlike native parallelism models such as CUDA, HIP,
    and SYCL, **alpaka** kernels are not restricted to three dimensions. Explicit
    caching of data within a frame via shared memory allows developers to fully unleash
    the performance of the compute device. Additionally, **alpaka** offers primitive
    functions such as iota, transform, transform-reduce, reduce, and concurrent, simplifying
    the development of portable high-performance applications. Host, device, mapped,
    and managed multi-dimensional views provide a natural way to operate on data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象基于一个虚拟索引域，该域被分解成称为帧的等大小块。**alpaka** 提供了一个统一的抽象来遍历这些帧，与底层硬件无关。要并行化的算法将分块索引域和本地工作线程映射到数据上，将计算表示为在并行线程（SIMT）中执行的内核，从而也利用了
    SIMD 单元。与 CUDA、HIP 和 SYCL 等原生并行模型不同，**alpaka** 内核不受三维的限制。通过共享内存显式缓存帧内的数据允许开发者充分发挥计算设备性能。此外，**alpaka**
    提供了诸如 iota、transform、transform-reduce、reduce 和 concurrent 等原始函数，简化了可移植高性能应用程序的开发。主机、设备、映射和管理多维视图提供了一种自然的方式来操作数据。
- en: Here we demonstrate the usage of **alpaka3**, which is a complete rewrite of
    [alpaka](https://github.com/alpaka-group/alpaka). It is planned to merge this
    separate codebase back into the mainline alpaka repository before the first release
    in Q2/Q3 of 2026. Nevertheless, the code is well-tested and can be used for development
    today.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们展示了 **alpaka3** 的使用方法，它是 [alpaka](https://github.com/alpaka-group/alpaka)
    的完全重写。计划在2026年第二季度/第三季度的第一次发布之前，将这个独立的代码库合并回主线 alpaka 仓库。尽管如此，代码经过了良好的测试，并且可以用于今天的开发。
- en: Installing alpaka on your system
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在您的系统上安装 alpaka
- en: For ease of use, we recommend installing alpaka using CMake as described below.
    For other ways to use alpaka in your projects, see the [alpaka3 documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们建议按照以下说明使用 CMake 安装 alpaka。有关在项目中使用 alpaka 的其他方法，请参阅 [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)。
- en: '**Clone the repository**'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**克隆仓库**'
- en: 'Clone the alpaka source code from GitHub to a directory of your choice:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从 GitHub 克隆 alpaka 源代码到您选择的目录：
- en: '[PRE19]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**Set installation directory**'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置安装目录**'
- en: Set the `ALPAKA_DIR` environment variable to the directory where you want to
    install alpaka. This can be any directory you choose where you have write access.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 `ALPAKA_DIR` 环境变量设置为想要安装 alpaka 的目录。这可以是您选择的任何目录，只要您有写入权限。
- en: '[PRE20]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Build and install**'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建和安装**'
- en: Create a build directory and use CMake to build and install alpaka. We use `CMAKE_INSTALL_PREFIX`
    to tell CMake where to install the library.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一个构建目录，并使用 CMake 构建和安装 alpaka。我们使用 `CMAKE_INSTALL_PREFIX` 来告诉 CMake 将库安装在哪里。
- en: '[PRE21]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**Update environment**'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新环境**'
- en: 'To make sure that other projects can find your alpaka installation, you should
    add the installation directory to your `CMAKE_PREFIX_PATH`. You can do this by
    adding the following line to your shell configuration file (e.g. `~/.bashrc`):'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保其他项目可以找到您的 alpaka 安装，您应该将安装目录添加到您的 `CMAKE_PREFIX_PATH` 中。您可以通过将以下行添加到您的
    shell 配置文件（例如 `~/.bashrc`）来实现：
- en: '[PRE22]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You will need to source your shell configuration file or open a new terminal
    for the changes to take effect.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要源您的 shell 配置文件或打开一个新的终端，以便更改生效。
- en: alpaka Compilation
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编译
- en: We recommend building your projects which use alpaka using CMake. A variety
    of strategies can be used to deal with building your application for a specific
    device or set of devices. Here we show a minimal way to get started, but this
    is by no means the only way to set up your projects. Please refer to the [alpaka3
    documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html) for
    alternative ways to use alpaka in your project, including a way to make your source
    code agnostic to the accelerator being targeted by defining a device specification
    in CMake.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用 CMake 构建使用 alpaka 的项目。可以采用各种策略来处理为特定设备或设备集构建应用程序。在这里，我们展示了入门的最小方法，但这绝不是设置项目的唯一方法。请参阅
    [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)，了解在项目中使用
    alpaka 的其他方法，包括在 CMake 中定义设备规范以使源代码与目标加速器无关的方法。
- en: 'The following example demonstrates a `CMakeLists.txt` for a single-file project
    using alpaka3 (`main.cpp` which is presented in the section below):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个使用alpaka3的单文件项目的`CMakeLists.txt`（以下章节中展示的`main.cpp`）：
- en: '[PRE23]'
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using alpaka on LUMI
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用alpaka
- en: To load the environment for using the AMD GPUs on LUMI with HIP, one can use
    the following modules -
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载在LUMI上使用AMD GPU的HIP环境，可以使用以下模块 -
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: alpaka Programming
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka编程
- en: 'When starting with alpaka3, the first step is understanding the **device selection
    model**. Unlike frameworks that require explicit initialization calls, alpaka3
    uses a device specification to determine which backend and hardware to use. The
    device specification consists of two components:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用alpaka3时，第一步是理解**设备选择模型**。与需要显式初始化调用的框架不同，alpaka3使用设备规范来确定使用哪个后端和硬件。设备规范由两个组件组成：
- en: '**API**: The parallel programming interface (host, cuda, hip, oneApi)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**：并行编程接口（host、cuda、hip、oneApi）'
- en: '**Device Kind**: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备类型**：硬件类型（cpu、nvidiaGpu、amdGpu、intelGpu）'
- en: Here we specify and use these at runtime to select and initialize devices. The
    device selection process is described in detail in the alpaka3 documentation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定并使用这些规范在运行时选择和初始化设备。设备选择过程在alpaka3文档中有详细描述。
- en: alpaka3 uses an **execution space model** to abstract parallel hardware details.
    A device selector is created using `alpaka::onHost::makeDeviceSelector(devSpec)`,
    which returns an object that can query available devices and create device instances
    for the selected backend.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3使用**执行空间模型**来抽象并行硬件细节。使用`alpaka::onHost::makeDeviceSelector(devSpec)`创建设备选择器，它返回一个可以查询可用设备并为所选后端创建设备实例的对象。
- en: 'The following example demonstrates a basic alpaka program that initializes
    a device and prints information about it:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个基本的alpaka程序，该程序初始化一个设备并打印有关它的信息：
- en: '[PRE25]'
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE25]'
- en: alpaka3 provides memory management abstractions through buffers and views. Memory
    can be allocated on host or device using `alpaka::allocBuf<T, Idx>(device, extent)`.
    Data transfers between host and device are handled through `alpaka::memcpy(queue,
    dst, src)`. The library automatically manages memory layouts for optimal performance
    on different architectures.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3通过缓冲区和视图提供内存管理抽象。可以使用`alpaka::allocBuf<T, Idx>(device, extent)`在主机或设备上分配内存。主机和设备之间的数据传输通过`alpaka::memcpy(queue,
    dst, src)`处理。该库自动管理不同架构上的内存布局以实现最佳性能。
- en: For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined
    as functors or lambda functions and executed using work division specifications
    that define the parallelization strategy. The framework supports various parallel
    patterns including element-wise operations, reductions, and scans.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行执行，alpaka3提供内核抽象。内核定义为函数式对象或lambda函数，并使用定义并行化策略的工作划分规范执行。该框架支持各种并行模式，包括逐元素操作、归约和扫描。
- en: Tour of **alpaka** Features
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**alpaka**功能巡礼'
- en: Now we will quickly explore the most commonly used features of alpaka and go
    over some basic usage. A quick reference of commonly used alpaka features is available
    [here.](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将快速探索alpaka最常用的功能，并简要介绍一些基本用法。常用的alpaka功能快速参考可在[这里](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)找到。
- en: '**General setup**: Include the consolidated header once and you are ready to
    start using alpaka.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用设置**：只需包含一次综合头文件，你就可以开始使用alpaka了。'
- en: '[PRE26]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '**Accelerator, platform, and device management**: Select devices by combining
    the desired API with the appropriate hardware kind using the device selector.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速器、平台和设备管理**：通过设备选择器结合所需的API和适当的硬件类型来选择设备。'
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**Queues and events**: Create blocking or non-blocking queues per device, record
    events, and synchronize work as needed.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**队列和事件**：为每个设备创建阻塞或非阻塞队列，记录事件，并根据需要同步工作。'
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Memory management**: Allocate host, device, mapped, unified, or deferred
    buffers, create non-owning views, and move data portably with memcpy, memset,
    and fill.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存管理**：分配主机、设备、映射、统一或延迟缓冲区，创建非拥有视图，并使用memcpy、memset和fill移动数据。'
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Kernel execution**: Build a FrameSpec manually or request one tuned for your
    data type, then enqueue kernels with automatic or explicit executors.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核执行**：手动构建FrameSpec或请求针对您数据类型调优的一个，然后使用自动或显式执行器排队内核。'
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '**Kernel implementation**: Write kernels as functors annotated with ALPAKA_FN_ACC,
    use shared memory, synchronization, atomics, and math helpers directly inside
    the kernel body.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核实现**：将内核作为带有 ALPAKA_FN_ACC 注解的函数编写，使用共享内存、同步、原子操作和数学助手直接在内核体内部。'
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Run alpaka3 Example in Simple Steps
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单步骤运行 alpaka3 示例
- en: The following example works on systems with CMake 3.25+ and an appropriate C++
    compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or
    oneAPI) is installed.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于 CMake 3.25+ 和适当的 C++ 编译器的系统。对于 GPU 执行，请确保已安装相应的运行时（CUDA、ROCm 或 oneAPI）。
- en: 'Create a directory for your project:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为你的项目创建一个目录：
- en: '[PRE32]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Copy the CMakeLists.txt from above into the current folder
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 CMakeLists.txt 复制到当前文件夹
- en: Copy the main.cpp file into the current folder
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 main.cpp 文件复制到当前文件夹
- en: 'Configure and build:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和构建：
- en: '[PRE33]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Run the executable:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行可执行文件：
- en: '[PRE34]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The device specification system allows you to select the target device at CMake
    configuration time. The format is `"api:deviceKind"`, where:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 设备规范系统允许你在 CMake 配置时间选择目标设备。格式为 `"api:deviceKind"`，其中：
- en: '**api**: The parallel programming interface (`host`, `cuda`, `hip`, `oneApi`)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api**：并行编程接口（`host`、`cuda`、`hip`、`oneApi`）'
- en: '**deviceKind**: The type of device (`cpu`, `nvidiaGpu`, `amdGpu`, `intelGpu`)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deviceKind**：设备的类型（`cpu`、`nvidiaGpu`、`amdGpu`、`intelGpu`）'
- en: 'Available combinations are: `host:cpu`, `cuda:nvidiaGpu`, `hip:amdGpu`, `oneApi:cpu`,
    `oneApi:intelGpu`, `oneApi:nvidiaGpu`, `oneApi:amdGpu`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的组合有：`host:cpu`、`cuda:nvidiaGpu`、`hip:amdGpu`、`oneApi:cpu`、`oneApi:intelGpu`、`oneApi:nvidiaGpu`、`oneApi:amdGpu`
- en: Warning
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI
    SDK are available respectively
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 CUDA SDK、HIP SDK 或 OneAPI SDK 可用时，CUDA、HIP 或 Intel 后端才有效
- en: Expected output
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预期输出
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD
    MI250X”, or your CPU model).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 设备名称将根据你的硬件而变化（例如，“NVIDIA A100”、“AMD MI250X”或你的 CPU 型号）。
- en: Compile and Execute Examples
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译和执行示例
- en: You can test the **alpaka** provided examples from the [example section](#examples).
    The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
    To switch to CPU usage only you can simply replace `ap::onHost::makeDeviceSelector(ap::api::hip,
    ap::deviceKind::amdGpu);` with `ap::onHost::makeDeviceSelector(ap::api::host,
    ap::deviceKind::cpu);`
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[示例部分](#examples)测试 alpaka 提供的示例。这些示例在 LUMI 上需要硬编码 AMD ROCm 平台的使用。要仅使用 CPU，你可以简单地替换
    `ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);` 为 `ap::onHost::makeDeviceSelector(ap::api::host,
    ap::deviceKind::cpu);`
- en: The following steps assume you have downloaded alpaka already and the path to
    the **alapka** source code is stored in the environment variable `ALPAKA_DIR`.
    To test the example copy the code into a file `main.cpp`
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤假设你已经下载了 alpaka，并且 alpaka 源代码的路径存储在环境变量 `ALPAKA_DIR` 中。要测试示例，请将代码复制到文件 `main.cpp`
- en: Alternatively, [click here](https://godbolt.org/z/69exnG4xb) to try the first
    example using in the godbolt compiler explorer.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，[点击此处](https://godbolt.org/z/69exnG4xb) 在 godbolt 编译器探索器中尝试第一个示例。
- en: '[PRE36]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA Gpus 的 oneAPI Sycl，你必须安装相应的 Codeplay oneAPI 插件，如[此处](https://codeplay.com/solutions/oneapi/plugins/)所述。
- en: '[PRE41]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA Gpus 的 oneAPI Sycl，你必须安装相应的 Codeplay oneAPI 插件，如[此处](https://codeplay.com/solutions/oneapi/plugins/)所述。
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Exercise
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Write a vector add kernel in alpaka'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在 alpaka 中编写向量加法内核
- en: In this exercise we would like to write (fill-in-the-blanks) a simple kernel
    to add two vectors.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的内核来添加两个向量。
- en: 'To compile and run the code interactively, first we first need to get an allocation
    on a GPU node and load the modules for alpaka:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，我们首先需要在一个 GPU 节点上获取一个分配并加载 alpaka 的模块：
- en: '[PRE43]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行一个简单的设备检测工具来检查是否有 GPU 可用（注意 `srun`）：
- en: '[PRE44]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, let’s look at the code to set up the exercise:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看设置练习的代码：
- en: Below we use fetch content with our CMake to get started with alpaka quickly.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们使用 CMake 的 fetch content 快速开始使用 alpaka。
- en: CMakeLists.txt
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: CMakeLists.txt
- en: '[PRE45]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Below we have the main alpaka code doing a vector addition on device using a
    high level transform function
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们有主要的 alpaka 代码，使用高级转换函数在设备上进行向量加法
- en: main.cpp
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: main.cpp
- en: '[PRE46]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: To set up our project, we create a folder and place our CMakeLists.txt and main.cpp
    in there.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置我们的项目，我们创建一个文件夹，并将我们的CMakeLists.txt和main.cpp放在那里。
- en: '[PRE47]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To compile and run the code, use the following commands:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE48]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now your task will be to write and launch your first alpaka kernel. This kernel
    will do the vector addition and we will use this instead of the transform helper.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务将是编写和启动你的第一个alpaka内核。这个内核将执行向量加法，我们将使用这个代替transform辅助器。
- en: Writing the vector add kernel
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 编写向量加法内核
- en: '[PRE49]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Examples
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: Parallel for with Unified Memory
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带统一内存的并行for循环
- en: '[PRE50]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Parallel for with GPU buffers
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带GPU缓冲区的并行for循环
- en: '[PRE56]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Asynchronous parallel for kernels
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步并行for内核
- en: '[PRE61]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Reduction
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 减少
- en: '[PRE66]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Pros and cons of cross-platform portability ecosystems
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨平台可移植生态系统优缺点
- en: General observations
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一般观察
- en: The amount of code duplication is minimized.
  id: totrans-261
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码重复量最小化。
- en: ''
  id: totrans-262
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-263
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The same code can be compiled to multiple architectures from different vendors.
  id: totrans-264
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一段代码可以编译成来自不同供应商的多种架构。
- en: ''
  id: totrans-265
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-266
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited learning resources compared to CUDA (Stack Overflow, course material,
    documentation).
  id: totrans-267
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与CUDA相比，学习资源有限（Stack Overflow、课程材料、文档）。
- en: Lambda-based kernel models (Kokkos, SYCL)
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Lambda的内核模型（Kokkos, SYCL）
- en: Higher level of abstraction.
  id: totrans-269
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高级别的抽象。
- en: ''
  id: totrans-270
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-271
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Less knowledge of the underlying architecture is needed for initial porting.
  id: totrans-272
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始移植所需的底层架构知识较少。
- en: ''
  id: totrans-273
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-274
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very nice and readable source code (C++ API).
  id: totrans-275
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好读的源代码（C++ API）。
- en: ''
  id: totrans-276
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-277
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The models are relatively new and not very popular yet.
  id: totrans-278
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些模型相对较新，尚未非常流行。
- en: Functor-based kernel model (alpaka)
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Functor的内核模型（alpaka）
- en: Very good portability.
  id: totrans-280
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-281
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-282
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Higher level of abstraction.
  id: totrans-283
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高级别的抽象。
- en: ''
  id: totrans-284
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-285
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API always awailable which gives more control and allows fine tuning.
  id: totrans-286
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API始终可用，这提供了更多控制并允许微调。
- en: ''
  id: totrans-287
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-288
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: User friendly C++ API for both the host and kernel code.
  id: totrans-289
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为主机和内核代码提供用户友好的C++ API。
- en: ''
  id: totrans-290
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-291
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Small community and ecosystem.
  id: totrans-292
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型社区和生态系统。
- en: Separate-source kernel models (OpenCL)
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 独立源代码内核模型（OpenCL）
- en: Very good portability.
  id: totrans-294
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-295
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-296
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mature ecosystem.
  id: totrans-297
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成熟的生态系统。
- en: ''
  id: totrans-298
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-299
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited number of vendor-provided libraries.
  id: totrans-300
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商提供的库数量有限。
- en: ''
  id: totrans-301
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-302
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API gives more control and allows fine tuning.
  id: totrans-303
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API提供了更多控制并允许微调。
- en: ''
  id: totrans-304
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-305
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both C and C++ APIs available (C++ API is less well supported).
  id: totrans-306
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供C和C++ API（C++ API支持较差）。
- en: ''
  id: totrans-307
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-308
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The low-level API and separate-source kernel model are less user friendly.
  id: totrans-309
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API和独立源代码内核模型对用户不太友好。
- en: C++ Standard Parallelism (StdPar, PSTL)
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++标准并行（StdPar、PSTL）
- en: Very high level of abstraction.
  id: totrans-311
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常高级的抽象。
- en: ''
  id: totrans-312
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-313
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Easy to speed up code which already relying on STL algorithms.
  id: totrans-314
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易加速依赖于STL算法的代码。
- en: ''
  id: totrans-315
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-316
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very little control over hardware.
  id: totrans-317
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对硬件的控制非常有限。
- en: ''
  id: totrans-318
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-319
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Support by compilers is improving, but is far from mature.
  id: totrans-320
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器的支持正在改善，但尚未成熟。
- en: Keypoints
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: General code organization is similar to non-portable kernel-based models.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用代码组织与非可移植的基于内核的模型相似。
- en: As long as no vendor-specific functionality is used, the same code can run on
    any GPU. [Previous](../7-non-portable-kernel-models/ "Non-portable kernel-based
    models") [Next](../9-language-support/ "High-level language support")
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要没有使用特定于供应商的功能，相同的代码可以在任何GPU上运行。[上一页](../7-non-portable-kernel-models/ "非可移植的基于内核的模型")
    [下一页](../9-language-support/ "高级语言支持")
- en: '* * *'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: © Copyright 2023-2024, The contributors.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: © 版权所有 2023-2024，贡献者。
- en: Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). Questions
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Read the Docs](https://readthedocs.org)提供的[主题](https://github.com/readthedocs/sphinx_rtd_theme)和[Sphinx](https://www.sphinx-doc.org/)构建。问题
- en: How to program GPUs with alpaka, C++ StdPar, Kokkos, OpenCL, and SYCL?
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用alpaka、C++ StdPar、Kokkos、OpenCL和SYCL编程GPU？
- en: What are the differences between these programming models.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些编程模型之间有什么区别？
- en: Objectives
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Be able to use portable kernel-based models to write simple codes
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用可移植的基于内核的模型编写简单代码
- en: Understand how different approaches to memory and synchronization in Kokkos
    and SYCL work
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kokkos和SYCL中不同内存和同步方法的工作原理
- en: Instructor note
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 60 min teaching
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 60分钟教学
- en: 30 min exercises
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30分钟练习
- en: The goal of the cross-platform portability ecosystems is to allow the same code
    to run on multiple architectures, therefore reducing code duplication. They are
    usually based on C++, and use function objects/lambda functions to define the
    loop body (i.e., the kernel), which can run on multiple architectures like CPU,
    GPU, and FPGA from different vendors. An exception to this is OpenCL, which originally
    offered only a C API (although currently also C++ API is available), and uses
    a separate-source model for the kernel code. However, unlike in many conventional
    CUDA or HIP implementations, the portability ecosystems require kernels to be
    written only once if one prefers to run it on CPU and GPU for example. Some notable
    cross-platform portability ecosystems are alpaka, Kokkos, OpenCL, RAJA, and SYCL.
    Kokkos, alpaka, and RAJA are individual projects whereas OpenCL and SYCL are standards
    followed by several projects implementing (and extending) them. For example, some
    notable SYCL implementations include [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html),
    [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) (previously known as
    hipSYCL or Open SYCL), [triSYCL](https://github.com/triSYCL/triSYCL), and [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 跨平台可移植性生态系统的目标是允许相同的代码在多个架构上运行，从而减少代码重复。它们通常基于 C++，并使用函数对象/lambda 函数来定义循环体（即内核），这可以在多个架构上运行，如来自不同供应商的
    CPU、GPU 和 FPGA。一个例外是 OpenCL，它最初只提供了 C API（尽管目前也提供了 C++ API），并且为内核代码使用单独的源模型。然而，与许多传统的
    CUDA 或 HIP 实现 不同，可移植性生态系统要求如果用户希望它在 CPU 和 GPU 上运行，例如，内核只需编写一次。一些值得注意的跨平台可移植性生态系统包括
    alpaka、Kokkos、OpenCL、RAJA 和 SYCL。Kokkos、alpaka 和 RAJA 是独立的项目，而 OpenCL 和 SYCL 是由多个项目遵循的标准，这些项目实现了（并扩展了）它们。例如，一些值得注意的
    SYCL 实现包括 [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)、[AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)（之前称为
    hipSYCL 或 Open SYCL）、[triSYCL](https://github.com/triSYCL/triSYCL) 和 [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)。
- en: C++ StdPar
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++ StdPar
- en: In C++17, the initial support for parallel execution of standard algorithms
    has been introduced. Most algorithms available via the standard `<algorithms>`
    header were given an overload accepting with an [*execution policy*](https://en.cppreference.com/w/cpp/algorithm)
    argument which allows the programmer to request parallel execution of the standard
    library function. While the main goal was to allow low-effort, high-level interface
    to run existing algorithms like `std::sort` on many CPU cores, implementations
    are allowed to use other hardware, and functions like `std::for_each` or `std::transform`
    offer great flexibility in writing the algorithm.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在 C++17 中，对标准算法并行执行的支持已经被引入。大多数通过标准 `<algorithms>` 头文件提供的算法都被赋予了接受一个 [*执行策略*](https://en.cppreference.com/w/cpp/algorithm)
    参数的重载，这允许程序员请求并行执行标准库函数。虽然主要目标是允许低成本的、高级接口运行现有的算法，如 `std::sort` 在许多 CPU 核心上，但实现允许使用其他硬件，并且
    `std::for_each` 或 `std::transform` 函数在编写算法时提供了很大的灵活性。
- en: C++ StdPar, also called Parallel STL or PSTL, could be considered similar to
    directive-based models, as it is very high-level and does not give the programmer
    fine-grained control over data movement or any access to hardware-specific features
    like shared (local) memory. Even the GPU to run on is selected automatically,
    since standard C++ does not have the concept of a *device* (but there are vendor
    extensions allowing the programmer more control) However, for applications that
    already relies on algorithms from C++ standard library, StdPar can be a good way
    to reap the performance benefits of both CPUs and GPUs with minimal code modifications.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: C++ StdPar，也称为并行 STL 或 PSTL，可以被认为是类似于指令驱动的模型，因为它非常高级，并且不给予程序员对数据移动的精细控制或对硬件特定功能（如共享（局部）内存）的访问。甚至用于运行的
    GPU 也是自动选择的，因为标准 C++ 没有概念上的 *设备*（尽管有供应商扩展允许程序员有更多的控制）。然而，对于已经依赖于 C++ 标准库算法的应用程序，StdPar
    可以是一种在最小代码修改的情况下获得 CPU 和 GPU 性能收益的好方法。
- en: 'For GPU programming, all three vendors offer their implementations of StdPar
    with the ability to offload code to the GPU: NVIDIA has `nvc++`, AMD has experimental
    [roc-stdpar](https://github.com/ROCm/roc-stdpar), and Intel offers StdPar offload
    with their oneAPI compiler. [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)
    offers an independent StdPar implementation, able to target devices from all three
    vendors. While being a part of the C++ standard, the level of support and the
    maturity of StdPar implementations varies a lot between different compilers: not
    all compilers support all algorithms, and different heuristics for mapping the
    algorithm to hardware and for managing data movement can have effect on performance.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GPU 编程，所有三个供应商都提供了他们的 StdPar 实现，可以将代码卸载到 GPU 上：NVIDIA 有 `nvc++`，AMD 有实验性的
    [roc-stdpar](https://github.com/ROCm/roc-stdpar)，Intel 通过他们的 oneAPI 编译器提供 StdPar
    卸载。[AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) 提供了一个独立的 StdPar
    实现，能够针对所有三个供应商的设备。虽然 StdPar 是 C++ 标准的一部分，但不同编译器对 StdPar 的支持和成熟度差异很大：并非所有编译器都支持所有算法，将算法映射到硬件和进行数据移动的不同启发式方法可能会影响性能。
- en: StdPar compilation
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 编译
- en: 'The build process depends a lot on the used compiler:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程在很大程度上取决于所使用的编译器：
- en: 'AdaptiveCpp: Add `--acpp-stdpar` flag when calling `acpp`.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AdaptiveCpp: 在调用 `acpp` 时添加 `--acpp-stdpar` 标志。'
- en: 'Intel oneAPI: Add `-fsycl -fsycl-pstl-offload=gpu` flags when calling `icpx`.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：在调用 `icpx` 时添加 `-fsycl -fsycl-pstl-offload=gpu` 标志。
- en: 'NVIDIA NVC++: Add `-stdpar` flag when calling `nvc++` (not supported with plain
    `nvcc`).'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA NVC++：在调用 `nvc++` 时添加 `-stdpar` 标志（不支持使用普通 `nvcc`）。
- en: StdPar programming
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 编程
- en: In its simplest form, using C++ standard parallelism requires including an additional
    `<execution>` header and adding one argument to a supported standard library function.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单的形式中，使用 C++ 标准并行性需要包含一个额外的 `<execution>` 头文件，并将一个参数添加到受支持的标准库函数中。
- en: 'For example, let’s look at the following sequential code sorting a vector:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看以下按顺序排序向量的代码：
- en: '[PRE71]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'To make it run sorting on the GPU, only a minor modification is needed:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 要使其在 GPU 上运行排序，只需要进行微小的修改：
- en: '[PRE72]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Now, when compiled with one of the supported compilers, the code will run the
    sorting on a GPU.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当使用支持的编译器编译时，代码将在 GPU 上运行排序。
- en: While the can initially seem very limiting, many standard algorithms, such as
    `std::transform`, `std::accumulate`, `std::transform_reduce`, and `std::for_each`
    can run custom functions over an array, thus allowing one to offload an arbitrary
    algorithm, as long as it does not violate typical limitations of GPU kernels,
    such as not throwing any exceptions and not doing system calls.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一开始可能看起来非常有限制，但许多标准算法，如 `std::transform`、`std::accumulate`、`std::transform_reduce`
    和 `std::for_each`，可以在数组上运行自定义函数，从而允许将任意算法卸载，只要它不违反 GPU 内核的典型限制，例如不抛出任何异常和不进行系统调用。
- en: StdPar execution policies
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar 执行策略
- en: 'In C++, there are four different execution policies to choose from:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在 C++ 中，有四种不同的执行策略可供选择：
- en: '`std::execution::seq`: run algorithm serially, don’t parallelize it.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::seq`：串行运行算法，不并行化它。'
- en: '`std::execution::par`: allow parallelizing the algorithm (as if using multiple
    threads),'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par`：允许并行化算法（就像使用多个线程一样），'
- en: '`std::execution::unseq`: allow vectorizing the algorithm (as if using SIMD),'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::unseq`：允许矢量化算法（就像使用 SIMD 一样），'
- en: '`std::execution::par_unseq`: allow both vectorizing and parallelizing the algorithm.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par_unseq`：允许矢量化并并行化算法。'
- en: 'The main difference between `par` and `unseq` is related to thread progress
    and locks: using `unseq` or `par_unseq` requires that the algorithms does not
    contain mutexes and other locks between the processes, while `par` does not have
    this limitation.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '`par` 和 `unseq` 之间的主要区别与线程进度和锁有关：使用 `unseq` 或 `par_unseq` 要求算法在进程之间不包含互斥锁和其他锁，而
    `par` 没有这种限制。'
- en: For GPU, the optimal choice is `par_unseq`, since this places the least requirement
    on the compiler in terms of operation ordering. While `par` is also supported
    in some cases, it is best avoided, both due to limited compiler support and as
    an indication that the algorithm is likely a poor fit for the hardware.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GPU，最佳选择是 `par_unseq`，因为它对编译器在操作顺序方面的要求最低。虽然 `par` 在某些情况下也受到支持，但最好避免使用它，这不仅因为编译器支持有限，而且也表明该算法可能不适合硬件。
- en: Kokkos
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kokkos
- en: Kokkos is an open-source performance portability ecosystem for parallelization
    on large heterogeneous hardware architectures of which development has mostly
    taken place on Sandia National Laboratories. The project started in 2011 as a
    parallel C++ programming model, but have since expanded into a more broad ecosystem
    including Kokkos Core (the programming model), Kokkos Kernels (math library),
    and Kokkos Tools (debugging, profiling and tuning tools). By preparing proposals
    for the C++ standard committee, the project also aims to influence the ISO/C++
    language standard such that, eventually, Kokkos capabilities will become native
    to the language standard. A more detailed introduction is found [HERE](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos是一个开源的性能可移植生态系统，用于在大型的异构硬件架构上并行化，其开发主要在桑迪亚国家实验室进行。该项目始于2011年，最初是一个并行C++编程模型，但后来扩展成为一个更广泛的生态系统，包括Kokkos
    Core（编程模型）、Kokkos Kernels（数学库）和Kokkos Tools（调试、分析和调优工具）。通过为C++标准委员会准备提案，该项目还旨在影响ISO/C++语言标准，使得最终Kokkos的功能将成为语言标准的一部分。更详细的介绍可以在[这里](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/)找到。
- en: The Kokkos library provides an abstraction layer for a variety of different
    parallel programming models, currently CUDA, HIP, SYCL, HPX, OpenMP, and C++ threads.
    Therefore, it allows better portability across different hardware manufactured
    by different vendors, but introduces an additional dependency to the software
    stack. For example, when using CUDA, only CUDA installation is required, but when
    using Kokkos with NVIDIA GPUs, Kokkos and CUDA installation are both required.
    Kokkos is not a very popular choice for parallel programming, and therefore, learning
    and using Kokkos can be more difficult compared to more established programming
    models such as CUDA, for which a much larger amount of search results and Stack
    Overflow discussions can be found.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos库为各种不同的并行编程模型提供了一个抽象层，目前包括CUDA、HIP、SYCL、HPX、OpenMP和C++线程。因此，它允许在不同厂商制造的硬件之间实现更好的可移植性，但引入了软件堆栈的额外依赖。例如，当使用CUDA时，只需要CUDA安装，但当使用Kokkos与NVIDIA
    GPU一起时，需要Kokkos和CUDA的安装。Kokkos并不是并行编程中非常受欢迎的选择，因此，与CUDA等更成熟的编程模型相比，学习和使用Kokkos可能会更加困难，对于CUDA，可以找到大量的搜索结果和Stack
    Overflow讨论。
- en: Kokkos compilation
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos编译
- en: Furthermore, one challenge with some cross-platform portability libraries is
    that even on the same system, different projects may require different combinations
    of compilation settings for the portability library. For example, in Kokkos, one
    project may wish the default execution space to be a CUDA device, whereas another
    requires a CPU. Even if the projects prefer the same execution space, one project
    may desire the Unified Memory to be the default memory space and the other may
    wish to use pinned GPU memory. It may be burdensome to maintain a large number
    of library instances on a single system.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些跨平台可移植库的一个挑战是，即使在同一系统上，不同的项目可能需要不同的编译设置组合来满足可移植库的需求。例如，在Kokkos中，一个项目可能希望默认执行空间是CUDA设备，而另一个项目可能需要CPU。即使项目偏好相同的执行空间，一个项目可能希望统一内存是默认内存空间，而另一个项目可能希望使用固定GPU内存。在单个系统上维护大量库实例可能会变得很麻烦。
- en: 'However, Kokkos offers a simple way to compile Kokkos library simultaneously
    with the user project. This is achieved by specifying Kokkos compilation settings
    (see [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html))
    and including the Kokkos Makefile in the user Makefile. CMake is also supported.
    This way, the user application and Kokkos library are compiled together. The following
    is an example Makefile for a single-file Kokkos project (hello.cpp) that uses
    CUDA (Volta architecture) as the backend (default execution space) and Unified
    Memory as the default memory space:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Kokkos提供了一种简单的方法来同时编译Kokkos库和用户项目。这是通过指定Kokkos编译设置（见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html)）并在用户Makefile中包含Kokkos
    Makefile来实现的。CMake也受到支持。这样，用户应用程序和Kokkos库一起编译。以下是一个使用CUDA（Volta架构）作为后端（默认执行空间）和统一内存作为默认内存空间的单文件Kokkos项目的示例Makefile：
- en: '[PRE73]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: To build a **hello.cpp** project with the above Makefile, no steps other than
    cloning the Kokkos project into the current directory is required.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用上述Makefile构建**hello.cpp**项目，除了将Kokkos项目克隆到当前目录外，不需要进行其他步骤。
- en: Kokkos programming
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos编程
- en: When starting to write a project using Kokkos, the first step is understand
    Kokkos initialization and finalization. Kokkos must be initialized by calling
    `Kokkos::initialize(int& argc, char* argv[])` and finalized by calling `Kokkos::finalize()`.
    More details are given in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始使用 Kokkos 编写项目时，第一步是了解 Kokkos 的初始化和终止。Kokkos 必须通过调用 `Kokkos::initialize(int&
    argc, char* argv[])` 进行初始化，并通过调用 `Kokkos::finalize()` 进行终止。更多详细信息请参阅[此处](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html)。
- en: Kokkos uses an execution space model to abstract the details of parallel hardware.
    The execution space instances map to the available backend options such as CUDA,
    OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer
    in the source code, the default execution space `Kokkos::DefaultExecutionSpace`
    is used. This is chosen when the Kokkos library is compiled. The Kokkos execution
    space model is described in more detail in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 使用执行空间模型来抽象并行硬件的细节。执行空间实例映射到可用的后端选项，如 CUDA、OpenMP、HIP 或 SYCL。如果程序员在源代码中没有明确选择执行空间，则使用默认执行空间
    `Kokkos::DefaultExecutionSpace`。这是在编译 Kokkos 库时选择的。Kokkos 执行空间模型在[此处](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces)有更详细的描述。
- en: Similarly, Kokkos uses a memory space model for different types of memory, such
    as host memory or device memory. If not defined explicitly, Kokkos uses the default
    memory space specified during Kokkos compilation as described [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，Kokkos 使用内存空间模型来处理不同类型的内存，例如主机内存或设备内存。如果没有明确定义，Kokkos 将使用在 Kokkos 编译期间指定的默认内存空间，具体描述见[此处](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces)。
- en: 'The following is an example of a Kokkos program that initializes Kokkos and
    prints the execution space and memory space instances:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个初始化 Kokkos 并打印执行空间和内存空间实例的 Kokkos 程序示例：
- en: '[PRE74]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: With Kokkos, the data can be accessed either through raw pointers or through
    Kokkos Views. With raw pointers, the memory allocation into the default memory
    space can be done using `Kokkos::kokkos_malloc(n * sizeof(int))`. Kokkos Views
    are a data type that provides a way to access data more efficiently in memory
    corresponding to a certain Kokkos memory space, such as host memory or device
    memory. A 1-dimensional view of type int* can be created by `Kokkos::View<int*>
    a("a", n)`, where `"a"` is a label, and `n` is the size of the allocation in the
    number of integers. Kokkos determines the optimal layout for the data at compile
    time for best overall performance as a function of the computer architecture.
    Furthermore, Kokkos handles the deallocation of such memory automatically. More
    details about Kokkos Views are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kokkos，数据可以通过原始指针或通过 Kokkos 视图进行访问。使用原始指针时，可以通过 `Kokkos::kokkos_malloc(n
    * sizeof(int))` 在默认内存空间中进行内存分配。Kokkos 视图是一种数据类型，它提供了一种更有效地访问与特定 Kokkos 内存空间（如主机内存或设备内存）相对应的数据的方法。可以通过
    `Kokkos::View<int*> a("a", n)` 创建一个类型为 int* 的一维视图，其中 `"a"` 是标签，`n` 是以整数数量表示的分配大小。Kokkos
    在编译时确定数据的最佳布局，以实现最佳的整体性能，这取决于计算机架构。此外，Kokkos 会自动处理此类内存的释放。有关 Kokkos 视图的更多详细信息，请参阅[此处](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html)。
- en: 'Finally, Kokkos provides three different parallel operations: `parallel_for`,
    `parallel_reduce`, and `parallel_scan`. The `parallel_for` operation is used to
    execute a loop in parallel. The `parallel_reduce` operation is used to execute
    a loop in parallel and reduce the results to a single value. The `parallel_scan`
    operation implements a prefix scan. The usage of `parallel_for` and `parallel_reduce`
    are demonstrated in the examples later in this chapter. More detail about the
    parallel operations are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html).'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kokkos 提供了三种不同的并行操作：`parallel_for`、`parallel_reduce` 和 `parallel_scan`。`parallel_for`
    操作用于并行执行循环。`parallel_reduce` 操作用于并行执行循环并将结果归约到单个值。`parallel_scan` 操作实现前缀扫描。`parallel_for`
    和 `parallel_reduce` 的用法将在本章后面的示例中演示。有关并行操作的更多详细信息，请参阅[此处](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html)。
- en: Run Kokkos hello.cpp example in simple steps
  id: totrans-377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单步骤运行 Kokkos hello.cpp 示例
- en: The following should work on AMD VEGA90A devices straight out of the box (needs
    ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use
    the variables commented out on the Makefile.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容应在AMD VEGA90A设备上直接使用（需要ROCm安装）。在NVIDIA Volta V100设备上（需要CUDA安装），请在Makefile中取消注释的变量。
- en: '`git clone https://github.com/kokkos/kokkos.git`'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`git clone https://github.com/kokkos/kokkos.git`'
- en: Copy the above Makefile into the current folder (make sure the indentation of
    the last line is tab, and not space)
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的Makefile复制到当前文件夹中（确保最后一行的缩进是制表符，而不是空格）
- en: Copy the above hello.cpp file into the current folder
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的hello.cpp文件复制到当前文件夹
- en: '`make`'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`make`'
- en: '`./hello`'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`./hello`'
- en: OpenCL
  id: totrans-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCL
- en: OpenCL is a cross-platform, open-standard API for writing parallel programs
    that execute across heterogeneous platforms consisting of CPUs, GPUs, FPGAs and
    other devices. The first version of OpenCL (1.0) was released in December 2008,
    and the latest version of OpenCL (3.0) was released in September 2020\. OpenCL
    is supported by a number of vendors, including AMD, ARM, Intel, NVIDIA, and Qualcomm.
    It is a royalty-free standard, and the OpenCL specification is maintained by the
    Khronos Group. OpenCL provides a low-level programming interface initially based
    on C, but more recently also a C++ interface has become available.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL是一个跨平台的开放标准API，用于编写在由CPU、GPU、FPGA和其他设备组成的异构平台上执行的并行程序。OpenCL的第一个版本（1.0）于2008年12月发布，最新的OpenCL版本（3.0）于2020年9月发布。OpenCL由包括AMD、ARM、Intel、NVIDIA和Qualcomm在内的多个厂商支持。它是一个免版税标准，OpenCL规范由Khronos
    Group维护。OpenCL提供了一个基于C的低级编程接口，但最近也提供了一种C++接口。
- en: OpenCL compilation
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL编译
- en: 'OpenCL supports two modes for compiling the programs: online and offline. Online
    compilation occurs at runtime, when the host program calls a function to compile
    the source code. Online mode allows dynamic generation and loading of kernels,
    but may incur some overhead due to compilation time and possible errors. Offline
    compilation occurs before runtime, when the source code of a kernel is compiled
    into a binary format that can be loaded by the host program. This mode allows
    faster execution and better optimization of kernels, but may limit the portability
    of the program, because the binary can only run on the architectures it was compiled
    for.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL支持两种编译程序的模式：在线和离线。在线编译发生在运行时，当主机程序调用一个函数来编译源代码时。在线模式允许动态生成和加载内核，但可能因为编译时间和可能的错误而带来一些开销。离线编译发生在运行之前，当内核的源代码被编译成主机程序可以加载的二进制格式。这种模式允许内核更快地执行和更好的优化，但可能会限制程序的便携性，因为二进制只能在编译时指定的架构上运行。
- en: 'OpenCL comes bundled with several parallel programming ecosystems, such as
    NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such
    packages and setting up the environment, one may simply compile an OpenCL program
    by the commands such as `icx cl_devices.c -lOpenCL` (Intel oneAPI) or `nvcc cl_devices.c
    -lOpenCL` (NVIDIA CUDA), where `cl_devices.c` is the compiled file. Unlike most
    other programming models, OpenCL stores kernels as text and compiles them for
    the device in runtime (JIT-compilation), and thus does not require any special
    compiler support: one can compile the code using simply `gcc cl_devices.c -lOpenCL`
    (or `g++` when using C++ API), as long as the required libraries and headers are
    installed in a standard locations.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL附带了一些并行编程生态系统，例如NVIDIA CUDA和Intel oneAPI。例如，在成功安装此类包并设置环境后，可以通过如`icx cl_devices.c
    -lOpenCL`（Intel oneAPI）或`nvcc cl_devices.c -lOpenCL`（NVIDIA CUDA）等命令简单地编译OpenCL程序，其中`cl_devices.c`是编译后的文件。与大多数其他编程模型不同，OpenCL将内核存储为文本，并在运行时（即时编译）为设备编译，因此不需要任何特殊的编译器支持：只要所需的库和头文件安装在标准位置，就可以使用`gcc
    cl_devices.c -lOpenCL`（或使用C++ API时使用`g++`）来编译代码。
- en: 'The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the
    latter with some limitations. To compile a program, you can use the AMD compilers
    on a GPU partition:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 安装在LUMI上的AMD编译器支持OpenCL C和C++ API，后者有一些限制。要编译程序，您可以使用GPU分区上的AMD编译器：
- en: '[PRE75]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: OpenCL programming
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL编程
- en: 'OpenCL programs consist of two parts: a host program that runs on the host
    device (usually a CPU) and one or more kernels that run on compute devices (such
    as GPUs). The host program is responsible for the tasks such as managing the devices
    for the selected platform, allocating memory objects, building and enqueueing
    kernels, and managing memory objects.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL程序由两部分组成：在主机设备（通常是CPU）上运行的宿主程序以及在一个或多个计算设备（如GPU）上运行的内核。宿主程序负责管理所选平台上的设备、分配内存对象、构建和排队内核以及管理内存对象等任务。
- en: The first steps when writing an OpenCL program are to initialize the OpenCL
    environment by selecting the platform and devices, creating a context or contexts
    associated with the selected device(s), and creating a command queue for each
    device. A simple example of selecting the default device, creating a context and
    a queue associated with the device is show below.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 编写OpenCL程序的第一步是初始化OpenCL环境，通过选择平台和设备，创建与所选设备关联的上下文或上下文，并为每个设备创建一个命令队列。以下是一个选择默认设备、创建与设备关联的上下文和队列的简单示例。
- en: '[PRE76]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'OpenCL provides two main programming models to manage the memory hierarchy
    of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers
    are the traditional memory model of OpenCL, where the host and the devices have
    separate address spaces and the programmer has to explicitly specify the memory
    allocations and how and where the memory is accessed. This can be done with class
    `cl::Buffer` and functions such as `cl::CommandQueue::enqueueReadBuffer()`. Buffers
    are supported since early versions of OpenCL, and work well across different architectures.
    Buffers can also take advantage of device-specific memory features, such as constant
    or local memory.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL提供了两种主要的编程模型来管理主机和加速器设备的内存层次结构：缓冲区和共享虚拟内存（SVM）。缓冲区是OpenCL的传统内存模型，其中主机和设备有独立的地址空间，程序员必须显式指定内存分配以及如何以及在哪里访问内存。这可以通过`cl::Buffer`类和如`cl::CommandQueue::enqueueReadBuffer()`这样的函数来完成。缓冲区自OpenCL的早期版本以来就得到了支持，并且在不同架构上都能很好地工作。缓冲区还可以利用特定于设备的内存特性，如常量或局部内存。
- en: SVM is a newer memory model of OpenCL, introduced in version 2.0, where the
    host and the devices share a single virtual address space. Thus, the programmer
    can use the same pointers to access the data from host and devices simplifying
    the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained
    buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow
    using the same pointers across a host and devices, but they differ in their granularity
    and synchronization requirements for the memory regions. Furthermore, the support
    for SVM is not universal across all OpenCL platforms and devices, and for example,
    GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer.
    This level requires explicit synchronization for memory accesses from a host and
    devices (using functions such as `cl::CommandQueue::enqueueMapSVM()` and `cl::CommandQueue::enqueueUnmapSVM()`),
    making the usage of SVM less convenient. It is further noted that this is unlike
    the regular Unified Memory offered by CUDA, which is closer to the fine-grained
    system SVM level in OpenCL.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是OpenCL中较新的内存模型，在2.0版本中引入，其中主机和设备共享一个单一的虚拟地址空间。因此，程序员可以使用相同的指针来访问主机和设备上的数据，从而简化编程工作。在OpenCL中，SVM有不同级别，如粗粒度缓冲区SVM、细粒度缓冲区SVM和细粒度系统SVM。所有级别都允许在主机和设备之间使用相同的指针，但它们在内存区域的粒度和同步要求上有所不同。此外，SVM的支持并不是在所有OpenCL平台和设备上都是通用的，例如，NVIDIA
    V100和A100这样的GPU只支持粗粒度SVM缓冲区。这一级别需要显式同步从主机和设备对内存的访问（使用如`cl::CommandQueue::enqueueMapSVM()`和`cl::CommandQueue::enqueueUnmapSVM()`这样的函数），这使得SVM的使用不太方便。值得注意的是，这与CUDA提供的常规统一内存不同，CUDA提供的统一内存更接近于OpenCL中的细粒度系统SVM级别。
- en: OpenCL uses a separate-source kernel model where the kernel code is often kept
    in separate files that may be compiled during runtime. The model allows the kernel
    source code to be passed as a string to the OpenCL driver after which the program
    object can be executed on a specific device. Although referred to as the separate-source
    kernel model, the kernels can still be defined as a string in the host program
    compilation units as well, which may be a more convenient approach in some cases.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 使用单独源内核模型，其中内核代码通常保存在单独的文件中，这些文件可以在运行时编译。该模型允许将内核源代码作为字符串传递给 OpenCL 驱动程序，然后程序对象可以在特定设备上执行。尽管被称为单独源内核模型，但内核也可以在主机程序编译单元中定义为字符串，这在某些情况下可能更方便。
- en: The online compilation with the separate-source kernel model has several advantages
    over the binary model, which requires offline compilation of kernels into device-specific
    binaries that can are loaded by the application at runtime. Online compilation
    preserves the portability and flexibility of OpenCL, as the same kernel source
    code can run on any supported device. Furthermore, dynamic optimization of kernels
    based on runtime information, such as input size, work-group size, or device capabilities,
    is possible. An example of an OpenCL kernel, defined by a string in the host compilation
    unit, and assigning the global thread index into a global device memory is shown
    below.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 与二进制模型相比，使用单独源内核模型的在线编译具有多个优势，后者需要离线编译内核到特定于设备的二进制文件，这些文件在运行时由应用程序加载。在线编译保留了
    OpenCL 的可移植性和灵活性，因为相同的内核源代码可以在任何支持的设备上运行。此外，基于运行时信息（如输入大小、工作组大小或设备功能）的内核动态优化也是可能的。以下是一个
    OpenCL 内核的示例，它由主机编译单元中的字符串定义，并将全局线程索引分配到全局设备内存中。
- en: '[PRE78]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The above kernel named `dot` and stored in the string `kernel_source` can be
    set to build in the host code as follows:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的名为 `dot` 并存储在字符串 `kernel_source` 中的内核可以设置在主机代码中构建，如下所示：
- en: '[PRE79]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: SYCL
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SYCL
- en: '[SYCL](https://www.khronos.org/sycl/) is a royalty-free, open-standard C++
    programming model for multi-device programming. It provides a high-level, single-source
    programming model for heterogeneous systems, including GPUs. There are several
    implementations of the standard. For GPU programming, [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    and [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) (also known as
    hipSYCL) are the most popular for desktop and HPC GPUs; [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    is a good choice for embedded devices. The same standard-compliant SYCL code should
    work with any implementation, but they are not binary-compatible.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '[SYCL](https://www.khronos.org/sycl/) 是一个免版税、开放标准的 C++ 编程模型，用于多设备编程。它为异构系统提供了一种高级、单源编程模型，包括
    GPU。该标准有几个实现。对于 GPU 编程，[Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    和 [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)（也称为 hipSYCL）是桌面和
    HPC GPU 中最受欢迎的；[ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    是嵌入式设备的良好选择。遵循相同标准合规的 SYCL 代码应该可以在任何实现上运行，但它们不是二进制兼容的。'
- en: The most recent version of the SYCL standard is SYCL 2020, and it is the version
    we will be using in this course.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: SYCL 标准的最新版本是 SYCL 2020，这是我们将在本课程中使用的版本。
- en: SYCL compilation
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL 编译
- en: Intel oneAPI DPC++
  id: totrans-408
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Intel oneAPI DPC++
- en: For targeting Intel GPUs, it is enough to install [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html).
    Then, the compilation is as simple as `icpx -fsycl file.cpp`.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Intel GPU，只需安装 [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html)
    即可。然后，编译就像 `icpx -fsycl file.cpp` 一样简单。
- en: 'It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI
    Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding
    [Codeplay oneAPI plugin](https://codeplay.com/solutions/oneapi/) must be installed.
    Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用 oneAPI 来针对 NVIDIA 和 AMD GPU。除了 oneAPI Base Toolkit 之外，还需要安装供应商提供的运行时（CUDA
    或 HIP）以及相应的 [Codeplay oneAPI 插件](https://codeplay.com/solutions/oneapi/)。然后，可以使用包含在
    oneAPI 中的 Intel LLVM 编译器编译代码：
- en: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` for targeting CUDA
    8.6 NVIDIA GPU,'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` 用于针对 CUDA 8.6 NVIDIA
    GPU，'
- en: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` for targeting GFX90a AMD GPU.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` 用于针对 GFX90a AMD GPU。'
- en: AdaptiveCpp
  id: totrans-413
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AdaptiveCpp
- en: 'Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed
    first. Then `acpp` can be used for compiling the code, specifying the target devices.
    For example, here is how to compile the program supporting an AMD and an NVIDIA
    device:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AdaptiveCpp为NVIDIA或AMD GPU编程也要求首先安装CUDA或HIP。然后可以使用`acpp`编译代码，指定目标设备。例如，以下是编译支持AMD和NVIDIA设备的程序的方法：
- en: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
- en: Using SYCL on LUMI
  id: totrans-416
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用SYCL
- en: 'LUMI does not have a system-wide installation of any SYCL framework, but a
    recent AdaptiveCpp installation is available in CSC modules:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI没有系统范围内安装任何SYCL框架，但CSC模块中有一个最新的AdaptiveCpp安装：
- en: '[PRE81]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The default compilation target is preset to MI250 GPUs, so to compile a single
    C++ file it is enough to call `acpp -O2 file.cpp`.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 默认编译目标已预设为MI250 GPU，因此要编译单个C++文件，只需调用`acpp -O2 file.cpp`即可。
- en: 'When running applications built with AdaptiveCpp, one can often see the warning
    “dag_direct_scheduler: Detected a requirement that is neither of discard access
    mode”, reflecting the lack of an optimization hint when using buffer-accessor
    model. The warning is harmless and can be ignored.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '当运行使用AdaptiveCpp构建的应用程序时，经常会看到警告“dag_direct_scheduler: 检测到一个既不是丢弃访问模式的要求”，这反映了在使用缓冲区访问器模型时缺少优化提示。这个警告是无害的，可以忽略。'
- en: SYCL programming
  id: totrans-421
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL编程
- en: SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source
    model with kernel lambdas.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，SYCL与OpenCL相似，但像Kokkos一样使用单源模型和内核lambda。
- en: 'To submit a task to device, first a sycl::queue must be created, which is used
    as a way to manage the task scheduling and execution. In the simplest case, that’s
    all the initialization one needs:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 要将任务提交到设备，首先必须创建一个sycl::queue，它被用作管理任务调度和执行的方式。在最简单的情况下，这就是所需的全部初始化：
- en: '[PRE82]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'If one wants more control, the device can be explicitly specified, or additional
    properties can be passed to a queue:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 如果想要更多控制，可以显式指定设备，或者向队列传递额外的属性：
- en: '[PRE83]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Memory management can be done in two different ways: *buffer-accessor* model
    and *unified shared memory* (USM). The choice of the memory management models
    also influences how the GPU tasks are synchronized.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理可以通过两种不同的方式完成：*缓冲区访问器*模型和*统一共享内存*（USM）。内存管理模型的选择也会影响GPU任务的同步方式。
- en: 'In the *buffer-accessor* model, a `sycl::buffer` objects are used to represent
    arrays of data. A buffer is not mapped to any single one memory space, and can
    be migrated between the GPU and the CPU memory transparently. The data in `sycl::buffer`
    cannot be read or written directly, an accessor must be created. `sycl::accessor`
    objects specify the location of data access (host or a certain GPU kernel) and
    the access mode (read-only, write-only, read-write). Such approach allows optimizing
    task scheduling by building a directed acyclic graph (DAG) of data dependencies:
    if kernel *A* creates a write-only accessor to a buffer, and then kernel *B* is
    submitted with a read-only accessor to the same buffer, and then a host-side read-only
    accessor is requested, then it can be deduced that *A* must complete before *B*
    is launched and also that the results must be copied to the host before the host
    task can proceed, but the host task can run in parallel with kernel *B*. Since
    the dependencies between tasks can be built automatically, by default SYCL uses
    *out-of-order queues*: when two tasks are submitted to the same `sycl::queue`,
    it is not guaranteed that the second one will launch only after the first one
    completes. When launching a kernel, accessors must be created:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在*缓冲区访问器*模型中，使用`sycl::buffer`对象来表示数据数组。缓冲区没有映射到任何单一内存空间，并且可以在GPU和CPU内存之间透明迁移。`sycl::buffer`中的数据不能直接读取或写入，必须创建访问器。`sycl::accessor`对象指定数据访问的位置（主机或某个GPU内核）以及访问模式（只读、只写、读写）。这种方法通过构建数据依赖的有向无环图（DAG）来优化任务调度：如果内核*A*创建了一个对缓冲区的只写访问器，然后内核*B*提交了一个对同一缓冲区的只读访问器，然后请求主机端的只读访问器，那么可以推断出*A*必须在*B*启动之前完成，并且结果必须在主机任务可以继续之前复制到主机，但主机任务可以与内核*B*并行运行。由于任务之间的依赖关系可以自动构建，因此默认情况下SYCL使用*乱序队列*：当两个任务提交到同一个`sycl::queue`时，不能保证第二个任务只有在第一个任务完成后才会启动。在启动内核时，必须创建访问器：
- en: '[PRE84]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Buffer-accessor model simplifies many aspects of heterogeneous programming and
    prevents many synchronization-related bugs, but it only allows very coarse control
    of data movement and kernel execution.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区访问模型简化了异构编程的许多方面，并防止了许多与同步相关的错误，但它只允许对数据移动和内核执行进行非常粗略的控制。
- en: 'The *USM* model is similar to how NVIDIA CUDA or AMD HIP manage memory. The
    programmer has to explicitly allocate the memory on the device (`sycl::malloc_device`),
    on the host (`sycl::malloc_host`), or in the shared memory space (`sycl::malloc_shared`).
    Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
    all USM allocations are shared: for example, a memory allocated by `sycl::malloc_device`
    cannot be accessed from the host. The allocation functions return memory pointers
    that can be used directly, without accessors. This means that the programmer have
    to ensure the correct synchronization between host and device tasks to avoid data
    races. With USM, it is often convenient to use *in-order queues* with USM, instead
    of the default *out-of-order* queues. More information on USM can be found in
    the [Section 4.8 of SYCL 2020 specification](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm).'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '*USM* 模型类似于 NVIDIA CUDA 或 AMD HIP 管理内存的方式。程序员必须显式地在设备上（`sycl::malloc_device`）、在主机上（`sycl::malloc_host`）或在共享内存空间中（`sycl::malloc_shared`）分配内存。尽管其名称为统一共享内存，并且与
    OpenCL 的 SVM 相似，但并非所有 USM 分配都是共享的：例如，由 `sycl::malloc_device` 分配的内存不能从主机访问。分配函数返回可以直接使用的内存指针，无需访问器。这意味着程序员必须确保主机和设备任务之间的正确同步，以避免数据竞争。使用
    USM 时，通常更方便使用 *顺序队列* 而不是默认的 *乱序队列*。有关 USM 的更多信息，请参阅 [SYCL 2020 规范的第 4.8 节](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm)。'
- en: '[PRE85]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Exercise
  id: totrans-433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Implement SAXPY in SYCL'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在 SYCL 中实现 SAXPY
- en: In this exercise we would like to write (fill-in-the-blanks) a simple code doing
    SAXPY (vector addition).
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的代码，执行 SAXPY（向量加法）。
- en: 'To compile and run the code interactively, first make an allocation and load
    the AdaptiveCpp module:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，首先进行分配并加载 AdaptiveCpp 模块：
- en: '[PRE86]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以运行一个简单的设备检测实用程序来检查是否有 GPU 可用（注意 `srun`）：
- en: '[PRE87]'
  id: totrans-439
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE87]'
- en: If you have not done it already, clone the repository using `git clone https://github.com/ENCCS/gpu-programming.git`
    or **update it** using `git pull origin main`.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有做，请使用 `git clone https://github.com/ENCCS/gpu-programming.git` 或 **更新**
    它使用 `git pull origin main` 来克隆仓库。
- en: 'Now, let’s look at the example code in `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp`:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp` 中的示例代码：
- en: '[PRE88]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'To compile and run the code, use the following command:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE89]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: The code will not compile as-is! Your task is to fill in missing bits indicated
    by `TODO` comments. You can also test your understanding using the “Bonus questions”
    in the code.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 代码不能直接编译！你的任务是填写由 `TODO` 注释指示的缺失部分。你还可以通过代码中的“附加问题”来测试你的理解。
- en: If you feel stuck, take a look at the `exercise-sycl-saxpy-solution.cpp` file.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感到困惑，请查看 `exercise-sycl-saxpy-solution.cpp` 文件。
- en: alpaka
  id: totrans-447
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: alpaka
- en: The [alpaka](https://github.com/alpaka-group/alpaka3) library is an open-source
    header-only C++20 abstraction library for accelerator development.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '[alpaka](https://github.com/alpaka-group/alpaka3) 库是一个开源的仅头文件 C++20 抽象库，用于加速器开发。'
- en: Its aim is to provide performance portability across accelerators by abstracting
    the underlying levels of parallelism. The project provides a single-source C++
    API that enables developers to write parallel code once and run it on different
    hardware architectures without modification. The name “alpaka” comes from **A**bstractions
    for **L**evels of **P**arallelism, **A**lgorithms, and **K**ernels for **A**ccelerators.
    The library is platform-independent and supports the concurrent and cooperative
    use of multiple devices, including host CPUs (x86, ARM, and RISC-V) and GPUs from
    different vendors (NVIDIA, AMD, and Intel). A variety of accelerator backends,
    CUDA, HIP, SYCL, OpenMP, and serial execution, are available and can be selected
    based on the target device. Only a single implementation of a user kernel is required,
    expressed as a function object with a standardized interface. This eliminates
    the need to write specialized CUDA, HIP, SYCL, OpenMP, Intel TBB or threading
    code. Moreover, multiple accelerator backends can be combined to target different
    vendor hardware within a single system and even within a single application.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 其目的是通过抽象底层并行级别，在加速器之间提供性能可移植性。该项目提供了一个单源C++ API，使开发者能够编写一次并行代码，并在不同的硬件架构上运行而无需修改。名称“alpaka”来源于**A**bstractions
    for **L**evels of **P**arallelism, **A**lgorithms, and **K**ernels for **A**ccelerators。该库是平台无关的，并支持多个设备的并发和协作使用，包括主机CPU（x86、ARM和RISC-V）以及来自不同供应商的GPU（NVIDIA、AMD和Intel）。提供了各种加速器后端，如CUDA、HIP、SYCL、OpenMP和串行执行，可以根据目标设备进行选择。只需要一个用户内核的实现，以具有标准化接口的函数对象的形式表达。这消除了编写专门的CUDA、HIP、SYCL、OpenMP、Intel
    TBB或线程代码的需求。此外，可以将多个加速器后端组合起来，以针对单个系统甚至单个应用程序中的不同供应商硬件。
- en: The abstraction is based on a virtual index domain decomposed into equally sized
    chunks called frames. **alpaka** provides a uniform abstraction to traverse these
    frames, independent of the underlying hardware. Algorithms to be parallelized
    map the chunked index domain and native worker threads onto the data, expressing
    the computation as kernels that are executed in parallel threads (SIMT), thereby
    also leveraging SIMD units. Unlike native parallelism models such as CUDA, HIP,
    and SYCL, **alpaka** kernels are not restricted to three dimensions. Explicit
    caching of data within a frame via shared memory allows developers to fully unleash
    the performance of the compute device. Additionally, **alpaka** offers primitive
    functions such as iota, transform, transform-reduce, reduce, and concurrent, simplifying
    the development of portable high-performance applications. Host, device, mapped,
    and managed multi-dimensional views provide a natural way to operate on data.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象基于一个虚拟索引域，该域被分解成大小相等的块，称为帧。**alpaka**提供了一种统一的抽象来遍历这些帧，独立于底层硬件。要并行化的算法将分块索引域和本地工作线程映射到数据上，将计算表示为在并行线程（SIMT）中执行的内核，从而也利用了SIMD单元。与CUDA、HIP和SYCL等本地并行模型不同，**alpaka**内核不受三维的限制。通过共享内存显式缓存帧内的数据允许开发者充分发挥计算设备性能。此外，**alpaka**还提供了诸如iota、transform、transform-reduce、reduce和concurrent等原始函数，简化了可移植高性能应用程序的开发。主机、设备、映射和管理多维视图提供了一种自然的方式来操作数据。
- en: Here we demonstrate the usage of **alpaka3**, which is a complete rewrite of
    [alpaka](https://github.com/alpaka-group/alpaka). It is planned to merge this
    separate codebase back into the mainline alpaka repository before the first release
    in Q2/Q3 of 2026. Nevertheless, the code is well-tested and can be used for development
    today.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们展示了 **alpaka3** 的用法，它是 [alpaka](https://github.com/alpaka-group/alpaka)
    的完全重写。计划在2026年第二季度/第三季度的第一次发布之前，将这个独立的代码库合并回alpaka的主仓库。尽管如此，代码经过了良好的测试，并且可以用于今天的开发。
- en: Installing alpaka on your system
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在您的系统上安装alpaka
- en: For ease of use, we recommend installing alpaka using CMake as described below.
    For other ways to use alpaka in your projects, see the [alpaka3 documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html).
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们建议按照以下说明使用CMake安装alpaka。有关在项目中使用alpaka的其他方法，请参阅[alpaka3文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)。
- en: '**Clone the repository**'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**克隆仓库**'
- en: 'Clone the alpaka source code from GitHub to a directory of your choice:'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从GitHub克隆alpaka源代码到您选择的目录：
- en: '[PRE90]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '**Set installation directory**'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置安装目录**'
- en: Set the `ALPAKA_DIR` environment variable to the directory where you want to
    install alpaka. This can be any directory you choose where you have write access.
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将`ALPAKA_DIR`环境变量设置为想要安装alpaka的目录。这可以是您选择的任何目录，只要您有写入权限。
- en: '[PRE91]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '**Build and install**'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建和安装**'
- en: Create a build directory and use CMake to build and install alpaka. We use `CMAKE_INSTALL_PREFIX`
    to tell CMake where to install the library.
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一个构建目录，并使用 CMake 构建 alpaka。我们使用 `CMAKE_INSTALL_PREFIX` 来告诉 CMake 将库安装在哪里。
- en: '[PRE92]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '**Update environment**'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新环境**'
- en: 'To make sure that other projects can find your alpaka installation, you should
    add the installation directory to your `CMAKE_PREFIX_PATH`. You can do this by
    adding the following line to your shell configuration file (e.g. `~/.bashrc`):'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保其他项目可以找到你的 alpaka 安装，你应该将安装目录添加到你的 `CMAKE_PREFIX_PATH` 中。你可以通过将以下行添加到你的
    shell 配置文件（例如 `~/.bashrc`）来实现：
- en: '[PRE93]'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: You will need to source your shell configuration file or open a new terminal
    for the changes to take effect.
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你需要源码你的 shell 配置文件或打开一个新的终端以使更改生效。
- en: alpaka Compilation
  id: totrans-467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编译
- en: We recommend building your projects which use alpaka using CMake. A variety
    of strategies can be used to deal with building your application for a specific
    device or set of devices. Here we show a minimal way to get started, but this
    is by no means the only way to set up your projects. Please refer to the [alpaka3
    documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html) for
    alternative ways to use alpaka in your project, including a way to make your source
    code agnostic to the accelerator being targeted by defining a device specification
    in CMake.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用 CMake 构建使用 alpaka 的项目。可以采用各种策略来处理为特定设备或设备集构建你的应用程序。这里我们展示了入门的最小方法，但这绝对不是设置项目的唯一方法。请参阅
    [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)，了解在项目中使用
    alpaka 的替代方法，包括在 CMake 中定义设备规范以使源代码与目标加速器无关的方法。
- en: 'The following example demonstrates a `CMakeLists.txt` for a single-file project
    using alpaka3 (`main.cpp` which is presented in the section below):'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个使用 alpaka3 的单文件项目的 `CMakeLists.txt`（下面章节中展示的 `main.cpp`）：
- en: '[PRE94]'
  id: totrans-470
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Using alpaka on LUMI
  id: totrans-471
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 LUMI 上使用 alpaka
- en: To load the environment for using the AMD GPUs on LUMI with HIP, one can use
    the following modules -
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载在 LUMI 上使用 HIP 的 AMD GPU 的环境，可以使用以下模块 -
- en: '[PRE95]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: alpaka Programming
  id: totrans-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编程
- en: 'When starting with alpaka3, the first step is understanding the **device selection
    model**. Unlike frameworks that require explicit initialization calls, alpaka3
    uses a device specification to determine which backend and hardware to use. The
    device specification consists of two components:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始使用 alpaka3 时，第一步是理解**设备选择模型**。与需要显式初始化调用的框架不同，alpaka3 使用设备规范来确定使用哪个后端和硬件。设备规范由两个组件组成：
- en: '**API**: The parallel programming interface (host, cuda, hip, oneApi)'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**：并行编程接口（主机、cuda、hip、oneApi）'
- en: '**Device Kind**: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备类型**：硬件类型（cpu、nvidiaGpu、amdGpu、intelGpu）'
- en: Here we specify and use these at runtime to select and initialize devices. The
    device selection process is described in detail in the alpaka3 documentation.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定并使用这些在运行时选择和初始化设备。设备选择过程在 alpaka3 文档中有详细描述。
- en: alpaka3 uses an **execution space model** to abstract parallel hardware details.
    A device selector is created using `alpaka::onHost::makeDeviceSelector(devSpec)`,
    which returns an object that can query available devices and create device instances
    for the selected backend.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3 使用**执行空间模型**来抽象并行硬件的细节。使用 `alpaka::onHost::makeDeviceSelector(devSpec)`
    创建一个设备选择器，它返回一个可以查询可用设备并为所选后端创建设备实例的对象。
- en: 'The following example demonstrates a basic alpaka program that initializes
    a device and prints information about it:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个基本的 alpaka 程序，该程序初始化一个设备并打印有关该设备的信息：
- en: '[PRE96]'
  id: totrans-481
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE96]'
- en: alpaka3 provides memory management abstractions through buffers and views. Memory
    can be allocated on host or device using `alpaka::allocBuf<T, Idx>(device, extent)`.
    Data transfers between host and device are handled through `alpaka::memcpy(queue,
    dst, src)`. The library automatically manages memory layouts for optimal performance
    on different architectures.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3 通过缓冲区和视图提供内存管理抽象。可以使用 `alpaka::allocBuf<T, Idx>(device, extent)` 在主机或设备上分配内存。主机和设备之间的数据传输通过
    `alpaka::memcpy(queue, dst, src)` 处理。库自动管理不同架构上的内存布局以实现最佳性能。
- en: For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined
    as functors or lambda functions and executed using work division specifications
    that define the parallelization strategy. The framework supports various parallel
    patterns including element-wise operations, reductions, and scans.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行执行，alpaka3 提供了内核抽象。内核定义为函数式对象或 lambda 函数，并使用定义并行化策略的工作划分规范执行。框架支持各种并行模式，包括逐元素操作、归约和扫描。
- en: Tour of **alpaka** Features
  id: totrans-484
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**alpaka** 功能巡览'
- en: Now we will quickly explore the most commonly used features of alpaka and go
    over some basic usage. A quick reference of commonly used alpaka features is available
    [here.](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将快速探索 alpaka 最常用的功能，并简要介绍一些基本用法。常用 alpaka 功能的快速参考可在此处找到。[链接](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
- en: '**General setup**: Include the consolidated header once and you are ready to
    start using alpaka.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用设置**：包含一次综合头文件，然后即可开始使用 alpaka。'
- en: '[PRE97]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '**Accelerator, platform, and device management**: Select devices by combining
    the desired API with the appropriate hardware kind using the device selector.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速器、平台和设备管理**：通过将所需的 API 与适当的硬件类型结合使用设备选择器来选择设备。'
- en: '[PRE98]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '**Queues and events**: Create blocking or non-blocking queues per device, record
    events, and synchronize work as needed.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '**队列和事件**：为每个设备创建阻塞或非阻塞队列，记录事件，并根据需要同步工作。'
- en: '[PRE99]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '**Memory management**: Allocate host, device, mapped, unified, or deferred
    buffers, create non-owning views, and move data portably with memcpy, memset,
    and fill.'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存管理**：分配主机、设备、映射、统一或延迟缓冲区，创建非拥有视图，并使用 memcpy、memset 和 fill 可移植地移动数据。'
- en: '[PRE100]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '**Kernel execution**: Build a FrameSpec manually or request one tuned for your
    data type, then enqueue kernels with automatic or explicit executors.'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核执行**：手动构建 FrameSpec 或请求针对您的数据类型调优的 FrameSpec，然后使用自动或显式执行器排队内核。'
- en: '[PRE101]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '**Kernel implementation**: Write kernels as functors annotated with ALPAKA_FN_ACC,
    use shared memory, synchronization, atomics, and math helpers directly inside
    the kernel body.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核实现**：将内核编写为带有 ALPAKA_FN_ACC 注解的函数式对象，并在内核体内部直接使用共享内存、同步、原子操作和数学助手。'
- en: '[PRE102]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Run alpaka3 Example in Simple Steps
  id: totrans-498
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单步骤运行 alpaka3 示例
- en: The following example works on systems with CMake 3.25+ and an appropriate C++
    compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or
    oneAPI) is installed.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于 CMake 3.25+ 及以上版本和合适的 C++ 编译器。对于 GPU 执行，请确保已安装相应的运行时（CUDA、ROCm 或 oneAPI）。
- en: 'Create a directory for your project:'
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的项目创建一个目录：
- en: '[PRE103]'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Copy the CMakeLists.txt from above into the current folder
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 CMakeLists.txt 文件复制到当前文件夹
- en: Copy the main.cpp file into the current folder
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 main.cpp 文件复制到当前文件夹
- en: 'Configure and build:'
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和构建：
- en: '[PRE104]'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'Run the executable:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行可执行文件：
- en: '[PRE105]'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Note
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The device specification system allows you to select the target device at CMake
    configuration time. The format is `"api:deviceKind"`, where:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 设备指定系统允许你在 CMake 配置时选择目标设备。格式为 `"api:deviceKind"`，其中：
- en: '**api**: The parallel programming interface (`host`, `cuda`, `hip`, `oneApi`)'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api**：并行编程接口（`host`、`cuda`、`hip`、`oneApi`）'
- en: '**deviceKind**: The type of device (`cpu`, `nvidiaGpu`, `amdGpu`, `intelGpu`)'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deviceKind**：设备类型（`cpu`、`nvidiaGpu`、`amdGpu`、`intelGpu`）'
- en: 'Available combinations are: `host:cpu`, `cuda:nvidiaGpu`, `hip:amdGpu`, `oneApi:cpu`,
    `oneApi:intelGpu`, `oneApi:nvidiaGpu`, `oneApi:amdGpu`'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的组合有：`host:cpu`、`cuda:nvidiaGpu`、`hip:amdGpu`、`oneApi:cpu`、`oneApi:intelGpu`、`oneApi:nvidiaGpu`、`oneApi:amdGpu`
- en: Warning
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI
    SDK are available respectively
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 CUDA SDK、HIP SDK 或 OneAPI SDK 可用分别时，CUDA、HIP 或 Intel 后端才有效。
- en: Expected output
  id: totrans-515
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预期输出
- en: '[PRE106]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD
    MI250X”, or your CPU model).
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 设备名称将根据您的硬件而变化（例如，“NVIDIA A100”、“AMD MI250X”或您的 CPU 型号）。
- en: Compile and Execute Examples
  id: totrans-518
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译和执行示例
- en: You can test the **alpaka** provided examples from the [example section](#examples).
    The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
    To switch to CPU usage only you can simply replace `ap::onHost::makeDeviceSelector(ap::api::hip,
    ap::deviceKind::amdGpu);` with `ap::onHost::makeDeviceSelector(ap::api::host,
    ap::deviceKind::cpu);`
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[示例部分](#examples)测试 alpaka 提供的示例。这些示例已硬编码了在 LUMI 上所需的 AMD ROCm 平台的使用。要仅使用
    CPU，您只需将 `ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);`
    替换为 `ap::onHost::makeDeviceSelector(ap::api::host, ap::deviceKind::cpu);`
- en: The following steps assume you have downloaded alpaka already and the path to
    the **alapka** source code is stored in the environment variable `ALPAKA_DIR`.
    To test the example copy the code into a file `main.cpp`
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤假设你已经下载了alpaka，并且**alapka**源代码的路径存储在环境变量`ALPAKA_DIR`中。要测试示例，请将代码复制到文件`main.cpp`中。
- en: Alternatively, [click here](https://godbolt.org/z/69exnG4xb) to try the first
    example using in the godbolt compiler explorer.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，[点击此处](https://godbolt.org/z/69exnG4xb)在godbolt编译器探索器中尝试第一个示例。
- en: '[PRE107]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Note
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用AMD或NVIDIA GPU上的oneAPI Sycl，你必须安装相应的Codeplay oneAPI插件，如[此处](https://codeplay.com/solutions/oneapi/plugins/)所述。
- en: '[PRE112]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Note
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用AMD或NVIDIA GPU上的oneAPI Sycl，你必须安装相应的Codeplay oneAPI插件，如[此处](https://codeplay.com/solutions/oneapi/plugins/)所述。
- en: '[PRE113]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: Exercise
  id: totrans-533
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Write a vector add kernel in alpaka'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在alpaka中编写向量加法内核
- en: In this exercise we would like to write (fill-in-the-blanks) a simple kernel
    to add two vectors.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的内核来添加两个向量。
- en: 'To compile and run the code interactively, first we first need to get an allocation
    on a GPU node and load the modules for alpaka:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式编译和运行代码，首先我们需要在GPU节点上获取一个分配并加载alpaka模块：
- en: '[PRE114]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行一个简单的设备检测工具来检查GPU是否可用（注意`srun`）：
- en: '[PRE115]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Now, let’s look at the code to set up the exercise:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看设置练习的代码：
- en: Below we use fetch content with our CMake to get started with alpaka quickly.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们使用CMake的fetch content功能快速开始使用alpaka。
- en: CMakeLists.txt
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: CMakeLists.txt
- en: '[PRE116]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: Below we have the main alpaka code doing a vector addition on device using a
    high level transform function
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们使用高级transform函数在设备上执行向量加法的主要alpaka代码。
- en: main.cpp
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: main.cpp
- en: '[PRE117]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: To set up our project, we create a folder and place our CMakeLists.txt and main.cpp
    in there.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置我们的项目，我们创建一个文件夹并将我们的CMakeLists.txt和main.cpp放在那里。
- en: '[PRE118]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'To compile and run the code, use the following commands:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE119]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Now your task will be to write and launch your first alpaka kernel. This kernel
    will do the vector addition and we will use this instead of the transform helper.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务是编写和启动你的第一个alpaka内核。这个内核将执行向量加法，我们将使用这个代替transform辅助函数。
- en: Writing the vector add kernel
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 编写向量加法内核
- en: '[PRE120]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Examples
  id: totrans-554
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: Parallel for with Unified Memory
  id: totrans-555
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带统一内存的并行for循环
- en: '[PRE121]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-561
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: Parallel for with GPU buffers
  id: totrans-562
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带GPU缓冲区的并行for循环
- en: '[PRE127]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-565
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: Asynchronous parallel for kernels
  id: totrans-568
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步并行for内核
- en: '[PRE132]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-572
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-573
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: Reduction
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 归约
- en: '[PRE137]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-579
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: Pros and cons of cross-platform portability ecosystems
  id: totrans-580
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨平台可移植生态系统的好处和坏处
- en: General observations
  id: totrans-581
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一般观察
- en: The amount of code duplication is minimized.
  id: totrans-582
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码重复量最小化。
- en: ''
  id: totrans-583
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-584
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The same code can be compiled to multiple architectures from different vendors.
  id: totrans-585
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一段代码可以编译成不同供应商的多种架构。
- en: ''
  id: totrans-586
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-587
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited learning resources compared to CUDA (Stack Overflow, course material,
    documentation).
  id: totrans-588
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与CUDA相比，学习资源有限（Stack Overflow、课程材料、文档）。
- en: Lambda-based kernel models (Kokkos, SYCL)
  id: totrans-589
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Lambda的内核模型（Kokkos、SYCL）
- en: Higher level of abstraction.
  id: totrans-590
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-591
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-592
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Less knowledge of the underlying architecture is needed for initial porting.
  id: totrans-593
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始移植所需的底层架构知识较少。
- en: ''
  id: totrans-594
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-595
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very nice and readable source code (C++ API).
  id: totrans-596
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好读的源代码（C++ API）。
- en: ''
  id: totrans-597
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-598
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The models are relatively new and not very popular yet.
  id: totrans-599
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些模型相对较新，尚未非常流行。
- en: Functor-based kernel model (alpaka)
  id: totrans-600
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Functor的内核模型（alpaka）
- en: Very good portability.
  id: totrans-601
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-602
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-603
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Higher level of abstraction.
  id: totrans-604
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-605
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-606
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API always awailable which gives more control and allows fine tuning.
  id: totrans-607
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API始终可用，提供更多控制并允许精细调整。
- en: ''
  id: totrans-608
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-609
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: User friendly C++ API for both the host and kernel code.
  id: totrans-610
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于主机和内核代码的用户友好C++ API。
- en: ''
  id: totrans-611
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-612
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Small community and ecosystem.
  id: totrans-613
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型社区和生态系统。
- en: Separate-source kernel models (OpenCL)
  id: totrans-614
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分离源内核模型（OpenCL）
- en: Very good portability.
  id: totrans-615
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-616
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-617
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mature ecosystem.
  id: totrans-618
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成熟的生态系统。
- en: ''
  id: totrans-619
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-620
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited number of vendor-provided libraries.
  id: totrans-621
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有限的供应商提供的库数量。
- en: ''
  id: totrans-622
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-623
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API gives more control and allows fine tuning.
  id: totrans-624
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API提供更多控制并允许精细调整。
- en: ''
  id: totrans-625
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-626
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both C and C++ APIs available (C++ API is less well supported).
  id: totrans-627
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供C和C++ API（C++ API支持度较低）。
- en: ''
  id: totrans-628
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-629
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The low-level API and separate-source kernel model are less user friendly.
  id: totrans-630
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API和分离源内核模型对用户不太友好。
- en: C++ Standard Parallelism (StdPar, PSTL)
  id: totrans-631
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++标准并行性（StdPar、PSTL）
- en: Very high level of abstraction.
  id: totrans-632
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常高的抽象级别。
- en: ''
  id: totrans-633
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-634
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Easy to speed up code which already relying on STL algorithms.
  id: totrans-635
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易加速依赖于STL算法的代码。
- en: ''
  id: totrans-636
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-637
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very little control over hardware.
  id: totrans-638
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对硬件的控制非常有限。
- en: ''
  id: totrans-639
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-640
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Support by compilers is improving, but is far from mature.
  id: totrans-641
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器的支持正在改善，但还远未成熟。
- en: Keypoints
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: General code organization is similar to non-portable kernel-based models.
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用代码组织与非可移植的基于内核的模型类似。
- en: As long as no vendor-specific functionality is used, the same code can run on
    any GPU.
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要不使用特定于供应商的功能，相同的代码就可以在任何GPU上运行。
- en: C++ StdPar
  id: totrans-645
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++ StdPar
- en: In C++17, the initial support for parallel execution of standard algorithms
    has been introduced. Most algorithms available via the standard `<algorithms>`
    header were given an overload accepting with an [*execution policy*](https://en.cppreference.com/w/cpp/algorithm)
    argument which allows the programmer to request parallel execution of the standard
    library function. While the main goal was to allow low-effort, high-level interface
    to run existing algorithms like `std::sort` on many CPU cores, implementations
    are allowed to use other hardware, and functions like `std::for_each` or `std::transform`
    offer great flexibility in writing the algorithm.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++17中，对标准算法并行执行的支持已经被引入。大多数通过标准`<algorithms>`头文件提供的算法都被赋予了接受[*执行策略*](https://en.cppreference.com/w/cpp/algorithm)参数的重载，这允许程序员请求并行执行标准库函数。虽然主要目标是允许低成本的、高级别的接口在许多CPU核心上运行现有的算法，如`std::sort`，但实现允许使用其他硬件，并且`std::for_each`或`std::transform`等函数在编写算法时提供了很大的灵活性。
- en: C++ StdPar, also called Parallel STL or PSTL, could be considered similar to
    directive-based models, as it is very high-level and does not give the programmer
    fine-grained control over data movement or any access to hardware-specific features
    like shared (local) memory. Even the GPU to run on is selected automatically,
    since standard C++ does not have the concept of a *device* (but there are vendor
    extensions allowing the programmer more control) However, for applications that
    already relies on algorithms from C++ standard library, StdPar can be a good way
    to reap the performance benefits of both CPUs and GPUs with minimal code modifications.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: C++ StdPar，也称为并行STL或PSTL，可以被认为是类似于指令驱动的模型，因为它非常高级，不提供程序员对数据移动的细粒度控制或对硬件特定功能（如共享（局部）内存）的访问。甚至运行的GPU也是自动选择的，因为标准C++没有*设备*的概念（但有一些供应商扩展允许程序员有更多的控制）。然而，对于已经依赖于C++标准库算法的应用程序，StdPar可以通过最小的代码修改来获得CPU和GPU的性能优势。
- en: 'For GPU programming, all three vendors offer their implementations of StdPar
    with the ability to offload code to the GPU: NVIDIA has `nvc++`, AMD has experimental
    [roc-stdpar](https://github.com/ROCm/roc-stdpar), and Intel offers StdPar offload
    with their oneAPI compiler. [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)
    offers an independent StdPar implementation, able to target devices from all three
    vendors. While being a part of the C++ standard, the level of support and the
    maturity of StdPar implementations varies a lot between different compilers: not
    all compilers support all algorithms, and different heuristics for mapping the
    algorithm to hardware and for managing data movement can have effect on performance.'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPU编程，三家供应商都提供了他们的StdPar实现，可以将代码卸载到GPU上：NVIDIA有`nvc++`，AMD有实验性的[roc-stdpar](https://github.com/ROCm/roc-stdpar)，而Intel通过他们的oneAPI编译器提供StdPar卸载功能。[AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)提供了一个独立的StdPar实现，能够针对三家供应商的设备。虽然StdPar是C++标准的一部分，但不同编译器对StdPar的支持水平和成熟度差异很大：并非所有编译器都支持所有算法，而且将算法映射到硬件以及管理数据移动的不同启发式方法可能会影响性能。
- en: StdPar compilation
  id: totrans-649
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar编译
- en: 'The build process depends a lot on the used compiler:'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程很大程度上取决于所使用的编译器：
- en: 'AdaptiveCpp: Add `--acpp-stdpar` flag when calling `acpp`.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AdaptiveCpp：在调用`acpp`时添加`--acpp-stdpar`标志。
- en: 'Intel oneAPI: Add `-fsycl -fsycl-pstl-offload=gpu` flags when calling `icpx`.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：在调用`icpx`时添加`-fsycl -fsycl-pstl-offload=gpu`标志。
- en: 'NVIDIA NVC++: Add `-stdpar` flag when calling `nvc++` (not supported with plain
    `nvcc`).'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA NVC++：在调用`nvc++`时添加`-stdpar`标志（不支持使用普通的`nvcc`）。
- en: StdPar programming
  id: totrans-654
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar编程
- en: In its simplest form, using C++ standard parallelism requires including an additional
    `<execution>` header and adding one argument to a supported standard library function.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的形式中，使用C++标准并行性需要包含额外的`<execution>`头文件，并将一个参数添加到支持的标准库函数中。
- en: 'For example, let’s look at the following sequential code sorting a vector:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看以下按顺序排序向量的代码：
- en: '[PRE142]'
  id: totrans-657
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: 'To make it run sorting on the GPU, only a minor modification is needed:'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 要使其在GPU上运行排序，只需要进行微小的修改：
- en: '[PRE143]'
  id: totrans-659
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: Now, when compiled with one of the supported compilers, the code will run the
    sorting on a GPU.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当使用支持的编译器编译时，代码将在GPU上运行排序。
- en: While the can initially seem very limiting, many standard algorithms, such as
    `std::transform`, `std::accumulate`, `std::transform_reduce`, and `std::for_each`
    can run custom functions over an array, thus allowing one to offload an arbitrary
    algorithm, as long as it does not violate typical limitations of GPU kernels,
    such as not throwing any exceptions and not doing system calls.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一开始可能看起来非常受限，但许多标准算法，例如`std::transform`、`std::accumulate`、`std::transform_reduce`和`std::for_each`，可以在数组上运行自定义函数，从而允许将任意算法卸载，只要它不违反GPU内核的典型限制，例如不抛出任何异常和不进行系统调用。
- en: StdPar execution policies
  id: totrans-662
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar执行策略
- en: 'In C++, there are four different execution policies to choose from:'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中，有四种不同的执行策略可供选择：
- en: '`std::execution::seq`: run algorithm serially, don’t parallelize it.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::seq`：串行运行算法，不进行并行化。'
- en: '`std::execution::par`: allow parallelizing the algorithm (as if using multiple
    threads),'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par`：允许并行化算法（类似于使用多个线程），'
- en: '`std::execution::unseq`: allow vectorizing the algorithm (as if using SIMD),'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::unseq`：允许向量化算法（类似于使用SIMD），'
- en: '`std::execution::par_unseq`: allow both vectorizing and parallelizing the algorithm.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par_unseq`：允许向量化并并行化算法。'
- en: 'The main difference between `par` and `unseq` is related to thread progress
    and locks: using `unseq` or `par_unseq` requires that the algorithms does not
    contain mutexes and other locks between the processes, while `par` does not have
    this limitation.'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: '`par`和`unseq`之间的主要区别与线程进度和锁有关：使用`unseq`或`par_unseq`要求算法在进程之间不包含互斥锁和其他锁，而`par`没有这个限制。'
- en: For GPU, the optimal choice is `par_unseq`, since this places the least requirement
    on the compiler in terms of operation ordering. While `par` is also supported
    in some cases, it is best avoided, both due to limited compiler support and as
    an indication that the algorithm is likely a poor fit for the hardware.
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPU，最佳选择是`par_unseq`，因为这在操作顺序方面对编译器的要求最低。虽然`par`在某些情况下也受到支持，但最好避免使用，这既是因为编译器支持有限，也是因为算法可能不适合硬件的迹象。
- en: StdPar compilation
  id: totrans-670
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar编译
- en: 'The build process depends a lot on the used compiler:'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程很大程度上取决于所使用的编译器：
- en: 'AdaptiveCpp: Add `--acpp-stdpar` flag when calling `acpp`.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AdaptiveCpp：在调用`acpp`时添加`--acpp-stdpar`标志。
- en: 'Intel oneAPI: Add `-fsycl -fsycl-pstl-offload=gpu` flags when calling `icpx`.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：在调用`icpx`时添加`-fsycl -fsycl-pstl-offload=gpu`标志。
- en: 'NVIDIA NVC++: Add `-stdpar` flag when calling `nvc++` (not supported with plain
    `nvcc`).'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA NVC++：在调用`nvc++`时添加`-stdpar`标志（不支持使用普通`nvcc`）。
- en: StdPar programming
  id: totrans-675
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar编程
- en: In its simplest form, using C++ standard parallelism requires including an additional
    `<execution>` header and adding one argument to a supported standard library function.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，使用C++标准并行性需要包含一个额外的`<execution>`头文件，并将一个参数添加到受支持的标准库函数中。
- en: 'For example, let’s look at the following sequential code sorting a vector:'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看以下按顺序排序向量的代码：
- en: '[PRE144]'
  id: totrans-678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'To make it run sorting on the GPU, only a minor modification is needed:'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 要使其在GPU上运行排序，只需要进行微小的修改：
- en: '[PRE145]'
  id: totrans-680
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: Now, when compiled with one of the supported compilers, the code will run the
    sorting on a GPU.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当使用支持的编译器编译时，代码将在GPU上运行排序。
- en: While the can initially seem very limiting, many standard algorithms, such as
    `std::transform`, `std::accumulate`, `std::transform_reduce`, and `std::for_each`
    can run custom functions over an array, thus allowing one to offload an arbitrary
    algorithm, as long as it does not violate typical limitations of GPU kernels,
    such as not throwing any exceptions and not doing system calls.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一开始可能看起来非常受限，但许多标准算法，例如`std::transform`、`std::accumulate`、`std::transform_reduce`和`std::for_each`，可以在数组上运行自定义函数，从而允许将任意算法卸载，只要它不违反GPU内核的典型限制，例如不抛出任何异常和不进行系统调用。
- en: StdPar execution policies
  id: totrans-683
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StdPar执行策略
- en: 'In C++, there are four different execution policies to choose from:'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中，有四种不同的执行策略可供选择：
- en: '`std::execution::seq`: run algorithm serially, don’t parallelize it.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::seq`：串行运行算法，不进行并行化。'
- en: '`std::execution::par`: allow parallelizing the algorithm (as if using multiple
    threads),'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par`：允许并行化算法（类似于使用多个线程），'
- en: '`std::execution::unseq`: allow vectorizing the algorithm (as if using SIMD),'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::unseq`: 允许算法向量化（类似于使用SIMD），'
- en: '`std::execution::par_unseq`: allow both vectorizing and parallelizing the algorithm.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std::execution::par_unseq`：允许对算法进行向量化和平行化。'
- en: 'The main difference between `par` and `unseq` is related to thread progress
    and locks: using `unseq` or `par_unseq` requires that the algorithms does not
    contain mutexes and other locks between the processes, while `par` does not have
    this limitation.'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: '`par`和`unseq`之间的主要区别与线程进度和锁有关：使用`unseq`或`par_unseq`要求算法在进程之间不包含互斥锁和其他锁，而`par`没有这个限制。'
- en: For GPU, the optimal choice is `par_unseq`, since this places the least requirement
    on the compiler in terms of operation ordering. While `par` is also supported
    in some cases, it is best avoided, both due to limited compiler support and as
    an indication that the algorithm is likely a poor fit for the hardware.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPU，最佳选择是`par_unseq`，因为它对编译器在操作顺序方面的要求最少。虽然`par`在某些情况下也得到支持，但最好避免使用，这不仅因为编译器支持有限，而且也表明算法可能不适合硬件。
- en: Kokkos
  id: totrans-691
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kokkos
- en: Kokkos is an open-source performance portability ecosystem for parallelization
    on large heterogeneous hardware architectures of which development has mostly
    taken place on Sandia National Laboratories. The project started in 2011 as a
    parallel C++ programming model, but have since expanded into a more broad ecosystem
    including Kokkos Core (the programming model), Kokkos Kernels (math library),
    and Kokkos Tools (debugging, profiling and tuning tools). By preparing proposals
    for the C++ standard committee, the project also aims to influence the ISO/C++
    language standard such that, eventually, Kokkos capabilities will become native
    to the language standard. A more detailed introduction is found [HERE](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/).
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 是一个开源的性能可移植生态系统，用于在大型的异构硬件架构上并行化，其开发主要在桑迪亚国家实验室进行。该项目始于2011年，最初是一个并行C++编程模型，但后来扩展成为一个更广泛的生态系统，包括Kokkos
    Core（编程模型）、Kokkos Kernels（数学库）和Kokkos Tools（调试、分析和调优工具）。通过为C++标准委员会准备提案，该项目还旨在影响ISO/C++语言标准，使得最终Kokkos的功能将成为语言标准的原生部分。更详细的介绍可以在[这里](https://www.sandia.gov/news/publications/hpc-annual-reports/article/kokkos/)找到。
- en: The Kokkos library provides an abstraction layer for a variety of different
    parallel programming models, currently CUDA, HIP, SYCL, HPX, OpenMP, and C++ threads.
    Therefore, it allows better portability across different hardware manufactured
    by different vendors, but introduces an additional dependency to the software
    stack. For example, when using CUDA, only CUDA installation is required, but when
    using Kokkos with NVIDIA GPUs, Kokkos and CUDA installation are both required.
    Kokkos is not a very popular choice for parallel programming, and therefore, learning
    and using Kokkos can be more difficult compared to more established programming
    models such as CUDA, for which a much larger amount of search results and Stack
    Overflow discussions can be found.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos库为各种不同的并行编程模型提供了一个抽象层，目前包括CUDA、HIP、SYCL、HPX、OpenMP和C++线程。因此，它允许在不同厂商制造的硬件之间实现更好的可移植性，但引入了软件堆栈的额外依赖。例如，当使用CUDA时，只需要CUDA安装即可，但当使用Kokkos与NVIDIA
    GPU一起时，需要Kokkos和CUDA的安装。Kokkos并不是并行编程的一个非常受欢迎的选择，因此，与CUDA等更成熟的编程模型相比，学习和使用Kokkos可能会更加困难，因为CUDA有大量的搜索结果和Stack
    Overflow讨论。
- en: Kokkos compilation
  id: totrans-694
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos编译
- en: Furthermore, one challenge with some cross-platform portability libraries is
    that even on the same system, different projects may require different combinations
    of compilation settings for the portability library. For example, in Kokkos, one
    project may wish the default execution space to be a CUDA device, whereas another
    requires a CPU. Even if the projects prefer the same execution space, one project
    may desire the Unified Memory to be the default memory space and the other may
    wish to use pinned GPU memory. It may be burdensome to maintain a large number
    of library instances on a single system.
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些跨平台可移植性库的挑战之一是，即使在同一系统上，不同的项目可能需要不同的编译设置组合来满足可移植性库。例如，在Kokkos中，一个项目可能希望默认的执行空间是CUDA设备，而另一个项目可能需要CPU。即使项目偏好相同的执行空间，一个项目可能希望统一内存成为默认的内存空间，而另一个项目可能希望使用固定GPU内存。在单个系统上维护大量库实例可能会变得很麻烦。
- en: 'However, Kokkos offers a simple way to compile Kokkos library simultaneously
    with the user project. This is achieved by specifying Kokkos compilation settings
    (see [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html))
    and including the Kokkos Makefile in the user Makefile. CMake is also supported.
    This way, the user application and Kokkos library are compiled together. The following
    is an example Makefile for a single-file Kokkos project (hello.cpp) that uses
    CUDA (Volta architecture) as the backend (default execution space) and Unified
    Memory as the default memory space:'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Kokkos 提供了一种简单的方法来同时编译 Kokkos 库和用户项目。这是通过指定 Kokkos 编译设置（见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html)）并在用户
    Makefile 中包含 Kokkos Makefile 来实现的。CMake 也受到支持。这样，用户应用程序和 Kokkos 库一起编译。以下是一个使用
    CUDA（Volta 架构）作为后端（默认执行空间）和统一内存作为默认内存空间的单文件 Kokkos 项目的示例 Makefile：
- en: '[PRE146]'
  id: totrans-697
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: To build a **hello.cpp** project with the above Makefile, no steps other than
    cloning the Kokkos project into the current directory is required.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用上述 Makefile 构建 **hello.cpp** 项目，除了将 Kokkos 项目克隆到当前目录外，无需进行其他步骤。
- en: Kokkos programming
  id: totrans-699
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos 编程
- en: When starting to write a project using Kokkos, the first step is understand
    Kokkos initialization and finalization. Kokkos must be initialized by calling
    `Kokkos::initialize(int& argc, char* argv[])` and finalized by calling `Kokkos::finalize()`.
    More details are given in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html).
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始使用 Kokkos 编写项目时，第一步是了解 Kokkos 的初始化和终止。Kokkos 必须通过调用 `Kokkos::initialize(int&
    argc, char* argv[])` 来初始化，并通过调用 `Kokkos::finalize()` 来终止。更多详细信息请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html)。
- en: Kokkos uses an execution space model to abstract the details of parallel hardware.
    The execution space instances map to the available backend options such as CUDA,
    OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer
    in the source code, the default execution space `Kokkos::DefaultExecutionSpace`
    is used. This is chosen when the Kokkos library is compiled. The Kokkos execution
    space model is described in more detail in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces).
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 使用执行空间模型来抽象并行硬件的细节。执行空间实例映射到可用的后端选项，如 CUDA、OpenMP、HIP 或 SYCL。如果程序员在源代码中没有明确选择执行空间，则使用默认的执行空间
    `Kokkos::DefaultExecutionSpace`。这是在编译 Kokkos 库时选择的。Kokkos 执行空间模型在[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces)有更详细的描述。
- en: Similarly, Kokkos uses a memory space model for different types of memory, such
    as host memory or device memory. If not defined explicitly, Kokkos uses the default
    memory space specified during Kokkos compilation as described [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces).
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Kokkos 使用内存空间模型来处理不同类型的内存，如主机内存或设备内存。如果没有明确定义，Kokkos 将使用在 Kokkos 编译期间指定的默认内存空间，如[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces)所述。
- en: 'The following is an example of a Kokkos program that initializes Kokkos and
    prints the execution space and memory space instances:'
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个初始化 Kokkos 并打印执行空间和内存空间实例的 Kokkos 程序示例：
- en: '[PRE147]'
  id: totrans-704
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: With Kokkos, the data can be accessed either through raw pointers or through
    Kokkos Views. With raw pointers, the memory allocation into the default memory
    space can be done using `Kokkos::kokkos_malloc(n * sizeof(int))`. Kokkos Views
    are a data type that provides a way to access data more efficiently in memory
    corresponding to a certain Kokkos memory space, such as host memory or device
    memory. A 1-dimensional view of type int* can be created by `Kokkos::View<int*>
    a("a", n)`, where `"a"` is a label, and `n` is the size of the allocation in the
    number of integers. Kokkos determines the optimal layout for the data at compile
    time for best overall performance as a function of the computer architecture.
    Furthermore, Kokkos handles the deallocation of such memory automatically. More
    details about Kokkos Views are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html).
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kokkos，数据可以通过原始指针或通过 Kokkos 视图来访问。使用原始指针，可以将内存分配到默认内存空间，使用 `Kokkos::kokkos_malloc(n
    * sizeof(int))`。Kokkos 视图是一种数据类型，提供了一种更有效地访问对应于特定 Kokkos 内存空间（如主机内存或设备内存）中的数据的方法。可以通过
    `Kokkos::View<int*> a("a", n)` 创建一个类型为 int* 的一维视图，其中 `"a"` 是标签，`n` 是以整数数量表示的分配大小。Kokkos
    在编译时确定数据的最佳布局，以实现最佳的整体性能，这取决于计算机架构。此外，Kokkos 会自动处理此类内存的释放。有关 Kokkos 视图的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html)。
- en: 'Finally, Kokkos provides three different parallel operations: `parallel_for`,
    `parallel_reduce`, and `parallel_scan`. The `parallel_for` operation is used to
    execute a loop in parallel. The `parallel_reduce` operation is used to execute
    a loop in parallel and reduce the results to a single value. The `parallel_scan`
    operation implements a prefix scan. The usage of `parallel_for` and `parallel_reduce`
    are demonstrated in the examples later in this chapter. More detail about the
    parallel operations are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html).'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kokkos 提供了三种不同的并行操作：`parallel_for`、`parallel_reduce` 和 `parallel_scan`。`parallel_for`
    操作用于并行执行循环。`parallel_reduce` 操作用于并行执行循环并将结果归约到单个值。`parallel_scan` 操作实现前缀扫描。`parallel_for`
    和 `parallel_reduce` 的用法将在本章后面的示例中演示。有关并行操作的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html)。
- en: Run Kokkos hello.cpp example in simple steps
  id: totrans-707
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单步骤运行 Kokkos hello.cpp 示例
- en: The following should work on AMD VEGA90A devices straight out of the box (needs
    ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use
    the variables commented out on the Makefile.
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容在 AMD VEGA90A 设备上直接使用应能正常工作（需要 ROCm 安装）。在 NVIDIA Volta V100 设备上（需要 CUDA
    安装），请在 Makefile 中使用注释掉的变量。
- en: '`git clone https://github.com/kokkos/kokkos.git`'
  id: totrans-709
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`git clone https://github.com/kokkos/kokkos.git`'
- en: Copy the above Makefile into the current folder (make sure the indentation of
    the last line is tab, and not space)
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 Makefile 复制到当前文件夹中（确保最后一行的缩进是制表符，而不是空格）
- en: Copy the above hello.cpp file into the current folder
  id: totrans-711
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 hello.cpp 文件复制到当前文件夹
- en: '`make`'
  id: totrans-712
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`make`'
- en: '`./hello`'
  id: totrans-713
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`./hello`'
- en: Kokkos compilation
  id: totrans-714
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos 编译
- en: Furthermore, one challenge with some cross-platform portability libraries is
    that even on the same system, different projects may require different combinations
    of compilation settings for the portability library. For example, in Kokkos, one
    project may wish the default execution space to be a CUDA device, whereas another
    requires a CPU. Even if the projects prefer the same execution space, one project
    may desire the Unified Memory to be the default memory space and the other may
    wish to use pinned GPU memory. It may be burdensome to maintain a large number
    of library instances on a single system.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些跨平台可移植库的挑战之一是，即使在同一系统上，不同的项目可能需要不同的编译设置组合来满足库的可移植性。例如，在 Kokkos 中，一个项目可能希望默认的执行空间是
    CUDA 设备，而另一个则可能需要 CPU。即使项目偏好相同的执行空间，一个项目可能希望统一内存成为默认的内存空间，而另一个则可能希望使用固定 GPU 内存。在单个系统上维护大量库实例可能会变得很麻烦。
- en: 'However, Kokkos offers a simple way to compile Kokkos library simultaneously
    with the user project. This is achieved by specifying Kokkos compilation settings
    (see [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html))
    and including the Kokkos Makefile in the user Makefile. CMake is also supported.
    This way, the user application and Kokkos library are compiled together. The following
    is an example Makefile for a single-file Kokkos project (hello.cpp) that uses
    CUDA (Volta architecture) as the backend (default execution space) and Unified
    Memory as the default memory space:'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Kokkos 提供了一种简单的方法来同时编译 Kokkos 库和用户项目。这是通过指定 Kokkos 编译设置（见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Compiling.html)）并在用户
    Makefile 中包含 Kokkos Makefile 来实现的。CMake 也受到支持。这样，用户应用程序和 Kokkos 库将一起编译。以下是一个使用
    CUDA（Volta 架构）作为后端（默认执行空间）和统一内存作为默认内存空间的单文件 Kokkos 项目的示例 Makefile：
- en: '[PRE148]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: To build a **hello.cpp** project with the above Makefile, no steps other than
    cloning the Kokkos project into the current directory is required.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用上述 Makefile 构建 **hello.cpp** 项目，除了将 Kokkos 项目克隆到当前目录外，无需其他步骤。
- en: Kokkos programming
  id: totrans-719
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos 编程
- en: When starting to write a project using Kokkos, the first step is understand
    Kokkos initialization and finalization. Kokkos must be initialized by calling
    `Kokkos::initialize(int& argc, char* argv[])` and finalized by calling `Kokkos::finalize()`.
    More details are given in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html).
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始使用 Kokkos 编写项目时，第一步是理解 Kokkos 的初始化和终止。Kokkos 必须通过调用 `Kokkos::initialize(int&
    argc, char* argv[])` 来初始化，并通过调用 `Kokkos::finalize()` 来终止。更多详细信息请见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Initialization.html)。
- en: Kokkos uses an execution space model to abstract the details of parallel hardware.
    The execution space instances map to the available backend options such as CUDA,
    OpenMP, HIP, or SYCL. If the execution space is not explicitly chosen by the programmer
    in the source code, the default execution space `Kokkos::DefaultExecutionSpace`
    is used. This is chosen when the Kokkos library is compiled. The Kokkos execution
    space model is described in more detail in [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces).
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 使用执行空间模型来抽象并行硬件的细节。执行空间实例映射到可用的后端选项，如 CUDA、OpenMP、HIP 或 SYCL。如果程序员在源代码中没有明确选择执行空间，则使用默认执行空间
    `Kokkos::DefaultExecutionSpace`。这是在编译 Kokkos 库时选择的。Kokkos 执行空间模型在[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-spaces)有更详细的描述。
- en: Similarly, Kokkos uses a memory space model for different types of memory, such
    as host memory or device memory. If not defined explicitly, Kokkos uses the default
    memory space specified during Kokkos compilation as described [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces).
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，Kokkos 使用内存空间模型来处理不同类型的内存，例如主机内存或设备内存。如果没有明确定义，Kokkos 将使用在 Kokkos 编译期间指定的默认内存空间，具体描述请见[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/Machine-Model.html#kokkos-memory-spaces)。
- en: 'The following is an example of a Kokkos program that initializes Kokkos and
    prints the execution space and memory space instances:'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个初始化 Kokkos 并打印执行空间和内存空间实例的 Kokkos 程序示例：
- en: '[PRE149]'
  id: totrans-724
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: With Kokkos, the data can be accessed either through raw pointers or through
    Kokkos Views. With raw pointers, the memory allocation into the default memory
    space can be done using `Kokkos::kokkos_malloc(n * sizeof(int))`. Kokkos Views
    are a data type that provides a way to access data more efficiently in memory
    corresponding to a certain Kokkos memory space, such as host memory or device
    memory. A 1-dimensional view of type int* can be created by `Kokkos::View<int*>
    a("a", n)`, where `"a"` is a label, and `n` is the size of the allocation in the
    number of integers. Kokkos determines the optimal layout for the data at compile
    time for best overall performance as a function of the computer architecture.
    Furthermore, Kokkos handles the deallocation of such memory automatically. More
    details about Kokkos Views are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html).
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kokkos，数据可以通过原始指针或通过 Kokkos Views 访问。使用原始指针，可以将内存分配到默认内存空间，使用 `Kokkos::kokkos_malloc(n
    * sizeof(int))`。Kokkos Views 是一种数据类型，提供了一种更有效地访问与特定 Kokkos 内存空间（如主机内存或设备内存）对应的数据的方法。可以通过
    `Kokkos::View<int*> a("a", n)` 创建一个类型为 int* 的一维视图，其中 `"a"` 是标签，`n` 是以整数数量表示的分配大小。Kokkos
    在编译时确定数据的最佳布局，以获得最佳的整体性能，这取决于计算机架构。此外，Kokkos 会自动处理此类内存的释放。有关 Kokkos Views 的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/View.html)。
- en: 'Finally, Kokkos provides three different parallel operations: `parallel_for`,
    `parallel_reduce`, and `parallel_scan`. The `parallel_for` operation is used to
    execute a loop in parallel. The `parallel_reduce` operation is used to execute
    a loop in parallel and reduce the results to a single value. The `parallel_scan`
    operation implements a prefix scan. The usage of `parallel_for` and `parallel_reduce`
    are demonstrated in the examples later in this chapter. More detail about the
    parallel operations are found [HERE](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html).'
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Kokkos 提供了三种不同的并行操作：`parallel_for`、`parallel_reduce` 和 `parallel_scan`。`parallel_for`
    操作用于并行执行循环。`parallel_reduce` 操作用于并行执行循环并将结果归约到单个值。`parallel_scan` 操作实现了前缀扫描。`parallel_for`
    和 `parallel_reduce` 的用法将在本章后面的示例中演示。有关并行操作的更多详细信息，请参阅[这里](https://kokkos.org/kokkos-core-wiki/ProgrammingGuide/ParallelDispatch.html)。
- en: Run Kokkos hello.cpp example in simple steps
  id: totrans-727
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按简单步骤运行 Kokkos hello.cpp 示例
- en: The following should work on AMD VEGA90A devices straight out of the box (needs
    ROCm installation). On NVIDIA Volta V100 devices (needs CUDA installation), use
    the variables commented out on the Makefile.
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容在 AMD VEGA90A 设备上直接使用即可（需要 ROCm 安装）。在 NVIDIA Volta V100 设备上（需要 CUDA 安装），请使用
    Makefile 中的注释变量。
- en: '`git clone https://github.com/kokkos/kokkos.git`'
  id: totrans-729
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`git clone https://github.com/kokkos/kokkos.git`'
- en: Copy the above Makefile into the current folder (make sure the indentation of
    the last line is tab, and not space)
  id: totrans-730
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 Makefile 复制到当前文件夹中（确保最后一行的缩进是制表符，而不是空格）
- en: Copy the above hello.cpp file into the current folder
  id: totrans-731
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 hello.cpp 文件复制到当前文件夹
- en: '`make`'
  id: totrans-732
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`make`'
- en: '`./hello`'
  id: totrans-733
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`./hello`'
- en: OpenCL
  id: totrans-734
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCL
- en: OpenCL is a cross-platform, open-standard API for writing parallel programs
    that execute across heterogeneous platforms consisting of CPUs, GPUs, FPGAs and
    other devices. The first version of OpenCL (1.0) was released in December 2008,
    and the latest version of OpenCL (3.0) was released in September 2020\. OpenCL
    is supported by a number of vendors, including AMD, ARM, Intel, NVIDIA, and Qualcomm.
    It is a royalty-free standard, and the OpenCL specification is maintained by the
    Khronos Group. OpenCL provides a low-level programming interface initially based
    on C, but more recently also a C++ interface has become available.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL 是一个跨平台的开放标准 API，用于编写在由 CPU、GPU、FPGA 和其他设备组成的异构平台上执行的并行程序。OpenCL 的第一个版本（1.0）于
    2008 年 12 月发布，最新版本 OpenCL（3.0）于 2020 年 9 月发布。OpenCL 获得了包括 AMD、ARM、Intel、NVIDIA
    和 Qualcomm 在内的多个厂商的支持。它是一个免版税的标准，OpenCL 规范由 Khronos Group 维护。OpenCL 提供了一个基于 C
    的低级编程接口，但最近也提供了一种 C++ 接口。
- en: OpenCL compilation
  id: totrans-736
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL 编译
- en: 'OpenCL supports two modes for compiling the programs: online and offline. Online
    compilation occurs at runtime, when the host program calls a function to compile
    the source code. Online mode allows dynamic generation and loading of kernels,
    but may incur some overhead due to compilation time and possible errors. Offline
    compilation occurs before runtime, when the source code of a kernel is compiled
    into a binary format that can be loaded by the host program. This mode allows
    faster execution and better optimization of kernels, but may limit the portability
    of the program, because the binary can only run on the architectures it was compiled
    for.'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL支持两种编译程序的模式：在线和离线。在线编译发生在运行时，当主机程序调用一个函数来编译源代码时。在线模式允许动态生成和加载内核，但可能会因为编译时间和可能的错误而带来一些开销。离线编译发生在运行之前，当内核的源代码被编译成主机程序可以加载的二进制格式。这种模式允许内核更快地执行和更好的优化，但可能会限制程序的移植性，因为二进制只能在编译时指定的架构上运行。
- en: 'OpenCL comes bundled with several parallel programming ecosystems, such as
    NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such
    packages and setting up the environment, one may simply compile an OpenCL program
    by the commands such as `icx cl_devices.c -lOpenCL` (Intel oneAPI) or `nvcc cl_devices.c
    -lOpenCL` (NVIDIA CUDA), where `cl_devices.c` is the compiled file. Unlike most
    other programming models, OpenCL stores kernels as text and compiles them for
    the device in runtime (JIT-compilation), and thus does not require any special
    compiler support: one can compile the code using simply `gcc cl_devices.c -lOpenCL`
    (or `g++` when using C++ API), as long as the required libraries and headers are
    installed in a standard locations.'
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL附带了一些并行编程生态系统，例如NVIDIA CUDA和Intel oneAPI。例如，在成功安装此类包并设置环境后，可以通过如`icx cl_devices.c
    -lOpenCL`（Intel oneAPI）或`nvcc cl_devices.c -lOpenCL`（NVIDIA CUDA）等命令简单地编译OpenCL程序，其中`cl_devices.c`是编译后的文件。与大多数其他编程模型不同，OpenCL将内核存储为文本，并在运行时（即时编译）为设备编译，因此不需要任何特殊的编译器支持：只要将所需的库和头文件安装到标准位置，就可以使用`gcc
    cl_devices.c -lOpenCL`（或使用C++ API时使用`g++`）编译代码。
- en: 'The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the
    latter with some limitations. To compile a program, you can use the AMD compilers
    on a GPU partition:'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 安装在LUMI上的AMD编译器支持OpenCL C和C++ API，后者有一些限制。要编译程序，您可以在GPU分区上使用AMD编译器：
- en: '[PRE150]'
  id: totrans-740
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: OpenCL programming
  id: totrans-741
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL编程
- en: 'OpenCL programs consist of two parts: a host program that runs on the host
    device (usually a CPU) and one or more kernels that run on compute devices (such
    as GPUs). The host program is responsible for the tasks such as managing the devices
    for the selected platform, allocating memory objects, building and enqueueing
    kernels, and managing memory objects.'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL程序由两部分组成：一部分是运行在主机设备（通常为CPU）上的主机程序，另一部分是运行在计算设备（如GPU）上的一或多个内核。主机程序负责管理所选平台上的设备、分配内存对象、构建和排队内核以及管理内存对象等任务。
- en: The first steps when writing an OpenCL program are to initialize the OpenCL
    environment by selecting the platform and devices, creating a context or contexts
    associated with the selected device(s), and creating a command queue for each
    device. A simple example of selecting the default device, creating a context and
    a queue associated with the device is show below.
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 编写OpenCL程序的第一步是初始化OpenCL环境，通过选择平台和设备，创建与所选设备关联的上下文或上下文，并为每个设备创建一个命令队列。以下是一个选择默认设备、创建与设备关联的上下文和队列的简单示例。
- en: '[PRE151]'
  id: totrans-744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-745
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'OpenCL provides two main programming models to manage the memory hierarchy
    of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers
    are the traditional memory model of OpenCL, where the host and the devices have
    separate address spaces and the programmer has to explicitly specify the memory
    allocations and how and where the memory is accessed. This can be done with class
    `cl::Buffer` and functions such as `cl::CommandQueue::enqueueReadBuffer()`. Buffers
    are supported since early versions of OpenCL, and work well across different architectures.
    Buffers can also take advantage of device-specific memory features, such as constant
    or local memory.'
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL提供了两种主要的编程模型来管理主机和加速设备内存层次结构：缓冲区和共享虚拟内存（SVM）。缓冲区是OpenCL的传统内存模型，其中主机和设备拥有独立的地址空间，程序员必须显式指定内存分配以及如何以及在哪里访问内存。这可以通过`cl::Buffer`类和如`cl::CommandQueue::enqueueReadBuffer()`这样的函数来实现。缓冲区自OpenCL的早期版本起就得到了支持，并且在不同架构上都能良好工作。缓冲区还可以利用设备特定的内存特性，例如常量或局部内存。
- en: SVM is a newer memory model of OpenCL, introduced in version 2.0, where the
    host and the devices share a single virtual address space. Thus, the programmer
    can use the same pointers to access the data from host and devices simplifying
    the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained
    buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow
    using the same pointers across a host and devices, but they differ in their granularity
    and synchronization requirements for the memory regions. Furthermore, the support
    for SVM is not universal across all OpenCL platforms and devices, and for example,
    GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer.
    This level requires explicit synchronization for memory accesses from a host and
    devices (using functions such as `cl::CommandQueue::enqueueMapSVM()` and `cl::CommandQueue::enqueueUnmapSVM()`),
    making the usage of SVM less convenient. It is further noted that this is unlike
    the regular Unified Memory offered by CUDA, which is closer to the fine-grained
    system SVM level in OpenCL.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是OpenCL的一个较新的内存模型，自2.0版本引入，其中主机和设备共享一个单一的虚拟地址空间。因此，程序员可以使用相同的指针从主机和设备访问数据，从而简化编程工作。在OpenCL中，SVM有不同级别，如粗粒度缓冲区SVM、细粒度缓冲区SVM和细粒度系统SVM。所有级别都允许在主机和设备之间使用相同的指针，但它们在内存区域的粒度和同步要求上有所不同。此外，SVM的支持并不是所有OpenCL平台和设备都通用的，例如，NVIDIA
    V100和A100这样的GPU只支持粗粒度SVM缓冲区。这一级别需要显式同步从主机和设备对内存的访问（使用如`cl::CommandQueue::enqueueMapSVM()`和`cl::CommandQueue::enqueueUnmapSVM()`这样的函数），这使得SVM的使用不太方便。值得注意的是，这与CUDA提供的常规统一内存不同，CUDA更接近于OpenCL中的细粒度系统SVM级别。
- en: OpenCL uses a separate-source kernel model where the kernel code is often kept
    in separate files that may be compiled during runtime. The model allows the kernel
    source code to be passed as a string to the OpenCL driver after which the program
    object can be executed on a specific device. Although referred to as the separate-source
    kernel model, the kernels can still be defined as a string in the host program
    compilation units as well, which may be a more convenient approach in some cases.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL使用一个独立的内核源模型，其中内核代码通常保存在单独的文件中，这些文件可能在运行时进行编译。该模型允许内核源代码作为字符串传递给OpenCL驱动程序，之后程序对象可以在特定设备上执行。尽管被称为独立的内核源模型，但内核也可以在主机程序编译单元中以字符串的形式定义，这在某些情况下可能是一个更方便的方法。
- en: The online compilation with the separate-source kernel model has several advantages
    over the binary model, which requires offline compilation of kernels into device-specific
    binaries that can are loaded by the application at runtime. Online compilation
    preserves the portability and flexibility of OpenCL, as the same kernel source
    code can run on any supported device. Furthermore, dynamic optimization of kernels
    based on runtime information, such as input size, work-group size, or device capabilities,
    is possible. An example of an OpenCL kernel, defined by a string in the host compilation
    unit, and assigning the global thread index into a global device memory is shown
    below.
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 与需要离线编译内核到特定设备二进制的二进制模型相比，使用独立内核源模型的在线编译有几个优点。在线编译保留了OpenCL的可移植性和灵活性，因为相同的内核源代码可以在任何支持的设备上运行。此外，基于运行时信息（如输入大小、工作组大小或设备能力）的内核动态优化也是可能的。下面是一个OpenCL内核的示例，该内核在主机编译单元中以字符串形式定义，并将全局线程索引赋值到全局设备内存中。
- en: '[PRE153]'
  id: totrans-750
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'The above kernel named `dot` and stored in the string `kernel_source` can be
    set to build in the host code as follows:'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的名为`dot`并存储在字符串`kernel_source`中的内核可以设置为在主机代码中构建，如下所示：
- en: '[PRE154]'
  id: totrans-752
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-753
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: OpenCL compilation
  id: totrans-754
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL编译
- en: 'OpenCL supports two modes for compiling the programs: online and offline. Online
    compilation occurs at runtime, when the host program calls a function to compile
    the source code. Online mode allows dynamic generation and loading of kernels,
    but may incur some overhead due to compilation time and possible errors. Offline
    compilation occurs before runtime, when the source code of a kernel is compiled
    into a binary format that can be loaded by the host program. This mode allows
    faster execution and better optimization of kernels, but may limit the portability
    of the program, because the binary can only run on the architectures it was compiled
    for.'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL支持两种编译程序的模式：在线和离线。在线编译发生在运行时，当主机程序调用一个函数来编译源代码时。在线模式允许动态生成和加载内核，但可能因为编译时间和可能的错误而带来一些开销。离线编译发生在运行之前，当内核的源代码被编译成主机程序可以加载的二进制格式。这种模式允许内核更快地执行和更好的优化，但可能会限制程序的移植性，因为二进制只能在编译时指定的架构上运行。
- en: 'OpenCL comes bundled with several parallel programming ecosystems, such as
    NVIDIA CUDA and Intel oneAPI. For example, after successfully installing such
    packages and setting up the environment, one may simply compile an OpenCL program
    by the commands such as `icx cl_devices.c -lOpenCL` (Intel oneAPI) or `nvcc cl_devices.c
    -lOpenCL` (NVIDIA CUDA), where `cl_devices.c` is the compiled file. Unlike most
    other programming models, OpenCL stores kernels as text and compiles them for
    the device in runtime (JIT-compilation), and thus does not require any special
    compiler support: one can compile the code using simply `gcc cl_devices.c -lOpenCL`
    (or `g++` when using C++ API), as long as the required libraries and headers are
    installed in a standard locations.'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL附带了一些并行编程生态系统，例如NVIDIA CUDA和Intel oneAPI。例如，在成功安装这些包并设置环境后，可以通过如`icx cl_devices.c
    -lOpenCL`（Intel oneAPI）或`nvcc cl_devices.c -lOpenCL`（NVIDIA CUDA）这样的命令简单地编译一个OpenCL程序，其中`cl_devices.c`是编译后的文件。与大多数其他编程模型不同，OpenCL将内核存储为文本，并在运行时（即时编译）为设备编译，因此不需要任何特殊的编译器支持：只要所需的库和头文件安装在标准位置，就可以使用`gcc
    cl_devices.c -lOpenCL`（或使用C++ API时使用`g++`）来编译代码。
- en: 'The AMD compiler installed on LUMI supports both OpenCL C and C++ API, the
    latter with some limitations. To compile a program, you can use the AMD compilers
    on a GPU partition:'
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 安装在LUMI上的AMD编译器支持OpenCL C和C++ API，后者有一些限制。要编译程序，您可以使用GPU分区上的AMD编译器：
- en: '[PRE156]'
  id: totrans-758
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: OpenCL programming
  id: totrans-759
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCL编程
- en: 'OpenCL programs consist of two parts: a host program that runs on the host
    device (usually a CPU) and one or more kernels that run on compute devices (such
    as GPUs). The host program is responsible for the tasks such as managing the devices
    for the selected platform, allocating memory objects, building and enqueueing
    kernels, and managing memory objects.'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL程序由两部分组成：在主机设备（通常是CPU）上运行的宿主程序以及在一个或多个计算设备（如GPU）上运行的内核。宿主程序负责管理所选平台上的设备、分配内存对象、构建和排队内核以及管理内存对象。
- en: The first steps when writing an OpenCL program are to initialize the OpenCL
    environment by selecting the platform and devices, creating a context or contexts
    associated with the selected device(s), and creating a command queue for each
    device. A simple example of selecting the default device, creating a context and
    a queue associated with the device is show below.
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 编写OpenCL程序的第一步是初始化OpenCL环境，通过选择平台和设备，创建与所选设备关联的上下文或上下文，并为每个设备创建一个命令队列。以下是一个选择默认设备、创建与设备关联的上下文和队列的简单示例。
- en: '[PRE157]'
  id: totrans-762
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-763
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'OpenCL provides two main programming models to manage the memory hierarchy
    of host and accelerator devices: buffers and shared virtual memory (SVM). Buffers
    are the traditional memory model of OpenCL, where the host and the devices have
    separate address spaces and the programmer has to explicitly specify the memory
    allocations and how and where the memory is accessed. This can be done with class
    `cl::Buffer` and functions such as `cl::CommandQueue::enqueueReadBuffer()`. Buffers
    are supported since early versions of OpenCL, and work well across different architectures.
    Buffers can also take advantage of device-specific memory features, such as constant
    or local memory.'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL提供了两种主要的编程模型来管理主机和加速设备内存层次结构：缓冲区和共享虚拟内存（SVM）。缓冲区是OpenCL的传统内存模型，其中主机和设备拥有独立的地址空间，程序员必须显式指定内存分配以及如何以及在哪里访问内存。这可以通过`cl::Buffer`类和如`cl::CommandQueue::enqueueReadBuffer()`这样的函数来实现。缓冲区自OpenCL的早期版本起就得到了支持，并且在不同架构上都能良好工作。缓冲区还可以利用设备特定的内存特性，例如常量或局部内存。
- en: SVM is a newer memory model of OpenCL, introduced in version 2.0, where the
    host and the devices share a single virtual address space. Thus, the programmer
    can use the same pointers to access the data from host and devices simplifying
    the programming effort. In OpenCL, SVM comes in different levels such as coarse-grained
    buffer SVM, fine-grained buffer SVM, and fine-grained system SVM. All levels allow
    using the same pointers across a host and devices, but they differ in their granularity
    and synchronization requirements for the memory regions. Furthermore, the support
    for SVM is not universal across all OpenCL platforms and devices, and for example,
    GPUs such as NVIDIA V100 and A100 only support the coarse-grained SVM buffer.
    This level requires explicit synchronization for memory accesses from a host and
    devices (using functions such as `cl::CommandQueue::enqueueMapSVM()` and `cl::CommandQueue::enqueueUnmapSVM()`),
    making the usage of SVM less convenient. It is further noted that this is unlike
    the regular Unified Memory offered by CUDA, which is closer to the fine-grained
    system SVM level in OpenCL.
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是OpenCL的一个较新的内存模型，自2.0版本引入，其中主机和设备共享一个单一的虚拟地址空间。因此，程序员可以使用相同的指针从主机和设备访问数据，从而简化编程工作。在OpenCL中，SVM有不同级别，如粗粒度缓冲区SVM、细粒度缓冲区SVM和细粒度系统SVM。所有级别都允许在主机和设备之间使用相同的指针，但它们在内存区域的粒度和同步要求上有所不同。此外，SVM的支持并不是所有OpenCL平台和设备都通用的，例如，NVIDIA
    V100和A100这样的GPU只支持粗粒度SVM缓冲区。这一级别需要显式同步从主机和设备对内存的访问（使用如`cl::CommandQueue::enqueueMapSVM()`和`cl::CommandQueue::enqueueUnmapSVM()`这样的函数），这使得SVM的使用不太方便。值得注意的是，这与CUDA提供的常规统一内存不同，CUDA更接近于OpenCL中的细粒度系统SVM级别。
- en: OpenCL uses a separate-source kernel model where the kernel code is often kept
    in separate files that may be compiled during runtime. The model allows the kernel
    source code to be passed as a string to the OpenCL driver after which the program
    object can be executed on a specific device. Although referred to as the separate-source
    kernel model, the kernels can still be defined as a string in the host program
    compilation units as well, which may be a more convenient approach in some cases.
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL使用一个独立的内核源模型，其中内核代码通常保存在单独的文件中，这些文件可能在运行时进行编译。该模型允许内核源代码作为字符串传递给OpenCL驱动程序，之后程序对象可以在特定设备上执行。尽管被称为独立的内核源模型，但内核也可以在主机程序编译单元中以字符串的形式定义，这在某些情况下可能是一个更方便的方法。
- en: The online compilation with the separate-source kernel model has several advantages
    over the binary model, which requires offline compilation of kernels into device-specific
    binaries that can are loaded by the application at runtime. Online compilation
    preserves the portability and flexibility of OpenCL, as the same kernel source
    code can run on any supported device. Furthermore, dynamic optimization of kernels
    based on runtime information, such as input size, work-group size, or device capabilities,
    is possible. An example of an OpenCL kernel, defined by a string in the host compilation
    unit, and assigning the global thread index into a global device memory is shown
    below.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 与需要离线编译内核到特定设备二进制的二进制模型相比，使用独立内核源模型的在线编译有几个优点。在线编译保留了OpenCL的可移植性和灵活性，因为相同的内核源代码可以在任何支持的设备上运行。此外，基于运行时信息（如输入大小、工作组大小或设备能力）的内核动态优化也是可能的。下面是一个OpenCL内核的示例，该内核在主机编译单元中以字符串形式定义，并将全局线程索引赋值到全局设备内存中。
- en: '[PRE159]'
  id: totrans-768
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: 'The above kernel named `dot` and stored in the string `kernel_source` can be
    set to build in the host code as follows:'
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的名为 `dot` 的内核存储在字符串 `kernel_source` 中，可以设置为在主机代码中构建，如下所示：
- en: '[PRE160]'
  id: totrans-770
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-771
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: SYCL
  id: totrans-772
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SYCL
- en: '[SYCL](https://www.khronos.org/sycl/) is a royalty-free, open-standard C++
    programming model for multi-device programming. It provides a high-level, single-source
    programming model for heterogeneous systems, including GPUs. There are several
    implementations of the standard. For GPU programming, [Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    and [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/) (also known as
    hipSYCL) are the most popular for desktop and HPC GPUs; [ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    is a good choice for embedded devices. The same standard-compliant SYCL code should
    work with any implementation, but they are not binary-compatible.'
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: '[SYCL](https://www.khronos.org/sycl/) 是一个免版税、开放标准的 C++ 编程模型，用于多设备编程。它为异构系统提供了一种高级、单源编程模型，包括
    GPU。该标准有几个实现。对于 GPU 编程，[Intel oneAPI DPC++](https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html)
    和 [AdaptiveCpp](https://github.com/AdaptiveCpp/AdaptiveCpp/)（也称为 hipSYCL）是桌面和
    HPC GPU 中最受欢迎的；[ComputeCPP](https://developer.codeplay.com/products/computecpp/ce/home/)
    是嵌入式设备的良好选择。相同的标准兼容 SYCL 代码应该与任何实现兼容，但它们不是二进制兼容的。'
- en: The most recent version of the SYCL standard is SYCL 2020, and it is the version
    we will be using in this course.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: SYCL 标准的最新版本是 SYCL 2020，这是我们将在本课程中使用的版本。
- en: SYCL compilation
  id: totrans-775
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL 编译
- en: Intel oneAPI DPC++
  id: totrans-776
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Intel oneAPI DPC++
- en: For targeting Intel GPUs, it is enough to install [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html).
    Then, the compilation is as simple as `icpx -fsycl file.cpp`.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Intel GPU，只需安装 [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html)。然后，编译就像
    `icpx -fsycl file.cpp` 那么简单。
- en: 'It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI
    Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding
    [Codeplay oneAPI plugin](https://codeplay.com/solutions/oneapi/) must be installed.
    Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用 oneAPI 来支持 NVIDIA 和 AMD GPU。除了 oneAPI Base Toolkit 之外，还需要安装供应商提供的运行时（CUDA
    或 HIP）以及相应的 [Codeplay oneAPI 插件](https://codeplay.com/solutions/oneapi/)。然后，可以使用包含在
    oneAPI 中的 Intel LLVM 编译器编译代码：
- en: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` for targeting CUDA
    8.6 NVIDIA GPU,'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` 用于针对 CUDA 8.6 NVIDIA
    GPU，'
- en: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` for targeting GFX90a AMD GPU.'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` 用于针对 GFX90a AMD GPU。'
- en: AdaptiveCpp
  id: totrans-781
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AdaptiveCpp
- en: 'Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed
    first. Then `acpp` can be used for compiling the code, specifying the target devices.
    For example, here is how to compile the program supporting an AMD and an NVIDIA
    device:'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AdaptiveCpp 为 NVIDIA 或 AMD GPU 编程还需要首先安装 CUDA 或 HIP。然后可以使用 `acpp` 编译代码，指定目标设备。例如，以下是如何编译支持
    AMD 和 NVIDIA 设备的程序：
- en: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
- en: Using SYCL on LUMI
  id: totrans-784
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 LUMI 上使用 SYCL
- en: 'LUMI does not have a system-wide installation of any SYCL framework, but a
    recent AdaptiveCpp installation is available in CSC modules:'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI 没有安装任何全局的 SYCL 框架，但在 CSC 模块中有一个最近的 AdaptiveCpp 安装：
- en: '[PRE162]'
  id: totrans-786
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: The default compilation target is preset to MI250 GPUs, so to compile a single
    C++ file it is enough to call `acpp -O2 file.cpp`.
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的编译目标是预置为 MI250 GPU，因此要编译单个 C++ 文件，只需调用 `acpp -O2 file.cpp` 即可。
- en: 'When running applications built with AdaptiveCpp, one can often see the warning
    “dag_direct_scheduler: Detected a requirement that is neither of discard access
    mode”, reflecting the lack of an optimization hint when using buffer-accessor
    model. The warning is harmless and can be ignored.'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '当运行使用 AdaptiveCpp 构建的程序时，经常会看到警告“dag_direct_scheduler: Detected a requirement
    that is neither of discard access mode”，这反映了在使用缓冲区访问模型时缺少优化提示。警告是无害的，可以忽略。'
- en: SYCL programming
  id: totrans-789
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL 编程
- en: SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source
    model with kernel lambdas.
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，SYCL 与 OpenCL 类似，但像 Kokkos 一样使用单个源模型和内核 lambda。
- en: 'To submit a task to device, first a sycl::queue must be created, which is used
    as a way to manage the task scheduling and execution. In the simplest case, that’s
    all the initialization one needs:'
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 要将任务提交到设备，首先必须创建一个 sycl::queue，它用作管理任务调度和执行的方式。在最简单的情况下，这就是所需的全部初始化：
- en: '[PRE163]'
  id: totrans-792
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: 'If one wants more control, the device can be explicitly specified, or additional
    properties can be passed to a queue:'
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要更多控制，可以显式指定设备，或者向队列传递额外的属性：
- en: '[PRE164]'
  id: totrans-794
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: 'Memory management can be done in two different ways: *buffer-accessor* model
    and *unified shared memory* (USM). The choice of the memory management models
    also influences how the GPU tasks are synchronized.'
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理可以通过两种不同的方式完成：*缓冲区访问器*模型和*统一共享内存*（USM）。内存管理模型的选择也会影响GPU任务的同步方式。
- en: 'In the *buffer-accessor* model, a `sycl::buffer` objects are used to represent
    arrays of data. A buffer is not mapped to any single one memory space, and can
    be migrated between the GPU and the CPU memory transparently. The data in `sycl::buffer`
    cannot be read or written directly, an accessor must be created. `sycl::accessor`
    objects specify the location of data access (host or a certain GPU kernel) and
    the access mode (read-only, write-only, read-write). Such approach allows optimizing
    task scheduling by building a directed acyclic graph (DAG) of data dependencies:
    if kernel *A* creates a write-only accessor to a buffer, and then kernel *B* is
    submitted with a read-only accessor to the same buffer, and then a host-side read-only
    accessor is requested, then it can be deduced that *A* must complete before *B*
    is launched and also that the results must be copied to the host before the host
    task can proceed, but the host task can run in parallel with kernel *B*. Since
    the dependencies between tasks can be built automatically, by default SYCL uses
    *out-of-order queues*: when two tasks are submitted to the same `sycl::queue`,
    it is not guaranteed that the second one will launch only after the first one
    completes. When launching a kernel, accessors must be created:'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 在*缓冲区访问器*模型中，使用`sycl::buffer`对象来表示数据数组。缓冲区没有映射到任何单一内存空间，并且可以在GPU和CPU内存之间透明迁移。`sycl::buffer`中的数据不能直接读取或写入，必须创建访问器。`sycl::accessor`对象指定数据访问的位置（主机或某个GPU内核）以及访问模式（只读、只写、读写）。这种方法允许通过构建数据依赖的有向无环图（DAG）来优化任务调度：如果内核*A*创建了一个对缓冲区的只写访问器，然后内核*B*提交了一个对同一缓冲区的只读访问器，然后请求主机端的只读访问器，那么可以推断出*A*必须在*B*启动之前完成，并且结果必须在主机任务可以继续之前复制到主机，但主机任务可以与内核*B*并行运行。由于任务之间的依赖关系可以自动构建，因此默认情况下SYCL使用*乱序队列*：当两个任务提交到同一个`sycl::queue`时，不能保证第二个任务只有在第一个任务完成后才会启动。在启动内核时，必须创建访问器：
- en: '[PRE165]'
  id: totrans-797
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: Buffer-accessor model simplifies many aspects of heterogeneous programming and
    prevents many synchronization-related bugs, but it only allows very coarse control
    of data movement and kernel execution.
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区访问器模型简化了异构编程的许多方面，并防止了许多与同步相关的错误，但它只允许对数据移动和内核执行进行非常粗略的控制。
- en: 'The *USM* model is similar to how NVIDIA CUDA or AMD HIP manage memory. The
    programmer has to explicitly allocate the memory on the device (`sycl::malloc_device`),
    on the host (`sycl::malloc_host`), or in the shared memory space (`sycl::malloc_shared`).
    Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
    all USM allocations are shared: for example, a memory allocated by `sycl::malloc_device`
    cannot be accessed from the host. The allocation functions return memory pointers
    that can be used directly, without accessors. This means that the programmer have
    to ensure the correct synchronization between host and device tasks to avoid data
    races. With USM, it is often convenient to use *in-order queues* with USM, instead
    of the default *out-of-order* queues. More information on USM can be found in
    the [Section 4.8 of SYCL 2020 specification](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm).'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '*USM*模型类似于NVIDIA CUDA或AMD HIP管理内存的方式。程序员必须显式地在设备上（`sycl::malloc_device`）、在主机上（`sycl::malloc_host`）或在共享内存空间中（`sycl::malloc_shared`）分配内存。尽管名为统一共享内存，并且与OpenCL的SVM相似，但并非所有USM分配都是共享的：例如，由`sycl::malloc_device`分配的内存不能从主机访问。分配函数返回可以直接使用的内存指针，无需访问器。这意味着程序员必须确保主机和设备任务之间的正确同步，以避免数据竞争。使用USM时，通常更方便使用*顺序队列*而不是默认的*乱序队列*。有关USM的更多信息，请参阅[SYCL
    2020规范的第4.8节](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm)。'
- en: '[PRE166]'
  id: totrans-800
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: Exercise
  id: totrans-801
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Implement SAXPY in SYCL'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在SYCL中实现SAXPY
- en: In this exercise we would like to write (fill-in-the-blanks) a simple code doing
    SAXPY (vector addition).
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的代码，执行SAXPY（向量加法）。
- en: 'To compile and run the code interactively, first make an allocation and load
    the AdaptiveCpp module:'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，首先进行分配并加载AdaptiveCpp模块：
- en: '[PRE167]'
  id: totrans-805
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行一个简单的设备检测实用程序来检查是否有GPU可用（注意`srun`）：
- en: '[PRE168]'
  id: totrans-807
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE168]'
- en: If you have not done it already, clone the repository using `git clone https://github.com/ENCCS/gpu-programming.git`
    or **update it** using `git pull origin main`.
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还没有这样做，请使用`git clone https://github.com/ENCCS/gpu-programming.git`克隆仓库或使用`git
    pull origin main`更新它。
- en: 'Now, let’s look at the example code in `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp`:'
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看`content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp`中的示例代码：
- en: '[PRE169]'
  id: totrans-810
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: 'To compile and run the code, use the following command:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE170]'
  id: totrans-812
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: The code will not compile as-is! Your task is to fill in missing bits indicated
    by `TODO` comments. You can also test your understanding using the “Bonus questions”
    in the code.
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: 代码不能直接编译！你的任务是填写由`TODO`注释指示的缺失部分。你还可以通过代码中的“Bonus questions”测试你的理解。
- en: If you feel stuck, take a look at the `exercise-sycl-saxpy-solution.cpp` file.
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得卡住了，可以查看`exercise-sycl-saxpy-solution.cpp`文件。
- en: SYCL compilation
  id: totrans-815
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL编译
- en: Intel oneAPI DPC++
  id: totrans-816
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Intel oneAPI DPC++
- en: For targeting Intel GPUs, it is enough to install [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html).
    Then, the compilation is as simple as `icpx -fsycl file.cpp`.
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 对于针对Intel GPU，只需安装[Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html)。然后，编译就像`icpx
    -fsycl file.cpp`一样简单。
- en: 'It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI
    Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding
    [Codeplay oneAPI plugin](https://codeplay.com/solutions/oneapi/) must be installed.
    Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用oneAPI针对NVIDIA和AMD GPU。除了oneAPI Base Toolkit外，还需要安装供应商提供的运行时（CUDA或HIP）以及相应的[Codeplay
    oneAPI插件](https://codeplay.com/solutions/oneapi/)。然后，可以使用包含在oneAPI中的Intel LLVM编译器编译代码：
- en: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` for targeting CUDA
    8.6 NVIDIA GPU,'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp`用于针对CUDA 8.6 NVIDIA
    GPU，'
- en: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` for targeting GFX90a AMD GPU.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a`用于针对GFX90a AMD GPU。'
- en: AdaptiveCpp
  id: totrans-821
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AdaptiveCpp
- en: 'Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed
    first. Then `acpp` can be used for compiling the code, specifying the target devices.
    For example, here is how to compile the program supporting an AMD and an NVIDIA
    device:'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AdaptiveCpp针对NVIDIA或AMD GPU也需要首先安装CUDA或HIP。然后可以使用`acpp`编译代码，指定目标设备。例如，以下是编译支持AMD和NVIDIA设备的程序的方法：
- en: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
- en: Using SYCL on LUMI
  id: totrans-824
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用SYCL
- en: 'LUMI does not have a system-wide installation of any SYCL framework, but a
    recent AdaptiveCpp installation is available in CSC modules:'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI没有系统范围内安装任何SYCL框架，但最新的AdaptiveCpp安装可在CSC模块中找到：
- en: '[PRE171]'
  id: totrans-826
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: The default compilation target is preset to MI250 GPUs, so to compile a single
    C++ file it is enough to call `acpp -O2 file.cpp`.
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: 默认编译目标已预设为MI250 GPU，因此要编译单个C++文件，只需调用`acpp -O2 file.cpp`即可。
- en: 'When running applications built with AdaptiveCpp, one can often see the warning
    “dag_direct_scheduler: Detected a requirement that is neither of discard access
    mode”, reflecting the lack of an optimization hint when using buffer-accessor
    model. The warning is harmless and can be ignored.'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: '当运行使用AdaptiveCpp构建的应用程序时，经常会看到警告“dag_direct_scheduler: 检测到一个既不是丢弃访问模式也不是的要求”，这反映了在使用缓冲区访问模型时缺少优化提示。警告是无害的，可以忽略。'
- en: Intel oneAPI DPC++
  id: totrans-829
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Intel oneAPI DPC++
- en: For targeting Intel GPUs, it is enough to install [Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html).
    Then, the compilation is as simple as `icpx -fsycl file.cpp`.
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 对于针对Intel GPU，只需安装[Intel oneAPI Base Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html)。然后，编译就像`icpx
    -fsycl file.cpp`一样简单。
- en: 'It is also possible to use oneAPI for NVIDIA and AMD GPUs. In addition to oneAPI
    Base Toolkit, the vendor-provided runtime (CUDA or HIP) and the corresponding
    [Codeplay oneAPI plugin](https://codeplay.com/solutions/oneapi/) must be installed.
    Then, the code can be compiled using Intel LLVM compiler bundled with oneAPI:'
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用oneAPI针对NVIDIA和AMD GPU。除了oneAPI Base Toolkit外，还需要安装供应商提供的运行时（CUDA或HIP）以及相应的[Codeplay
    oneAPI插件](https://codeplay.com/solutions/oneapi/)。然后，可以使用包含在oneAPI中的Intel LLVM编译器编译代码：
- en: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp` for targeting CUDA
    8.6 NVIDIA GPU,'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=nvidia_gpu_sm_86 file.cpp`用于针对CUDA 8.6 NVIDIA
    GPU，'
- en: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a` for targeting GFX90a AMD GPU.'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clang++ -fsycl -fsycl-targets=amd_gpu_gfx90a`用于针对GFX90a AMD GPU。'
- en: AdaptiveCpp
  id: totrans-834
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AdaptiveCpp
- en: 'Using AdaptiveCpp for NVIDIA or AMD GPUs also requires having CUDA or HIP installed
    first. Then `acpp` can be used for compiling the code, specifying the target devices.
    For example, here is how to compile the program supporting an AMD and an NVIDIA
    device:'
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 在NVIDIA或AMD GPU上使用AdaptiveCpp也需要首先安装CUDA或HIP。然后可以使用`acpp`编译代码，指定目标设备。例如，以下是编译支持AMD和NVIDIA设备的程序的方法：
- en: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acpp --acpp-targets=''hip:gfx90a;cuda:sm_70'' file.cpp`'
- en: Using SYCL on LUMI
  id: totrans-837
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用SYCL
- en: 'LUMI does not have a system-wide installation of any SYCL framework, but a
    recent AdaptiveCpp installation is available in CSC modules:'
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI没有系统范围内安装任何SYCL框架，但CSC模块中有最新的AdaptiveCpp安装：
- en: '[PRE172]'
  id: totrans-839
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: The default compilation target is preset to MI250 GPUs, so to compile a single
    C++ file it is enough to call `acpp -O2 file.cpp`.
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 默认编译目标预设为MI250 GPU，因此要编译单个C++文件，只需要调用`acpp -O2 file.cpp`。
- en: 'When running applications built with AdaptiveCpp, one can often see the warning
    “dag_direct_scheduler: Detected a requirement that is neither of discard access
    mode”, reflecting the lack of an optimization hint when using buffer-accessor
    model. The warning is harmless and can be ignored.'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: '当运行使用AdaptiveCpp构建的应用程序时，经常会看到警告“dag_direct_scheduler: Detected a requirement
    that is neither of discard access mode”，这反映了在使用缓冲区访问器模型时缺少优化提示。警告是无害的，可以忽略。'
- en: SYCL programming
  id: totrans-842
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SYCL编程
- en: SYCL is, in many aspects, similar to OpenCL, but uses, like Kokkos, a single-source
    model with kernel lambdas.
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: SYCL在很多方面与OpenCL相似，但像Kokkos一样，使用单源模型和内核lambda。
- en: 'To submit a task to device, first a sycl::queue must be created, which is used
    as a way to manage the task scheduling and execution. In the simplest case, that’s
    all the initialization one needs:'
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: 要将任务提交到设备，首先必须创建一个`sycl::queue`，它被用作管理任务调度和执行的方式。在最简单的情况下，这就是所需的全部初始化：
- en: '[PRE173]'
  id: totrans-845
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: 'If one wants more control, the device can be explicitly specified, or additional
    properties can be passed to a queue:'
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: 如果想要更多控制，可以显式指定设备，或者可以向队列传递额外的属性：
- en: '[PRE174]'
  id: totrans-847
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: 'Memory management can be done in two different ways: *buffer-accessor* model
    and *unified shared memory* (USM). The choice of the memory management models
    also influences how the GPU tasks are synchronized.'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理可以通过两种不同的方式完成：*缓冲区访问器*模型和*统一共享内存*（USM）。内存管理模型的选择也影响GPU任务的同步。
- en: 'In the *buffer-accessor* model, a `sycl::buffer` objects are used to represent
    arrays of data. A buffer is not mapped to any single one memory space, and can
    be migrated between the GPU and the CPU memory transparently. The data in `sycl::buffer`
    cannot be read or written directly, an accessor must be created. `sycl::accessor`
    objects specify the location of data access (host or a certain GPU kernel) and
    the access mode (read-only, write-only, read-write). Such approach allows optimizing
    task scheduling by building a directed acyclic graph (DAG) of data dependencies:
    if kernel *A* creates a write-only accessor to a buffer, and then kernel *B* is
    submitted with a read-only accessor to the same buffer, and then a host-side read-only
    accessor is requested, then it can be deduced that *A* must complete before *B*
    is launched and also that the results must be copied to the host before the host
    task can proceed, but the host task can run in parallel with kernel *B*. Since
    the dependencies between tasks can be built automatically, by default SYCL uses
    *out-of-order queues*: when two tasks are submitted to the same `sycl::queue`,
    it is not guaranteed that the second one will launch only after the first one
    completes. When launching a kernel, accessors must be created:'
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: 在*缓冲区访问器*模型中，使用`sycl::buffer`对象来表示数据数组。缓冲区没有映射到任何单一内存空间，并且可以在GPU和CPU内存之间透明迁移。`sycl::buffer`中的数据不能直接读取或写入，必须创建访问器。`sycl::accessor`对象指定数据访问的位置（主机或某个GPU内核）和访问模式（只读、只写、读写）。这种方法通过构建数据依赖的有向无环图（DAG）来优化任务调度：如果内核*A*创建了一个对缓冲区的只写访问器，然后内核*B*提交了一个对同一缓冲区的只读访问器，然后请求主机端的只读访问器，那么可以推断出*A*必须在*B*启动之前完成，并且结果必须在主机任务可以继续之前复制到主机，但主机任务可以与内核*B*并行运行。由于任务之间的依赖关系可以自动构建，因此默认情况下SYCL使用*乱序队列*：当两个任务提交到同一个`sycl::queue`时，不能保证第二个任务只有在第一个任务完成后才会启动。在启动内核时，必须创建访问器：
- en: '[PRE175]'
  id: totrans-850
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: Buffer-accessor model simplifies many aspects of heterogeneous programming and
    prevents many synchronization-related bugs, but it only allows very coarse control
    of data movement and kernel execution.
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区访问模型简化了异构编程的许多方面，并防止了许多与同步相关的错误，但它只允许对数据移动和内核执行进行非常粗略的控制。
- en: 'The *USM* model is similar to how NVIDIA CUDA or AMD HIP manage memory. The
    programmer has to explicitly allocate the memory on the device (`sycl::malloc_device`),
    on the host (`sycl::malloc_host`), or in the shared memory space (`sycl::malloc_shared`).
    Despite its name, unified shared memory, and the similarity to OpenCL’s SVM, not
    all USM allocations are shared: for example, a memory allocated by `sycl::malloc_device`
    cannot be accessed from the host. The allocation functions return memory pointers
    that can be used directly, without accessors. This means that the programmer have
    to ensure the correct synchronization between host and device tasks to avoid data
    races. With USM, it is often convenient to use *in-order queues* with USM, instead
    of the default *out-of-order* queues. More information on USM can be found in
    the [Section 4.8 of SYCL 2020 specification](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm).'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: '*USM* 模型类似于 NVIDIA CUDA 或 AMD HIP 管理内存的方式。程序员必须显式地在设备上（`sycl::malloc_device`）、在主机上（`sycl::malloc_host`）或在共享内存空间中（`sycl::malloc_shared`）分配内存。尽管其名称为统一共享内存，并且与
    OpenCL 的 SVM 相似，但并非所有 USM 分配都是共享的：例如，由 `sycl::malloc_device` 分配的内存不能从主机访问。分配函数返回可以直接使用的内存指针，无需访问器。这意味着程序员必须确保主机和设备任务之间的正确同步，以避免数据竞争。使用
    USM 时，通常更方便使用 *顺序队列* 而不是默认的 *乱序队列*。有关 USM 的更多信息，请参阅 [SYCL 2020 规范的第 4.8 节](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html#sec:usm)。'
- en: '[PRE176]'
  id: totrans-853
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: Exercise
  id: totrans-854
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Implement SAXPY in SYCL'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：实现 SYCL 中的 SAXPY
- en: In this exercise we would like to write (fill-in-the-blanks) a simple code doing
    SAXPY (vector addition).
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的代码，执行 SAXPY（向量加法）。
- en: 'To compile and run the code interactively, first make an allocation and load
    the AdaptiveCpp module:'
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，首先进行分配并加载 AdaptiveCpp 模块：
- en: '[PRE177]'
  id: totrans-858
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行一个简单的设备检测实用程序来检查GPU是否可用（注意`srun`）：
- en: '[PRE178]'
  id: totrans-860
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE178]'
- en: If you have not done it already, clone the repository using `git clone https://github.com/ENCCS/gpu-programming.git`
    or **update it** using `git pull origin main`.
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有做，请使用 `git clone https://github.com/ENCCS/gpu-programming.git` 或 **使用
    `git pull origin main` 更新** 仓库。
- en: 'Now, let’s look at the example code in `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp`:'
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `content/examples/portable-kernel-models/exercise-sycl-saxpy.cpp` 中的示例代码：
- en: '[PRE179]'
  id: totrans-863
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: 'To compile and run the code, use the following command:'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE180]'
  id: totrans-865
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: The code will not compile as-is! Your task is to fill in missing bits indicated
    by `TODO` comments. You can also test your understanding using the “Bonus questions”
    in the code.
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: 代码不能直接编译！你的任务是填写由 `TODO` 注释指示的缺失部分。你也可以通过代码中的“附加问题”来测试你的理解。
- en: If you feel stuck, take a look at the `exercise-sycl-saxpy-solution.cpp` file.
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得卡住了，请查看 `exercise-sycl-saxpy-solution.cpp` 文件。
- en: alpaka
  id: totrans-868
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: alpaka
- en: The [alpaka](https://github.com/alpaka-group/alpaka3) library is an open-source
    header-only C++20 abstraction library for accelerator development.
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: '[alpaka](https://github.com/alpaka-group/alpaka3) 库是一个开源的仅头文件 C++20 抽象库，用于加速器开发。'
- en: Its aim is to provide performance portability across accelerators by abstracting
    the underlying levels of parallelism. The project provides a single-source C++
    API that enables developers to write parallel code once and run it on different
    hardware architectures without modification. The name “alpaka” comes from **A**bstractions
    for **L**evels of **P**arallelism, **A**lgorithms, and **K**ernels for **A**ccelerators.
    The library is platform-independent and supports the concurrent and cooperative
    use of multiple devices, including host CPUs (x86, ARM, and RISC-V) and GPUs from
    different vendors (NVIDIA, AMD, and Intel). A variety of accelerator backends,
    CUDA, HIP, SYCL, OpenMP, and serial execution, are available and can be selected
    based on the target device. Only a single implementation of a user kernel is required,
    expressed as a function object with a standardized interface. This eliminates
    the need to write specialized CUDA, HIP, SYCL, OpenMP, Intel TBB or threading
    code. Moreover, multiple accelerator backends can be combined to target different
    vendor hardware within a single system and even within a single application.
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: 其目的是通过抽象底层并行级别，在加速器之间提供性能可移植性。该项目提供了一个单源 C++ API，使开发者能够编写一次并行代码，并在不同的硬件架构上运行而无需修改。名称“alpaka”来源于**A**bstractions
    for **L**evels of **P**arallelism、**A**lgorithms 和 **K**ernels for **A**ccelerators。该库是平台无关的，并支持多个设备的并发和协作使用，包括主机
    CPU（x86、ARM 和 RISC-V）以及来自不同供应商的 GPU（NVIDIA、AMD 和 Intel）。提供了各种加速器后端，如 CUDA、HIP、SYCL、OpenMP
    和串行执行，可以根据目标设备进行选择。只需要一个用户内核的实现，以具有标准化接口的函数对象的形式表达。这消除了编写专门的 CUDA、HIP、SYCL、OpenMP、Intel
    TBB 或线程代码的需求。此外，可以将多个加速器后端组合起来，以针对单个系统甚至单个应用程序中的不同供应商硬件。
- en: The abstraction is based on a virtual index domain decomposed into equally sized
    chunks called frames. **alpaka** provides a uniform abstraction to traverse these
    frames, independent of the underlying hardware. Algorithms to be parallelized
    map the chunked index domain and native worker threads onto the data, expressing
    the computation as kernels that are executed in parallel threads (SIMT), thereby
    also leveraging SIMD units. Unlike native parallelism models such as CUDA, HIP,
    and SYCL, **alpaka** kernels are not restricted to three dimensions. Explicit
    caching of data within a frame via shared memory allows developers to fully unleash
    the performance of the compute device. Additionally, **alpaka** offers primitive
    functions such as iota, transform, transform-reduce, reduce, and concurrent, simplifying
    the development of portable high-performance applications. Host, device, mapped,
    and managed multi-dimensional views provide a natural way to operate on data.
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象基于一个虚拟索引域，该域被分解成大小相等的块，称为帧。**alpaka** 提供了一个统一的抽象来遍历这些帧，独立于底层硬件。要并行化的算法将分块索引域和本地工作线程映射到数据上，将计算表示为在并行线程（SIMT）中执行的内核，从而也利用了
    SIMD 单元。与 CUDA、HIP 和 SYCL 等原生并行模型不同，**alpaka** 内核不受三维的限制。通过共享内存显式缓存帧内的数据允许开发者充分发挥计算设备性能。此外，**alpaka**
    还提供了原始函数，如 iota、transform、transform-reduce、reduce 和 concurrent，简化了可移植高性能应用程序的开发。主机、设备、映射和管理多维视图提供了一种自然的数据操作方式。
- en: Here we demonstrate the usage of **alpaka3**, which is a complete rewrite of
    [alpaka](https://github.com/alpaka-group/alpaka). It is planned to merge this
    separate codebase back into the mainline alpaka repository before the first release
    in Q2/Q3 of 2026. Nevertheless, the code is well-tested and can be used for development
    today.
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们展示了 **alpaka3** 的用法，这是一个对 [alpaka](https://github.com/alpaka-group/alpaka)
    的完整重写。计划在 2026 年第二季度/第三季度首次发布之前，将这个独立的代码库合并回主线 alpaka 仓库。尽管如此，代码经过充分测试，可以用于今天的开发。
- en: Installing alpaka on your system
  id: totrans-873
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在您的系统上安装 alpaka
- en: For ease of use, we recommend installing alpaka using CMake as described below.
    For other ways to use alpaka in your projects, see the [alpaka3 documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html).
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们建议按照以下说明使用 CMake 安装 alpaka。有关在项目中使用 alpaka 的其他方法，请参阅 [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)。
- en: '**Clone the repository**'
  id: totrans-875
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**克隆仓库**'
- en: 'Clone the alpaka source code from GitHub to a directory of your choice:'
  id: totrans-876
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从 GitHub 克隆 alpaka 源代码到您选择的目录：
- en: '[PRE181]'
  id: totrans-877
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '**Set installation directory**'
  id: totrans-878
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置安装目录**'
- en: Set the `ALPAKA_DIR` environment variable to the directory where you want to
    install alpaka. This can be any directory you choose where you have write access.
  id: totrans-879
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 `ALPAKA_DIR` 环境变量设置为想要安装 alpaka 的目录。这可以是您选择的任何目录，只要您有写入权限。
- en: '[PRE182]'
  id: totrans-880
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '**Build and install**'
  id: totrans-881
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建和安装**'
- en: Create a build directory and use CMake to build and install alpaka. We use `CMAKE_INSTALL_PREFIX`
    to tell CMake where to install the library.
  id: totrans-882
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一个构建目录并使用 CMake 构建和安装 alpaka。我们使用 `CMAKE_INSTALL_PREFIX` 来告诉 CMake 将库安装在哪里。
- en: '[PRE183]'
  id: totrans-883
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '**Update environment**'
  id: totrans-884
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新环境**'
- en: 'To make sure that other projects can find your alpaka installation, you should
    add the installation directory to your `CMAKE_PREFIX_PATH`. You can do this by
    adding the following line to your shell configuration file (e.g. `~/.bashrc`):'
  id: totrans-885
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保其他项目可以找到您的 alpaka 安装，您应该将安装目录添加到您的 `CMAKE_PREFIX_PATH` 中。您可以通过将以下行添加到您的
    shell 配置文件（例如 `~/.bashrc`）来实现：
- en: '[PRE184]'
  id: totrans-886
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: You will need to source your shell configuration file or open a new terminal
    for the changes to take effect.
  id: totrans-887
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要源码您的 shell 配置文件或打开一个新的终端以使更改生效。
- en: alpaka Compilation
  id: totrans-888
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编译
- en: We recommend building your projects which use alpaka using CMake. A variety
    of strategies can be used to deal with building your application for a specific
    device or set of devices. Here we show a minimal way to get started, but this
    is by no means the only way to set up your projects. Please refer to the [alpaka3
    documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html) for
    alternative ways to use alpaka in your project, including a way to make your source
    code agnostic to the accelerator being targeted by defining a device specification
    in CMake.
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用 CMake 构建使用 alpaka 的项目。可以采用各种策略来处理为特定设备或设备集构建应用程序。这里我们展示了开始的最小方法，但这绝不是设置项目的唯一方法。请参阅
    [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)，了解在项目中使用
    alpaka 的替代方法，包括在 CMake 中定义设备规范以使源代码与目标加速器无关的方法。
- en: 'The following example demonstrates a `CMakeLists.txt` for a single-file project
    using alpaka3 (`main.cpp` which is presented in the section below):'
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个使用 alpaka3 的单文件项目的 `CMakeLists.txt`（以下部分中展示的 `main.cpp`）：
- en: '[PRE185]'
  id: totrans-891
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE185]'
- en: Using alpaka on LUMI
  id: totrans-892
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 LUMI 上使用 alpaka
- en: To load the environment for using the AMD GPUs on LUMI with HIP, one can use
    the following modules -
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载在 LUMI 上使用 HIP 的 AMD GPU 的环境，可以使用以下模块 -
- en: '[PRE186]'
  id: totrans-894
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: alpaka Programming
  id: totrans-895
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编程
- en: 'When starting with alpaka3, the first step is understanding the **device selection
    model**. Unlike frameworks that require explicit initialization calls, alpaka3
    uses a device specification to determine which backend and hardware to use. The
    device specification consists of two components:'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 alpaka3 开始时，第一步是理解 **设备选择模型**。与需要显式初始化调用的框架不同，alpaka3 使用设备规范来确定使用哪个后端和硬件。设备规范由两个组件组成：
- en: '**API**: The parallel programming interface (host, cuda, hip, oneApi)'
  id: totrans-897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**: 并行编程接口（主机、cuda、hip、oneApi）'
- en: '**Device Kind**: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)'
  id: totrans-898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备类型**: 硬件类型（cpu、nvidiaGpu、amdGpu、intelGpu）'
- en: Here we specify and use these at runtime to select and initialize devices. The
    device selection process is described in detail in the alpaka3 documentation.
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定并使用这些在运行时选择和初始化设备。设备选择过程在 alpaka3 文档中有详细描述。
- en: alpaka3 uses an **execution space model** to abstract parallel hardware details.
    A device selector is created using `alpaka::onHost::makeDeviceSelector(devSpec)`,
    which returns an object that can query available devices and create device instances
    for the selected backend.
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3 使用 **执行空间模型** 来抽象并行硬件细节。使用 `alpaka::onHost::makeDeviceSelector(devSpec)`
    创建一个设备选择器，它返回一个可以查询可用设备并为所选后端创建设备实例的对象。
- en: 'The following example demonstrates a basic alpaka program that initializes
    a device and prints information about it:'
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个基本的 alpaka 程序，该程序初始化一个设备并打印有关该设备的信息：
- en: '[PRE187]'
  id: totrans-902
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE187]'
- en: alpaka3 provides memory management abstractions through buffers and views. Memory
    can be allocated on host or device using `alpaka::allocBuf<T, Idx>(device, extent)`.
    Data transfers between host and device are handled through `alpaka::memcpy(queue,
    dst, src)`. The library automatically manages memory layouts for optimal performance
    on different architectures.
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3 通过缓冲区和视图提供内存管理抽象。可以使用 `alpaka::allocBuf<T, Idx>(device, extent)` 在主机或设备上分配内存。主机和设备之间的数据传输通过
    `alpaka::memcpy(queue, dst, src)` 处理。该库自动管理不同架构上的内存布局以实现最佳性能。
- en: For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined
    as functors or lambda functions and executed using work division specifications
    that define the parallelization strategy. The framework supports various parallel
    patterns including element-wise operations, reductions, and scans.
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行执行，alpaka3 提供了内核抽象。内核被定义为函数式对象或 lambda 函数，并使用定义并行化策略的工作划分规范来执行。该框架支持各种并行模式，包括逐元素操作、归约和扫描。
- en: Tour of **alpaka** Features
  id: totrans-905
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**alpaka** 功能概览'
- en: Now we will quickly explore the most commonly used features of alpaka and go
    over some basic usage. A quick reference of commonly used alpaka features is available
    [here.](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将快速探索 alpaka 最常用的功能，并简要介绍一些基本用法。常用 alpaka 功能的快速参考可在[此处](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)找到。
- en: '**General setup**: Include the consolidated header once and you are ready to
    start using alpaka.'
  id: totrans-907
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般设置**：包含一次综合头文件，您就可以开始使用 alpaka。'
- en: '[PRE188]'
  id: totrans-908
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '**Accelerator, platform, and device management**: Select devices by combining
    the desired API with the appropriate hardware kind using the device selector.'
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速器、平台和设备管理**：通过将所需的 API 与适当的硬件类型结合使用设备选择器来选择设备。'
- en: '[PRE189]'
  id: totrans-910
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '**Queues and events**: Create blocking or non-blocking queues per device, record
    events, and synchronize work as needed.'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: '**队列和事件**：为每个设备创建阻塞或非阻塞队列，记录事件，并根据需要同步工作。'
- en: '[PRE190]'
  id: totrans-912
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '**Memory management**: Allocate host, device, mapped, unified, or deferred
    buffers, create non-owning views, and move data portably with memcpy, memset,
    and fill.'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存管理**：分配主机、设备、映射、统一或延迟缓冲区，创建非拥有视图，并使用 memcpy、memset 和 fill 可移植地移动数据。'
- en: '[PRE191]'
  id: totrans-914
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '**Kernel execution**: Build a FrameSpec manually or request one tuned for your
    data type, then enqueue kernels with automatic or explicit executors.'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核执行**：手动构建 FrameSpec 或请求针对您数据类型优化的 FrameSpec，然后使用自动或显式执行器将内核入队。'
- en: '[PRE192]'
  id: totrans-916
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '**Kernel implementation**: Write kernels as functors annotated with ALPAKA_FN_ACC,
    use shared memory, synchronization, atomics, and math helpers directly inside
    the kernel body.'
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核实现**：将内核编写为带有 ALPAKA_FN_ACC 注解的函数式对象，在内核体内部直接使用共享内存、同步、原子操作和数学助手。'
- en: '[PRE193]'
  id: totrans-918
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: Run alpaka3 Example in Simple Steps
  id: totrans-919
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单步骤运行 alpaka3 示例
- en: The following example works on systems with CMake 3.25+ and an appropriate C++
    compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or
    oneAPI) is installed.
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于 CMake 3.25+ 和适当的 C++ 编译器。对于 GPU 执行，请确保已安装相应的运行时（CUDA、ROCm 或 oneAPI）。
- en: 'Create a directory for your project:'
  id: totrans-921
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的项目创建一个目录：
- en: '[PRE194]'
  id: totrans-922
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: Copy the CMakeLists.txt from above into the current folder
  id: totrans-923
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 CMakeLists.txt 复制到当前文件夹
- en: Copy the main.cpp file into the current folder
  id: totrans-924
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 main.cpp 文件复制到当前文件夹
- en: 'Configure and build:'
  id: totrans-925
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和构建：
- en: '[PRE195]'
  id: totrans-926
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: 'Run the executable:'
  id: totrans-927
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行可执行文件：
- en: '[PRE196]'
  id: totrans-928
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: Note
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The device specification system allows you to select the target device at CMake
    configuration time. The format is `"api:deviceKind"`, where:'
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: 设备规范系统允许您在 CMake 配置时选择目标设备。格式为 `"api:deviceKind"`，其中：
- en: '**api**: The parallel programming interface (`host`, `cuda`, `hip`, `oneApi`)'
  id: totrans-931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api**：并行编程接口（`host`、`cuda`、`hip`、`oneApi`）'
- en: '**deviceKind**: The type of device (`cpu`, `nvidiaGpu`, `amdGpu`, `intelGpu`)'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deviceKind**：设备类型（`cpu`、`nvidiaGpu`、`amdGpu`、`intelGpu`）'
- en: 'Available combinations are: `host:cpu`, `cuda:nvidiaGpu`, `hip:amdGpu`, `oneApi:cpu`,
    `oneApi:intelGpu`, `oneApi:nvidiaGpu`, `oneApi:amdGpu`'
  id: totrans-933
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的组合有：`host:cpu`、`cuda:nvidiaGpu`、`hip:amdGpu`、`oneApi:cpu`、`oneApi:intelGpu`、`oneApi:nvidiaGpu`、`oneApi:amdGpu`
- en: Warning
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI
    SDK are available respectively
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 CUDA SDK、HIP SDK 或 OneAPI SDK 分别可用时，CUDA、HIP 或 Intel 后端才有效。
- en: Expected output
  id: totrans-936
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预期输出
- en: '[PRE197]'
  id: totrans-937
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD
    MI250X”, or your CPU model).
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 设备名称将根据您的硬件而变化（例如，“NVIDIA A100”、“AMD MI250X”或您的 CPU 型号）。
- en: Compile and Execute Examples
  id: totrans-939
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译和执行示例
- en: You can test the **alpaka** provided examples from the [example section](#examples).
    The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
    To switch to CPU usage only you can simply replace `ap::onHost::makeDeviceSelector(ap::api::hip,
    ap::deviceKind::amdGpu);` with `ap::onHost::makeDeviceSelector(ap::api::host,
    ap::deviceKind::cpu);`
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[示例部分](#examples)测试 alpaka 提供的示例。这些示例已硬编码了在 LUMI 上所需的 AMD ROCm 平台的用法。要仅使用
    CPU，您只需将 `ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);`
    替换为 `ap::onHost::makeDeviceSelector(ap::api::host, ap::deviceKind::cpu);`
- en: The following steps assume you have downloaded alpaka already and the path to
    the **alapka** source code is stored in the environment variable `ALPAKA_DIR`.
    To test the example copy the code into a file `main.cpp`
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤假设您已经下载了 alpaka，并且 **alapka** 源代码的路径已存储在环境变量 `ALPAKA_DIR` 中。要测试示例，请将代码复制到文件
    `main.cpp`
- en: Alternatively, [click here](https://godbolt.org/z/69exnG4xb) to try the first
    example using in the godbolt compiler explorer.
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，[点击此处](https://godbolt.org/z/69exnG4xb) 尝试在 godbolt 编译器探索器中使用第一个示例。
- en: '[PRE198]'
  id: totrans-943
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-944
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-945
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '[PRE201]'
  id: totrans-946
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
- en: Note
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA Gpus 的 oneAPI Sycl，您必须安装相应的 Codeplay oneAPI 插件，具体说明请参阅[此处](https://codeplay.com/solutions/oneapi/plugins/)。
- en: '[PRE203]'
  id: totrans-950
  prefs: []
  type: TYPE_PRE
  zh: '[PRE203]'
- en: Note
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA Gpus 的 oneAPI Sycl，您必须安装相应的 Codeplay oneAPI 插件，具体说明请参阅[此处](https://codeplay.com/solutions/oneapi/plugins/)。
- en: '[PRE204]'
  id: totrans-953
  prefs: []
  type: TYPE_PRE
  zh: '[PRE204]'
- en: Exercise
  id: totrans-954
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Write a vector add kernel in alpaka'
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在 alpaka 中编写向量加法内核
- en: In this exercise we would like to write (fill-in-the-blanks) a simple kernel
    to add two vectors.
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的内核来添加两个向量。
- en: 'To compile and run the code interactively, first we first need to get an allocation
    on a GPU node and load the modules for alpaka:'
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 为了交互式地编译和运行代码，首先我们需要在 GPU 节点上获取一个分配并加载 alpaka 的模块：
- en: '[PRE205]'
  id: totrans-958
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以运行一个简单的设备检测实用程序来检查是否有 GPU 可用（注意 `srun`）：
- en: '[PRE206]'
  id: totrans-960
  prefs: []
  type: TYPE_PRE
  zh: '[PRE206]'
- en: 'Now, let’s look at the code to set up the exercise:'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看设置练习的代码：
- en: Below we use fetch content with our CMake to get started with alpaka quickly.
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们使用 CMake 的 fetch content 快速开始使用 alpaka。
- en: CMakeLists.txt
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: CMakeLists.txt
- en: '[PRE207]'
  id: totrans-964
  prefs: []
  type: TYPE_PRE
  zh: '[PRE207]'
- en: Below we have the main alpaka code doing a vector addition on device using a
    high level transform function
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们主要的 alpaka 代码，使用高级转换函数在设备上进行向量加法
- en: main.cpp
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: main.cpp
- en: '[PRE208]'
  id: totrans-967
  prefs: []
  type: TYPE_PRE
  zh: '[PRE208]'
- en: To set up our project, we create a folder and place our CMakeLists.txt and main.cpp
    in there.
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置我们的项目，我们创建一个文件夹，并将我们的 CMakeLists.txt 和 main.cpp 放在那里。
- en: '[PRE209]'
  id: totrans-969
  prefs: []
  type: TYPE_PRE
  zh: '[PRE209]'
- en: 'To compile and run the code, use the following commands:'
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE210]'
  id: totrans-971
  prefs: []
  type: TYPE_PRE
  zh: '[PRE210]'
- en: Now your task will be to write and launch your first alpaka kernel. This kernel
    will do the vector addition and we will use this instead of the transform helper.
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的任务将是编写和启动您的第一个 alpaka 内核。这个内核将执行向量加法，我们将使用这个而不是转换辅助函数。
- en: Writing the vector add kernel
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 编写向量加法内核
- en: '[PRE211]'
  id: totrans-974
  prefs: []
  type: TYPE_PRE
  zh: '[PRE211]'
- en: Installing alpaka on your system
  id: totrans-975
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在您的系统上安装 alpaka
- en: For ease of use, we recommend installing alpaka using CMake as described below.
    For other ways to use alpaka in your projects, see the [alpaka3 documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html).
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便使用，我们建议按照以下说明使用 CMake 安装 alpaka。有关在项目中使用 alpaka 的其他方法，请参阅 [alpaka3 文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)。
- en: '**Clone the repository**'
  id: totrans-977
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**克隆仓库**'
- en: 'Clone the alpaka source code from GitHub to a directory of your choice:'
  id: totrans-978
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 alpaka 源代码从 GitHub 克隆到您选择的目录：
- en: '[PRE212]'
  id: totrans-979
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '**Set installation directory**'
  id: totrans-980
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置安装目录**'
- en: Set the `ALPAKA_DIR` environment variable to the directory where you want to
    install alpaka. This can be any directory you choose where you have write access.
  id: totrans-981
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 `ALPAKA_DIR` 环境变量设置为要安装 alpaka 的目录。这可以是您选择的任何目录，您有写入权限。
- en: '[PRE213]'
  id: totrans-982
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '**Build and install**'
  id: totrans-983
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建和安装**'
- en: Create a build directory and use CMake to build and install alpaka. We use `CMAKE_INSTALL_PREFIX`
    to tell CMake where to install the library.
  id: totrans-984
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建一个构建目录，并使用 CMake 构建和安装 alpaka。我们使用 `CMAKE_INSTALL_PREFIX` 来告诉 CMake 将库安装在哪里。
- en: '[PRE214]'
  id: totrans-985
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '**Update environment**'
  id: totrans-986
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新环境**'
- en: 'To make sure that other projects can find your alpaka installation, you should
    add the installation directory to your `CMAKE_PREFIX_PATH`. You can do this by
    adding the following line to your shell configuration file (e.g. `~/.bashrc`):'
  id: totrans-987
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保其他项目可以找到您的 alpaka 安装，您应该将安装目录添加到您的 `CMAKE_PREFIX_PATH` 中。您可以通过将以下行添加到您的
    shell 配置文件（例如 `~/.bashrc`）来实现：
- en: '[PRE215]'
  id: totrans-988
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: You will need to source your shell configuration file or open a new terminal
    for the changes to take effect.
  id: totrans-989
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您需要源码您的 shell 配置文件或打开一个新的终端以使更改生效。
- en: alpaka Compilation
  id: totrans-990
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka 编译
- en: We recommend building your projects which use alpaka using CMake. A variety
    of strategies can be used to deal with building your application for a specific
    device or set of devices. Here we show a minimal way to get started, but this
    is by no means the only way to set up your projects. Please refer to the [alpaka3
    documentation](https://alpaka3.readthedocs.io/en/latest/basic/install.html) for
    alternative ways to use alpaka in your project, including a way to make your source
    code agnostic to the accelerator being targeted by defining a device specification
    in CMake.
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用CMake构建使用alpaka的项目。可以采用各种策略来处理为特定设备或设备集构建应用程序。这里我们展示了开始的最小方法，但这绝对不是设置项目的唯一方法。请参阅[alpaka3文档](https://alpaka3.readthedocs.io/en/latest/basic/install.html)，了解在项目中使用alpaka的替代方法，包括通过在CMake中定义设备规范来使源代码与目标加速器无关的方法。
- en: 'The following example demonstrates a `CMakeLists.txt` for a single-file project
    using alpaka3 (`main.cpp` which is presented in the section below):'
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个使用alpaka3的单文件项目的`CMakeLists.txt`（以下章节中展示的`main.cpp`）：
- en: '[PRE216]'
  id: totrans-993
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE216]'
- en: Using alpaka on LUMI
  id: totrans-994
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用alpaka
- en: To load the environment for using the AMD GPUs on LUMI with HIP, one can use
    the following modules -
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载在LUMI上使用AMD GPU的HIP环境，可以使用以下模块 -
- en: '[PRE217]'
  id: totrans-996
  prefs: []
  type: TYPE_PRE
  zh: '[PRE217]'
- en: Using alpaka on LUMI
  id: totrans-997
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在LUMI上使用alpaka
- en: To load the environment for using the AMD GPUs on LUMI with HIP, one can use
    the following modules -
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载在LUMI上使用AMD GPU的HIP环境，可以使用以下模块 -
- en: '[PRE218]'
  id: totrans-999
  prefs: []
  type: TYPE_PRE
  zh: '[PRE218]'
- en: alpaka Programming
  id: totrans-1000
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: alpaka编程
- en: 'When starting with alpaka3, the first step is understanding the **device selection
    model**. Unlike frameworks that require explicit initialization calls, alpaka3
    uses a device specification to determine which backend and hardware to use. The
    device specification consists of two components:'
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: 当从alpaka3开始时，第一步是理解**设备选择模型**。与需要显式初始化调用的框架不同，alpaka3使用设备规范来确定使用哪个后端和硬件。设备规范由两个组件组成：
- en: '**API**: The parallel programming interface (host, cuda, hip, oneApi)'
  id: totrans-1002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**: 并行编程接口（host、cuda、hip、oneApi）'
- en: '**Device Kind**: The type of hardware (cpu, nvidiaGpu, amdGpu, intelGpu)'
  id: totrans-1003
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备类型**: 硬件类型（cpu、nvidiaGpu、amdGpu、intelGpu）'
- en: Here we specify and use these at runtime to select and initialize devices. The
    device selection process is described in detail in the alpaka3 documentation.
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定并使用这些内容在运行时选择和初始化设备。设备选择过程在alpaka3文档中有详细描述。
- en: alpaka3 uses an **execution space model** to abstract parallel hardware details.
    A device selector is created using `alpaka::onHost::makeDeviceSelector(devSpec)`,
    which returns an object that can query available devices and create device instances
    for the selected backend.
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3使用**执行空间模型**来抽象并行硬件细节。使用`alpaka::onHost::makeDeviceSelector(devSpec)`创建设备选择器，它返回一个可以查询可用设备并为所选后端创建设备实例的对象。
- en: 'The following example demonstrates a basic alpaka program that initializes
    a device and prints information about it:'
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了一个基本的alpaka程序，该程序初始化一个设备并打印有关该设备的信息：
- en: '[PRE219]'
  id: totrans-1007
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE219]'
- en: alpaka3 provides memory management abstractions through buffers and views. Memory
    can be allocated on host or device using `alpaka::allocBuf<T, Idx>(device, extent)`.
    Data transfers between host and device are handled through `alpaka::memcpy(queue,
    dst, src)`. The library automatically manages memory layouts for optimal performance
    on different architectures.
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: alpaka3通过缓冲区和视图提供内存管理抽象。可以使用`alpaka::allocBuf<T, Idx>(device, extent)`在主机或设备上分配内存。主机和设备之间的数据传输通过`alpaka::memcpy(queue,
    dst, src)`处理。库自动管理不同架构上的内存布局以实现最佳性能。
- en: For parallel execution, alpaka3 provides kernel abstractions. Kernels are defined
    as functors or lambda functions and executed using work division specifications
    that define the parallelization strategy. The framework supports various parallel
    patterns including element-wise operations, reductions, and scans.
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行执行，alpaka3提供内核抽象。内核被定义为函数式对象或lambda函数，并使用定义并行化策略的工作划分规范来执行。该框架支持各种并行模式，包括逐元素操作、归约和扫描。
- en: Tour of **alpaka** Features
  id: totrans-1010
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**alpaka**功能概览'
- en: Now we will quickly explore the most commonly used features of alpaka and go
    over some basic usage. A quick reference of commonly used alpaka features is available
    [here.](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将快速探索alpaka最常用的功能，并简要介绍一些基本用法。常用alpaka功能的快速参考可在[这里](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)找到。
- en: '**General setup**: Include the consolidated header once and you are ready to
    start using alpaka.'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用设置**: 一次性包含综合头文件，然后即可开始使用alpaka。'
- en: '[PRE220]'
  id: totrans-1013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '**Accelerator, platform, and device management**: Select devices by combining
    the desired API with the appropriate hardware kind using the device selector.'
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速器、平台和设备管理**：通过使用设备选择器将所需的 API 与适当的硬件类型组合来选择设备。'
- en: '[PRE221]'
  id: totrans-1015
  prefs: []
  type: TYPE_PRE
  zh: '[PRE221]'
- en: '**Queues and events**: Create blocking or non-blocking queues per device, record
    events, and synchronize work as needed.'
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: '**队列和事件**：为每个设备创建阻塞或非阻塞队列，记录事件，并在需要时同步工作。'
- en: '[PRE222]'
  id: totrans-1017
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: '**Memory management**: Allocate host, device, mapped, unified, or deferred
    buffers, create non-owning views, and move data portably with memcpy, memset,
    and fill.'
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存管理**：分配主机、设备、映射、统一或延迟缓冲区，创建非拥有视图，并使用 memcpy、memset 和 fill 可移植地移动数据。'
- en: '[PRE223]'
  id: totrans-1019
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '**Kernel execution**: Build a FrameSpec manually or request one tuned for your
    data type, then enqueue kernels with automatic or explicit executors.'
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核执行**：手动构建 FrameSpec 或请求针对您的数据类型调优的 FrameSpec，然后使用自动或显式执行器将内核入队。'
- en: '[PRE224]'
  id: totrans-1021
  prefs: []
  type: TYPE_PRE
  zh: '[PRE224]'
- en: '**Kernel implementation**: Write kernels as functors annotated with ALPAKA_FN_ACC,
    use shared memory, synchronization, atomics, and math helpers directly inside
    the kernel body.'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核实现**：将内核编写为带有 ALPAKA_FN_ACC 注解的函数式对象，在内核体内部直接使用共享内存、同步、原子操作和数学助手。'
- en: '[PRE225]'
  id: totrans-1023
  prefs: []
  type: TYPE_PRE
  zh: '[PRE225]'
- en: Run alpaka3 Example in Simple Steps
  id: totrans-1024
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单步骤运行 alpaka3 示例
- en: The following example works on systems with CMake 3.25+ and an appropriate C++
    compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or
    oneAPI) is installed.
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于 CMake 3.25+ 及适当的 C++ 编译器。对于 GPU 执行，请确保已安装相应的运行时（CUDA、ROCm 或 oneAPI）。
- en: 'Create a directory for your project:'
  id: totrans-1026
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的项目创建一个目录：
- en: '[PRE226]'
  id: totrans-1027
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: Copy the CMakeLists.txt from above into the current folder
  id: totrans-1028
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 CMakeLists.txt 复制到当前文件夹
- en: Copy the main.cpp file into the current folder
  id: totrans-1029
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 main.cpp 文件复制到当前文件夹
- en: 'Configure and build:'
  id: totrans-1030
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和构建：
- en: '[PRE227]'
  id: totrans-1031
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: 'Run the executable:'
  id: totrans-1032
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行可执行文件：
- en: '[PRE228]'
  id: totrans-1033
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: Note
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The device specification system allows you to select the target device at CMake
    configuration time. The format is `"api:deviceKind"`, where:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 设备规范系统允许你在 CMake 配置时间选择目标设备。格式为 `"api:deviceKind"`，其中：
- en: '**api**: The parallel programming interface (`host`, `cuda`, `hip`, `oneApi`)'
  id: totrans-1036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api**：并行编程接口（`host`、`cuda`、`hip`、`oneApi`）'
- en: '**deviceKind**: The type of device (`cpu`, `nvidiaGpu`, `amdGpu`, `intelGpu`)'
  id: totrans-1037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deviceKind**：设备类型（`cpu`、`nvidiaGpu`、`amdGpu`、`intelGpu`）'
- en: 'Available combinations are: `host:cpu`, `cuda:nvidiaGpu`, `hip:amdGpu`, `oneApi:cpu`,
    `oneApi:intelGpu`, `oneApi:nvidiaGpu`, `oneApi:amdGpu`'
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的组合有：`host:cpu`、`cuda:nvidiaGpu`、`hip:amdGpu`、`oneApi:cpu`、`oneApi:intelGpu`、`oneApi:nvidiaGpu`、`oneApi:amdGpu`
- en: Warning
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI
    SDK are available respectively
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 CUDA SDK、HIP SDK 或 OneAPI SDK 分别可用时，CUDA、HIP 或 Intel 后端才有效。
- en: Expected output
  id: totrans-1041
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预期输出
- en: '[PRE229]'
  id: totrans-1042
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD
    MI250X”, or your CPU model).
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: 设备名称将根据您的硬件而变化（例如，“NVIDIA A100”、“AMD MI250X”或您的 CPU 型号）。
- en: Tour of **alpaka** Features
  id: totrans-1044
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**alpaka** 功能巡礼'
- en: Now we will quickly explore the most commonly used features of alpaka and go
    over some basic usage. A quick reference of commonly used alpaka features is available
    [here.](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将快速探索 alpaka 最常用的功能，并简要介绍一些基本用法。常用的 alpaka 功能快速参考可在[这里](https://alpaka3.readthedocs.io/en/latest/basic/cheatsheet.html)找到。
- en: '**General setup**: Include the consolidated header once and you are ready to
    start using alpaka.'
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用设置**：包含一次综合头文件，您就可以开始使用 alpaka 了。'
- en: '[PRE230]'
  id: totrans-1047
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: '**Accelerator, platform, and device management**: Select devices by combining
    the desired API with the appropriate hardware kind using the device selector.'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速器、平台和设备管理**：通过使用设备选择器将所需的 API 与适当的硬件类型组合来选择设备。'
- en: '[PRE231]'
  id: totrans-1049
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: '**Queues and events**: Create blocking or non-blocking queues per device, record
    events, and synchronize work as needed.'
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: '**队列和事件**：为每个设备创建阻塞或非阻塞队列，记录事件，并在需要时同步工作。'
- en: '[PRE232]'
  id: totrans-1051
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: '**Memory management**: Allocate host, device, mapped, unified, or deferred
    buffers, create non-owning views, and move data portably with memcpy, memset,
    and fill.'
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存管理**：分配主机、设备、映射、统一或延迟缓冲区，创建非拥有视图，并使用 memcpy、memset 和 fill 可移植地移动数据。'
- en: '[PRE233]'
  id: totrans-1053
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: '**Kernel execution**: Build a FrameSpec manually or request one tuned for your
    data type, then enqueue kernels with automatic or explicit executors.'
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核执行**：手动构建 FrameSpec 或请求针对您的数据类型调优的 FrameSpec，然后使用自动或显式执行器将内核入队。'
- en: '[PRE234]'
  id: totrans-1055
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: '**Kernel implementation**: Write kernels as functors annotated with ALPAKA_FN_ACC,
    use shared memory, synchronization, atomics, and math helpers directly inside
    the kernel body.'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核实现**：将内核编写为带有 ALPAKA_FN_ACC 注解的函数式对象，在内核体内部直接使用共享内存、同步、原子操作和数学助手。'
- en: '[PRE235]'
  id: totrans-1057
  prefs: []
  type: TYPE_PRE
  zh: '[PRE235]'
- en: Run alpaka3 Example in Simple Steps
  id: totrans-1058
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单步骤运行 alpaka3 示例
- en: The following example works on systems with CMake 3.25+ and an appropriate C++
    compiler. For GPU execution, ensure the corresponding runtime (CUDA, ROCm, or
    oneAPI) is installed.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于 CMake 3.25+ 和适当的 C++ 编译器。对于 GPU 执行，请确保已安装相应的运行时（CUDA、ROCm 或 oneAPI）。
- en: 'Create a directory for your project:'
  id: totrans-1060
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的项目创建一个目录：
- en: '[PRE236]'
  id: totrans-1061
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: Copy the CMakeLists.txt from above into the current folder
  id: totrans-1062
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上面的 CMakeLists.txt 复制到当前文件夹
- en: Copy the main.cpp file into the current folder
  id: totrans-1063
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 main.cpp 文件复制到当前文件夹
- en: 'Configure and build:'
  id: totrans-1064
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和构建：
- en: '[PRE237]'
  id: totrans-1065
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE237]'
- en: 'Run the executable:'
  id: totrans-1066
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行可执行文件：
- en: '[PRE238]'
  id: totrans-1067
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE238]'
- en: Note
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The device specification system allows you to select the target device at CMake
    configuration time. The format is `"api:deviceKind"`, where:'
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: 设备指定系统允许您在 CMake 配置时选择目标设备。格式为 `"api:deviceKind"`，其中：
- en: '**api**: The parallel programming interface (`host`, `cuda`, `hip`, `oneApi`)'
  id: totrans-1070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api**：并行编程接口（`host`、`cuda`、`hip`、`oneApi`）'
- en: '**deviceKind**: The type of device (`cpu`, `nvidiaGpu`, `amdGpu`, `intelGpu`)'
  id: totrans-1071
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**deviceKind**：设备类型（`cpu`、`nvidiaGpu`、`amdGpu`、`intelGpu`）'
- en: 'Available combinations are: `host:cpu`, `cuda:nvidiaGpu`, `hip:amdGpu`, `oneApi:cpu`,
    `oneApi:intelGpu`, `oneApi:nvidiaGpu`, `oneApi:amdGpu`'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的组合有：`host:cpu`、`cuda:nvidiaGpu`、`hip:amdGpu`、`oneApi:cpu`、`oneApi:intelGpu`、`oneApi:nvidiaGpu`、`oneApi:amdGpu`
- en: Warning
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: The CUDA, HIP, or Intel backends only work if the CUDA SDK, HIP SDK, or OneAPI
    SDK are available respectively
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 CUDA SDK、HIP SDK 或 OneAPI SDK 可用时，CUDA、HIP 或 Intel 后端才有效
- en: Expected output
  id: totrans-1075
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预期输出
- en: '[PRE239]'
  id: totrans-1076
  prefs: []
  type: TYPE_PRE
  zh: '[PRE239]'
- en: The device name will vary depending on your hardware (e.g., “NVIDIA A100”, “AMD
    MI250X”, or your CPU model).
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: 设备名称将根据您的硬件而有所不同（例如，“NVIDIA A100”，“AMD MI250X”或您的 CPU 型号）。
- en: Compile and Execute Examples
  id: totrans-1078
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编译和执行示例
- en: You can test the **alpaka** provided examples from the [example section](#examples).
    The examples have hard coded the usage of the AMD ROCm platform required on LUMI.
    To switch to CPU usage only you can simply replace `ap::onHost::makeDeviceSelector(ap::api::hip,
    ap::deviceKind::amdGpu);` with `ap::onHost::makeDeviceSelector(ap::api::host,
    ap::deviceKind::cpu);`
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[示例部分](#examples)测试提供的 **alpaka** 示例。这些示例已硬编码了在 LUMI 上所需的 AMD ROCm 平台的用法。要仅使用
    CPU，您只需将 `ap::onHost::makeDeviceSelector(ap::api::hip, ap::deviceKind::amdGpu);`
    替换为 `ap::onHost::makeDeviceSelector(ap::api::host, ap::deviceKind::cpu);`
- en: The following steps assume you have downloaded alpaka already and the path to
    the **alapka** source code is stored in the environment variable `ALPAKA_DIR`.
    To test the example copy the code into a file `main.cpp`
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤假设您已经下载了 alpaka，并且 **alapka** 源代码的路径已存储在环境变量 `ALPAKA_DIR` 中。要测试示例，请将代码复制到文件
    `main.cpp`
- en: Alternatively, [click here](https://godbolt.org/z/69exnG4xb) to try the first
    example using in the godbolt compiler explorer.
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，[点击此处](https://godbolt.org/z/69exnG4xb) 尝试使用 godbolt 编译器探索器中的第一个示例。
- en: '[PRE240]'
  id: totrans-1082
  prefs: []
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[PRE241]'
  id: totrans-1083
  prefs: []
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-1084
  prefs: []
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-1085
  prefs: []
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-1086
  prefs: []
  type: TYPE_PRE
  zh: '[PRE244]'
- en: Note
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA GPU 的 oneAPI Sycl，你必须安装相应的 Codeplay oneAPI 插件，具体说明[在此](https://codeplay.com/solutions/oneapi/plugins/)。
- en: '[PRE245]'
  id: totrans-1089
  prefs: []
  type: TYPE_PRE
  zh: '[PRE245]'
- en: Note
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To use oneAPI Sycl with AMD or NVIDIA Gpus you must install the corresponding
    Codeplay oneAPI plugin as described [here](https://codeplay.com/solutions/oneapi/plugins/).
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AMD 或 NVIDIA GPU 的 oneAPI Sycl，你必须安装相应的 Codeplay oneAPI 插件，具体说明[在此](https://codeplay.com/solutions/oneapi/plugins/)。
- en: '[PRE246]'
  id: totrans-1092
  prefs: []
  type: TYPE_PRE
  zh: '[PRE246]'
- en: Exercise
  id: totrans-1093
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: 'Exercise: Write a vector add kernel in alpaka'
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：在 alpaka 中编写向量加法内核
- en: In this exercise we would like to write (fill-in-the-blanks) a simple kernel
    to add two vectors.
  id: totrans-1095
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们希望编写（填空）一个简单的内核来添加两个向量。
- en: 'To compile and run the code interactively, first we first need to get an allocation
    on a GPU node and load the modules for alpaka:'
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: 要交互式地编译和运行代码，我们首先需要在一个 GPU 节点上获取一个分配并加载 alpaka 的模块：
- en: '[PRE247]'
  id: totrans-1097
  prefs: []
  type: TYPE_PRE
  zh: '[PRE247]'
- en: 'Now you can run a simple device-detection utility to check that a GPU is available
    (note `srun`):'
  id: totrans-1098
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以运行一个简单的设备检测工具来检查是否有 GPU 可用（注意 `srun`）：
- en: '[PRE248]'
  id: totrans-1099
  prefs: []
  type: TYPE_PRE
  zh: '[PRE248]'
- en: 'Now, let’s look at the code to set up the exercise:'
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看设置练习的代码：
- en: Below we use fetch content with our CMake to get started with alpaka quickly.
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们使用 CMake 的 fetch content 快速开始使用 alpaka。
- en: CMakeLists.txt
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: CMakeLists.txt
- en: '[PRE249]'
  id: totrans-1103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE249]'
- en: Below we have the main alpaka code doing a vector addition on device using a
    high level transform function
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们使用高级转换函数在设备上执行向量加法的主要 alpaka 代码
- en: main.cpp
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: main.cpp
- en: '[PRE250]'
  id: totrans-1106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE250]'
- en: To set up our project, we create a folder and place our CMakeLists.txt and main.cpp
    in there.
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置我们的项目，我们创建一个文件夹，并将我们的 CMakeLists.txt 和 main.cpp 放在那里。
- en: '[PRE251]'
  id: totrans-1108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE251]'
- en: 'To compile and run the code, use the following commands:'
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: 要编译和运行代码，请使用以下命令：
- en: '[PRE252]'
  id: totrans-1110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE252]'
- en: Now your task will be to write and launch your first alpaka kernel. This kernel
    will do the vector addition and we will use this instead of the transform helper.
  id: totrans-1111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务是编写和启动你的第一个alpaka内核。这个内核将执行向量加法，我们将使用这个代替transform辅助器。
- en: Writing the vector add kernel
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: 编写向量加法内核。
- en: '[PRE253]'
  id: totrans-1113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE253]'
- en: Examples
  id: totrans-1114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例。
- en: Parallel for with Unified Memory
  id: totrans-1115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带统一内存的并行for循环。
- en: '[PRE254]'
  id: totrans-1116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE254]'
- en: '[PRE255]'
  id: totrans-1117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-1118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-1119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE257]'
- en: '[PRE258]'
  id: totrans-1120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE258]'
- en: '[PRE259]'
  id: totrans-1121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE259]'
- en: Parallel for with GPU buffers
  id: totrans-1122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带GPU缓冲区的并行for循环。
- en: '[PRE260]'
  id: totrans-1123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-1124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-1125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-1126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE263]'
- en: '[PRE264]'
  id: totrans-1127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE264]'
- en: Asynchronous parallel for kernels
  id: totrans-1128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步并行内核。
- en: '[PRE265]'
  id: totrans-1129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE265]'
- en: '[PRE266]'
  id: totrans-1130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE266]'
- en: '[PRE267]'
  id: totrans-1131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE267]'
- en: '[PRE268]'
  id: totrans-1132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE268]'
- en: '[PRE269]'
  id: totrans-1133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE269]'
- en: Reduction
  id: totrans-1134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚合操作。
- en: '[PRE270]'
  id: totrans-1135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-1136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-1137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[PRE273]'
  id: totrans-1138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-1139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE274]'
- en: Parallel for with Unified Memory
  id: totrans-1140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带统一内存的并行for循环。
- en: '[PRE275]'
  id: totrans-1141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-1142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-1143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-1144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-1145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '[PRE280]'
  id: totrans-1146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE280]'
- en: Parallel for with GPU buffers
  id: totrans-1147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带GPU缓冲区的并行for循环。
- en: '[PRE281]'
  id: totrans-1148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-1149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-1150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE283]'
- en: '[PRE284]'
  id: totrans-1151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-1152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE285]'
- en: Asynchronous parallel for kernels
  id: totrans-1153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步并行内核。
- en: '[PRE286]'
  id: totrans-1154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE286]'
- en: '[PRE287]'
  id: totrans-1155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-1156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-1157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-1158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE290]'
- en: Reduction
  id: totrans-1159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚合操作。
- en: '[PRE291]'
  id: totrans-1160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE291]'
- en: '[PRE292]'
  id: totrans-1161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-1162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-1163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '[PRE295]'
  id: totrans-1164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE295]'
- en: Pros and cons of cross-platform portability ecosystems
  id: totrans-1165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨平台可移植性生态系统的优缺点。
- en: General observations
  id: totrans-1166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一般观察。
- en: The amount of code duplication is minimized.
  id: totrans-1167
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码重复量最小化。
- en: ''
  id: totrans-1168
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1169
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The same code can be compiled to multiple architectures from different vendors.
  id: totrans-1170
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一段代码可以编译成不同供应商的多种架构。
- en: ''
  id: totrans-1171
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1172
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited learning resources compared to CUDA (Stack Overflow, course material,
    documentation).
  id: totrans-1173
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与CUDA相比，学习资源有限（Stack Overflow、课程材料、文档）。
- en: Lambda-based kernel models (Kokkos, SYCL)
  id: totrans-1174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Lambda的内核模型（Kokkos，SYCL）。
- en: Higher level of abstraction.
  id: totrans-1175
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-1176
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1177
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Less knowledge of the underlying architecture is needed for initial porting.
  id: totrans-1178
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始移植不需要对底层架构有太多了解。
- en: ''
  id: totrans-1179
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1180
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very nice and readable source code (C++ API).
  id: totrans-1181
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好读的源代码（C++ API）。
- en: ''
  id: totrans-1182
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1183
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The models are relatively new and not very popular yet.
  id: totrans-1184
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些模型相对较新，尚未非常流行。
- en: Functor-based kernel model (alpaka)
  id: totrans-1185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Functor的内核模型（alpaka）。
- en: Very good portability.
  id: totrans-1186
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-1187
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1188
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Higher level of abstraction.
  id: totrans-1189
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-1190
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1191
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API always awailable which gives more control and allows fine tuning.
  id: totrans-1192
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API始终可用，提供更多控制并允许微调。
- en: ''
  id: totrans-1193
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1194
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: User friendly C++ API for both the host and kernel code.
  id: totrans-1195
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于主机和内核代码的用户友好C++ API。
- en: ''
  id: totrans-1196
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1197
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Small community and ecosystem.
  id: totrans-1198
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型社区和生态系统。
- en: Separate-source kernel models (OpenCL)
  id: totrans-1199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 独立源代码内核模型（OpenCL）。
- en: Very good portability.
  id: totrans-1200
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-1201
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1202
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mature ecosystem.
  id: totrans-1203
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成熟的生态系统。
- en: ''
  id: totrans-1204
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1205
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited number of vendor-provided libraries.
  id: totrans-1206
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商提供的库数量有限。
- en: ''
  id: totrans-1207
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1208
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API gives more control and allows fine tuning.
  id: totrans-1209
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API提供更多控制并允许微调。
- en: ''
  id: totrans-1210
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1211
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both C and C++ APIs available (C++ API is less well supported).
  id: totrans-1212
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: C和C++ API都可用（C++ API支持得不太好）。
- en: ''
  id: totrans-1213
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1214
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The low-level API and separate-source kernel model are less user friendly.
  id: totrans-1215
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API和独立源代码内核模型对用户不太友好。
- en: C++ Standard Parallelism (StdPar, PSTL)
  id: totrans-1216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++标准并行性（StdPar，PSTL）。
- en: Very high level of abstraction.
  id: totrans-1217
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常高的抽象级别。
- en: ''
  id: totrans-1218
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1219
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Easy to speed up code which already relying on STL algorithms.
  id: totrans-1220
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易加速依赖于STL算法的代码。
- en: ''
  id: totrans-1221
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1222
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very little control over hardware.
  id: totrans-1223
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对硬件的控制非常有限。
- en: ''
  id: totrans-1224
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1225
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Support by compilers is improving, but is far from mature.
  id: totrans-1226
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器的支持正在改善，但远未成熟。
- en: Keypoints
  id: totrans-1227
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点。
- en: General code organization is similar to non-portable kernel-based models.
  id: totrans-1228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用代码组织与不可移植的基于内核的模型类似。
- en: As long as no vendor-specific functionality is used, the same code can run on
    any GPU.
  id: totrans-1229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要不使用供应商特定的功能，相同的代码可以在任何GPU上运行。
- en: General observations
  id: totrans-1230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一般观察。
- en: The amount of code duplication is minimized.
  id: totrans-1231
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码重复量最小化。
- en: ''
  id: totrans-1232
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1233
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The same code can be compiled to multiple architectures from different vendors.
  id: totrans-1234
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一段代码可以编译成不同供应商的多种架构。
- en: ''
  id: totrans-1235
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1236
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited learning resources compared to CUDA (Stack Overflow, course material,
    documentation).
  id: totrans-1237
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与CUDA相比，学习资源有限（Stack Overflow、课程材料、文档）。
- en: Lambda-based kernel models (Kokkos, SYCL)
  id: totrans-1238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Lambda的内核模型（Kokkos，SYCL）。
- en: Higher level of abstraction.
  id: totrans-1239
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-1240
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1241
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Less knowledge of the underlying architecture is needed for initial porting.
  id: totrans-1242
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始移植不需要对底层架构有太多了解。
- en: ''
  id: totrans-1243
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1244
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very nice and readable source code (C++ API).
  id: totrans-1245
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好读的源代码（C++ API）。
- en: ''
  id: totrans-1246
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1247
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The models are relatively new and not very popular yet.
  id: totrans-1248
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些模型相对较新，尚未非常流行。
- en: Functor-based kernel model (alpaka)
  id: totrans-1249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Functor的内核模型（alpaka）。
- en: Very good portability.
  id: totrans-1250
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-1251
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1252
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Higher level of abstraction.
  id: totrans-1253
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的抽象级别。
- en: ''
  id: totrans-1254
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1255
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API always awailable which gives more control and allows fine tuning.
  id: totrans-1256
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API始终可用，提供更多控制并允许微调。
- en: ''
  id: totrans-1257
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1258
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: User friendly C++ API for both the host and kernel code.
  id: totrans-1259
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于主机和内核代码的用户友好C++ API。
- en: ''
  id: totrans-1260
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1261
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Small community and ecosystem.
  id: totrans-1262
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型社区和生态系统。
- en: Separate-source kernel models (OpenCL)
  id: totrans-1263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 独立源代码内核模型（OpenCL）。
- en: Very good portability.
  id: totrans-1264
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的可移植性。
- en: ''
  id: totrans-1265
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1266
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mature ecosystem.
  id: totrans-1267
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成熟的生态系统。
- en: ''
  id: totrans-1268
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1269
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited number of vendor-provided libraries.
  id: totrans-1270
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商提供的库数量有限。
- en: ''
  id: totrans-1271
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1272
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Low-level API gives more control and allows fine tuning.
  id: totrans-1273
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API提供更多控制并允许微调。
- en: ''
  id: totrans-1274
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1275
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both C and C++ APIs available (C++ API is less well supported).
  id: totrans-1276
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: C和C++ API都可用（C++ API支持得不太好）。
- en: ''
  id: totrans-1277
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1278
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The low-level API and separate-source kernel model are less user friendly.
  id: totrans-1279
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API和分离源代码的内核模型对用户不太友好。
- en: C++ Standard Parallelism (StdPar, PSTL)
  id: totrans-1280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++标准并行性（StdPar，PSTL）
- en: Very high level of abstraction.
  id: totrans-1281
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常高的抽象级别。
- en: ''
  id: totrans-1282
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1283
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Easy to speed up code which already relying on STL algorithms.
  id: totrans-1284
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易加速依赖于STL算法的代码。
- en: ''
  id: totrans-1285
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1286
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Very little control over hardware.
  id: totrans-1287
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对硬件的控制非常有限。
- en: ''
  id: totrans-1288
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1289
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Support by compilers is improving, but is far from mature.
  id: totrans-1290
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器的支持正在改善，但远未成熟。
- en: Keypoints
  id: totrans-1291
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: General code organization is similar to non-portable kernel-based models.
  id: totrans-1292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用代码组织与不可移植的基于内核的模型相似。
- en: As long as no vendor-specific functionality is used, the same code can run on
    any GPU.*
  id: totrans-1293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要不使用特定供应商的功能，相同的代码可以在任何GPU上运行。*
