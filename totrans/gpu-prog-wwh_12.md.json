["```\nusing  Pkg\nPkg.add(\"CUDA\") \n```", "```\nusing  Pkg\nPkg.add(\"AMDGPU\") \n```", "```\nusing  Pkg\nPkg.add(\"oneAPI\") \n```", "```\nusing  Pkg\nPkg.add(\"Metal\") \n```", "```\nusing  CUDA\nCUDA.versioninfo() \n```", "```\nusing  CUDA\n\nA_d  =  CuArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  AMDGPU\n\nA_d  =  ROCArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  oneAPI\n\nA_d  =  oneArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  Metal\n\nA_d  =  MtlArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nA  =  Array(A_d) \n```", "```\nusing  BenchmarkTools\nusing  CUDA\n\nA  =  rand(2^9,  2^9);\nA_d  =  CuArray(A);\n\n@btime  $A  *  $A;\n@btime  CUDA.@sync  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  AMDGPU\n\nA  =  rand(2^9,  2^9);\nA_d  =  ROCArray(A);\n\n@btime  $A  *  $A;\n@btime  begin\n  $A_d  *  $A_d;\n  AMDGPU.synchronize()\nend \n```", "```\nusing  BenchmarkTools\nusing  oneAPI\n\nA  =  rand(2^9,  2^9);\nA_d  =  oneArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  Metal\n\nA  =  rand(2^9,  2^9);\nA_d  =  MtlArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\n# create a 100x100 Float32 random array and an uninitialized array\nA  =  CUDA.rand(2^9,  2^9);\nB  =  CuArray{Float32,  2}(undef,  2^9,  2^9);\n\n# regular matrix multiplication uses cuBLAS under the hood\nA  *  A\n\n# use LinearAlgebra for matrix multiplication\nusing  LinearAlgebra\nmul!(B,  A,  A)\n\n# use cuSOLVER for QR factorization\nqr(A)\n\n# solve equation A*X == B\nA  \\  B\n\n# use cuFFT for FFT\nusing  CUDA.CUFFT\nfft(A) \n```", "```\nbroadcast(A)  do  x\n  x  +=  1\nend \n```", "```\nmap(A)  do  x\n  x  +  1\nend \n```", "```\nreduce(+,  A) \n```", "```\naccumulate(+,  A) \n```", "```\nusing  CUDA\n\nfunction  vadd!(C,  A,  B)\n  i  =  threadIdx().x  +  (blockIdx().x  -  1)  *  blockDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  CUDA.ones(2^9)*2,  CUDA.ones(2^9)*3;\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@cuda  threads=nthreads  blocks=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  AMDGPU\n\nfunction  vadd!(C,  A,  B)\n  i  =  workitemIdx().x  +  (workgroupIdx().x  -  1)  *  workgroupDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  ROCArray(ones(2^9)*2),  ROCArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@roc  groupsize=nthreads  gridsize=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  oneAPI\n# WARNING: this is still untested on Intel GPUs\nfunction  vadd!(C,  A,  B)\n  i  =  get_global_id()\n  if  i  <=  length(a)\n  c[i]  =  a[i]  +  b[i]\n  end\n  return\nend\n\nA,  B  =  oneArray(ones(2^9)*2),  oneArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumgroups  =  cld(length(a),256)\n\n@oneapi  items=nthreads  groups=numgroups  vadd!(c,  a,  b)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  Metal\n\nfunction  vadd!(C,  A,  B)\n  i  =  thread_position_in_grid_1d()\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  MtlArray(ones(Float32,  2^9)*2),  MtlArray(Float32,  ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@metal  threads=nthreads  grid=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  CUDA\nbackend  =  CUDABackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  AMDGPU\nbackend  =  ROCBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  oneAPI\nbackend  =  oneAPIBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  Metal\nbackend  =  MetalBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\ntry:\n    from  numba  import hip\nexcept ImportError:\n    pass\nelse:\n    hip.pose_as_cuda() \n```", "```\nimport  math\n\ndef  f(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cpu')\ndef  f_numba_cpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cuda')\ndef  f_numba_gpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  numpy  as  np\nx = np.random.rand(10_000_000)\nres = np.random.rand(10_000_000) \n```", "```\n%%timeit -r 1\nfor i in range(10000000):\n    res[i]=f(x[i], x[i])\n    # 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) \n```", "```\n%timeit res=f_numba_cpu(x, x)\n# 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\n%timeit res=f_numba_gpu(x, x)\n# 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\nimport  numpy  as  np\n\ndef  matmul_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cpu')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cpu')\ndef  matmul_numba_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cuda')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cuda')\ndef  matmul_numba_gpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nN = 50\nA = np.random.rand(N,N)\nB = np.random.rand(N,N)\nC = np.random.rand(N,N) \n```", "```\n%timeit matmul_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_gpu(A,B,C) \n```", "```\nusing  Pkg\nPkg.add(\"CUDA\") \n```", "```\nusing  Pkg\nPkg.add(\"AMDGPU\") \n```", "```\nusing  Pkg\nPkg.add(\"oneAPI\") \n```", "```\nusing  Pkg\nPkg.add(\"Metal\") \n```", "```\nusing  CUDA\nCUDA.versioninfo() \n```", "```\nusing  CUDA\n\nA_d  =  CuArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  AMDGPU\n\nA_d  =  ROCArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  oneAPI\n\nA_d  =  oneArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  Metal\n\nA_d  =  MtlArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nA  =  Array(A_d) \n```", "```\nusing  BenchmarkTools\nusing  CUDA\n\nA  =  rand(2^9,  2^9);\nA_d  =  CuArray(A);\n\n@btime  $A  *  $A;\n@btime  CUDA.@sync  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  AMDGPU\n\nA  =  rand(2^9,  2^9);\nA_d  =  ROCArray(A);\n\n@btime  $A  *  $A;\n@btime  begin\n  $A_d  *  $A_d;\n  AMDGPU.synchronize()\nend \n```", "```\nusing  BenchmarkTools\nusing  oneAPI\n\nA  =  rand(2^9,  2^9);\nA_d  =  oneArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  Metal\n\nA  =  rand(2^9,  2^9);\nA_d  =  MtlArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\n# create a 100x100 Float32 random array and an uninitialized array\nA  =  CUDA.rand(2^9,  2^9);\nB  =  CuArray{Float32,  2}(undef,  2^9,  2^9);\n\n# regular matrix multiplication uses cuBLAS under the hood\nA  *  A\n\n# use LinearAlgebra for matrix multiplication\nusing  LinearAlgebra\nmul!(B,  A,  A)\n\n# use cuSOLVER for QR factorization\nqr(A)\n\n# solve equation A*X == B\nA  \\  B\n\n# use cuFFT for FFT\nusing  CUDA.CUFFT\nfft(A) \n```", "```\nbroadcast(A)  do  x\n  x  +=  1\nend \n```", "```\nmap(A)  do  x\n  x  +  1\nend \n```", "```\nreduce(+,  A) \n```", "```\naccumulate(+,  A) \n```", "```\nusing  CUDA\n\nfunction  vadd!(C,  A,  B)\n  i  =  threadIdx().x  +  (blockIdx().x  -  1)  *  blockDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  CUDA.ones(2^9)*2,  CUDA.ones(2^9)*3;\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@cuda  threads=nthreads  blocks=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  AMDGPU\n\nfunction  vadd!(C,  A,  B)\n  i  =  workitemIdx().x  +  (workgroupIdx().x  -  1)  *  workgroupDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  ROCArray(ones(2^9)*2),  ROCArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@roc  groupsize=nthreads  gridsize=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  oneAPI\n# WARNING: this is still untested on Intel GPUs\nfunction  vadd!(C,  A,  B)\n  i  =  get_global_id()\n  if  i  <=  length(a)\n  c[i]  =  a[i]  +  b[i]\n  end\n  return\nend\n\nA,  B  =  oneArray(ones(2^9)*2),  oneArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumgroups  =  cld(length(a),256)\n\n@oneapi  items=nthreads  groups=numgroups  vadd!(c,  a,  b)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  Metal\n\nfunction  vadd!(C,  A,  B)\n  i  =  thread_position_in_grid_1d()\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  MtlArray(ones(Float32,  2^9)*2),  MtlArray(Float32,  ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@metal  threads=nthreads  grid=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  CUDA\nbackend  =  CUDABackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  AMDGPU\nbackend  =  ROCBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  oneAPI\nbackend  =  oneAPIBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  Metal\nbackend  =  MetalBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\ntry:\n    from  numba  import hip\nexcept ImportError:\n    pass\nelse:\n    hip.pose_as_cuda() \n```", "```\nimport  math\n\ndef  f(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cpu')\ndef  f_numba_cpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cuda')\ndef  f_numba_gpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  numpy  as  np\nx = np.random.rand(10_000_000)\nres = np.random.rand(10_000_000) \n```", "```\n%%timeit -r 1\nfor i in range(10000000):\n    res[i]=f(x[i], x[i])\n    # 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) \n```", "```\n%timeit res=f_numba_cpu(x, x)\n# 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\n%timeit res=f_numba_gpu(x, x)\n# 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\nimport  numpy  as  np\n\ndef  matmul_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cpu')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cpu')\ndef  matmul_numba_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cuda')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cuda')\ndef  matmul_numba_gpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nN = 50\nA = np.random.rand(N,N)\nB = np.random.rand(N,N)\nC = np.random.rand(N,N) \n```", "```\n%timeit matmul_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_gpu(A,B,C) \n```", "```\nusing  Pkg\nPkg.add(\"CUDA\") \n```", "```\nusing  Pkg\nPkg.add(\"AMDGPU\") \n```", "```\nusing  Pkg\nPkg.add(\"oneAPI\") \n```", "```\nusing  Pkg\nPkg.add(\"Metal\") \n```", "```\nusing  CUDA\nCUDA.versioninfo() \n```", "```\nusing  CUDA\n\nA_d  =  CuArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  AMDGPU\n\nA_d  =  ROCArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  oneAPI\n\nA_d  =  oneArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  Metal\n\nA_d  =  MtlArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nA  =  Array(A_d) \n```", "```\nusing  BenchmarkTools\nusing  CUDA\n\nA  =  rand(2^9,  2^9);\nA_d  =  CuArray(A);\n\n@btime  $A  *  $A;\n@btime  CUDA.@sync  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  AMDGPU\n\nA  =  rand(2^9,  2^9);\nA_d  =  ROCArray(A);\n\n@btime  $A  *  $A;\n@btime  begin\n  $A_d  *  $A_d;\n  AMDGPU.synchronize()\nend \n```", "```\nusing  BenchmarkTools\nusing  oneAPI\n\nA  =  rand(2^9,  2^9);\nA_d  =  oneArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  Metal\n\nA  =  rand(2^9,  2^9);\nA_d  =  MtlArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\n# create a 100x100 Float32 random array and an uninitialized array\nA  =  CUDA.rand(2^9,  2^9);\nB  =  CuArray{Float32,  2}(undef,  2^9,  2^9);\n\n# regular matrix multiplication uses cuBLAS under the hood\nA  *  A\n\n# use LinearAlgebra for matrix multiplication\nusing  LinearAlgebra\nmul!(B,  A,  A)\n\n# use cuSOLVER for QR factorization\nqr(A)\n\n# solve equation A*X == B\nA  \\  B\n\n# use cuFFT for FFT\nusing  CUDA.CUFFT\nfft(A) \n```", "```\nbroadcast(A)  do  x\n  x  +=  1\nend \n```", "```\nmap(A)  do  x\n  x  +  1\nend \n```", "```\nreduce(+,  A) \n```", "```\naccumulate(+,  A) \n```", "```\nusing  CUDA\n\nfunction  vadd!(C,  A,  B)\n  i  =  threadIdx().x  +  (blockIdx().x  -  1)  *  blockDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  CUDA.ones(2^9)*2,  CUDA.ones(2^9)*3;\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@cuda  threads=nthreads  blocks=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  AMDGPU\n\nfunction  vadd!(C,  A,  B)\n  i  =  workitemIdx().x  +  (workgroupIdx().x  -  1)  *  workgroupDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  ROCArray(ones(2^9)*2),  ROCArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@roc  groupsize=nthreads  gridsize=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  oneAPI\n# WARNING: this is still untested on Intel GPUs\nfunction  vadd!(C,  A,  B)\n  i  =  get_global_id()\n  if  i  <=  length(a)\n  c[i]  =  a[i]  +  b[i]\n  end\n  return\nend\n\nA,  B  =  oneArray(ones(2^9)*2),  oneArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumgroups  =  cld(length(a),256)\n\n@oneapi  items=nthreads  groups=numgroups  vadd!(c,  a,  b)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  Metal\n\nfunction  vadd!(C,  A,  B)\n  i  =  thread_position_in_grid_1d()\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  MtlArray(ones(Float32,  2^9)*2),  MtlArray(Float32,  ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@metal  threads=nthreads  grid=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  CUDA\nbackend  =  CUDABackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  AMDGPU\nbackend  =  ROCBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  oneAPI\nbackend  =  oneAPIBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  Metal\nbackend  =  MetalBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  CUDA\n\nA_d  =  CuArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  AMDGPU\n\nA_d  =  ROCArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  oneAPI\n\nA_d  =  oneArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nusing  Metal\n\nA_d  =  MtlArray([1,2,3,4])\nA_d  .+=  1 \n```", "```\nA  =  Array(A_d) \n```", "```\nusing  BenchmarkTools\nusing  CUDA\n\nA  =  rand(2^9,  2^9);\nA_d  =  CuArray(A);\n\n@btime  $A  *  $A;\n@btime  CUDA.@sync  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  AMDGPU\n\nA  =  rand(2^9,  2^9);\nA_d  =  ROCArray(A);\n\n@btime  $A  *  $A;\n@btime  begin\n  $A_d  *  $A_d;\n  AMDGPU.synchronize()\nend \n```", "```\nusing  BenchmarkTools\nusing  oneAPI\n\nA  =  rand(2^9,  2^9);\nA_d  =  oneArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\nusing  BenchmarkTools\nusing  Metal\n\nA  =  rand(2^9,  2^9);\nA_d  =  MtlArray(A);\n\n@btime  $A  *  $A;\n@btime  $A_d  *  $A_d; \n```", "```\n# create a 100x100 Float32 random array and an uninitialized array\nA  =  CUDA.rand(2^9,  2^9);\nB  =  CuArray{Float32,  2}(undef,  2^9,  2^9);\n\n# regular matrix multiplication uses cuBLAS under the hood\nA  *  A\n\n# use LinearAlgebra for matrix multiplication\nusing  LinearAlgebra\nmul!(B,  A,  A)\n\n# use cuSOLVER for QR factorization\nqr(A)\n\n# solve equation A*X == B\nA  \\  B\n\n# use cuFFT for FFT\nusing  CUDA.CUFFT\nfft(A) \n```", "```\nbroadcast(A)  do  x\n  x  +=  1\nend \n```", "```\nmap(A)  do  x\n  x  +  1\nend \n```", "```\nreduce(+,  A) \n```", "```\naccumulate(+,  A) \n```", "```\nusing  CUDA\n\nfunction  vadd!(C,  A,  B)\n  i  =  threadIdx().x  +  (blockIdx().x  -  1)  *  blockDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  CUDA.ones(2^9)*2,  CUDA.ones(2^9)*3;\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@cuda  threads=nthreads  blocks=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  AMDGPU\n\nfunction  vadd!(C,  A,  B)\n  i  =  workitemIdx().x  +  (workgroupIdx().x  -  1)  *  workgroupDim().x\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  ROCArray(ones(2^9)*2),  ROCArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@roc  groupsize=nthreads  gridsize=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  oneAPI\n# WARNING: this is still untested on Intel GPUs\nfunction  vadd!(C,  A,  B)\n  i  =  get_global_id()\n  if  i  <=  length(a)\n  c[i]  =  a[i]  +  b[i]\n  end\n  return\nend\n\nA,  B  =  oneArray(ones(2^9)*2),  oneArray(ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumgroups  =  cld(length(a),256)\n\n@oneapi  items=nthreads  groups=numgroups  vadd!(c,  a,  b)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  Metal\n\nfunction  vadd!(C,  A,  B)\n  i  =  thread_position_in_grid_1d()\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\n  return\nend\n\nA,  B  =  MtlArray(ones(Float32,  2^9)*2),  MtlArray(Float32,  ones(2^9)*3);\nC  =  similar(A);\n\nnthreads  =  256\n# smallest integer larger than or equal to length(A)/threads\nnumblocks  =  cld(length(A),  nthreads)\n\n# run using 256 threads\n@metal  threads=nthreads  grid=numblocks  vadd!(C,  A,  B)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  CUDA\nbackend  =  CUDABackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  AMDGPU\nbackend  =  ROCBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  oneAPI\nbackend  =  oneAPIBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\nusing  KernelAbstractions\n\nusing  Metal\nbackend  =  MetalBackend()\n\n@kernel  function  vadd!(C,  @Const(A),  @Const(B))\n  i  =  @index(Global)\n  if  i  <=  length(A)\n  @inbounds  C[i]  =  A[i]  +  B[i]\n  end\nend\n\nA  =  KernelAbstractions.ones(backend,  Float64,  2^9)*2;\nB  =  KernelAbstractions.ones(backend,  Float64,  2^9)*3;\nC  =  similar(A)\n\nkernel!  =  vadd!(backend)\nkernel!(C,  A,  B,  ndrange=size(C))\nKernelAbstractions.synchronize(backend)\n\n@assert  all(Array(C)  .==  5.0) \n```", "```\ntry:\n    from  numba  import hip\nexcept ImportError:\n    pass\nelse:\n    hip.pose_as_cuda() \n```", "```\nimport  math\n\ndef  f(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cpu')\ndef  f_numba_cpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cuda')\ndef  f_numba_gpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  numpy  as  np\nx = np.random.rand(10_000_000)\nres = np.random.rand(10_000_000) \n```", "```\n%%timeit -r 1\nfor i in range(10000000):\n    res[i]=f(x[i], x[i])\n    # 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) \n```", "```\n%timeit res=f_numba_cpu(x, x)\n# 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\n%timeit res=f_numba_gpu(x, x)\n# 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\nimport  numpy  as  np\n\ndef  matmul_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cpu')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cpu')\ndef  matmul_numba_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cuda')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cuda')\ndef  matmul_numba_gpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nN = 50\nA = np.random.rand(N,N)\nB = np.random.rand(N,N)\nC = np.random.rand(N,N) \n```", "```\n%timeit matmul_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_gpu(A,B,C) \n```", "```\ntry:\n    from  numba  import hip\nexcept ImportError:\n    pass\nelse:\n    hip.pose_as_cuda() \n```", "```\nimport  math\n\ndef  f(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cpu')\ndef  f_numba_cpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cuda')\ndef  f_numba_gpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  numpy  as  np\nx = np.random.rand(10_000_000)\nres = np.random.rand(10_000_000) \n```", "```\n%%timeit -r 1\nfor i in range(10000000):\n    res[i]=f(x[i], x[i])\n    # 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) \n```", "```\n%timeit res=f_numba_cpu(x, x)\n# 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\n%timeit res=f_numba_gpu(x, x)\n# 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\nimport  numpy  as  np\n\ndef  matmul_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cpu')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cpu')\ndef  matmul_numba_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cuda')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cuda')\ndef  matmul_numba_gpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nN = 50\nA = np.random.rand(N,N)\nB = np.random.rand(N,N)\nC = np.random.rand(N,N) \n```", "```\n%timeit matmul_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_gpu(A,B,C) \n```", "```\nimport  math\n\ndef  f(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cpu')\ndef  f_numba_cpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  math\nimport  numba\n\n@numba.vectorize([numba.float64(numba.float64, numba.float64)], target='cuda')\ndef  f_numba_gpu(x,y):\n    return math.pow(x,3.0) + 4*math.sin(y) \n```", "```\nimport  numpy  as  np\nx = np.random.rand(10_000_000)\nres = np.random.rand(10_000_000) \n```", "```\n%%timeit -r 1\nfor i in range(10000000):\n    res[i]=f(x[i], x[i])\n    # 6.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each) \n```", "```\n%timeit res=f_numba_cpu(x, x)\n# 734 ms ± 435 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\n%timeit res=f_numba_gpu(x, x)\n# 78.4 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) \n```", "```\nimport  numpy  as  np\n\ndef  matmul_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cpu')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cpu')\ndef  matmul_numba_cpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nimport  numba\n\n#@numba.guvectorize(['(float64[:,:], float64[:,:], float64[:,:])'], '(m,l),(l,n)->(m,n)', target='cuda')\n@numba.guvectorize([numba.void(numba.float64[:,:], numba.float64[:,:], numba.float64[:,:])], '(m,l),(l,n)->(m,n)', target='cuda')\ndef  matmul_numba_gpu(A,B,C):\n    for i in range(A.shape[0]):\n        for j in range(B.shape[1]):\n            tmp=0.0\n            for k in range(B.shape[0]):\n                tmp += A[i, k] * B[k, j]\n            C[i,j] += tmp \n```", "```\nimport  numpy  as  np\nN = 50\nA = np.random.rand(N,N)\nB = np.random.rand(N,N)\nC = np.random.rand(N,N) \n```", "```\n%timeit matmul_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_cpu(A,B,C) \n```", "```\n%timeit matmul_numba_gpu(A,B,C) \n```"]