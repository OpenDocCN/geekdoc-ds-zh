- en: Newton's Method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/arithmetic/newton/](https://en.algorithmica.org/hpc/arithmetic/newton/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Reaching the maximum possible precision is rarely required from a practical
    algorithm. In real-world data, modeling and measurement errors are usually several
    orders of magnitude larger than the errors that come from rounding floating-point
    numbers and such, and we are often perfectly happy with picking an approximate
    method that trades off precision for speed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we introduce one of the most important building blocks in
    such approximate, numerical algorithms: *Newton’s method*.'
  prefs: []
  type: TYPE_NORMAL
- en: '## [#](https://en.algorithmica.org/hpc/arithmetic/newton/#newtons-method)Newton’s
    Method'
  prefs: []
  type: TYPE_NORMAL
- en: 'Newton’s method is a simple yet very powerful algorithm for finding approximate
    roots of real-valued functions, that is, the solutions to the following generic
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: $$ f(x) = 0 $$
  prefs: []
  type: TYPE_NORMAL
- en: The only thing assumed about the function $f$ is that at least one root exists
    and that $f(x)$ is continuous and differentiable on the search interval. There
    are also some [boring corner cases](https://en.wikipedia.org/wiki/Newton%27s_method#Failure_analysis),
    but they almost never occur in practice, so we will just informally say that the
    function is “good.”
  prefs: []
  type: TYPE_NORMAL
- en: The main idea of the algorithm is to start with some initial approximation $x_0$
    and then iteratively improve it by drawing the tangent to the graph of the function
    at $x = x_i$ and setting the next approximation $x_{i+1}$ equal to the $x$-coordinate
    of its intersection with the $x$-axis. The intuition is that if the function $f$
    is “[good](https://en.wikipedia.org/wiki/Smoothness)” and $x_i$ is already close
    enough to the root, then $x_{i+1}$ will be even closer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/18f0c447cf274c200cca85ada7b37649.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To obtain the point of intersection for $x_n$, we need to equal its tangent
    line function to zero:'
  prefs: []
  type: TYPE_NORMAL
- en: $$ 0 = f(x_i) + (x_{i+1} - x_i) f'(x_i) $$ from which we derive $$ x_{i+1} =
    x_i - \frac{f(x_i)}{f'(x_i)} $$
  prefs: []
  type: TYPE_NORMAL
- en: 'Newton’s method is very important: it is the basis of a wide range of optimization
    solvers in science and engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/arithmetic/newton/#square-root)Square
    Root'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a simple example, let’s derive the algorithm for the problem of finding
    square roots:'
  prefs: []
  type: TYPE_NORMAL
- en: '$$ x = \sqrt n \iff x^2 = n \iff f(x) = x^2 - n = 0 $$ If we substitute $f(x)
    = x^2 - n$ into the generic formula above, we can obtain the following update
    rule: $$ x_{i+1} = x_i - \frac{x_i^2 - n}{2 x_i} = \frac{x_i + n / x_i}{2} $$'
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice we also want to stop it as soon as it is close enough to the right
    answer, which we can simply check after each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm converges for many functions, although it does so reliably and
    provably only for a certain subset of them (e.g., convex functions). Another question
    is how fast the convergence is, if it occurs.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/arithmetic/newton/#rate-of-convergence)Rate
    of Convergence'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run a few iterations of Newton’s method to find the square root of $2$,
    starting with $x_0 = 1$, and check how many digits it got correct after each iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Looking carefully, we can see that the number of accurate digits approximately
    doubles on each iteration. This fantastic convergence rate is not a coincidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'To analyze convergence rate quantitatively, we need to consider a small relative
    error $\delta_i$ on the $i$-th iteration and determine how much smaller the error
    $\delta_{i+1}$ is on the next iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: $$ |\delta_i| = \frac{|x_n - x|}{x} $$ We can express $x_i$ as $x \cdot (1 +
    \delta_i)$. Plugging it into the Newton iteration formula and dividing both sides
    by $x$ we get $$ 1 + \delta_{i+1} = \frac{1}{2} (1 + \delta_i + \frac{1}{1 + \delta_i})
    = \frac{1}{2} (1 + \delta_i + 1 - \delta_i + \delta_i^2 + o(\delta_i^2)) = 1 +
    \frac{\delta_i^2}{2} + o(\delta_i^2) $$
  prefs: []
  type: TYPE_NORMAL
- en: Here we have Taylor-expanded $(1 + \delta_i)^{-1}$ at $0$, using the assumption
    that the error $d_i$ is small (since the sequence converges, $d_i \ll 1$ for sufficiently
    large $n$).
  prefs: []
  type: TYPE_NORMAL
- en: Rearranging for $\delta_{i+1}$, we obtain
  prefs: []
  type: TYPE_NORMAL
- en: $$ \delta_{i+1} = \frac{\delta_i^2}{2} + o(\delta_i^2) $$
  prefs: []
  type: TYPE_NORMAL
- en: which means that the error roughly squares (and halves) on each iteration once
    we are close to the solution. Since the logarithm $(- \log_{10} \delta_i)$ is
    roughly the number of accurate significant digits in the answer $x_i$, squaring
    the relative error corresponds precisely to doubling the number of significant
    digits that we had observed.
  prefs: []
  type: TYPE_NORMAL
- en: This is known as *quadratic convergence*, and in fact, this is not limited to
    finding square roots. With detailed proof being left as an exercise to the reader,
    it can be shown that, in general
  prefs: []
  type: TYPE_NORMAL
- en: $$ |\delta_{i+1}| = \frac{|f''(x_i)|}{2 \cdot |f'(x_n)|} \cdot \delta_i^2 $$
  prefs: []
  type: TYPE_NORMAL
- en: which results in at least quadratic convergence under a few additional assumptions,
    namely $f’(x)$ not being equal to $0$ and $f’’(x)$ being continuous.
  prefs: []
  type: TYPE_NORMAL
- en: '## [#](https://en.algorithmica.org/hpc/arithmetic/newton/#further-reading)Further
    Reading'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction to numerical methods at MIT](https://ocw.mit.edu/courses/mathematics/18-330-introduction-to-numerical-analysis-spring-2012/lecture-notes/MIT18_330S12_Chapter4.pdf).
    [← Rounding Errors](https://en.algorithmica.org/hpc/arithmetic/errors/)[Fast Inverse
    Square Root →](https://en.algorithmica.org/hpc/arithmetic/rsqrt/)'
  prefs: []
  type: TYPE_NORMAL
