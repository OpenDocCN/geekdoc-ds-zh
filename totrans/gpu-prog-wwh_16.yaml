- en: 'Example: putting it all together'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：整合所有内容
- en: 原文：[https://enccs.github.io/gpu-programming/13-examples/](https://enccs.github.io/gpu-programming/13-examples/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://enccs.github.io/gpu-programming/13-examples/](https://enccs.github.io/gpu-programming/13-examples/)
- en: '*[GPU programming: why, when and how?](../)* **   Example: putting it all together'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*[GPU编程：为什么、何时以及如何？](../)* **   示例：整合所有内容'
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/13-examples.rst)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在GitHub上编辑](https://github.com/ENCCS/gpu-programming/blob/main/content/13-examples.rst)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Questions
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: How do I compile and run code developed using different programming models and
    frameworks?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何编译和运行使用不同编程模型和框架开发的代码？
- en: What can I expect from the GPU-ported programs in terms of performance gains
    / trends and how do I estimate this?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以从GPU移植的程序中期望什么样的性能提升/趋势，以及我该如何估计这一点？
- en: Objectives
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: To show a self-contained example of parallel computation executed on CPU and
    GPU using different programming models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示一个在CPU和GPU上使用不同编程模型执行的并行计算的自包含示例
- en: To show differences and consequences of implementing the same algorithm in natural
    “style” of different models/ frameworks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示在自然“风格”的不同模型/框架中实现相同算法的差异和后果
- en: To discuss how to assess theoretical and practical performance scaling of GPU
    codes
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论如何评估GPU代码的理论和实际性能缩放
- en: Instructor note
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 35 min teaching
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 35分钟教学
- en: 30 min exercises
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30分钟练习
- en: 'Problem: heat flow in two-dimensional area'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题：二维区域中的热流
- en: 'Heat flows in objects according to local temperature differences, as if seeking
    local equilibrium. The following example defines a rectangular area with two always-warm
    sides (temperature 70 and 85), two cold sides (temperature 20 and 5) and a cold
    disk at the center. Because of heat diffusion, temperature of neighboring patches
    of the area is bound to equalize, changing the overall distribution:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 物体中的热流根据局部温度差异进行，就像寻求局部平衡一样。以下示例定义了一个矩形区域，其中有两个始终温暖的侧面（温度为70和85），两个冷的侧面（温度为20和5）以及中心的一个冷盘。由于热扩散，区域相邻区域的温度必然趋于相等，从而改变整体分布：
- en: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
- en: Over time, the temperature distribution progresses from the initial state toward
    an end state where upper triangle is warm and lower is cold. The average temperature
    tends to (70 + 85 + 20 + 5) / 4 = 45.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，温度分布从初始状态向最终状态发展，其中上三角区域温暖，下三角区域寒冷。平均温度趋于 (70 + 85 + 20 + 5) / 4 = 45。
- en: 'Technique: stencil computation'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术：模板计算
- en: Heat transfer in the system above is governed by the partial differential equation(s)
    describing local variation of the temperature field in time and space. That is,
    the rate of change of the temperature field \(u(x, y, t)\) over two spatial dimensions
    \(x\) and \(y\) and time \(t\) (with rate coefficient \(\alpha\)) can be modelled
    via the equation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的系统中热传递由描述时间和空间中温度场局部变化的偏微分方程（组）控制。也就是说，温度场 \(u(x, y, t)\) 在两个空间维度 \(x\) 和
    \(y\) 以及时间 \(t\)（速率系数为 \(\alpha\)）上的变化率可以通过以下方程进行建模
- en: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
- en: The standard way to numerically solve differential equations is to *discretize*
    them, i. e. to consider only a set/ grid of specific area points at specific moments
    in time. That way, partial derivatives \({\partial u}\) are converted into differences
    between adjacent grid points \(u^{m}(i,j)\), with \(m, i, j\) denoting time and
    spatial grid points, respectively. Temperature change in time at a certain point
    can now be computed from the values of neighboring points at earlier time; the
    same expression, called *stencil*, is applied to every point on the grid.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数值求解微分方程的标准方法是对其进行**离散化**，即只考虑在特定时间点上的特定区域点集/网格。这样，偏导数 \({\partial u}\) 就被转换成相邻网格点
    \(u^{m}(i,j)\) 之间的差值，其中 \(m, i, j\) 分别表示时间和空间网格点。现在可以从较早时间点的邻近点的值计算某一点的温度随时间的变化；相同的表达式，称为**模板**，应用于网格上的每个点。
- en: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
- en: This simplified model uses an 8x8 grid of data in light blue in state \(m\),
    each location of which has to be updated based on the indicated 5-point stencil
    in yellow to move to the next time point \(m+1\).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化的模型使用状态 \(m\) 中浅蓝色的 8x8 数据网格，每个位置都必须根据指示的黄色 5 点模板进行更新，以移动到下一个时间点 \(m+1\)。
- en: 'Question: stencil applications'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：模板应用
- en: Stencil computation is a common occurrence in solving numerical problems. Have
    you already encountered it? Can you think of a problem that could be formulated
    this way in your field / area of expertise?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模板计算在解决数值问题时很常见。你遇到过吗？你能想到在你的领域/专业领域中可以用这种方式表述的问题吗？
- en: Solution
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: One obvious choice is *convolution* operation, used in image processing to apply
    various filter kernels; in some contexts, “convolution” and “stencil” are used
    almost interchangeably. Other related use is for averaging/ pooling adjacent values.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的选择是**卷积**操作，在图像处理中用于应用各种滤波核；在某些情况下，“卷积”和“模板”几乎可以互换使用。其他相关用途是用于相邻值的平均/池化。
- en: Technical considerations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术考虑
- en: '**1\. How fast and/ or accurate can the solution be?**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 解的求解速度和/或精度如何？**'
- en: Spatial resolution of the temperature field is controlled by the number/ density
    of the grid points. As the full grid update is required to proceed from one time
    point to the next, stencil computation is the main target of parallelization (on
    CPU or GPU).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 温度场的空间分辨率由网格点的数量/密度控制。由于需要完整的网格更新才能从一个时间点推进到下一个时间点，因此模板计算是并行化的主要目标（在CPU或GPU上）。
- en: Moreover, in many cases the chosen time step cannot be arbitrarily large, otherwise
    the numerical differentiation will fail, and dense/ accurate grids imply small
    time steps (see inset below), which makes efficient spatial update even more important.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在许多情况下，选择的时间步长不能任意大，否则数值微分将失败，密集/精确的网格意味着小的时间步长（见下插图中），这使得有效的空间更新变得更加重要。
- en: 'Optional: stencil expression and time-step limit'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：模板表达式和时间步长限制
- en: 'Differential equation shown above can be discretized using different schemes.
    For this example, temperature values at each grid point \(u^{m}(i,j)\) are updated
    from one time point (\(m\)) to the next (\(m+1\)), using the following expressions:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的微分方程可以使用不同的方案进行离散化。对于这个例子，每个网格点 \(u^{m}(i,j)\) 的温度值从一点时间 (\(m\)) 更新到下一个时间点
    (\(m+1\))，使用以下表达式：
- en: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
- en: where
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
- en: and \(\Delta x\), \(\Delta y\), \(\Delta t\) are step sizes in space and time,
    respectively.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 \(\Delta x\)，\(\Delta y\)，\(\Delta t\) 分别是空间和时间中的步长。
- en: Time-update schemes often have a limit on the maximum allowed time step \(\Delta
    t\). For the current scheme, it is equal to
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 时间更新方案通常对最大允许的时间步长 \(\Delta t\) 有限制。对于当前方案，它等于
- en: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
- en: '**2\. What to do with area boundaries?**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 如何处理区域边界？**'
- en: Naturally, stencil expression can’t be applied directly to the outermost grid
    points that have no outer neighbors. This can be solved by either changing the
    expression for those points or by adding an additional layer of grid that is used
    in computing update, but not updated itself – points of fixed temperature for
    the sides are being used in this example.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，模板表达式不能直接应用于最外层的网格点，这些点没有外部邻居。这可以通过改变这些点的表达式或添加一个额外的网格层来解决，该网格层用于计算更新，但自身不更新
    - 在这个例子中，用于边界的固定温度点正在被使用。
- en: '**3\. How could the algorithm be optimized further?**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 如何进一步优化算法？**'
- en: In [an earlier episode](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations),
    importance of efficient memory access was already stressed. In the following examples,
    each grid point (and its neighbors) is treated mostly independently; however,
    this also means that for 5-point stencil each value of the grid point may be read
    up to 5 times from memory (even if it’s the fast GPU memory). By rearranging the
    order of mathematical operations, it may be possible to reuse these values in
    a more efficient way.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在[早期的一集](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations)中，已经强调了高效内存访问的重要性。在以下示例中，每个网格点（及其邻居）主要被独立处理；然而，这也意味着对于5点stencil，每个网格点的值可能最多从内存中读取5次（即使它是快速的GPU内存）。通过重新排列数学运算的顺序，可能以更有效的方式重用这些值。
- en: Another point to note is that even if the solution is propagated in small time
    steps, not every step might actually be needed for output. Once some *local* region
    of the field is updated, mathematically nothing prevents it from being updated
    for the second time step – even if the rest of the field is still being recalculated
    – as long as \(t = m-1\) values for the region boundary are there when needed.
    (Of course, this is more complicated to implement and would only give benefits
    in certain cases.)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，即使解决方案以小时间步传播，也不一定每个步骤都需要输出。一旦某个*局部*区域被更新，从数学上讲，它不会被更新第二次——即使其余区域仍在重新计算——只要在需要时该区域的边界有\(t
    = m-1\)值。（当然，这更难实现，并且只有在某些情况下才会带来好处。）
- en: 'The following table will aid you in navigating the rest of this section:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下表将帮助您导航本节的其余部分：
- en: Episode guide
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本集指南
- en: '[Sequential and OpenMP-threaded code](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    in C++, including compilation/ running instructions'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++中的[顺序和OpenMP线程代码](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)，包括编译/运行说明
- en: '[Naive GPU parallelization](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps),
    including SYCL compilation instructions'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单的GPU并行化](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps)，包括SYCL编译说明'
- en: '[GPU code with device data management](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)
    (OpenMP, SYCL)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带有设备数据管理的GPU代码](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)（OpenMP，SYCL）'
- en: '[Python implementation](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration),
    including running instructions on [Google Colab](https://colab.research.google.com/)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python实现](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration)，包括在[Google
    Colab](https://colab.research.google.com/)上的运行说明'
- en: '[Julia implementation](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration),
    including running instructions'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Julia实现](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration)，包括运行说明'
- en: Sequential and thread-parallel program in C++
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++中的顺序和线程并行程序
- en: Trying out code examples
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试代码示例
- en: 'Source files of the examples presented for the rest of this episode are available
    in the [content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)
    directory. To download them to your preferred directory on the cluster (f.e. `/scratch/project_<#>/<your_folder>/`),
    you can use Git:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本节其余部分展示的示例源文件可在[content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)目录中找到。要将它们下载到集群上您偏好的目录（例如
    `/scratch/project_<#>/<your_folder>/`），您可以使用Git：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Warning
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: Don’t forget to `git pull` for the latest updates if you already have the content
    from the first day of the workshop!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经从工作坊的第一天开始就有内容，别忘了使用`git pull`获取最新更新！
- en: 'If we assume the grid point values to be truly independent *for a single time
    step*, stencil application procedure may be straightforwardly written as a loop
    over the grid points, as shown below in tab “Stencil update”. (General structure
    of the program and the default parameter values for the problem model are also
    provided for reference.) CPU-thread parallelism can then be enabled by a single
    OpenMP `#pragma`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设网格点值在单个时间步长内真正独立，那么可以将stencil应用过程直接编写为对网格点的循环，如下表“Stencil更新”所示。（程序的一般结构和问题模型的默认参数值也提供供参考。）然后可以通过单个OpenMP
    `#pragma`启用CPU线程并行：
- en: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**core.cpp**'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.cpp**'
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**main.cpp**'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**main.cpp**'
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**heat.h**'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.h**'
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Optional: compiling the executables'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：编译可执行文件
- en: 'To compile executable files for the OpenMP-based variants, follow the instructions
    below:'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要编译基于OpenMP的可执行文件，请按照以下说明操作：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Afterwards login into a compute node and test the executables (or just `srun
    <executable>` directly):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 之后登录到计算节点并测试可执行文件（或直接使用`srun <executable>`）：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该看起来像这样：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'CPU parallelization: timings'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU并行化：计时
- en: '(**NOTE**: for thread-parallel runs it is necessary to request multiple CPU
    cores. In LUMI-G partitions, this can be done by asking for multiple GPUs; an
    alternative is to use -C partitions.)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: （**注意**：对于线程并行运行，需要请求多个CPU核心。在LUMI-G分区中，可以通过请求多个GPU来实现；另一种选择是使用-C分区。）
- en: 'For later comparison, some benchmarks of the OpenMP thread-parallel implementation
    are provided below:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下提供了OpenMP线程并行实现的基准测试：
- en: Run times of OpenMP-enabled executable, s
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 运行OpenMP启用可执行文件的时间，s
- en: '| Job size | 1 CPU core | 32 CPU cores |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 任务大小 | 1 CPU核心 | 32 CPU核心 |'
- en: '| --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S:2000 T:500 | 1.402 | 0.064 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.402 | 0.064 |'
- en: '| S:2000 T:5000 | 13.895 | 0.538 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:5000 | 13.895 | 0.538 |'
- en: '| S:2000 T:10000 | 27.753 | 1.071 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:10000 | 27.753 | 1.071 |'
- en: '| S:4000 T:500 | 5.727 | 0.633 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| S:4000 T:500 | 5.727 | 0.633 |'
- en: '| S:8000 T:500 | 24.130 | 16.616 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| S:8000 T:500 | 24.130 | 16.616 |'
- en: 'A closer look reveals that the computation time scales very nicely with increasing
    **time steps**:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察可以发现，计算时间随着**时间步**的增加而非常理想地扩展：
- en: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
- en: 'However, for larger **grid sizes** the parallelization becomes inefficient
    – as the individual chunks of the grid get too large to fit into CPU cache, threads
    become bound by the speed of RAM reads/writes:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于更大的**网格大小**，并行化变得效率低下——因为网格的各个块太大，无法适应CPU缓存，线程的速度受到RAM读取/写入速度的限制：
- en: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
- en: 'Discussion: heat flow computation scaling'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论：热流计算扩展
- en: How is heat flow computation **expected** to scale with respect to the number
    of time steps?
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 热流计算**预计**如何随时间步数的增加而扩展？
- en: Linearly
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性级
- en: Quadratically
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方级
- en: Exponentially
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数级
- en: How is stencil application (grid update) **expected** to scale with respect
    to the size of the grid side?
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: stencils应用（网格更新）**预计**如何随网格边长的大小而扩展？
- en: Linearly
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性级
- en: Quadratically
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方级
- en: Exponentially
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数级
- en: (Optional) Do you expect GPU-accelerated computations to follow the above-mentioned
    trends? Why/ why not?
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）你期望GPU加速计算会遵循上述趋势吗？为什么/为什么不？
- en: Solution
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The answer is a: since each time-step follows the previous one and involves
    a similar number of operations, then the update time per step will be more or
    less constant.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是a：因为每个时间步都遵循前一个时间步，并且涉及相似数量的操作，因此每步的更新时间将大致保持不变。
- en: 'The answer is b: since stencil application is independent for every grid point,
    the update time will be proportional to the number of points, i.e. side * side.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是b：因为stencil应用对每个网格点都是独立的，更新时间将与点的数量成正比，即边长 * 边长。
- en: 'GPU parallelization: first steps'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU并行化：第一步
- en: Let’s apply several techniques presented in previous episodes to make stencil
    update run on GPU.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用之前几集中介绍的一些技术，使stencil更新在GPU上运行。
- en: OpenMP (or OpenACC) offloading requires to define a region to be executed in
    parallel as well as data that shall be copied over/ used in GPU memory. Similarly,
    SYCL programming model offers convenient ways to define execution kernels, as
    well as context to run them in (called queue).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP（或OpenACC）卸载需要定义一个要并行执行的区域以及要复制到/在GPU内存中使用的数据。同样，SYCL编程模型提供了方便的方式来定义执行内核，以及运行它们的环境（称为队列）。
- en: 'Changes of stencil update code for OpenMP and SYCL are shown in the tabs below:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下面标签中显示了stencil更新代码对OpenMP和SYCL的更改：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-off.cpp**'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-off.cpp**'
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**sycl/core-naive.cpp**'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core-naive.cpp**'
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Loading SYCL modules on LUMI
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在LUMI上加载SYCL模块
- en: 'As SYCL is placed on top of ROCm/HIP (or CUDA) software stack, running SYCL
    executables may require respective modules to be loaded. On current nodes, it
    can be done as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于SYCL位于ROCm/HIP（或CUDA）软件堆栈之上，运行SYCL可执行文件可能需要加载相应的模块。在当前节点上，可以按以下方式完成：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Optional: compiling the SYCL executables'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：编译SYCL可执行文件
- en: 'As previously, you are welcome to generate your own executables:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，您欢迎生成自己的可执行文件：
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该类似于以下内容：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Exercise: naive GPU ports'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：原始GPU端口
- en: 'Test your compiled executables `base/stencil`, `base/stencil_off` and `sycl/stencil_naive`.
    Try changing problem size parameters:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 测试您编译的可执行文件`base/stencil`、`base/stencil_off`和`sycl/stencil_naive`。尝试更改问题大小参数：
- en: '`srun stencil_naive 2000 2000 5000`'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil_naive 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的事项：
- en: How computation times change?
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间如何变化？
- en: Do the results align to your expectations?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果是否符合您的预期？
- en: Solution
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'You might notice that the GPU-“ported” versions actually run slower than the
    single-CPU-core version! In fact, the scaling behavior of all three variants is
    similar and expected, which is a good sign; only the “computation unit cost” is
    different. You can compare benchmark summaries in the tabs below:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到，GPU-“移植”版本实际上比单CPU核心版本运行得更慢！实际上，所有三个版本的扩展行为都是相似且预期的，这是一个好兆头；只是“计算单元成本”不同。您可以在下面的选项卡中比较基准摘要：
- en: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
- en: 'GPU parallelization: data movement'
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU并行化：数据移动
- en: Why the porting approach above seems to be quite inefficient?
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么上述移植方法似乎效率很低？
- en: 'On each step, we:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，我们：
- en: re-allocate GPU memory,
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新分配GPU内存，
- en: copy the data from CPU to GPU,
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据从CPU复制到GPU，
- en: perform the computation,
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行计算，
- en: then copy the data back.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后将数据复制回来。
- en: 'But overhead can be reduced by taking care to minimize data transfers between
    *host* and *device* memory:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，通过注意最小化主机和设备内存之间的数据传输，可以减少开销：
- en: allocate GPU memory once at the start of the program,
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在程序开始时一次性分配GPU内存，
- en: only copy the data from GPU to CPU when we need it,
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只在我们需要时从GPU复制数据到CPU，
- en: swap the GPU buffers between timesteps, like we do with CPU buffers. (OpenMP
    does this automatically.)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间步之间交换GPU缓冲区，就像我们处理CPU缓冲区一样。（OpenMP会自动完成此操作。）
- en: 'Changes of stencil update code are shown in tabs below (also check out the
    respective main() functions for calls to persistent GPU buffer creation, access,
    and deletion):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 下面显示了stencil更新代码的变化（也可以查看相应的main()函数以检查持久GPU缓冲区创建、访问和删除的调用）：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-data.cpp**'
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-data.cpp**'
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**sycl/core.cpp**'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core.cpp**'
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Exercise: updated GPU ports'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：更新后的GPU端口
- en: 'Test your compiled executables `base/stencil_data` and `sycl/stencil_data`.
    Try changing problem size parameters:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 测试您编译的可执行文件`base/stencil_data`和`sycl/stencil_data`。尝试更改问题大小参数：
- en: '`srun stencil 2000 2000 5000`'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的事项：
- en: How computation times change this time around?
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这次计算时间如何变化？
- en: What largest grid and/or longest propagation time can you get in 10 s on your
    machine?
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的机器上，10秒内您能得到最大的网格和/或最长的传播时间是多少？
- en: Solution
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: Using GPU offloading with mapped device data, it is possible to achieve performance
    gains compared to thread-parallel version for larger grid sizes, due to the fact
    that the latter version becomes essentially RAM-bound, but the former does not.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用具有映射设备数据的GPU卸载，对于较大的网格大小，与线程并行版本相比，可以实现性能提升，因为后者版本本质上成为RAM限制的，但前者不是。
- en: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
- en: Below you can find the summary graphs for step- and grid- scaling of the stencil
    update task. Because of the more explicit programming approach, SYCL GPU port
    is much faster than OpenMP-offloaded version, comparable with thread-parallel
    CPU version running on all cores of a single node.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 下面您可以找到stencil更新任务的步骤和网格扩展的摘要图。由于更明确的编程方法，SYCL GPU端口比OpenMP卸载版本快得多，与运行在单个节点所有核心上的线程并行CPU版本相当。
- en: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
- en: 'Python: JIT and GPU acceleration'
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python：JIT 和 GPU 加速
- en: 'As mentioned [previously](https://enccs.github.io/gpu-programming/9-language-support/#numba),
    Numba package allows developers to just-in-time (JIT) compile Python code to run
    fast on CPUs, but can also be used for JIT compiling for (NVIDIA) GPUs. JIT seems
    to work well on loop-based, computationally heavy functions, so trying it out
    is a nice choice for initial source version:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述 [之前](https://enccs.github.io/gpu-programming/9-language-support/#numba)，Numba
    包允许开发者即时（JIT）编译 Python 代码以在 CPU 上快速运行，但也可以用于为（NVIDIA）GPU 进行 JIT 编译。JIT 在基于循环、计算密集型函数上似乎运行良好，因此尝试它是一个不错的选择，用于初始源版本：
- en: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
- en: '**core.py**'
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.py**'
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**heat.py**'
  id: totrans-161
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.py**'
- en: '[PRE15]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**core_cuda.py**'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core_cuda.py**'
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The alternative approach would be to rewrite stencil update code in NumPy style,
    exploiting loop vectorization.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将模板更新代码重写为 NumPy 风格，利用循环向量化。
- en: Trying out Python examples
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试 Python 示例
- en: You can run follow the links below for instructions from the [Setup](../0-setup/)
    episode. You may choose to run the provided code examples either on
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下链接获取 [设置](../0-setup/) 部分的说明。您可以选择在以下任一位置运行提供的代码示例：
- en: on a [LUMI GPU node](../0-setup/#setup-python-lumi-gpu), or
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [LUMI GPU 节点](../0-setup/#setup-python-lumi-gpu)上，或者
- en: your local machine, or [LUMI CPU node](../0-setup/#setup-python-lumi-cpu), or
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的本地机器，或者 [LUMI CPU 节点](../0-setup/#setup-python-lumi-cpu)，或者
- en: '[Google Colab](../0-setup/#setup-google-colab).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google Colab](../0-setup/#setup-google-colab).'
- en: To run the example in a GPU node via the container,
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过容器在 GPU 节点上运行示例，
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To run the example in a CPU node,
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 CPU 节点上运行示例，
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Short summary of a typical Colab run is provided below:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下面提供了典型 Colab 运行的简要总结：
- en: Run times of Numba JIT-enabled Python program, s
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时间，Numba JIT 启用的 Python 程序，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | Job size | no JIT (Colab) |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 任务大小 | JIT (LUMI) | JIT (Colab) | 任务大小 | 无 JIT (Colab) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
- en: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
- en: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
- en: Numba’s `@vectorize` and `@guvectorize` decorators offer an interface to create
    CPU- (or GPU-) accelerated *Python* functions without explicit implementation
    details. However, such functions become increasingly complicated to write (and
    optimize by the compiler) with increasing complexity of the computations within.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 的 `@vectorize` 和 `@guvectorize` 装饰器提供了一个接口，用于创建无需显式实现细节的 CPU-（或 GPU-）加速
    *Python* 函数。然而，随着计算复杂性的增加，此类函数的编写（以及由编译器优化）变得越来越复杂。
- en: Numba also offers direct CUDA-based kernel programming, which can be the best
    choice for those already familiar with CUDA. Example for stencil update written
    in Numba CUDA is shown in the above section, tab “Stencil update in GPU”. In this
    case, data transfer functions `devdata = cuda.to_device(data)` and `devdata.copy_to_host(data)`
    (see `main_cuda.py`) are already provided by Numba package.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 还提供基于 CUDA 的直接内核编程，对于那些已经熟悉 CUDA 的人来说可能是最佳选择。上面章节中，在“GPU 上的模板更新”标签中展示了使用
    Numba CUDA 编写的模板更新示例。在这种情况下，数据传输函数 `devdata = cuda.to_device(data)` 和 `devdata.copy_to_host(data)`（见
    `main_cuda.py`）已由 Numba 包提供。
- en: 'Exercise: CUDA acceleration in Python'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：Python 中的 CUDA 加速
- en: 'Using Google Colab (or your own machine), run provided Numba-CUDA Python program.
    Try changing problem size parameters:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Google Colab（或您自己的机器），运行提供的 Numba-CUDA Python 程序。尝试更改问题大小参数：
- en: '`args.rows, args.cols, args.nsteps = 2000, 2000, 5000` for notebooks,'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args.rows, args.cols, args.nsteps = 2000, 2000, 5000` 用于笔记本，'
- en: '[`srun`] `python3 main.py 2000 2000 5000` for command line.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命令行运行 `srun python3 main.py 2000 2000 5000`。
- en: 'Things to look for:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的事项：
- en: How computation times change?
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间如何变化？
- en: Do you get better performance than from JIT-compiled CPU version? How far can
    you push the problem size?
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否获得了比 JIT 编译的 CPU 版本更好的性能？您可以将问题大小推到多远？
- en: Are you able to monitor the GPU usage?
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您能否监控 GPU 使用情况？
- en: Solution
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Some numbers from Colab:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一些来自 Colab 的数字：
- en: Run times of Numba CUDA Python program, s
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时间，Numba CUDA Python 程序，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 作业大小 | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
- en: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
- en: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
- en: Julia GPU acceleration
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Julia GPU 加速
- en: A Julia version of the stencil example above can be found below (a simplified
    version of the HeatEquation module at [https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)).
    The source files are also available in the [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    directory of this repository.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的示例中可以找到一个 Julia 版本的 stencil 示例（[https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)
    中 HeatEquation 模块的简化版本）。源文件也位于此存储库的 [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    目录中。
- en: 'To run the example on LUMI CPU partition, type:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 LUMI CPU 分区上运行示例，请输入：
- en: '[PRE19]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To run on the GPU partition, use instead the `srun` command
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 GPU 分区上运行，请使用 `srun` 命令
- en: '[PRE20]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Optional dependency
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 可选依赖
- en: Note that the `Plots.jl` dependency is commented out in `main.jl` and `Project.toml`.
    This saves ~2 minute precompilation time when you first instantiate the Julia
    environment. To generate plots, just uncomment the commented `Plots.jl` dependency
    in `Project.toml`, instantiate again, and import and use `Plots` in `main.jl`.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`main.jl` 和 `Project.toml` 中的 `Plots.jl` 依赖项已被注释掉。这在你首次实例化 Julia 环境时可以节省大约
    2 分钟的预编译时间。要生成绘图，只需在 `Project.toml` 中取消注释注释掉的 `Plots.jl` 依赖项，重新实例化，并在 `main.jl`
    中导入和使用 `Plots`。
- en: '[PRE21]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Exercise: Julia port to GPUs'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：Julia 移植到 GPU
- en: 'Carefully inspect all Julia source files and consider the following questions:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细检查所有 Julia 源文件，并考虑以下问题：
- en: Which functions should be ported to run on GPU?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些函数应该移植到 GPU 上运行？
- en: Look at the `initialize!()` function and how it uses the `arraytype` argument.
    This could be done more compactly and elegantly, but this solution solves scalar
    indexing errors. What are scalar indexing errors?
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看 `initialize!()` 函数及其如何使用 `arraytype` 参数。这可以做得更紧凑和优雅，但这个解决方案解决了标量索引错误。什么是标量索引错误？
- en: Try to start sketching GPU-ported versions of the key functions.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试开始绘制关键函数的 GPU 移植版本。
- en: When you have a version running on a GPU (your own or the solution provided
    below), try benchmarking it by adding `@btime` in front of `simulate!()` in `main.jl`.
    Benchmark also the CPU version, and compare.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你在 GPU 上运行版本（你的或下面提供的解决方案）时，尝试通过在 `main.jl` 中的 `simulate!()` 前添加 `@btime` 来对其进行基准测试。也要基准测试
    CPU 版本，并进行比较。
- en: Hints
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: create a new function `evolve_gpu!()` which contains the GPU kernelized version
    of `evolve!()`
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的函数 `evolve_gpu!()`，它包含 `evolve!()` 的 GPU 核化版本
- en: 'in the loop over timesteps in `simulate!()`, you will need a conditional like
    `if typeof(curr.data) <: ROCArray` to call your GPU-ported function'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 `simulate!()` 中的时间步长循环中，你需要一个条件语句，例如 `if typeof(curr.data) <: ROCArray` 来调用你的
    GPU 移植函数'
- en: you cannot pass the struct `Field` to the kernel. You will instead need to directly
    pass the array `Field.data`. This also necessitates passing in other variables
    like `curr.dx^2`, etc.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能将 `Field` 结构体传递给内核。你将需要直接传递数组 `Field.data`。这也需要传递其他变量，如 `curr.dx^2` 等。
- en: More hints
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 更多提示
- en: since the data is two-dimensional, you’ll need `i = (blockIdx().x - 1) * blockDim().x
    + threadIdx().x` and `j = (blockIdx().y - 1) * blockDim().y + threadIdx().y`
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于数据是二维的，你需要 `i = (blockIdx().x - 1) * blockDim().x + threadIdx().x` 和 `j =
    (blockIdx().y - 1) * blockDim().y + threadIdx().y`
- en: to not overindex the 2D array, you can use a conditional like `if i > 1 && j
    > 1 && i < nx+2 && j < ny+2`
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了不过度索引二维数组，你可以使用一个条件语句，例如 `if i > 1 && j > 1 && i < nx+2 && j < ny+2`
- en: when calling the kernel, you can set the number of threads and blocks like `xthreads
    = ythreads = 16` and `xblocks, yblocks = cld(curr.nx, xthreads), cld(curr.ny,
    ythreads)`, and then call it with, e.g., `@roc threads=(xthreads, ythreads) blocks
    = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)`.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用内核时，你可以设置线程数和块数，例如 `xthreads = ythreads = 16` 和 `xblocks, yblocks = cld(curr.nx,
    xthreads), cld(curr.ny, ythreads)`，然后使用，例如 `@roc threads=(xthreads, ythreads)
    blocks = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)` 来调用它。
- en: Solution
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The `evolve!()` and `simulate!()` functions need to be ported. The `main.jl`
    file also needs to be updated to work with GPU arrays.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`evolve!()` 和 `simulate!()` 函数需要移植。`main.jl` 文件也需要更新以支持 GPU 数组。'
- en: “Scalar indexing” is where you iterate over a GPU array, which would be excruciatingly
    slow and is indeed only allowed in interactive REPL sessions. Without the if-statements
    in the `initialize!()` function, the `generate_field!()` method would be doing
    disallowed scalar indexing if you were running on a GPU.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “标量索引”是指遍历GPU数组，这会非常慢，实际上仅在交互式REPL会话中允许这样做。如果没有`initialize!()`函数中的if语句，那么如果你在GPU上运行，`generate_field!()`方法将执行不允许的标量索引。
- en: The GPU-ported version is found below. Try it out on both CPU and GPU and observe
    the speedup. Play around with array size to see if the speedup is affected. You
    can also play around with the `xthreads` and `ythreads` variables to see if it
    changes anything.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU移植的版本如下。在CPU和GPU上尝试它，并观察加速效果。尝试调整数组大小，看看加速效果是否受到影响。你还可以尝试调整`xthreads`和`ythreads`变量，看看是否会有所改变。
- en: '[PRE25]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: See also
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: This section leans heavily on source code and material created for several other
    computing workshops by [ENCCS](https://enccs.se/) and [CSC](https://csc.fi/) and
    adapted for the purposes of this lesson. If you want to know more about specific
    programming models / framework, definitely check these out!
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 本节大量借鉴了[ENCCS](https://enccs.se/)和[CSC](https://csc.fi/)为几个其他计算研讨会创建的源代码和材料，并为此课程的目的进行了改编。如果你想了解更多关于特定编程模型/框架的信息，请务必查看这些内容！
- en: '[OpenMP for GPU offloading](https://enccs.github.io/openmp-gpu/)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenMP用于GPU卸载](https://enccs.github.io/openmp-gpu/)'
- en: '[Heterogeneous programming with SYCL](https://enccs.github.io/sycl-workshop/)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用SYCL进行异构编程](https://enccs.github.io/sycl-workshop/)'
- en: '[Educational implementation of heat flow example (incl. MPI-aware CUDA)](https://github.com/cschpc/heat-equation/)
    [Previous](../12-recommendations/ "Recommendations") [Next](../quick-reference/
    "Quick Reference")'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[热流示例的教育实现（包括MPI感知CUDA）](https://github.com/cschpc/heat-equation/) [上一页](../12-recommendations/
    "推荐") [下一页](../quick-reference/ "快速参考")'
- en: '* * *'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: © Copyright 2023-2024, The contributors.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: © 版权所有 2023-2024，贡献者。
- en: Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). Questions
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Sphinx](https://www.sphinx-doc.org/)和由[Read the Docs](https://readthedocs.org)提供的[主题](https://github.com/readthedocs/sphinx_rtd_theme)构建。有问题？
- en: How do I compile and run code developed using different programming models and
    frameworks?
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何编译和运行使用不同编程模型和框架开发的代码？
- en: What can I expect from the GPU-ported programs in terms of performance gains
    / trends and how do I estimate this?
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以从GPU移植的程序中获得哪些性能提升/趋势，我该如何估计这一点？
- en: Objectives
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: To show a self-contained example of parallel computation executed on CPU and
    GPU using different programming models
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了展示使用不同编程模型在CPU和GPU上执行的并行计算的独立示例
- en: To show differences and consequences of implementing the same algorithm in natural
    “style” of different models/ frameworks
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了展示在自然“风格”的不同模型/框架中实现相同算法的差异和后果
- en: To discuss how to assess theoretical and practical performance scaling of GPU
    codes
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论如何评估GPU代码的理论和实际性能扩展
- en: Instructor note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 35 min teaching
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 35分钟教学
- en: 30 min exercises
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30分钟练习
- en: 'Problem: heat flow in two-dimensional area'
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题：二维区域的热流
- en: 'Heat flows in objects according to local temperature differences, as if seeking
    local equilibrium. The following example defines a rectangular area with two always-warm
    sides (temperature 70 and 85), two cold sides (temperature 20 and 5) and a cold
    disk at the center. Because of heat diffusion, temperature of neighboring patches
    of the area is bound to equalize, changing the overall distribution:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 物体中的热量根据局部温度差异流动，就像在寻求局部平衡。以下示例定义了一个矩形区域，其中两侧始终温暖（温度70和85），两侧寒冷（温度20和5）以及中心的一个冷盘。由于热量扩散，该区域相邻区域的温度必然趋于平衡，从而改变整体分布：
- en: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
- en: Over time, the temperature distribution progresses from the initial state toward
    an end state where upper triangle is warm and lower is cold. The average temperature
    tends to (70 + 85 + 20 + 5) / 4 = 45.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，温度分布从初始状态向最终状态发展，其中上三角区域温暖，下三角区域寒冷。平均温度趋于（70 + 85 + 20 + 5）/ 4 = 45。
- en: 'Technique: stencil computation'
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术：模板计算
- en: Heat transfer in the system above is governed by the partial differential equation(s)
    describing local variation of the temperature field in time and space. That is,
    the rate of change of the temperature field \(u(x, y, t)\) over two spatial dimensions
    \(x\) and \(y\) and time \(t\) (with rate coefficient \(\alpha\)) can be modelled
    via the equation
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的系统中，传热由描述时间和空间中温度场局部变化的偏微分方程（组）控制。也就是说，温度场 \(u(x, y, t)\) 在两个空间维度 \(x\) 和
    \(y\) 以及时间 \(t\)（速率系数为 \(\alpha\)）上的变化率可以通过以下方程进行建模
- en: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
- en: The standard way to numerically solve differential equations is to *discretize*
    them, i. e. to consider only a set/ grid of specific area points at specific moments
    in time. That way, partial derivatives \({\partial u}\) are converted into differences
    between adjacent grid points \(u^{m}(i,j)\), with \(m, i, j\) denoting time and
    spatial grid points, respectively. Temperature change in time at a certain point
    can now be computed from the values of neighboring points at earlier time; the
    same expression, called *stencil*, is applied to every point on the grid.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 数值求解微分方程的标准方法是对其进行 *离散化*，即仅在特定时间点的特定区域点集上考虑。这样，偏导数 \({\partial u}\) 转换为相邻网格点
    \(u^{m}(i,j)\) 之间的差值，其中 \(m, i, j\) 分别表示时间和空间网格点。现在可以从较早时间点的邻近点的值计算某一点的温度随时间的变化；相同的表达式，称为
    *模板*，应用于网格上的每个点。
- en: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
- en: This simplified model uses an 8x8 grid of data in light blue in state \(m\),
    each location of which has to be updated based on the indicated 5-point stencil
    in yellow to move to the next time point \(m+1\).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化的模型使用状态 \(m\) 中浅蓝色的 8x8 数据网格，每个位置都必须根据指示的黄色 5 点模板进行更新，以移动到下一个时间点 \(m+1\)。
- en: 'Question: stencil applications'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：模板应用
- en: Stencil computation is a common occurrence in solving numerical problems. Have
    you already encountered it? Can you think of a problem that could be formulated
    this way in your field / area of expertise?
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 模板计算在解决数值问题时很常见。你遇到过它吗？你能想到在你的领域/专业领域可以用这种方式表述的问题吗？
- en: Solution
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 解法
- en: One obvious choice is *convolution* operation, used in image processing to apply
    various filter kernels; in some contexts, “convolution” and “stencil” are used
    almost interchangeably. Other related use is for averaging/ pooling adjacent values.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的选择是 *卷积* 操作，用于图像处理中应用各种滤波内核；在某些情况下，“卷积”和“模板”几乎可以互换使用。其他相关用途是用于相邻值的平均/池化。
- en: Technical considerations
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术考虑
- en: '**1\. How fast and/ or accurate can the solution be?**'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 解法有多快和/或有多准确？**'
- en: Spatial resolution of the temperature field is controlled by the number/ density
    of the grid points. As the full grid update is required to proceed from one time
    point to the next, stencil computation is the main target of parallelization (on
    CPU or GPU).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 温度场的空间分辨率由网格点的数量/密度控制。由于需要完整的网格更新才能从一个时间点推进到下一个时间点，因此模板计算是并行化的主要目标（在 CPU 或 GPU
    上）。
- en: Moreover, in many cases the chosen time step cannot be arbitrarily large, otherwise
    the numerical differentiation will fail, and dense/ accurate grids imply small
    time steps (see inset below), which makes efficient spatial update even more important.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在许多情况下，选择的时间步长不能任意大，否则数值微分将失败，密集/精确的网格意味着时间步长很小（见下插图中），这使得有效的空间更新变得更加重要。
- en: 'Optional: stencil expression and time-step limit'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：模板表达式和时间步长限制
- en: 'Differential equation shown above can be discretized using different schemes.
    For this example, temperature values at each grid point \(u^{m}(i,j)\) are updated
    from one time point (\(m\)) to the next (\(m+1\)), using the following expressions:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的微分方程可以使用不同的方案进行离散化。对于这个例子，每个网格点 \(u^{m}(i,j)\) 的温度值使用以下表达式从时间点 (\(m\)) 更新到下一个
    (\(m+1\))：
- en: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
- en: where
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
- en: and \(\Delta x\), \(\Delta y\), \(\Delta t\) are step sizes in space and time,
    respectively.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 \(\Delta x\)、\(\Delta y\)、\(\Delta t\) 分别是空间和时间步长。
- en: Time-update schemes often have a limit on the maximum allowed time step \(\Delta
    t\). For the current scheme, it is equal to
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 时间更新方案通常对允许的最大时间步长 \(\Delta t\) 有限制。对于当前方案，它等于
- en: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
- en: '**2\. What to do with area boundaries?**'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 如何处理区域边界？**'
- en: Naturally, stencil expression can’t be applied directly to the outermost grid
    points that have no outer neighbors. This can be solved by either changing the
    expression for those points or by adding an additional layer of grid that is used
    in computing update, but not updated itself – points of fixed temperature for
    the sides are being used in this example.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，卷积表达式不能直接应用于没有外部邻居的最外层网格点。这可以通过改变这些点的表达式或添加一个额外的网格层来解决，该层用于计算更新但不进行更新——在这个例子中使用了固定温度的边点。
- en: '**3\. How could the algorithm be optimized further?**'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 算法如何进一步优化？**'
- en: In [an earlier episode](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations),
    importance of efficient memory access was already stressed. In the following examples,
    each grid point (and its neighbors) is treated mostly independently; however,
    this also means that for 5-point stencil each value of the grid point may be read
    up to 5 times from memory (even if it’s the fast GPU memory). By rearranging the
    order of mathematical operations, it may be possible to reuse these values in
    a more efficient way.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [早期的一集](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations)
    中，已经强调了高效内存访问的重要性。在以下示例中，每个网格点（及其邻居）主要被独立处理；然而，这也意味着对于5点卷积，每个网格点的值可能最多从内存中读取5次（即使它是快速的GPU内存）。通过重新排列数学运算的顺序，可能以更有效的方式重用这些值。
- en: Another point to note is that even if the solution is propagated in small time
    steps, not every step might actually be needed for output. Once some *local* region
    of the field is updated, mathematically nothing prevents it from being updated
    for the second time step – even if the rest of the field is still being recalculated
    – as long as \(t = m-1\) values for the region boundary are there when needed.
    (Of course, this is more complicated to implement and would only give benefits
    in certain cases.)
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，即使解以小时间步长传播，也不一定每个步骤都需要输出。一旦某个 *局部* 区域的场被更新，数学上没有任何东西阻止它在第二次时间步中再次更新——即使其余的场仍在重新计算——只要在该区域边界需要时存在
    \(t = m-1\) 的值。（当然，这更难实现，并且只有在某些情况下才会带来好处。）
- en: 'The following table will aid you in navigating the rest of this section:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 下表将帮助您导航本节的其余部分：
- en: Episode guide
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 播放指南
- en: '[Sequential and OpenMP-threaded code](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    in C++, including compilation/ running instructions'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顺序和OpenMP线程代码](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    在C++中，包括编译/运行说明'
- en: '[Naive GPU parallelization](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps),
    including SYCL compilation instructions'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单的GPU并行化](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps)，包括SYCL编译说明'
- en: '[GPU code with device data management](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)
    (OpenMP, SYCL)'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[具有设备数据管理的GPU代码](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)
    (OpenMP, SYCL)'
- en: '[Python implementation](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration),
    including running instructions on [Google Colab](https://colab.research.google.com/)'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python实现](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration)，包括在
    [Google Colab](https://colab.research.google.com/) 上的运行说明'
- en: '[Julia implementation](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration),
    including running instructions'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Julia实现](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration)，包括运行说明'
- en: Sequential and thread-parallel program in C++
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++中的顺序和线程并行程序
- en: Trying out code examples
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试代码示例
- en: 'Source files of the examples presented for the rest of this episode are available
    in the [content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)
    directory. To download them to your preferred directory on the cluster (f.e. `/scratch/project_<#>/<your_folder>/`),
    you can use Git:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本节余下部分提供的示例源文件位于[content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)目录中。要将它们下载到集群上您首选的目录（例如
    `/scratch/project_<#>/<your_folder>/`），您可以使用Git：
- en: '[PRE27]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Warning
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: Don’t forget to `git pull` for the latest updates if you already have the content
    from the first day of the workshop!
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经从工作坊的第一天开始就有内容，别忘了使用 `git pull` 获取最新更新！
- en: 'If we assume the grid point values to be truly independent *for a single time
    step*, stencil application procedure may be straightforwardly written as a loop
    over the grid points, as shown below in tab “Stencil update”. (General structure
    of the program and the default parameter values for the problem model are also
    provided for reference.) CPU-thread parallelism can then be enabled by a single
    OpenMP `#pragma`:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设网格点值在单个时间步长内真正独立，那么模板应用过程可以简单地写成对网格点的循环，如下表“模板更新”所示。（程序的一般结构和问题模型的默认参数值也提供供参考。）然后可以通过单个OpenMP
    `#pragma` 启用CPU线程并行：
- en: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**core.cpp**'
  id: totrans-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.cpp**'
- en: '[PRE28]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**main.cpp**'
  id: totrans-297
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**main.cpp**'
- en: '[PRE29]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**heat.h**'
  id: totrans-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.h**'
- en: '[PRE30]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Optional: compiling the executables'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: （可选）编译可执行文件
- en: 'To compile executable files for the OpenMP-based variants, follow the instructions
    below:'
  id: totrans-302
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要编译基于OpenMP的可执行文件，请按照以下说明操作：
- en: '[PRE31]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Afterwards login into a compute node and test the executables (or just `srun
    <executable>` directly):'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 之后登录到计算节点并测试可执行文件（或直接使用 `srun <executable>`）：
- en: '[PRE32]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该类似于以下内容：
- en: '[PRE33]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'CPU parallelization: timings'
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU并行化：计时
- en: '(**NOTE**: for thread-parallel runs it is necessary to request multiple CPU
    cores. In LUMI-G partitions, this can be done by asking for multiple GPUs; an
    alternative is to use -C partitions.)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: （**注意**：对于线程并行运行，需要请求多个CPU核心。在LUMI-G分区中，可以通过请求多个GPU来实现；另一种选择是使用 -C 分区。）
- en: 'For later comparison, some benchmarks of the OpenMP thread-parallel implementation
    are provided below:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 下面提供了OpenMP线程并行实现的某些基准测试，以供后续比较：
- en: Run times of OpenMP-enabled executable, s
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 运行OpenMP启用可执行文件的时间，s
- en: '| Job size | 1 CPU core | 32 CPU cores |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 任务大小 | 1 CPU核心 | 32 CPU核心 |'
- en: '| --- | --- | --- |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S:2000 T:500 | 1.402 | 0.064 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.402 | 0.064 |'
- en: '| S:2000 T:5000 | 13.895 | 0.538 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:5000 | 13.895 | 0.538 |'
- en: '| S:2000 T:10000 | 27.753 | 1.071 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:10000 | 27.753 | 1.071 |'
- en: '| S:4000 T:500 | 5.727 | 0.633 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| S:4000 T:500 | 5.727 | 0.633 |'
- en: '| S:8000 T:500 | 24.130 | 16.616 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| S:8000 T:500 | 24.130 | 16.616 |'
- en: 'A closer look reveals that the computation time scales very nicely with increasing
    **time steps**:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察可以发现，计算时间随着时间步的增加而非常理想地缩放：
- en: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
- en: 'However, for larger **grid sizes** the parallelization becomes inefficient
    – as the individual chunks of the grid get too large to fit into CPU cache, threads
    become bound by the speed of RAM reads/writes:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于较大的**网格大小**，并行化变得效率低下——因为网格的各个块太大，无法适应CPU缓存，线程的速度受到RAM读写速度的限制：
- en: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
- en: 'Discussion: heat flow computation scaling'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论：热流计算缩放
- en: How is heat flow computation **expected** to scale with respect to the number
    of time steps?
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 热流计算**预期**如何根据时间步的数量进行缩放？
- en: Linearly
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方级
- en: Exponentially
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数级
- en: How is stencil application (grid update) **expected** to scale with respect
    to the size of the grid side?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模板应用（网格更新）**预期**如何根据网格边的大小进行缩放？
- en: Linearly
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方
- en: Exponentially
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数级
- en: (Optional) Do you expect GPU-accelerated computations to follow the above-mentioned
    trends? Why/ why not?
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）您预计GPU加速的计算会遵循上述趋势吗？为什么/为什么不？
- en: Solution
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'The answer is a: since each time-step follows the previous one and involves
    a similar number of operations, then the update time per step will be more or
    less constant.'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是a：因为每个时间步都遵循前一个时间步，并且涉及相似数量的操作，因此每步的更新时间将大致保持不变。
- en: 'The answer is b: since stencil application is independent for every grid point,
    the update time will be proportional to the number of points, i.e. side * side.'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是 b：由于 stencil 应用对每个网格点都是独立的，更新时间将与点的数量成比例，即边长 * 边长。
- en: 'GPU parallelization: first steps'
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 并行化：第一步
- en: Let’s apply several techniques presented in previous episodes to make stencil
    update run on GPU.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用之前几集中介绍的一些技术，使 stencil 更新在 GPU 上运行。
- en: OpenMP (or OpenACC) offloading requires to define a region to be executed in
    parallel as well as data that shall be copied over/ used in GPU memory. Similarly,
    SYCL programming model offers convenient ways to define execution kernels, as
    well as context to run them in (called queue).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP（或 OpenACC）卸载需要定义一个要并行执行的区域以及要复制到/在 GPU 内存中使用的内存。同样，SYCL 编程模型提供了方便的方式来定义执行内核，以及运行它们的环境（称为队列）。
- en: 'Changes of stencil update code for OpenMP and SYCL are shown in the tabs below:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP 和 SYCL 的 stencil 更新代码更改显示在下面的选项卡中：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-off.cpp**'
  id: totrans-341
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-off.cpp**'
- en: '[PRE34]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '**sycl/core-naive.cpp**'
  id: totrans-343
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core-naive.cpp**'
- en: '[PRE35]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Loading SYCL modules on LUMI
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LUMI 上加载 SYCL 模块
- en: 'As SYCL is placed on top of ROCm/HIP (or CUDA) software stack, running SYCL
    executables may require respective modules to be loaded. On current nodes, it
    can be done as follows:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 SYCL 位于 ROCm/HIP（或 CUDA）软件堆栈之上，运行 SYCL 可执行文件可能需要加载相应的模块。在当前节点上，可以这样做：
- en: '[PRE36]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Optional: compiling the SYCL executables'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：编译 SYCL 可执行文件
- en: 'As previously, you are welcome to generate your own executables:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，欢迎你生成自己的可执行文件：
- en: '[PRE37]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该类似于以下内容：
- en: '[PRE38]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Exercise: naive GPU ports'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：原始 GPU 移植
- en: 'Test your compiled executables `base/stencil`, `base/stencil_off` and `sycl/stencil_naive`.
    Try changing problem size parameters:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 测试你编译的可执行文件 `base/stencil`、`base/stencil_off` 和 `sycl/stencil_naive`。尝试更改问题大小参数：
- en: '`srun stencil_naive 2000 2000 5000`'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil_naive 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的事项：
- en: How computation times change?
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间如何变化？
- en: Do the results align to your expectations?
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果是否符合你的预期？
- en: Solution
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'You might notice that the GPU-“ported” versions actually run slower than the
    single-CPU-core version! In fact, the scaling behavior of all three variants is
    similar and expected, which is a good sign; only the “computation unit cost” is
    different. You can compare benchmark summaries in the tabs below:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，GPU-“移植”版本实际上比单核 CPU 版本运行得更慢！实际上，所有三个版本的比例行为都是相似且预期的，这是一个好兆头；只是“计算单元成本”不同。你可以在下面的选项卡中比较基准摘要：
- en: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
- en: 'GPU parallelization: data movement'
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 并行化：数据移动
- en: Why the porting approach above seems to be quite inefficient?
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么上述的移植方法看起来效率很低？
- en: 'On each step, we:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，我们：
- en: re-allocate GPU memory,
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新分配 GPU 内存，
- en: copy the data from CPU to GPU,
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据从 CPU 复制到 GPU，
- en: perform the computation,
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行计算，
- en: then copy the data back.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后将数据复制回来。
- en: 'But overhead can be reduced by taking care to minimize data transfers between
    *host* and *device* memory:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 但可以通过最小化 *主机* 和 *设备* 之间的数据传输来减少开销：
- en: allocate GPU memory once at the start of the program,
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在程序开始时一次性分配 GPU 内存，
- en: only copy the data from GPU to CPU when we need it,
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只在我们需要时从 GPU 复制数据到 CPU，
- en: swap the GPU buffers between timesteps, like we do with CPU buffers. (OpenMP
    does this automatically.)
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间步之间交换 GPU 缓冲区，就像我们处理 CPU 缓冲区一样。（OpenMP 会自动完成这项工作。）
- en: 'Changes of stencil update code are shown in tabs below (also check out the
    respective main() functions for calls to persistent GPU buffer creation, access,
    and deletion):'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: stencil 更新代码的更改显示在下面的选项卡中（还可以查看相应的 main() 函数，以检查持久 GPU 缓冲区创建、访问和删除的调用）：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-data.cpp**'
  id: totrans-375
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-data.cpp**'
- en: '[PRE39]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '**sycl/core.cpp**'
  id: totrans-377
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core.cpp**'
- en: '[PRE40]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Exercise: updated GPU ports'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：更新后的 GPU 移植
- en: 'Test your compiled executables `base/stencil_data` and `sycl/stencil_data`.
    Try changing problem size parameters:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 测试你的编译可执行文件`base/stencil_data`和`sycl/stencil_data`。尝试更改问题大小参数：
- en: '`srun stencil 2000 2000 5000`'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找的内容：
- en: How computation times change this time around?
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这次的计算时间如何变化？
- en: What largest grid and/or longest propagation time can you get in 10 s on your
    machine?
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的机器上，10秒内你能得到多大的网格和/或最长的传播时间？
- en: Solution
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: Using GPU offloading with mapped device data, it is possible to achieve performance
    gains compared to thread-parallel version for larger grid sizes, due to the fact
    that the latter version becomes essentially RAM-bound, but the former does not.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 使用映射设备数据的GPU卸载，对于较大的网格大小，与线程并行版本相比，可以实现性能提升，因为后者版本本质上受限于RAM，而前者则不是。
- en: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
- en: Below you can find the summary graphs for step- and grid- scaling of the stencil
    update task. Because of the more explicit programming approach, SYCL GPU port
    is much faster than OpenMP-offloaded version, comparable with thread-parallel
    CPU version running on all cores of a single node.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以找到stencil更新任务的步长和网格缩放步骤的总结图表。由于编程方法更加明确，SYCL GPU端口比OpenMP卸载版本快得多，与在单个节点所有核心上运行的线程并行CPU版本相当。
- en: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
- en: 'Python: JIT and GPU acceleration'
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Python: JIT和GPU加速'
- en: 'As mentioned [previously](https://enccs.github.io/gpu-programming/9-language-support/#numba),
    Numba package allows developers to just-in-time (JIT) compile Python code to run
    fast on CPUs, but can also be used for JIT compiling for (NVIDIA) GPUs. JIT seems
    to work well on loop-based, computationally heavy functions, so trying it out
    is a nice choice for initial source version:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述[之前](https://enccs.github.io/gpu-programming/9-language-support/#numba)，Numba包允许开发者即时（JIT）编译Python代码以在CPU上快速运行，但也可以用于（NVIDIA）GPU的JIT编译。JIT似乎在基于循环、计算密集型函数上运行良好，因此尝试它是一个不错的选择，对于初始源版本：
- en: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
- en: '**core.py**'
  id: totrans-393
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.py**'
- en: '[PRE41]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '**heat.py**'
  id: totrans-395
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.py**'
- en: '[PRE42]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '**core_cuda.py**'
  id: totrans-397
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core_cuda.py**'
- en: '[PRE43]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The alternative approach would be to rewrite stencil update code in NumPy style,
    exploiting loop vectorization.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用NumPy风格重写stencil更新代码，利用循环向量化。
- en: Trying out Python examples
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试运行Python示例
- en: You can run follow the links below for instructions from the [Setup](../0-setup/)
    episode. You may choose to run the provided code examples either on
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以运行以下链接以获取[设置](../0-setup/)部分的说明。您可以选择在提供的代码示例上运行
- en: on a [LUMI GPU node](../0-setup/#setup-python-lumi-gpu), or
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[LUMI GPU节点](../0-setup/#setup-python-lumi-gpu)上，或
- en: your local machine, or [LUMI CPU node](../0-setup/#setup-python-lumi-cpu), or
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的本地机器，或[LUMI CPU节点](../0-setup/#setup-python-lumi-cpu)，或
- en: '[Google Colab](../0-setup/#setup-google-colab).'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google Colab](../0-setup/#setup-google-colab).'
- en: To run the example in a GPU node via the container,
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 通过容器在GPU节点上运行示例，
- en: '[PRE44]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: To run the example in a CPU node,
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在CPU节点上运行示例，
- en: '[PRE45]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Short summary of a typical Colab run is provided below:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个典型的Colab运行的简要总结：
- en: Run times of Numba JIT-enabled Python program, s
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Numba JIT启用Python程序的时间，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | Job size | no JIT (Colab) |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 任务大小 | JIT (LUMI) | JIT (Colab) | 任务大小 | 无JIT (Colab) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
- en: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
- en: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
- en: Numba’s `@vectorize` and `@guvectorize` decorators offer an interface to create
    CPU- (or GPU-) accelerated *Python* functions without explicit implementation
    details. However, such functions become increasingly complicated to write (and
    optimize by the compiler) with increasing complexity of the computations within.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: Numba的`@vectorize`和`@guvectorize`装饰器提供了一个接口，用于创建无需显式实现细节的CPU-（或GPU-）加速*Python*函数。然而，随着计算复杂性的增加，此类函数的编写（以及编译器优化）变得越来越复杂。
- en: Numba also offers direct CUDA-based kernel programming, which can be the best
    choice for those already familiar with CUDA. Example for stencil update written
    in Numba CUDA is shown in the above section, tab “Stencil update in GPU”. In this
    case, data transfer functions `devdata = cuda.to_device(data)` and `devdata.copy_to_host(data)`
    (see `main_cuda.py`) are already provided by Numba package.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 还提供基于 CUDA 的直接内核编程，这对于已经熟悉 CUDA 的人来说可能是最佳选择。上面章节中展示了用 Numba CUDA 编写的 stencils
    更新示例，在“GPU 中的 stencils 更新”标签页中。在这种情况下，数据传输函数 `devdata = cuda.to_device(data)`
    和 `devdata.copy_to_host(data)`（见 `main_cuda.py`）已由 Numba 包提供。
- en: 'Exercise: CUDA acceleration in Python'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：Python 中的 CUDA 加速
- en: 'Using Google Colab (or your own machine), run provided Numba-CUDA Python program.
    Try changing problem size parameters:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Google Colab（或您自己的机器），运行提供的 Numba-CUDA Python 程序。尝试更改问题大小参数：
- en: '`args.rows, args.cols, args.nsteps = 2000, 2000, 5000` for notebooks,'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 笔记本中：`args.rows, args.cols, args.nsteps = 2000, 2000, 5000`。
- en: '[`srun`] `python3 main.py 2000 2000 5000` for command line.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun` 命令行：`python3 main.py 2000 2000 5000`。'
- en: 'Things to look for:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找的内容：
- en: How computation times change?
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间如何变化？
- en: Do you get better performance than from JIT-compiled CPU version? How far can
    you push the problem size?
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否获得了比 JIT 编译的 CPU 版本更好的性能？您可以将问题大小推到多远？
- en: Are you able to monitor the GPU usage?
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您能否监控 GPU 使用情况？
- en: Solution
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Some numbers from Colab:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 一些来自 Colab 的数字：
- en: Run times of Numba CUDA Python program, s
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: Numba CUDA Python 程序的运行时间，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 任务大小 | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
- en: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
- en: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
- en: Julia GPU acceleration
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Julia GPU 加速
- en: A Julia version of the stencil example above can be found below (a simplified
    version of the HeatEquation module at [https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)).
    The source files are also available in the [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    directory of this repository.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的示例中提到的 Julia 版本的 stencils 示例可以在下面找到（[https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)
    中 HeatEquation 模块的简化版本）。源文件也位于本仓库的 [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    目录中。
- en: 'To run the example on LUMI CPU partition, type:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 LUMI CPU 分区上运行示例，请输入：
- en: '[PRE46]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: To run on the GPU partition, use instead the `srun` command
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 GPU 分区上运行，请使用 `srun` 命令。
- en: '[PRE47]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Optional dependency
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 可选依赖项
- en: Note that the `Plots.jl` dependency is commented out in `main.jl` and `Project.toml`.
    This saves ~2 minute precompilation time when you first instantiate the Julia
    environment. To generate plots, just uncomment the commented `Plots.jl` dependency
    in `Project.toml`, instantiate again, and import and use `Plots` in `main.jl`.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`main.jl` 和 `Project.toml` 中的 `Plots.jl` 依赖项已被注释掉。这可以在您首次实例化 Julia 环境时节省约
    2 分钟的预编译时间。要生成绘图，只需在 `Project.toml` 中取消注释注释的 `Plots.jl` 依赖项，重新实例化，并在 `main.jl`
    中导入和使用 `Plots` 即可。
- en: '[PRE48]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Exercise: Julia port to GPUs'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：将 Julia 移植到 GPU 上
- en: 'Carefully inspect all Julia source files and consider the following questions:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细检查所有 Julia 源文件，并考虑以下问题：
- en: Which functions should be ported to run on GPU?
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些函数应该移植到 GPU 上运行？
- en: Look at the `initialize!()` function and how it uses the `arraytype` argument.
    This could be done more compactly and elegantly, but this solution solves scalar
    indexing errors. What are scalar indexing errors?
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看 `initialize!()` 函数及其如何使用 `arraytype` 参数。这可以做得更紧凑和优雅，但这个解决方案解决了标量索引错误。什么是标量索引错误？
- en: Try to start sketching GPU-ported versions of the key functions.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试开始绘制关键函数的 GPU 移植版本。
- en: When you have a version running on a GPU (your own or the solution provided
    below), try benchmarking it by adding `@btime` in front of `simulate!()` in `main.jl`.
    Benchmark also the CPU version, and compare.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您有一个在 GPU 上运行的版本（您自己的或下面提供的解决方案）时，尝试通过在 `main.jl` 中的 `simulate!()` 前添加 `@btime`
    来对其进行基准测试。也要基准测试 CPU 版本，并进行比较。
- en: Hints
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: create a new function `evolve_gpu!()` which contains the GPU kernelized version
    of `evolve!()`
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新函数 `evolve_gpu!()`，其中包含 `evolve!()` 的 GPU 核函数版本。
- en: 'in the loop over timesteps in `simulate!()`, you will need a conditional like
    `if typeof(curr.data) <: ROCArray` to call your GPU-ported function'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 `simulate!()` 函数中对时间步长进行循环时，您将需要一个条件语句，例如 `if typeof(curr.data) <: ROCArray`
    来调用您的 GPU 移植函数。'
- en: you cannot pass the struct `Field` to the kernel. You will instead need to directly
    pass the array `Field.data`. This also necessitates passing in other variables
    like `curr.dx^2`, etc.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能将结构 `Field` 传递给内核。相反，你需要直接传递数组 `Field.data`。这也需要传递其他变量，如 `curr.dx^2` 等。
- en: More hints
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 更多提示
- en: since the data is two-dimensional, you’ll need `i = (blockIdx().x - 1) * blockDim().x
    + threadIdx().x` and `j = (blockIdx().y - 1) * blockDim().y + threadIdx().y`
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于数据是二维的，你需要 `i = (blockIdx().x - 1) * blockDim().x + threadIdx().x` 和 `j =
    (blockIdx().y - 1) * blockDim().y + threadIdx().y`
- en: to not overindex the 2D array, you can use a conditional like `if i > 1 && j
    > 1 && i < nx+2 && j < ny+2`
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了不过度索引二维数组，你可以使用条件语句 `if i > 1 && j > 1 && i < nx+2 && j < ny+2`
- en: when calling the kernel, you can set the number of threads and blocks like `xthreads
    = ythreads = 16` and `xblocks, yblocks = cld(curr.nx, xthreads), cld(curr.ny,
    ythreads)`, and then call it with, e.g., `@roc threads=(xthreads, ythreads) blocks
    = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)`.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用内核时，你可以设置线程和块的数量，例如 `xthreads = ythreads = 16` 和 `xblocks, yblocks = cld(curr.nx,
    xthreads), cld(curr.ny, ythreads)`，然后使用，例如，`@roc threads=(xthreads, ythreads)
    blocks = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)` 调用它。
- en: Solution
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The `evolve!()` and `simulate!()` functions need to be ported. The `main.jl`
    file also needs to be updated to work with GPU arrays.
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`evolve!()` 和 `simulate!()` 函数需要移植。`main.jl` 文件也需要更新，以便与 GPU 数组一起工作。'
- en: “Scalar indexing” is where you iterate over a GPU array, which would be excruciatingly
    slow and is indeed only allowed in interactive REPL sessions. Without the if-statements
    in the `initialize!()` function, the `generate_field!()` method would be doing
    disallowed scalar indexing if you were running on a GPU.
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “标量索引”是在 GPU 数组上迭代的地方，这会非常慢，实际上只允许在交互式 REPL 会话中使用。如果没有在 `initialize!()` 函数中包含
    if-语句，那么如果你在 GPU 上运行，`generate_field!()` 方法将会执行不允许的标量索引。
- en: The GPU-ported version is found below. Try it out on both CPU and GPU and observe
    the speedup. Play around with array size to see if the speedup is affected. You
    can also play around with the `xthreads` and `ythreads` variables to see if it
    changes anything.
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU 端口的版本见下文。在 CPU 和 GPU 上都试一试，观察速度提升。通过调整数组大小来查看速度提升是否受到影响。你还可以尝试调整 `xthreads`
    和 `ythreads` 变量，看看是否会有所改变。
- en: '[PRE52]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: See also
  id: totrans-466
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: This section leans heavily on source code and material created for several other
    computing workshops by [ENCCS](https://enccs.se/) and [CSC](https://csc.fi/) and
    adapted for the purposes of this lesson. If you want to know more about specific
    programming models / framework, definitely check these out!
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 本节大量借鉴了 [ENCCS](https://enccs.se/) 和 [CSC](https://csc.fi/) 为几个其他计算研讨会创建的源代码和材料，并为此课程的目的进行了改编。如果你想了解更多关于特定编程模型/框架的信息，请务必查看这些内容！
- en: '[OpenMP for GPU offloading](https://enccs.github.io/openmp-gpu/)'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenMP 用于 GPU 转移](https://enccs.github.io/openmp-gpu/)'
- en: '[Heterogeneous programming with SYCL](https://enccs.github.io/sycl-workshop/)'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 SYCL 进行异构编程](https://enccs.github.io/sycl-workshop/)'
- en: '[Educational implementation of heat flow example (incl. MPI-aware CUDA)](https://github.com/cschpc/heat-equation/)'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[热流示例的教育实现（包括 MPI-aware CUDA）](https://github.com/cschpc/heat-equation/)'
- en: 'Problem: heat flow in two-dimensional area'
  id: totrans-471
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题：二维区域的热流
- en: 'Heat flows in objects according to local temperature differences, as if seeking
    local equilibrium. The following example defines a rectangular area with two always-warm
    sides (temperature 70 and 85), two cold sides (temperature 20 and 5) and a cold
    disk at the center. Because of heat diffusion, temperature of neighboring patches
    of the area is bound to equalize, changing the overall distribution:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 热量在物体中根据局部温度差异流动，就像在寻求局部平衡。以下示例定义了一个矩形区域，其中有两个始终温暖的侧面（温度为 70 和 85），两个寒冷的侧面（温度为
    20 和 5）以及中心的一个寒冷圆盘。由于热量扩散，区域相邻区域的温度必然趋于平衡，从而改变整体分布：
- en: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/heat_montage.png](../Images/a35d1f1ff482677729c4a0e99db22510.png)'
- en: Over time, the temperature distribution progresses from the initial state toward
    an end state where upper triangle is warm and lower is cold. The average temperature
    tends to (70 + 85 + 20 + 5) / 4 = 45.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，温度分布从初始状态向最终状态发展，其中上三角区域温暖，下三角区域寒冷。平均温度趋于 (70 + 85 + 20 + 5) / 4 = 45。
- en: 'Technique: stencil computation'
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术：模板计算
- en: Heat transfer in the system above is governed by the partial differential equation(s)
    describing local variation of the temperature field in time and space. That is,
    the rate of change of the temperature field \(u(x, y, t)\) over two spatial dimensions
    \(x\) and \(y\) and time \(t\) (with rate coefficient \(\alpha\)) can be modelled
    via the equation
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的系统中的传热由描述时间和空间中温度场局部变化的偏微分方程（组）控制。也就是说，温度场 \(u(x, y, t)\) 在两个空间维度 \(x\) 和
    \(y\) 以及时间 \(t\)（速率系数为 \(\alpha\)）上的变化率可以通过以下方程进行建模
- en: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial u}{\partial t} = \alpha \left( \frac{\partial^2 u}{\partial
    x^2} + \frac{\partial^2 u}{\partial y^2}\right)\]
- en: The standard way to numerically solve differential equations is to *discretize*
    them, i. e. to consider only a set/ grid of specific area points at specific moments
    in time. That way, partial derivatives \({\partial u}\) are converted into differences
    between adjacent grid points \(u^{m}(i,j)\), with \(m, i, j\) denoting time and
    spatial grid points, respectively. Temperature change in time at a certain point
    can now be computed from the values of neighboring points at earlier time; the
    same expression, called *stencil*, is applied to every point on the grid.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 数值求解微分方程的标准方法是**离散化**它们，即只考虑在特定时间点特定区域内的特定点集/网格。这样，偏导数 \({\partial u}\) 转换为相邻网格点
    \(u^{m}(i,j)\) 之间的差值，其中 \(m, i, j\) 分别表示时间和空间网格点。现在可以从较早时间点的邻近点的值计算某一点的温度随时间的变化；相同的表达式，称为**模板**，应用于网格上的每个点。
- en: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
  id: totrans-479
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/stencil.svg](../Images/1ff8eef868cbbc0909c826b5871f271f.png)'
- en: This simplified model uses an 8x8 grid of data in light blue in state \(m\),
    each location of which has to be updated based on the indicated 5-point stencil
    in yellow to move to the next time point \(m+1\).
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化的模型使用状态 \(m\) 中浅蓝色的 8x8 数据网格，每个位置都必须根据指示的黄色 5 点模板进行更新，以移动到下一个时间点 \(m+1\)。
- en: 'Question: stencil applications'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：模板应用
- en: Stencil computation is a common occurrence in solving numerical problems. Have
    you already encountered it? Can you think of a problem that could be formulated
    this way in your field / area of expertise?
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 模板计算在解决数值问题时很常见。你遇到过吗？你能想到在你的领域/专业领域内可以用这种方式表述的问题吗？
- en: Solution
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: One obvious choice is *convolution* operation, used in image processing to apply
    various filter kernels; in some contexts, “convolution” and “stencil” are used
    almost interchangeably. Other related use is for averaging/ pooling adjacent values.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的选择是**卷积**操作，在图像处理中用于应用各种滤波核；在某些情况下，“卷积”和“模板”几乎可以互换使用。其他相关用途是对相邻值的平均/池化。
- en: Technical considerations
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术考虑
- en: '**1\. How fast and/ or accurate can the solution be?**'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 解的速率和/或精度如何？**'
- en: Spatial resolution of the temperature field is controlled by the number/ density
    of the grid points. As the full grid update is required to proceed from one time
    point to the next, stencil computation is the main target of parallelization (on
    CPU or GPU).
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 温度场的空间分辨率由网格点的数量/密度控制。由于需要完整的网格更新才能从一个时间点推进到下一个，因此模板计算是并行化的主要目标（在 CPU 或 GPU
    上）。
- en: Moreover, in many cases the chosen time step cannot be arbitrarily large, otherwise
    the numerical differentiation will fail, and dense/ accurate grids imply small
    time steps (see inset below), which makes efficient spatial update even more important.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在许多情况下，选择的时间步长不能任意大，否则数值微分将失败，密集/精确的网格意味着时间步长较小（见下插图），这使得有效的空间更新变得更加重要。
- en: 'Optional: stencil expression and time-step limit'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：模板表达式和时间步长限制
- en: 'Differential equation shown above can be discretized using different schemes.
    For this example, temperature values at each grid point \(u^{m}(i,j)\) are updated
    from one time point (\(m\)) to the next (\(m+1\)), using the following expressions:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的微分方程可以使用不同的方案进行离散化。对于这个例子，每个网格点 \(u^{m}(i,j)\) 的温度值从一个时间点 (\(m\)) 更新到下一个
    (\(m+1\))，使用以下表达式：
- en: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
- en: where
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
- en: and \(\Delta x\), \(\Delta y\), \(\Delta t\) are step sizes in space and time,
    respectively.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 \(\Delta x\)、\(\Delta y\)、\(\Delta t\) 分别是空间和时间中的步长。
- en: Time-update schemes often have a limit on the maximum allowed time step \(\Delta
    t\). For the current scheme, it is equal to
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 时间更新方案通常对最大允许的时间步长 \(\Delta t\) 有限制。对于当前方案，它等于
- en: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
- en: '**2\. What to do with area boundaries?**'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 如何处理区域边界？**'
- en: Naturally, stencil expression can’t be applied directly to the outermost grid
    points that have no outer neighbors. This can be solved by either changing the
    expression for those points or by adding an additional layer of grid that is used
    in computing update, but not updated itself – points of fixed temperature for
    the sides are being used in this example.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，模板表达式不能直接应用于没有外部邻居的最外层网格点。这可以通过改变这些点的表达式或添加一个额外的网格层来解决，该网格层用于计算更新，但自身不更新——在这个例子中，用于边界的固定温度点正在被使用。
- en: '**3\. How could the algorithm be optimized further?**'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 如何进一步优化算法？**'
- en: In [an earlier episode](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations),
    importance of efficient memory access was already stressed. In the following examples,
    each grid point (and its neighbors) is treated mostly independently; however,
    this also means that for 5-point stencil each value of the grid point may be read
    up to 5 times from memory (even if it’s the fast GPU memory). By rearranging the
    order of mathematical operations, it may be possible to reuse these values in
    a more efficient way.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [早期的一集](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations)
    中，已经强调了高效内存访问的重要性。在以下示例中，每个网格点（及其邻居）主要被独立处理；然而，这也意味着对于5点模板，每个网格点的值可能最多从内存中读取5次（即使它是快速的GPU内存）。通过重新排列数学运算的顺序，可能以更有效的方式重用这些值。
- en: Another point to note is that even if the solution is propagated in small time
    steps, not every step might actually be needed for output. Once some *local* region
    of the field is updated, mathematically nothing prevents it from being updated
    for the second time step – even if the rest of the field is still being recalculated
    – as long as \(t = m-1\) values for the region boundary are there when needed.
    (Of course, this is more complicated to implement and would only give benefits
    in certain cases.)
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，即使解是在小时间步长中传播的，也不一定每个步骤都需要输出。一旦某个 *局部* 区域的场被更新，数学上没有任何东西阻止它在第二次时间步中再次被更新——即使其余的场仍在重新计算——只要在需要时该区域的边界
    \(t = m-1\) 值存在。（当然，这更难实现，并且只有在某些情况下才会带来好处。）
- en: 'The following table will aid you in navigating the rest of this section:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格将帮助您导航本节的其余部分：
- en: Episode guide
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 播放指南
- en: '[Sequential and OpenMP-threaded code](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    in C++, including compilation/ running instructions'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顺序和OpenMP线程代码](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    在C++中，包括编译/运行说明'
- en: '[Naive GPU parallelization](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps),
    including SYCL compilation instructions'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单的GPU并行化](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps)，包括SYCL编译说明'
- en: '[GPU code with device data management](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)
    (OpenMP, SYCL)'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[具有设备数据管理的GPU代码](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)（OpenMP，SYCL）'
- en: '[Python implementation](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration),
    including running instructions on [Google Colab](https://colab.research.google.com/)'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 实现](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration)，包括在
    [Google Colab](https://colab.research.google.com/) 上的运行说明'
- en: '[Julia implementation](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration),
    including running instructions'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Julia 实现](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration)，包括运行说明'
- en: Technical considerations
  id: totrans-509
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 技术考虑因素
- en: '**1\. How fast and/ or accurate can the solution be?**'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 解的速度和/或精度如何？**'
- en: Spatial resolution of the temperature field is controlled by the number/ density
    of the grid points. As the full grid update is required to proceed from one time
    point to the next, stencil computation is the main target of parallelization (on
    CPU or GPU).
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 温度场的空间分辨率由网格点的数量/密度控制。由于需要完整的网格更新才能从一个时间点推进到下一个，因此模板计算是并行化的主要目标（在CPU或GPU上）。
- en: Moreover, in many cases the chosen time step cannot be arbitrarily large, otherwise
    the numerical differentiation will fail, and dense/ accurate grids imply small
    time steps (see inset below), which makes efficient spatial update even more important.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在许多情况下，选择的时间步长不能任意大，否则数值微分将失败，密集/精确的网格意味着时间步长较小（见下插图），这使得有效的空间更新变得更加重要。
- en: 'Optional: stencil expression and time-step limit'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：模板表达式和时间步长限制
- en: 'Differential equation shown above can be discretized using different schemes.
    For this example, temperature values at each grid point \(u^{m}(i,j)\) are updated
    from one time point (\(m\)) to the next (\(m+1\)), using the following expressions:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的微分方程可以使用不同的方案进行离散化。对于这个例子，每个网格点 \(u^{m}(i,j)\) 的温度值从一个时间点 (\(m\)) 更新到下一个
    (\(m+1\))，使用以下表达式：
- en: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: \[u^{m+1}(i,j) = u^m(i,j) + \Delta t \alpha \nabla^2 u^m(i,j) ,\]
- en: where
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split}\nabla^2 u &= \frac{u(i-1,j)-2u(i,j)+u(i+1,j)}{(\Delta x)^2}
    \\ &+ \frac{u(i,j-1)-2u(i,j)+u(i,j+1)}{(\Delta y)^2} ,\end{split}\]
- en: and \(\Delta x\), \(\Delta y\), \(\Delta t\) are step sizes in space and time,
    respectively.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 \(\Delta x\), \(\Delta y\), \(\Delta t\) 分别是空间和时间步长。
- en: Time-update schemes often have a limit on the maximum allowed time step \(\Delta
    t\). For the current scheme, it is equal to
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 时间更新方案通常对最大允许的时间步长 \(\Delta t\) 有限制。对于当前方案，它等于
- en: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: \[\Delta t_{max} = \frac{(\Delta x)^2 (\Delta y)^2}{2 \alpha ((\Delta x)^2 +
    (\Delta y)^2)}\]
- en: '**2\. What to do with area boundaries?**'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 如何处理区域边界？**'
- en: Naturally, stencil expression can’t be applied directly to the outermost grid
    points that have no outer neighbors. This can be solved by either changing the
    expression for those points or by adding an additional layer of grid that is used
    in computing update, but not updated itself – points of fixed temperature for
    the sides are being used in this example.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，模板表达式不能直接应用于最外层的网格点，这些点没有外部邻居。这可以通过改变这些点的表达式或添加一个额外的网格层来解决，该网格层用于计算更新，但自身不更新——在这个例子中，用于边界的固定温度点被使用。
- en: '**3\. How could the algorithm be optimized further?**'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 如何进一步优化算法？**'
- en: In [an earlier episode](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations),
    importance of efficient memory access was already stressed. In the following examples,
    each grid point (and its neighbors) is treated mostly independently; however,
    this also means that for 5-point stencil each value of the grid point may be read
    up to 5 times from memory (even if it’s the fast GPU memory). By rearranging the
    order of mathematical operations, it may be possible to reuse these values in
    a more efficient way.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [一个早期的情节](https://enccs.github.io/gpu-programming/7-non-portable-kernel-models/#memory-optimizations)
    中，已经强调了高效内存访问的重要性。在以下示例中，每个网格点（及其邻居）主要独立处理；然而，这也意味着对于5点模板，每个网格点的值可能从内存中读取多达5次（即使它是快速的GPU内存）。通过重新排列数学运算的顺序，可能以更有效的方式重用这些值。
- en: Another point to note is that even if the solution is propagated in small time
    steps, not every step might actually be needed for output. Once some *local* region
    of the field is updated, mathematically nothing prevents it from being updated
    for the second time step – even if the rest of the field is still being recalculated
    – as long as \(t = m-1\) values for the region boundary are there when needed.
    (Of course, this is more complicated to implement and would only give benefits
    in certain cases.)
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，即使解以小时间步传播，也不一定每个步骤都需要输出。一旦某个 *局部* 区域的场被更新，数学上没有任何阻止它第二次更新的东西——即使其余的场仍在重新计算——只要在需要时该区域的边界
    \(t = m-1\) 值存在。（当然，这更难实现，并且只有在某些情况下才会带来好处。）
- en: 'The following table will aid you in navigating the rest of this section:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 下表将帮助您导航本节的其余部分：
- en: Episode guide
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 情节指南
- en: '[Sequential and OpenMP-threaded code](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)
    in C++, including compilation/ running instructions'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[C++中的顺序和OpenMP线程代码](https://enccs.github.io/gpu-programming/13-examples/#sequential-and-thread-parallel-program-in-c)，包括编译/运行说明'
- en: '[Naive GPU parallelization](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps),
    including SYCL compilation instructions'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单的GPU并行化](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-first-steps)，包括SYCL编译说明'
- en: '[GPU code with device data management](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)
    (OpenMP, SYCL)'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带有设备数据管理的GPU代码](https://enccs.github.io/gpu-programming/13-examples/#gpu-parallelization-data-movement)（OpenMP，SYCL）'
- en: '[Python implementation](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration),
    including running instructions on [Google Colab](https://colab.research.google.com/)'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python实现](https://enccs.github.io/gpu-programming/13-examples/#python-jit-and-gpu-acceleration)，包括在[Google
    Colab](https://colab.research.google.com/)上的运行说明'
- en: '[Julia implementation](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration),
    including running instructions'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Julia实现](https://enccs.github.io/gpu-programming/13-examples/#julia-gpu-acceleration)，包括运行说明'
- en: Sequential and thread-parallel program in C++
  id: totrans-533
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C++中的顺序和线程并行程序
- en: Trying out code examples
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试代码示例
- en: 'Source files of the examples presented for the rest of this episode are available
    in the [content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)
    directory. To download them to your preferred directory on the cluster (f.e. `/scratch/project_<#>/<your_folder>/`),
    you can use Git:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 本集中展示的示例的源文件可在[content/examples/stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/)目录中找到。要将它们下载到集群上您偏好的目录（例如`/scratch/project_<#>/<your_folder>/`），您可以使用Git：
- en: '[PRE54]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Warning
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 警告
- en: Don’t forget to `git pull` for the latest updates if you already have the content
    from the first day of the workshop!
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经从研讨会第一天获得了内容，请不要忘记使用`git pull`获取最新更新！
- en: 'If we assume the grid point values to be truly independent *for a single time
    step*, stencil application procedure may be straightforwardly written as a loop
    over the grid points, as shown below in tab “Stencil update”. (General structure
    of the program and the default parameter values for the problem model are also
    provided for reference.) CPU-thread parallelism can then be enabled by a single
    OpenMP `#pragma`:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设网格点值在**单个时间步长**内真正独立，那么可以简单地将stencil应用过程编写为遍历网格点的循环，如下表“Stencil更新”所示。（程序的一般结构和问题模型默认参数值也提供供参考。）然后可以通过单个OpenMP
    `#pragma`启用CPU线程并行：
- en: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/base/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**core.cpp**'
  id: totrans-541
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.cpp**'
- en: '[PRE55]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '**main.cpp**'
  id: totrans-543
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**main.cpp**'
- en: '[PRE56]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '**heat.h**'
  id: totrans-545
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.h**'
- en: '[PRE57]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Optional: compiling the executables'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：编译可执行文件
- en: 'To compile executable files for the OpenMP-based variants, follow the instructions
    below:'
  id: totrans-548
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要编译基于OpenMP的可执行文件，请按照以下说明操作：
- en: '[PRE58]'
  id: totrans-549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Afterwards login into a compute node and test the executables (or just `srun
    <executable>` directly):'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 之后登录到计算节点并测试可执行文件（或直接使用`srun <executable>`）：
- en: '[PRE59]'
  id: totrans-551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该类似于以下内容：
- en: '[PRE60]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'CPU parallelization: timings'
  id: totrans-554
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU并行化：计时
- en: '(**NOTE**: for thread-parallel runs it is necessary to request multiple CPU
    cores. In LUMI-G partitions, this can be done by asking for multiple GPUs; an
    alternative is to use -C partitions.)'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: （**注意**：对于线程并行运行，需要请求多个CPU核心。在LUMI-G分区中，可以通过请求多个GPU来实现；另一种选择是使用-C分区。）
- en: 'For later comparison, some benchmarks of the OpenMP thread-parallel implementation
    are provided below:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 下面提供了一些OpenMP线程并行实现的基准测试，供后续比较：
- en: Run times of OpenMP-enabled executable, s
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 开启OpenMP功能的可执行程序的运行时间，s
- en: '| Job size | 1 CPU core | 32 CPU cores |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| 工作大小 | 1 CPU核心 | 32 CPU核心 |'
- en: '| --- | --- | --- |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S:2000 T:500 | 1.402 | 0.064 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.402 | 0.064 |'
- en: '| S:2000 T:5000 | 13.895 | 0.538 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:5000 | 13.895 | 0.538 |'
- en: '| S:2000 T:10000 | 27.753 | 1.071 |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:10000 | 27.753 | 1.071 |'
- en: '| S:4000 T:500 | 5.727 | 0.633 |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| S:4000 T:500 | 5.727 | 0.633 |'
- en: '| S:8000 T:500 | 24.130 | 16.616 |'
  id: totrans-564
  prefs: []
  type: TYPE_TB
  zh: '| S:8000 T:500 | 24.130 | 16.616 |'
- en: 'A closer look reveals that the computation time scales very nicely with increasing
    **time steps**:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察可以发现，计算时间随着**时间步长**的增加而非常理想地扩展：
- en: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
  id: totrans-566
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
- en: 'However, for larger **grid sizes** the parallelization becomes inefficient
    – as the individual chunks of the grid get too large to fit into CPU cache, threads
    become bound by the speed of RAM reads/writes:'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于更大的**网格大小**，并行化变得效率低下——因为网格的各个块变得太大，无法适应CPU缓存，线程的速度受到RAM读取/写入速度的限制：
- en: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
  id: totrans-568
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
- en: 'Discussion: heat flow computation scaling'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论：热流计算扩展
- en: How is heat flow computation **expected** to scale with respect to the number
    of time steps?
  id: totrans-570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何预期热流计算相对于时间步的数量进行扩展？
- en: Linearly
  id: totrans-571
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-572
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方
- en: Exponentially
  id: totrans-573
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数
- en: How is stencil application (grid update) **expected** to scale with respect
    to the size of the grid side?
  id: totrans-574
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何预期stencil应用（网格更新）相对于网格边长的大小进行扩展？
- en: Linearly
  id: totrans-575
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-576
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方
- en: Exponentially
  id: totrans-577
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数
- en: (Optional) Do you expect GPU-accelerated computations to follow the above-mentioned
    trends? Why/ why not?
  id: totrans-578
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）您预计GPU加速的计算会遵循上述趋势吗？为什么/为什么不？
- en: Solution
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The answer is a: since each time-step follows the previous one and involves
    a similar number of operations, then the update time per step will be more or
    less constant.'
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是a：由于每次时间步都遵循前一次，并且涉及相似数量的操作，因此每步的更新时间将大致保持不变。
- en: 'The answer is b: since stencil application is independent for every grid point,
    the update time will be proportional to the number of points, i.e. side * side.'
  id: totrans-581
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是b：由于每个网格点上的stencil应用都是独立的，更新时间将与点的数量成比例，即边长 * 边长。
- en: 'CPU parallelization: timings'
  id: totrans-582
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPU并行化：计时
- en: '(**NOTE**: for thread-parallel runs it is necessary to request multiple CPU
    cores. In LUMI-G partitions, this can be done by asking for multiple GPUs; an
    alternative is to use -C partitions.)'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: （**注意**：对于线程并行运行，需要请求多个CPU核心。在LUMI-G分区中，可以通过请求多个GPU来实现；另一种选择是使用-C分区。）
- en: 'For later comparison, some benchmarks of the OpenMP thread-parallel implementation
    are provided below:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 为了后续比较，以下提供了OpenMP线程并行实现的某些基准：
- en: Run times of OpenMP-enabled executable, s
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 启用OpenMP的可执行程序的运行时间，s
- en: '| Job size | 1 CPU core | 32 CPU cores |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
  zh: '| 工作大小 | 1 CPU核心 | 32 CPU核心 |'
- en: '| --- | --- | --- |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S:2000 T:500 | 1.402 | 0.064 |'
  id: totrans-588
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.402 | 0.064 |'
- en: '| S:2000 T:5000 | 13.895 | 0.538 |'
  id: totrans-589
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:5000 | 13.895 | 0.538 |'
- en: '| S:2000 T:10000 | 27.753 | 1.071 |'
  id: totrans-590
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:10000 | 27.753 | 1.071 |'
- en: '| S:4000 T:500 | 5.727 | 0.633 |'
  id: totrans-591
  prefs: []
  type: TYPE_TB
  zh: '| S:4000 T:500 | 5.727 | 0.633 |'
- en: '| S:8000 T:500 | 24.130 | 16.616 |'
  id: totrans-592
  prefs: []
  type: TYPE_TB
  zh: '| S:8000 T:500 | 24.130 | 16.616 |'
- en: 'A closer look reveals that the computation time scales very nicely with increasing
    **time steps**:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察发现，计算时间随着时间步的增加而非常理想地扩展：
- en: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
  id: totrans-594
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-step.png](../Images/810309a3883969c1640d34255f4ed61e.png)'
- en: 'However, for larger **grid sizes** the parallelization becomes inefficient
    – as the individual chunks of the grid get too large to fit into CPU cache, threads
    become bound by the speed of RAM reads/writes:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于更大的**网格大小**，并行化变得效率低下——因为网格的各个块变得太大，无法适应CPU缓存，线程的速度受到RAM读取/写入速度的限制：
- en: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
  id: totrans-596
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-scaling-grid.png](../Images/d7b5dbdf6c5a48df4e9ebdf5ce5a9322.png)'
- en: 'Discussion: heat flow computation scaling'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论：热流计算扩展
- en: How is heat flow computation **expected** to scale with respect to the number
    of time steps?
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何预期热流计算相对于时间步的数量进行扩展？
- en: Linearly
  id: totrans-599
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-600
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方
- en: Exponentially
  id: totrans-601
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数
- en: How is stencil application (grid update) **expected** to scale with respect
    to the size of the grid side?
  id: totrans-602
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何预期stencil应用（网格更新）相对于网格边长的大小进行扩展？
- en: Linearly
  id: totrans-603
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性
- en: Quadratically
  id: totrans-604
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二次方
- en: Exponentially
  id: totrans-605
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数
- en: (Optional) Do you expect GPU-accelerated computations to follow the above-mentioned
    trends? Why/ why not?
  id: totrans-606
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）您预计GPU加速的计算会遵循上述趋势吗？为什么/为什么不？
- en: Solution
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'The answer is a: since each time-step follows the previous one and involves
    a similar number of operations, then the update time per step will be more or
    less constant.'
  id: totrans-608
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是a：由于每次时间步都遵循前一次，并且涉及相似数量的操作，因此每步的更新时间将大致保持不变。
- en: 'The answer is b: since stencil application is independent for every grid point,
    the update time will be proportional to the number of points, i.e. side * side.'
  id: totrans-609
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是b：由于每个网格点上的stencil应用都是独立的，更新时间将与点的数量成比例，即边长 * 边长。
- en: 'GPU parallelization: first steps'
  id: totrans-610
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU并行化：第一步
- en: Let’s apply several techniques presented in previous episodes to make stencil
    update run on GPU.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用之前几集中介绍的一些技术，使 stencil 更新在 GPU 上运行。
- en: OpenMP (or OpenACC) offloading requires to define a region to be executed in
    parallel as well as data that shall be copied over/ used in GPU memory. Similarly,
    SYCL programming model offers convenient ways to define execution kernels, as
    well as context to run them in (called queue).
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP（或 OpenACC）卸载需要定义一个要并行执行的区域以及要复制到/在 GPU 内存中使用的数据。同样，SYCL 编程模型提供了方便的方式来定义执行内核，以及运行它们的环境（称为队列）。
- en: 'Changes of stencil update code for OpenMP and SYCL are shown in the tabs below:'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 下面选项卡中显示了 OpenMP 和 SYCL 的 stencil 更新代码的变化：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-off.cpp**'
  id: totrans-615
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-off.cpp**'
- en: '[PRE61]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '**sycl/core-naive.cpp**'
  id: totrans-617
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core-naive.cpp**'
- en: '[PRE62]'
  id: totrans-618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Loading SYCL modules on LUMI
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LUMI 上加载 SYCL 模块
- en: 'As SYCL is placed on top of ROCm/HIP (or CUDA) software stack, running SYCL
    executables may require respective modules to be loaded. On current nodes, it
    can be done as follows:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 SYCL 位于 ROCm/HIP（或 CUDA）软件堆栈之上，运行 SYCL 可执行文件可能需要加载相应的模块。在当前节点上，可以按以下方式完成：
- en: '[PRE63]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Optional: compiling the SYCL executables'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 可选：编译 SYCL 可执行文件
- en: 'As previously, you are welcome to generate your own executables:'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，欢迎你生成自己的可执行文件：
- en: '[PRE64]'
  id: totrans-624
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'If everything works well, the output should look similar to this:'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，输出应该类似于以下内容：
- en: '[PRE65]'
  id: totrans-626
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Exercise: naive GPU ports'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：简单的 GPU 端口
- en: 'Test your compiled executables `base/stencil`, `base/stencil_off` and `sycl/stencil_naive`.
    Try changing problem size parameters:'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 测试你编译的可执行文件 `base/stencil`、`base/stencil_off` 和 `sycl/stencil_naive`。尝试更改问题大小参数：
- en: '`srun stencil_naive 2000 2000 5000`'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil_naive 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 要注意的事项：
- en: How computation times change?
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间如何变化？
- en: Do the results align to your expectations?
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果是否符合你的预期？
- en: Solution
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'You might notice that the GPU-“ported” versions actually run slower than the
    single-CPU-core version! In fact, the scaling behavior of all three variants is
    similar and expected, which is a good sign; only the “computation unit cost” is
    different. You can compare benchmark summaries in the tabs below:'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，GPU-“移植”版本实际上比单核 CPU 版本运行得更慢！实际上，所有三个变体的扩展行为都是相似且预期的，这是一个好兆头；只是“计算单元成本”不同。你可以在下面的选项卡中比较基准摘要：
- en: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
  id: totrans-635
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/cpu-seq-scaling.png](../Images/f914c858f1d0af184a01a3be041bc986.png)![../_images/omp-gpu-naive-scaling.png](../Images/60ce6615dd04e25662bd6cce1bee82bf.png)![../_images/omp-sycl-naive-scaling-new.png](../Images/6983096d4b59ed832c9bc3fae5a9e4e0.png)'
- en: 'GPU parallelization: data movement'
  id: totrans-636
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 并行化：数据移动
- en: Why the porting approach above seems to be quite inefficient?
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么上述移植方法似乎效率很低？
- en: 'On each step, we:'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，我们：
- en: re-allocate GPU memory,
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新分配 GPU 内存，
- en: copy the data from CPU to GPU,
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据从 CPU 复制到 GPU，
- en: perform the computation,
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行计算，
- en: then copy the data back.
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后将数据复制回。
- en: 'But overhead can be reduced by taking care to minimize data transfers between
    *host* and *device* memory:'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 但可以通过尽量减少主机和设备内存之间的数据传输来减少开销：
- en: allocate GPU memory once at the start of the program,
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在程序开始时一次性分配 GPU 内存，
- en: only copy the data from GPU to CPU when we need it,
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只在我们需要时从 GPU 复制数据到 CPU，
- en: swap the GPU buffers between timesteps, like we do with CPU buffers. (OpenMP
    does this automatically.)
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间步之间交换 GPU 缓冲区，就像我们处理 CPU 缓冲区一样。（OpenMP 会自动执行此操作。）
- en: 'Changes of stencil update code are shown in tabs below (also check out the
    respective main() functions for calls to persistent GPU buffer creation, access,
    and deletion):'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 下面选项卡中显示了 stencil 更新代码的变化（还可以查看相应的 main() 函数以检查持久 GPU 缓冲区创建、访问和删除的调用）：
- en: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/base/)'
- en: '**base/core-data.cpp**'
  id: totrans-649
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**base/core-data.cpp**'
- en: '[PRE66]'
  id: totrans-650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '**sycl/core.cpp**'
  id: totrans-651
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**sycl/core.cpp**'
- en: '[PRE67]'
  id: totrans-652
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Exercise: updated GPU ports'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：更新 GPU 端口
- en: 'Test your compiled executables `base/stencil_data` and `sycl/stencil_data`.
    Try changing problem size parameters:'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 测试你编译的可执行文件 `base/stencil_data` 和 `sycl/stencil_data`。尝试更改问题大小参数：
- en: '`srun stencil 2000 2000 5000`'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun stencil 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 要注意的事项：
- en: How computation times change this time around?
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这次计算时间如何变化？
- en: What largest grid and/or longest propagation time can you get in 10 s on your
    machine?
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的机器上，10秒内可以获得最大的网格大小和/或最长的传播时间是多少？
- en: Solution
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: Using GPU offloading with mapped device data, it is possible to achieve performance
    gains compared to thread-parallel version for larger grid sizes, due to the fact
    that the latter version becomes essentially RAM-bound, but the former does not.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有映射设备数据的 GPU 卸载，对于较大的网格大小，与线程并行版本相比可以实现性能提升，因为后者版本本质上受到 RAM 的限制，而前者则没有。
- en: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
  id: totrans-661
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/omp-cpu-vs-gpu.png](../Images/cb5974969100b722e87051a97d144b8c.png)'
- en: Below you can find the summary graphs for step- and grid- scaling of the stencil
    update task. Because of the more explicit programming approach, SYCL GPU port
    is much faster than OpenMP-offloaded version, comparable with thread-parallel
    CPU version running on all cores of a single node.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 下面您可以找到 stencil 更新任务步骤和网格缩放的总结图表。由于更明确的编程方法，SYCL GPU 端口比 OpenMP 卸载版本快得多，与在单个节点所有核心上运行的线程并行
    CPU 版本相当。
- en: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
  id: totrans-663
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/summary-scaling-step-new.png](../Images/6704bb2fd89cb6e760535f15dfc6af72.png)![../_images/summary-scaling-grid-new.png](../Images/f60d760b3af83514c7a5865edfae846d.png)'
- en: 'Python: JIT and GPU acceleration'
  id: totrans-664
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python：JIT 和 GPU 加速
- en: 'As mentioned [previously](https://enccs.github.io/gpu-programming/9-language-support/#numba),
    Numba package allows developers to just-in-time (JIT) compile Python code to run
    fast on CPUs, but can also be used for JIT compiling for (NVIDIA) GPUs. JIT seems
    to work well on loop-based, computationally heavy functions, so trying it out
    is a nice choice for initial source version:'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述 [之前](https://enccs.github.io/gpu-programming/9-language-support/#numba)，Numba
    包允许开发者即时（JIT）编译 Python 代码以在 CPU 上快速运行，但也可以用于为（NVIDIA）GPU 进行 JIT 编译。JIT 在基于循环、计算密集型函数上似乎表现良好，因此尝试它是一个不错的选择，对于初始源版本：
- en: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '[stencil/python-numba](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/python-numba/)'
- en: '**core.py**'
  id: totrans-667
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core.py**'
- en: '[PRE68]'
  id: totrans-668
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '**heat.py**'
  id: totrans-669
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**heat.py**'
- en: '[PRE69]'
  id: totrans-670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '**core_cuda.py**'
  id: totrans-671
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**core_cuda.py**'
- en: '[PRE70]'
  id: totrans-672
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The alternative approach would be to rewrite stencil update code in NumPy style,
    exploiting loop vectorization.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用 NumPy 风格重写 stencil 更新代码，利用循环向量化。
- en: Trying out Python examples
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试 Python 示例
- en: You can run follow the links below for instructions from the [Setup](../0-setup/)
    episode. You may choose to run the provided code examples either on
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下链接获取从 [设置](../0-setup/) 集的说明。您可以选择在提供的代码示例上运行
- en: on a [LUMI GPU node](../0-setup/#setup-python-lumi-gpu), or
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个 [LUMI GPU 节点](../0-setup/#setup-python-lumi-gpu)上，或者
- en: your local machine, or [LUMI CPU node](../0-setup/#setup-python-lumi-cpu), or
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的本地机器，或者 [LUMI CPU 节点](../0-setup/#setup-python-lumi-cpu)，或者
- en: '[Google Colab](../0-setup/#setup-google-colab).'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google Colab](../0-setup/#setup-google-colab).'
- en: To run the example in a GPU node via the container,
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过容器在 GPU 节点上运行示例，
- en: '[PRE71]'
  id: totrans-680
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: To run the example in a CPU node,
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 CPU 节点上运行示例，
- en: '[PRE72]'
  id: totrans-682
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Short summary of a typical Colab run is provided below:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 下面提供了一个典型的 Colab 运行的简要总结：
- en: Run times of Numba JIT-enabled Python program, s
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: Numba JIT 启用的 Python 程序的运行时间，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | Job size | no JIT (Colab) |'
  id: totrans-685
  prefs: []
  type: TYPE_TB
  zh: '| Job size | JIT (LUMI) | JIT (Colab) | Job size | no JIT (Colab) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-686
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
  id: totrans-687
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | S:200 T:50 | 5.318 |'
- en: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
  id: totrans-688
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:200 | 0.787 | 3.524 | S:200 T:20 | 1.859 |'
- en: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
  id: totrans-689
  prefs: []
  type: TYPE_TB
  zh: '| S:1000 T:500 | 0.547 | 2.230 | S:100 T:50 | 1.156 |'
- en: Numba’s `@vectorize` and `@guvectorize` decorators offer an interface to create
    CPU- (or GPU-) accelerated *Python* functions without explicit implementation
    details. However, such functions become increasingly complicated to write (and
    optimize by the compiler) with increasing complexity of the computations within.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 的 `@vectorize` 和 `@guvectorize` 装饰器提供了一个接口来创建无需显式实现细节的 CPU-（或 GPU-）加速
    *Python* 函数。然而，随着计算复杂性的增加，此类函数的编写（以及由编译器优化）变得越来越复杂。
- en: Numba also offers direct CUDA-based kernel programming, which can be the best
    choice for those already familiar with CUDA. Example for stencil update written
    in Numba CUDA is shown in the above section, tab “Stencil update in GPU”. In this
    case, data transfer functions `devdata = cuda.to_device(data)` and `devdata.copy_to_host(data)`
    (see `main_cuda.py`) are already provided by Numba package.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: Numba 还提供了基于 CUDA 的直接内核编程，对于那些已经熟悉 CUDA 的人来说，这可能是一个最佳选择。上面章节中展示了用 Numba CUDA
    编写的 stenciling 更新示例，在“GPU 中的 stenciling 更新”标签页中。在这种情况下，数据传输函数 `devdata = cuda.to_device(data)`
    和 `devdata.copy_to_host(data)`（见 `main_cuda.py`）已由 Numba 包提供。
- en: 'Exercise: CUDA acceleration in Python'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：Python 中的 CUDA 加速
- en: 'Using Google Colab (or your own machine), run provided Numba-CUDA Python program.
    Try changing problem size parameters:'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Google Colab（或你自己的机器），运行提供的 Numba-CUDA Python 程序。尝试更改问题大小参数：
- en: '`args.rows, args.cols, args.nsteps = 2000, 2000, 5000` for notebooks,'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 笔记本中 `args.rows, args.cols, args.nsteps = 2000, 2000, 5000`
- en: '[`srun`] `python3 main.py 2000 2000 5000` for command line.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srun` 命令用于命令行：`python3 main.py 2000 2000 5000`'
- en: 'Things to look for:'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 需要关注的事项：
- en: How computation times change?
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时间是如何变化的？
- en: Do you get better performance than from JIT-compiled CPU version? How far can
    you push the problem size?
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否比 JIT 编译的 CPU 版本获得了更好的性能？你可以将问题大小推到多远？
- en: Are you able to monitor the GPU usage?
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能否监控 GPU 使用情况？
- en: Solution
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'Some numbers from Colab:'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 一些来自 Colab 的数字：
- en: Run times of Numba CUDA Python program, s
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: Numba CUDA Python 程序的运行时间，s
- en: '| Job size | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
  id: totrans-703
  prefs: []
  type: TYPE_TB
  zh: '| Job size | JIT (LUMI) | JIT (Colab) | CUDA (Colab) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-704
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
  id: totrans-705
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:500 | 1.648 | 8.495 | 1.079 |'
- en: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
  id: totrans-706
  prefs: []
  type: TYPE_TB
  zh: '| S:2000 T:2000 | 6.133 | 36.61 | 3.931 |'
- en: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
  id: totrans-707
  prefs: []
  type: TYPE_TB
  zh: '| S:5000 T:500 | 9.478 | 57.19 | 6.448 |'
- en: Julia GPU acceleration
  id: totrans-708
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Julia GPU 加速
- en: A Julia version of the stencil example above can be found below (a simplified
    version of the HeatEquation module at [https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)).
    The source files are also available in the [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    directory of this repository.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的示例中，可以找到 Julia 版本的 stenciling 示例（[https://github.com/ENCCS/HeatEquation.jl](https://github.com/ENCCS/HeatEquation.jl)
    中 HeatEquation 模块的简化版本）。源文件也位于本仓库的 [content/examples/stencil/julia](https://github.com/ENCCS/gpu-programming/tree/main/content/examples/stencil/julia)
    目录中。
- en: 'To run the example on LUMI CPU partition, type:'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 LUMI CPU 分区上运行示例，请输入：
- en: '[PRE73]'
  id: totrans-711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: To run on the GPU partition, use instead the `srun` command
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 GPU 分区上运行，请使用 `srun` 命令
- en: '[PRE74]'
  id: totrans-713
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Optional dependency
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 可选依赖项
- en: Note that the `Plots.jl` dependency is commented out in `main.jl` and `Project.toml`.
    This saves ~2 minute precompilation time when you first instantiate the Julia
    environment. To generate plots, just uncomment the commented `Plots.jl` dependency
    in `Project.toml`, instantiate again, and import and use `Plots` in `main.jl`.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`main.jl` 和 `Project.toml` 中的 `Plots.jl` 依赖项已被注释掉。这在你首次实例化 Julia 环境时可以节省大约
    2 分钟的预编译时间。要生成绘图，只需在 `Project.toml` 中取消注释注释掉的 `Plots.jl` 依赖项，再次实例化，并在 `main.jl`
    中导入和使用 `Plots`。
- en: '[PRE75]'
  id: totrans-716
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-719
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Exercise: Julia port to GPUs'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 练习：将 Julia 端移植到 GPU
- en: 'Carefully inspect all Julia source files and consider the following questions:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细检查所有 Julia 源文件，并考虑以下问题：
- en: Which functions should be ported to run on GPU?
  id: totrans-722
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些函数应该移植到 GPU 上运行？
- en: Look at the `initialize!()` function and how it uses the `arraytype` argument.
    This could be done more compactly and elegantly, but this solution solves scalar
    indexing errors. What are scalar indexing errors?
  id: totrans-723
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看 `initialize!()` 函数以及它是如何使用 `arraytype` 参数的。这可以做得更紧凑和优雅，但这个解决方案解决了标量索引错误。什么是标量索引错误？
- en: Try to start sketching GPU-ported versions of the key functions.
  id: totrans-724
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试开始绘制关键函数的 GPU 端版本。
- en: When you have a version running on a GPU (your own or the solution provided
    below), try benchmarking it by adding `@btime` in front of `simulate!()` in `main.jl`.
    Benchmark also the CPU version, and compare.
  id: totrans-725
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你在 GPU 上（无论是自己的还是下面提供的解决方案）运行版本时，尝试通过在 `main.jl` 中的 `simulate!()` 前添加 `@btime`
    来对其进行基准测试。也要基准测试 CPU 版本，并进行比较。
- en: Hints
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: create a new function `evolve_gpu!()` which contains the GPU kernelized version
    of `evolve!()`
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新函数 `evolve_gpu!()`，它包含 `evolve!()` 的 GPU 核函数版本
- en: 'in the loop over timesteps in `simulate!()`, you will need a conditional like
    `if typeof(curr.data) <: ROCArray` to call your GPU-ported function'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 `simulate!()` 函数中对时间步长进行循环时，你需要一个条件语句，例如 `if typeof(curr.data) <: ROCArray`
    来调用你的 GPU 端函数'
- en: you cannot pass the struct `Field` to the kernel. You will instead need to directly
    pass the array `Field.data`. This also necessitates passing in other variables
    like `curr.dx^2`, etc.
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能将`Field`结构体传递给内核。相反，你需要直接传递数组`Field.data`。这也需要传递其他变量，如`curr.dx^2`等。
- en: More hints
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 更多提示
- en: since the data is two-dimensional, you’ll need `i = (blockIdx().x - 1) * blockDim().x
    + threadIdx().x` and `j = (blockIdx().y - 1) * blockDim().y + threadIdx().y`
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于数据是二维的，你需要`i = (blockIdx().x - 1) * blockDim().x + threadIdx().x`和`j = (blockIdx().y
    - 1) * blockDim().y + threadIdx().y`
- en: to not overindex the 2D array, you can use a conditional like `if i > 1 && j
    > 1 && i < nx+2 && j < ny+2`
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了不过度索引二维数组，你可以使用条件语句，如`if i > 1 && j > 1 && i < nx+2 && j < ny+2`
- en: when calling the kernel, you can set the number of threads and blocks like `xthreads
    = ythreads = 16` and `xblocks, yblocks = cld(curr.nx, xthreads), cld(curr.ny,
    ythreads)`, and then call it with, e.g., `@roc threads=(xthreads, ythreads) blocks
    = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)`.
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用内核时，你可以设置线程数和块数，例如`xthreads = ythreads = 16`和`xblocks, yblocks = cld(curr.nx,
    xthreads), cld(curr.ny, ythreads)`，然后使用，例如`@roc threads=(xthreads, ythreads) blocks
    = (xblocks, yblocks) evolve_rocm!(curr.data, prev.data, curr.dx^2, curr.dy^2,
    nx, ny, a, dt)`来调用它。
- en: Solution
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The `evolve!()` and `simulate!()` functions need to be ported. The `main.jl`
    file also needs to be updated to work with GPU arrays.
  id: totrans-735
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`evolve!()`和`simulate!()`函数需要移植。`main.jl`文件也需要更新，以便与GPU数组一起工作。'
- en: “Scalar indexing” is where you iterate over a GPU array, which would be excruciatingly
    slow and is indeed only allowed in interactive REPL sessions. Without the if-statements
    in the `initialize!()` function, the `generate_field!()` method would be doing
    disallowed scalar indexing if you were running on a GPU.
  id: totrans-736
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “标量索引”是指遍历GPU数组，这会非常慢，实际上仅在交互式REPL会话中允许这样做。如果没有在`initialize!()`函数中包含if语句，那么如果你在GPU上运行，`generate_field!()`方法将会进行不允许的标量索引。
- en: The GPU-ported version is found below. Try it out on both CPU and GPU and observe
    the speedup. Play around with array size to see if the speedup is affected. You
    can also play around with the `xthreads` and `ythreads` variables to see if it
    changes anything.
  id: totrans-737
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU移植版本见下文。在CPU和GPU上尝试它，观察速度提升。尝试调整数组大小，看看速度提升是否受到影响。你还可以尝试调整`xthreads`和`ythreads`变量，看看是否会有所改变。
- en: '[PRE79]'
  id: totrans-738
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-739
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: See also
  id: totrans-740
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: This section leans heavily on source code and material created for several other
    computing workshops by [ENCCS](https://enccs.se/) and [CSC](https://csc.fi/) and
    adapted for the purposes of this lesson. If you want to know more about specific
    programming models / framework, definitely check these out!
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 本节大量借鉴了[ENCCS](https://enccs.se/)和[CSC](https://csc.fi/)为其他几个计算工作坊创建的源代码和材料，并针对本课程进行了改编。如果你想了解更多关于特定编程模型/框架的信息，绝对应该查看这些内容！
- en: '[OpenMP for GPU offloading](https://enccs.github.io/openmp-gpu/)'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenMP for GPU offloading](https://enccs.github.io/openmp-gpu/)'
- en: '[Heterogeneous programming with SYCL](https://enccs.github.io/sycl-workshop/)'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用SYCL进行异构编程](https://enccs.github.io/sycl-workshop/)'
- en: '[Educational implementation of heat flow example (incl. MPI-aware CUDA)](https://github.com/cschpc/heat-equation/)*'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[教育性的热流示例实现（包括MPI感知CUDA）](https://github.com/cschpc/heat-equation/)*'
