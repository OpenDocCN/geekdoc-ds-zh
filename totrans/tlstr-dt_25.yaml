- en: 13  Generalized linear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://tellingstorieswithdata.com/13-ijaglm.html](https://tellingstorieswithdata.com/13-ijaglm.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Modeling](./12-ijalm.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[13  Generalized linear models](./13-ijaglm.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Chapman and Hall/CRC published this book in July 2023\. You can purchase that
    [here](https://www.routledge.com/Telling-Stories-with-Data-With-Applications-in-R/Alexander/p/book/9781032134772).'
  prefs: []
  type: TYPE_NORMAL
- en: This online version has some updates to what was printed. An online version
    that matches the print version is available [here](https://rohanalexander.github.io/telling_stories-published/).*  ***Prerequisites**
  prefs: []
  type: TYPE_NORMAL
- en: Read *Regression and Other Stories*, ([Gelman, Hill, and Vehtari 2020](99-references.html#ref-gelmanhillvehtari2020))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on Chapters 13 “Logistic regression” and 15 “Other generalized linear
    models”, which provide a detailed guide to generalized linear models.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Read *An Introduction to Statistical Learning with Applications in R*, ([James
    et al. [2013] 2021](99-references.html#ref-islr))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on Chapter 4 “Classification”, which is a complementary treatment of generalized
    linear models from a different perspective.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Read *We Gave Four Good Pollsters the Same Raw Data. They Had Four Different
    Results*, ([Cohn 2016](99-references.html#ref-cohn2016))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Details a situation in which different modeling choices, given the same dataset,
    result in different forecasts.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key concepts and skills**'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression can be generalized for alternative types of outcome variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression can be used when we have a binary outcome variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poisson regression can be used when we have an integer count outcome variable.
    A variant—negative binomial regression—is often also considered because the assumptions
    are less onerous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multilevel modeling is an approach that can allow us to make better use of our
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software and packages**'
  prefs: []
  type: TYPE_NORMAL
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boot` ([Canty and Ripley 2021](99-references.html#ref-boot); [Davison and
    Hinkley 1997](99-references.html#ref-bootii))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`broom.mixed` ([Bolker and Robinson 2022](99-references.html#ref-mixedbroom))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`collapse` ([Krantz 2023](99-references.html#ref-collapse))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataverse` ([Kuriwaki, Beasley, and Leeper 2023](99-references.html#ref-dataverse))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gutenbergr` ([Johnston and Robinson 2022](99-references.html#ref-gutenbergr))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`marginaleffects` ([Arel-Bundock 2023](99-references.html#ref-marginaleffects))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rstanarm` ([Goodrich et al. 2023](99-references.html#ref-citerstanarm))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidybayes` ([Kay 2022](99-references.html#ref-citetidybayes))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*## 13.1 Introduction'
  prefs: []
  type: TYPE_NORMAL
- en: Linear models, covered in [Chapter 12](12-ijalm.html), have evolved substantially
    over the past century. Francis Galton, mentioned in [Chapter 8](08-hunt.html),
    and others of his generation used linear regression in earnest in the late 1800s
    and early 1900s. Binary outcomes quickly became of interest and needed special
    treatment, leading to the development and wide adaption of logistic regression
    and similar methods in the mid-1900s ([Cramer 2003](99-references.html#ref-cramer2002origins)).
    The generalized linear model framework came into being, in a formal sense, in
    the 1970s with Nelder and Wedderburn ([1972](99-references.html#ref-nelder1972generalized)).
    Generalized linear models (GLMs) broaden the types of outcomes that are allowed.
    We still model outcomes as a linear function, but we are less constrained. The
    outcome can be anything in the exponential family, and popular choices include
    the logistic distribution and the Poisson distribution. For the sake of a completed
    story but turning to approaches that are beyond the scope of this book, a further
    generalization of GLMs is generalized additive models (GAMs) where we broaden
    the structure of the explanatory side. We still explain the outcome variable as
    an additive function of various bits and pieces, but those bits and pieces can
    be functions. This framework was proposed in the 1990s by Hastie and Tibshirani
    ([1990](99-references.html#ref-hastie1990generalized)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of generalized linear models, in this chapter we consider logistic,
    Poisson, and negative binomial regression. But we also explore a variant that
    is relevant to both linear models and generalized linear models: multilevel modeling.
    This is when we take advantage of some type of grouping that exists within our
    dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 13.2 Logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear regression is a useful way to better understand our data. But it assumes
    a continuous outcome variable that can take any number on the real line. We would
    like some way to use this same machinery when we cannot satisfy this condition.
    We turn to logistic and Poisson regression for binary and count outcome variables,
    respectively. They are still linear models, because the predictor variables enter
    in a linear fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression, and its close variants, are useful in a variety of settings,
    from elections ([Wang et al. 2015](99-references.html#ref-wang2015forecasting))
    through to horse racing ([Chellel 2018](99-references.html#ref-chellel2018gambler);
    [Bolton and Chapman 1986](99-references.html#ref-boltonruth)). We use logistic
    regression when the outcome variable is a binary outcome, such as 0 or 1, or “yes”
    or “no”. Although the presence of a binary outcome variable may sound limiting,
    there are a lot of circumstances in which the outcome either naturally falls into
    this situation or can be adjusted into it. For instance, win or lose, available
    or not available, support or not.
  prefs: []
  type: TYPE_NORMAL
- en: The foundation of this is the Bernoulli distribution. There is a certain probability,
    \(p\), of outcome “1” and the remainder, \(1-p\), for outcome “0”. We can use
    `rbinom()` with one trial (“size = 1”) to simulate data from the Bernoulli distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE2]*  *One reason to use logistic regression is that we will be modeling
    a probability, hence it will be bounded between 0 and 1\. With linear regression
    we may end up with values outside this. The foundation of logistic regression
    is the logit function:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mbox{logit}(x) = \log\left(\frac{x}{1-x}\right). \] This will transpose
    values between 0 and 1 onto the real line. For instance, `logit(0.1) = -2.2`,
    `logit(0.5) = 0`, and `logit(0.9) = 2.2` ([Figure 13.1](#fig-heyitslogit)). We
    call this the “link function”. It relates the distribution of interest in a generalized
    linear model to the machinery we use in linear models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f5d39fc643f7992f9884d37e4e47c1e8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: Example of the logit function for values between 0 and 1'
  prefs: []
  type: TYPE_NORMAL
- en: '13.2.1 Simulated example: day or night'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate logistic regression, we will simulate data on whether it is a
    weekday or weekend, based on the number of cars on the road. We will assume that
    on weekdays the road is busier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE4]*  *We can use `glm()` from base R to do a quick estimation. In this
    case we will try to work out whether it is a weekday or weekend, based on the
    number of cars we can see. We are interested in estimating [Equation 13.1](#eq-logisticexample):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mbox{Pr}(y_i=1) = \mbox{logit}^{-1}\left(\beta_0+\beta_1 x_i\right) \tag{13.1}\]
  prefs: []
  type: TYPE_NORMAL
- en: where \(y_i\) is whether it is a weekday and \(x_i\) is the number of cars on
    the road.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE6]*  *The estimated coefficient on the number of cars is 0.19\. The interpretation
    of coefficients in logistic regression is more complicated than linear regression
    as they relate to changes in the log-odds of the binary outcome. For instance,
    the estimate of 0.19 is the average change in the log-odds of it being a weekday
    with observing one extra car on the road. The coefficient is positive which means
    an increase. As it is non-linear, if we want to specify a particular change, then
    this will be different for different baseline levels of the observation. That
    is, an increase of 0.19 log-odds has a larger impact when the baseline log-odds
    are 0, compared to 2.'
  prefs: []
  type: TYPE_NORMAL
- en: We can translate our estimate into the probability of it being a weekday, for
    a given number of cars. We can add the implied probability that it is a weekday
    for each observation using `predictions()` from `marginaleffects`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE8]*  *And we can then graph the probability that our model implies, for
    each observation, of it being a weekday ([Figure 13.2](#fig-dayornightprobs)).
    This is a nice opportunity to consider a few different ways of illustrating the
    fit. While it is common to use a scatterplot ([Figure 13.2 (a)](#fig-dayornightprobs-1)),
    this is also an opportunity to use an ECDF ([Figure 13.2 (b)](#fig-dayornightprobs-2)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e05a463cebe8d858d5c0232f7451d936.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Illustrating the fit with a scatterplot
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f55673a973373e12b85fecb248a6cea9.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Illustrating the fit with an ECDF
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.2: Logistic regression probability results with simulated data of
    whether it is a weekday or weekend based on the number of cars that are around'
  prefs: []
  type: TYPE_NORMAL
- en: The marginal effect at each observation is of interest because it provides a
    sense of how this probability is changing. It enables us to say that at the median
    (which in this case is if we were to see 50 cars) the probability of it being
    a weekday increases by almost five per cent if we were to see another car ([Table 13.1](#tbl-marginaleffectcar)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.1: Marginal effect of another car on the probability that it is a
    weekday, at the median'
  prefs: []
  type: TYPE_NORMAL
- en: '| Term | Estimate | Standard error |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| num_cars | 0.047 | 0.004 |*  *To more thoroughly examine the situation we
    might want to build a Bayesian model using `rstanarm`. As in [Chapter 12](12-ijalm.html)
    we will specify priors for our model, but these will just be the default priors
    that `rstanarm` uses:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\pi_i & \sim \mbox{Bern}(\pi_i) \\ \mbox{logit}(\pi_i)
    & = \beta_0+\beta_1 x_i \\ \beta_0 & \sim \mbox{Normal}(0, 2.5)\\ \beta_1 & \sim
    \mbox{Normal}(0, 2.5) \end{aligned} \] where \(y_i\) is whether it is a weekday
    (actually 0 or 1), \(x_i\) is the number of cars on the road, and \(\pi_i\) is
    the probability that observation \(i\) is a weekday.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*The results of our Bayesian model are similar to the quick model we built
    using base ([Table 13.2](#tbl-modelsummarylogistic)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.2: Explaining whether it is day or night, based on the number of
    cars on the road'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Day or night |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | -9.464 |'
  prefs: []
  type: TYPE_TB
- en: '| number_of_cars | 0.186 |'
  prefs: []
  type: TYPE_TB
- en: '| Num.Obs. | 1000 |'
  prefs: []
  type: TYPE_TB
- en: '| R2 | 0.779 |'
  prefs: []
  type: TYPE_TB
- en: '| Log.Lik. | -177.899 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD | -179.8 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD s.e. | 13.9 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC | 359.6 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC s.e. | 27.9 |'
  prefs: []
  type: TYPE_TB
- en: '| WAIC | 359.6 |'
  prefs: []
  type: TYPE_TB
- en: '| RMSE | 0.24 |*  *[Table 13.2](#tbl-modelsummarylogistic) makes it clear that
    each of the approaches is similar in this case. They agree on the direction of
    the effect of seeing an extra car on the probability of it being a weekday. Even
    the magnitude of the effect is estimated to be similar.*******  ***### 13.2.2
    Political support in the United States'
  prefs: []
  type: TYPE_NORMAL
- en: One area where logistic regression is often used is political polling. In many
    cases voting implies the need for one preference ranking, and so issues are reduced,
    whether appropriately or not, to “support” or “not support”.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a reminder, the workflow we advocate in this book is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\mbox{Plan} \rightarrow \mbox{Simulate} \rightarrow \mbox{Acquire} \rightarrow
    \mbox{Explore} \rightarrow \mbox{Share}\]
  prefs: []
  type: TYPE_NORMAL
- en: While the focus here is the exploration of data using models, we still need
    to do the other aspects. We begin by planning. In this case, we are interested
    in US political support. In particular we are interested in whether we can forecast
    who a respondent is likely to vote for, based only on knowing their highest level
    of education and gender. That means we are interested in a dataset with variables
    for who an individual voted for, and some of their characteristics, such as gender
    and education. A quick sketch of such a dataset is [Figure 13.3 (a)](#fig-uspoliticalsupportsketch).
    We would like our model to average over these points. A quick sketch is [Figure 13.3
    (b)](#fig-uspoliticalsupportmodel).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47606870e19f3d58d654b4c5de3c0ad0.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Quick sketch of a dataset that could be used to examine US political support
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5074e2a953ed039df2d4ecbe7bef8caa.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Quick sketch of what we expect from the analysis before finalizing either
    the data or the analysis
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.3: Sketches of the expected dataset and analysis focus and clarify
    our thinking even if they will be updated later'
  prefs: []
  type: TYPE_NORMAL
- en: We will simulate a dataset where the chance that a person supports Biden depends
    on their gender and education.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*For the actual data we can use the 2020 Cooperative Election Study (CES) ([Schaffner,
    Ansolabehere, and Luks 2021](99-references.html#ref-cooperativeelectionstudyus)).
    This is a long-standing annual survey of US political opinion. In 2020, there
    were 61,000 respondents who completed the post-election survey. The sampling methodology,
    detailed in Ansolabehere, Schaffner, and Luks ([2021, 13](99-references.html#ref-guidetothe2020ces)),
    relies on matching and is an accepted approach that balances sampling concerns
    and cost.'
  prefs: []
  type: TYPE_NORMAL
- en: We can access the CES using `get_dataframe_by_name()` after installing and loading
    `dataverse`. This approach was introduced in [Chapter 7](07-gather.html) and [Chapter
    10](10-store_and_share.html). We save the data that are of interest to us, and
    then refer to that saved dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE15]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE16]'
  prefs: []
  type: TYPE_NORMAL
- en: When we look at the actual data, there are concerns that we did not anticipate
    in our sketches. We use the codebook to investigate this more thoroughly. We only
    want respondents who are registered to vote, and we are only interested in those
    that voted for either Biden or Trump. We see that when the variable “CC20_410”
    is 1, then this means the respondent supported Biden, and when it is 2 that means
    Trump. We can filter to only those respondents and then add more informative labels.
    Genders of “female” and “male” is what is available from the CES, and when the
    variable “gender” is 1, then this means “male”, and when it is 2 this means “females”.
    Finally, the codebook tells us that “educ” is a variable from 1 to 6, in increasing
    levels of education.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*In the end we are left with 43,554 respondents ([Figure 13.4](#fig-cesissogooditslikecheating)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/1a65322dd28d0dc6bb4d9b43fadbf31c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.4: The distribution of presidential preferences, by gender, and highest
    education*  *The model that we are interested in is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\pi_i & \sim \mbox{Bern}(\pi_i) \\ \mbox{logit}(\pi_i)
    & = \beta_0+\beta_1 \times \mbox{gender}_i + \beta_2 \times \mbox{education}_i
    \\ \beta_0 & \sim \mbox{Normal}(0, 2.5)\\ \beta_1 & \sim \mbox{Normal}(0, 2.5)\\
    \beta_2 & \sim \mbox{Normal}(0, 2.5) \end{aligned} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(y_i\) is the political preference of the respondent and equal to 1 if
    Biden and 0 if Trump, \(\mbox{gender}_i\) is the gender of the respondent, and
    \(\mbox{education}_i\) is the education of the respondent. We could estimate the
    parameters using `stan_glm()`. Note that the model is a generally accepted short-hand.
    In practice `rstanarm` converts categorical variables into a series of indicator
    variables and there are multiple coefficients estimated. In the interest of run-time
    we will randomly sample 1,000 observations and fit the model on that, rather than
    the full dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE20]'
  prefs: []
  type: TYPE_NORMAL
- en: '*The results of our model are interesting. They suggest males were less likely
    to vote for Biden, and that there is a considerable effect of education ([Table 13.3](#tbl-modelsummarylogisticpolitical)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.3: Whether a respondent is likely to vote for Biden based on their
    gender and education'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Support Biden |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | -0.745 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.517) |'
  prefs: []
  type: TYPE_TB
- en: '| genderMale | -0.477 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.136) |'
  prefs: []
  type: TYPE_TB
- en: '| educationHigh school graduate | 0.617 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.534) |'
  prefs: []
  type: TYPE_TB
- en: '| educationSome college | 1.494 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.541) |'
  prefs: []
  type: TYPE_TB
- en: '| education2-year | 0.954 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.538) |'
  prefs: []
  type: TYPE_TB
- en: '| education4-year | 1.801 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.532) |'
  prefs: []
  type: TYPE_TB
- en: '| educationPost-grad | 1.652 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.541) |'
  prefs: []
  type: TYPE_TB
- en: '| Num.Obs. | 1000 |'
  prefs: []
  type: TYPE_TB
- en: '| R2 | 0.064 |'
  prefs: []
  type: TYPE_TB
- en: '| Log.Lik. | -646.335 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD | -653.5 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD s.e. | 9.4 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC | 1307.0 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC s.e. | 18.8 |'
  prefs: []
  type: TYPE_TB
- en: '| WAIC | 1307.0 |'
  prefs: []
  type: TYPE_TB
- en: '| RMSE | 0.48 |*  *It can be useful to plot the credibility intervals of these
    predictors ([Figure 13.5](#fig-modelplotlogisticpolitical)). In particular this
    might be something that is especially useful in an appendix.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/80b5ae52df44038377e0ab89dbe906d5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.5: Credible intervals for predictors of support for Biden*************  ***##
    13.3 Poisson regression'
  prefs: []
  type: TYPE_NORMAL
- en: When we have count data we should initially think to take advantage of the Poisson
    distribution. One application of Poisson regression is modeling the outcomes of
    sports. For instance Burch ([2023](99-references.html#ref-Burch2023)) builds a
    Poisson model of hockey outcomes, following Baio and Blangiardo ([2010](99-references.html#ref-Baio2010))
    who build a Poisson model of football outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Poisson distribution is governed by one parameter, \(\lambda\). This distributes
    probabilities over non-negative integers and hence governs the shape of the distribution.
    As such, the Poisson distribution has the interesting feature that the mean is
    also the variance. As the mean increases, so does the variance. The Poisson probability
    mass function is ([Pitman 1993, 121](99-references.html#ref-pitman)):'
  prefs: []
  type: TYPE_NORMAL
- en: \[P_{\lambda}(k) = e^{-\lambda}\lambda^k/k!\mbox{, for }k=0,1,2,\dots\] We can
    simulate \(n=20\) draws from the Poisson distribution with `rpois()`, where \(\lambda\)
    is equal to three.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE24]*  *We can also look at what happens to the distribution as we change
    the value of \(\lambda\) ([Figure 13.6](#fig-poissondistributiontakingshape)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/25ca792a6efd972f65a47e22e52c62b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.6: The Poisson distribution is governed by the value of the mean,
    which is the same as its variance'
  prefs: []
  type: TYPE_NORMAL
- en: '13.3.1 Simulated example: number of As by department'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate the situation, we could simulate data about the number of As that
    are awarded in each university course. In this simulated example, we consider
    three departments, each of which has many courses. Each course will award a different
    number of As.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE26]'
  prefs: []
  type: TYPE_NORMAL
- en: '*![](../Images/c40c20c68bb9b28a91f64cae0f9d5171.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.7: Simulated number of As in various classes across three departments*  *Our
    simulated dataset has the number of As awarded by courses, which are structured
    within departments ([Figure 13.7](#fig-simgradesdepartments)). In [Chapter 16](15-mrp.html),
    we will take advantage of this departmental structure, but for now we just ignore
    it and focus on differences between departments.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The model that we are interested in estimating is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\lambda_i &\sim \mbox{Poisson}(\lambda_i)\\ \log(\lambda_i)
    & = \beta_0 + \beta_1 \times \mbox{department}_i \end{aligned} \] where \(y_i\)
    is the number of A grades awarded, and we are interested in how this differs by
    department.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `glm()` from base R to get a quick sense of the data. This function
    is quite general, and we specify Poisson regression by setting the “family” parameter.
    The estimates are contained in the first column of [Table 13.4](#tbl-modelsummarypoisson).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE28]*  *As with logistic regression, the interpretation of the coefficients
    from Poisson regression can be difficult. The interpretation of the coefficient
    on “department2” is that it is the log of the expected difference between departments.
    We expect \(e^{0.883} \approx 2.4\) and \(e^{1.703} \approx 5.5\) as many A grades
    in departments 2 and 3, respectively, compared with department 1 ([Table 13.4](#tbl-modelsummarypoisson)).'
  prefs: []
  type: TYPE_NORMAL
- en: We could build a Bayesian model and estimate it with `rstanarm` ([Table 13.4](#tbl-modelsummarypoisson)).
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\lambda_i &\sim \mbox{Poisson}(\lambda_i)\\ \log(\lambda_i)
    & = \beta_0 + \beta_1 \times\mbox{department}_i\\ \beta_0 & \sim \mbox{Normal}(0,
    2.5)\\ \beta_1 & \sim \mbox{Normal}(0, 2.5) \end{aligned} \] where \(y_i\) is
    the number of As awarded.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*The results are in [Table 13.4](#tbl-modelsummarypoisson).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.4: Examining the number of A grades given in different departments'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Number of As |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | 1.321 |'
  prefs: []
  type: TYPE_TB
- en: '| department2 | 0.884 |'
  prefs: []
  type: TYPE_TB
- en: '| department3 | 1.706 |'
  prefs: []
  type: TYPE_TB
- en: '| Num.Obs. | 78 |'
  prefs: []
  type: TYPE_TB
- en: '| Log.Lik. | -193.355 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD | -196.2 |'
  prefs: []
  type: TYPE_TB
- en: '| ELPD s.e. | 7.7 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC | 392.4 |'
  prefs: []
  type: TYPE_TB
- en: '| LOOIC s.e. | 15.4 |'
  prefs: []
  type: TYPE_TB
- en: '| WAIC | 392.4 |'
  prefs: []
  type: TYPE_TB
- en: '| RMSE | 3.41 |*  *As with logistic regression, we can use `slopes()` from
    `marginaleffects` to help with interpreting these results. It may be useful to
    consider how we expect the number of A grades to change as we go from one department
    to another. [Table 13.5](#tbl-marginaleffectspoisson) suggests that in our dataset,
    classes in Department 2 tend to have around five additional A grades, compared
    with Department 1, and that classes in Department 3 tend to have around 17 more
    A grades, compared with Department 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.5: The estimated difference in the number of A grades awarded at
    each department'
  prefs: []
  type: TYPE_NORMAL
- en: '| Compare department | Estimate | 2.5% | 97.5% |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 - 1 | 5.32 | 4.01 | 6.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 - 1 | 16.92 | 15.1 | 18.84 |******  ***### 13.3.2 Letters used in *Jane
    Eyre*'
  prefs: []
  type: TYPE_NORMAL
- en: In an earlier age, Edgeworth ([1885](99-references.html#ref-edgeworth1885methods))
    made counts of the dactyls in Virgil’s *Aeneid* (Stigler ([1978, 301](99-references.html#ref-Stigler1978))
    provides helpful background and the dataset is available using `Dactyl` from `HistData`
    ([Friendly 2021](99-references.html#ref-HistData))). Inspired by this we could
    use `gutenbergr` to get the text of *Jane Eyre* by Charlotte Brontë. (Recall that
    in [Chapter 7](07-gather.html) we converted PDFs of *Jane Eyre* into a dataset.)
    We could then consider the first ten lines of each chapter, count the number of
    words, and count the number of times either “E” or “e” appears. We are interested
    to see whether the number of e/Es increases as more words are used. If not, it
    could suggest that the distribution of e/Es is not consistent, which could be
    of interest to linguists.
  prefs: []
  type: TYPE_NORMAL
- en: Following the workflow advocated in this book, we first sketch our dataset and
    model. A quick sketch of what the dataset could look like is [Figure 13.12 (a)](#fig-letterssketch),
    and a quick sketch of our model is [Figure 13.12 (b)](#fig-lettersmodel).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/436d9c367f7e4accbb32d62d4f5bb950.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Planned counts, by line and chapter, in *Jane Eyre*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/24fb289538534259885d2c7aaa6a7876.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Expected relationship between count of e/Es and number of words in the line
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.8: Sketches of the expected dataset and analysis force us to consider
    what we are interested in'
  prefs: []
  type: TYPE_NORMAL
- en: We simulate a dataset of how the number of e/Es could be distributed following
    the Poisson distribution ([Figure 13.9](#fig-simenum)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/8375100b284bbd8393b31e298ab42171.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.9: Simulated counts of e/Es*  *We can now gather and prepare our
    data. We download the text of the book from Project Gutenberg using `gutenberg_download()`
    from `gutenbergr`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '*We will download it and then use our local copy to avoid overly imposing on
    the Project Gutenberg servers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE35]'
  prefs: []
  type: TYPE_NORMAL
- en: We are interested in only those lines that have content, so we remove those
    empty lines that are just there for spacing. Then we can create counts of the
    number of e/Es in that line, for the first ten lines of each chapter. For instance,
    we can look at the first few lines and see that there are five e/Es in the first
    line and eight in the second.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE37]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE38]*  *We can verify that the mean and variance of the number of e/Es
    is roughly similar by plotting all of the data ([Figure 13.10](#fig-janeecounts)).
    The mean, in pink, is 6.7, and the variance, in blue, is 6.2\. While they are
    not entirely the same, they are similar. We include the diagonal in [Figure 13.10
    (b)](#fig-janeecounts-2) to help with thinking about the data. If the data were
    on the \(y=x\) line, then on average there would be one e/E per word. Given the
    mass of points below that line expect that on average there is less than one per
    word.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/d365b52ccb37988b7d289188e7fdd605.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Distribution of the number of e/Es
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70bde923d9bd1f0793291e3c7201272a.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Comparison of the number of e/Es in the line and the number of words in
    the line
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.10: Number of e/Es letters in the first ten lines of each chapter
    in Jane Eyre'
  prefs: []
  type: TYPE_NORMAL
- en: 'We could consider the following model:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\lambda_i &\sim \mbox{Poisson}(\lambda_i)\\ \log(\lambda_i)
    & = \beta_0 + \beta_1 \times \mbox{Number of words}_i\\ \beta_0 & \sim \mbox{Normal}(0,
    2.5)\\ \beta_1 & \sim \mbox{Normal}(0, 2.5) \end{aligned} \] where \(y_i\) is
    the number of e/Es in the line and the explanatory variable is the number of words
    in the line. We could estimate the model using `stan_glm()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '*While we would normally be interested in the table of estimates, as we have
    seen that a few times now, rather than again creating a table of the estimates,
    we introduce `plot_cap()` from `marginaleffects`. We can use this to show the
    number of e/Es predicted by the model, for each line, based on the number of words
    in that line. [Figure 13.11](#fig-predictionsjaneecounts) makes it clear that
    we expect a positive relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/7daece35a861e879fa4040d102858ef0.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.11: The predicted number of e/Es in each line based on the number
    of words************  ***## 13.4 Negative binomial regression'
  prefs: []
  type: TYPE_NORMAL
- en: One of the restrictions with Poisson regression is the assumption that the mean
    and the variance are the same. We can relax this assumption to allow over-dispersion
    by using a close variant, negative binomial regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Poisson and negative binomial models go hand in hand. It is often the case
    that we will end up fitting both, and then comparing them. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Maher ([1982](99-references.html#ref-maher1982modelling)) considers both in
    the context of results from the English Football League and discusses situations
    in which one may be considered more appropriate than the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smith ([2002](99-references.html#ref-thanksleo)) considers the 2000 US presidential
    election and especially the issue of overdispersion in a Poisson analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Osgood ([2000](99-references.html#ref-Osgood2000)) compares them in the case
    of crime data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 13.4.1 Mortality in Alberta, Canada
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Consider, somewhat morbidly, that every year each individual either dies or
    does not. From the perspective of a geographic area, we could gather data on the
    number of people who died each year, by their cause of death. The Canadian province
    of Alberta has made [available](https://open.alberta.ca/opendata/leading-causes-of-death)
    the number of deaths, by cause, since 2001, for the top 30 causes each year.
  prefs: []
  type: TYPE_NORMAL
- en: As always we first sketch our dataset and model. A quick sketch of what the
    dataset could look like is [Figure 13.12 (a)](#fig-albertadatasketch), and a quick
    sketch of our model is [Figure 13.12 (b)](#fig-albertamodelsketch)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1519d91972744065af259ab9e88bd9d0.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Quick sketch of a dataset that could be used to examine cause of death in
    Alberta
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b03ac43ca4ed8abc0c6869a700b7fde4.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Quick sketch of what we expect from the analysis of cause of death in Alberta
    before finalizing either the data or the analysis
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.12: Sketches of the expected dataset and analysis for cause of death
    in Alberta'
  prefs: []
  type: TYPE_NORMAL
- en: We will simulate a dataset of cause of death distributed following the negative
    binomial distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE43]*  *We can look at the distribution of these deaths, by year and cause
    ([Figure 13.13](#fig-albertacod)). We have truncated the full cause of death because
    some are quite long. As some causes are not always in the top 30 each year, not
    all causes have the same number of occurrences.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '*If we were to look at the top-ten causes in 2021, we would notice a variety
    of interesting aspects ([Table 13.6](#tbl-albertahuh)). For instance, we would
    expect that the most common causes would be present in all 21 years of our data.
    But we notice that the most common cause, “Other ill-defined and unknown causes
    of mortality”, is only in three years. “COVID-19, virus identified”, is only in
    two other years, as there were no known COVID deaths in Canada before 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.6: Top-ten causes of death in Alberta in 2021'
  prefs: []
  type: TYPE_NORMAL
- en: '| Year | Cause | Ranking | Deaths | Years |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Other ill-defined and unkno... | 1 | 3,362 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Organic dementia | 2 | 2,135 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | COVID-19, virus identified | 3 | 1,950 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | All other forms of chronic ... | 4 | 1,939 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Malignant neoplasms of trac... | 5 | 1,552 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Acute myocardial infarction | 6 | 1,075 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Other chronic obstructive p... | 7 | 1,028 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Diabetes mellitus | 8 | 728 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Stroke, not specified as he... | 9 | 612 | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| 2,021 | Accidental poisoning by and... | 10 | 604 | 9 |*  *For simplicity
    we restrict ourselves to the five most common causes of death in 2021 of those
    that have been present every year.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE47]'
  prefs: []
  type: TYPE_NORMAL
- en: '*![](../Images/d92459691acc3ba41750d6e97e6281a5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.13: Annual number of deaths for the top-five causes in 2021, since
    2001, for Alberta, Canada*  *One thing that we notice is that the mean, 1,273,
    is different to the variance, 182,378 ([Table 13.7](#tbl-ohboyalberta)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13.7: Summary statistics of the number of yearly deaths, by cause, in
    Alberta, Canada'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Min | Mean | Max | SD | Var | N |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| total_deaths | 280 | 1273 | 2135 | 427 | 182378 | 105 |'
  prefs: []
  type: TYPE_TB
- en: We can implement negative binomial regression when using `stan_glm()` by specifying
    the negative binomial distribution in “family”. In this case, we run both Poisson
    and negative binomial.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '*We can compare our different models ([Table 13.8](#tbl-modelsummarypoissonvsnegbinomial)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13.8: Modeling the most prevalent cause of deaths in Alberta, 2001-2020'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '*The estimates are similar. We could use posterior predictive checks, introduced
    in [Section 12.4](12-ijalm.html#sec-inferencewithbayesianmethods), to show that
    the negative binomial approach is a better choice for this circumstance ([Figure 13.14](#fig-ppcheckpoissonvsbinomial)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/c121da9512b39af25165e1e4adfb5872.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Poisson model
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/483256ef3d786f9cf71aad6741c45f1e.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Negative binomial model
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.14: Comparing posterior prediction checks for Poisson and negative
    binomial models'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can compare between the models using the resampling method leave-one-out
    (LOO) cross-validation (CV). This is a variant of cross-validation, where the
    size of each fold is one. That is to say, if there was a dataset with 100 observations,
    this LOO is equivalent to 100-fold cross validation. We can implement this in
    `rstanarm` with `loo()` for each model, and then compare between them with `loo_compare()`
    where the higher the better.[¹](#fn1)
  prefs: []
  type: TYPE_NORMAL
- en: We provide more information on cross-validation in [Online Appendix 14](13-prediction.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE52]*  *In this case we find that the negative binomial model is a better
    fit than the Poisson, because ELPD is larger.*********  ***## 13.5 Multilevel
    modeling'
  prefs: []
  type: TYPE_NORMAL
- en: Multilevel modeling goes by a variety of names including “hierarchical”, and
    “random effects”. While there are sometimes small differences in meaning between
    disciplines, in general they refer to the same or at least similar ideas. The
    fundamental insight of multilevel modeling is that a lot of the time our observations
    are not completely independent of each other, and can instead be grouped. Accounting
    for that grouping when we model, can provide us with some useful information.
    For instance, there is a difference in the earnings of professional athletes depending
    on whether they compete in men’s or women’s events. If we were interested in trying
    to forecast the earnings of a particular athlete, based on their competition results,
    then knowing which type of competition the individual competed in would enable
    the model to make a better forecast.
  prefs: []
  type: TYPE_NORMAL
- en: '*Shoulders of giants* *Dr Fiona Steele is a Professor of Statistics at the
    London School of Economics (LSE). After earning a PhD in Statistics from University
    of Southampton in 1996, she was appointed as a Lecturer at the LSE, before moving
    to the University of London, and the University of Bristol where she was appointed
    a full professor in 2008\. She returned to the LSE in 2013\. One area of her research
    is multilevel modeling and applications in demography, education, family psychology,
    and health. For instance, Steele ([2007](99-references.html#ref-Steele2007)) looks
    at multilevel models for longitudinal data, and Steele, Vignoles, and Jenkins
    ([2007](99-references.html#ref-Steele2007again)) uses a multilevel model to look
    at the relationship between school resources and pupil attainment. She was awarded
    the Royal Statistical Society Guy Medal in Bronze in 2008.*  *We distinguish between
    three settings:'
  prefs: []
  type: TYPE_NORMAL
- en: Complete pooling, where we treat every observation as being from the same group,
    which is what we have been doing to this point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No pooling, where we treat every group separately, which might happen if we
    were to run a separate regression for each group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Partial pooling, where we allow group membership to have some influence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For instance, consider we are interested in the relationship between GDP and
    inflation for each of the countries in the world. Complete pooling would have
    us put all the countries into the one group; no pooling would have us run separate
    regressions for each continent. We will now illustrate the partial pooling approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general there are two ways to go about this:'
  prefs: []
  type: TYPE_NORMAL
- en: enable varying intercepts, or
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: enable varying slopes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this book we consider only the first, but you should move onto Gelman, Hill,
    and Vehtari ([2020](99-references.html#ref-gelmanhillvehtari2020)), McElreath
    ([[2015] 2020](99-references.html#ref-citemcelreath)), and Johnson, Ott, and Dogucu
    ([2022](99-references.html#ref-bayesrules)).
  prefs: []
  type: TYPE_NORMAL
- en: '13.5.1 Simulated example: political support'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let us consider a situation in which the probability of support for a particular
    political party depends on an individual’s gender, and the state that they live
    in.
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{aligned} y_i|\pi_i & \sim \mbox{Bern}(\pi_i) \\ \mbox{logit}(\pi_i)
    & = \beta_0 + \alpha_{g[i]}^{\mbox{gender}} + \alpha_{s[i]}^{\mbox{state}} \\
    \beta_0 & \sim \mbox{Normal}(0, 2.5)\\ \alpha_{g}^{\mbox{gender}} & \sim \mbox{Normal}(0,
    2.5)\mbox{ for }g=1, 2\\ \alpha_{s}^{\mbox{state}} & \sim \mbox{Normal}\left(0,
    \sigma_{\mbox{state}}^2\right)\mbox{ for }s=1, 2, \dots, S\\ \sigma_{\mbox{state}}
    & \sim \mbox{Exponential}(1) \end{aligned} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\pi_i = \mbox{Pr}(y_i=1)\), there are two gender groups, because that
    is what is going to be available from the survey we will use in [Chapter 16](15-mrp.html),
    and \(S\) is the total number of states. We include this in the function with
    “(1 | state)” within `stan_glmer()` from `rstanarm` ([Goodrich et al. 2023](99-references.html#ref-citerstanarm)).
    This term indicates that we are looking at a group effect by state, which means
    that the fitted model’s intercept is allowed to vary according by state.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE54]*  *[PRE55]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE56]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE57]*  *It is worth trying to look for opportunities to use a multilevel
    model when you come to a new modeling situation, especially one where inference
    is the primary concern. There is often some grouping that can be taken advantage
    of to provide the model with more information.'
  prefs: []
  type: TYPE_NORMAL
- en: When we move to multilevel modeling, it is possible that some `rstanarm` models
    will result in a warning about “divergent transitions”. For the purposes of getting
    a model working for this book, if there are just a handful of warnings and the
    Rhat values of the coefficients are all close to one (check this with `any(summary(change_this_to_the_model_name)[,
    "Rhat"] > 1.1)`), then just ignore it. If there are more than a handful, and/or
    any of the Rhats are not close to one, then add “adapt_delta = 0.99” as an argument
    to `stan_glmer()` and re-run the model (keeping in mind that it will take longer
    to run). If that does not fix the issue, then simplify the model by removing a
    variable. We will see an example in [Chapter 16](15-mrp.html) when we apply MRP
    to the 2020 US election, where the “adapt_delta” strategy fixes the issue.***  ***###
    13.5.2 Austen, Brontë, Dickens, and Shakespeare
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example of multilevel modeling, we consider data from Project Gutenberg
    on the length of books by four authors: Jane Austen, Charlotte Brontë, Charles
    Dickens, and William Shakespeare. We would expect that Austen, Brontë, and Dickens,
    as they wrote books, will have longer books than Shakespeare, as he wrote plays.
    But it is not clear what difference we should expect between the three book authors.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE59]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE60]'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PRE61]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 13.9: Explaining whether Austen, Brontë, Dickens, or Shakespeare wrote
    a book based on the number of lines'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '*[Table 13.9](#tbl-modelsummaryaustenshakes) is a little empty for the multilevel
    model, and we often use graphs to avoid overwhelming the reader with numbers (we
    will see examples of this in [Chapter 16](15-mrp.html)). For instance, [Figure 13.15](#fig-multilevelexampleleveldistribution)
    shows the distribution of draws for each of the four authors using `spread_draws()`
    from `tidybayes`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/096fa7bffb1de4504fdd9edd5e75d5d9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13.15: Examining the distribution of draws for each of the four authors*  *In
    this case, we see that we typically expect Brontë to write the longest books of
    the three book authors. Shakespeare, as expected, typically wrote works with the
    fewest lines.**********  ****## 13.6 Concluding remarks'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we have considered generalized linear models and introduced
    multilevel modeling. We built on the foundation established in [Chapter 12](12-ijalm.html)
    and provided some essentials for Bayesian model building. As mentioned in [Chapter
    12](12-ijalm.html), this is enough to get started. Hopefully you are excited to
    learn more and to do that you should start with the modeling books recommended
    in [Chapter 18](17-concluding.html).
  prefs: []
  type: TYPE_NORMAL
- en: Over the course of [Chapter 12](12-ijalm.html) and [Chapter 13](#sec-its-just-a-generalized-linear-model)
    we have covered a variety of approaches for Bayesian models. But we have not done
    everything for every model.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is difficult to be definitive about what is “enough” because it is context
    specific, but the following checklist, drawn from concepts introduced across [Chapter
    12](12-ijalm.html) and [Chapter 13](#sec-its-just-a-generalized-linear-model)
    would be sufficient for most purposes when you are getting started. In the model
    section of the paper, write out the model using equations and include a few paragraphs
    of text explaining the equations. Then justify the model choices, and briefly
    detail any alternatives that you considered. Finish with a sentence explaining
    how the model was fit, which in this case is likely to be with `rstanarm`, and
    that diagnostics are available in a cross-referenced appendix. In that appendix
    you should include: prior predictive checks, trace plots, Rhat plots, posterior
    distributions, and posterior predictive checks.'
  prefs: []
  type: TYPE_NORMAL
- en: In the results section you should include a table of the estimates, built using
    `modelsummary`, and talk through them, likely with the help of `marginaleffects`.
    It may also be useful to include a graph of your results, especially if you are
    using a multilevel model, with the help of `tidybayes`. The model itself should
    be run in a separate R script. It should be preceded by tests of class and the
    number of observations. It should be followed by tests of the coefficients. These
    should be based on simulation. You should save the model in that R script using
    `saveRDS()`. In the Quarto document, you should read in that model using `readRDS()`.
  prefs: []
  type: TYPE_NORMAL
- en: 13.7 Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Practice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*(Plan)* Consider the following scenario: *A person is interested in the number
    of deaths, attributed to cancer, in Sydney, Australia. They collect data from
    the five largest hospitals, for the past 20 years.* Please sketch out what that
    dataset could look like and then sketch a graph that you could build to show all
    observations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation—both the outcome (number of deaths, by cause) and a handful of predictors.
    Please include at least ten tests based on the simulated data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Acquire)* Please describe one possible source of such a dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched. Then
    use `rstanarm` to build a model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Communicate)* Please write two paragraphs about what you did.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When should we consider logistic regression (pick one)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Continuous outcome variable.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Binary outcome variable.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Count outcome variable.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We are interested in studying how voting intentions in the 2020 US presidential
    election vary by an individual’s income. We set up a logistic regression model
    to study this relationship. In this study, one possible outcome variable would
    be (pick one)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Whether the respondent is a US citizen (yes/no)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The respondent’s personal income (high/low)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Whether the respondent is going to vote for Biden (yes/no)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Who the respondent voted for in 2016 (Trump/Clinton)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We are interested in studying how voting intentions in the 2020 US presidential
    election vary by an individual’s income. We set up a logistic regression model
    to study this relationship. In this study, some possible predictor variables could
    be (select all that apply)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The race of the respondent (white/not white)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The respondent’s marital status (married/not)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Whether the respondent is going to vote for Biden (yes/no)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The mean of a Poisson distribution is equal to its?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Median.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Standard deviation.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Variance.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Please redo the `rstanarm` example of US elections but include additional variables.
    Which variable did you choose, and how did the performance of the model improve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please create the graph of the density of the Poisson distribution when \(\lambda
    = 75\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From Gelman, Hill, and Vehtari ([2020](99-references.html#ref-gelmanhillvehtari2020)),
    what is the offset in Poisson regression?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Redo the *Jane Eyre* example, but for “A/a”.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The twentieth century British statistician George Box, famously said, “[s]ince
    all models are wrong the scientist must be alert to what is importantly wrong.
    It is inappropriate to be concerned about mice when there are tigers abroad.”
    ([Box 1976, 792](99-references.html#ref-Box1976)). Discuss, with the help of examples
    and citations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Class activities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Discuss how you would build a Bayesian regression model to look at the association
    between whether someone prefers football or hockey, and their age, gender, and
    location. Write out:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcome of interest and the likelihood
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The regression model for the outcome of interest
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The priors on any parameters to be estimated in the model.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Like in [Chapter 12](12-ijalm.html), we are again interested in understanding
    the relationship between bill length and depth using `palmerpenguins`, but this
    time for all three species. Begin by estimating separate models for each. Then
    estimate one model for all three species. Finally, estimate a model with partial
    pooling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and
    create a new repo. Add a link to the GitHub repo in the class’s shared Google
    Doc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are interested in explaining support for either a Democrat or Republican,
    based on education, age-group, and gender, and state. Please sketch and simulate
    the situation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Please obtain the data underpinning Cohn ([2016](99-references.html#ref-cohn2016)),
    available [here](https://github.com/TheUpshot/2016-upshot-siena-polls/). Save
    the unedited data, and construct an analysis dataset (there is some code below
    to get you started). Add graphs of each of the variables, individually, into the
    data section, as well as graphs of how they relate.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Please build one model explaining “vt_pres_2”, as a function of “gender”, “educ”,
    and “age”; and another which additionally considers “state”. Write up the two
    models in a model section, and add the results into the results section (again,
    there is some code below to get you started).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE66]*  **### Task'
  prefs: []
  type: TYPE_NORMAL
- en: Please consider Maher ([1982](99-references.html#ref-maher1982modelling)), Smith
    ([2002](99-references.html#ref-thanksleo)), or Cohn ([2016](99-references.html#ref-cohn2016)).
    Build a simplified version of their model.
  prefs: []
  type: TYPE_NORMAL
- en: Obtain some recent relevant data, estimate the model, and discuss your choice
    between logistic, Poisson, and negative binomial regression.
  prefs: []
  type: TYPE_NORMAL
- en: Use Quarto, and include an appropriate title, author, date, link to a GitHub
    repo, sections, and citations, and be sure to thoroughly specify the model.
  prefs: []
  type: TYPE_NORMAL
- en: Paper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At about this point the *Spadina* Paper from [Online Appendix F](25-papers.html)
    would be appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ansolabehere, Stephen, Brian Schaffner, and Sam Luks. 2021\. “Guide to the
    2020 Cooperative Election Study.” [https://doi.org/10.7910/DVN/E9N6PH](https://doi.org/10.7910/DVN/E9N6PH).Arel-Bundock,
    Vincent. 2022\. “modelsummary: Data and Model Summaries in R.” *Journal of Statistical
    Software* 103 (1): 1–23\. [https://doi.org/10.18637/jss.v103.i01](https://doi.org/10.18637/jss.v103.i01).———.
    2023\. *marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, and
    Hypothesis Tests*. [https://vincentarelbundock.github.io/marginaleffects/](https://vincentarelbundock.github.io/marginaleffects/).———.
    2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,” “Markdown,”
    “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Baio,
    Gianluca, and Marta Blangiardo. 2010\. “Bayesian Hierarchical Model for the Prediction
    of Football Results.” *Journal of Applied Statistics* 37 (2): 253–64\. [https://doi.org/10.1080/02664760802684177](https://doi.org/10.1080/02664760802684177).Bolker,
    Ben, and David Robinson. 2022\. *broom.mixed: Tidying Methods for Mixed Models*.
    [https://CRAN.R-project.org/package=broom.mixed](https://CRAN.R-project.org/package=broom.mixed).Bolton,
    Ruth, and Randall Chapman. 1986\. “Searching for Positive Returns at the Track.”
    *Management Science* 32 (August): 1040–60\. [https://doi.org/10.1287/mnsc.32.8.1040](https://doi.org/10.1287/mnsc.32.8.1040).Box,
    George E. P. 1976\. “Science and Statistics.” *Journal of the American Statistical
    Association* 71 (356): 791–99\. [https://doi.org/10.1080/01621459.1976.10480949](https://doi.org/10.1080/01621459.1976.10480949).Burch,
    Tyler James. 2023\. “2023 NHL Playoff Predictions,” April. [https://tylerjamesburch.com/blog/misc/nhl-predictions](https://tylerjamesburch.com/blog/misc/nhl-predictions).Canty,
    Angelo, and B. D. Ripley. 2021\. *boot: Bootstrap R (S-Plus) Functions*.Chellel,
    Kit. 2018\. “The Gambler Who Cracked the Horse-Racing Code.” *Bloomberg Businessweek*,
    May. [https://www.bloomberg.com/news/features/2018-05-03/the-gambler-who-cracked-the-horse-racing-code](https://www.bloomberg.com/news/features/2018-05-03/the-gambler-who-cracked-the-horse-racing-code).Cohn,
    Nate. 2016\. “We Gave Four Good Pollsters the Same Raw Data. They Had Four Different
    Results.” *The New York Times*, September. [https://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html](https://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html).Cramer,
    Jan Salomon. 2003\. “The Origins of Logistic Regression.” *SSRN Electronic Journal*.
    [https://doi.org/10.2139/ssrn.360300](https://doi.org/10.2139/ssrn.360300).Davison,
    A. C., and D. V. Hinkley. 1997\. *Bootstrap Methods and Their Applications*. Cambridge:
    Cambridge University Press. [http://statwww.epfl.ch/davison/BMA/](http://statwww.epfl.ch/davison/BMA/).Edgeworth,
    Francis Ysidro. 1885\. “Methods of Statistics.” *Journal of the Statistical Society
    of London*, 181–217.Firke, Sam. 2023\. *janitor: Simple Tools for Examining and
    Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Friendly,
    Michael. 2021\. *HistData: Data Sets from the History of Statistics and Data Visualization*.
    [https://CRAN.R-project.org/package=HistData](https://CRAN.R-project.org/package=HistData).Gelman,
    Andrew, Jennifer Hill, and Aki Vehtari. 2020\. *Regression and Other Stories*.
    Cambridge University Press. [https://avehtari.github.io/ROS-Examples/](https://avehtari.github.io/ROS-Examples/).Goodrich,
    Ben, Jonah Gabry, Imad Ali, and Sam Brilleman. 2023\. “rstanarm: Bayesian applied
    regression modeling via Stan.” [https://mc-stan.org/rstanarm](https://mc-stan.org/rstanarm).Hastie,
    Trevor, and Robert Tibshirani. 1990\. *Generalized Additive Models*. 1st ed. Boca
    Raton: Chapman; Hall/CRC.James, Gareth, Daniela Witten, Trevor Hastie, and Robert
    Tibshirani. (2013) 2021\. *An Introduction to Statistical Learning with Applications
    in R*. 2nd ed. Springer. [https://www.statlearning.com](https://www.statlearning.com).Johnson,
    Alicia, Miles Ott, and Mine Dogucu. 2022\. *Bayes Rules! An Introduction to Bayesian
    Modeling with R*. 1st ed. Chapman; Hall/CRC. [https://www.bayesrulesbook.com](https://www.bayesrulesbook.com).Johnston,
    Myfanwy, and David Robinson. 2022\. *gutenbergr: Download and Process Public Domain
    Works from Project Gutenberg*. [https://CRAN.R-project.org/package=gutenbergr](https://CRAN.R-project.org/package=gutenbergr).Kay,
    Matthew. 2022\. *tidybayes: Tidy Data and Geoms for Bayesian Models*. [https://doi.org/10.5281/zenodo.1308151](https://doi.org/10.5281/zenodo.1308151).Krantz,
    Sebastian. 2023\. *collapse: Advanced and Fast Data Transformation*. [https://CRAN.R-project.org/package=collapse](https://CRAN.R-project.org/package=collapse).Kuriwaki,
    Shiro, Will Beasley, and Thomas Leeper. 2023\. *dataverse: R Client for Dataverse
    4+ Repositories*.Maher, Michael. 1982\. “Modelling Association Football Scores.”
    *Statistica Neerlandica* 36 (3): 109–18\. [https://doi.org/10.1111/j.1467-9574.1982.tb00782.x](https://doi.org/10.1111/j.1467-9574.1982.tb00782.x).McElreath,
    Richard. (2015) 2020\. *Statistical Rethinking: A Bayesian Course with Examples
    in R and Stan*. 2nd ed. Chapman; Hall/CRC.Nelder, John, and Robert Wedderburn.
    1972\. “Generalized Linear Models.” *Journal of the Royal Statistical Society:
    Series A (General)* 135 (3): 370–84\. [https://doi.org/10.2307/2344614](https://doi.org/10.2307/2344614).Osgood,
    D. Wayne. 2000\. “Poisson-Based Regression Analysis of Aggregate Crime Rates.”
    *Journal of Quantitative Criminology* 16 (1): 21–43\. [https://doi.org/10.1023/a:1007521427059](https://doi.org/10.1023/a:1007521427059).Pitman,
    Jim. 1993\. *Probability*. 1st ed. New York: Springer. [https://doi.org/10.1007/978-1-4612-4374-8](https://doi.org/10.1007/978-1-4612-4374-8).R
    Core Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Schaffner,
    Brian, Stephen Ansolabehere, and Sam Luks. 2021\. “Cooperative Election Study
    Common Content, 2020.” Harvard Dataverse. [https://doi.org/10.7910/DVN/E9N6PH](https://doi.org/10.7910/DVN/E9N6PH).Smith,
    Richard. 2002\. “A Statistical Assessment of Buchanan’s Vote in Palm Beach County.”
    *Statistical Science* 17 (4): 441–57\. [https://doi.org/10.1214/ss/1049993203](https://doi.org/10.1214/ss/1049993203).Steele,
    Fiona. 2007\. “Multilevel Models for Longitudinal Data.” *Journal of the Royal
    Statistical Society Series A: Statistics in Society* 171 (1): 5–19\. [https://doi.org/10.1111/j.1467-985x.2007.00509.x](https://doi.org/10.1111/j.1467-985x.2007.00509.x).Steele,
    Fiona, Anna Vignoles, and Andrew Jenkins. 2007\. “The Effect of School Resources
    on Pupil Attainment: A Multilevel Simultaneous Equation Modelling Approach.” *Journal
    of the Royal Statistical Society Series A: Statistics in Society* 170 (3): 801–24\.
    [https://doi.org/10.1111/j.1467-985x.2007.00476.x](https://doi.org/10.1111/j.1467-985x.2007.00476.x).Stigler,
    Stephen. 1978\. “Francis Ysidro Edgeworth, Statistician.” *Journal of the Royal
    Statistical Society. Series A (General)* 141 (3): 287–322\. [https://doi.org/10.2307/2344804](https://doi.org/10.2307/2344804).Wang,
    Wei, David Rothschild, Sharad Goel, and Andrew Gelman. 2015\. “Forecasting Elections
    with Non-Representative Polls.” *International Journal of Forecasting* 31 (3):
    980–91\. [https://doi.org/10.1016/j.ijforecast.2014.06.001](https://doi.org/10.1016/j.ijforecast.2014.06.001).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).**
    *** * *'
  prefs: []
  type: TYPE_NORMAL
- en: By way of background, LOO-CV is not done by `loo()`, because it would be too
    computationally intensive. Instead an approximation is done which provides the
    expected log point wise predictive density (ELPD). The `rstanarm` vignettes provide
    more detail.[↩︎](#fnref1)*****************
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
