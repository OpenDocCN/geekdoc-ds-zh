["```py\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(estimatr)\nlibrary(haven)\nlibrary(MatchIt)\nlibrary(modelsummary)\nlibrary(palmerpenguins)\nlibrary(rdrobust)\nlibrary(rstanarm)\nlibrary(scales)\nlibrary(tidyverse)\nlibrary(tinytable)\n```", "```py\nset.seed(853)\n\nnumber_in_each <- 1000\n\ndepartment_one <-\n tibble(\n undergrad = runif(n = number_in_each, min = 0.7, max = 0.9),\n noise = rnorm(n = number_in_each, 0, sd = 0.1),\n grad = undergrad + noise,\n type = \"Department 1\"\n )\n\ndepartment_two <-\n tibble(\n undergrad = runif(n = number_in_each, min = 0.6, max = 0.8),\n noise = rnorm(n = number_in_each, 0, sd = 0.1),\n grad = undergrad + noise + 0.3,\n type = \"Department 2\"\n )\n\nboth_departments <- rbind(department_one, department_two)\n\nboth_departments\n```", "```py\n# A tibble: 2,000 × 4\n   undergrad   noise  grad type        \n       <dbl>   <dbl> <dbl> <chr>       \n 1     0.772 -0.0566 0.715 Department 1\n 2     0.724 -0.0312 0.693 Department 1\n 3     0.797  0.0770 0.874 Department 1\n 4     0.763 -0.0664 0.697 Department 1\n 5     0.707  0.0717 0.779 Department 1\n 6     0.781 -0.0165 0.764 Department 1\n 7     0.726 -0.104  0.623 Department 1\n 8     0.749  0.0527 0.801 Department 1\n 9     0.732 -0.0471 0.684 Department 1\n10     0.738  0.0552 0.793 Department 1\n# ℹ 1,990 more rows\n```", "```py\nboth_departments |>\n ggplot(aes(x = undergrad, y = grad)) +\n geom_point(aes(color = type), alpha = 0.1) +\n geom_smooth(aes(color = type), method = \"lm\", formula = \"y ~ x\") +\n geom_smooth(method = \"lm\", formula = \"y ~ x\", color = \"black\") +\n labs(\n x = \"Undergraduate results\",\n y = \"Graduate results\",\n color = \"Department\"\n ) +\n theme_minimal() +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\npenguins |>\n ggplot(aes(x = body_mass_g, y = bill_depth_mm)) +\n geom_point(aes(color = species), alpha = 0.1) +\n geom_smooth(aes(color = species), method = \"lm\", formula = \"y ~ x\") +\n geom_smooth(\n method = \"lm\",\n formula = \"y ~ x\",\n color = \"black\"\n ) +\n labs(\n x = \"Body mass (grams)\",\n y = \"Bill depth (millimeters)\",\n color = \"Species\"\n ) +\n theme_minimal() +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\nset.seed(853)\n\nnum_pros <- 100\nnum_public <- 1000\n\nprofessionals <- tibble(\n VO2 = runif(num_pros, 0.7, 0.9),\n chance_of_winning = runif(num_pros, 0.7, 0.9),\n type = \"Professionals\"\n)\n\ngeneral_public <- tibble(\n VO2 = runif(num_public, 0.6, 0.8),\n chance_of_winning = VO2 + rnorm(num_public, 0, 0.03) + 0.1,\n type = \"Public\"\n)\n\nprofessionals_and_public <- bind_rows(professionals, general_public)\n```", "```py\nprofessionals_and_public |>\n ggplot(aes(x = VO2, y = chance_of_winning)) +\n geom_point(aes(color = type), alpha = 0.1) +\n geom_smooth(aes(color = type), method = \"lm\", formula = \"y ~ x\") +\n geom_smooth(method = \"lm\", formula = \"y ~ x\", color = \"black\") +\n labs(\n x = \"VO2 max\",\n y = \"Chance of winning a bike race\",\n color = \"Type\"\n ) +\n theme_minimal() +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\nset.seed(853)\n\nsimulated_diff_in_diff <-\n tibble(\n person = rep(c(1:1000), times = 2),\n time = c(rep(0, times = 1000), rep(1, times = 1000)),\n treat_group = rep(sample(x = 0:1, size = 1000, replace = TRUE ), times = 2)\n ) |>\n mutate(\n treat_group = as.factor(treat_group),\n time = as.factor(time)\n )\n\nsimulated_diff_in_diff <-\n simulated_diff_in_diff |>\n rowwise() |>\n mutate(\n serve_speed = case_when(\n time == 0 & treat_group == 0 ~ rnorm(n = 1, mean = 5, sd = 1),\n time == 1 & treat_group == 0 ~ rnorm(n = 1, mean = 6, sd = 1),\n time == 0 & treat_group == 1 ~ rnorm(n = 1, mean = 8, sd = 1),\n time == 1 & treat_group == 1 ~ rnorm(n = 1, mean = 14, sd = 1)\n )\n )\n\nsimulated_diff_in_diff\n```", "```py\n# A tibble: 2,000 × 4\n# Rowwise: \n   person time  treat_group serve_speed\n    <int> <fct> <fct>             <dbl>\n 1      1 0     0                  4.43\n 2      2 0     1                  6.96\n 3      3 0     1                  7.77\n 4      4 0     0                  5.31\n 5      5 0     0                  4.09\n 6      6 0     0                  4.85\n 7      7 0     0                  6.43\n 8      8 0     0                  5.77\n 9      9 0     1                  6.13\n10     10 0     1                  7.32\n# ℹ 1,990 more rows\n```", "```py\nsimulated_diff_in_diff |>\n ggplot(aes(x = time, y = serve_speed, color = treat_group)) +\n geom_point(alpha = 0.2) +\n geom_line(aes(group = person), alpha = 0.1) +\n theme_minimal() +\n labs(x = \"Time period\", y = \"Serve speed\", color = \"Person got a new racket\") +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\nave_diff <-\n simulated_diff_in_diff |>\n pivot_wider(\n names_from = time,\n values_from = serve_speed,\n names_prefix = \"time_\"\n ) |>\n mutate(difference = time_1 - time_0) |>\n # Average difference between old and new racket serve speed within groups\n summarise(average_difference = mean(difference),\n .by = treat_group)\n\n# Difference between the average differences of each group\nave_diff$average_difference[2] - ave_diff$average_difference[1]\n```", "```py\n[1] 5.058414\n```", "```py\ndiff_in_diff_example_regression <-\n stan_glm(\n formula = serve_speed ~ treat_group * time,\n data = simulated_diff_in_diff,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n diff_in_diff_example_regression,\n file = \"diff_in_diff_example_regression.rds\"\n)\n```", "```py\ndiff_in_diff_example_regression <-\n readRDS(file = \"diff_in_diff_example_regression.rds\")\n```", "```py\nmodelsummary(\n diff_in_diff_example_regression\n)\n```", "```py\nnewspapers <- read_dta(\"Angelucci_Cage_AEJMicro_dataset.dta\")\n```", "```py\nnewspapers <-\n newspapers |>\n select(\n year, id_news, after_national, local, national, ra_cst, ps_cst, qtotal\n ) |> \n mutate(ra_cst_div_qtotal = ra_cst / qtotal, \n across(c(id_news, after_national, local, national), as.factor),\n year = as.integer(year))\n\nnewspapers\n```", "```py\n# A tibble: 1,196 × 9\n    year id_news after_national local national    ra_cst ps_cst  qtotal\n   <int> <fct>   <fct>          <fct> <fct>        <dbl>  <dbl>   <dbl>\n 1  1960 1       0              1     0         52890272   2.29  94478.\n 2  1961 1       0              1     0         56601060   2.20  96289.\n 3  1962 1       0              1     0         64840752   2.13  97313.\n 4  1963 1       0              1     0         70582944   2.43 101068.\n 5  1964 1       0              1     0         74977888   2.35 102103.\n 6  1965 1       0              1     0         74438248   2.29 105169.\n 7  1966 1       0              1     0         81383000   2.31 126235.\n 8  1967 1       0              1     0         80263152   2.88 128667.\n 9  1968 1       0              1     0         87165704   3.45 131824.\n10  1969 1       0              1     0        102596384   3.28 132417.\n# ℹ 1,186 more rows\n# ℹ 1 more variable: ra_cst_div_qtotal <dbl>\n```", "```py\nnewspapers |>\n mutate(type = if_else(local == 1, \"Local\", \"National\")) |>\n ggplot(aes(x = year, y = ra_cst)) +\n geom_point(alpha = 0.5) +\n scale_y_continuous(\n labels = dollar_format(\n prefix = \"$\",\n suffix = \"M\",\n scale = 0.000001)) +\n labs(x = \"Year\", y = \"Advertising revenue\") +\n facet_wrap(vars(type), nrow = 2) +\n theme_minimal() +\n geom_vline(xintercept = 1966.5, linetype = \"dashed\")\n```", "```py\nad_revenue <-\n stan_glm(\n formula = log(ra_cst) ~ after_national + id_news + year,\n data = newspapers,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n ad_revenue,\n file = \"ad_revenue.rds\"\n)\n\nad_revenue_div_circulation <-\n stan_glm(\n formula = log(ra_cst_div_qtotal) ~ after_national + id_news + year,\n data = newspapers,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n ad_revenue_div_circulation,\n file = \"ad_revenue_div_circulation.rds\"\n)\n\n# Consumer side\nsubscription_price <-\n stan_glm(\n formula = log(ps_cst) ~ after_national + id_news + year,\n data = newspapers,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n subscription_price,\n file = \"subscription_price.rds\"\n)\n```", "```py\nad_revenue <-\n readRDS(file = \"ad_revenue.rds\")\n\nad_revenue_div_circulation <-\n readRDS(file = \"ad_revenue_div_circulation\")\n\nsubscription_price <-\n readRDS(file = \"subscription_price.rds\")\n```", "```py\nselected_variables <- c(\"year\" = \"Year\", \"after_national1\" = \"After change\")\n\nmodelsummary(\n models = list(\n \"Ad revenue\" = ad_revenue,\n \"Ad revenue over circulation\" = ad_revenue_div_circulation,\n \"Subscription price\" = subscription_price\n ),\n fmt = 2,\n coef_map = selected_variables\n)\n```", "```py\nset.seed(853)\n\nsample_size <- 10000\n\npurchase_data <-\n tibble(\n unique_person_id = 1:sample_size,\n age = sample(x = 18:100, size = sample_size, replace = TRUE),\n gender = sample(\n x = c(\"Female\", \"Male\", \"Other/decline\"),\n size = sample_size,\n replace = TRUE,\n prob = c(0.49, 0.47, 0.02)\n ),\n income = rnorm(n = sample_size, mean = 60000, sd = 15000) |> round(0)\n ) \n\npurchase_data\n```", "```py\n# A tibble: 10,000 × 4\n   unique_person_id   age gender income\n              <int> <int> <chr>   <dbl>\n 1                1    26 Male    68637\n 2                2    81 Female  71486\n 3                3    34 Male    75652\n 4                4    46 Male    68068\n 5                5   100 Female  73206\n 6                6    20 Male    41872\n 7                7    50 Female  75957\n 8                8    36 Female  56566\n 9                9    72 Male    54621\n10               10    52 Female  40722\n# ℹ 9,990 more rows\n```", "```py\npurchase_data <- \n purchase_data |>\n mutate(\n # change characteristics to bounded numbers\n age_num = rank(1 / age, ties.method = \"random\") %/% 3000,\n # force it between 0 and 3\n gender_num = case_when(\n gender == \"Male\" ~ 3,\n gender == \"Female\" ~ 2,\n gender == \"Other/decline\" ~ 1\n ),\n income_num = rank(income, ties.method = \"random\") %/% 3000\n ) |>\n mutate(\n sum_num = age_num + gender_num + income_num,\n softmax_prob = exp(sum_num) / exp(max(sum_num) + 0.5),\n free_shipping = rbinom(n = sample_size, size = 1, prob = softmax_prob)) |>\n select(-(age_num:softmax_prob))\n```", "```py\npurchase_data <-\n purchase_data |>\n mutate(\n noise = rnorm(n = nrow(purchase_data), mean = 5, sd = 2),\n spend = income / 1000 + noise,\n spend = if_else(free_shipping == 1, spend + 10, spend),\n spend = as.integer(spend)\n ) |>\n select(-noise) |>\n mutate(across(c(gender, free_shipping), as.factor))\n\npurchase_data\n```", "```py\n# A tibble: 10,000 × 6\n   unique_person_id   age gender income free_shipping spend\n              <int> <int> <fct>   <dbl> <fct>         <int>\n 1                1    26 Male    68637 0                72\n 2                2    81 Female  71486 0                73\n 3                3    34 Male    75652 0                80\n 4                4    46 Male    68068 0                75\n 5                5   100 Female  73206 0                78\n 6                6    20 Male    41872 0                45\n 7                7    50 Female  75957 0                78\n 8                8    36 Female  56566 0                62\n 9                9    72 Male    54621 0                55\n10               10    52 Female  40722 0                47\n# ℹ 9,990 more rows\n```", "```py\npurchase_data |>\n summarise(average_spend = round(mean(spend), 2), .by = free_shipping) |>\n mutate(free_shipping = if_else(free_shipping == 0, \"No\", \"Yes\")) |>\n tt() |> \n style_tt(j = 1:2, align = \"lr\") |> \n setNames(c(\"Received free shipping?\", \"Average spend\"))\n```", "```py\nmatched_groups <- \n matchit(\n free_shipping ~ age + gender + income,\n data = purchase_data,\n method = \"nearest\",\n distance = \"glm\"\n)\n\nmatched_groups\n```", "```py\nA `matchit` object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score             - estimated with logistic regression\n - number of obs.: 10000 (original), 508 (matched)\n - target estimand: ATT\n - covariates: age, gender, income\n```", "```py\nmatched_dataset <- match.data(matched_groups)\n\nmatched_dataset\n```", "```py\n# A tibble: 508 × 9\n   unique_person_id   age gender     income free_shipping spend distance weights\n              <int> <int> <fct>       <dbl> <fct>         <int>    <dbl>   <dbl>\n 1               23    28 Female      65685 1                79  0.0334        1\n 2               24    67 Male        71150 0                76  0.0220        1\n 3               32    22 Female      86071 0                92  0.131         1\n 4               48    66 Female     100105 0               108  0.0473        1\n 5               59    25 Male        55548 1                68  0.0541        1\n 6               82    66 Male        70721 0                75  0.0224        1\n 7               83    58 Male        83443 0                88  0.0651        1\n 8               87    46 Male        59073 1                73  0.0271        1\n 9              119    89 Other/dec…  72284 0                74  0.00301       1\n10              125    51 Female      81164 1                96  0.0303        1\n# ℹ 498 more rows\n# ℹ 1 more variable: subclass <fct>\n```", "```py\npropensity_score_regression <- lm(\n spend ~ age + gender + income + free_shipping,\n data = matched_dataset\n)\n\nmodelsummary(propensity_score_regression)\n```", "```py\nset.seed(853)\n\nnum_observations <- 1000\n\nrdd_example_data <- tibble(\n person = c(1:num_observations),\n mark = runif(num_observations, min = 78, max = 82),\n income = rnorm(num_observations, 10, 1)\n)\n\n## Make income more likely to be higher if mark at least 80\nrdd_example_data <-\n rdd_example_data |>\n mutate(\n noise = rnorm(n = num_observations, mean = 2, sd = 1),\n income = if_else(mark >= 80, income + noise, income)\n )\n\nrdd_example_data\n```", "```py\n# A tibble: 1,000 × 4\n   person  mark income noise\n    <int> <dbl>  <dbl> <dbl>\n 1      1  79.4   9.43 1.87 \n 2      2  78.5   9.69 2.26 \n 3      3  79.9  10.8  1.14 \n 4      4  79.3   9.34 2.50 \n 5      5  78.1  10.7  2.21 \n 6      6  79.6   9.83 2.47 \n 7      7  78.5   8.96 4.22 \n 8      8  79.0  10.5  3.11 \n 9      9  78.6   9.53 0.671\n10     10  78.8  10.6  2.46 \n# ℹ 990 more rows\n```", "```py\nrdd_example_data |>\n ggplot(aes(\n x = mark,\n y = income\n )) +\n geom_point(alpha = 0.2) +\n geom_smooth(\n data = rdd_example_data |> filter(mark < 80),\n method = \"lm\",\n color = \"black\",\n formula = \"y ~ x\"\n ) +\n geom_smooth(\n data = rdd_example_data |> filter(mark >= 80),\n method = \"lm\",\n color = \"black\",\n formula = \"y ~ x\"\n ) +\n theme_minimal() +\n labs(\n x = \"Mark\",\n y = \"Income ($)\"\n )\n```", "```py\nrdd_example_data <-\n rdd_example_data |>\n mutate(mark_80_and_over = if_else(mark < 80, 0, 1))\n\nrdd_example <-\n stan_glm(\n formula = income ~ mark + mark_80_and_over,\n data = rdd_example_data,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n rdd_example,\n file = \"rdd_example.rds\"\n)\n```", "```py\nrdd_example <-\n readRDS(file = \"rdd_example.rds\")\n```", "```py\nmodelsummary(\n models = rdd_example,\n fmt = 2\n)\n```", "```py\nrdrobust(\n y = rdd_example_data$income,\n x = rdd_example_data$mark,\n c = 80,\n h = 2,\n all = TRUE\n) |>\n summary()\n```", "```py\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                      Manual\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  497          503\nEff. Number of Obs.             497          503\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   2.000        2.000\nBW bias (b)                   2.000        2.000\nrho (h/b)                     1.000        1.000\nUnique Obs.                     497          503\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     1.913     0.161    11.876     0.000     [1.597 , 2.229]     \nBias-Corrected     1.966     0.161    12.207     0.000     [1.650 , 2.282]     \n        Robust     1.966     0.232     8.461     0.000     [1.511 , 2.422]     \n=============================================================================\n```", "```py\nsome_data <-\n tibble(\n outcome = rnorm(n = 100, mean = 1, sd = 1),\n running_variable = c(1:100),\n location = \"before\"\n )\n\nsome_more_data <-\n tibble(\n outcome = rnorm(n = 100, mean = 2, sd = 1),\n running_variable = c(101:200),\n location = \"after\"\n )\n\nboth <-\n rbind(some_data, some_more_data)\n\nboth |>\n ggplot(aes(x = running_variable, y = outcome, color = location)) +\n geom_point(alpha = 0.5) +\n geom_smooth(formula = y ~ x, method = \"lm\") +\n theme_minimal() +\n theme(legend.position = \"bottom\")\n\nboth |>\n ggplot(aes(x = running_variable, y = outcome, color = location)) +\n geom_point(alpha = 0.5) +\n geom_smooth(formula = y ~ poly(x, 3), method = \"lm\") +\n theme_minimal() +\n theme(legend.position = \"bottom\")\n```", "```py\ncarpenter_dobkin <-\n read_dta(\n \"P01 Age Profile of Arrest Rates 1979-2006.dta\"\n )\n```", "```py\ncarpenter_dobkin_prepared <-\n carpenter_dobkin |>\n mutate(age = 21 + days_to_21 / 365) |>\n select(age, assault, aggravated_assault, dui, traffic_violations) |>\n pivot_longer(\n cols = c(assault, aggravated_assault, dui, traffic_violations),\n names_to = \"arrested_for\",\n values_to = \"number\"\n )\n\ncarpenter_dobkin_prepared |>\n mutate(\n arrested_for =\n case_when(\n arrested_for == \"assault\" ~ \"Assault\",\n arrested_for == \"aggravated_assault\" ~ \"Aggravated assault\",\n arrested_for == \"dui\" ~ \"DUI\",\n arrested_for == \"traffic_violations\" ~ \"Traffic violations\"\n )\n ) |>\n ggplot(aes(x = age, y = number)) +\n geom_point(alpha = 0.05) +\n facet_wrap(facets = vars(arrested_for), scales = \"free_y\") +\n theme_minimal()\n```", "```py\ncarpenter_dobkin_aggravated_assault_only <-\n carpenter_dobkin_prepared |>\n filter(\n arrested_for == \"aggravated_assault\",\n abs(age - 21) < 2\n ) |>\n mutate(is_21_or_more = if_else(age < 21, 0, 1))\n```", "```py\nrdd_carpenter_dobkin <-\n stan_glm(\n formula = number ~ age + is_21_or_more,\n data = carpenter_dobkin_aggravated_assault_only,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(0, 2.5, autoscale = TRUE),\n prior_aux = exponential(rate = 1, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n rdd_example,\n file = \"rdd_example.rds\"\n)\n```", "```py\nrdd_carpenter_dobkin <-\n readRDS(file = \"rdd_carpenter_dobkin.rds\")\n```", "```py\nmodelsummary(\n models = rdd_carpenter_dobkin,\n fmt = 2\n)\n```", "```py\nrdrobust(\n y = carpenter_dobkin_aggravated_assault_only$number,\n x = carpenter_dobkin_aggravated_assault_only$age,\n c = 21,\n h = 2,\n all = TRUE\n) |>\n summary()\n```", "```py\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1459\nBW type                      Manual\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  729          730\nEff. Number of Obs.             729          730\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   2.000        2.000\nBW bias (b)                   2.000        2.000\nrho (h/b)                     1.000        1.000\nUnique Obs.                     729          730\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    14.126     1.918     7.364     0.000    [10.366 , 17.886]    \nBias-Corrected    16.708     1.918     8.709     0.000    [12.948 , 20.468]    \n        Robust    16.708     2.879     5.804     0.000    [11.066 , 22.350]    \n=============================================================================\n```", "```py\nset.seed(853)\n\nnum_observations <- 10000\n\niv_example_data <- tibble(\n person = c(1:num_observations),\n smoker = \n sample(x = c(0:1), size = num_observations, replace = TRUE)\n )\n```", "```py\niv_example_data <-\n iv_example_data |>\n mutate(health = if_else(\n smoker == 0,\n rnorm(n = n(), mean = 1, sd = 1),\n rnorm(n = n(), mean = 0, sd = 1)\n ))\n```", "```py\niv_example_data <- iv_example_data |>\n mutate(\n province = case_when(\n smoker == 0 ~ sample(\n c(\"Nova Scotia\", \"Alberta\"),\n size = n(),\n replace = TRUE,\n prob = c(1/2, 1/2)\n ),\n smoker == 1 ~ sample(\n c(\"Nova Scotia\", \"Alberta\"),\n size = n(),\n replace = TRUE,\n prob = c(1/4, 3/4)\n )\n ),\n tax = case_when(province == \"Alberta\" ~ 0.3, \n province == \"Nova Scotia\" ~ 0.5,\n TRUE ~ 9999999\n )\n )\n\niv_example_data\n```", "```py\n# A tibble: 10,000 × 5\n   person smoker  health province      tax\n    <int>  <int>   <dbl> <chr>       <dbl>\n 1      1      0  1.11   Alberta       0.3\n 2      2      1 -0.0831 Alberta       0.3\n 3      3      1 -0.0363 Alberta       0.3\n 4      4      0  2.48   Alberta       0.3\n 5      5      0  0.617  Nova Scotia   0.5\n 6      6      0  0.748  Alberta       0.3\n 7      7      0  0.499  Alberta       0.3\n 8      8      0  1.05   Nova Scotia   0.5\n 9      9      1  0.113  Alberta       0.3\n10     10      1 -0.0105 Alberta       0.3\n# ℹ 9,990 more rows\n```", "```py\niv_example_data |>\n mutate(smoker = as_factor(smoker)) |>\n ggplot(aes(x = health, fill = smoker)) +\n geom_histogram(position = \"dodge\", binwidth = 0.2) +\n theme_minimal() +\n labs(\n x = \"Health rating\",\n y = \"Number of people\",\n fill = \"Smoker\"\n ) +\n scale_fill_brewer(palette = \"Set1\") +\n facet_wrap(vars(province))\n```", "```py\nhealth_on_tax <- lm(health ~ tax, data = iv_example_data)\nsmoker_on_tax <- lm(smoker ~ tax, data = iv_example_data)\n\ntibble(\n coefficient = c(\"health ~ tax\", \"smoker ~ tax\", \"ratio\"),\n value = c(\n coef(health_on_tax)[\"tax\"],\n coef(smoker_on_tax)[\"tax\"],\n coef(health_on_tax)[\"tax\"] / coef(smoker_on_tax)[\"tax\"]\n )\n)\n```", "```py\n# A tibble: 3 × 2\n  coefficient   value\n  <chr>         <dbl>\n1 health ~ tax  1.24 \n2 smoker ~ tax -1.27 \n3 ratio        -0.980\n```", "```py\niv_robust(health ~ smoker | tax, data = iv_example_data) |>\n modelsummary()\n```", "```py\ndigraph D {\n\n node  [shape=plaintext, fontname  =  \"helvetica\"];\n a  [label  =  \"Income\"]\n b  [label  =  \"Happiness\"]\n c  [label  =  \"Education\"]\n d  [label  =  \"Tax rebate\"]\n {  rank=same  a  b};\n\n a->b\n c->a\n c->b\n d->a\n}\n```"]