- en: Masking and Blending
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掩码和混合
- en: 原文：[https://en.algorithmica.org/hpc/simd/masking/](https://en.algorithmica.org/hpc/simd/masking/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/simd/masking/](https://en.algorithmica.org/hpc/simd/masking/)
- en: One of the bigger challenges of SIMD programming is that its options for control
    flow are very limited — because the operations you apply to a vector are the same
    for all its elements.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD编程的一个较大挑战是它的控制流选项非常有限——因为应用于向量的操作对所有元素都是相同的。
- en: This makes the problems that are usually trivially resolved with an `if` or
    any other type of branching much harder. With SIMD, they have to be dealt with
    by the means of various [branchless programming](/hpc/pipelining/branchless) techniques,
    which aren’t always that straightforward to apply.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得通常可以用`if`或任何其他类型的分支轻易解决的问题变得更加困难。在SIMD中，它们必须通过各种[无分支编程](/hpc/pipelining/branchless)技术来处理，而这些技术并不总是那么容易应用。
- en: '### [#](https://en.algorithmica.org/hpc/simd/masking/#masking)Masking'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/masking/#masking)掩码'
- en: 'The main way to make a computation branchless is through *predication* — computing
    the results of both branches and then using either some arithmetic trick or a
    special “conditional move” instruction:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 使计算无分支的主要方式是通过*预测*——计算两个分支的结果，然后使用某种算术技巧或特殊的“条件移动”指令：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To vectorize this loop, we are going to need two new instructions:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向量化这个循环，我们需要两个新的指令：
- en: '`_mm256_cmpgt_epi32`, which compares the integers in two vectors and produces
    a mask of all ones if the first element is more than the second and a mask of
    full zeros otherwise.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_mm256_cmpgt_epi32`，它比较两个向量中的整数，如果第一个元素大于第二个元素，则产生全一的掩码，否则产生全零的掩码。'
- en: '`_mm256_blendv_epi8`, which blends (combines) the values of two vectors based
    on the provided mask.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_mm256_blendv_epi8`，它根据提供的掩码将两个向量的值进行混合（组合）。'
- en: 'By masking and blending the elements of a vector so that only the selected
    subset of them is affected by computation, we can perform predication in a manner
    similar to the conditional move:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过掩码和混合向量的元素，使得只有选定的子集受到计算的影响，我们可以以类似于条件移动的方式执行预测：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: (Minor details such as [horizontal summation and accounting for the remainder
    of the array](../reduction) are omitted for brevity.)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: （为了简洁起见，省略了[水平求和和考虑数组余数](../reduction)等次要细节。）
- en: 'This is how predication is usually done in SIMD, but it isn’t always the most
    optimal approach. We can use the fact that one of the blended values is zero,
    and use bitwise `and` with the mask instead of blending:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是在SIMD中执行预测的方式，但并不总是最优的方法。我们可以利用混合值中有一个是零的事实，并用位运算`and`与掩码而不是混合：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This loop performs slightly faster because on this particular CPU, the vector
    `and` takes one cycle less than `blend`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个循环执行速度略快，因为在特定的CPU上，向量`and`操作比`blend`操作少一个周期。
- en: 'Several other instructions support masks as inputs, most notably:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 几种其他指令支持将掩码作为输入，其中最值得注意的是：
- en: The `_mm256_blend_epi32` intrinsic is a `blend` that takes an 8-bit integer
    mask instead of a vector (which is why it doesn’t have `v` at the end).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_mm256_blend_epi32`内联函数是一个`blend`，它使用8位整数掩码而不是向量（这就是为什么它没有`v`在结尾）。'
- en: The `_mm256_maskload_epi32` and `_mm256_maskstore_epi32` intrinsics that load/store
    a SIMD block from memory and `and` it with a mask in one go.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_mm256_maskload_epi32`和`_mm256_maskstore_epi32`内联函数，它们一次从内存中加载/存储SIMD块并与掩码进行`and`操作。'
- en: 'We can also use predication with built-in vector types:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用内置的向量类型进行预测：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: All these versions work at around 13 GFLOPS as this example is so simple that
    the compiler can vectorize the loop all by itself. Let’s move on to more complex
    examples that can’t be auto-vectorized.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些版本在约13 GFLOPS的速度下工作，因为本例非常简单，编译器可以完全自行将循环向量化。让我们继续看一些更复杂的例子，这些例子不能自动向量化。
- en: '### [#](https://en.algorithmica.org/hpc/simd/masking/#searching)Searching'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/masking/#searching)搜索'
- en: 'In the next example, we need to find a specific value in an array and return
    its position (aka `std::find`):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们需要在数组中找到一个特定的值并返回其位置（即`std::find`）：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To benchmark the `find` function, we fill the array with numbers from $0$ to
    $(N - 1)$ and then repeatedly search for a random element:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了基准测试`find`函数，我们用从$0$到$(N - 1)$的数字填充数组，然后重复搜索随机元素：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The scalar version gives ~4 GFLOPS of performance. This number includes the
    elements we haven’t had to process, so divide this number by two in your head
    (the expected fraction of the elements we have to check).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 标量版本提供了大约4 GFLOPS的性能。这个数字包括了我们没有必要处理的元素，所以在大脑中将这个数字除以2（我们预期需要检查的元素的比例）。
- en: To vectorize it, we need to compare a vector of its elements with the searched
    value for equality, producing a mask, and then somehow check if this mask is zero.
    If it isn’t, the needed element is somewhere within this block of 8.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向量化它，我们需要将包含其元素的向量与搜索值进行比较，以产生一个掩码，然后以某种方式检查这个掩码是否为零。如果不是，所需的元素就在这个8元素块中的某个地方。
- en: 'To check if the mask is zero, we can use the `_mm256_movemask_ps` intrinsic,
    which takes the first bit of each 32-bit element in a vector and produces an 8-bit
    integer mask out of them. We can then check if this mask is non-zero — and if
    it is, also immediately get the index with the `ctz` instruction:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查掩码是否为零，我们可以使用`_mm256_movemask_ps`内建函数，它从向量的每个32位元素中取出第一个位，并从中生成一个8位整数掩码。然后我们可以检查这个掩码是否非零——如果是的话，也可以立即使用`ctz`指令获取索引：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This version gives ~20 GFLOPS or about 5 times faster than the scalar one.
    It only uses 3 instructions in the hot loop:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本提供了大约20 GFLOPS或大约比标量版本快5倍。它只在热循环中使用3条指令：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Checking if a vector is zero is a common operation, and there is an operation
    similar to `test` in SIMD that we can use:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一个向量是否为零是一个常见的操作，在SIMD中有一个类似于`test`的操作我们可以使用：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We are still using `movemask` to do `ctz` later, but the hot loop is now one
    instruction shorter:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然使用`movemask`来稍后执行`ctz`，但现在热循环现在少了一条指令：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This doesn’t improve performance much because both both `vptest` and `vmovmskps`
    have a throughput of one and will bottleneck the computation regardless of anything
    else we do in the loop.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这并没有显著提高性能，因为`vptest`和`vmovmskps`的吞吐量都是1，并且无论我们在循环中做什么，都会成为计算的瓶颈。
- en: 'To work around this limitation, we can iterate in blocks of 16 elements and
    combine the results of independent comparisons of two 256-bit AVX2 registers using
    a bitwise `or`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个限制，我们可以以16个元素为一组进行迭代，并使用位运算`or`将两个256位AVX2寄存器的独立比较结果组合起来：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With this obstacle removed, the performance now peaks at ~34 GFLOPS. But why
    not 40? Shouldn’t it be twice as fast?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 移除这个障碍后，性能现在达到大约34 GFLOPS。但为什么不是40呢？难道不应该快两倍吗？
- en: 'Here is how one iteration of the loop looks in assembly:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何在汇编中查看循环的一次迭代的示例：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Every iteration, we need to execute 5 instructions. While the throughputs of
    all relevant execution ports allow to do that in one cycle on average, we can’t
    do that because the decode width of this particular CPU (Zen 2) is 4\. Therefore,
    the performance is limited by ⅘ of what it could have been.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代，我们需要执行5条指令。虽然所有相关执行端口的吞吐量允许在平均一个周期内完成这些操作，但我们不能这样做，因为这个特定CPU（Zen 2）的解码宽度是4。因此，性能受到限制，只有其可能性能的5/9。
- en: 'To mitigate this, we can once again double the number of SIMD blocks we process
    on each iteration:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻这一点，我们可以在每次迭代中再次加倍我们处理的SIMD块的数量：
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It now shows the throughput of 43 GFLOPS — or about 10x faster than the original
    scalar implementation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在显示的吞吐量为43 GFLOPS——或者大约比原始标量实现快10倍。
- en: 'Extending it to 64 values per cycle doesn’t help: small arrays suffer from
    the overhead of all these additional `movemask`-s when we hit the condition, and
    larger arrays are bottlenecked by [memory bandwidth](/hpc/cpu-cache/bandwidth)
    anyway.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将每个周期扩展到64个值并不能有所帮助：当遇到条件时，小数组会因为所有这些额外的`movemask`而受到开销的影响，而大数组无论如何都会因为[内存带宽](/hpc/cpu-cache/bandwidth)成为瓶颈。
- en: '### [#](https://en.algorithmica.org/hpc/simd/masking/#counting-values)Counting
    Values'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/masking/#counting-values) 计数值'
- en: 'As the final exercise, let’s find the count of a value in an array instead
    of just its first occurrence:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的练习，让我们找到数组中一个值的计数，而不仅仅是它的第一次出现：
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To vectorize it, we just need to convert the comparison mask to either one
    or zero per element and calculate the sum:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向量化它，我们只需要将比较掩码转换为每个元素为0或1，并计算总和：
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Both implementations yield ~15 GFLOPS: the compiler can vectorize the first
    one all by itself.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 两种实现都产生了大约15 GFLOPS：编译器可以完全自行向量化第一种实现。
- en: 'But a trick that the compiler can’t find is to notice that the mask of all
    ones is [minus one](/hpc/arithmetic/integer) when reinterpreted as an integer.
    So we can skip the and-the-lowest-bit part and use the mask itself, and then just
    negate the final result:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，编译器无法发现的一个技巧是，当重新解释为整数时，所有位都是1的掩码是[负一](/hpc/arithmetic/integer)。因此，我们可以跳过与最低位进行与操作的部分，并直接使用掩码本身，然后只需对最终结果取反：
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This doesn’t improve the performance in this particular architecture because
    the throughput is actually bottlenecked by updating `s`: there is a dependency
    on the previous iteration, so the loop can’t proceed faster than one iteration
    per CPU cycle. We can make use of [instruction-level parallelism](../reduction#instruction-level-parallelism)
    if we split the accumulator in two:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '这并不提高该特定架构的性能，因为吞吐量实际上是由更新`s`的操作瓶颈所限制的：存在对前一次迭代的依赖，因此循环不能比每个CPU周期一次迭代更快地执行。如果我们把累加器分成两部分，我们可以利用[指令级并行性](../reduction#instruction-level-parallelism)： '
- en: '[PRE16]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It now gives ~22 GFLOPS of performance, which is as high as it can get.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 它现在提供约22 GFLOPS的性能，这是可能达到的最高水平。
- en: When adapting this code for shorter data types, keep in mind that the accumulator
    may overflow. To work around this, add another accumulator of larger size and
    regularly stop the loop to add the values in the local accumulator to it and then
    reset the local accumulator. For example, for 8-bit integers, this means creating
    another inner loop that does $\lfloor \frac{256-1}{8} \rfloor = 15$ iterations.
    [← Reductions](https://en.algorithmica.org/hpc/simd/reduction/)[In-Register Shuffles
    →](https://en.algorithmica.org/hpc/simd/shuffling/)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当将此代码适配为较短的数据类型时，请注意累加器可能会溢出。为了解决这个问题，可以添加另一个更大的累加器，并定期停止循环，将本地累加器中的值添加到它，然后重置本地累加器。例如，对于8位整数，这意味着创建另一个内部循环，该循环执行
    $\lfloor \frac{256-1}{8} \rfloor = 15$ 次迭代。[← 减法操作](https://en.algorithmica.org/hpc/simd/reduction/)[寄存器内洗牌
    →](https://en.algorithmica.org/hpc/simd/shuffling/)
