- en: '8.1\. Motivating example: classifying natural images#'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap08_nn/01_motiv/roch-mmids-nn-motiv.html](https://mmids-textbook.github.io/chap08_nn/01_motiv/roch-mmids-nn-motiv.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this chapter, we return to the classification problem. This time we consider
    more complex datasets involving natural images. We have seen an example previously,
    the MNIST dataset. We use a related dataset known as Fashion-MNIST developed by
    the [Zalando Research](https://engineering.zalando.com/tags/zalando-research.html).
    Quoting from their [GitHub repository](https://github.com/zalandoresearch/fashion-mnist):'
  prefs: []
  type: TYPE_NORMAL
- en: Fashion-MNIST is a dataset of Zalando’s article images – consisting of a training
    set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28
    grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST
    to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking
    machine learning algorithms. It shares the same image size and structure of training
    and testing splits.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Figure:** Fashion-MNIST sample images ([Source](https://github.com/zalandoresearch/fashion-mnist))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fashion-MNIST sample images](../Images/ca5de089f1108499cd298a6112fb5d69.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: We first load the data and convert it to an appropriate matrix representation.
    The data can be accessed with [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For example, the first image and its label are the following. The [`squeeze()`](https://pytorch.org/docs/stable/generated/torch.Tensor.squeeze.html)
    below removes the color dimension in the image, which is grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/e147d6f854f4e44af9650dd813c7dd25d252f8f6cfe588b3dc237b732a50999b.png](../Images/519ce9781fa942190a03ecb90108d942.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This label is not particularly meaningful. One can get the actual names of the
    classes as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The purpose of this chapter is to develop some of the mathematical tools used
    to solve this kind of classification problem:'
  prefs: []
  type: TYPE_NORMAL
- en: neural networks,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: backpropagation,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: stochastic gradient descent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
