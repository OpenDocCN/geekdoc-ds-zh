["```py\nlibrary(boot)\nlibrary(broom.mixed)\nlibrary(collapse)\nlibrary(dataverse)\nlibrary(gutenbergr)\nlibrary(janitor)\nlibrary(marginaleffects)\nlibrary(modelsummary)\nlibrary(rstanarm)\nlibrary(tidybayes)\nlibrary(tidyverse)\nlibrary(tinytable)\n```", "```py\nset.seed(853)\n\nbernoulli_example <-\n tibble(draws = rbinom(n = 20, size = 1, prob = 0.1))\n\nbernoulli_example |> pull(draws)\n```", "```py\n [1] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n```", "```py\nset.seed(853)\n\nweek_or_weekday <-\n tibble(\n num_cars = sample.int(n = 100, size = 1000, replace = TRUE),\n noise = rnorm(n = 1000, mean = 0, sd = 10),\n is_weekday = if_else(num_cars + noise > 50, 1, 0)\n ) |>\n select(-noise)\n\nweek_or_weekday\n```", "```py\n# A tibble: 1,000 × 2\n   num_cars is_weekday\n      <int>      <dbl>\n 1        9          0\n 2       64          1\n 3       90          1\n 4       93          1\n 5       17          0\n 6       29          0\n 7       84          1\n 8       83          1\n 9        3          0\n10       33          1\n# ℹ 990 more rows\n```", "```py\nweek_or_weekday_model <-\n glm(\n is_weekday ~ num_cars,\n data = week_or_weekday,\n family = \"binomial\"\n )\n\nsummary(week_or_weekday_model)\n```", "```py\n Call:\nglm(formula = is_weekday ~ num_cars, family = \"binomial\", data = week_or_weekday)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -9.48943    0.74492  -12.74   <2e-16 ***\nnum_cars     0.18980    0.01464   12.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1386.26  on 999  degrees of freedom\nResidual deviance:  337.91  on 998  degrees of freedom\nAIC: 341.91\n\nNumber of Fisher Scoring iterations: 7\n```", "```py\nweek_or_weekday_predictions <-\n predictions(week_or_weekday_model) |>\n as_tibble()\n\nweek_or_weekday_predictions\n```", "```py\n# A tibble: 1,000 × 8\n   rowid estimate  p.value s.value  conf.low conf.high is_weekday num_cars\n   <int>    <dbl>    <dbl>   <dbl>     <dbl>     <dbl>      <dbl>    <int>\n 1     1 0.000417 1.40e-36   119\\.  0.000125   0.00139           0        9\n 2     2 0.934    9.33e-27    86.5 0.898      0.959             1       64\n 3     3 0.999    1.97e-36   119\\.  0.998      1.00              1       90\n 4     4 1.00     1.10e-36   119\\.  0.999      1.00              1       93\n 5     5 0.00190  1.22e-35   116\\.  0.000711   0.00508           0       17\n 6     6 0.0182   3.34e-32   105\\.  0.00950    0.0348            0       29\n 7     7 0.998    1.00e-35   116\\.  0.996      0.999             1       84\n 8     8 0.998    1.42e-35   116\\.  0.995      0.999             1       83\n 9     9 0.000134 5.22e-37   121\\.  0.0000338  0.000529          0        3\n10    10 0.0382   1.08e-29    96.2 0.0222     0.0649            1       33\n# ℹ 990 more rows\n```", "```py\n# Panel (a)\nweek_or_weekday_predictions |>\n mutate(is_weekday = factor(is_weekday)) |>\n ggplot(aes(x = num_cars, y = estimate, color = is_weekday)) +\n geom_jitter(width = 0.01, height = 0.01, alpha = 0.3) +\n labs(\n x = \"Number of cars that were seen\",\n y = \"Estimated probability it is a weekday\",\n color = \"Was actually weekday\"\n ) +\n theme_classic() +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n\n# Panel (b)\nweek_or_weekday_predictions |>\n mutate(is_weekday = factor(is_weekday)) |>\n ggplot(aes(x = num_cars, y = estimate, color = is_weekday)) +\n stat_ecdf(geom = \"point\", alpha = 0.75) +\n labs(\n x = \"Number of cars that were seen\",\n y = \"Estimated probability it is a weekday\",\n color = \"Actually weekday\"\n ) +\n theme_classic() +\n scale_color_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\nslopes(week_or_weekday_model, newdata = \"median\") |>\n select(term, estimate, std.error) |>\n tt() |> \n style_tt(j = 1:3, align = \"lrr\") |> \n format_tt(digits = 3, num_mark_big = \",\", num_fmt = \"decimal\") |> \n setNames(c(\"Term\", \"Estimate\", \"Standard error\"))\n```", "```py\nweek_or_weekday_rstanarm <-\n stan_glm(\n is_weekday ~ num_cars,\n data = week_or_weekday,\n family = binomial(link = \"logit\"),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 2.5, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n week_or_weekday_rstanarm,\n file = \"week_or_weekday_rstanarm.rds\"\n)\n```", "```py\nmodelsummary(\n list(\n \"Day or night\" = week_or_weekday_rstanarm\n )\n)\n```", "```py\nset.seed(853)\n\nnum_obs <- 1000\n\nus_political_preferences <- tibble(\n education = sample(0:4, size = num_obs, replace = TRUE),\n gender = sample(0:1, size = num_obs, replace = TRUE),\n support_prob = ((education + gender) / 5),\n) |>\n mutate(\n supports_biden = if_else(runif(n = num_obs) < support_prob, \"yes\", \"no\"),\n education = case_when(\n education == 0 ~ \"< High school\",\n education == 1 ~ \"High school\",\n education == 2 ~ \"Some college\",\n education == 3 ~ \"College\",\n education == 4 ~ \"Post-grad\"\n ),\n gender = if_else(gender == 0, \"Male\", \"Female\")\n ) |>\n select(-support_prob, supports_biden, gender, education)\n```", "```py\nces2020 <-\n get_dataframe_by_name(\n filename = \"CES20_Common_OUTPUT_vv.csv\",\n dataset = \"10.7910/DVN/E9N6PH\",\n server = \"dataverse.harvard.edu\",\n .f = read_csv\n ) |>\n select(votereg, CC20_410, gender, educ)\n\nwrite_csv(ces2020, \"ces2020.csv\")\n```", "```py\nces2020 <-\n read_csv(\n \"ces2020.csv\",\n col_types =\n cols(\n \"votereg\" = col_integer(),\n \"CC20_410\" = col_integer(),\n \"gender\" = col_integer(),\n \"educ\" = col_integer()\n )\n )\n\nces2020\n```", "```py\n# A tibble: 61,000 × 4\n   votereg CC20_410 gender  educ\n     <int>    <int>  <int> <int>\n 1       1        2      1     4\n 2       2       NA      2     6\n 3       1        1      2     5\n 4       1        1      2     5\n 5       1        4      1     5\n 6       1        2      1     3\n 7       2       NA      1     3\n 8       1        2      2     3\n 9       1        2      2     2\n10       1        1      2     5\n# ℹ 60,990 more rows\n```", "```py\nces2020 <-\n ces2020 |>\n filter(votereg == 1,\n CC20_410 %in% c(1, 2)) |>\n mutate(\n voted_for = if_else(CC20_410 == 1, \"Biden\", \"Trump\"),\n voted_for = as_factor(voted_for),\n gender = if_else(gender == 1, \"Male\", \"Female\"),\n education = case_when(\n educ == 1 ~ \"No HS\",\n educ == 2 ~ \"High school graduate\",\n educ == 3 ~ \"Some college\",\n educ == 4 ~ \"2-year\",\n educ == 5 ~ \"4-year\",\n educ == 6 ~ \"Post-grad\"\n ),\n education = factor(\n education,\n levels = c(\n \"No HS\",\n \"High school graduate\",\n \"Some college\",\n \"2-year\",\n \"4-year\",\n \"Post-grad\"\n )\n )\n ) |>\n select(voted_for, gender, education)\n```", "```py\nces2020 |>\n ggplot(aes(x = education, fill = voted_for)) +\n stat_count(position = \"dodge\") +\n facet_wrap(facets = vars(gender)) +\n theme_minimal() +\n labs(\n x = \"Highest education\",\n y = \"Number of respondents\",\n fill = \"Voted for\"\n ) +\n coord_flip() +\n scale_fill_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\nset.seed(853)\n\nces2020_reduced <- \n ces2020 |> \n slice_sample(n = 1000)\n\npolitical_preferences <-\n stan_glm(\n voted_for ~ gender + education,\n data = ces2020_reduced,\n family = binomial(link = \"logit\"),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = \n normal(location = 0, scale = 2.5, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n political_preferences,\n file = \"political_preferences.rds\"\n)\n```", "```py\npolitical_preferences <-\n readRDS(file = \"political_preferences.rds\")\n```", "```py\nmodelsummary(\n list(\n \"Support Biden\" = political_preferences\n ),\n statistic = \"mad\"\n )\n```", "```py\nmodelplot(political_preferences, conf_level = 0.9) +\n labs(x = \"90 per cent credibility interval\")\n```", "```py\nrpois(n = 20, lambda = 3)\n```", "```py\n [1] 3 1 5 6 2 0 2 4 6 2 1 0 3 3 2 2 2 2 2 6\n```", "```py\nset.seed(853)\n\nclass_size <- 26\n\ncount_of_A <-\n tibble(\n # From Chris DuBois: https://stackoverflow.com/a/1439843\n department = \n c(rep.int(\"1\", 26), rep.int(\"2\", 26), rep.int(\"3\", 26)),\n course = c(\n paste0(\"DEP_1_\", letters),\n paste0(\"DEP_2_\", letters),\n paste0(\"DEP_3_\", letters)\n ),\n number_of_As = c(\n rpois(n = class_size, lambda = 5),\n rpois(n = class_size, lambda = 10),\n rpois(n = class_size, lambda = 20)\n )\n )\n```", "```py\ncount_of_A |>\n ggplot(aes(x = number_of_As)) +\n geom_histogram(aes(fill = department), position = \"dodge\") +\n labs(\n x = \"Number of As awarded\",\n y = \"Number of classes\",\n fill = \"Department\"\n ) +\n theme_classic() +\n scale_fill_brewer(palette = \"Set1\") +\n theme(legend.position = \"bottom\")\n```", "```py\ngrades_base <-\n glm(\n number_of_As ~ department,\n data = count_of_A,\n family = \"poisson\"\n )\n\nsummary(grades_base)\n```", "```py\n Call:\nglm(formula = number_of_As ~ department, family = \"poisson\", \n    data = count_of_A)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.3269     0.1010  13.135  < 2e-16 ***\ndepartment2   0.8831     0.1201   7.353 1.94e-13 ***\ndepartment3   1.7029     0.1098  15.505  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 426.201  on 77  degrees of freedom\nResidual deviance:  75.574  on 75  degrees of freedom\nAIC: 392.55\n\nNumber of Fisher Scoring iterations: 4\n```", "```py\ngrades_rstanarm <-\n stan_glm(\n number_of_As ~ department,\n data = count_of_A,\n family = poisson(link = \"log\"),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 2.5, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n grades_rstanarm,\n file = \"grades_rstanarm.rds\"\n)\n```", "```py\nmodelsummary(\n list(\n \"Number of As\" = grades_rstanarm\n )\n)\n```", "```py\nslopes(grades_rstanarm) |>\n select(contrast, estimate, conf.low, conf.high) |>\n unique() |> \n tt() |> \n style_tt(j = 1:4, align = \"lrrr\") |> \n format_tt(digits = 2, num_mark_big = \",\", num_fmt = \"decimal\") |> \n setNames(c(\"Compare department\", \"Estimate\", \"2.5%\", \"97.5%\"))\n```", "```py\ncount_of_e_simulation <-\n tibble(\n chapter = c(rep(1, 10), rep(2, 10), rep(3, 10)),\n line = rep(1:10, 3),\n number_words_in_line = runif(min = 0, max = 15, n = 30) |> round(0),\n number_e = rpois(n = 30, lambda = 10)\n )\n\ncount_of_e_simulation |>\n ggplot(aes(y = number_e, x = number_words_in_line)) +\n geom_point() +\n labs(\n x = \"Number of words in line\",\n y = \"Number of e/Es in the first ten lines\"\n ) +\n theme_classic() +\n scale_fill_brewer(palette = \"Set1\")\n```", "```py\ngutenberg_id_of_janeeyre <- 1260\n\njane_eyre <-\n gutenberg_download(\n gutenberg_id = gutenberg_id_of_janeeyre,\n mirror = \"https://gutenberg.pglaf.org/\"\n )\n\njane_eyre\n\nwrite_csv(jane_eyre, \"jane_eyre.csv\")\n```", "```py\njane_eyre <- read_csv(\n \"jane_eyre.csv\",\n col_types = cols(\n gutenberg_id = col_integer(),\n text = col_character()\n )\n)\n\njane_eyre\n```", "```py\n# A tibble: 21,001 × 2\n   gutenberg_id text                           \n          <int> <chr>                          \n 1         1260 JANE EYRE                      \n 2         1260 AN AUTOBIOGRAPHY               \n 3         1260 <NA>                           \n 4         1260 by Charlotte Brontë            \n 5         1260 <NA>                           \n 6         1260 _ILLUSTRATED BY F. H. TOWNSEND_\n 7         1260 <NA>                           \n 8         1260 London                         \n 9         1260 SERVICE & PATON                \n10         1260 5 HENRIETTA STREET             \n# ℹ 20,991 more rows\n```", "```py\njane_eyre_reduced <-\n jane_eyre |>\n filter(!is.na(text)) |> # Remove empty lines\n mutate(chapter = if_else(str_detect(text, \"CHAPTER\") == TRUE,\n text,\n NA_character_)) |> # Find start of chapter\n fill(chapter, .direction = \"down\") |> \n mutate(chapter_line = row_number(), \n .by = chapter) |> # Add line number to each chapter\n filter(!is.na(chapter), \n chapter_line %in% c(2:11)) |> # Remove \"CHAPTER I\" etc\n select(text, chapter) |>\n mutate(\n chapter = str_remove(chapter, \"CHAPTER \"),\n chapter = str_remove(chapter, \"—CONCLUSION\"),\n chapter = as.integer(as.roman(chapter))\n ) |> # Change chapters to integers\n mutate(count_e = str_count(text, \"e|E\"),\n word_count = str_count(text, \"\\\\w+\")\n # From: https://stackoverflow.com/a/38058033\n ) \n```", "```py\njane_eyre_reduced |>\n select(chapter, word_count, count_e, text) |>\n head()\n```", "```py\n# A tibble: 6 × 4\n  chapter word_count count_e text                                               \n    <int>      <int>   <int> <chr>                                              \n1       1         13       5 There was no possibility of taking a walk that day…\n2       1         11       8 wandering, indeed, in the leafless shrubbery an ho…\n3       1         12       9 but since dinner (Mrs. Reed, when there was no com…\n4       1         14       3 the cold winter wind had brought with it clouds so…\n5       1         11       7 so penetrating, that further outdoor exercise was …\n6       1          1       1 question. \n```", "```py\nmean_e <- mean(jane_eyre_reduced$count_e)\nvariance_e <- var(jane_eyre_reduced$count_e)\n\njane_eyre_reduced |>\n ggplot(aes(x = count_e)) +\n geom_histogram() +\n geom_vline(xintercept = mean_e, \n linetype = \"dashed\", \n color = \"#C64191\") +\n geom_vline(xintercept = variance_e, \n linetype = \"dashed\", \n color = \"#0ABAB5\") +\n theme_minimal() +\n labs(\n y = \"Count\",\n x = \"Number of e's per line for first ten lines\"\n )\n\njane_eyre_reduced |>\n ggplot(aes(x = word_count, y = count_e)) +\n geom_jitter(alpha = 0.5) +\n geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n theme_minimal() +\n labs(\n x = \"Number of words in the line\",\n y = \"Number of e/Es in the line\"\n )\n```", "```py\njane_e_counts <-\n stan_glm(\n count_e ~ word_count,\n data = jane_eyre_reduced,\n family = poisson(link = \"log\"),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 2.5, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n jane_e_counts,\n file = \"jane_e_counts.rds\"\n)\n```", "```py\nplot_predictions(jane_e_counts, condition = \"word_count\") +\n labs(x = \"Number of words\",\n y = \"Average number of e/Es in the first 10 lines\") +\n theme_classic()\n```", "```py\nalberta_death_simulation <-\n tibble(\n cause = rep(x = c(\"Heart\", \"Stroke\", \"Diabetes\"), times = 10),\n year = rep(x = 2016:2018, times = 10),\n deaths = rnbinom(n = 30, size = 20, prob = 0.1)\n )\n\nalberta_death_simulation\n```", "```py\n# A tibble: 30 × 3\n   cause     year deaths\n   <chr>    <int>  <int>\n 1 Heart     2016    241\n 2 Stroke    2017    197\n 3 Diabetes  2018    139\n 4 Heart     2016    136\n 5 Stroke    2017    135\n 6 Diabetes  2018    130\n 7 Heart     2016    194\n 8 Stroke    2017    211\n 9 Diabetes  2018    190\n10 Heart     2016    142\n# ℹ 20 more rows\n```", "```py\nalberta_cod <-\n read_csv(\n \"https://open.alberta.ca/dataset/03339dc5-fb51-4552-97c7-853688fc428d/resource/3e241965-fee3-400e-9652-07cfbf0c0bda/download/deaths-leading-causes.csv\",\n skip = 2,\n col_types = cols(\n `Calendar Year` = col_integer(),\n Cause = col_character(),\n Ranking = col_integer(),\n `Total Deaths` = col_integer()\n )\n ) |>\n clean_names() |>\n add_count(cause) |>\n mutate(cause = str_trunc(cause, 30))\n```", "```py\nalberta_cod |>\n filter(\n calendar_year == 2021,\n ranking <= 10\n ) |>\n mutate(total_deaths = format(total_deaths, big.mark = \",\")) |>\n tt() |> \n style_tt(j = 1:5, align = \"lrrrr\") |> \n format_tt(digits = 0, num_mark_big = \",\", num_fmt = \"decimal\") |> \n setNames(c(\"Year\", \"Cause\", \"Ranking\", \"Deaths\", \"Years\"))\n```", "```py\nalberta_cod_top_five <-\n alberta_cod |>\n filter(\n calendar_year == 2021,\n n == 21\n ) |>\n slice_max(order_by = desc(ranking), n = 5) |>\n pull(cause)\n\nalberta_cod <-\n alberta_cod |>\n filter(cause %in% alberta_cod_top_five)\n```", "```py\nalberta_cod |>\n ggplot(aes(x = calendar_year, y = total_deaths, color = cause)) +\n geom_line() +\n theme_minimal() +\n scale_color_brewer(palette = \"Set1\") +\n labs(x = \"Year\", y = \"Annual number of deaths in Alberta\") +\n facet_wrap(vars(cause), dir = \"v\", ncol = 1) +\n theme(legend.position = \"none\")\n```", "```py\ncause_of_death_alberta_poisson <-\n stan_glm(\n total_deaths ~ cause,\n data = alberta_cod,\n family = poisson(link = \"log\"),\n seed = 853\n )\n\ncause_of_death_alberta_neg_binomial <-\n stan_glm(\n total_deaths ~ cause,\n data = alberta_cod,\n family = neg_binomial_2(link = \"log\"),\n seed = 853\n )\n```", "```py\ncoef_short_names <- \n c(\"causeAll other forms of chronic ischemic heart disease\"\n = \"causeAll other forms of...\",\n \"causeMalignant neoplasms of trachea, bronchus and lung\"\n = \"causeMalignant neoplas...\",\n \"causeOrganic dementia\"\n = \"causeOrganic dementia\",\n \"causeOther chronic obstructive pulmonary disease\"\n = \"causeOther chronic obst...\"\n )\n\nmodelsummary(\n list(\n \"Poisson\" = cause_of_death_alberta_poisson,\n \"Negative binomial\" = cause_of_death_alberta_neg_binomial\n ),\n coef_map = coef_short_names\n)\n```", "```py\npp_check(cause_of_death_alberta_poisson) +\n theme(legend.position = \"bottom\")\n\npp_check(cause_of_death_alberta_neg_binomial) +\n theme(legend.position = \"bottom\")\n```", "```py\npoisson <- loo(cause_of_death_alberta_poisson, cores = 2)\nneg_binomial <- loo(cause_of_death_alberta_neg_binomial, cores = 2)\n\nloo_compare(poisson, neg_binomial)\n```", "```py\n elpd_diff se_diff\ncause_of_death_alberta_neg_binomial     0.0       0.0\ncause_of_death_alberta_poisson      -4536.7    1089.5\n```", "```py\nset.seed(853)\n\npolitical_support <-\n tibble(\n state = sample(1:50, size = 1000, replace = TRUE),\n gender = sample(c(1, 2), size = 1000, replace = TRUE),\n noise = rnorm(n = 1000, mean = 0, sd = 10) |> round(),\n supports = if_else(state + gender + noise > 50, 1, 0)\n )\n\npolitical_support\n```", "```py\n# A tibble: 1,000 × 4\n   state gender noise supports\n   <int>  <dbl> <dbl>    <dbl>\n 1     9      1    11        0\n 2    26      1     3        0\n 3    29      2     7        0\n 4    17      2    13        0\n 5    37      2    11        0\n 6    29      2     9        0\n 7    50      2     3        1\n 8    20      2     3        0\n 9    19      1    -1        0\n10     3      2     7        0\n# ℹ 990 more rows\n```", "```py\nvoter_preferences <-\n stan_glmer(\n supports ~ gender + (1 | state),\n data = political_support,\n family = binomial(link = \"logit\"),\n prior = normal(location = 0, scale = 2.5, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 2.5, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n voter_preferences,\n file = \"voter_preferences.rds\"\n)\n```", "```py\nvoter_preferences\n```", "```py\nstan_glmer\n family:       binomial [logit]\n formula:      supports ~ gender + (1 | state)\n observations: 1000\n------\n            Median MAD_SD\n(Intercept) -4.4    0.7  \ngender       0.4    0.3  \n\nError terms:\n Groups Name        Std.Dev.\n state  (Intercept) 2.5     \nNum. levels: state 50 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```", "```py\nauthors <- c(\"Austen, Jane\", \"Dickens, Charles\", \n \"Shakespeare, William\", \"Brontë, Charlotte\")\n\n# The document values for duplicates and letters that we do not want\ndont_get_shakespeare <-\n c(2270, 4774, 5137, 9077, 10606, 12578, 22791, 23041, 23042, 23043, \n 23044, 23045, 23046, 28334, 45128, 47518, 47715, 47960, 49007, \n 49008, 49297, 50095, 50559)\ndont_get_bronte <- c(31100, 42078)\ndont_get_dickens <-\n c(25852, 25853, 25854, 30368, 32241, 35536, 37121, 40723, 42232, 43111, \n 43207, 46675, 47529, 47530, 47531, 47534, 47535, 49927, 50334)\n\nbooks <-\n gutenberg_works(\n author %in% authors,\n !gutenberg_id %in% \n c(dont_get_shakespeare, dont_get_bronte, dont_get_dickens)\n ) |>\n gutenberg_download(\n meta_fields = c(\"title\", \"author\"),\n mirror = \"https://gutenberg.pglaf.org/\"\n )\n\nwrite_csv(books, \"books-austen_bronte_dickens_shakespeare.csv\")\n```", "```py\nbooks <- read_csv(\n \"books-austen_bronte_dickens_shakespeare.csv\",\n col_types = cols(\n gutenberg_id = col_integer(),\n text = col_character(),\n title = col_character(),\n author = col_character()\n )\n)\n```", "```py\nlines_by_author_work <-\n books |>\n summarise(number_of_lines = n(),\n .by = c(author, title))\n\nlines_by_author_work\n```", "```py\n# A tibble: 125 × 3\n   author            title                       number_of_lines\n   <chr>             <chr>                                 <int>\n 1 Austen, Jane      Emma                                  16488\n 2 Austen, Jane      Lady Susan                             2525\n 3 Austen, Jane      Love and Freindship [sic]              3401\n 4 Austen, Jane      Mansfield Park                        15670\n 5 Austen, Jane      Northanger Abbey                       7991\n 6 Austen, Jane      Persuasion                             8353\n 7 Austen, Jane      Pride and Prejudice                   14199\n 8 Austen, Jane      Sense and Sensibility                 12673\n 9 Brontë, Charlotte Jane Eyre: An Autobiography           21001\n10 Brontë, Charlotte Shirley                               25520\n# ℹ 115 more rows\n```", "```py\nauthor_lines_rstanarm <-\n stan_glm(\n number_of_lines ~ author,\n data = lines_by_author_work,\n family = neg_binomial_2(link = \"log\"),\n prior = normal(location = 0, scale = 3, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 3, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n author_lines_rstanarm,\n file = \"author_lines_rstanarm.rds\"\n)\n\nauthor_lines_rstanarm_multilevel <-\n stan_glmer(\n number_of_lines ~ (1 | author),\n data = lines_by_author_work,\n family = neg_binomial_2(link = \"log\"),\n prior = normal(location = 0, scale = 3, autoscale = TRUE),\n prior_intercept = normal(location = 0, scale = 3, autoscale = TRUE),\n seed = 853\n )\n\nsaveRDS(\n author_lines_rstanarm_multilevel,\n file = \"author_lines_rstanarm_multilevel.rds\"\n)\n```", "```py\nmodelsummary(\n list(\n \"Neg binomial\" = author_lines_rstanarm,\n \"Multilevel neg binomial\" = author_lines_rstanarm_multilevel\n )\n)\n```", "```py\nauthor_lines_rstanarm_multilevel |>\n spread_draws(`(Intercept)`, b[, group]) |>\n mutate(condition_mean = `(Intercept)` + b) |>\n ggplot(aes(y = group, x = condition_mean)) +\n stat_halfeye() +\n theme_minimal()\n```", "```py\nvote_data <-\n read_csv(\n \"https://raw.githubusercontent.com/TheUpshot/2016-upshot-siena-polls/master/upshot-siena-polls.csv\"\n )\n\ncleaned_vote_data <-\n vote_data |>\n select(vt_pres_2, gender, educ, age, state) |>\n rename(vote = vt_pres_2) |>\n mutate(\n gender = factor(gender),\n educ = factor(educ),\n state = factor(state),\n age = as.integer(age)\n ) |>\n mutate(\n vote =\n case_when(\n vote == \"Donald Trump, the Republican\" ~ \"0\",\n vote == \"Hillary Clinton, the Democrat\" ~ \"1\",\n TRUE ~ vote\n )\n ) |>\n filter(vote %in% c(\"0\", \"1\")) |>\n mutate(vote = as.integer(vote))\n```", "```py\nvote_model <-\n stan_glm(\n formula = vote ~ age + educ,\n data = cleaned_vote_data,\n family = gaussian(),\n prior = normal(location = 0, scale = 2.5),\n prior_intercept = normal(location = 0, scale = 2.5),\n prior_aux = exponential(rate = 1),\n seed = 853\n )\n```"]