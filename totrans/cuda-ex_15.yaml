- en: '**Chapter 12 The Final Countdown**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**第12章 最终倒计时**'
- en: Congratulations! We hope you’ve enjoyed learning about CUDA C and experimenting
    some with GPU computing. It’s been a long trip, so let’s take a moment to review
    where we started and how much ground we’ve covered. Starting with a background
    in C or C++ programming, we’ve learned how to use the CUDA runtime’s angle bracket
    syntax to easily launch multiple copies of kernels across any number of multiprocessors.
    We expanded these concepts to use collections of threads *and* blocks, operating
    on arbitrarily large inputs. These more complex launches exploited interthread
    communication using the GPU’s special, on-chip shared memory, and they employed
    dedicated synchronization primitives to ensure correct operation in an environment
    that supports (and encourages) thousands upon thousands of parallel threads.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！希望你在学习CUDA C并进行一些GPU计算实验的过程中感到愉快。这是一段漫长的旅程，所以让我们花点时间回顾一下我们从哪里开始，以及我们已经取得了多少进展。从具有C或C++编程背景开始，我们学习了如何使用CUDA运行时的尖括号语法，轻松地在任意数量的多处理器上启动多个内核副本。我们将这些概念扩展到使用线程*和*块的集合，处理任意大的输入。这些更复杂的启动操作利用了GPU的特殊片上共享内存进行线程间通信，并使用了专用的同步原语，以确保在支持（并鼓励）成千上万并行线程的环境中正确操作。
- en: Armed with basic concepts about parallel programming using CUDA C on NVIDIA’s
    CUDA Architecture, we explored some of the more advanced concepts and APIs that
    NVIDIA provides. The GPU’s dedicated graphics hardware proves useful for GPU computing,
    so we learned how to exploit texture memory to accelerate some common patterns
    of memory access. Because many users add GPU computing to their interactive graphics
    applications, we explored the interoperation of CUDA C kernels with industry-standard
    graphics APIs such as OpenGL and DirectX. Atomic operations on both global and
    shared memory allowed safe, multithreaded access to common memory locations. Moving
    steadily into more and more advanced topics, streams enabled us to keep our entire
    system as busy as possible, allowing kernels to execute simultaneously with memory
    copies between the host and GPU. Finally, we looked at the ways in which we could
    allocate and use zero-copy memory to accelerate applications on integrated GPUs.
    Moreover, we learned to initialize multiple devices and allocate portable pinned
    memory in order to write CUDA C that fully utilizes increasingly common, multi-GPU
    environments.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了使用CUDA C在NVIDIA CUDA架构上进行并行编程的基本概念后，我们探索了一些NVIDIA提供的更高级的概念和API。GPU的专用图形硬件在GPU计算中证明了其价值，因此我们学习了如何利用纹理内存来加速一些常见的内存访问模式。由于许多用户将GPU计算添加到他们的互动图形应用程序中，我们探讨了CUDA
    C内核与行业标准图形API（如OpenGL和DirectX）的互操作性。对全局内存和共享内存进行的原子操作使得多线程安全地访问公共内存位置成为可能。随着我们稳步深入越来越高级的主题，流（streams）使我们能够保持整个系统尽可能繁忙，让内核能够在主机和GPU之间的内存拷贝同时执行。最后，我们探讨了如何分配和使用零拷贝内存，以加速集成GPU上的应用程序。此外，我们还学习了如何初始化多个设备并分配可移植的固定内存，以编写能够充分利用日益普及的多GPU环境的CUDA
    C代码。
- en: '**12.1 Chapter Objectives**'
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.1 章节目标**'
- en: 'Through the course of this chapter, you will accomplish the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章节的学习过程中，你将完成以下任务：
- en: • You will learn about some of the tools available to aid your CUDA C development.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将了解一些可用于辅助CUDA C开发的工具。
- en: • You will learn about additional written and code resources to take your CUDA
    C development to the next level.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习到更多的书面和代码资源，以将你的CUDA C开发提升到更高的水平。
- en: '**12.2 CUDA Tools**'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.2 CUDA工具**'
- en: Through the course of this book, we have relied upon several components of the
    CUDA C software system. The applications we wrote made heavy use of the CUDA C
    compiler in order to convert our CUDA C kernels into code that could be executed
    on NVIDIA GPUs. We also used the CUDA runtime in order to perform much of the
    setup and dirty work behind launching kernels and communicating with the GPU.
    The CUDA runtime, in turn, uses the CUDA driver to talk directly to the hardware
    in your system. In addition to these components that we have already used at length,
    NVIDIA makes available a host of other software in order to ease the development
    of CUDA C applications. This section does not serve well as a user’s manual to
    these products, but rather, it aims solely to inform you of the existence and
    utility of these packages.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的过程中，我们依赖了 CUDA C 软件系统的多个组件。我们编写的应用程序大量使用了 CUDA C 编译器，将我们的 CUDA C 核心转换成可以在
    NVIDIA GPU 上执行的代码。我们还使用了 CUDA 运行时来执行大部分设置工作和启动内核以及与 GPU 通信的“脏活”。CUDA 运行时反过来使用
    CUDA 驱动程序直接与系统硬件进行通信。除了这些我们已经详细使用过的组件，NVIDIA 还提供了其他一些软件，旨在简化 CUDA C 应用程序的开发。本节并不是这些产品的用户手册，而是专门向你介绍这些软件包的存在及其用途。
- en: '**12.2.1 CUDA Toolkit**'
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.1 CUDA 工具包**'
- en: You almost certainly already have the CUDA Toolkit collection of software on
    your development machine. We can be so sure of this because the set of CUDA C
    compiler tools comprises one of the principal components of this package. If you
    don’t have the CUDA Toolkit on your machine, then it’s a veritable certainty that
    you haven’t tried to write or compile any CUDA C code. We’re on to you now, sucker!
    Actually, this is no big deal (but it does make us wonder why you’ve read this
    entire book). On the other hand, if you *have* been working through the examples
    in this book, then you should possess the libraries we’re about to discuss.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎可以肯定已经在你的开发机器上安装了 CUDA 工具包。这一点我们敢这么肯定，因为 CUDA C 编译器工具集是这个包的核心组件之一。如果你的机器上没有安装
    CUDA 工具包，那你几乎可以确定自己没有尝试编写或编译任何 CUDA C 代码。我们现在知道了，傻瓜！实际上，这不是什么大事（但我们还是忍不住想知道你为什么读完了整本书）。另一方面，如果你*确实*在跟随本书的示例进行学习，那么你应该已经具备了我们接下来要讨论的库。
- en: '**12.2.2 CUFFT**'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.2 CUFFT**'
- en: 'The CUDA Toolkit comes with two very important utility libraries if you plan
    to pursue GPU computing in your own applications. First, NVIDIA provides a tuned
    Fast Fourier Transform library known as *CUFFT*. As of release 3.0, the CUFFT
    library supports a number of useful features, including the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算在自己的应用程序中进行 GPU 计算，CUDA 工具包包含了两个非常重要的实用库。首先，NVIDIA 提供了一个经过调优的快速傅里叶变换库，称为
    *CUFFT*。从 3.0 版本开始，CUFFT 库支持许多有用的功能，包括以下内容：
- en: • One-, two-, and three-dimensional transforms of both real-valued and complex-valued
    input data
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: • 一维、二维和三维变换，支持实值和复值输入数据
- en: • Batch execution for performing multiple one-dimensional transforms in parallel
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: • 批量执行，支持并行执行多个一维变换
- en: • 2D and 3D transforms with sizes ranging from 2 to 16,384 in any dimension
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: • 支持二维和三维变换，尺寸范围从 2 到 16,384，任意维度
- en: • 1D transforms of inputs up to 8 million elements in size
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: • 支持最大达到800万个元素的输入的一维变换
- en: • In-place and out-of-place transforms for both real-valued and complex-valued
    data
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: • 支持实值和复值数据的原地和非原地变换
- en: NVIDIA provides the CUFFT library free of charge with an accompanying license
    that allows for use in any application, regardless of whether it’s for personal,
    academic, or professional development.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 提供了免费的 CUFFT 库，并附带许可，允许在任何应用中使用，无论是个人、学术还是职业开发。
- en: '**12.2.3 CUBLAS**'
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.3 CUBLAS**'
- en: In addition to a Fast Fourier Transform library, NVIDIA also provides a library
    of linear algebra routines that implements the well-known package of Basic Linear
    Algebra Subprograms (BLAS). This library, named *CUBLAS*, is also freely available
    and supports a large subset of the full BLAS package. This includes versions of
    each routine that accept both single- and double-precision inputs as well as real-
    and complex-valued data. Because BLAS was originally a FORTRAN-implemented library
    of linear algebra routines, NVIDIA attempts to maximize compatibility with the
    requirements and expectations of these implementations. Specifically, the CUBLAS
    library uses a column-major storage layout for arrays, rather than the row-major
    layout natively used by C and C++. In practice, this is not typically a concern,
    but it does allow for current users of BLAS to adapt their applications to exploit
    the GPU-accelerated CUBLAS with minimal effort. NVIDIA also distributes FORTRAN
    bindings to CUBLAS in order to demonstrate how to link existing FORTRAN applications
    to CUDA libraries.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了快速傅里叶变换库，NVIDIA 还提供了一个线性代数库，实现了著名的基础线性代数子程序包（BLAS）。这个库名为 *CUBLAS*，也是免费提供的，并支持
    BLAS 包的一个大子集。这包括接受单精度和双精度输入以及实数和复数数据的每个例程的版本。由于 BLAS 最初是一个用 FORTRAN 实现的线性代数例程库，NVIDIA
    尝试最大化与这些实现的要求和期望的兼容性。具体来说，CUBLAS 库使用列主存储布局来存储数组，而不是 C 和 C++ 本地使用的行主存储布局。实际上，这通常不会成为一个问题，但它确实使得现有的
    BLAS 用户能够轻松地将他们的应用程序适配到 GPU 加速的 CUBLAS 上。NVIDIA 还分发了 CUBLAS 的 FORTRAN 绑定，以演示如何将现有的
    FORTRAN 应用程序链接到 CUDA 库。
- en: '**12.2.4 NVIDIA GPU Computing SDK**'
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.4 NVIDIA GPU 计算 SDK**'
- en: 'Available separately from the NVIDIA drivers and CUDA Toolkit, the optional
    *GPU Computing SDK* download contains a package of dozens and dozens of sample
    GPU computing applications. We mentioned this SDK earlier in the book because
    its samples serve as an excellent complement to the material we’ve covered in
    the first 11 chapters. But if you haven’t taken a look yet, NVIDIA has geared
    these samples toward varying levels of CUDA C competency as well as spreading
    them over a broad spectrum of subject material. The samples are roughly categorized
    into the following sections:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 可单独从 NVIDIA 驱动程序和 CUDA 工具包中获取，可选的 *GPU 计算 SDK* 下载包含了数十个 GPU 计算应用程序示例包。我们在本书中早些时候提到过这个
    SDK，因为它的示例作为我们在前 11 章中所覆盖的内容的极好补充。但如果你还没有查看过，NVIDIA 将这些示例针对不同级别的 CUDA C 能力进行了设计，并覆盖了广泛的主题内容。这些示例大致分为以下几个部分：
- en: CUDA Basic Topics
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 基础主题
- en: CUDA Advanced Topics
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 高级主题
- en: CUDA Systems Integration
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 系统集成
- en: Data-Parallel Algorithms
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行算法
- en: Graphics Interoperability
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图形互操作性
- en: Texture
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 纹理
- en: Performance Strategies
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 性能策略
- en: Linear Algebra
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数
- en: Image/Video Processing
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图像/视频处理
- en: Computational Finance
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 计算金融
- en: Data Compression
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据压缩
- en: Physically-Based Simulation
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于物理的仿真
- en: The examples work on any platform that CUDA C works on and can serve as excellent
    jumping-off points for your own applications. For readers who have considerable
    experience in some of these areas, we warn you against expecting to see state-of-the-art
    implementations of your favorite algorithms in the NVIDIA GPU Computing SDK. These
    code samples should not be treated as production-worthy library code but rather
    as educational illustrations of functioning CUDA C programs, not unlike the examples
    in this book.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例可以在任何支持 CUDA C 的平台上运行，并且可以作为你自己应用程序的优秀起点。对于那些在这些领域有丰富经验的读者，我们提醒你不要指望在 NVIDIA
    GPU 计算 SDK 中看到你最喜欢的算法的最前沿实现。这些代码示例不应被视为生产级的库代码，而应视为功能性 CUDA C 程序的教育性示例，类似于本书中的示例。
- en: '**12.2.5 NVIDIA Performance Primitives**'
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.5 NVIDIA 性能原语**'
- en: In addition to the routines offered in the CUFFT and CUBLAS libraries, NVIDIA
    also maintains a library of functions for performing CUDA-accelerated data processing
    known as the NVIDIA Performance Primitives (NPP). Currently, NPP’s initial set
    of functionality focuses specifically on imaging and video processing and is widely
    applicable for developers in these areas. NVIDIA intends for NPP to evolve over
    time to address a greater number of computing tasks in a wider range of domains.
    If you have an interest in high-performance imaging or video applications, you
    should make it a priority to look into NPP, available as a free download at [www.nvidia.com/object/npp.html](http://www.nvidia.com/object/npp.html)
    (or accessible from your favorite web search engine).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在CUFFT和CUBLAS库中提供的例程外，NVIDIA还维护了一组用于执行CUDA加速数据处理的函数库，称为NVIDIA性能原语（NPP）。目前，NPP的初始功能集专注于图像和视频处理，并且在这些领域的开发者中得到广泛应用。NVIDIA计划随着时间推移让NPP演进，以应对更多计算任务并涵盖更广泛的领域。如果你对高性能的图像或视频应用感兴趣，应该优先关注NPP，它可以通过[www.nvidia.com/object/npp.html](http://www.nvidia.com/object/npp.html)免费下载（或通过你喜欢的搜索引擎访问）。
- en: '**12.2.6 Debugging CUDA C**'
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.6 调试CUDA C**'
- en: We have heard from a variety of sources that, in rare instances, computer software
    does not work exactly as intended when first executed. Some code computes incorrect
    values, some fails to terminate execution, and some code even puts the computer
    into a state that only a flip of the power switch can remedy. Although having
    clearly *never* written code like this personally, the authors of this book recognize
    that some software engineers may desire resources to debug their CUDA C kernels.
    Fortunately, NVIDIA provides tools to make this painful process significantly
    less troublesome.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从各种来源听说过，在极少数情况下，计算机软件在首次执行时并没有完全按预期工作。有些代码计算出错误的值，有些代码未能终止执行，还有些代码甚至让计算机进入只能通过切换电源才能恢复的状态。尽管*从未*亲自编写过这样的代码，本书的作者认识到，某些软件工程师可能需要资源来调试他们的CUDA
    C内核。幸运的是，NVIDIA提供了一些工具，使这个痛苦的过程变得不那么麻烦。
- en: '**CUDA-GDB**'
  id: totrans-40
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**CUDA-GDB**'
- en: 'A tool known as *CUDA-GDB* is one of the most useful CUDA downloads available
    to CUDA C programmers who develop their code on Linux-based systems. NVIDIA extended
    the open source GNU debugger (`gdb`) to transparently support debugging device
    code in real time while maintaining the familiar interface of `gdb`. Prior to
    CUDA-GDB, there existed no good way to debug device code outside of using the
    CPU to simulate the way in which it was expected to run. This method yielded extremely
    slow debugging, and in fact, it was frequently a very poor approximation of the
    exact GPU execution of the kernel. NVIDIA’s CUDA-GDB enables programmers to debug
    their kernels directly on the GPU, affording them all of the control that they’ve
    grown accustomed to with CPU debuggers. Some of the highlights of CUDA-GDB include
    the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一款名为*CUDA-GDB*的工具，是CUDA C程序员在基于Linux的系统上开发代码时最有用的CUDA下载之一。NVIDIA扩展了开源的GNU调试器（`gdb`），使其透明地支持实时调试设备代码，同时保持`gdb`的熟悉界面。在CUDA-GDB之前，除了使用CPU模拟代码的预期执行方式外，并没有好的方法来调试设备代码。这种方法的调试非常缓慢，实际上，它经常只能近似GPU内核的真实执行。NVIDIA的CUDA-GDB使程序员能够直接在GPU上调试内核，赋予他们与CPU调试器一样的控制能力。CUDA-GDB的一些亮点包括：
- en: • Viewing CUDA state, such as information regarding installed GPUs and their
    capabilities
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: • 查看CUDA状态，如已安装GPU及其功能信息
- en: • Setting breakpoints in CUDA C source code
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: • 在CUDA C源代码中设置断点
- en: • Inspecting GPU memory, including all global and shared memory
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: • 检查GPU内存，包括所有全局内存和共享内存
- en: • Inspecting the blocks and threads currently resident on the GPU
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: • 检查当前驻留在GPU上的块和线程
- en: • Single-stepping a warp of threads
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: • 单步执行一个线程束（warp）
- en: • Breaking into currently running applications, including hung or deadlocked
    applications
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: • 进入当前正在运行的应用程序，包括卡死或死锁的应用程序
- en: Along with the debugger, NVIDIA provides the CUDA Memory Checker whose functionality
    can be accessed through CUDA-GDB or the stand-alone tool, `cuda-memcheck`. Because
    the CUDA Architecture includes a sophisticated memory management unit built directly
    into the hardware, all illegal memory accesses will be detected and prevented
    by the hardware. As a result of a memory violation, your program will cease functioning
    as expected, so you will certainly want visibility into these types of errors.
    When enabled, the CUDA Memory Checker will detect any global memory violations
    or misaligned global memory accesses that your kernel attempts to make, reporting
    them to you in a far more helpful and verbose manner than previously possible.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 除了调试器，NVIDIA还提供了CUDA内存检查器，其功能可以通过CUDA-GDB或独立工具`cuda-memcheck`访问。由于CUDA架构包括一个直接嵌入硬件的复杂内存管理单元，因此所有非法内存访问都将被硬件检测并防止。因此，由于内存违规，您的程序将无法按预期运行，因此您肯定希望能够查看此类错误。当启用时，CUDA内存检查器将检测您的内核尝试进行的任何全局内存违规或未对齐的全局内存访问，并以比以前更有帮助和更详细的方式向您报告它们。
- en: '**NVIDIA Parallel Nsight**'
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**NVIDIA Parallel Nsight**'
- en: Although CUDA-GDB is a mature and fantastic tool for debugging your CUDA C kernels
    on hardware in real time, NVIDIA recognizes that not every developer is over the
    moon about Linux. So, unless Windows users are hedging their bets by saving up
    to open their own pet stores, they need a way to debug their applications, too.
    Toward the end of 2009, NVIDIA introduced NVIDIA Parallel Nsight (originally code-named
    Nexus), the first integrated GPU/CPU debugger for Microsoft Visual Studio. Like
    CUDA-GDB, Parallel Nsight supports debugging CUDA applications with thousands
    of threads. Users can place breakpoints anywhere in their CUDA C source code,
    including breakpoints that trigger on writes to arbitrary memory locations. They
    can inspect GPU memory directly from the Visual Studio Memory window and check
    for out-of-bounds memory accesses. This tool has been made publicly available
    in a beta program as of press time, and the final version should be released shortly.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CUDA-GDB是一个成熟且出色的工具，可以实时调试硬件上的CUDA C内核，但NVIDIA意识到并非每个开发者都对Linux感到兴奋。因此，除非Windows用户正准备存钱开设自己的宠物商店，否则他们也需要一种调试应用程序的方法。2009年末，NVIDIA推出了NVIDIA
    Parallel Nsight（最初代号为Nexus），这是首个集成的GPU/CPU调试器，用于Microsoft Visual Studio。与CUDA-GDB类似，Parallel
    Nsight支持调试具有数千个线程的CUDA应用程序。用户可以在CUDA C源代码中的任何位置设置断点，包括触发写入任意内存位置的断点。他们可以直接从Visual
    Studio内存窗口检查GPU内存，并检查越界内存访问。该工具目前已在Beta程序中公开发布，最终版本应很快发布。
- en: '**12.2.7 CUDA Visual Profiler**'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.7 CUDA Visual Profiler**'
- en: We often tout the CUDA Architecture as a wonderful foundation for high-performance
    computing applications. Unfortunately, the reality is that after ferreting out
    all the bugs from your applications, even the most well-meaning “high-performance
    computing” applications are more accurately referred to as simply “computing”
    applications. We have often been in the position where we wonder, “Why in the
    Sam Hill is my code performing so poorly?” In situations like this, it helps to
    be able to execute the kernels in question under the watchful gaze of a profiling
    tool. NVIDIA provides just such a tool, available as a separate download on the
    CUDA Zone website. [Figure 12.1](ch12.html#ch12fig01) shows the Visual Profiler
    being used to compare two implementations of a matrix transpose operation. Despite
    not looking at a line of code, it becomes quite easy to determine that both memory
    and instruction throughput of the `transpose()` kernel outstrip that of the `transpose_naive()`
    kernel. (But then again, it would be unfair to expect much more from a function
    with *naive* in the name.)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们常常将CUDA架构誉为高性能计算应用程序的绝佳基础。不幸的是，现实是，在排除应用程序中的所有错误后，即使是最有善意的“高性能计算”应用程序，也更准确地称为简单的“计算”应用程序。我们经常处于这样的境地，心想：“为什么我的代码表现这么差？”在这种情况下，能够在分析工具的注视下执行相关内核会很有帮助。NVIDIA正提供这样一个工具，可以通过CUDA
    Zone网站单独下载。[图12.1](ch12.html#ch12fig01)展示了使用Visual Profiler比较两个矩阵转置操作实现的情况。尽管没有查看一行代码，但很容易判断`transpose()`内核的内存和指令吞吐量超过了`transpose_naive()`内核。（不过，话又说回来，期望一个名字里带有*naive*的函数能做得更好也是不公平的。）
- en: '***Figure 12.1*** The CUDA Visual Profiler being used to profile a matrix transpose
    application'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '***图12.1*** 使用CUDA Visual Profiler对矩阵转置应用程序进行分析'
- en: '![image](graphics/ch_12_transpose.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/ch_12_transpose.jpg)'
- en: The CUDA Visual Profiler will execute your application, examining special performance
    counters built into the GPU. After execution, the profiler can compile data based
    on these counters and present you with reports based on what it observed. It can
    verify how long your application spends executing each kernel as well as determine
    the number of blocks launched, whether your kernel’s memory accesses are coalesced,
    the number of divergent branches the warps in your code execute, and so on. We
    encourage you to look into the CUDA Visual Profiler if you have some subtle performance
    problems in need of resolution.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA Visual Profiler将执行你的应用程序，检查GPU中内置的特殊性能计数器。执行完成后，分析器可以根据这些计数器汇总数据，并为你提供基于其观察结果的报告。它可以验证你的应用程序在执行每个内核时所花费的时间，并确定启动的块数量、内核的内存访问是否合并、代码中的warp执行了多少条分支等。我们鼓励你使用CUDA
    Visual Profiler，尤其是在你遇到一些微妙的性能问题需要解决时。
- en: '**12.3 Written Resources**'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.3 书面资源**'
- en: If you haven’t already grown queasy from all the prose in this book, then it’s
    possible you might actually be interested in reading more. We know that some of
    you are more likely to want to play with code in order to continue your learning,
    but for the rest of you, there are additional written resources to maintain your
    growth as a CUDA C coder.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有因为这本书的冗长文字感到恶心，那么你可能真的有兴趣阅读更多内容。我们知道，一些人更倾向于通过代码练习来继续学习，但对于其他人来说，还有更多的书面资源来帮助你作为CUDA
    C程序员继续成长。
- en: '**12.3.1 Programming Massively Parallel Processors: A Hands-On Approach**'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.3.1 大规模并行处理器编程：实践方法**'
- en: If you read [Chapter 1](ch01.html#ch01), we assured you that this book was most
    decidedly *not* a textbook on parallel architectures. Sure, we bandied about terms
    such as *multiprocessor* and *warp*, but this book strives to teach the softer
    side of programming with CUDA C and its attendant APIs. We learned the CUDA C
    language within the programming model set forth in the *NVIDIA CUDA Programming
    Guide*, largely ignoring the way NVIDIA’s hardware actually accomplishes the tasks
    we give it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了[第一章](ch01.html#ch01)，我们曾向你保证，这本书绝对不是一本关于并行架构的教材。虽然我们确实提到了一些术语，比如*多处理器*和*warp*，但这本书的目标是教授如何用CUDA
    C及其相关API进行编程的软技能。我们在*NVIDIA CUDA编程指南*中学习了CUDA C语言的编程模型，基本忽略了NVIDIA硬件如何实际完成我们交给它的任务。
- en: 'But to truly become an advanced, well-rounded CUDA C programmer, you will need
    a more intimate familiarity with the CUDA Architecture and some of the nuances
    of how NVIDIA GPUs work behind the scenes. To accomplish this, we recommend working
    your way through *Programming Massively Parallel Processors: A Hands-on Approach*.
    To write it, David Kirk, formerly NVIDIA’s chief scientist, collaborated with
    Wen-mei W. Hwu, the W.J. Sanders III chairman in electrical and computer engineering
    at University of Illinois. You’ll encounter a number of familiar terms and concepts,
    but you will learn about the gritty details of NVIDIA’s CUDA Architecture, including
    thread scheduling and latency tolerance, memory bandwidth usage and efficiency,
    specifics on floating-point handling, and much more. The book also addresses parallel
    programming in a more general sense than this book, so you will gain a better
    overall understanding of how to engineer parallel solutions to large, complex
    problems.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但要真正成为一名高级且全面的CUDA C程序员，你需要更深入地了解CUDA架构，以及NVIDIA GPU在幕后如何工作的一些细节。为了实现这一点，我们建议你阅读*大规模并行处理器编程：实践方法*。为编写这本书，前NVIDIA首席科学家David
    Kirk与伊利诺伊大学电气与计算机工程系的W.J. Sanders III讲座教授Wen-mei W. Hwu合作。你将遇到许多熟悉的术语和概念，但你也将学习到关于NVIDIA
    CUDA架构的深入细节，包括线程调度、延迟容忍、内存带宽使用与效率、浮点处理的具体细节等。这本书也比本书更广泛地讨论了并行编程，因此你将更全面地理解如何为大型复杂问题设计并行解决方案。
- en: '**12.3.2 CUDA U**'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.3.2 CUDA U**'
- en: Some of us were unlucky enough to have attended university prior to the exciting
    world of GPU computing. For those who are fortunate enough to be attending college
    now or in the near future, about 300 universities across the world currently teach
    courses involving CUDA. But before you start a crash diet to fit back into your
    college gear, there’s an alternative! On the CUDA Zone website, you will find
    a link for *CUDA U*, which is essentially an online university for CUDA education.
    Or you can navigate directly there with the URL [www.nvidia.com/object/cuda_education](http://www.nvidia.com/object/cuda_education).
    Although you will be able to learn quite a bit about GPU computing if you attend
    some of the online lectures at CUDA U, as of press time there are still no online
    fraternities for partying after class.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当中有些人不幸在 GPU 计算的精彩世界出现之前就上了大学。对于那些现在或不久的将来有幸上大学的人来说，目前全球约有 300 所大学开设了涉及 CUDA
    的课程。但在你开始进行疯狂的减肥，以便重新穿回大学时的衣服之前，还有一个替代方案！在 CUDA Zone 网站上，你会找到一个链接指向 *CUDA U*，它本质上是一个提供
    CUDA 教育的在线大学。或者你可以直接通过网址 [www.nvidia.com/object/cuda_education](http://www.nvidia.com/object/cuda_education)
    访问。尽管你如果参加了 CUDA U 的一些在线讲座，能够学到相当多的 GPU 计算知识，但截止本文发布时，仍然没有线上社团可以在下课后聚会。
- en: '**University Course Materials**'
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**大学课程材料**'
- en: 'Among the myriad sources of CUDA education, one of the highlights includes
    an entire course from the University of Illinois on programming in CUDA C. NVIDIA
    and the University of Illinois provide this content free of charge in the M4V
    video format for your iPod, iPhones, or compatible video players. We know what
    you’re thinking: “Finally, a way to learn CUDA while I wait in line at the Department
    of Motor Vehicles!” You may also be wondering why we waited until the very end
    of this book to inform you of the existence of what is essentially a movie version
    of this book. We’re sorry for holding out on you, but the movie is hardly ever
    as good as the book anyway, right? In addition to actual course materials from
    the University of Illinois and from the University of California Davis, you will
    also find materials from CUDA Training Podcasts and links to third-party training
    and consultancy services.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多 CUDA 教育资源中，其中一个亮点是伊利诺伊大学提供的整个 CUDA C 编程课程。NVIDIA 和伊利诺伊大学免费提供这些内容，格式为 M4V
    视频，适用于你的 iPod、iPhone 或兼容的视频播放器。我们知道你在想什么：“终于找到了一个可以在车管所排队时学习 CUDA 的方法！”你可能还在想，为什么我们要等到本书的最后才告诉你这个基本上是本书电影版的存在。我们很抱歉没有早点告诉你，但电影版总是比书籍差点，不是吗？除了伊利诺伊大学和加利福尼亚大学戴维斯分校的实际课程材料外，你还会找到来自
    CUDA 培训播客的材料，以及第三方培训和咨询服务的链接。
- en: '***Dr. Dobb’s***'
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '***Dr. Dobb’s***'
- en: For more than 30 years, *Dr. Dobb’s* has covered nearly every major development
    in computing technology, and NVIDIA’s CUDA is no exception. As part of an ongoing
    series, *Dr. Dobb’s* has published an extensive series of articles cutting a broad
    swath through the CUDA landscape. Entitled *CUDA, Supercomputing for the Masses*,
    the series starts with an introduction to GPU computing and progresses quickly
    from a first kernel to other pieces of the CUDA programming model. The articles
    in *Dr. Dobb’s* cover error handling, global memory performance, shared memory,
    the CUDA Visual Profiler, texture memory, CUDA-GDB, and the CUDPP library of data-parallel
    CUDA primitives, as well as many other topics. This series of articles is an excellent
    place to get additional information about some of the material we’ve attempted
    to convey in this book. Furthermore, you’ll find practical information concerning
    some of the tools that we’ve only had time to glance over in this text, such as
    the profiling and debugging options available to you. The series of articles is
    linked from the CUDA Zone web page but is readily accessible through a web search
    for *Dr Dobbs CUDA*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 超过 30 年以来，*Dr. Dobb’s* 涵盖了几乎所有计算技术的重大进展，NVIDIA 的 CUDA 也不例外。作为持续系列的一部分，*Dr. Dobb’s*
    发布了一系列广泛的文章，全面介绍了 CUDA 领域。名为 *CUDA, Supercomputing for the Masses* 的系列文章从 GPU
    计算的介绍开始，并迅速从第一个内核进展到 CUDA 编程模型的其他部分。*Dr. Dobb’s* 中的文章涉及错误处理、全局内存性能、共享内存、CUDA 可视化分析器、纹理内存、CUDA-GDB
    和 CUDPP 库等数据并行 CUDA 原语，以及许多其他主题。这些文章是了解我们在本书中尝试传达的部分内容的绝佳来源。此外，你还会找到关于我们在本书中仅有时间简要介绍的一些工具的实用信息，例如可供你使用的分析和调试选项。该系列文章可以通过
    CUDA Zone 网页找到，并且可以通过搜索 *Dr Dobbs CUDA* 在网上轻松找到。
- en: '**12.3.3 NVIDIA Forums**'
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.3.3 NVIDIA 论坛**'
- en: Even after digging around all of NVIDIA’s documentation, you may find yourself
    with an unanswered or particularly intriguing question. Perhaps you’re wondering
    whether anyone else has seen some funky behavior you’re experiencing. Or maybe
    you’re throwing a CUDA celebration party and wanted to assemble a group of like-minded
    individuals. For anything you’re interested in asking, we strongly recommend the
    forums on NVIDIA’s website. Located at [http://forums.nvidia.com](http://forums.nvidia.com),
    the forums are a great place to ask questions of other CUDA users. In fact, after
    reading this book, you’re in a position to potentially help others if you want!
    NVIDIA employees regularly prowl the forums, too, so the trickiest questions will
    prompt authoritative advice right from the source. We also love to get suggestions
    for new features and feedback on the good, bad, and ugly things that we at NVIDIA
    do.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在深入研究 NVIDIA 的所有文档后，你可能仍然会遇到一些没有解答的，或者特别引人兴趣的问题。也许你在想，是否有其他人遇到了你正在经历的奇怪行为。或者你正在举办一场
    CUDA 庆祝派对，想组织一群志同道合的人。如果你有任何问题，我们强烈推荐访问 NVIDIA 网站上的论坛。论坛地址是 [http://forums.nvidia.com](http://forums.nvidia.com)，这是一个向其他
    CUDA 用户提问的好地方。事实上，阅读完本书后，你也有能力帮助其他人！NVIDIA 员工也会定期浏览论坛，因此最棘手的问题很可能会得到来自源头的权威建议。我们也非常欢迎大家提供新功能建议和对
    NVIDIA 工作中好的、坏的和丑的部分的反馈。
- en: '**12.4 Code Resources**'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.4 代码资源**'
- en: Although the NVIDIA GPU Computing SDK is a treasure trove of how-to samples,
    it’s not designed to be used for much more than pedagogy. If you’re hunting for
    production-caliber, CUDA-powered libraries or source code, you’ll need to look
    a bit further. Fortunately, there is a large community of CUDA developers who
    have produced top-notch solutions. A couple of these tools and libraries are presented
    here, but you are encouraged to search the Web for whatever solutions you need.
    And hey, maybe you’ll contribute some of your own to the CUDA C community some
    day!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 NVIDIA GPU 计算 SDK 是一个宝贵的操作示例宝库，但它的设计目的主要是用于教学。如果你在寻找适合生产级别的、CUDA 驱动的库或源代码，你需要再进一步寻找。幸运的是，CUDA
    开发者社区非常庞大，已经开发出了许多顶级的解决方案。这里介绍了其中的一些工具和库，但你也可以自行在网络上搜索你所需要的解决方案。嘿，也许有一天你会为 CUDA
    C 社区贡献自己的成果！
- en: '**12.4.1 CUDA Data Parallel Primitives Library**'
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.4.1 CUDA 数据并行原语库**'
- en: NVIDIA, with the help of researchers at the University of California Davis,
    has released a library known as the CUDA Data Parallel Primitives Library (CUDPP).
    CUDPP, as the name indicates, is a library of data-parallel algorithm primitives.
    Some of these primitives include parallel prefix-sum (*scan*), parallel sort,
    and parallel reduction. Primitives such as these form the foundation of a wide
    variety of data-parallel algorithms, including sorting, stream compaction, building
    data structures, and many others. If you’re looking to write an even moderately
    complex algorithm, chances are good that either CUDPP already has what you need
    or it can get you significantly closer to where you want to be. Download it at
    [http://code.google.com/p/cudpp](http://code.google.com/p/cudpp).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在加利福尼亚大学戴维斯分校研究人员的帮助下，NVIDIA 发布了一个名为 CUDA 数据并行原语库（CUDPP）的库。顾名思义，CUDPP 是一个数据并行算法原语的库。这些原语包括并行前缀和（*扫描*）、并行排序和并行归约等。这些原语构成了各种数据并行算法的基础，包括排序、流压缩、构建数据结构等。如果你打算编写一个稍微复杂的算法，CUDPP
    很可能已经提供了你所需要的功能，或者它能让你更接近你的目标。可以在 [http://code.google.com/p/cudpp](http://code.google.com/p/cudpp)
    下载它。
- en: '**12.4.2 CULAtools**'
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.4.2 CULAtools**'
- en: 'As we mentioned in Section 12.2.3: CUBLAS, NVIDIA provides an implementation
    of the BLAS packaged along with the CUDA Toolkit download. For readers who need
    a broader solution for linear algebra, take a look at EM Photonics’ CUDA implementation
    of the industry-standard Linear Algebra Package (LAPACK). Its LAPACK implementation
    is known as *CULAtools* and offers more complex linear algebra routines that are
    built on NVIDIA’s CUBLAS technology. The freely available Basic package offers
    LU decomposition, QR factorization, linear system solver, and singular value decomposition,
    as well as least squares and constrained least squares solvers. You can obtain
    the Basic download at [www.culatools.com/versions/basic](http://www.culatools.com/versions/basic).
    You will also notice that EM Photonics offers Premium and Commercial licenses,
    which contain a far greater fraction of the LAPACK routines, as well as licensing
    terms that will allow you to distribute your own commercial applications based
    on CULAtools.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第12.2.3节中提到的：CUBLAS，NVIDIA提供了与CUDA工具包一起下载的BLAS实现。对于需要更广泛线性代数解决方案的读者，可以看看EM
    Photonics的CUDA实现，它是业界标准线性代数包（LAPACK）的实现。它的LAPACK实现被称为*CULAtools*，并提供了更多复杂的线性代数例程，这些例程建立在NVIDIA的CUBLAS技术之上。免费提供的Basic包包括LU分解、QR分解、线性系统求解、奇异值分解以及最小二乘法和约束最小二乘法求解器。你可以在[www.culatools.com/versions/basic](http://www.culatools.com/versions/basic)下载Basic包。你还会注意到EM
    Photonics提供了Premium和Commercial许可证，其中包含更多的LAPACK例程，并且许可条款允许你分发基于CULAtools的商业应用程序。
- en: '**12.4.3 Language Wrappers**'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.4.3 语言包装器**'
- en: This book has primarily been concerned with C and C++, but clearly hundreds
    of projects exist that don’t employ these languages. Fortunately, third parties
    have written wrappers to allow access to CUDA technology from languages not officially
    supported by NVIDIA. NVIDIA itself provides FORTRAN bindings for its CUBLAS library,
    but you can also find Java bindings for several of the CUDA libraries at [www.jcuda.org](http://www.jcuda.org).
    Likewise, Python wrappers to allow the use of CUDA C kernels from Python applications
    are available from the PyCUDA project at [http://mathema.tician.de/software/pycuda](http://mathema.tician.de/software/pycuda).
    Finally, there are bindings for the Microsoft .NET environment available from
    the CUDA.NET project at [www.hoopoe-cloud.com/Solutions/CUDA.NET](http://www.hoopoe-cloud.com/Solutions/CUDA.NET).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要关注C和C++，但显然也有成百上千个项目没有使用这些语言。幸运的是，第三方已经编写了包装器，允许从NVIDIA官方不支持的语言中访问CUDA技术。NVIDIA本身提供了用于其CUBLAS库的FORTRAN绑定，但你也可以在[www.jcuda.org](http://www.jcuda.org)找到多个CUDA库的Java绑定。同样，可以从PyCUDA项目在[http://mathema.tician.de/software/pycuda](http://mathema.tician.de/software/pycuda)获得Python包装器，以便在Python应用中使用CUDA
    C内核。最后，CUDA.NET项目提供了适用于Microsoft .NET环境的绑定，网址是[www.hoopoe-cloud.com/Solutions/CUDA.NET](http://www.hoopoe-cloud.com/Solutions/CUDA.NET)。
- en: Although these projects are not officially supported by NVIDIA, they have been
    around for several versions of CUDA, are all freely available, and each has many
    successful customers. The moral of this story is, if your language of choice (or
    your boss’s choice) is not C or C++, you should not rule out GPU computing until
    you’ve first looked to see whether the necessary bindings are available.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些项目没有得到NVIDIA的官方支持，但它们已经存在了好几个版本的CUDA，都是免费的，并且每个项目都有许多成功的客户。这则故事的寓意是，如果你选择的编程语言（或你老板选择的语言）不是C或C++，那么在你还没有确认是否有必要的绑定可用之前，不应该排除GPU计算。
- en: '**12.5 Chapter Review**'
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.5 本章回顾**'
- en: And there you have it. Even after 11 chapters of CUDA C, there are still loads
    of resources to download, read, watch, and compile. This is a remarkably interesting
    time to be learning GPU computing, as the era of heterogeneous computing platforms
    matures. We hope that you have enjoyed learning about one of the most pervasive
    parallel programming environments in existence. Moreover, we hope that you leave
    this experience excited about the possibilities to develop new and exciting means
    for interacting with computers and for processing the ever-increasing amount of
    information available to your software. It’s your ideas and the amazing technologies
    you develop that will push GPU computing to the next level.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样了。即使经过了11章的CUDA C学习，仍然有大量资源可以下载、阅读、观看和编译。在异构计算平台逐渐成熟的时代，学习GPU计算是一个异常有趣的时刻。我们希望你在学习这个最广泛应用的并行编程环境之一时感到愉快。此外，我们希望你能带着对开发新颖且激动人心的计算机交互方式和处理不断增加的信息量的可能性感到兴奋地离开这段学习经历。正是你的创意和你所开发的惊人技术将推动GPU计算迈向新的高度。
