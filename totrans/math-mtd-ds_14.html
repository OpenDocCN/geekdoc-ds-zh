<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>2.5. Application: regression analysis#</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>2.5. Application: regression analysis#</h1>
<blockquote>原文：<a href="https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html">https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html</a></blockquote>

<p>We return to our motivating example, the regression problem, and apply the least squares approach.</p>
<section id="linear-regression">
<h2><span class="section-number">2.5.1. </span>Linear regression<a class="headerlink" href="#linear-regression" title="Link to this heading">#</a></h2>
<p><strong>Linear regression</strong> <span class="math notranslate nohighlight">\(\idx{linear regression}\xdi\)</span> We seek an affine function to fit input data points <span class="math notranslate nohighlight">\(\{(\mathbf{x}_i, y_i)\}_{i=1}^n\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}_i = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\)</span> and <span class="math notranslate nohighlight">\(y_i \in \mathbb{R}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>. The common approach involves finding coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize the criterion</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
\]</div>
<p>This is indeed a linear least squares problem.</p>
<p><img alt="A regression line (with help from ChatGPT; code converted from (Source))" src="../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png" data-original-src="https://mmids-textbook.github.io/_images/lin-reg.png"/></p>
<p>In matrix form, let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} = 
\begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{pmatrix},
\quad\quad
A =
\begin{pmatrix}
1 &amp; \mathbf{x}_1^T \\
1 &amp; \mathbf{x}_2^T \\
\vdots &amp; \vdots \\
1 &amp; \mathbf{x}_n^T
\end{pmatrix}
\quad\text{and}\quad
\boldsymbol{\beta} = 
\begin{pmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_d
\end{pmatrix}.
\end{split}\]</div>
<p>Then the problem is</p>
<div class="math notranslate nohighlight">
\[
\min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} 
\|\mathbf{y} 
- A \boldsymbol{\beta}\|^2.
\]</div>
<p>We assume that the columns of <span class="math notranslate nohighlight">\(A\)</span> are linearly independent, which is often the case with real data (unless there is an algebraic relationship between some columns). The normal equations are then</p>
<div class="math notranslate nohighlight">
\[
A^T A \boldsymbol{\beta} = A^T \mathbf{y}.
\]</div>
<p>Let <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\)</span> be the unique solution of the system. It gives the vector of coefficients in our fitted model. We refer to</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i
= \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
\]</div>
<p>as the fitted values and to</p>
<div class="math notranslate nohighlight">
\[
r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n
\]</div>
<p>as the residuals<span class="math notranslate nohighlight">\(\idx{residuals}\xdi\)</span>. In vector form, we obtain <span class="math notranslate nohighlight">\(\hat{\mathbf{y}} = (\hat{y}_1,\ldots,\hat{y}_n)\)</span> and <span class="math notranslate nohighlight">\(\mathbf{r} = (r_1,\ldots,r_n)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathbf{y}}
= A \boldsymbol{\hat\beta}
\quad
\text{and}
\quad
\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}.
\]</div>
<p>The residual sum of squares (RSS)<span class="math notranslate nohighlight">\(\idx{residual sum of squares}\xdi\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n r_i^2
= \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d \hat{\beta}_j x_{i,j}\right\}\right)^2
\]</div>
<p>or, in vector form,</p>
<div class="math notranslate nohighlight">
\[
\|\mathbf{r}\|^2 
= \|\mathbf{y} - \hat{\mathbf{y}}\|^2
= \|\mathbf{y} - A \boldsymbol{\hat\beta}\|^2.
\]</div>
<p><strong>NUMERICAL CORNER:</strong> We test our least-squares method on simulated data. This has the advantage that we know the truth.</p>
<p>Suppose the truth is a linear function of one variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span><span class="o">*</span><span class="n">x</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png" src="../Images/2eef44a4747d0f6416d01155aadc0534.png" data-original-src="https://mmids-textbook.github.io/_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png"/>
</div>
</div>
<p>A perfect straight line is little too easy. So let’s add some noise. That is, to each <span class="math notranslate nohighlight">\(y_i\)</span> we add an independent random variable <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> with a standard Normal distribution (mean <span class="math notranslate nohighlight">\(0\)</span>, variance <span class="math notranslate nohighlight">\(1\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">y</span> <span class="o">+=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png" src="../Images/0ea0617d403c0459cb176423ab08728a.png" data-original-src="https://mmids-textbook.github.io/_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png"/>
</div>
</div>
<p>We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta}\)</span>. The function <code class="docutils literal notranslate"><span class="pre">ls_by_qr</span></code>, which we implemented previously, is in <a class="reference external" href="https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py">mmids.py</a>, which is available on the <a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main">GitHub of the book</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="n">x</span><span class="p">),</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[-1.03381171  1.01808039]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png" src="../Images/d879007a695e84bcc491f8d33559f076.png" data-original-src="https://mmids-textbook.github.io/_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
</section>
<section id="polynomial-regression-and-overfitting">
<h2><span class="section-number">2.5.2. </span>Polynomial regression (and overfitting)<a class="headerlink" href="#polynomial-regression-and-overfitting" title="Link to this heading">#</a></h2>
<p><strong>Beyond linearity</strong> <span class="math notranslate nohighlight">\(\idx{polynomial regression}\xdi\)</span> The linear assumption is not as restrictive as it may first appear. The same approach can be extended straightforwardly to fit polynomials or more complicated combination of functions. For instance, suppose <span class="math notranslate nohighlight">\(d=1\)</span>. To fit a second degree polynomial to the data <span class="math notranslate nohighlight">\(\{(x_i, y_i)\}_{i=1}^n\)</span>, we add a column to the <span class="math notranslate nohighlight">\(A\)</span> matrix with the squares of the <span class="math notranslate nohighlight">\(x_i\)</span>’s. That is, we let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\begin{pmatrix}
1 &amp; x_1 &amp; x_1^2 \\
1 &amp; x_2 &amp; x_2^2 \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2
\end{pmatrix}.
\end{split}\]</div>
<p>Then, we are indeed fitting a degree-two polynomial as follows</p>
<div class="math notranslate nohighlight">
\[
(A \boldsymbol{\beta})_i 
= \beta_0 + \beta_1 x_i + \beta_2 x_i^2.
\]</div>
<p>The solution otherwise remains the same.</p>
<p>This idea of adding columns can also be used to model interactions between predictors. Suppose <span class="math notranslate nohighlight">\(d=2\)</span>. Then we can consider the following <span class="math notranslate nohighlight">\(A\)</span> matrix, where the last column combines both predictors into their product,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; x_{11} x_{12} \\
1 &amp; x_{21} &amp; x_{22} &amp; x_{21} x_{22} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n1} x_{n2}
\end{pmatrix}.
\end{split}\]</div>
<p><strong>NUMERICAL CORNER:</strong> Suppose the truth is in fact a degree-two polynomial of one variable with Gaussian noise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b2</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">10</span><span class="o">*</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png" src="../Images/9fde58544d9266d798debbcd18cf995a.png" data-original-src="https://mmids-textbook.github.io/_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png"/>
</div>
</div>
<p>We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[-2.76266982  1.01627798  0.93554204]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png" src="../Images/c79327531705ad13d8cb4943a270ee4e.png" data-original-src="https://mmids-textbook.github.io/_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>Overfitting in polynomial regression</strong> In adding more parameters, one must worry about <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-1">overfitting</a><span class="math notranslate nohighlight">\(\idx{overfitting}\xdi\)</span>. To quote Wikipedia:</p>
<blockquote>
<div><p>In statistics, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably”.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-1">1</a>] An overfitted model is a statistical model that contains more parameters than can be justified by the data.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2">2</a>] The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3">3</a>]</p>
</div></blockquote>
<p><strong>NUMERICAL CORNER:</strong> We return to the <code class="docutils literal notranslate"><span class="pre">Advertising</span></code> dataset from the <a class="reference external" href="https://www.statlearning.com/">[ISLP]</a> textbook. We load the dataset again.</p>
<p><strong>Figure:</strong> Pie chart (<em>Credit:</em> Made with <a class="reference external" href="https://www.midjourney.com/">Midjourney</a>)</p>
<p><img alt="Predicting sales" src="../Images/a2936245bd692ef24ec32aa2c9836872.png" data-original-src="https://mmids-textbook.github.io/_images/pie_chart_on_a_screen-small.png"/></p>
<p><span class="math notranslate nohighlight">\(\bowtie\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'advertising.csv'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will focus for now on the TV budget. We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">TV</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'TV'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'sales'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">TV</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="n">TV</span><span class="p">),</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[7.03259355 0.04753664]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">TVgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">TV</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">TV</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">TVgrid</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png" src="../Images/bcffea330b988d225e11b92c7e85f38a.png" data-original-src="https://mmids-textbook.github.io/_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png"/>
</div>
</div>
<p>A degree-two polynomial might be a better fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">TV</span><span class="p">,</span> <span class="n">TV</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[ 6.11412013e+00  6.72659270e-02 -6.84693373e-05]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png" src="../Images/6df89699e41e6a5486cb045e7360d476.png" data-original-src="https://mmids-textbook.github.io/_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png"/>
</div>
</div>
<p>The fit looks slightly better than the linear one. This is not entirely surprising though given that the linear model is a subset of the quadratic one. But, as we mentioned earlier, when adding more parameters we must now worry about overfitting the data. To illustrate, let’s see what happens with a degree-<span class="math notranslate nohighlight">\(20\)</span> polynomial fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">deg</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">TV</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deg</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[ 1.06538698e+00  6.72896471e-01 -1.53138969e-02 -2.74088516e-04
  1.83651714e-05 -3.40080020e-07  3.17915742e-09 -1.64042005e-11
  4.43633296e-14 -4.25654490e-17 -5.28727398e-20  1.11822932e-22
 -3.47096893e-27 -2.44665112e-30 -2.79435976e-33 -4.05263859e-36
 -6.83137511e-39 -1.27993830e-41 -2.59569760e-44 -5.59960687e-47
 -1.26949578e-49]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">saleshat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">coeff</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deg</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">saleshat</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png" src="../Images/8a6079d567365e38718954b97e0d5d59.png" data-original-src="https://mmids-textbook.github.io/_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png"/>
</div>
</div>
<p>The outcome now seems to vary wildly, seemingly driven by the randomness of the data.</p>
<p><strong>CHAT &amp; LEARN:</strong> Ask your favorite AI chatbot about using cross-validation to choose a suitable degree. Ask for code and apply it to this dataset. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> In linear regression, the goal is to find coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize which of the following criteria?</p>
<p>a) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)</span></p>
<p><strong>2</strong> The normal equations for linear regression are:</p>
<p>a) <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(A A^T \boldsymbol{\beta} = A \mathbf{y}\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A \mathbf{y}\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)</span></p>
<p><strong>3</strong> In the numerical example with a degree-20 polynomial fit, the fitted curve:</p>
<p>a) Fits the data perfectly.</p>
<p>b) Fails to capture the overall trend in the data.</p>
<p>c) Captures the noise in the data as if it were the underlying structure.</p>
<p>d) Is a straight line.</p>
<p><strong>4</strong> What is the primary advantage of using simulated data to test the least squares method?</p>
<p>a) Simulated data eliminates the need for real-world data.</p>
<p>b) Simulated data provides a perfect fit without noise.</p>
<p>c) Simulated data allows us to know the ground truth.</p>
<p>d) Simulated data reduces computational complexity.</p>
<p><strong>5</strong> Which of the following best describes overfitting?</p>
<p>a) The model fits the training data well but generalizes poorly to new data.</p>
<p>b) The model fits both the training data and new data well.</p>
<p>c) The model fits the training data poorly but generalizes well to new data.</p>
<p>d) The model ignores random noise in the training data.</p>
<p>Answer for 1: b. Justification: The text states that in linear regression, we seek to find coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize the criterion <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)</span>.</p>
<p>Answer for 2: a. Justification: The text states, “The normal equations are then <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)</span>.”</p>
<p>Answer for 3: c. Justification: The text states that “The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e., the noise) as if that variation represented underlying model structure.”</p>
<p>Answer for 4: c. Justification: The text notes, “This has the advantage that we know the truth.”</p>
<p>Answer for 5: a. Justification: The text quotes Wikipedia: “An overfitted model is a statistical model that contains more parameters than can be justified by the data.”</p>
</section>
&#13;

<h2><span class="section-number">2.5.1. </span>Linear regression<a class="headerlink" href="#linear-regression" title="Link to this heading">#</a></h2>
<p><strong>Linear regression</strong> <span class="math notranslate nohighlight">\(\idx{linear regression}\xdi\)</span> We seek an affine function to fit input data points <span class="math notranslate nohighlight">\(\{(\mathbf{x}_i, y_i)\}_{i=1}^n\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}_i = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\)</span> and <span class="math notranslate nohighlight">\(y_i \in \mathbb{R}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>. The common approach involves finding coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize the criterion</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
\]</div>
<p>This is indeed a linear least squares problem.</p>
<p><img alt="A regression line (with help from ChatGPT; code converted from (Source))" src="../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png" data-original-src="https://mmids-textbook.github.io/_images/lin-reg.png"/></p>
<p>In matrix form, let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} = 
\begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{pmatrix},
\quad\quad
A =
\begin{pmatrix}
1 &amp; \mathbf{x}_1^T \\
1 &amp; \mathbf{x}_2^T \\
\vdots &amp; \vdots \\
1 &amp; \mathbf{x}_n^T
\end{pmatrix}
\quad\text{and}\quad
\boldsymbol{\beta} = 
\begin{pmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_d
\end{pmatrix}.
\end{split}\]</div>
<p>Then the problem is</p>
<div class="math notranslate nohighlight">
\[
\min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} 
\|\mathbf{y} 
- A \boldsymbol{\beta}\|^2.
\]</div>
<p>We assume that the columns of <span class="math notranslate nohighlight">\(A\)</span> are linearly independent, which is often the case with real data (unless there is an algebraic relationship between some columns). The normal equations are then</p>
<div class="math notranslate nohighlight">
\[
A^T A \boldsymbol{\beta} = A^T \mathbf{y}.
\]</div>
<p>Let <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\)</span> be the unique solution of the system. It gives the vector of coefficients in our fitted model. We refer to</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i
= \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
\]</div>
<p>as the fitted values and to</p>
<div class="math notranslate nohighlight">
\[
r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n
\]</div>
<p>as the residuals<span class="math notranslate nohighlight">\(\idx{residuals}\xdi\)</span>. In vector form, we obtain <span class="math notranslate nohighlight">\(\hat{\mathbf{y}} = (\hat{y}_1,\ldots,\hat{y}_n)\)</span> and <span class="math notranslate nohighlight">\(\mathbf{r} = (r_1,\ldots,r_n)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathbf{y}}
= A \boldsymbol{\hat\beta}
\quad
\text{and}
\quad
\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}.
\]</div>
<p>The residual sum of squares (RSS)<span class="math notranslate nohighlight">\(\idx{residual sum of squares}\xdi\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n r_i^2
= \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d \hat{\beta}_j x_{i,j}\right\}\right)^2
\]</div>
<p>or, in vector form,</p>
<div class="math notranslate nohighlight">
\[
\|\mathbf{r}\|^2 
= \|\mathbf{y} - \hat{\mathbf{y}}\|^2
= \|\mathbf{y} - A \boldsymbol{\hat\beta}\|^2.
\]</div>
<p><strong>NUMERICAL CORNER:</strong> We test our least-squares method on simulated data. This has the advantage that we know the truth.</p>
<p>Suppose the truth is a linear function of one variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span><span class="o">*</span><span class="n">x</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png" src="../Images/2eef44a4747d0f6416d01155aadc0534.png" data-original-src="https://mmids-textbook.github.io/_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png"/>
</div>
</div>
<p>A perfect straight line is little too easy. So let’s add some noise. That is, to each <span class="math notranslate nohighlight">\(y_i\)</span> we add an independent random variable <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> with a standard Normal distribution (mean <span class="math notranslate nohighlight">\(0\)</span>, variance <span class="math notranslate nohighlight">\(1\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">y</span> <span class="o">+=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png" src="../Images/0ea0617d403c0459cb176423ab08728a.png" data-original-src="https://mmids-textbook.github.io/_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png"/>
</div>
</div>
<p>We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta}\)</span>. The function <code class="docutils literal notranslate"><span class="pre">ls_by_qr</span></code>, which we implemented previously, is in <a class="reference external" href="https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py">mmids.py</a>, which is available on the <a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main">GitHub of the book</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="n">x</span><span class="p">),</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[-1.03381171  1.01808039]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png" src="../Images/d879007a695e84bcc491f8d33559f076.png" data-original-src="https://mmids-textbook.github.io/_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
&#13;

<h2><span class="section-number">2.5.2. </span>Polynomial regression (and overfitting)<a class="headerlink" href="#polynomial-regression-and-overfitting" title="Link to this heading">#</a></h2>
<p><strong>Beyond linearity</strong> <span class="math notranslate nohighlight">\(\idx{polynomial regression}\xdi\)</span> The linear assumption is not as restrictive as it may first appear. The same approach can be extended straightforwardly to fit polynomials or more complicated combination of functions. For instance, suppose <span class="math notranslate nohighlight">\(d=1\)</span>. To fit a second degree polynomial to the data <span class="math notranslate nohighlight">\(\{(x_i, y_i)\}_{i=1}^n\)</span>, we add a column to the <span class="math notranslate nohighlight">\(A\)</span> matrix with the squares of the <span class="math notranslate nohighlight">\(x_i\)</span>’s. That is, we let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\begin{pmatrix}
1 &amp; x_1 &amp; x_1^2 \\
1 &amp; x_2 &amp; x_2^2 \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2
\end{pmatrix}.
\end{split}\]</div>
<p>Then, we are indeed fitting a degree-two polynomial as follows</p>
<div class="math notranslate nohighlight">
\[
(A \boldsymbol{\beta})_i 
= \beta_0 + \beta_1 x_i + \beta_2 x_i^2.
\]</div>
<p>The solution otherwise remains the same.</p>
<p>This idea of adding columns can also be used to model interactions between predictors. Suppose <span class="math notranslate nohighlight">\(d=2\)</span>. Then we can consider the following <span class="math notranslate nohighlight">\(A\)</span> matrix, where the last column combines both predictors into their product,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; x_{11} x_{12} \\
1 &amp; x_{21} &amp; x_{22} &amp; x_{21} x_{22} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; x_{n1} x_{n2}
\end{pmatrix}.
\end{split}\]</div>
<p><strong>NUMERICAL CORNER:</strong> Suppose the truth is in fact a degree-two polynomial of one variable with Gaussian noise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b2</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">10</span><span class="o">*</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png" src="../Images/9fde58544d9266d798debbcd18cf995a.png" data-original-src="https://mmids-textbook.github.io/_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png"/>
</div>
</div>
<p>We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\hat\beta}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[-2.76266982  1.01627798  0.93554204]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png" src="../Images/c79327531705ad13d8cb4943a270ee4e.png" data-original-src="https://mmids-textbook.github.io/_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>Overfitting in polynomial regression</strong> In adding more parameters, one must worry about <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-1">overfitting</a><span class="math notranslate nohighlight">\(\idx{overfitting}\xdi\)</span>. To quote Wikipedia:</p>
<blockquote>
<div><p>In statistics, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably”.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-1">1</a>] An overfitted model is a statistical model that contains more parameters than can be justified by the data.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2">2</a>] The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.[<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3">3</a>]</p>
</div></blockquote>
<p><strong>NUMERICAL CORNER:</strong> We return to the <code class="docutils literal notranslate"><span class="pre">Advertising</span></code> dataset from the <a class="reference external" href="https://www.statlearning.com/">[ISLP]</a> textbook. We load the dataset again.</p>
<p><strong>Figure:</strong> Pie chart (<em>Credit:</em> Made with <a class="reference external" href="https://www.midjourney.com/">Midjourney</a>)</p>
<p><img alt="Predicting sales" src="../Images/a2936245bd692ef24ec32aa2c9836872.png" data-original-src="https://mmids-textbook.github.io/_images/pie_chart_on_a_screen-small.png"/></p>
<p><span class="math notranslate nohighlight">\(\bowtie\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'advertising.csv'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will focus for now on the TV budget. We form the matrix <span class="math notranslate nohighlight">\(A\)</span> and use our least-squares code to solve for <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">TV</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'TV'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'sales'</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">TV</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="n">TV</span><span class="p">),</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[7.03259355 0.04753664]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">TVgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">TV</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">TV</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">TVgrid</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png" src="../Images/bcffea330b988d225e11b92c7e85f38a.png" data-original-src="https://mmids-textbook.github.io/_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png"/>
</div>
</div>
<p>A degree-two polynomial might be a better fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">TV</span><span class="p">,</span> <span class="n">TV</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[ 6.11412013e+00  6.72659270e-02 -6.84693373e-05]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span> <span class="o">+</span> <span class="n">coeff</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png" src="../Images/6df89699e41e6a5486cb045e7360d476.png" data-original-src="https://mmids-textbook.github.io/_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png"/>
</div>
</div>
<p>The fit looks slightly better than the linear one. This is not entirely surprising though given that the linear model is a subset of the quadratic one. But, as we mentioned earlier, when adding more parameters we must now worry about overfitting the data. To illustrate, let’s see what happens with a degree-<span class="math notranslate nohighlight">\(20\)</span> polynomial fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">deg</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">TV</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deg</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">ls_by_qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sales</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[ 1.06538698e+00  6.72896471e-01 -1.53138969e-02 -2.74088516e-04
  1.83651714e-05 -3.40080020e-07  3.17915742e-09 -1.64042005e-11
  4.43633296e-14 -4.25654490e-17 -5.28727398e-20  1.11822932e-22
 -3.47096893e-27 -2.44665112e-30 -2.79435976e-33 -4.05263859e-36
 -6.83137511e-39 -1.27993830e-41 -2.59569760e-44 -5.59960687e-47
 -1.26949578e-49]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">saleshat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">coeff</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">TVgrid</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deg</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">TV</span><span class="p">,</span> <span class="n">sales</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">TVgrid</span><span class="p">,</span> <span class="n">saleshat</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png" src="../Images/8a6079d567365e38718954b97e0d5d59.png" data-original-src="https://mmids-textbook.github.io/_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png"/>
</div>
</div>
<p>The outcome now seems to vary wildly, seemingly driven by the randomness of the data.</p>
<p><strong>CHAT &amp; LEARN:</strong> Ask your favorite AI chatbot about using cross-validation to choose a suitable degree. Ask for code and apply it to this dataset. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> In linear regression, the goal is to find coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize which of the following criteria?</p>
<p>a) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)</span></p>
<p><strong>2</strong> The normal equations for linear regression are:</p>
<p>a) <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(A A^T \boldsymbol{\beta} = A \mathbf{y}\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A \mathbf{y}\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)</span></p>
<p><strong>3</strong> In the numerical example with a degree-20 polynomial fit, the fitted curve:</p>
<p>a) Fits the data perfectly.</p>
<p>b) Fails to capture the overall trend in the data.</p>
<p>c) Captures the noise in the data as if it were the underlying structure.</p>
<p>d) Is a straight line.</p>
<p><strong>4</strong> What is the primary advantage of using simulated data to test the least squares method?</p>
<p>a) Simulated data eliminates the need for real-world data.</p>
<p>b) Simulated data provides a perfect fit without noise.</p>
<p>c) Simulated data allows us to know the ground truth.</p>
<p>d) Simulated data reduces computational complexity.</p>
<p><strong>5</strong> Which of the following best describes overfitting?</p>
<p>a) The model fits the training data well but generalizes poorly to new data.</p>
<p>b) The model fits both the training data and new data well.</p>
<p>c) The model fits the training data poorly but generalizes well to new data.</p>
<p>d) The model ignores random noise in the training data.</p>
<p>Answer for 1: b. Justification: The text states that in linear regression, we seek to find coefficients <span class="math notranslate nohighlight">\(\beta_j\)</span>’s that minimize the criterion <span class="math notranslate nohighlight">\(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)</span>.</p>
<p>Answer for 2: a. Justification: The text states, “The normal equations are then <span class="math notranslate nohighlight">\(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)</span>.”</p>
<p>Answer for 3: c. Justification: The text states that “The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e., the noise) as if that variation represented underlying model structure.”</p>
<p>Answer for 4: c. Justification: The text notes, “This has the advantage that we know the truth.”</p>
<p>Answer for 5: a. Justification: The text quotes Wikipedia: “An overfitted model is a statistical model that contains more parameters than can be justified by the data.”</p>
    
</body>
</html>