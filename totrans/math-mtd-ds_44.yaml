- en: '6\. Probabilistic models: from simple to complex#'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6. 概率模型：从简单到复杂#
- en: 原文：[https://mmids-textbook.github.io/chap06_prob/00_intro/roch-mmids-prob-intro.html](https://mmids-textbook.github.io/chap06_prob/00_intro/roch-mmids-prob-intro.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap06_prob/00_intro/roch-mmids-prob-intro.html](https://mmids-textbook.github.io/chap06_prob/00_intro/roch-mmids-prob-intro.html)
- en: In this chapter, we take a deeper look at probabilistic models, which we have
    already encountered throughout. We show how to construct a variety of models,
    in particular by using the notion of conditional independence. We also describe
    some standard methods for estimating parameters and hidden states. Finally, we
    discuss and implement some applications, including Kalman filtering. We return
    to sampling in the next chapter. Here is a more detailed overview of the main
    sections of the chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们更深入地探讨了概率模型，这是我们之前已经遇到过的。我们展示了如何构建各种模型，特别是通过使用条件独立性的概念。我们还描述了一些标准的方法来估计参数和隐藏状态。最后，我们讨论并实现了一些应用，包括卡尔曼滤波。我们将在下一章回到抽样。以下是本章主要部分的更详细概述。
- en: '*“Background: introduction to parametric families and maximum likelihood estimation”*
    This section introduces parametric families of probability distributions, focusing
    on exponential families, which include many common distributions such as Bernoulli,
    categorical, multinomial, multivariate Gaussian, and Dirichlet distributions.
    It then discusses parameter estimation, specifically maximum likelihood estimation,
    which chooses the parameter that maximizes the probability of observing the data,
    and derives the maximum likelihood estimator for exponential families. The section
    proves that, under certain conditions, the maximum likelihood estimator is guaranteed
    to converge to the true parameter as the number of samples grows, a property known
    as statistical consistency. Finally, it presents generalized linear models, which
    provide an important generalization of linear regression using exponential families,
    and revisits linear and logistic regression from this perspective.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*“背景：参数族和最大似然估计的介绍”* 本节介绍了概率分布的参数族，重点关注指数族，它包括许多常见的分布，如伯努利分布、分类分布、多项分布、多元高斯分布和狄利克雷分布。然后，它讨论了参数估计，特别是最大似然估计，该估计选择最大化观察数据概率的参数，并推导出指数族的最大似然估计器。本节证明，在一定的条件下，随着样本数量的增加，最大似然估计器保证收敛到真实参数，这一性质被称为统计一致性。最后，它介绍了广义线性模型，它提供了使用指数族对线性回归的重要推广，并从这个角度重新审视了线性回归和逻辑回归。'
- en: '*“Modeling more complex dependencies 1: using conditional independence”* This
    section discusses techniques for constructing joint probability distributions
    from simpler building blocks, focusing on imposing conditional independence relations.
    It introduces the basic configurations of conditional independence for three random
    variables: the fork \((Y \leftarrow X \rightarrow Z)\), the chain \((X \rightarrow
    Y \rightarrow Z)\), and the collider \((X \rightarrow Z \leftarrow Y)\). The section
    then presents the Naive Bayes model as an example of applying conditional independence
    to document classification, where the presence or absence of words in a document
    is assumed to be conditionally independent given the document’s topic. Finally,
    it demonstrates fitting a Naive Bayes model using maximum likelihood estimation.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*“建模更复杂的依赖关系1：使用条件独立性”* 本节讨论了从更简单的构建块构建联合概率分布的技术，重点关注施加条件独立性关系。它介绍了三个随机变量的条件独立性基本配置：分叉
    \((Y \leftarrow X \rightarrow Z)\)，链 \((X \rightarrow Y \rightarrow Z)\)，和碰撞 \((X
    \rightarrow Z \leftarrow Y)\)。然后，本节以朴素贝叶斯模型为例，展示了如何将条件独立性应用于文档分类，其中假设文档中单词的存在与否在给定文档主题的情况下是条件独立的。最后，它演示了使用最大似然估计来拟合朴素贝叶斯模型。'
- en: '*“Modeling more complex dependencies 2: marginalizing out an unobserved variable”*
    This section discusses modeling dependencies in joint distributions by marginalizing
    out an unobserved random variable. It introduces the concept of mixtures as convex
    combinations of distributions. The section then considers the specific case of
    mixtures of multivariate Bernoullis and the Expectation-Maximization (EM) algorithm
    for parameter estimation in this context, leveraging the more general principle
    of majorization-minimization. Finally, the mixture of multivariate Bernoullis
    model is applied to clustering handwritten digits from the MNIST dataset.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*“建模更复杂的依赖关系 2：边缘化未观测变量”* 本节讨论了通过边缘化未观测随机变量来建模联合分布中的依赖关系。它介绍了混合的概念，即分布的凸组合。然后，本节考虑了多元伯努利混合的特定情况，以及在此背景下参数估计的期望最大化（EM）算法，利用更一般的极大化-极小化原理。最后，多元伯努利混合模型被应用于从MNIST数据集中聚类手写数字。'
- en: '*“Application: linear-Gaussian models and Kalman filtering”* This section discusses
    the application of linear-Gaussian models and Kalman filtering for object tracking.
    It begins by presenting the properties of block matrices and the Schur complement,
    which are used to derive the marginal and conditional distributions of multivariate
    Gaussians. The section then introduces the Kalman filter, a recursive algorithm
    for inferring unobserved states in a linear-Gaussian system, where the state evolves
    according to a linear-Gaussian model and noisy observations are made at each time
    step. The section concludes by applying the Kalman filter to a location tracking
    example, which consists in estimating the true path of an object from noisy observations.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*“应用：线性高斯模型和卡尔曼滤波”* 本节讨论了线性高斯模型和卡尔曼滤波在目标跟踪中的应用。它首先介绍了块矩阵和舒尔补的性质，这些性质被用来推导多元高斯分布的边缘和条件分布。然后，本节介绍了卡尔曼滤波，这是一种用于推断线性高斯系统中未观测状态的递归算法，其中状态根据线性高斯模型演变，并在每个时间步进行有噪声的观测。本节最后通过将卡尔曼滤波应用于位置跟踪示例来结束，该示例涉及从有噪声的观测中估计物体的真实路径。'
