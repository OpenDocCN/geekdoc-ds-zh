- en: 9  Clean, prepare, and test
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9  清洁、准备和测试
- en: 原文：[https://tellingstorieswithdata.com/09-clean_and_prepare.html](https://tellingstorieswithdata.com/09-clean_and_prepare.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Preparation](./09-clean_and_prepare.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[准备](./09-clean_and_prepare.html)'
- en: '[9  Clean, prepare, and test](./09-clean_and_prepare.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[9 清洁、准备和测试](./09-clean_and_prepare.html)'
- en: '**Prerequisites**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件**'
- en: Read *Data Feminism*, ([D’Ignazio and Klein 2020](99-references.html#ref-datafeminism2020))
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读《数据女性主义》，([D’Ignazio 和 Klein 2020](99-references.html#ref-datafeminism2020))
- en: Focus on Chapter 5 “Unicorns, Janitors, Ninjas, Wizards, and Rock Stars”, which
    discusses the importance of considering different sources of data about the same
    process.
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于第5章“独角兽、清洁工、忍者、巫师和摇滚明星”，该章节讨论了考虑关于同一过程的不同数据来源的重要性。
- en: Read *R for Data Science*, ([Wickham, Çetinkaya-Rundel, and Grolemund [2016]
    2023](99-references.html#ref-r4ds))
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *R for Data Science* ([Wickham, Çetinkaya-Rundel, and Grolemund [2016] 2023](99-references.html#ref-r4ds))
- en: Focus on Chapter 6 “Data tidying”, which provides an overview of tidy data and
    some strategies to obtain it.
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于第6章“数据整理”，该章节概述了整洁数据及其获取的一些策略。
- en: Read *An introduction to data cleaning with R*, ([De Jonge and van der Loo 2013](99-references.html#ref-de2013introduction))
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读《使用 R 进行数据清洗的入门》，([De Jonge 和 van der Loo 2013](99-references.html#ref-de2013introduction))
- en: Focus on Chapter 2 “From raw data to technically correct data”, which provides
    detailed information about reading data into R and various classes.
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于第二章“从原始数据到技术正确数据”，该章节提供了关于将数据读入R以及各种类别的详细信息。
- en: Read *What The Washington Post Elections Engineering team had to learn about
    election data* ([Liu, Bronner, and Bowers 2022](99-references.html#ref-washingtonpostelections))
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读*《华盛顿邮报选举工程团队必须了解的选举数据》*([刘、布罗纳和鲍尔斯 2022](99-references.html#ref-washingtonpostelections))
- en: Details several practical issues about real-world datasets.
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细说明关于现实世界数据集的几个实际问题。
- en: Read *Column Names as Contracts*, ([Riederer 2020](99-references.html#ref-columnnamesascontracts))
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文章《将列名视为合约》（[Riederer 2020](99-references.html#ref-columnnamesascontracts))
- en: Introduces the benefits of having a limited vocabulary for naming variables.
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍限制变量命名词汇量的好处。
- en: Read *Combining Statistical, Physical, and Historical Evidence to Improve Historical
    Sea-Surface Temperature Records*, ([Chan 2021](99-references.html#ref-Chan2021Combining))
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *结合统计、物理和历史证据以改善历史海面温度记录* ([Chan 2021](99-references.html#ref-Chan2021Combining))
- en: Details the difficulty of creating a dataset of temperatures from observations
    taken by different ships at different times.
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细说明了从不同船只在不同时间进行的观测中创建温度数据集的难度。
- en: '**Key concepts and skills**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键概念和技能**'
- en: Cleaning and preparing a dataset is difficult work that involves making many
    decisions. Planning an endpoint and simulating the dataset that we would like
    to end up with are key elements of cleaning and preparing data.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗和准备数据集是一项困难的工作，涉及做出许多决策。规划一个终点并模拟我们希望最终得到的数据集是清洗和准备数据的关键要素。
- en: It can help to work in an iterative way, beginning with a small sample of the
    dataset. Write code to fix some aspect, and then iterate and generalize to additional
    tranches.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以帮助以迭代的方式工作，从数据集的小样本开始。编写代码来修复某些方面，然后迭代并推广到额外的部分。
- en: During that process we should also develop a series of tests and checks that
    the dataset should pass. This should focus on key features that we would expect
    of the dataset.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在此过程中，我们还应该开发一系列测试和检查，以确保数据集能够通过。这应该集中在我们期望数据集具备的关键特征上。
- en: We should be especially concerned about the class of variables, having clear
    names, and that the unique values of each variable are as expected given all this.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该特别关注变量的类别，确保变量名称清晰，并且考虑到所有这些因素，每个变量的唯一值都符合预期。
- en: '**Software and packages**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件和包**'
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础 R ([R 核心团队 2024](99-references.html#ref-citeR))
- en: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`清洁工` ([Firke 2023](99-references.html#ref-janitor))'
- en: '`lubridate` ([Grolemund and Wickham 2011](99-references.html#ref-GrolemundWickham2011))'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lubridate` ([Grolemund 和 Wickham 2011](99-references.html#ref-GrolemundWickham2011))'
- en: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
- en: '`opendatatoronto` ([Gelfand 2022](99-references.html#ref-citeSharla))'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opendatatoronto` ([Gelfand 2022](99-references.html#ref-citeSharla))'
- en: '`pdftools` ([Ooms 2022](99-references.html#ref-pdftools))'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pdftools` ([Ooms 2022](99-references.html#ref-pdftools))'
- en: '`pointblank` ([Iannone and Vargas 2022](99-references.html#ref-pointblank))'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pointblank` ([Iannone 和 Vargas 2022](99-references.html#ref-pointblank))'
- en: '`readxl` ([Wickham and Bryan 2023](99-references.html#ref-readxl))'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`readxl` ([Wickham 和 Bryan 2023](99-references.html#ref-readxl))'
- en: '`scales` ([Wickham and Seidel 2022](99-references.html#ref-scales))'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scales` ([Wickham 和 Seidel 2022](99-references.html#ref-scales))'
- en: '`stringi` ([Gagolewski 2022](99-references.html#ref-stringi))'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stringi` ([Gagolewski 2022](99-references.html#ref-stringi))'
- en: '`testthat` ([Wickham 2011](99-references.html#ref-testthat))'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`testthat` ([Wickham 2011](99-references.html#ref-testthat))'
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tidyverse` ([Wickham 等人 2019](99-references.html#ref-tidyverse))'
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
- en: '`validate` ([van der Loo and De Jonge 2021](99-references.html#ref-validate))'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validate` ([验证](99-references.html#ref-validate))'
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*## 9.1 Introduction'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*## 9.1 简介'
- en: “Well, Lyndon, you may be right and they may be every bit as intelligent as
    you say,” said Rayburn, “but I’d feel a whole lot better about them if just one
    of them had run for sheriff once.”
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “嗯，林登，你可能是对的，他们可能和你说的那样聪明，”雷伯恩说，“但如果其中之一曾经竞选过警长，我会感觉好得多。”
- en: ''
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sam Rayburn reacting to Lyndon Johnson’s enthusiasm about John Kennedy’s incoming
    cabinet, as quoted in *The Best and the Brightest* ([Halberstam 1972, 41](99-references.html#ref-halberstam)).
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 山姆·雷伯恩对林登·约翰逊对约翰·肯尼迪即将上任的内阁的热情反应，正如在《最优秀与最聪明的人》一书中引用的那样（[Halberstam 1972, 41](99-references.html#ref-halberstam)）。
- en: 'In this chapter we put in place more formal approaches for data cleaning and
    preparation. These are centered around:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了更多正式的数据清洗和准备方法。这些方法主要围绕以下方面：
- en: validity;
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有效性；
- en: internal consistency; and
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内部一致性；
- en: external consistency.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 外部一致性。
- en: Your model does not care whether you validated your data, but you should. Validity
    means that the values in the dataset are not obviously wrong. For instance, with
    few exceptions, currencies should not have letters in them, names should not have
    numbers, and velocities should not be faster than the speed of light. Internal
    consistency means the dataset does not contradict itself. For instance, that might
    mean that constituent columns add to the total column. External consistency means
    that the dataset does not, in general, contradict outside sources, and is deliberate
    when it does. For instance, if our dataset purports to be about the population
    of cities, then we would expect that they are the same as, to a rough approximation,
    say, those available from relevant censuses on Wikipedia.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你的模型不在乎你是否验证了你的数据，但你应该这么做。有效性意味着数据集中的值没有明显错误。例如，除少数例外，货币中不应含有字母，姓名中不应含有数字，速度不应超过光速。内部一致性意味着数据集不会自相矛盾。例如，这可能意味着构成列的总和等于总列。外部一致性意味着数据集通常不会与外部来源矛盾，并且在出现矛盾时是有意为之的。例如，如果我们的数据集声称是关于城市人口的话，那么我们就会期望它们与来自相关维基百科普查的大致相同。
- en: SpaceX, the United States rocket company, uses cycles of ten or 50 Hertz (equivalent
    to 0.1 and 0.02 seconds, respectively) to control their rockets. Each cycle, the
    inputs from sensors, such as temperature and pressure, are read, processed, and
    used to make a decision, such as whether to adjust some setting ([Martin and Popper
    2021](99-references.html#ref-martinpopper)). We recommend a similar iterative
    approach of small adjustments during data cleaning and preparation. Rather than
    trying to make everything perfect from the start, just get started, and iterate
    through a process of small, continuous improvements.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SpaceX，美国火箭公司，使用10或50赫兹（分别相当于0.1和0.02秒）的周期来控制他们的火箭。在每个周期中，传感器（如温度和压力）的输入被读取、处理，并用于做出决策，例如是否调整某些设置（[马丁和波珀2021](99-references.html#ref-martinpopper)）。我们建议在数据清理和准备过程中采用类似的迭代方法，进行小幅度调整。与其试图一开始就做到完美，不如开始行动，并通过一系列小而持续的改进过程进行迭代。
- en: To a large extent, the role of data cleaning and preparation is so great that
    the only people that understand a dataset are those that have cleaned it. Yet,
    the paradox of data cleaning is that often those that do the cleaning and preparation
    are those that have the least trust in the resulting dataset. At some point in
    every data science workflow, those doing the modeling should do some data cleaning.
    Even though few want to do it ([Sambasivan et al. 2021](99-references.html#ref-Sambasivan2021)),
    it can be as influential as modeling. To clean and prepare data is to make many
    decisions, some of which may have important effects on our results. For instance,
    Northcutt, Athalye, and Mueller ([2021](99-references.html#ref-labelsiswrongs))
    find the test sets of some popular datasets in computer science contain, on average,
    labels that are wrong in around three per cent of cases. Banes et al. ([2022](99-references.html#ref-Banes2022))
    re-visit the Sumatran orang-utan *(Pongo abelii)* reference genome and find that
    nine of the ten samples had some issue. And Du, Huddart, and Jiang ([2022](99-references.html#ref-eveninaccountingwhat))
    find a substantial difference between the as-filed and standardized versions of
    a company’s accounting data, especially for complex financial situations. Like
    Sam Rayburn wishing that Kennedy’s cabinet despite their intelligence, had experience
    in the nitty-gritty, a data scientist needs to immerse themselves in the messy
    reality of their dataset.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在很大程度上，数据清洗和准备的作用非常重要，只有那些清洗过数据集的人才能真正理解它。然而，数据清洗的悖论在于，通常进行清洗和准备的人是对结果数据集最缺乏信任的人。在每一个数据科学工作流程的某个阶段，那些进行建模的人应该进行一些数据清洗。尽管很少有人愿意这样做([Sambasivan
    等人 2021](99-references.html#ref-Sambasivan2021))，但它的影响力可以与建模相媲美。清洗和准备数据意味着要做出许多决定，其中一些可能对我们的结果产生重要影响。例如，Northcutt、Athalye
    和 Mueller ([2021](99-references.html#ref-labelsiswrongs)) 发现一些流行数据集的测试集中，平均有大约三百分之一的标签是错误的。Banes
    等人 ([2022](99-references.html#ref-Banes2022)) 重新审视了苏门答腊猩猩 *(Pongo abelii)* 的参考基因组，并发现十个样本中有九个存在问题。而杜、Huddart
    和 Jiang ([2022](99-references.html#ref-eveninaccountingwhat)) 发现一家公司的会计数据在原始版本和标准化版本之间存在显著差异，尤其是在复杂的财务情况下。就像
    Sam Rayburn 希望肯尼迪内阁尽管他们聪明，但能有一些实际经验一样，数据科学家需要沉浸在他们数据集的混乱现实中。
- en: The reproducibility crisis, which was identified early in psychology ([Open
    Science Collaboration 2015](99-references.html#ref-anniesfind)) but since extended
    to many other disciplines in the physical and social sciences, brought to light
    issues such as p-value “hacking”, researcher degrees of freedom, file-drawer issues,
    and even data and results fabrication ([Gelman and Loken 2013](99-references.html#ref-gelman2013garden)).
    Steps are now being put in place to address these. But there has been relatively
    little focus on the data gathering, cleaning, and preparation aspects of applied
    statistics, despite evidence that decisions made during these steps greatly affect
    statistical results ([Huntington-Klein et al. 2021](99-references.html#ref-huntington2021influence)).
    In this chapter we focus on these issues.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 可重复性危机，在心理学领域早期就被识别出来（[开放科学合作组织 2015](99-references.html#ref-anniesfind)），但后来扩展到物理和社会科学的许多其他学科，揭示了诸如p值“黑客攻击”、研究者的自由度、文件抽屉问题以及甚至数据和结果伪造等问题（[Gelman
    和 Loken 2013](99-references.html#ref-gelman2013garden)）。现在正在采取措施来解决这些问题。但相对而言，对应用统计学中的数据收集、清理和准备方面的关注相对较少，尽管有证据表明在这些步骤中做出的决策极大地影响了统计结果（[Huntington-Klein
    等人 2021](99-references.html#ref-huntington2021influence)）。在本章中，我们关注这些问题。
- en: While the statistical practices that underpin data science are themselves correct
    and robust when applied to simulated datasets, data science is not typically conducted
    with data that follow the assumptions underlying the models that are commonly
    fit. For instance, data scientists are interested in “messy, unfiltered, and possibly
    unclean data—tainted by heteroskedasticity, complex dependence and missingness
    patterns—that until recently were avoided in polite conversations between more
    traditional statisticians” ([Craiu 2019](99-references.html#ref-craiu2019hiring)).
    Big data does not resolve this issue and may even exacerbate it. For instance,
    population inference based on larger amounts of poor-quality data, without adjusting
    for data issues, will just lead to more confidently wrong conclusions ([Meng 2018](99-references.html#ref-meng2018statistical)).
    The problems that are found in much of applied statistics research are not necessarily
    associated with researcher quality, or their biases ([Silberzahn et al. 2018](99-references.html#ref-silberzahn2018many)).
    Instead, they are a result of the context within which data science is conducted.
    This chapter provides an approach and tools to explicitly think about this work.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管支撑数据科学的统计实践本身在应用于模拟数据集时是正确且稳健的，但数据科学通常并不是在遵循常见拟合模型假设的数据上进行进行的。例如，数据科学家对“混乱、未经筛选、可能不干净的数据——受到异方差性、复杂依赖性和缺失模式的影响——这些数据直到最近在更传统的统计学家之间的礼貌对话中还被避免”([Craiu
    2019](99-references.html#ref-craiu2019hiring))感兴趣。大数据并没有解决这个问题，甚至可能加剧了这个问题。例如，基于大量低质量数据的人口推断，如果不调整数据问题，只会导致更加自信的错误结论([Meng
    2018](99-references.html#ref-meng2018statistical))。在许多应用统计学研究中发现的问题并不一定与研究者质量或他们的偏见([Silberzahn
    et al. 2018](99-references.html#ref-silberzahn2018many))相关。相反，它们是数据科学进行背景下的结果。本章提供了一种方法和工具，以明确思考这项工作。
- en: Gelman and Vehtari ([2021](99-references.html#ref-gelman2020most)), writing
    about the most important statistical ideas of the past 50 years, say that each
    of them enabled new ways of thinking about data analysis. These ideas brought
    into the tent of statistics, approaches that “had been considered more a matter
    of taste or philosophy”. The focus on data cleaning and preparation in this chapter
    is analogous, insofar as it represents a codification, or bringing inside the
    tent, of aspects that are typically, incorrectly, considered those of taste rather
    than core statistical concerns.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 吉尔曼和维塔里([2021](99-references.html#ref-gelman2020most))在讨论过去50年最重要的统计思想时表示，每个思想都为数据分析带来了新的思考方式。这些思想将那些“曾被认为更多是品味或哲学问题”的方法引入了统计学领域。本章对数据清洗和准备的关注是类似的，因为它们代表了通常被错误地认为是品味而非核心统计关注点的方面的规范化，或者说将它们纳入了统计学领域。
- en: 'The workflow for data cleaning and preparation that we advocate is:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们倡导的数据清洗和准备工作流程是：
- en: Save the original, unedited data.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存原始、未编辑的数据。
- en: Begin with an end in mind by sketching and simulating.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制和模拟来以终为始。
- en: Write tests and documentation.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写测试和文档。
- en: Execute the plan on a small sample.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在小样本上执行计划。
- en: Iterate the plan.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代计划。
- en: Generalize the execution.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 概括执行。
- en: Update tests and documentation.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新测试和文档。
- en: We will need a variety of skills to be effective, but this is the very stuff
    of data science. The approach needed is some combination of dogged and sensible.
    Perfect is very much the enemy of good enough when it comes to data cleaning.
    And to be specific, it is better to have 90 per cent of the data cleaned and prepared,
    and to start exploring that, before deciding whether it is worth the effort to
    clean and prepare the remaining 10 per cent. Because that remainder will likely
    take an awful lot of time and effort.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要各种技能才能有效，但这正是数据科学的核心。所需的方法是坚定与明智的结合。在数据清洗方面，完美往往是足够好的敌人。具体来说，最好是先完成90%的数据清洗和准备，然后开始探索这些数据，在决定是否值得花费精力去清洗和准备剩余的10%之前。因为那剩余的部分可能需要大量的时间和精力。
- en: All data regardless of whether they were obtained from farming, gathering, or
    hunting, will have issues. We need approaches that can deal with a variety of
    concerns, and more importantly, understand how they might affect our modeling
    ([Van den Broeck et al. 2005](99-references.html#ref-van2005data)). To clean data
    is to analyze data. This is because the process forces us to make choices about
    what we value in our results ([Au 2020](99-references.html#ref-thatrandyauperson)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据，无论它们是从农业、采集还是狩猎中获得的，都会存在问题。我们需要能够处理各种问题的方法，更重要的是，理解它们可能对我们建模产生的影响（[Van
    den Broeck 等人 2005](99-references.html#ref-van2005data)）。清理数据就是分析数据。这是因为这个过程迫使我们做出选择，关于我们在结果中重视什么（[Au
    2020](99-references.html#ref-thatrandyauperson)）。
- en: 9.2 Workflow
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 工作流程
- en: 9.2.1 Save the original, unedited data
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 保存原始未编辑的数据
- en: The first step is to save the original, unedited data into a separate, local
    folder. The original, unedited data establishes the foundation for reproducibility
    ([Wilson et al. 2017](99-references.html#ref-wilsongoodenough)). If we obtained
    our data from a third-party, such as a government website, then we have no control
    over whether they will continue to host that data, update it, or change the address
    at which it is available. Saving a local copy also reduces the burden that we
    impose on their servers.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将原始的、未经编辑的数据保存到一个单独的本地文件夹中。原始的、未经编辑的数据为可重复性奠定了基础 ([Wilson 等人 2017](99-references.html#ref-wilsongoodenough))。如果我们从第三方，例如政府网站，获取数据，那么我们就无法控制他们是否会继续托管这些数据，更新它们，或者更改数据可用的地址。保存本地副本也可以减少我们对他们服务器的负担。
- en: Having locally saved the original, unedited data we must maintain a copy of
    it in that state, and not modify it. As we begin to clean and prepare it, we instead
    make these changes to a copy of the dataset. Maintaining the original, unedited
    dataset, and using scripts to create the dataset that we are interested in analyzing,
    ensures that our entire workflow is reproducible. It may be that the changes that
    we decide to make today, are not ones that we would make tomorrow, having learnt
    more about the dataset. We need to ensure that we have that data in the original,
    unedited state in case we need to return to it ([Borer et al. 2009](99-references.html#ref-Borer2009)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地保存了原始、未经编辑的数据后，我们必须保留其原始状态的一个副本，并且不得对其进行修改。当我们开始清理和准备数据时，我们反而将这些更改应用到数据集的副本上。保留原始、未经编辑的数据集，并使用脚本创建我们感兴趣分析的数据集，确保我们的整个工作流程是可重复的。可能的情况是，我们今天决定做出的更改，在了解更多关于数据集的信息后，可能不是我们明天会做出的更改。我们需要确保在需要返回时，我们拥有原始、未经编辑状态的数据（[Borer
    等人 2009](99-references.html#ref-Borer2009)）。
- en: We may not always be allowed to share that original, unedited data, but we can
    almost always create something similar. For instance, if we are using a restricted-use
    computer, then it may be that the best we can do is create a simulated version
    of the original, unedited data that conveys the main features, and include detailed
    access instructions in a README file.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能并不总是被允许分享原始的、未经编辑的数据，但我们可以几乎总是创造出类似的东西。例如，如果我们使用的是受限使用的计算机，那么我们可能最好的做法就是创建一个模拟原始、未经编辑数据的版本，该版本传达了主要特征，并在README文件中包含详细的访问说明。
- en: 9.2.2 Plan
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 计划
- en: Planning the endpoint forces us to begin with an end in mind and is important
    for a variety of reasons. As with scraping data, introduced in [Chapter 7](07-gather.html),
    it helps us to be proactive about scope-creep. But with data cleaning it additionally
    forces us to really think about what we want the final dataset to look like.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 规划终点迫使我们从结果出发思考，并且出于多种原因非常重要。正如在[第7章](07-gather.html)中介绍的“抓取数据”一样，它帮助我们主动应对范围蔓延的问题。但与数据清洗相比，它还迫使我们真正思考我们希望最终数据集看起来像什么。
- en: The first step is to sketch the dataset that we are interested in. The key features
    of the sketch will be aspects such as the names of the columns, their class, and
    the possible range of values. For instance, we might be interested in the populations
    of US states. Our sketch might look like [Figure 9.1](#fig-sketchdataplan).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是绘制我们感兴趣的数据库草图。草图的关键特征将包括诸如列名、它们的类别以及可能值的范围等方面。例如，我们可能对美国的州人口感兴趣。我们的草图可能看起来像[图9.1](#fig-sketchdataplan)。
- en: '![](../Images/0fbdef137b0956d4986807d8b9239c3a.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/0fbdef137b0956d4986807d8b9239c3a.png)'
- en: 'Figure 9.1: Planned dataset of US states and their populations'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：美国各州及其人口规划数据集
- en: In this case, the sketch forces us to decide that we want full names rather
    than abbreviations for the state names, and the population to be measured in millions.
    The process of sketching this endpoint has forced us to make decisions early on
    and be clear about our desired endpoint.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，草图迫使我们决定我们想要使用全名而不是缩写来表示州名，并且人口数量要以百万为单位进行衡量。绘制这个端点的过程迫使我们提前做出决定，并清楚地了解我们期望的终点。
- en: We then implement that using code to simulate data. Again, this process forces
    us to think about what reasonable values look like in our dataset because we must
    decide which functions to use. We need to think carefully about the unique values
    of each variable. For instance, if the variable is meant to be “gender” then unique
    values such as “male”, “female”, “other”, and “unknown” may be expected, but a
    number such as “1,000” would likely be wrong. It also forces us to be explicit
    about names because we must assign the output of those functions to a variable.
    For instance, we could simulate some population data for the US states.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后使用代码来模拟数据。同样，这个过程迫使我们思考在数据集中合理的值看起来是什么样子，因为我们必须决定使用哪些函数。我们需要仔细思考每个变量的唯一值。例如，如果变量意味着是“性别”，那么可能期望的唯一值如“男性”、“女性”、“其他”和“未知”，但像“1,000”这样的数字可能是不正确的。这也迫使我们明确名称，因为我们必须将这些函数的输出分配给变量。例如，我们可以模拟美国各州的人口数据。
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*[PRE2]*  *Our purpose, during data cleaning and preparation, is to then bring
    our original, unedited data close to that plan. Ideally, we would plan so that
    the desired endpoint of our dataset is “tidy data”. This is introduced in [Online
    Appendix A](20-r_essentials.html), but briefly, it means that ([Wickham, Çetinkaya-Rundel,
    and Grolemund [2016] 2023](99-references.html#ref-r4ds); [Wickham 2014, 4](99-references.html#ref-wickham2014tidy)):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE2]*  *我们的目的是在数据清洗和准备过程中，将我们的原始、未编辑的数据尽可能接近该计划。理想情况下，我们会制定计划，使得我们数据集的期望终点是“整洁数据”。这在[在线附录A](20-r_essentials.html)中有所介绍，但简要来说，这意味着([Wickham,
    Çetinkaya-Rundel, and Grolemund [2016] 2023](99-references.html#ref-r4ds); [Wickham
    2014, 4](99-references.html#ref-wickham2014tidy))：'
- en: each variable is in its own column;
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个变量都在自己的列中；
- en: each observation is in its own row; and
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个观察都在其自己的行中；并且
- en: each value is in its own cell.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个值都在自己的单元格中。
- en: Begin thinking about validity and internal consistency at this stage. What are
    some of the features that these data should have? Note these as you go through
    the process of simulating the dataset because we will draw on them to write tests.*  *###
    9.2.3 Start small
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段开始思考有效性和内部一致性。这些数据应该具备哪些特征？在模拟数据集的过程中将这些特征记录下来，因为我们将在编写测试时参考它们。*  *###
    9.2.3 从小开始
- en: Having thoroughly planned we can turn to the original, unedited data that we
    are dealing with. Usually we want to manipulate the original, unedited data into
    a rectangular dataset as quickly as possible. This allows us to use familiar functions
    from the `tidyverse`. For instance, let us assume that we are starting with a
    `.txt` file.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 经过周密规划后，我们可以转向处理原始、未经编辑的数据。通常，我们希望尽可能快地将原始、未经编辑的数据转换成一个矩形数据集。这使我们能够使用来自`tidyverse`的熟悉函数。例如，让我们假设我们从一个`.txt`文件开始。
- en: The first step is to look for regularities in the dataset. We want to end up
    with tabular data, which means that we need some type of delimiter to distinguish
    different columns. Ideally this might be features such as a comma, a semicolon,
    a tab, a double space, or a line break. In the following case we could take advantage
    of the comma.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是寻找数据集中的规律性。我们希望最终得到表格数据，这意味着我们需要某种类型的分隔符来区分不同的列。理想情况下，这可能是一些特征，如逗号、分号、制表符、双空格或换行符。在以下情况下，我们可以利用逗号。
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In more challenging cases there may be some regular feature of the dataset that
    we can take advantage of. Sometimes various text is repeated, as in the following
    case.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在更具挑战性的情况下，我们可能可以利用数据集的一些规律性特征。有时各种文本会重复出现，如下例所示。
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, although we do not have a traditional delimiter, we can use the
    regularity of “State is”, “and population is”, and “million” to get what we need.
    A more difficult case is when we do not have line breaks. This final case is illustrative
    of that.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，尽管我们没有传统的分隔符，但我们可以利用“状态是”，“人口是”，以及“百万”的规律来获取所需信息。一个更复杂的情况是当我们没有行断的情况下。这个最终案例就是这种情况的说明。
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: One way to approach this is to take advantage of the different classes and values
    that we are looking for. For instance, we know that we are after US states, so
    there are only 50 possible options (setting D.C. to one side for the time being),
    and we could use the these as a delimiter. We could also use the fact that population
    is a number, and so separate based on a space followed by a number.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接近这个问题的方法之一是利用我们正在寻找的不同类别和值。例如，我们知道我们正在寻找的是美国各州，因此只有50个可能的选择（暂时将哥伦比亚特区排除在外），我们可以将这些作为分隔符。我们还可以利用人口是一个数字的事实，并基于一个数字后的空格进行分隔。
- en: We will now convert this final case into tidy data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将这个最终案例转换为整洁数据。
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*[PRE7]*  *### 9.2.4 Write tests and documentation'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE7]*  *### 9.2.4 编写测试和文档'
- en: Having established a rectangular dataset, albeit a messy one, we should begin
    to look at the classes that we have. We do not necessarily want to fix the classes
    at this point, because that can result in lost data. But we look at the class
    to see what it is, compare it to our simulated dataset, and note the columns where
    it is different to see what changes need to be made. Background on `class()` is
    available in [Online Appendix A](20-r_essentials.html).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们建立了一个矩形数据集，尽管有些杂乱，但我们应该开始查看我们拥有的类别。在这个阶段，我们不一定想固定类别，因为这可能会导致数据丢失。但我们查看类别以了解其内容，将其与我们的模拟数据集进行比较，并注意不同的列以了解需要做出哪些更改。关于`class()`的背景信息可在[在线附录A](20-r_essentials.html)中找到。
- en: 'Before changing the class and before going on to more bespoke issues, we should
    deal with some common issues including:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在更改班级之前以及继续探讨更定制化的问题之前，我们应该处理一些常见问题，包括：
- en: Commas and other punctuation, such as denomination signs ($, €, £, etc.), in
    variables that should be numeric.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逗号和其他标点符号，例如货币符号（$，€，£等），在应该为数字的变量中。
- en: Inconsistent formatting of dates, such as “December” and “Dec” and “12” all
    in the one variable.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期格式不一致，例如在一个变量中同时出现“December”、“Dec”和“12”。
- en: Unexpected character encoding, especially in Unicode, which may not display
    consistently.[¹](#fn1)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可预料的字符编码，尤其是在 Unicode 中，可能会导致显示不一致。[¹](#fn1)
- en: Typically, we want to fix anything immediately obvious. For instance, we should
    remove commas that have been used to group digits in currencies. However, the
    situation will often feel overwhelming. What we need to do is to look at the unique
    values in each variable, and then triage what we will fix. We make the triage
    decision based on what is likely to have the largest impact. That usually means
    creating counts of the observations, sorting them in descending order, and then
    dealing with them in this order.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们希望立即修复任何明显的问题。例如，我们应该删除用于将货币中的数字分组使用的逗号。然而，情况往往会让人感到不知所措。我们需要做的是查看每个变量的唯一值，然后对我们将要修复的内容进行分类。我们根据可能产生最大影响的因素来做出分类决策。这通常意味着创建观察值的计数，按降序排列，然后按此顺序处理。
- en: When the tests of membership are passed—which we initially establish based on
    simulation and experience—then we can change the class, and run all the tests
    again. We have adapted this idea from the software development approach of unit
    testing. Tests are crucial because they enable us to understand whether software
    (or in this case data) is fit for our purpose ([Irving et al. 2021](99-references.html#ref-researchsoftware)).
    Tests, especially in data science, are not static things that we just write once
    and then forget. Instead they should update and evolve as needed.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过成员资格测试——我们最初基于模拟和经验来建立这些测试——然后我们可以更改类别，并再次运行所有测试。我们从单元测试的软件开发方法中借鉴了这个想法。测试至关重要，因为它们使我们能够了解软件（或在这种情况下数据）是否适合我们的目的（[Irving
    等人 2021](99-references.html#ref-researchsoftware)）。在数据科学中，测试不是我们只写一次然后忘记的静态事物。相反，它们应根据需要更新和演变。
- en: '*Oh, you think we have good data on that!* *The simplification of reality can
    be especially seen in sports records, which necessarily must choose what to record.
    Sports records are fit for some purposes and not for others. For instance, chess
    is played on an 8 x 8 board of alternating black and white squares. The squares
    are denoted by a unique combination of both a letter (A-G) and a number (1-8).
    Most pieces have a unique abbreviation, for instance knights are N and bishops
    are B. Each game is independently recorded using this “algebraic notation” by
    each player. These records allow us to recreate the moves of the game. The 2021
    Chess World Championship was contested by Magnus Carlsen and Ian Nepomniachtchi.
    There were a variety of reasons this game was particularly noteworthy—including
    it being the longest world championship game—but one is the uncharacteristic mistakes
    that both Carlsen and Nepomniachtchi made. For instance, at Move 33 Carlsen did
    not exploit an opportunity; and at Move 36 a different move would have provided
    Nepomniachtchi with a promising endgame ([Doggers 2021](99-references.html#ref-PeterDoggers)).
    One reason for these mistakes may have been that both players at that point in
    the game had very little time remaining—they had to decide on their moves very
    quickly. But there is no sense of that in the representation provided by the game
    sheet because it does not record time remaining. The record is fit for purpose
    as a “correct” representation of what happened in the game; but not necessarily
    why it happened.*  *Let us run through an example with a collection of strings,
    some of which are slightly wrong. This type of output is typical of OCR, introduced
    in [Chapter 7](07-gather.html), which often gets most of the way there, but not
    quite.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*哦，你以为我们对这方面的数据很好吗!* *现实简化的情况在体育记录中尤为明显，因为体育记录必然需要选择记录什么。体育记录适合某些目的，但不适合其他目的。例如，国际象棋是在一个交替着黑白方格的8
    x 8棋盘上进行的。方格由一个独特的字母（A-G）和数字（1-8）的组合来表示。大多数棋子都有一个独特的缩写，例如骑士是N，主教是B。每个游戏都是通过每个玩家使用这种“代数记法”独立记录的。这些记录使我们能够重现游戏的走法。2021年国际象棋世界锦标赛由马格努斯·卡尔森和伊恩·内波姆尼亚奇进行。这场比赛之所以特别引人注目，有多种原因——包括这是最长的世界锦标赛游戏——但其中之一是卡尔森和内波姆尼亚奇都犯了一些不寻常的错误。例如，在第33步，卡尔森没有利用一个机会；在第36步，一个不同的走法本可以为内波姆尼亚奇提供一个有希望的残局([Doggers
    2021](99-references.html#ref-PeterDoggers))。这些错误可能的原因之一是，在游戏的那个阶段，两位选手剩余的时间非常少——他们必须非常快速地决定他们的走法。但在游戏记录表提供的表示中，并没有这种感觉，因为它没有记录剩余时间。记录适合作为“正确”地表示游戏中发生的事情；但不一定是为什么发生。[让我们通过一组字符串的例子来运行一个示例，其中一些字符串略有错误。这种类型的输出是[第7章](07-gather.html)中介绍的OCR的典型输出，它通常已经完成了大部分工作，但还不够。*'
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*As before, we first get this into a rectangular dataset.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*与之前一样，我们首先将数据集整理成矩形格式。'
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*[PRE10]*  *We now need to decide which of these errors we are going to fix.
    To help us decide which are most important, we create a count.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE10]*  *我们现在需要决定我们将要修复哪些错误。为了帮助我们决定哪些是最重要的，我们创建了一个计数。'
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*[PRE12]*  *The most common unique observation is the correct one. The next
    one—“PatricIa”—looks like the “i” has been incorrectly capitalized. This is true
    for “PatrIcia” as well. We can fix the capitalization issues with `str_to_title()`,
    which converts the first letter of each word in a string to uppercase and the
    rest to lowercase, and then redo the count.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE12]*  *最常见的独特观察结果是正确的。下一个——“PatricIa”——看起来像是“i”被错误地大写了。对于“PatrIcia”也是如此。我们可以使用`str_to_title()`函数来修复大小写问题，该函数将字符串中每个单词的首字母转换为大写，其余部分转换为小写，然后重新进行计数。'
- en: Background on strings is available in [Online Appendix A](20-r_essentials.html).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 弦论背景信息可在[在线附录A](20-r_essentials.html)中找到。
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*[PRE14]*  *Already this is much better with 60 per cent of the values are
    correct, compared with the earlier 30 per cent. There are two more clear errors—“8tricia”
    and “Ptricia”—with the first distinguished by an “8” instead of a “P”, and the
    second missing an “a”. We can fix these issues with `str_replace_all()`.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE14]*  *这已经比之前的30%正确率要好多了，现在有60%的值是正确的。还有两个明显的错误——“8tricia”和“Ptricia”——第一个错误在于用“8”代替了“P”，而第二个错误则缺少了一个“a”。我们可以使用`str_replace_all()`来修复这些问题。'
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*[PRE16]*  *We have achieved an 80 per cent outcome with not too much effort.
    The final two issues are more subtle. The first has occurred because the “i” has
    been incorrectly coded as a “1”. In some fonts this will show up, but in others
    it will be more difficult to see. This is a common issue, especially with OCR,
    and something to be aware of. The second occurs because of a trailing space. Trailing
    and leading spaces are another common issue and we can address them with `str_trim()`.
    After we fix these two remaining issues we have all entries corrected.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE16]*  *我们以不太多的努力实现了80%的成果。最后两个问题更为微妙。第一个问题发生是因为“i”被错误地编码为“1”。在某些字体中这会显示出来，但在其他字体中则更难看到。这是一个常见问题，尤其是在OCR中，需要引起注意。第二个问题是因为尾随空格。尾随和首部空格又是另一个常见问题，我们可以通过`str_trim()`来解决。在我们修复这两个剩余问题之后，所有条目都得到了纠正。*'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*[PRE18]*  *We have been doing the tests in our head in this example. We know
    that we are hoping for “Patricia”. But we can start to document this test as well.
    One way is to look to see if values other than “Patricia” exist in the dataset.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE18]*  *在这个例子中，我们已经在脑海中进行了测试。我们知道我们希望得到“Patricia”。但我们可以开始记录这个测试。一种方法是查看数据集中是否存在除了“Patricia”之外的其他值。*'
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*We can make things a little more imposing by stopping our code execution if
    the condition is not met with `stopifnot()`. To use this function we define a
    condition that we would like met. We could implement this type of check throughout
    our code. For instance if we expected there to be a certain number of observations
    in the dataset, or for a certain variable to have various properties, such as
    being an integer or a factor.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以通过使用`stopifnot()`函数在条件不满足时停止代码执行，使事情显得更加严格。要使用这个函数，我们需要定义一个期望满足的条件。我们可以在代码的任何地方实现这种检查。例如，如果我们期望数据集中有特定数量的观测值，或者某个变量具有各种属性，例如是一个整数或因子。*'
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*We can use `stopifnot()` to ensure that our script is working as expected
    as it runs.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以使用 `stopifnot()` 来确保我们的脚本在运行时按预期工作。'
- en: Another way to write tests for our dataset is to use `testthat`. Although developed
    for testing packages, we can use the functionality to test our datasets. For instance,
    we can use `expect_length()` to check the length of a dataset and `expect_equal()`
    to check the content.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为我们的数据集编写测试的另一种方法是使用 `testthat`。尽管它是为测试软件包而开发的，但我们仍然可以利用其功能来测试我们的数据集。例如，我们可以使用
    `expect_length()` 来检查数据集的长度，以及使用 `expect_equal()` 来检查内容。
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*If the tests pass then nothing happens, but if the tests fail then the script
    will stop.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果测试通过则不会发生任何事，但如果测试失败则脚本将停止。'
- en: What do we test? It is a difficult problem, and we detail a range of more-specific
    tests in the next section. But broadly we test what we have, against what we expect.
    The engineers working on the software for the Apollo program in the 1960s initially
    considered writing tests to be “busy work” ([Mindell 2008, 170](99-references.html#ref-digitalapollo)).
    But they eventually came to realize that NASA would not have faith that software
    could be used to send men to the moon unless it was accompanied by a comprehensive
    suite of tests. And it is the same for data science.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测试什么？这是一个难题，我们将在下一节详细描述一系列更具体的测试。但总体来说，我们测试的是我们所拥有的，与我们所期望的进行对比。20世纪60年代参与阿波罗计划软件开发的工程师最初认为编写测试是“忙碌的工作”([Mindell
    2008, 170](99-references.html#ref-digitalapollo))。但最终他们意识到，除非软件伴随着一套全面的测试，否则NASA不会相信软件能够用来将人类送上月球。数据科学也是如此。
- en: Start with tests for validity. These will typically check the class of the variables,
    their unique values, and the number of observations. For instance, if we were
    using a recent dataset then columns that are years could be tested to ensure that
    all elements have four digits and start with a “2”. Baumgartner ([2021](99-references.html#ref-peterbaumgartnertesting))
    describes this as tests on the schema.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从有效性测试开始。这些测试通常检查变量的类别、它们的唯一值以及观测数的数量。例如，如果我们使用的是最近的数据集，那么年份的列可以测试以确保所有元素都有四位数字并以“2”开头。Baumgartner
    ([2021](99-references.html#ref-peterbaumgartnertesting)) 将其描述为对模式的测试。
- en: After that, turn to checks of internal consistency. For instance, if there are
    variables of different numeric responses, then check that the sum of those equals
    a total variable, or if it does not then this difference is explainable. Finally,
    turn to tests for external consistency. Here we want to use outside information
    to inform our tests. For instance, if we had a variable of the neonatal mortality
    rate (NMR) for Germany (this concept was introduced in [Chapter 2](02-drinking_from_a_fire_hose.html)),
    then we could look at the estimates from the World Health Organization (WHO),
    and ensure our NMR variable aligns. Experienced analysts do this all in their
    head. The issue is that it does not scale, can be inconsistent, and overloads
    on reputation. We return to this issue in [Chapter 12](12-ijalm.html) in the context
    of modeling.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，转向内部一致性的检查。例如，如果有不同数值响应的变量，那么检查这些变量的总和是否等于总变量，或者如果不等于，那么这种差异是有解释的。最后，转向外部一致性的测试。在这里，我们希望使用外部信息来指导我们的测试。例如，如果我们有一个德国新生儿死亡率（NMR）的变量（这一概念在[第二章](02-drinking_from_a_fire_hose.html)中介绍），那么我们可以查看世界卫生组织（WHO）的估计，并确保我们的NMR变量是一致的。经验丰富的分析师会在脑海中完成这些操作。问题是，这不能扩展，可能不一致，并且过度依赖声誉。我们将在[第十二章](12-ijalm.html)的建模背景下回到这个问题。
- en: 'We write tests throughout our code, rather than right at the end. In particular,
    using `stopifnot()` statements on intermediate steps ensures that the dataset
    is being cleaned in a way that we expect. For instance, when merging two datasets
    we could check:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在整个代码中编写测试，而不是仅在最后。特别是，在中间步骤使用`stopifnot()`语句可以确保数据集正在以我们期望的方式进行清理。例如，当合并两个数据集时，我们可以检查：
- en: The variable names in the datasets are unique, apart from the column/s to be
    used as the key/s.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集中的变量名称是唯一的，除了用作键的列/之外。
- en: The number of observations of each type is being carried through appropriately.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每种类型的观测数量正在被适当地传递。
- en: The dimensions of the dataset are not being unexpectedly changed.**********  ****###
    9.2.5 Iterate, generalize, and update
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集的维度没有出现意外变化。**********  ****### 9.2.5 迭代、归纳和更新
- en: We could now iterate the plan. In this most recent case, we started with ten
    entries. There is no reason that we could not increase this to 100 or even 1,000\.
    We may need to generalize the cleaning procedures and tests. But eventually we
    would start to bring the dataset into some sort of order.******  ****## 9.3 Checking
    and testing
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以迭代这个计划。在这个最近的案例中，我们开始时有十个条目。我们没有理由不能增加到100个甚至1,000个。我们可能需要将清理程序和测试进行一般化。但最终，我们会开始将数据集整理成某种秩序。******  ****##
    9.3 检查和测试
- en: Robert Caro, the biographer of Lyndon Johnson introduced in [Chapter 4](04-writing_research.html),
    spent years tracking down everyone connected to the 36th President of the United
    States. Caro and his wife Ina went so far as to live in Texas Hill Country for
    three years so that they could better understand where Johnson was from. When
    Caro heard that Johnson, as a senator, would run to the Senate from where he stayed
    in D.C., he ran that route multiple times himself to try to understand why Johnson
    was running. Caro eventually understood it only when he ran the route as the sun
    was rising, just as Johnson had done; it turns out that the sun hits the Senate
    Rotunda in a particularly inspiring way ([Caro 2019, 156](99-references.html#ref-caroonworking)).
    This background work enabled him to uncover aspects that no one else knew. For
    instance, Johnson almost surely stole his first election win ([Caro 2019, 116](99-references.html#ref-caroonworking)).
    We need to understand our data to this same extent. We want to metaphorically
    turn every page.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 罗伯特·卡罗，林登·约翰逊的传记作者，在[第四章](04-writing_research.html)中介绍，花费多年时间追踪与美利坚合众国第36任总统相关联的每一个人。卡罗和他的妻子伊娜甚至搬到德克萨斯州的希尔乡村居住了三年，以便更好地了解约翰逊的出身。当卡罗听说约翰逊作为参议员将从他在华盛顿特区居住的地方参选参议院时，他自己多次跑那条路线，试图理解约翰逊为何要这么做。卡罗最终是在太阳升起时跑那条路线，就像约翰逊所做的那样，才理解了这一切；结果证明，太阳以特别鼓舞人心的方式照射着参议院圆顶([Caro
    2019, 156](99-references.html#ref-caroonworking))。这项背景工作使他能够揭露其他人不知道的方面。例如，约翰逊几乎肯定是在第一次选举中窃取了胜利([Caro
    2019, 116](99-references.html#ref-caroonworking))。我们需要像这样深入理解我们的数据。我们希望比喻性地翻阅每一页。
- en: 'The idea of negative space is well established in design. It refers to that
    which surrounds the subject. Sometimes negative space is used as an effect. For
    instance the logo of FedEx, an American logistics company, has negative space
    between the E and X that creates an arrow. In a similar way, we want to be cognizant
    of the data that we have, and the data that we do not have ([Hodgetts 2022](99-references.html#ref-citemyboy)).
    We are worried that the data that we do not have somehow has meaning, potentially
    even to the extent of changing our conclusions. When we are cleaning data, we
    are looking for anomalies. We are interested in values that are in the dataset
    that should not be, but also the opposite situation—values that should be in the
    dataset but are not. There are three tools that we use to identify these situations:
    graphs, counts, and tests.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 负空间的观念在设计领域中已经得到了很好的确立。它指的是围绕主题的部分。有时负空间会被用作一种效果。例如，美国物流公司FedEx的标志在E和X之间就利用了负空间，形成了一个箭头。以类似的方式，我们希望对所拥有的数据和未拥有的数据保持警觉（[Hodgetts
    2022](99-references.html#ref-citemyboy)）。我们担心那些我们没有的数据可能具有某种意义，甚至可能到足以改变我们结论的程度。当我们清理数据时，我们正在寻找异常值。我们对数据集中不应该存在的值感兴趣，但也对应该存在于数据集中但实际不存在的值感兴趣。我们有三种工具用来识别这些情况：图表、计数和测试。
- en: We also use these tools to ensure that we are not changing correct observations
    to incorrect. Especially when our cleaning and preparation requires many steps,
    it may be that fixes at one stage are undone later. We use graphs, counts, and
    especially tests, to prevent this. The importance of these grows exponentially
    with the size of the dataset. Small and medium datasets are more amenable to manual
    inspection and other aspects that rely on the analyst, while larger datasets especially
    require more efficient strategies ([Hand 2018](99-references.html#ref-hand2018statistical)).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也使用这些工具来确保我们不会将正确的观察结果改为错误的。尤其是在我们的清理和准备需要许多步骤时，可能会出现某个阶段的修复在后续被撤销的情况。我们使用图表、计数，尤其是测试，来防止这种情况发生。这些工具的重要性随着数据集大小的增加而呈指数级增长。小型和中型数据集更易于手动检查和其他依赖分析师的方面，而大型数据集尤其需要更有效的策略([Hand
    2018](99-references.html#ref-hand2018statistical))。
- en: 9.3.1 Graphs
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 图
- en: 'Graphs are an invaluable tool when cleaning data, because they show each observation
    in the dataset, potentially in relation to the other observations. They are useful
    for identifying when a value does not belong. For instance, if a value is expected
    to be numerical, but is still a character then it will not plot, and a warning
    will be displayed. Graphs will be especially useful for numerical data, but are
    still useful for text and categorical data. Let us pretend that we have a situation
    where we are interested in a person’s age, for some youth survey. We have the
    following data:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图表在数据清洗时是一个无价之宝，因为它们展示了数据集中的每个观测值，可能还与其他观测值相关。它们有助于识别哪些值不属于正常范围。例如，如果一个值预期是数值型的，但实际是字符型，那么它将无法绘制，并会显示警告。图表对于数值数据尤其有用，但对于文本和分类数据也同样有用。让我们假设我们有一个情况，我们对于一个青年调查中的人的年龄感兴趣。我们有以下数据：
- en: '[PRE22]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE23]'
- en: '*![](../Images/b05d9fcb26b3be254d854a37ed58303f.png)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/b05d9fcb26b3be254d854a37ed58303f.png)*'
- en: (a) Before cleaning
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 清洁前
- en: '![](../Images/5fc37b290e649f248b703dce819cb2e5.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/5fc37b290e649f248b703dce819cb2e5.png)'
- en: (b) After cleaning
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 清洁后
- en: 'Figure 9.2: The ages in the simulated youth survey dataset identify a data
    issue'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：模拟青年调查数据集中的年龄识别出一个数据问题
- en: '[Figure 9.2 (a)](#fig-youth-survey-1) shows an unexpected value of 150\. The
    most likely explanation is that the data were incorrectly entered, missing the
    decimal place, and should be 15.0\. We could fix that, document it, and then redo
    the graph, which would show that everything seemed more valid ([Figure 9.2 (b)](#fig-youth-survey-2)).**  **###
    9.3.2 Counts'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.2 (a)](#fig-youth-survey-1) 显示了一个意外的值150。最可能的解释是数据输入错误，遗漏了小数点，应该是15.0。我们可以修复这个问题，记录下来，然后重新绘制图表，这将显示一切看起来更加有效
    ([图9.2 (b)](#fig-youth-survey-2))。**  **### 9.3.2 计数'
- en: We want to focus on getting most of the data right, so we are interested in
    the counts of unique values. Hopefully most of the data are concentrated in the
    most common counts. But it can also be useful to invert it and see what is especially
    uncommon. The extent to which we want to deal with these depends on what we need.
    Ultimately, each time we fix one we are getting very few additional observations,
    potentially even just one. Counts are especially useful with text or categorical
    data but can be helpful with numerical data as well.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望专注于获取大部分数据的准确性，因此我们对唯一值的计数感兴趣。希望大部分数据都集中在最常见的计数中。但反过来查看特别不常见的数据也可能很有用。我们处理这些数据的程度取决于我们的需求。最终，每次我们修正一个数据点，我们只能获得非常少的额外观察结果，甚至可能只有一条。计数在处理文本或分类数据时特别有用，但在处理数值数据时也可能有所帮助。
- en: Let us see an example of text data, each of which is meant to be “Australia”.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个文本数据的例子，每个都代表“澳大利亚”。
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '*[PRE25]*  *The use of this count identifies where we should spend our time:
    changing “Australie” to “Australia” would almost double the amount of usable data.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE25]*  *使用这个计数可以确定我们应该在哪里花费时间：将“Australie”改为“Australia”几乎可以使可用数据量翻倍。'
- en: Turning, briefly to numeric data, Preece ([1981](99-references.html#ref-Preece1981))
    recommends plotting counts of the final digit of each observation in a variable.
    For instance, if the observations of the variable were “41.2”, “80.3”, “20.7”,
    “1.2”, “46.5”, “96.2”, “32.7”, “44.3”, “5.1”, and “49.0”. Then we note that 0,
    1 and 5 all occur once, 3 and 7 occur twice, and 2 occurs three times. We might
    expect that there should be a uniform distribution of these final digits. But
    that is surprisingly often not the case, and the ways in which it differs can
    be informative. For instance, it may be that data were rounded, or recorded by
    different collectors.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地转向数值数据，Preece ([1981](99-references.html#ref-Preece1981)) 建议绘制每个变量观测值的最后一位数字的计数图。例如，如果该变量的观测值为“41.2”，“80.3”，“20.7”，“1.2”，“46.5”，“96.2”，“32.7”，“44.3”，“5.1”，和“49.0”。那么我们注意到0、1和5各出现一次，3和7各出现两次，而2出现了三次。我们可能会预期这些最后一位数字应该有一个均匀的分布。但出人意料的是，这往往不是情况，而且它差异的方式可能是有启发性的。例如，可能数据被四舍五入，或者由不同的收集者记录。
- en: For instance, later in this chapter we will gather, clean, and prepare some
    data from the 2019 Kenyan census. We pre-emptively use that dataset here and look
    at the count of the final digits of the ages. That is, say, from age 35 we take
    “5”, from age 74, we take “4”. [Table 9.1](#tbl-countofages) shows the expected
    age-heaping that occurs because some respondents reply to questions about age
    with a value to the closest 5 or 10\. If we had an age variable without that pattern
    then we might expect it had been constructed from a different type of question.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在本章的后面部分，我们将收集、清洗和准备一些来自2019年肯尼亚人口普查的数据。我们预先使用这个数据集，并查看年龄最后一位数的计数。也就是说，比如说，从35岁我们取“5”，从74岁我们取“4”。[表9.1](#tbl-countofages)显示了由于一些受访者回答关于年龄的问题时选择了最接近的5或10的值，因此发生的预期年龄尾数堆积。如果我们有一个没有这种模式的年龄变量，那么我们可能会预期它是由不同类型的问题构建的。
- en: 'Table 9.1: Excess of 0 and 5 digits in counts of the final digits of single-year
    ages in Nairobi from the 2019 Kenyan census'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1：内罗毕单一年龄人口年龄末尾数字中0和5数字的过剩情况，数据来源于2019年肯尼亚人口普查
- en: '| Final digit of age | Number of times |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 年龄的最后一位数字 | 出现次数 |'
- en: '| --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 347,233 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 347,233 |'
- en: '| 1 | 278,930 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 278,930 |'
- en: '| 2 | 308,933 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 308,933 |'
- en: '| 3 | 285,745 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 285,745 |'
- en: '| 4 | 270,355 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 270,355 |'
- en: '| 5 | 303,817 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 303,817 |'
- en: '| 6 | 246,582 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 246,582 |'
- en: '| 7 | 242,688 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 242,688 |'
- en: '| 8 | 207,739 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 207,739 |'
- en: '| 9 | 216,355 |*  *### 9.3.3 Tests'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '| 9 | 216,355 |*  *### 9.3.3 测试'
- en: As we said in [Chapter 3](03-workflow.html), if you write code, then you are
    a programmer, but there is a difference between someone coding for fun, and, say,
    writing the code that runs the James Webb Telescope. Following Weinberg ([1971,
    122](99-references.html#ref-weinbergpsychology)), we can distinguish between amateurs
    and professionals based the existence of subsequent users. When you first start
    out coding, you typically write code that only you will use. For instance, you
    may write some code for a class paper. After you get a grade, then in most cases,
    the code will not be run again. In contrast, a professional writes code for, and
    often with, other people.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第3章](03-workflow.html)中所述，如果你编写代码，那么你就是一名程序员，但仅仅是为了娱乐而编码的人和编写运行詹姆斯·韦伯望远镜代码的人之间是有区别的。遵循温伯格([1971,
    122](99-references.html#ref-weinbergpsychology))的观点，我们可以根据后续用户的存在来区分业余爱好者和专业人士。当你刚开始编码时，你通常编写的是只有你自己会使用的代码。例如，你可能为课程论文编写一些代码。在你得到成绩后，在大多数情况下，代码将不再被运行。相比之下，专业人士编写代码是为了，并且经常与，其他人一起。
- en: Much academic research these days relies on code. If that research is to contribute
    to lasting knowledge, then the code that underpins it is being written for others
    and must work for others well after the researcher has moved to other projects.
    A professional places appropriate care on tasks that ensure code can be considered
    by others. A large part of that is tests.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，许多学术研究都依赖于代码。如果这项研究要为持久的知识做出贡献，那么支撑它的代码就需要为他人编写，并且在使用者转向其他项目之后，代码仍需为他人良好地工作。专业人士会对确保代码能为他人所考虑的任务给予适当的关注。其中很大一部分是测试。
- en: Jet Propulsion Laboratory ([2009, 14](99-references.html#ref-jplcodingstandards))
    claim that analysis after the fact “often find at least one defect per one hundred
    lines of code written”. There is no reason to believe that code without tests
    is free of defects, just that they are not known. As such, we should strive to
    include tests in our code when possible. There is some infrastructure for testing
    data science code. For instance, in Python there is the Test-Driven Data Analysis
    library of Radcliffe ([2023](99-references.html#ref-tdda)), but more is needed.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 火箭推进实验室 ([2009, 14](99-references.html#ref-jplcodingstandards)) 声称，事后的分析“通常每写一百行代码就能发现至少一个缺陷”。没有理由相信没有测试的代码是没有缺陷的，只是它们尚未被发现。因此，我们应该尽可能地在代码中包含测试。有一些基础设施用于测试数据科学代码。例如，在
    Python 中有 Radcliffe 的测试驱动数据分析库 ([2023](99-references.html#ref-tdda))，但还需要更多。
- en: 'Some things are so important that we require that the cleaned dataset have
    them. These are conditions that we should check. They would typically come from
    experience, expert knowledge, or the planning and simulation stages. For instance,
    there should be no negative numbers in an age variable, and few ages above 110\.
    For these we could specifically require that the condition is met. Another example
    is when doing cross-country analysis, a list of country names that we know should
    be in our dataset would be useful. Our test would then be that there were:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 有些事情非常重要，以至于我们要求清洗后的数据集必须包含它们。这些是我们应该检查的条件。它们通常来自经验、专业知识或规划和模拟阶段。例如，年龄变量中不应有负数，并且年龄超过110岁的情况很少。对于这些情况，我们可以具体要求满足条件。另一个例子是在进行跨国分析时，一个我们知道应该包含在我们数据集中的国家名称列表将是有用的。我们的测试将是确保以下情况存在：
- en: values not in that list that were in our dataset, or vice versa; and
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那个列表中没有但在我们的数据集中存在的值，或者反过来；以及
- en: countries that we expected to be in our dataset that were not.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们预期应该包含在我们的数据集中但实际并未出现的国家。
- en: 'To have a concrete example, let us consider if we were doing some analysis
    about the five largest counties in Kenya. From looking it up, we find these are:
    “Nairobi”, “Kiambu”, “Nakuru”, “Kakamega”, and “Bungoma”. We can create that variable.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有一个具体的例子，让我们考虑如果我们正在对肯尼亚最大的五个县进行分析。通过查询，我们发现这些是：“内罗毕”、“基安布”、“纳库鲁”、“卡卡梅加”和“布隆迪马”。我们可以创建那个变量。
- en: '[PRE26]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '*Then pretend we have the following dataset, which contains errors.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*然后假设我们有一个包含错误的以下数据集。'
- en: '[PRE27]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*[PRE28]*  *Based on the count we know that we must fix some of them. There
    are two with numbers in the names.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE28]*  *根据计数，我们知道我们必须修复其中的一些。有两个名字中有数字。'
- en: '[PRE29]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*[PRE30]*  *At this point we can compare this with our known correct variable.
    We check both ways, i.e. is there anything in the correct variable not in our
    dataset, and is there anything in the dataset not in our correct variable. We
    use our check conditions to decide whether we are finished.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE30]*  *在这个阶段，我们可以将此与我们所知的正确变量进行比较。我们进行双向检查，即检查正确变量中是否有不在我们的数据集中，以及数据集中是否有不在我们的正确变量中的内容。我们使用检查条件来决定我们是否完成。'
- en: '[PRE31]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE32]'
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*[PRE34]**  **It is clear that we still have cleaning to do because not all
    the counties match what we were expecting.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE34]**  **很明显，我们仍然需要进行清理，因为并非所有县都符合我们的预期。'
- en: 9.3.3.1 Aspects to test
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.3.3.1 需要测试的方面
- en: 'We will talk about explicit tests for class and dates, given their outsized
    importance, and how common it is for them to go wrong. But other aspects to explicitly
    consider testing include:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论针对类和日期的显式测试，鉴于它们的重要性非同寻常，以及它们出错是多么常见。但需要明确考虑测试的其他方面包括：
- en: Variables of monetary values should be tested for reasonable bounds given the
    situation. In some cases negative values will not be possible. Sometimes an upper
    bound can be identified. Monetary variables should be numeric. They should not
    have commas or other separators. They should not contain symbols such as currency
    signs or semicolons.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 货币价值的变量应根据具体情况测试其合理的范围。在某些情况下，负值可能不可行。有时可以确定一个上限。货币变量应该是数字。它们不应包含逗号或其他分隔符。它们不应包含货币符号或分号等符号。
- en: Variables of population values should likely not be negative. Populations of
    cities should likely be somewhere between 100,000 and 50,000,000\. They again
    should be numeric, and contain only numbers, no symbols.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口值的变量很可能不应为负数。城市的人口数量很可能在100,000到50,000,000之间。它们再次应该是数字的，并且只包含数字，没有符号。
- en: Names should be character variables. They likely do not contain numbers. They
    may contain some limited set of symbols, and this would be context specific.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称应该是字符变量。它们很可能不包含数字。它们可能包含一些有限的符号集，这将是上下文特定的。
- en: The number of observations is surprisingly easy to inadvertently change. While
    it is fine for this to happen deliberately, when it happens accidentally it can
    create substantial problems. The number of observations should be tested at the
    start of any data cleaning process against the data simulation and this expectation
    updated as necessary. It should be tested throughout the data cleaning process,
    but especially before and after any joins.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察数的数量意外改变的情况令人惊讶地容易发生。虽然故意这样做是可以接受的，但当它意外发生时，可能会造成重大问题。在任何数据清洗过程的开始阶段，观察数应该与数据模拟进行测试，并根据需要更新这一预期。在整个数据清洗过程中都应进行测试，但尤其是在任何连接操作之前和之后。
- en: More generally, work with experts and draw on prior knowledge to work out some
    reasonable features for the variables of interest and then implement these. For
    instance, consider how Baker ([2023](99-references.html#ref-scamswillnotsaveus))
    was able to quickly identify an error in a claim about user numbers by roughly
    comparing it with how many institutions in the US receive federal financial aid.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地，与专家合作，利用先验知识为感兴趣的变量制定一些合理的特征，然后实施这些特征。例如，考虑Baker ([2023](99-references.html#ref-scamswillnotsaveus))
    如何通过大致比较美国有多少机构接受联邦财政援助来快速识别关于用户数量的声明中的错误。
- en: We can use `validate` to set up a series of tests. For instance, here we will
    simulate some data with clear issues.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`validate`来设置一系列测试。例如，这里我们将模拟一些存在明显问题的数据。
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '*[PRE36]*  *In this case, there is an impossible age, one observation in the
    gender variable that should not be there, and finally, income is a character variable
    instead of a numeric. We use `validator()` to establish rules we expect the data
    to satisfy and `confront()` to determine whether it does.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE36]*  *在这种情况下，存在一个不可能的年龄，性别变量中有一个不应该存在的观测值，最后，收入是一个字符变量而不是数值变量。我们使用`validator()`来建立我们期望数据满足的规则，并使用`confront()`来确定它是否满足这些规则。'
- en: '[PRE37]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '*[PRE38]*  *In this case, we can see that there are issues with the final three
    rules that we established. More generally, van der Loo ([2022](99-references.html#ref-datavalidationbook))
    provides many example tests that can be used.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE38]*  *在这种情况下，我们可以看到我们确立的最后三条规则存在问题。更普遍地，van der Loo ([2022](99-references.html#ref-datavalidationbook))
    提供了许多可以使用的示例测试。*'
- en: As mentioned in [Chapter 6](06-farm.html), gender is something that we need
    to be especially careful about. We will typically have a small number of responses
    that are neither “male” or “female”. The correct way to deal with the situation
    depends on context. But if responses other than “male” or “female” are going to
    be removed from the dataset and ignored, because there are too few of them, showing
    respect for the respondent might mean including a brief discussion of how they
    were similar or different to the rest of the dataset. Plots and a more extensive
    discussion could then be included in an appendix.**  **#### 9.3.3.2 Class
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第6章](06-farm.html)所述，性别是我们需要特别小心对待的问题。我们通常只有少数既不是“男性”也不是“女性”的回答。正确处理这种情况的方式取决于上下文。但如果除了“男性”或“女性”之外的其他回答因为数量太少而被从数据集中移除并忽略，那么尊重受访者可能意味着包括一个简短的讨论，说明他们与数据集中其他部分相似或不同之处。然后可以在附录中包含图表和更广泛的讨论。**  **####
    9.3.3.2 类
- en: 'It is sometimes said that Americans are obsessed with money, while the English
    are obsessed with class. In the case of data cleaning and preparation we need
    to be English. Class is critical and worthy of special attention. We introduce
    class in [Online Appendix A](20-r_essentials.html) and here we focus on “numeric”,
    “character”, and “factor”. Explicit checks of the class of variables are essential.
    Accidentally assigning the wrong class to a variable can have a large effect on
    subsequent analysis. It is important to:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有时人们会说美国人沉迷于金钱，而英国人沉迷于阶级。在数据清洗和准备的情况下，我们需要表现得像英国人。阶级至关重要，值得特别注意。我们在[在线附录A](20-r_essentials.html)中介绍了阶级，在这里我们关注“数值”、“字符”和“因子”。对变量类别的明确检查是必不可少的。错误地将变量分配到错误的类别可能会对后续分析产生重大影响。重要的是：
- en: check whether some value should be a number or a factor; and
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查某个值是否应该是数字或因子；并且
- en: check that values are numbers not characters.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查值是否为数字而非字符。
- en: 'To understand why it is important to be clear about whether a value is a number
    or a factor, consider the following situation:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么明确一个值是数字还是因素很重要，考虑以下情况：
- en: '[PRE39]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '*We use logistic regression, which we cover in more detail in [Chapter 12](12-ijalm.html),
    and first include “group” as an integer, then we include it as a factor. [Table 9.2](#tbl-effect-of-class)
    shows how different the results are and highlights the importance of getting the
    class of variables used in regression right. In the former, where group is an
    integer, we impose a consistent relationship between the different levels of the
    observations, whereas in the latter, where it is a factor, we enable more freedom.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用逻辑回归，这在[第12章](12-ijalm.html)中进行了更详细的介绍，首先将“group”作为一个整数包含在内，然后将其作为一个因子包含。[表9.2](#tbl-effect-of-class)展示了不同结果之间的差异，并突出了正确选择用于回归的变量类别的重要性。在前者中，当group是一个整数时，我们要求观察的不同级别之间保持一致的关系，而在后者中，当它是一个因子时，我们允许更多的自由度。
- en: '[PRE40]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '*Table 9.2: Examining the effect of class on regression results'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*表9.2：检验班级对回归结果的影响*'
- en: '|  | Group as integer | Group as factor |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | 将组作为整数 | 将组作为因子 |'
- en: '| --- | --- | --- |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| (Intercept) | 1.417 | 1.099 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| (拦截) | 1.417 | 1.099 |'
- en: '|  | (1.755) | (1.155) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  | (1.755) | (1.155) |'
- en: '| group_as_integer | -0.666 |  |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 整数分组 | -0.666 |  |'
- en: '|  | (0.894) |  |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.894) |  |'
- en: '| group_as_factor2 |  | -1.792 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| group_as_factor2 |  | -1.792 |'
- en: '|  |  | (1.683) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (1.683) |'
- en: '| group_as_factor3 |  | -1.099 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| group_as_factor3 |  | -1.099 |'
- en: '|  |  | (1.826) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (1.826) |'
- en: '| Num.Obs. | 9 | 9 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 观测数量 | 9 | 9 |'
- en: '| AIC | 15.8 | 17.1 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| AIC | 15.8 | 17.1 |'
- en: '| BIC | 16.2 | 17.7 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| BIC | 16.2 | 17.7 |'
- en: '| Log.Lik. | -5.891 | -5.545 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 对数似然 | -5.891 | -5.545 |'
- en: '| F | 0.554 | 0.579 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| F | 0.554 | 0.579 |'
- en: '| RMSE | 0.48 | 0.46 |*  *Class is so important, subtle, and can have such
    a pernicious effect on analysis, that analysis with a suite of tests that check
    class is easier to believe. Establishing this suite is especially valuable just
    before modeling, but it is worthwhile setting this up as part of data cleaning
    and preparation. One reason that Jane Street, the US proprietary trading firm,
    uses a particular programming language, OCaml, is that its type system makes it
    more reliable with regard to class ([Somers 2015](99-references.html#ref-somers2015)).
    When code matters, class is of vital concern.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '| RMSE | 0.48 | 0.46 |*  *班级非常重要，微妙，并且可能对分析产生如此有害的影响，以至于使用一系列检查类别的测试套件进行分析更容易让人相信。在建模之前建立这个套件尤其有价值，但将其作为数据清洗和准备的一部分设置起来也是值得的。Jane
    Street，一家美国自营交易公司，使用特定编程语言OCaml的原因之一是，其类型系统使其在类别方面更加可靠（[Somers 2015](99-references.html#ref-somers2015)）。当代码很重要时，类别是一个至关重要的关注点。'
- en: There are many open questions around the effect and implications of type in
    computer science more generally but there has been some work. For instance, Gao,
    Bird, and Barr ([2017](99-references.html#ref-Gao2017)) find that the use of a
    static type system would have caught around 15 per cent of errors in production
    JavaScript systems. Languages have been developed, such as Typescript, where the
    primary difference, in this case from JavaScript, is that they are strongly typed.
    Turcotte et al. ([2020](99-references.html#ref-Turcotte2020)) examine some of
    the considerations for adding a type system in R. They develop a prototype that
    goes some way to addressing the technical issues, but acknowledge that large-scale
    implementation would be challenging for many reasons including the need for users
    to change.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学领域，关于类型效应和影响的许多开放性问题尚未解决，但已有一些研究工作。例如，高、伯德和巴勒（[2017](99-references.html#ref-Gao2017)）发现，使用静态类型系统可以捕捉到生产环境中JavaScript系统大约15%的错误。已经开发了一些语言，如TypeScript，其中主要区别在于，在这种情况下与JavaScript相比，它们是强类型。图尔科特等人（[2020](99-references.html#ref-Turcotte2020)）探讨了在R语言中添加类型系统的某些考虑因素。他们开发了一个原型，在某种程度上解决了技术问题，但承认由于需要用户改变等多种原因，大规模实施将具有挑战性。
- en: 'To this point in this book when we have used `read_csv()`, and other functions
    for importing data, we have allowed the function to guess the class of the variables.
    Moving forward we will be more deliberate and instead specify it ourselves using
    “col_types”. For instance, instead of:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书的这一部分，当我们使用 `read_csv()` 和其他导入数据的函数时，我们允许函数猜测变量的类型。从现在开始，我们将更加谨慎，并使用“col_types”自行指定它。例如，而不是：
- en: '[PRE41]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '*We recommend using:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推荐使用：
- en: '[PRE42]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '*This is typically an iterative process of initially reading in the dataset,
    getting a quick sense of it, and then reading it in properly with only the necessary
    columns and classes specified. While this will require a little extra work of
    us, it is important that we are clear about class.****  ***#### 9.3.3.3 Dates'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的迭代过程，最初是读取数据集，快速了解其内容，然后只指定必要的列和类别，正确地读取它。虽然这会让我们多做一些额外的工作，但清楚类别是很重要的。****  ***####
    9.3.3.3 日期
- en: A shibboleth for whether someone has worked with dates is their reaction when
    you tell them you are going to be working with dates. If they share a horror story,
    then they have likely worked with dates before!
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 判断一个人是否处理过日期的一个标志是，当你告诉他们你将要处理日期时他们的反应。如果他们分享了一个恐怖故事，那么他们很可能之前处理过日期！
- en: 'Extensive checking of dates is important. Ideally, we would like dates to be
    in the following format: YYYY-MM-DD. There are differences of opinion as to what
    is an appropriate date format in the broader world. Reasonable people can differ
    on whether 1 July 2022 or July 1, 2022 is better, but YYYY-MM-DD is the international
    standard and we should use that in our date variables where possible.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 日期的详细检查非常重要。理想情况下，我们希望日期采用以下格式：YYYY-MM-DD。关于在更广泛的世界中哪种日期格式是合适的，存在不同的观点。合理的人可能会对2022年7月1日或7月1日，2022年哪个更好持有不同意见，但YYYY-MM-DD是国际标准，我们应在可能的情况下在我们的日期变量中使用该格式。
- en: 'A few tests that could be useful include:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 一些可能有用的测试包括：
- en: If a column is days of the week, then test that the only components are Monday,
    Tuesday, \(\dots\), Sunday. Further, test that all seven days are present. Similarly,
    for month.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一列是星期几，那么测试该列仅包含周一、周二、\(\dots\)、周日。进一步，测试这七天是否都存在。同样地，对于月份。
- en: Test that the number of days is appropriate for each month, for instance, check
    that September has 30 days, etc.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试每个月的天数是否合适，例如，检查九月是否有30天等。
- en: Check whether the dates are in order in the dataset. This need not necessarily
    be the case, but often when it is not, there are issues worth exploring.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据集中日期是否按顺序排列。这不一定必须如此，但通常当顺序不对时，会有值得探索的问题。
- en: Check that the years are complete and appropriate to the analysis period.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查年份是否完整且适合分析期
- en: In [Chapter 2](02-drinking_from_a_fire_hose.html) we introduced a dataset of
    shelter usage in Toronto in 2021 using `opendatatoronto`. Here we examine that
    same dataset, but for 2017, to illustrate some issues with dates. We first need
    to download the data.[²](#fn2)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](02-drinking_from_a_fire_hose.html)中，我们使用`opendatatoronto`介绍了2021年多伦多庇护所使用的数据集。在这里，我们考察同一数据集，但针对2017年，以说明一些与日期相关的问题。我们首先需要下载这些数据。[²](#fn2)
- en: '[PRE43]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '*We need to make the names easier to type and only keep relevant columns.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们需要使名称更容易输入，并且只保留相关列。'
- en: '[PRE44]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '*The main issue with this dataset will be the dates. We will find that the
    dates appear to be mostly year-month-day, but certain observations may be year-day-month.
    We use `ymd()` from `lubridate` to parse the date in that order.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个数据集的主要问题将是日期。我们会发现日期大多以年-月-日格式出现，但某些观测值可能是年-日-月格式。我们使用`lubridate`中的`ymd()`函数按此顺序解析日期。*'
- en: '[PRE45]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '*[PRE46]*  *The plot of the distribution of what purports to be the day component
    makes it clear that there are concerns ([Figure 9.3 (a)](#fig-homeless-daycount-1)).
    In particular we are concerned that the distribution of the days is not roughly
    uniform.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE46]*  *该分布图展示了所谓日成分的分布情况，从中可以明显看出存在一些担忧（[图9.3 (a)](#fig-homeless-daycount-1)）。特别是，我们担心这些天的分布并非大致均匀。'
- en: '[PRE47]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '*![](../Images/0da30e0c5ecff04de4a2d2e4bf3dc316.png)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/0da30e0c5ecff04de4a2d2e4bf3dc316.png)*'
- en: (a) Counts, by third component of occupancy date
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 按占用日期的第三分量计数
- en: '![](../Images/721b0ada2b49576360d99a4f25d8ab3e.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/721b0ada2b49576360d99a4f25d8ab3e.png)'
- en: (b) Comparison of row number with date
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 比较行号与日期
- en: 'Figure 9.3: Examining the date in more detail'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3：更详细地检查日期
- en: As mentioned, one graph that is especially useful when cleaning a dataset is
    the order the observations appear in the dataset. For instance, we would generally
    expect that there would be a rough ordering in terms of date. To examine whether
    this is the case, we can graph the date variable in the order it appears in the
    dataset ([Figure 9.3 (b)](#fig-homeless-daycount-2)).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在清理数据集时，一个特别有用的图表是观察在数据集中出现的顺序。例如，我们通常会期望在日期方面有一个大致的顺序。为了检验这一点，我们可以按数据集中出现的顺序绘制日期变量（[图9.3
    (b)](#fig-homeless-daycount-2)）。
- en: While this is just a quick graph it illustrates the point—there are a lot in
    order, but not all. If they were in order, then we would expect them to be along
    the diagonal. It is odd that the data are not in order, especially as there appears
    to be something systematic initially. We can summarize the data to get a count
    of occupancy by day.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这只是个快速绘制的图表，但它说明了这个观点——有很多数据是有序的，但并非全部。如果它们是有序的，那么我们预期它们会沿着对角线排列。数据最初似乎存在某种系统性，但数据并不有序，这很奇怪。我们可以总结数据以获取按日占用的计数。
- en: '[PRE48]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '*We are interested in the availability of shelter spots in Toronto for each
    day ([Figure 9.4](#fig-plotoccupancy)).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们对多伦多每天可用的庇护所位置感兴趣 ([图9.4](#fig-plotoccupancy))。'
- en: '[PRE49]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '*![](../Images/63b0b58c04175b2869079ab7cd1f1b91.png)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/63b0b58c04175b2869079ab7cd1f1b91.png)*'
- en: 'Figure 9.4: Occupancy per day in Toronto shelters*  *It is clear there seems
    to be an issue with the first 12 days of the month. We noted that when we look
    at the data it is a bit odd that it is not in order. From [Figure 9.3 (b)](#fig-homeless-daycount-2)
    it looks like there are some systematic issue that affects many observations.
    In general, it seems that it might be the case that in the date variable the first
    12 days are the wrong way around, i.e. we think it is year-month-day, but it is
    actually year-day-month. But there are exceptions. As a first pass, we can flip
    those first 12 days of each month and see if that helps. It will be fairly blunt,
    but hopefully gets us somewhere.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4：多伦多收容所每日占用情况*  *很明显，似乎这个月的前12天存在问题。我们注意到，当我们查看数据时，它似乎有些不按顺序，这有点奇怪。从[图9.3（b）](#fig-homeless-daycount-2)来看，似乎有一些系统性问题影响了多个观察结果。总的来说，似乎可能是日期变量中的前12天顺序错误，即我们认为它是年-月-日，但实际上是年-日-月。但也有一些例外。作为初步尝试，我们可以将每个月的前12天颠倒过来，看看是否有所帮助。这将会相当直接，但希望这能让我们有所进展。
- en: '[PRE50]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '*Now let us take a look ([Figure 9.5](#fig-sheltersdatebyrowadj)).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*现在让我们来看一下 ([图9.5](#fig-sheltersdatebyrowadj)).'
- en: '[PRE51]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '*![](../Images/00b8638269285159ed25f38ff6201f48.png)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/00b8638269285159ed25f38ff6201f48.png)*'
- en: (a) Date of each row in order after adjustment
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 调整后每行的日期顺序
- en: '![](../Images/86c40bcb780df61ad732c28ddaa432e2.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/86c40bcb780df61ad732c28ddaa432e2.png)'
- en: (b) Toronto shelters daily occupancy after adjustment
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 调整后的多伦多庇护所每日容纳量
- en: 'Figure 9.5: Adjusted dates, occupancy in Toronto shelters'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5：调整后的日期，多伦多收容所的入住率
- en: 'It has not fixed all the issues. For instance, notice there are now no entries
    below the diagonal ([Figure 9.5 (a)](#fig-sheltersdatebyrowadj-1)). But we can
    see that has almost entirely taken care of the systematic differences ([Figure 9.5
    (b)](#fig-sheltersdatebyrowadj-2)). This is where we will leave this example.*********************  ***##
    9.4 Simulated example: running times'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 它并没有解决所有问题。例如，请注意现在对角线以下没有条目([图9.5 (a)](#fig-sheltersdatebyrowadj-1))。但我们可以看出，它几乎完全处理了系统差异([图9.5
    (b)](#fig-sheltersdatebyrowadj-2))。这就是我们将结束这个示例的地方。*********************  ***##
    9.4 模拟示例：运行时间
- en: To provide a specific example, which we will return to in [Chapter 12](12-ijalm.html),
    consider the time it takes someone to run five kilometers (which is a little over
    three miles), compared with the time it takes them to run a marathon ([Figure 12.2
    (a)](12-ijalm.html#fig-fivekmvsmarathon-1)).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个具体的例子，我们将在[第12章](12-ijalm.html)中再次提及，考虑某人跑五公里（略超过三英里）所需的时间，与跑马拉松所需的时间相比（[图12.2
    (a)](12-ijalm.html#fig-fivekmvsmarathon-1))。
- en: Here we consider “simulate” and “acquire”, focused on testing. In the simulation
    we specify a relationship of 8.4, as that is roughly the ratio between a five-kilometer
    run and the 42.2 kilometer distance of a marathon (a little over 26 miles).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们考虑“模拟”和“获取”，重点关注测试。在模拟中，我们指定了一个8.4的关系，因为这是五公里跑和马拉松42.2公里距离（略超过26英里）的大致比例。
- en: '[PRE52]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '*[PRE53]*  *We can use our simulation to put in place various tests that we
    would want the actual data to satisfy. For instance, we want the class of the
    five kilometer and marathon run times to be numeric. And we want 200 observations.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE53]*  *我们可以使用我们的模拟来实施各种测试，我们希望实际数据能够满足这些测试。例如，我们希望5公里和马拉松跑步时间的类别是数值型的。并且我们希望有200个观测值。'
- en: '[PRE54]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '*We know that any value that is less than 15 minutes or more than 30 minutes
    for the five-kilometer run time is likely something that needs to be followed
    up on.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，对于五公里跑步时间，任何少于15分钟或超过30分钟的价值都可能是需要跟进的事情。
- en: '[PRE55]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '*Based on this maximum and the simulated relationship of 8.4, we would be surprised
    if we found any marathon times that were substantially over \(30\times8.4=252\)
    minutes, after we allow for a little bit of drift, say 300 minutes. (To be clear,
    there is nothing wrong with taking longer than this to run a marathon, but it
    is just unlikely based on our simulation parameters). And we would be surprised
    if the world record marathon time, 121 minutes as at the start of 2023, were improved
    by anything more than a minute or two, say, anything faster than 118 minutes.
    (It will turn out that our simulated data do not satisfy this and result in a
    implausibly fast 88 minute marathon time, which suggests a need to improve the
    simulation.)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此最大值和模拟的8.4倍关系，如果我们发现任何马拉松时间显著超过\(30\times8.4=252\)分钟，即在考虑到一点漂移，比如300分钟之后，我们会感到惊讶。（为了明确，跑马拉松用时超过这个时间并没有什么不妥，但根据我们的模拟参数来看，这种情况不太可能）。而且，如果截至2023年开始的世界纪录马拉松时间，121分钟，能比一分钟或两分钟更快，比如说，比118分钟更快，我们也会感到惊讶。（结果将表明，我们的模拟数据并不满足这一条件，导致了一个不切实际的88分钟马拉松时间，这表明需要改进模拟。）
- en: '[PRE56]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '*We can then take these tests to real data. Actual survey data on the relationship
    between five kilometer and marathon run times are available from Vickers and Vertosick
    ([2016](99-references.html#ref-Vickers2016)). After downloading the data, which
    Vickers and Vertosick ([2016](99-references.html#ref-Vickers2016)) make available
    as an “Additional file”, we can focus on the variables of interest and only individuals
    with both a five-kilometer time and a marathon time.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '*然后我们可以将这些测试应用于实际数据。关于五公里跑和马拉松跑时间之间关系的实际调查数据，可以从Vickers和Vertosick（[2016](99-references.html#ref-Vickers2016)）处获得）。下载这些数据后，Vickers和Vertosick（[2016](99-references.html#ref-Vickers2016)）将其作为“附加文件”提供，我们可以专注于感兴趣的变量，并且只关注那些既有五公里跑时间又有马拉松跑时间的个体。'
- en: '[PRE57]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '*[PRE58]'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE58]'
- en: The first thing that we notice is that our data are in seconds, whereas we were
    expecting them to be in minutes. This is fine. Our simulation and tests can update,
    or we can adjust our data. Our simulation and tests retain their value even when
    the data turn out to be slightly different, which they inevitably will.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先注意到的是，我们的数据是以秒为单位的，而我们都期待它们是以分钟为单位的。这没问题。我们的模拟和测试可以更新，或者我们可以调整我们的数据。即使数据最终略有不同，这是不可避免的，我们的模拟和测试仍然保持着它们的价值。
- en: In this case, we will divide by sixty, and round, to shift our data into minutes.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将除以六十并四舍五入，以便将我们的数据转换为分钟。
- en: '[PRE59]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '*[PRE60]*  *[PRE61]'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE60]*  *[PRE61]'
- en: '*In this case, our tests, which were written for the simulated data, identify
    that we have five kilometer run times that are faster that 15 minutes and longer
    than 30 minutes. They also identify marathon times that are longer than 300 minutes.
    If we were actually using this data for analysis, then our next step would be
    to plot the data, taking care to examine each of these points that our tests identified,
    and then either adjust the tests or the dataset.*******  ***## 9.5 Names'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这种情况下，我们为模拟数据编写的测试表明，我们有五公里的跑步时间，其速度超过15分钟且超过30分钟。它们还确定了马拉松时间超过300分钟。如果我们实际上使用这些数据进行分析，那么我们的下一步将是绘制数据图表，注意检查我们测试中确定的每一个这些点，然后调整测试或数据集。*******  ***##
    9.5 名称'
- en: An improved scanning software we developed identified gene name errors in 30.9%
    (3,436/11,117) of articles with supplementary Excel gene lists; a figure significantly
    higher than previously estimated. This is due to gene names being converted not
    just to dates and floating-point numbers, but also to internal date format (five-digit
    numbers).
  id: totrans-272
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们开发的一种改进型扫描软件在带有补充Excel基因列表的30.9%（3,436/11,117）篇文章中识别出了基因名称错误；这个比例显著高于之前的估计。这是因为基因名称不仅被转换成了日期和浮点数，还被转换成了内部日期格式（五位数字）。
- en: ''
  id: totrans-273
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Abeysooriya et al. ([2021](99-references.html#ref-omggenes))
  id: totrans-274
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Abeysooriya等人([2021](99-references.html#ref-omggenes))
- en: Names matter. The land on which much of this book was written is today named
    Canada, but for a long time was known as Turtle Island. Similarly, there is a
    big rock in the center of Australia. For a long time, it was called Uluru, then
    it was known as Ayers Rock. Today it has a dual name that combines both. And in
    parts of the US South, including signage surrounding the South Carolina State
    House, the US Civil War is referred to as the War of Northern Aggression. In these
    examples, the name that is used conveys information, not only about the user,
    but about the circumstances. Even the British Royal Family recognizes the power
    of names. In 1917 they changed from the House of Saxe-Coburg and Gotha to the
    House of Windsor. It was felt that the former was too Germanic given World War
    I. Names matter in everyday life. And they matter in our code, too.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 名字很重要。这本书的大部分内容是在今天被称为加拿大的土地上写成的，但长期以来被称为海龟岛。同样，在澳大利亚的中心有一个大岩石。长期以来，它被称为乌卢鲁，后来被称为艾尔斯岩。今天，它有一个结合两者的双重名字。在美国南部的部分地区，包括围绕南卡罗来纳州州议会的标志，美国内战被称为北方侵略战争。在这些例子中，使用的名字不仅传达了关于用户的信息，还传达了关于情况的信息。甚至英国王室也认识到名字的力量。1917年，他们从萨克斯-科堡-哥达家族改名为温莎家族。人们觉得，鉴于第一次世界大战，前者太德国化了。名字在日常生活中很重要。在我们的代码中也是如此。
- en: 'When coding, names are critical and worthy of special attention because ([Hermans
    2021](99-references.html#ref-hermans2021programmer)):'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 当编码时，名称至关重要，值得特别注意，因为 ([Hermans 2021](99-references.html#ref-hermans2021programmer))：
- en: they help document our code as they are contained in the code;
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们帮助文档化我们的代码，因为它们包含在代码中；
- en: they make up a large proportion of any script;
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们构成了任何剧本的大部分；
- en: they are referred to a lot by others; and
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们经常被其他人提到；并且
- en: they help the reader understand what is happening in the code.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们帮助读者理解代码中正在发生的事情。
- en: 'In addition to respecting the nature of the data, names need to satisfy two
    additional considerations:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 除了尊重数据本身的性质，名称还需要满足两个额外的考虑因素：
- en: they need to be machine readable, and
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们需要是机器可读的，并且
- en: they need to be human readable.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们需要是可读的。
- en: 9.5.1 Machine-readable
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 可机器读取
- en: Ensuring machine-readable names can be an easier standard to meet. It usually
    means avoiding spaces and special characters. A space can be replaced with an
    underscore. For instance, we prefer “my_data” to “my data”. Avoiding spaces enables
    tab-completion which makes us more efficient. It also helps with reproducibility
    because spaces are considered differently by different operating systems.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 确保名称机器可读可以是一个更容易达到的标准。这通常意味着避免使用空格和特殊字符。空格可以用下划线替换。例如，我们更喜欢“my_data”而不是“my data”。避免使用空格可以启用自动补全，这使我们更有效率。同时，它也有助于可重复性，因为不同的操作系统对空格的处理方式不同。
- en: Usually, special characters should be removed because they can be inconsistent
    between different computers and languages. This is especially the case with slash,
    backslash, asterisk, and both single, and double quotation marks. Try to avoid
    using those in names.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，应该删除特殊字符，因为它们在不同计算机和语言之间可能不一致。这种情况尤其适用于斜杠、反斜杠、星号以及单引号和双引号。尽量在名称中避免使用这些字符。
- en: Names should also be unique within a dataset, and unique within a collection
    of datasets unless that particular variable is being deliberately used as a key
    to join different datasets. This usually means that the domain is critical for
    effective names, and when working as part of a team this all gets much more difficult
    ([Hermans 2017](99-references.html#ref-hermans2017peter)). Names need to not only
    be unique, but notably different when there is a potential for confusion. For
    instance, for many years, the language PHP had both `mysql_escape_string` and
    `mysql_real_escape_string` ([Somers 2015](99-references.html#ref-somers2015)).
    It is easy to see how programmers may have accidentally written one when they
    meant the other.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 名称还应在数据集内部保持唯一，在数据集集合中也应保持唯一，除非该特定变量被故意用作连接不同数据集的关键。这通常意味着域对于有效的名称至关重要，当作为团队的一部分工作时，这一切都会变得更加困难
    ([Hermans 2017](99-references.html#ref-hermans2017peter))。名称不仅需要唯一，而且在可能产生混淆的情况下，还需要显著不同。例如，多年来，PHP
    语言中既有 `mysql_escape_string` 和 `mysql_real_escape_string` ([Somers 2015](99-references.html#ref-somers2015))。很容易看出，程序员在意图使用另一个函数时可能会不小心写错其中一个。
- en: An especially useful function to use to get closer to machine-readable names
    is `clean_names()` from `janitor`. This deals with those issues mentioned above
    as well as a few others.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别有用的函数，用于获取更接近机器可读名称的是来自`janitor`的`clean_names()`。这个函数处理了上述提到的问题以及一些其他问题。
- en: '[PRE62]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '*[PRE63]'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE63]'
- en: '[PRE64]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '*[PRE65]**  **### 9.5.2 Human-readable'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE65]**  **### 9.5.2 可读性'
- en: Programs must be written for people to read, and only incidentally for machines
    to execute
  id: totrans-293
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 程序必须为人们阅读而编写，而只是偶然地为了机器执行
- en: ''
  id: totrans-294
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Abelson and Sussman ([1996](99-references.html#ref-abelson1996structure))
  id: totrans-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Abelson 和 Sussman ([1996](99-references.html#ref-abelson1996structure))
- en: In the same way that we emphasized in [Chapter 4](04-writing_research.html)
    that we write papers for the reader, here we emphasize that we write code for
    the reader. Human-readable names require an additional layer, and extensive consideration.
    Following Lockheed Martin ([2005, 25](99-references.html#ref-jsfcodingstandards)),
    we should avoid names that only differ by the use of the letter “O”, instead of
    the number “0” or the letter “D”. Similarly, “S” with “5”.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在[第4章](04-writing_research.html)中强调的那样，我们写论文是为了读者，这里我们再次强调，我们写代码也是为了读者。可读性强的名字需要额外的层次和广泛的考虑。遵循洛克希德·马丁公司([2005,
    25](99-references.html#ref-jsfcodingstandards))的建议，我们应该避免使用仅通过字母“O”代替数字“0”或字母“D”来区分的名字。同样，“S”与“5”也是如此。
- en: We should consider other cultures and how they may interpret some of the names
    that we use. We also need to consider different experience levels that subsequent
    users of the dataset may have. This is both in terms of experience with data science,
    but also experience with similar datasets. For instance, a variable called “flag”
    is often used to signal that a variable contains data that needs to be followed
    up with or treated carefully in some way. An experienced analyst will know this,
    but a beginner will not. Try to use meaningful names wherever possible ([Lin,
    Ali, and Wilson 2021](99-references.html#ref-lin2020ten)). It has been found that
    shorter names may take longer to comprehend ([Hofmeister, Siegmund, and Holt 2017](99-references.html#ref-shorternamestakelonger)),
    and so it is often useful to avoid uncommon abbreviations where possible.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该考虑其他文化以及它们可能对我们使用的某些名称的解释。我们还需要考虑数据集后续使用者可能具有的不同经验水平。这既包括数据科学方面的经验，也包括与类似数据集相关的经验。例如，一个名为“flag”的变量通常用于表示该变量包含需要跟进或以某种方式小心处理的数据。经验丰富的分析师会知道这一点，但初学者可能不知道。尽可能使用有意义的名称（[林、阿里和威尔逊
    2021](99-references.html#ref-lin2020ten)）。研究发现，较短的名称可能需要更长的时间来理解（[霍夫迈斯特、西格蒙德和霍尔特
    2017](99-references.html#ref-shorternamestakelonger)），因此尽可能避免使用不常见的缩写通常是很有用的。
- en: Bryan ([2015](99-references.html#ref-jennybryanonnames)) recommends that file
    names, in particular, should consider the default ordering that a file manager
    will impose. This might mean adding prefixes such as “00-”, “01-”, etc to filenames
    (which might involve left-padding with zeros depending on the number of files).
    Critically it means using ISO 8601 for dates. That was introduced earlier and
    means that 2 December 2022 would be written “2022-12-02”. The reason for using
    such file names is to provide information to other people about the order of the
    files.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 布赖恩([2015](99-references.html#ref-jennybryanonnames))建议，特别是文件名，应考虑文件管理器将施加的默认排序。这可能意味着在文件名前添加前缀，如“00-”、“01-”等（这可能会根据文件数量进行左填充）。关键在于使用ISO
    8601日期格式。这在前文已介绍，意味着2022年12月2日将写作“2022-12-02”。使用此类文件名的目的是为其他人提供关于文件顺序的信息。
- en: 'One interesting feature of R is that in certain cases partial matching on names
    is possible. For instance:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: R语言的一个有趣特性是，在某些情况下可以进行名称的部分匹配。例如：
- en: '[PRE66]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '*[PRE67]'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE67]'
- en: '[PRE68]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '*[PRE69]**  **This behavior is not possible within the `tidyverse` (for instance,
    if `data.frame` were replaced with `tibble` in the above code). Partial matching
    should rarely be used. It makes it more difficult to understand code after a break,
    and for others to come to it fresh.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE69]**  **这种行为在`tidyverse`中是不可能的（例如，如果在上面的代码中将`data.frame`替换为`tibble`）。部分匹配应很少使用。它使得在休息后理解代码变得更加困难，并且对于其他人来说，要全新地接触它也更加困难。'
- en: Variable names should have a consistent structure. For instance, imposing the
    naming pattern `verb_noun`, as in `read_csv()`, then having one function that
    was `noun_verb`, perhaps `csv_read()`, would be inconsistent. That inconsistency
    imposes a significant cost because it makes it more difficult to remember the
    name of the function.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 变量名应该有一个一致的格式。例如，强制执行命名模式 `verb_noun`，如 `read_csv()`，然后有一个函数是 `noun_verb`，可能
    `csv_read()`，这将是不一致的。这种不一致性会带来显著的成本，因为它使得记住函数的名称变得更加困难。
- en: R, Python, and many of the other languages that are commonly used for data science
    are dynamically typed, as opposed to static typed. This means that class can be
    defined independently of declaring a variable. One interesting area of data science
    research is going partially toward static typed and understanding what that might
    mean. For instance, Python [enabled](https://peps.python.org/pep-0484/) type hints
    in 2014 ([Boykis 2019](99-references.html#ref-boykistypehints)). While not required,
    this goes someway to being more explicit about types.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: R、Python以及许多其他常用于数据科学的语言都是动态类型，与静态类型相反。这意味着可以在不声明变量的情况下独立定义类。数据科学研究的有趣领域之一是部分转向静态类型，并理解这可能意味着什么。例如，Python在2014年[启用](https://peps.python.org/pep-0484/)了类型提示（[Boykis
    2019](99-references.html#ref-boykistypehints)）。虽然这不是必需的，但这在某种程度上使得类型更加明确。
- en: Riederer ([2020](99-references.html#ref-columnnamesascontracts)) advises using
    variable names as contracts. We do this by establishing a controlled vocabulary
    for them. In this way, we would define a set of words that we can use in names.
    In the controlled vocabulary of Riederer ([2020](99-references.html#ref-columnnamesascontracts))
    a variable could start with an abbreviation for its class, then something specific
    to what it pertains to, and then various details.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: Riederer ([2020](99-references.html#ref-columnnamesascontracts)) 建议使用变量名作为契约。我们通过为它们建立一个受控词汇表来实现这一点。这样，我们就可以定义一组可以在名称中使用的单词。在
    Riederer ([2020](99-references.html#ref-columnnamesascontracts)) 的受控词汇表中，一个变量可以以其类别的缩写开头，然后是与其相关的一些特定内容，最后是各种细节。
- en: For instance, we could consider column names of “age” and “sex”. Following Riederer
    ([2020](99-references.html#ref-columnnamesascontracts)) we may change these to
    be more informative of the class and other information. This issue is not settled,
    and there is not yet best practice. For instance, there are arguments against
    this in terms of readability.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以考虑“年龄”和“性别”这样的列名。遵循Riederer（[2020](99-references.html#ref-columnnamesascontracts)）的做法，我们可能将这些列名改为更能反映类别和其他信息的名称。这个问题尚未解决，也没有最佳实践。例如，有人反对这种做法，认为它会影响可读性。
- en: '[PRE70]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '*[PRE71]'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE71]'
- en: '[PRE72]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '*[PRE73]**  **Even just trying to be a little more explicit and consistent
    about names throughout a project typically brings substantial benefits when we
    come to revisit the project later. Would a rose by any other name smell as sweet?
    Of course. But we call it a rose—or even better *Rosa rubiginosa*—because that
    helps others know what we are talking about, compared with, say, “red_thing”,
    “five_petaled_smell_nice”, “flower”, or “r_1”. It is clearer, and helps others
    efficiently understand.******  ***## 9.6 1996 Tanzanian DHS'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE73]**  **甚至只是在项目中进行一点更明确和一致的命名通常在我们稍后回顾项目时能带来实质性的好处。玫瑰换个名字还会香吗？当然会。但我们称之为玫瑰——或者更好的是
    *Rosa rubiginosa*——因为这样有助于他人了解我们在谈论什么，与“红色东西”、“五瓣香花”、“花”或“r_1”相比。这更清晰，有助于他人高效理解。******  ***##
    9.6 1996 坦桑尼亚DHS'
- en: 'We will now go through the first of two examples. The Demographic and Health
    Surveys (DHS) play an important role in gathering data in areas where we may not
    have other datasets. Here we will clean and prepare a DHS table about household
    populations in Tanzania in 1996\. As a reminder, the workflow that we advocate
    in this book is:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将讨论两个例子中的第一个。人口与健康调查（DHS）在我们可能没有其他数据集的地区收集数据时发挥着重要作用。在这里，我们将清洗并准备一个关于1996年坦桑尼亚家庭人口的DHS表格。作为提醒，本书中我们倡导的工作流程是：
- en: \[ \mbox{Plan}\rightarrow\mbox{Simulate}\rightarrow\mbox{Acquire}\rightarrow\mbox{Explore}\rightarrow\mbox{Share}
    \]
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 计划\rightarrow 模拟\rightarrow 获取\rightarrow 探索\rightarrow 分享 \]
- en: We are interested in the distribution of age-groups, gender, and urban/rural.
    A quick sketch might look like [Figure 9.6](#fig-tanzaniasketch).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对年龄组、性别以及城市/农村的分布情况感兴趣。一个快速草图可能看起来像[图9.6](#fig-tanzaniasketch)。
- en: '![](../Images/1eb32209a83d034c9065a9f1174d9748.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1eb32209a83d034c9065a9f1174d9748.png)'
- en: 'Figure 9.6: Quick sketch of a dataset that we might be interested in'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6：我们可能感兴趣的数据库的快速草图
- en: We can then simulate a dataset.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以随后模拟一个数据集。
- en: '[PRE74]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '*[PRE75]*  *Based on this simulation we are interested to test:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE75]*  *基于这次模拟，我们感兴趣的是测试以下内容：'
- en: Whether there are only numbers.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否只有数字。
- en: Whether the sum of urban and rural match the total column.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 城乡总和是否与总列匹配。
- en: Whether the sum of the age-groups match the total.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否年龄组的总和与总数相符。
- en: We begin by downloading the data.[³](#fn3)
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先开始下载数据。[³](#fn3)
- en: '[PRE76]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '*When we have a PDF and want to read the content into R, then `pdf_text()`
    from `pdftools` is useful, as introduced in [Chapter 7](07-gather.html). It works
    well for many recently produced PDFs because the content is text which it can
    extract. But if the PDF is an image, then `pdf_text()` will not work. Instead,
    the PDF will first need to go through OCR, which was also introduced in [Chapter
    7](07-gather.html).'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '*当我们有一个PDF文件并希望将其内容读入R时，`pdftools`中的`pdf_text()`函数很有用，如[第7章](07-gather.html)中所述。它对许多近期生成的PDF文件效果良好，因为这些文件的内容是文本，它可以提取。但如果PDF是一个图像，那么`pdf_text()`将不起作用。相反，PDF首先需要通过OCR处理，这也在[第7章](07-gather.html)中介绍过。*'
- en: '[PRE77]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '*In this case we are interested in Table 2.1, which is on the 33rd page of
    the PDF ([Figure 9.7](#fig-tanzanian-dhs)).'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这种情况下，我们关注的是表2.1，它位于PDF的第33页([图9.7](#fig-tanzanian-dhs)))。'
- en: '![](../Images/2affbc72f28af9c9b7ec9edd5176807b.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2affbc72f28af9c9b7ec9edd5176807b.png)'
- en: 'Figure 9.7: The page of interest in the 1996 Tanzanian DHS'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7：1996年坦桑尼亚DHS调查中感兴趣的页面
- en: We use `stri_split_lines()` from `stringi` to focus on that particular page.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `stri_split_lines()` 函数从 `stringi` 库中，来专注于那一特定页面。
- en: '[PRE78]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '*We first want to remove all the written content and focus on the table. We
    then want to convert that into a tibble so that we can use our familiar `tidyverse`
    approaches.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先希望移除所有文字内容，专注于表格。然后我们希望将其转换为tibble格式，以便我们可以使用我们熟悉的`tidyverse`方法。
- en: '[PRE79]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '*[PRE80]*  *All the columns have been collapsed into one, so we need to separate
    them. We will do this based on the existence of a space, which means we first
    need to change “Age group” to “Age-group” because we do not want that separated.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE80]*  *所有列都已经被合并成了一列，因此我们需要将它们分开。我们将根据空格的存在来操作，这意味着我们首先需要将“Age group”改为“Age-group”，因为我们不希望它们被分开。*'
- en: '[PRE81]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '*[PRE82]*  *Now we need to clean the rows and columns. One helpful “negative
    space” approach to work out what we need to remove, is to look at what is left
    if we temporarily remove everything that we know we want. Whatever is left is
    then a candidate for being removed. In this case we know that we want the columns
    to contain numbers, so we remove numeric digits from all columns to see what might
    stand in our way of converting from string to numeric.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE82]*  *我们现在需要清理行和列。一种有助于确定需要移除内容的“负空间”方法是，看看如果我们暂时移除所有已知想要保留的内容后剩下什么。剩下的任何内容都将成为移除的候选对象。在这种情况下，我们知道我们希望列中包含数字，因此我们从所有列中移除数字，以查看这可能会阻碍我们从字符串转换为数字的障碍。'
- en: '[PRE83]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '*[PRE84]*  *In this case we can see that some commas and semicolons have been
    incorrectly considered decimal places. Also, some tildes and blank lines need
    to be removed. After that we can impose the correct class.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE84]*  *在这种情况下，我们可以看到一些逗号和分号被错误地认为是小数点。此外，一些波浪线和空白行需要被移除。之后，我们就可以应用正确的类别了。'
- en: '[PRE85]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '*[PRE86]*  *Finally, we may wish to check that the sum of the constituent parts
    equals the total.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE86]*  *最后，我们可能希望检查构成部分的总和是否等于总数。'
- en: '[PRE87]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '*[PRE88]*  *In this case we can see that it is a few tenths of a percentage
    point off.*********  ***## 9.7 2019 Kenyan census'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE88]*  *在这种情况下，我们可以看到它偏离了几个百分点。*********  ***## 9.7 2019 肯尼亚人口普查'
- en: As a final example, let us consider a more extensive situation and gather, clean,
    and prepare some data from the 2019 Kenyan census. We will focus on creating a
    dataset of single-year counts, by gender, for Nairobi.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的例子，让我们考虑一个更广泛的情况，并从2019年肯尼亚人口普查中收集、清理和准备一些数据。我们将专注于创建一个按性别划分的单年计数数据集，针对内罗毕。
- en: The distribution of population by age, sex, and administrative unit from the
    2019 Kenyan census can be downloaded [here](https://www.knbs.or.ke/?wpdmpro=2019-kenya-population-and-housing-census-volume-iii-distribution-of-population-by-age-sex-and-administrative-units).
    While this format as a PDF makes it easy to look up a particular result, it is
    not overly useful if we want to model the data. In order to be able to do that,
    we need to convert this PDF into a tidy dataset that can be analyzed.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 2019年肯尼亚人口普查按年龄、性别和行政单位分布的数据可以在此处下载[这里](https://www.knbs.or.ke/?wpdmpro=2019-kenya-population-and-housing-census-volume-iii-distribution-of-population-by-age-sex-and-administrative-units)。虽然这种格式作为PDF文件便于查找特定结果，但如果我们要建模数据，它就不是很实用了。为了能够做到这一点，我们需要将这个PDF文件转换成一个整洁的数据集，以便进行分析。
- en: 9.7.1 Gather and clean
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.7.1 收集和清理
- en: We first need to download and read in the PDF of the 2019 Kenyan census.[⁴](#fn4)
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要下载并阅读2019年肯尼亚人口普查的PDF文件。[⁴](#fn4)
- en: '[PRE89]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '*We can use `pdf_text()` from `pdftools` again here.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以再次在这里使用来自 `pdftools` 的 `pdf_text()` 函数。'
- en: '[PRE90]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '*In this example we will focus on the page of the PDF about Nairobi ([Figure 9.8](#fig-examplekenyancensuspage)).'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这个例子中，我们将关注关于内罗毕的PDF页面([图9.8](#fig-examplekenyancensuspage))。'
- en: '![](../Images/77252391ad58947295e8f5fd9704ab90.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/77252391ad58947295e8f5fd9704ab90.png)'
- en: 'Figure 9.8: Page from the 2019 Kenyan census about Nairobi'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8：2019年肯尼亚人口普查关于内罗毕的页面
- en: 9.7.1.1 Make rectangular
  id: totrans-353
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.7.1.1 创建矩形
- en: The first challenge is to get the dataset into a format that we can more easily
    manipulate. We will extract the relevant parts of the page. In this case, data
    about Nairobi is on page 410.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 首个挑战是将数据集转换成我们更容易操作的形式。我们将提取页面中的相关部分。在这种情况下，关于内罗毕的数据位于第410页。
- en: '[PRE91]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '*At this point the data are in a tibble. This allows us to use our familiar
    `dplyr` verbs. In particular we want to separate the columns.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这一步，数据已经处于tibble格式。这使得我们可以使用我们熟悉的`dplyr`动词。特别是，我们想要分离列。*'
- en: '[PRE92]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '*They are side by side at the moment. We need to instead append to the bottom.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '*他们此刻并排在一起。我们需要改为添加到底部。'
- en: '[PRE93]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '*[PRE94]'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE94]'
- en: '*[PRE95]*  *Having got it into a rectangular format, we now need to clean the
    dataset to make it useful.****  ***#### 9.7.1.2 Validity'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE95]*  *将其整理成矩形格式后，我们现在需要清理数据集以使其变得有用。****  ***#### 9.7.1.2 有效性'
- en: To attain validity requires a number of steps. The first step is to make the
    numbers into actual numbers, rather than characters. Before we can convert the
    type, we need to remove anything that is not a number otherwise that cell will
    be converted into an NA. We first identify any values that are not numbers so
    that we can remove them, and `distinct()` is especially useful.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得有效性需要多个步骤。第一步是将数字转换为实际的数字，而不是字符。在我们转换类型之前，我们需要移除任何非数字的内容，否则该单元格将被转换为NA。我们首先识别任何非数字的值，以便我们可以移除它们，而`distinct()`函数特别有用。
- en: '[PRE96]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '*[PRE97]*  *We need to remove commas. While we could use `janitor` here, it
    is worthwhile to at least first look at what is going on because sometimes there
    is odd stuff that `janitor` (and other packages) will not deal with in a way that
    we want. Nonetheless, having identified everything that needs to be removed, we
    can do the actual removal and convert our character column of numbers to integers.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE97]*  *我们需要删除逗号。虽然在这里我们可以使用`janitor`，但至少首先看看发生了什么是有价值的，因为有时会有一些奇怪的东西，`janitor`（以及其他包）不会以我们想要的方式处理。尽管如此，一旦确定了所有需要删除的内容，我们就可以进行实际的删除操作，并将我们的数字字符列转换为整数。'
- en: '[PRE98]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '*[PRE99]**  **#### 9.7.1.3 Internal consistency'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE99]**  **#### 9.7.1.3 内部一致性'
- en: 'The census has done some of the work of putting together age-groups for us,
    but we want to make it easy to just focus on the counts by single-year age. As
    such we will add a flag as to the type of age it is: an age-group, such as “ages
    0 to 5”, or a single age, such as “1”.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 人口普查已经为我们做了一些将年龄组组合起来的工作，但我们希望让它变得容易，只需关注按单一年龄的计数。因此，我们将添加一个标志来表示年龄的类型：一个年龄组，例如“0至5岁”，或者一个单一年龄，例如“1岁”。
- en: '[PRE100]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '*At the moment, age is a character variable. We have a decision to make here.
    We do not want it to be a character variable (because it will not graph properly),
    but we do not want it to be numeric, because there is `total` and `100+` in there.
    For now, we will just make it into a factor, and at least that will be able to
    be nicely graphed.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '*目前，年龄是一个字符变量。我们在这里有一个决定要做。我们不想让它成为一个字符变量（因为它无法正确绘图），但我们也不希望它是数字的，因为其中包含了`total`和`100+`。目前，我们将其转换为因子，至少这样它能够被很好地绘制。*'
- en: '[PRE101]********  ***### 9.7.2 Check and test'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE101]********  ***### 9.7.2 检查和测试'
- en: Having gathered and cleaned the data, we would like to run a few checks. Given
    the format of the data, we can check that “total” is the sum of “male” and “female”,
    which are the only two gender categories available.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 收集并清理完数据后，我们希望运行一些检查。鉴于数据的格式，我们可以检查“总数”是否是“男性”和“女性”的总和，这两个是唯一可用的性别类别。
- en: '[PRE102]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '*[PRE103]*  *Finally, we want to check that the single-age counts sum to the
    age-groups.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE103]*  *最后，我们想要检查单年龄段的计数总和是否等于年龄段的总和。'
- en: '[PRE104]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '*[PRE105]**  **### 9.7.3 Tidy-up'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE105]**  **### 9.7.3 整理'
- en: Now that we are reasonably confident that everything is looking good, we can
    convert it to tidy format. This will make it easier to work with.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有理由相信一切看起来都很顺利，我们可以将其转换为整洁的格式。这将使工作变得更加容易。
- en: '[PRE106]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '*The original purpose of cleaning this dataset was to make a table that is
    used by Alexander and Alkema ([2022](99-references.html#ref-alexander2021bayesian)).
    We will return to this dataset, but just to bring this all together, we may like
    to make a graph of single-year counts, by gender, for Nairobi ([Figure 9.9](#fig-monicasnairobigraph)).'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '*清洗这个数据集的原始目的是制作一个由亚历山大和阿尔克玛([2022](99-references.html#ref-alexander2021bayesian))使用的表格。我们将回到这个数据集，但为了把这些内容都整合在一起，我们可能想要制作一个按性别划分的单年计数图，以展示内罗毕的情况([图9.9](#fig-monicasnairobigraph)))。'
- en: '[PRE107]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '*![](../Images/e7b328c14ad08fbc5f8d85b215c51993.png)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/e7b328c14ad08fbc5f8d85b215c51993.png)*'
- en: 'Figure 9.9: Distribution of age and gender in Nairobi in 2019, based on Kenyan
    census*  *A variety of features are clear from [Figure 9.9](#fig-monicasnairobigraph),
    including age-heaping, a slight difference in the ratio of male-female birth,
    and a substantial difference between ages 15 and 25.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9：2019年内罗毕年龄和性别的分布，基于肯尼亚人口普查*  *从[图9.9](#fig-monicasnairobigraph)中可以清晰地看到多种特征，包括年龄集中、男女性出生比例的微小差异以及15至25岁之间的显著差异。
- en: 'Finally, we may wish to use more informative names. For instance, in the Kenyan
    data example earlier we have the following column names: “area”, “age”, “gender”,
    and “number”. If we were to use our column names as contracts, then these could
    be: “chr_area”, “fctr_group_age”, “chr_group_gender”, and “int_group_count”.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可能希望使用更具信息量的名称。例如，在之前提到的肯尼亚数据示例中，我们有以下列名：“area”（面积）、“age”（年龄）、“gender”（性别）和“number”（数量）。如果我们把列名当作合约，那么它们可以是：“chr_area”（染色体面积）、“fctr_group_age”（因素分组年龄）、“chr_group_gender”（染色体分组性别）和“int_group_count”（整数分组计数）。
- en: '[PRE108]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '*We can then use `pointblank` to set-up tests for us.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以使用 `pointblank` 来为我们设置测试。'
- en: '[PRE109]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '*| Pointblank Validation |'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '*| 点对点验证 |'
- en: '| --- |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| [2024-11-21&#124;09:51:24]tibble column_names_as_contracts |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| [2024-11-21&#124;09:51:24]tibble 列名_as_contracts |'
- en: '| --- |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
- en: '|  |  | STEP | COLUMNS | VALUES | TBL | EVAL | UNITS | PASS | FAIL | W | S
    | N | EXT |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 步骤 | 列 | 值 | 表格 | 评估 | 单位 | 通过 | 失败 | W | S | N | 扩展 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
- en: '|   | 1 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_character</title></svg>` col_is_character()`
    |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '|   | 1 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_character</title></svg>` col_is_character()`
    |'
- en: '`▮``chr_group_gender`'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '`▮``chr_group_gender`'
- en: '| — |  | ✓ | `1` | `1` `1` | `0` `0` | — | — | — | — |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
- en: '|   | 2 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_factor</title></svg>` col_is_factor()`
    |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '|   | 2 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_factor</title></svg>` col_is_factor()`
    |'
- en: '`▮``fctr_group_age`'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '`▮``fctr_group_age`'
- en: '| — |  | ✓ | `1` | `1` `1` | `0` `0` | — | — | — | — |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
- en: '|   | 3 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_integer</title></svg>` col_is_integer()`
    |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '|   | 3 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_is_integer</title></svg>` col_is_integer()`
    |'
- en: '`▮``int_group_count`'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`▮``int_group_count`'
- en: '| — |  | ✓ | `1` | `1` `1` | `0` `0` | — | — | — | — |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
- en: '|   | 4 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_vals_in_set</title></svg>` col_vals_in_set()`
    |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '|   | 4 | <svg width="30px" height="30px" viewBox="0 0 67 67" version="1.1"
    xlink="http://www.w3.org/1999/xlink"><title>col_vals_in_set</title></svg>` col_vals_in_set()`
    |'
- en: '`▮``chr_group_gender`'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '`▮``chr_group_gender`'
- en: '|'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`male, female, total`'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '`男性, 女性, 总计`'
- en: '|  | ✓ | `306` | `306` `1` | `0` `0` | — | — | — | — |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '|  | ✓ | `306` | `306` `1` | `0` `0` | — | — | — | — |'
- en: '| 2024-11-21 09:51:24 EST < 1 s 2024-11-21 09:51:24 EST |*********  ***## 9.8
    Exercises'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '| 2024-11-21 09:51:24 EST < 1 s 2024-11-21 09:51:24 EST |*********  ***## 9.8
    练习'
- en: Practice
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: '*(Plan)* Consider the following scenario: *You manage a shop with two employees
    and are interested in modeling their efficiency. The shop opens at 9am and closes
    at 5pm. The efficiency of the employees is mildly correlated and defined by the
    number of customers that they serve each hour. Be clear about whether you assume
    a negative or positive correlation.* Please sketch what that dataset could look
    like and then sketch a graph that you could build to show all observations.'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(计划)* 考虑以下场景：*你管理着一家拥有两名员工的商店，并且对他们的效率建模感兴趣。商店上午9点开门，下午5点关门。员工的效率与每小时接待的客户数量呈轻度相关，并以此定义。请明确你假设的是负相关还是正相关。*
    请绘制出该数据集可能的样子，然后绘制一个图表来展示所有观察结果。'
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation. Please include five tests based on the simulated data. Submit a link
    to a GitHub Gist that contains your code.'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(模拟)* 请进一步考虑所描述的场景并模拟该情况。请基于模拟数据包括五个测试。提交一个包含您代码的GitHub Gist链接。'
- en: '*(Acquire)* Please describe a possible source of such a dataset.'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(获取)* 请描述这样一个数据集的可能来源。'
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched using
    the simulated data from step 1\. Submit a link to a GitHub Gist that contains
    your code.'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(探索)* 请使用 `ggplot2` 根据第1步中使用的模拟数据绘制你草图中的图形。提交一个包含你代码的GitHub Gist链接。'
- en: '*(Communicate)* Please write two paragraphs about what you did.'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(沟通)* 请写两段关于你所做的事情的描述。'
- en: Quiz
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测验
- en: If we had a character variable “some_words” with one observation `"You know
    what"` within a dataset called `sayings`, then which of the following would split
    it into its constituent words (pick one)?
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有一个名为“some_words”的字符变量，在名为`sayings`的数据集中有一个观察值`"You know what"`，那么以下哪个选项可以将它拆分成其构成单词（选择一个）？
- en: '`separate(data = sayings, col = some_words, into = c("one", "two", "three"),
    sep = " ")`'
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`将(data = sayings, col = some_words, into = c("one", "two", "three"), sep =
    " ")`'
- en: '`split(data = sayings, col = some_words, into = c("one", "two", "three"), sep
    = " ")`'
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`split(data = sayings, col = some_words, into = c("one", "two", "three"), sep
    = " ")`'
- en: '`divide(data = sayings, col = some_words, into = c("one", "two", "three"),
    sep = " ")`'
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`divide(data = sayings, col = some_words, into = c("one", "two", "three"),
    sep = " ")`'
- en: '`part(data = sayings, col = some_words, into = c("one", "two", "three"), sep
    = " ")`'
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`part(data = sayings, col = some_words, into = c("one", "two", "three"), sep
    = " ")`'
- en: '`unattach(data = sayings, col = some_words, into = c("one", "two", "three"),
    sep = " ")`'
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`unattach(data = sayings, col = some_words, into = c("one", "two", "three"),
    sep = " ")`'
- en: Is the following an example of tidy data?
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是否是整洁数据的示例？
- en: '[PRE110]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '*[PRE111]'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE111]'
- en: Which function would change “lemons” into “lemonade”?
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个函数可以将“lemons”转换为“lemonade”？
- en: '`str_replace(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
  id: totrans-424
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`str_replace(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
- en: '`chr_replace(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
  id: totrans-425
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`chr_replace(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
- en: '`str_change(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
  id: totrans-426
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`str_change(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
- en: '`chr_change(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
  id: totrans-427
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`chr_change(string = "lemons", pattern = "lemons", replacement = "lemonade")`'
- en: When dealing with ages, what are some desirable classes for the variable (select
    all that apply)?
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当处理年龄时，变量有哪些理想的类别（选择所有适用的选项）？
- en: integer
  id: totrans-429
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整数
- en: matrix
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 矩阵
- en: numeric
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数字
- en: 'Please consider the following cities in Germany: “Berlin”, “Hamburg”, “Munich”,
    “Cologne”, “Frankfurt”, and “Rostock”. Use `testthat` to define three tests that
    could apply if we had a dataset with a variable “german_cities” that claimed to
    contain these, and only these, cities. Submit a link to a GitHub Gist.'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请考虑以下德国城市：“柏林”、“汉堡”、“慕尼黑”、“科隆”、“法兰克福”和“罗斯托克”。使用 `testthat` 定义三个测试，假设我们有一个包含变量“german_cities”的数据集，该数据集声称只包含这些城市。提交一个GitHub
    Gist链接。
- en: Which is the most acceptable format for dates in data science?
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学中日期的哪种格式是最可接受的？
- en: YYYY-DD-MM
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: YYYY-DD-MM
- en: YYYY-MM-DD
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: YYYY-MM-DD
- en: DD-MM-YYYY
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: DD-MM-YYYY
- en: MM-MM-YYYY
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: MM-MM-YYYY
- en: Which of the following likely does not belong? `c(15.9, 14.9, 16.6, 15.8, 16.7,
    17.9, I2.6, 11.5, 16.2, 19.5, 15.0)`
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪一项可能不属于其中？ `c(15.9, 14.9, 16.6, 15.8, 16.7, 17.9, I2.6, 11.5, 16.2, 19.5,
    15.0)`
- en: With regard to “AV Rule 48” from Lockheed Martin ([2005, 25](99-references.html#ref-jsfcodingstandards))
    which of the following are not allowed to differ identifiers (select all that
    apply)?
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于洛克希德·马丁的“AV Rule 48”([2005, 25](99-references.html#ref-jsfcodingstandards))，以下哪些不允许标识符不同（选择所有适用的选项）？
- en: Only a mixture of case
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有混合案例
- en: The presence/absence of the underscore character
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下划线字符的存在/不存在
- en: The interchange of the letter “O” with the number “0” or the letter “D”
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 字母“O”与数字“0”或字母“D”的互换
- en: The interchange of the letter “I” with the number “1” or the letter “l”
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 字母“I”与数字“1”或字母“l”的互换
- en: With regard to Preece ([1981](99-references.html#ref-Preece1981)) please discuss
    two ways in which final digits can be informative. Write at least a paragraph
    about each and include examples.*  *### Class activities
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于普雷斯的著作([1981](99-references.html#ref-Preece1981))，请讨论两种最终数字可以提供信息的方式。针对每种方式，至少写一段话并包含例子。*  *###
    课堂活动
- en: 'Pick a topic that you know well, then:'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个你非常熟悉的主题，然后：
- en: Reproducibly simulate an idealized dataset in an R script.
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 R 脚本中可重复地模拟一个理想化的数据集。
- en: Write five tests for it in a different R script.
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同的 R 脚本中为它编写五个测试。
- en: 'Give the code to create the dataset (not the tests) to someone else, via a
    GitHub Gist. Have them use code to deliberately create three different data issues
    in the dataset and then send it back to you (some ideas include: inconsistent
    date formatting, adding missing values, adding negative values, changing the decimal
    place)'
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将创建数据集（不是测试）的代码（通过GitHub Gist）交给其他人。让他们使用代码故意在数据集中创建三个不同的数据问题，然后将它发回给你（一些想法包括：不一致的日期格式，添加缺失值，添加负值，改变小数点位置）
- en: Do your tests identify the issues?
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的测试能否识别出问题？
- en: 'Discuss, with the help of simulation, the following claim: “This house believes
    that strings are better than factors”.[⁵](#fn5)'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模拟的帮助下讨论以下观点：“本议院认为弦比因子更好”。[⁵](#fn5)
- en: I obtain some data about income. Why would I be concerned if there were many
    respondents with income “999999”?
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我获取了一些关于收入的数据。为什么如果有很多受访者的收入为“999999”，我会感到担忧呢？
- en: 'Create a new R project and use an R script to download and load the original
    “Adélie penguin data” ([Palmer Station Antarctica LTER and Gorman, Kristen 2020](99-references.html#ref-penguinsoriginaldata)),
    (some code[⁶](#fn6) is included below to help with this) then:'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的 R 项目，并使用 R 脚本下载和加载原始的“阿德利企鹅数据”（[帕尔默站南极 LTER 和 Gorman, Kristen 2020](99-references.html#ref-penguinsoriginaldata))，（以下包含一些[⁶](#fn6)代码以帮助完成此操作），然后：
- en: Use `rename()` to improve the names.
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `rename()` 来改进名称。
- en: Add the folder to a GitHub repo.
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文件夹添加到 GitHub 仓库中。
- en: Exchange the repo with another student.
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与另一位学生交换仓库。
- en: Create a GitHub issue with two dot points about where the names could be improved.
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个GitHub问题，包含两个关于如何改进名称的要点。
- en: Discuss how your names compare with `palmerpenguins::penguins`.
  id: totrans-457
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论你的名字与`palmerpenguins::penguins`的比较
- en: '[PRE112]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '**   Produce a tidy version of Anscombe’s Quartet, available using `anscombe`.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '**   生成一个整洁版本的 Anscombe 四重奏，可以使用 `anscombe` 命令获取。'
- en: How does the US General Social Survey code “don’t know”?
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国综合社会调查（US General Social Survey）中的“不知道”代码是如何编码的？
- en: 'Discuss the advantages and disadvantages of each option for coding missing
    data:'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论编码缺失数据每个选项的优缺点：
- en: '[PRE113]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '**   How do you think missing data should be coded in a dataset?'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为在数据集中缺失数据应该如何编码？
- en: Using a new R project, for a city that you are interested in:[⁷](#fn7)
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个新的 R 项目，针对你感兴趣的城市：[⁷](#fn7)
- en: Write reproducible code to download a ShotSpotter dataset from [here](http://justicetechlab.org/shotspotter-data/)
    and clean up the dataset.
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写可复现的代码从[这里](http://justicetechlab.org/shotspotter-data/)下载 ShotSpotter 数据集并进行数据清洗。
- en: Add your code to GitHub.
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的代码添加到GitHub。
- en: Exchange your repo with someone else in the class. They are to make a pull request
    that uses your dataset to make a graph.
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与班上其他人交换你的代码库。他们需要提交一个使用你的数据集来生成图表的拉取请求。
- en: Get the ImageNet dataset and open ten random images. Apply your own label. To
    what extent does your label agree with the actual label? What are the effects
    of this on the outcomes of models trained on this dataset?
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取ImageNet数据集并打开十张随机图像。应用你自己的标签。你的标签与实际标签在多大程度上达成一致？这对在此数据集上训练的模型的结果有何影响？
- en: Imagine you are interested in understanding intergenerational wealth, and one
    aspect of this is linking the educational outcomes of people today with those
    of people one hundred years ago, and in different countries. Please make the dataset
    consistent, and document why you made the choices that you made.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想象一下你对理解代际财富感兴趣，其中一个方面是将今天人们的教育成果与一百年前的人们以及不同国家的人们联系起来。请确保数据集的一致性，并记录你做出这些选择的原因。
- en: '[PRE114]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '**   Make tidy data from `datasets::UCBAdmissions`.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '**   从 `datasets::UCBAdmissions` 中整理数据**'
- en: 'Using `datasets::LifeCycleSavings`:'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 `datasets::LifeCycleSavings`:'
- en: First use `pivot_longer()` to make it long.
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先使用 `pivot_longer()` 使其变长。
- en: Make a graph using `ggplot`.
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `ggplot` 制作图表。
- en: Then use `pivot_wider()` to change it back to wide.
  id: totrans-475
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后使用 `pivot_wider()` 将其转换回宽格式。
- en: Make a table using `tinytable::tt()` for Australia, Canada, New Zealand, and
    a country that you choose.
  id: totrans-476
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `tinytable::tt()` 为澳大利亚、加拿大、新西兰以及你选择的某个国家制作一个表格。
- en: 'Fix the following:'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复以下问题：
- en: '[PRE115]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '**   Fix the following:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '**   修复以下问题：'
- en: '[PRE116]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '**   Assume you live in Toronto, Canada. What is wrong with the following date?[⁸](#fn8)
    `2023-03-12 02:01:00`.'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '**   假设你住在加拿大多伦多。以下日期有什么问题？[⁸](#fn8) `2023-03-12 02:01:00`。'
- en: Following the example in [Chapter 16](15-mrp.html) read in a “.dta” file from
    the [US General Social Survey](https://gss.norc.org/Get-The-Data), add the labels,
    and build a graph of some variable. What happens to the missing data?*****  ***###
    Task
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照第[16章](15-mrp.html)中的示例，从[美国综合社会调查](https://gss.norc.org/Get-The-Data)读取一个“.dta”文件，添加标签，并绘制某个变量的图表。缺失数据会发生什么？*****  ***
- en: With regard to Jordan ([2019](99-references.html#ref-Jordan2019Artificial)),
    D’Ignazio and Klein ([2020, chap. 6](99-references.html#ref-datafeminism2020)),
    Au ([2020](99-references.html#ref-thatrandyauperson)), and other relevant work,
    to what extent do you think we should let the data speak for themselves? Please
    write at least two pages.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 关于乔丹([2019](99-references.html#ref-Jordan2019Artificial))、D’Ignazio和Klein([2020,
    第6章](99-references.html#ref-datafeminism2020))、Au([2020](99-references.html#ref-thatrandyauperson))以及其他相关研究，你认为我们应该让数据自己说话到什么程度？请至少写两页。
- en: Use Quarto, and include an appropriate title, author, date, link to a GitHub
    repo, and citations to produce a draft. After this, please pair with another student
    and exchange your written work. Update it based on their feedback, and be sure
    to acknowledge them by name in your paper. Submit a PDF.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Quarto，并包含一个合适的标题、作者、日期、指向GitHub仓库的链接以及引用来生成草稿。之后，请与另一位学生配对并交换你们的书面作品。根据他们的反馈进行更新，并确保在你们的论文中按名字提及他们。提交PDF文件。
- en: 'Abelson, Harold, and Gerald Jay Sussman. 1996\. *Structure and Interpretation
    of Computer Programs*. Cambridge: The MIT Press.Abeysooriya, Mandhri, Megan Soria,
    Mary Sravya Kasu, and Mark Ziemann. 2021\. “Gene Name Errors: Lessons Not Learned.”
    *PLOS Computational Biology* 17 (7): 1–13\. [https://doi.org/10.1371/journal.pcbi.1008984](https://doi.org/10.1371/journal.pcbi.1008984).Alexander,
    Monica, and Leontine Alkema. 2022\. “A Bayesian Cohort Component Projection Model
    to Estimate Women of Reproductive Age at the Subnational Level in Data-Sparse
    Settings.” *Demography* 59 (5): 1713–37\. [https://doi.org/10.1215/00703370-10216406](https://doi.org/10.1215/00703370-10216406).Arel-Bundock,
    Vincent. 2022\. “modelsummary: Data and Model Summaries in R.” *Journal of Statistical
    Software* 103 (1): 1–23\. [https://doi.org/10.18637/jss.v103.i01](https://doi.org/10.18637/jss.v103.i01).———.
    2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,” “Markdown,”
    “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Au,
    Randy. 2020\. “Data Cleaning IS Analysis, Not Grunt Work,” September. [https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt](https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt).Baker,
    Dominique. 2023\. “Scams Will Not Save Us (Tuition Dollars),” February. [http://www.dominiquebaker.com/blog/2023/2/16/scams-will-not-save-us-tuition-dollars](http://www.dominiquebaker.com/blog/2023/2/16/scams-will-not-save-us-tuition-dollars).Banes,
    Graham, Emily Fountain, Alyssa Karklus, Robert Fulton, Lucinda Antonacci-Fulton,
    and Joanne Nelson. 2022\. “Nine out of ten samples were mistakenly switched by
    The Orang-utan Genome Consortium.” *Scientific Data* 9 (1). [https://doi.org/10.1038/s41597-022-01602-0](https://doi.org/10.1038/s41597-022-01602-0).Baumgartner,
    Peter. 2021\. “Ways I Use Testing as a Data Scientist,” December. [https://www.peterbaumgartner.com/blog/testing-for-data-science/](https://www.peterbaumgartner.com/blog/testing-for-data-science/).Borer,
    Elizabeth T., Eric W. Seabloom, Matthew B. Jones, and Mark Schildhauer. 2009\.
    “Some Simple Guidelines for Effective Data Management.” *Bulletin of the Ecological
    Society of America* 90 (2): 205–14\. [https://doi.org/10.1890/0012-9623-90.2.205](https://doi.org/10.1890/0012-9623-90.2.205).Boykis,
    Vicki. 2019\. “A Deep Dive on Python Type Hints,” July. [https://vickiboykis.com/2019/07/08/a-deep-dive-on-python-type-hints/](https://vickiboykis.com/2019/07/08/a-deep-dive-on-python-type-hints/).Bryan,
    Jenny. 2015\. “Naming Things.” *Reproducible Science Workshop*, May. [https://speakerdeck.com/jennybc/how-to-name-files](https://speakerdeck.com/jennybc/how-to-name-files).Caro,
    Robert. 2019\. *Working*. 1st ed. New York: Knopf.Chan, Duo. 2021\. “Combining
    Statistical, Physical, and Historical Evidence to Improve Historical Sea-Surface
    Temperature Records.” *Harvard Data Science Review* 3 (1). [https://doi.org/10.1162/99608f92.edcee38f](https://doi.org/10.1162/99608f92.edcee38f).Craiu,
    Radu. 2019\. “The Hiring Gambit: In Search of the Twofer Data Scientist.” *Harvard
    Data Science Review* 1 (1). [https://doi.org/10.1162/99608f92.440445cb](https://doi.org/10.1162/99608f92.440445cb).D’Ignazio,
    Catherine, and Lauren Klein. 2020\. *Data Feminism*. Massachusetts: The MIT Press.
    [https://data-feminism.mitpress.mit.edu](https://data-feminism.mitpress.mit.edu).De
    Jonge, Edwin, and Mark van der Loo. 2013\. *An introduction to data cleaning with
    R*. Statistics Netherlands Heerlen. [https://cran.r-project.org/doc/contrib/de%5FJonge+van%5Fder%5FLoo-Introduction%5Fto%5Fdata%5Fcleaning%5Fwith%5FR.pdf](https://cran.r-project.org/doc/contrib/de%5FJonge+van%5Fder%5FLoo-Introduction%5Fto%5Fdata%5Fcleaning%5Fwith%5FR.pdf).Doggers,
    Peter. 2021\. “Carlsen Wins Game 6, Longest World Chess Championship Game of All
    Time,” December. [https://www.chess.com/news/view/fide-world-chess-championship-2021-game-6](https://www.chess.com/news/view/fide-world-chess-championship-2021-game-6).Du,
    Kai, Steven Huddart, and Xin Daniel Jiang. 2022\. “Lost in Standardization: Effects
    of Financial Statement Database Discrepancies on Inference.” *Journal of Accounting
    and Economics*, December, 101573\. [https://doi.org/10.1016/j.jacceco.2022.101573](https://doi.org/10.1016/j.jacceco.2022.101573).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gagolewski,
    Marek. 2022\. “stringi: Fast and Portable Character String Processing in R.” *Journal
    of Statistical Software* 103 (2): 1–59\. [https://doi.org/10.18637/jss.v103.i02](https://doi.org/10.18637/jss.v103.i02).Gao,
    Zheng, Christian Bird, and Earl T. Barr. 2017\. “To Type or Not to Type: Quantifying
    Detectable Bugs in JavaScript.” In *2017 IEEE/ACM 39th International Conference
    on Software Engineering (ICSE)*. IEEE. [https://doi.org/10.1109/icse.2017.75](https://doi.org/10.1109/icse.2017.75).Gelfand,
    Sharla. 2022\. *opendatatoronto: Access the City of Toronto Open Data Portal*.
    [https://CRAN.R-project.org/package=opendatatoronto](https://CRAN.R-project.org/package=opendatatoronto).Gelman,
    Andrew, and Eric Loken. 2013\. “The Garden of Forking Paths: Why Multiple Comparisons
    Can Be a Problem, Even When There Is No ‘Fishing Expedition’ or ‘p-Hacking’ and
    the Research Hypothesis Was Posited Ahead of Time.” *Department of Statistics,
    Columbia University*. [http://www.stat.columbia.edu/~gelman/research/unpublished/p%5Fhacking.pdf](http://www.stat.columbia.edu/~gelman/research/unpublished/p%5Fhacking.pdf).Gelman,
    Andrew, and Aki Vehtari. 2021\. “What Are the Most Important Statistical Ideas
    of the Past 50 Years?” *Journal of the American Statistical Association* 116 (536):
    2087–97\. [https://doi.org/10.1080/01621459.2021.1938081](https://doi.org/10.1080/01621459.2021.1938081).Grolemund,
    Garrett, and Hadley Wickham. 2011\. “Dates and Times Made Easy with lubridate.”
    *Journal of Statistical Software* 40 (3): 1–25\. [https://doi.org/10.18637/jss.v040.i03](https://doi.org/10.18637/jss.v040.i03).Halberstam,
    David. 1972\. *The Best and the Brightest*. 1st ed. New York: Random House.Hand,
    David. 2018\. “Statistical Challenges of Administrative and Transaction Data.”
    *Journal of the Royal Statistical Society: Series A (Statistics in Society)* 181
    (3): 555–605\. [https://doi.org/10.1111/rssa.12315](https://doi.org/10.1111/rssa.12315).Hermans,
    Felienne. 2017\. “Peter Hilton on Naming.” *IEEE Software* 34 (3): 117–20\. [https://doi.org/10.1109/MS.2017.81](https://doi.org/10.1109/MS.2017.81).———.
    2021\. *The Programmer’s Brain: What Every Programmer Needs to Know about Cognition*.
    1st ed. New York: Simon; Schuster. [https://www.manning.com/books/the-programmers-brain](https://www.manning.com/books/the-programmers-brain).Hodgetts,
    Paul. 2022\. “The Negative Space of Data,” March. [https://hodgettsp.netlify.app/post/data-negativespace/](https://hodgettsp.netlify.app/post/data-negativespace/).Hofmeister,
    Johannes, Janet Siegmund, and Daniel Holt. 2017\. “Shorter Identifier Names Take
    Longer to Comprehend.” In *2017 IEEE 24th International Conference on Software
    Analysis, Evolution and Reengineering (SANER)*, 217–27\. [https://doi.org/10.1109/saner.2017.7884623](https://doi.org/10.1109/saner.2017.7884623).Huntington-Klein,
    Nick, Andreu Arenas, Emily Beam, Marco Bertoni, Jeffrey Bloem, Pralhad Burli,
    Naibin Chen, et al. 2021\. “The Influence of Hidden Researcher Decisions in Applied
    Microeconomics.” *Economic Inquiry* 59: 944–60\. [https://doi.org/10.1111/ecin.12992](https://doi.org/10.1111/ecin.12992).Iannone,
    Richard, and Mauricio Vargas. 2022\. *pointblank: Data Validation and Organization
    of Metadata for Local and Remote Tables*. [https://CRAN.R-project.org/package=pointblank](https://CRAN.R-project.org/package=pointblank).Irving,
    Damien, Kate Hertweck, Luke Johnston, Joel Ostblom, Charlotte Wickham, and Greg
    Wilson. 2021\. *Research Software Engineering with Python*. Chapman; Hall/CRC.Jet
    Propulsion Laboratory. 2009\. “JPL Institutional Coding Standard for the C Programming
    Language.” *Document Number D-60411*, March. [https://web.archive.org/web/20111015064908/http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf](https://web.archive.org/web/20111015064908/http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf).Jordan,
    Michael. 2019\. “Artificial Intelligence–The Revolution Hasn’t Happened Yet.”
    *Harvard Data Science Review* 1 (1). [https://doi.org/10.1162/99608f92.f06c6e61](https://doi.org/10.1162/99608f92.f06c6e61).Lin,
    Sarah, Ibraheem Ali, and Greg Wilson. 2021\. “Ten Quick Tips for Making Things
    Findable.” *PLOS Computational Biology* 16 (12): 1–10\. [https://doi.org/10.1371/journal.pcbi.1008469](https://doi.org/10.1371/journal.pcbi.1008469).Liu,
    Emily, Lenny Bronner, and Jeremy Bowers. 2022\. “What the Washington Post Elections
    Engineering Team Had to Learn about Election Data.” *Washington Post Engineering*,
    April. [https://washpost.engineering/what-the-washington-post-elections-engineering-team-had-to-learn-about-election-data-a41603daf9ca](https://washpost.engineering/what-the-washington-post-elections-engineering-team-had-to-learn-about-election-data-a41603daf9ca).Lockheed
    Martin. 2005\. “Joint Strike Fighter Air Vehicle C++ Coding Standards For The
    System Development And Demonstration Program.” *Document Number 2RDU00001 Rev
    C*, December. [https://www.stroustrup.com/JSF-AV-rules.pdf](https://www.stroustrup.com/JSF-AV-rules.pdf).Martin,
    Charles, and Ben Popper. 2021\. “Don’t Push That Button: Exploring the Software
    That Flies SpaceX Rockets and Starships.” *The Overflow*, December. [https://stackoverflow.blog/2021/12/27/dont-push-that-button-exploring-the-software-that-flies-spacex-starships/](https://stackoverflow.blog/2021/12/27/dont-push-that-button-exploring-the-software-that-flies-spacex-starships/).Meng,
    Xiao-Li. 2018\. “Statistical Paradises and Paradoxes in Big Data (i): Law of Large
    Populations, Big Data Paradox, and the 2016 US Presidential Election.” *The Annals
    of Applied Statistics* 12 (2): 685–726\. [https://doi.org/10.1214/18-AOAS1161SF](https://doi.org/10.1214/18-AOAS1161SF).Mindell,
    David. 2008\. *Digital Apollo: Human and Machine in Spaceflight*. 1st ed. New
    York: The MIT Press.Northcutt, Curtis, Anish Athalye, and Jonas Mueller. 2021\.
    “Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks.”
    In *Proceedings of the 35th Conference on Neural Information Processing Systems
    Track on Datasets and Benchmarks*. [https://doi.org/10.48550/arXiv.2103.14749](https://doi.org/10.48550/arXiv.2103.14749).Ooms,
    Jeroen. 2022\. *pdftools: Text Extraction, Rendering and Converting of PDF Documents*.
    [https://CRAN.R-project.org/package=pdftools](https://CRAN.R-project.org/package=pdftools).Open
    Science Collaboration. 2015\. “Estimating the Reproducibility of Psychological
    Science.” *Science* 349 (6251): aac4716\. [https://doi.org/10.1126/science.aac4716](https://doi.org/10.1126/science.aac4716).Palmer
    Station Antarctica LTER, and Gorman, Kristen. 2020\. “Structural Size Measurements
    and Isotopic Signatures of Foraging Among Adult Male and Female Adélie Penguins
    (Pygoscelis Adeliae) Nesting Along the Palmer Archipelago Near Palmer Station,
    2007-2009.” [https://doi.org/10.6073/PASTA/98B16D7D563F265CB52372C8CA99E60F](https://doi.org/10.6073/PASTA/98B16D7D563F265CB52372C8CA99E60F).Preece,
    Donald Arthur. 1981\. “Distributions of Final Digits in Data.” *The Statistician*
    30 (1): 31\. [https://doi.org/10.2307/2987702](https://doi.org/10.2307/2987702).R
    Core Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Radcliffe,
    Nicholas. 2023\. *Test-Driven Data Analysis (Python TDDA library)*. [https://tdda.readthedocs.io/en/latest/index.html](https://tdda.readthedocs.io/en/latest/index.html).Riederer,
    Emily. 2020\. “Column Names as Contracts,” September. [https://emilyriederer.netlify.app/post/column-name-contracts/](https://emilyriederer.netlify.app/post/column-name-contracts/).Sambasivan,
    Nithya, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and
    Lora Aroyo. 2021\. “‘Everyone Wants to Do the Model Work, Not the Data Work’:
    Data Cascades in High-Stakes AI.” In *Proceedings of the 2021 CHI Conference on
    Human Factors in Computing Systems*. ACM. [https://doi.org/10.1145/3411764.3445518](https://doi.org/10.1145/3411764.3445518).Silberzahn,
    Raphael, Eric Uhlmann, Daniel Martin, Pasquale Anselmi, Frederik Aust, Eli Awtrey,
    Štěpán Bahnı́k, et al. 2018\. “Many Analysts, One Data Set: Making Transparent
    How Variations in Analytic Choices Affect Results.” *Advances in Methods and Practices
    in Psychological Science* 1 (3): 337–56\. [https://doi.org/10.1177/2515245917747646](https://doi.org/10.1177/2515245917747646).Somers,
    James. 2015\. “Toolkits for the Mind.” *MIT Technology Review*, April. [https://www.technologyreview.com/2015/04/02/168469/toolkits-for-the-mind/](https://www.technologyreview.com/2015/04/02/168469/toolkits-for-the-mind/).Turcotte,
    Alexi, Aviral Goel, Filip Křikava, and Jan Vitek. 2020\. “Designing Types for
    r, Empirically.” *Proceedings of the ACM on Programming Languages* 4 (OOPSLA):
    1–25\. [https://doi.org/10.1145/3428249](https://doi.org/10.1145/3428249).Van
    den Broeck, Jan, Solveig Argeseanu Cunningham, Roger Eeckels, and Kobus Herbst.
    2005\. “Data Cleaning: Detecting, Diagnosing, and Editing Data Abnormalities.”
    *PLOS Medicine* 2 (10): e267\. [https://doi.org/10.1371/journal.pmed.0020267](https://doi.org/10.1371/journal.pmed.0020267).van
    der Loo, Mark. 2022\. *The Data Validation Cookbook*. [https://data-cleaning.github.io/validate/](https://data-cleaning.github.io/validate/).van
    der Loo, Mark, and Edwin De Jonge. 2021\. “Data Validation Infrastructure for
    R.” *Journal of Statistical Software* 97 (10): 1–33\. [https://doi.org/10.18637/jss.v097.i10](https://doi.org/10.18637/jss.v097.i10).Vickers,
    Andrew, and Emily Vertosick. 2016\. “An Empirical Study of Race Times in Recreational
    Endurance Runners.” *BMC Sports Science, Medicine and Rehabilitation* 8 (1). [https://doi.org/10.1186/s13102-016-0052-y](https://doi.org/10.1186/s13102-016-0052-y).Weinberg,
    Gerald. 1971\. *The Psychology of Computer Programming*. New York: Van Nostrand
    Reinhold Company.Wickham, Hadley. 2011\. “testthat: Get Started with Testing.”
    *The R Journal* 3: 5–10\. [https://journal.r-project.org/archive/2011-1/RJournal%5F2011-1%5FWickham.pdf](https://journal.r-project.org/archive/2011-1/RJournal%5F2011-1%5FWickham.pdf).———.
    2014\. “Tidy Data.” *Journal of Statistical Software* 59 (1): 1–23\. [https://doi.org/10.18637/jss.v059.i10](https://doi.org/10.18637/jss.v059.i10).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).Wickham,
    Hadley, and Jennifer Bryan. 2023\. *readxl: Read Excel Files*. [https://CRAN.R-project.org/package=readxl](https://CRAN.R-project.org/package=readxl).Wickham,
    Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. (2016) 2023\. *R for Data
    Science*. 2nd ed. O’Reilly Media. [https://r4ds.hadley.nz](https://r4ds.hadley.nz).Wickham,
    Hadley, and Dana Seidel. 2022\. *scales: Scale Functions for Visualization*. [https://CRAN.R-project.org/package=scales](https://CRAN.R-project.org/package=scales).Wilson,
    Greg, Jenny Bryan, Karen Cranston, Justin Kitzes, Lex Nederbragt, and Tracy Teal.
    2017\. “Good Enough Practices in Scientific Computing.” *PLOS Computational Biology*
    13 (6): 1–20\. [https://doi.org/10.1371/journal.pcbi.1005510](https://doi.org/10.1371/journal.pcbi.1005510).****
    **** * *'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: By way of background, character encoding is needed for computers, which are
    based on strings of 0s and 1s, to be able to consider symbols such as alphabets.
    One source of particularly annoying data cleaning issues is different character
    encoding. This is especially common when dealing with foreign languages and odd
    characters. In general, we use an encoding called UTF-8\. The encoding of a character
    vector can be found using `Encoding()`.[↩︎](#fnref1)
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为背景，由于计算机基于由0和1组成的字符串，因此需要字符编码才能考虑字母表等符号。特别令人烦恼的数据清理问题之一是不同的字符编码。在处理外语和特殊字符时尤其常见。通常，我们使用一种称为UTF-8的编码。可以使用`Encoding()`函数找到字符向量的编码。[↩︎](#fnref1)
- en: 'If this does not work, then the City of Toronto government may have moved the
    datasets. Instead use: `earlier_toronto_shelters <- read_csv("https://www.tellingstorieswithdata.com/inputs/data/earlier_toronto_shelters.csv")`.[↩︎](#fnref2)'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果这种方法不起作用，那么多伦多市政府可能已经移动了数据集。相反，请使用：`earlier_toronto_shelters <- read_csv("https://www.tellingstorieswithdata.com/inputs/data/earlier_toronto_shelters.csv")`。[↩︎](#fnref2)
- en: 'Or use: https://www.tellingstorieswithdata.com/inputs/pdfs/1996_Tanzania_DHS.pdf.[↩︎](#fnref3)'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 或者使用：[https://www.tellingstorieswithdata.com/inputs/pdfs/1996_Tanzania_DHS.pdf](https://www.tellingstorieswithdata.com/inputs/pdfs/1996_Tanzania_DHS.pdf)[↩︎](#fnref3)
- en: 'If the Kenyan government link breaks then replace their URL with: https://www.tellingstorieswithdata.com/inputs/pdfs/2019_Kenya_census.pdf.[↩︎](#fnref4)'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果肯尼亚政府的链接失效，请将他们的URL替换为：https://www.tellingstorieswithdata.com/inputs/pdfs/2019_Kenya_census.pdf.[↩︎](#fnref4)
- en: The underlying idea for this exercise is from Michael Donnelly.[↩︎](#fnref5)
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个练习的基本想法来自迈克尔·多尼利。[↩︎](#fnref5)
- en: This code is from Christina Wei.[↩︎](#fnref6)
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码来自克里斯蒂娜·魏。[↩︎](#fnref6)
- en: The idea for this exercise is from Taylor John Wright.[↩︎](#fnref7)
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个练习的想法来自Taylor John Wright。[↩︎](#fnref7)
- en: The idea for this exercise is from Derek Beaton.[↩︎](#fnref8)***********************
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个练习的想法来自德里克·比顿。[↩︎](#fnref8)***********************
