- en: '18'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MONTE CARLO SIMULATION
  prefs: []
  type: TYPE_NORMAL
- en: In Chapters 16 and 17, we looked at different ways of using randomness in computations.
    Many of the examples we presented fall into the class of computation known as
    **Monte Carlo simulation**. Monte Carlo simulation is a technique used to approximate
    the probability of an event by running the same simulation multiple times and
    averaging the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stanislaw Ulam and Nicholas Metropolis coined the term Monte Carlo simulation
    in 1949 in homage to the games of chance played in the casino in the Principality
    of Monaco. Ulam, who is best known for designing the hydrogen bomb with Edward
    Teller, described the invention of the method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The first thoughts and attempts I made to practice [the Monte Carlo Method]
    were suggested by a question which occurred to me in 1946 as I was convalescing
    from an illness and playing solitaires. The question was what are the chances
    that a Canfield solitaire laid out with 52 cards will come out successfully? After
    spending a lot of time trying to estimate them by pure combinatorial calculations,
    I wondered whether a more practical method than “abstract thinking” might not
    be to lay it out say one hundred times and simply observe and count the number
    of successful plays. This was already possible to envisage with the beginning
    of the new era of fast computers,*[*^(124)*](#c18-fn-0001) *and I immediately
    thought of problems of neutron diffusion and other questions of mathematical physics,
    and more generally how to change processes described by certain differential equations
    into an equivalent form interpretable as a succession of random operations. Later
    … [in 1946, I] described the idea to John von Neumann, and we began to plan actual
    calculations.*[*^(125)*](#c18-fn-0002)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The technique was used during the Manhattan Project to predict what would happen
    during a nuclear fission reaction, but did not really take off until the 1950s,
    when computers became both more common and more powerful.
  prefs: []
  type: TYPE_NORMAL
- en: Ulam was not the first mathematician to think about using the tools of probability
    to understand a game of chance. The history of probability is intimately connected
    to the history of gambling. It is uncertainty that makes gambling possible. And
    the existence of gambling provoked the development of much of the mathematics
    needed to reason about uncertainty. Contributions to the foundations of probability
    theory by Cardano, Pascal, Fermat, Bernoulli, de Moivre, and Laplace were all
    motivated by a desire to better understand (and perhaps profit from) games of
    chance.
  prefs: []
  type: TYPE_NORMAL
- en: 18.1 Pascal's Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the early work on probability theory revolved around games using dice.[^(126)](#c18-fn-0003)
    Reputedly, Pascal''s interest in the field that came to be known as probability
    theory began when a friend asked him whether it would be profitable to bet that
    within 24 rolls of a pair of dice he would roll a double `6`. This was considered
    a hard problem in the mid-seventeenth century. Pascal and Fermat, two pretty smart
    guys, exchanged a number of letters about how to resolve the issue, but it now
    seems like an easy question to answer:'
  prefs: []
  type: TYPE_NORMAL
- en: On the first roll the probability of rolling a `6` on each die is `1/6`, so
    the probability of rolling a `6` with both dice is `1/36`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, the probability of not rolling a double `6` on the first roll is
    `1 ‑ 1/36 =` `35/36`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, the probability of not rolling `6` on both die 24 consecutive times
    is `(35/36)`^(24), nearly `0.51`, and therefore the probability of rolling a double
    `6` is `1 - (35/36)`^(24), about `0.49`. In the long run, it would not be profitable
    to bet on rolling a double `6` within 24 rolls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just to be safe, let's write a little program, [Figure 18-1](#c18-fig-0001),
    to simulate Pascal's friend's game and confirm that we get the same answer as
    Pascal. (All of the code in this chapter assumes that
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: occur at the start of the file in which the code occurs.) When run the first
    time, the call `check_pascal(1000000)` printed
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is indeed quite close to `1 - (35/36)`^(24); typing `1-(35.0/36.0)**24`
    into the Python shell produces `0.49140387613090342`.
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0001.jpg](../images/c18-fig-0001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 18-1](#c18-fig-0001a) Checking Pascal''s analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 18.2 Pass or Don't Pass?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all questions about games of chance are so easily answered. In the game
    craps, the shooter (the person who rolls the dice) chooses between making a “pass
    line” or a “don't pass line” bet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pass Line: Shooter wins if the first roll is a “natural” (`7` or `11`) and
    loses if it is “craps” (`2`, `3`, or `12`). If some other number is rolled, that
    number becomes the “point,” and the shooter keeps rolling. If the shooter rolls
    the point before rolling a `7`, the shooter wins. Otherwise the shooter loses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Don''t Pass Line: Shooter loses if the first roll is `7` or `11`, wins if it
    is `2` or `3`, and ties (a “push” in gambling jargon) if it is `12`. If some other
    number is rolled, that number becomes the point, and the shooter keeps rolling.
    If the shooter rolls a `7` before rolling the point, the shooter wins. Otherwise
    the shooter loses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is one of these a better bet than the other? Is either a good bet? It is possible
    to analytically derive the answer to these questions, but it seems easier (at
    least to us) to write a program that simulates a craps game and see what happens.
    [Figure 18-2](#c18-fig-0002) contains the heart of such a simulation.
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0002.jpg](../images/c18-fig-0002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 18-2](#c18-fig-0002a) `Craps_game` class'
  prefs: []
  type: TYPE_NORMAL
- en: The values of the instance variables of an instance of class `Craps_game` record
    the performance of the pass and don't pass lines since the start of the game.
    The observer methods `pass_results` and `dp_results` return these values. The
    method `play_hand` simulates one hand of a game. A “hand” starts when the shooter
    is “coming out,” the term used in craps for a roll before a point is established.
    A hand ends when the shooter has won or lost his or her initial bet. The bulk
    of the code in `play_hand` is merely an algorithmic description of the rules stated
    above. Notice that there is a loop in the `else` clause corresponding to what
    happens after a point is established. It is exited using a `break` statement when
    either a seven or the point is rolled.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 18-3](#c18-fig-0003) contains a function that uses class `Craps_game`
    to simulate a series of craps games.'
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0003.jpg](../images/c18-fig-0003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 18-3](#c18-fig-0003a) Simulating a craps game'
  prefs: []
  type: TYPE_NORMAL
- en: 'The structure of `craps_sim` is typical of many simulation programs:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. It runs multiple games (think of each game as analogous to a trial in our
    earlier simulations) and accumulates the results. Each game includes multiple
    hands, so there is a nested loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2\. It then produces and stores statistics for each game.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 3\. Finally, it produces and outputs summary statistics. In this case, it prints
    the expected return on investment (ROI) for each kind of betting line and the
    standard deviation of that ROI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Return on investment** is defined by the equation[^(127)](#c18-fn-0004)'
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5001.jpg](../images/c18-fig-5001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Since the pass and don't pass lines pay even money (if you bet `$1` and win,
    you gain `$1`), the ROI is
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5002.jpg](../images/c18-fig-5002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For example, if you made `100` pass line bets and won half, your ROI would be
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5003.jpg](../images/c18-fig-5003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If you bet the don't pass line 100 times and had 25 wins and 5 pushes, the ROI
    would be
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5004.jpg](../images/c18-fig-5004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's run our craps game simulation and see what happens when we try `craps_sim(20,
    10)`:[^(128)](#c18-fn-0005)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It looks as if it would be a good idea to avoid the pass line—where the expected
    return on investment is a `7%` loss. But the don't pass line looks like a pretty
    good bet. Or does it?
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the standard deviations, it seems that perhaps the don't pass line
    is not such a safe bet after all. Recall that under the assumption that the distribution
    is normal, the `95%` confidence interval is encompassed by `1.96` standard deviations
    on either side of the mean. For the don't pass line, the `95%` confidence interval
    is `[4.0–1.96`*`23.5372, 4.0+1.96`*`23.5372]`—roughly `[-43%, +51%]`. That certainly
    doesn't suggest that betting the don't pass line is a sure thing.
  prefs: []
  type: TYPE_NORMAL
- en: Time to put the law of large numbers to work; `craps_sim(1000000, 10)` prints
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can now be pretty safe in assuming that neither of these is a good bet.[^(129)](#c18-fn-0006)
    It looks as if the don't pass line might be slightly less bad, but we probably
    shouldn't count on that. If the `95%` confidence intervals for the pass and don't
    pass lines did not overlap, it would be safe to assume that the difference in
    the two means was statistically significant.[^(130)](#c18-fn-0007) However, they
    do overlap, so no conclusion can be safely drawn.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that instead of increasing the number of hands per game, we increased
    the number of games, e.g., by making the call `craps_sim(20, 1000000)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The standard deviations are high—indicating that the outcome of a single game
    of `20` hands is highly uncertain.
  prefs: []
  type: TYPE_NORMAL
- en: One of the nice things about simulations is that they make it easy to perform
    “what if” experiments. For example, what if a player could sneak in a pair of
    cheater's dice that favored `5` over `2` (`5` and `2` are on the opposite sides
    of a die)? To test this out, all we have to do is replace the implementation of
    `roll_die` by something like
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This relatively small change in the die makes a dramatic difference in the odds.
    Running `craps_sim(1000000, 10)` yields
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: No wonder casinos go to a lot of trouble to make sure that players don't introduce
    their own dice into the game!
  prefs: []
  type: TYPE_NORMAL
- en: '**Finger exercise**: A “big 6” bet pays even money if a 6 is rolled before
    a 7\. Assuming 30 $5 bets per hour, write a Monte Carlo simulation that estimates
    the cost per hour and the standard deviation of that cost of playing “big 6” bets.'
  prefs: []
  type: TYPE_NORMAL
- en: 18.3 Using Table Lookup to Improve Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might not want to try running `craps_sim(100000000, 10)` at home. It takes
    a long time to complete on most computers. That raises the question of whether
    there is a simple way to speed up the simulation.
  prefs: []
  type: TYPE_NORMAL
- en: The complexity of the implementation of the function `craps_sim` is roughly
    *θ*`(``play_hand``)`*`hands_per_game`*`num_games`. The running time of `play_hand`
    depends upon the number of times the loop in it is executed. In principle, the
    loop could be executed an unbounded number of times since there is no bound on
    how long it could take to roll either a `7` or the point. In practice, of course,
    we have every reason to believe it will always terminate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice, however, that the result of a call to `play_hand` does not depend on
    how many times the loop is executed, but only on which exit condition is reached.
    For each possible point, we can easily calculate the probability of rolling that
    point before rolling a `7`. For example, using a pair of dice we can roll a `4`
    in three different ways: `<1, 3>, <3, 1>,` and `<2, 2>`. We can roll a `7` in
    six different ways`: <1, 6>, <6, 1>, <2, 5>, <5, 2>, <3, 4>`, and `<4, 3>`. Therefore,
    exiting the loop by rolling a `7` is twice as likely as exiting the loop by rolling
    a `4`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 18-4](#c18-fig-0008) contains an implementation of `play_hand` that
    exploits this thinking. We first compute the probability of making the point before
    rolling a `7` for each possible value of the point and store those values in a
    dictionary. Suppose, for example, that the point is `8`. The shooter continues
    to roll until he either rolls the point or rolls craps. There are five ways of
    rolling an `8` `(<6,2>,` `<2,6>, <5,3>, <3,5>, and <4,4>)` and six ways of rolling
    a `7`. So, the value for the dictionary key `8` is the value of the expression
    `5/11`. Having this table allows us to replace the inner loop, which contained
    an unbounded number of rolls, with a test against one call to `random.random`.
    The asymptotic complexity of this version of `play_hand` is `O(1)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of replacing computation by **table lookup** has broad applicability
    and is frequently used when speed is an issue. Table lookup is an example of the
    general idea of **trading time for space**. As we saw in Chapter 15, it is the
    key idea behind dynamic programming. We saw another example of this technique
    in our analysis of hashing: the larger the table, the fewer the collisions, and
    the faster the average lookup. In this case, the table is small, so the space
    cost is negligible.'
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0004.jpg](../images/c18-fig-0004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 18-4](#c18-fig-0008a) Using table lookup to improve performance'
  prefs: []
  type: TYPE_NORMAL
- en: 18.4 Finding π
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is easy to see how Monte Carlo simulation is useful for tackling problems
    in which nondeterminism plays a role. Interestingly, however, Monte Carlo simulation
    (and randomized algorithms in general) can be used to solve problems that are
    not inherently stochastic, i.e., for which there is no uncertainty about outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Consider *π*. For thousands of years, people have known that there is a constant
    (called *π* since the eighteenth century) such that the circumference of a circle
    is equal to `π` * `diameter` and the area of the circle equal to *π* * `radius`².
    What they did not know was the value of this constant.
  prefs: []
  type: TYPE_NORMAL
- en: One of the earliest estimates, `4`*`(8/9)`² `= 3.16`, can found in the Egyptian
    *Rhind Papyrus*, circa 1650 BC. More than a thousand years later, the *Old Testament*
    (1 Kings 7.23) implied a different value for *π* when giving the specifications
    of one of King Solomon's construction projects,
  prefs: []
  type: TYPE_NORMAL
- en: '*And he made a molten sea, ten cubits from the one brim to the other: it was
    round all about, and his height was five cubits: and a line of 30 cubits did compass
    it round about.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Solving for *π*, `10π = 30`, so *π* `= 3`. Perhaps the *Bible* is simply wrong,
    or perhaps the molten sea wasn't perfectly circular, or perhaps the circumference
    was measured from the outside of the wall and the diameter from the inside, or
    perhaps it's just poetic license. We leave it to the reader to decide.
  prefs: []
  type: TYPE_NORMAL
- en: Archimedes of Syracuse (287-212 BCE) derived upper and lower bounds on the value
    of *π* by using a high-degree polygon to approximate a circular shape. Using a
    polygon with `96` sides, he concluded that `223/71 <` *π* `< 22/7`. Giving upper
    and lower bounds was a rather sophisticated approach for the time. If we take
    his best estimate as the average of his two bounds, we obtain `3.1418`, an error
    of about `0.0002`. Not bad! But about 700 years later, the Chinese mathematician
    Zu Chongzhi used a polygon with 24,576 sides to conclude that `3.1415962 <` *π*
    `< 3.1415927\.` About 800 years after that, the Dutch cartographer Adriaan Anthonisz
    (1527-1607) estimated it as `355/113`, roughly3.1415929203539825\. That estimate
    is good enough for most practical purposes, but it didn't keep mathematicians
    from working on the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Long before computers were invented, the French mathematicians Buffon (1707-1788)
    and Laplace (1749-1827) proposed using a stochastic simulation to estimate the
    value of *π*.[^(131)](#c18-fn-0008) Think about inscribing a circle in a square
    with sides of length `2`, so that the radius, r, of the circle is of length `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0005.jpg](../images/c18-fig-0005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18-5 Unit circle inscribed in a square
  prefs: []
  type: TYPE_NORMAL
- en: By the definition of *π*, *area* = *πr*². Since `r` is `1`, *π* `= area`. But
    what's the area of the circle? Buffon suggested that he could estimate the area
    of a circle by a dropping a large number of needles (which he argued would follow
    a random path as they fell) in the vicinity of the square. The ratio of the number
    of needles with tips lying within the square to the number of needles with tips
    lying within the circle could then be used to estimate the area of the circle.
  prefs: []
  type: TYPE_NORMAL
- en: If the locations of the needles are truly random, we know that
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5005.jpg](../images/c18-fig-5005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and solving for the area of the circle,
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5006.jpg](../images/c18-fig-5006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Recall that the area of a `2` by `2` square is `4`, so,
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-5007.jpg](../images/c18-fig-5007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In general, to estimate the area of some region `R`:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Pick an enclosing region, `E`, such that the area of `E` is easy to calculate
    and `R` lies completely within `E`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2\. Pick a set of random points that lie within `E`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 3\. Let `F` be the fraction of the points that fall within `R`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 4\. Multiply the area of `E` by `F`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you try Buffon's experiment, you'll soon realize that the places where the
    needles land are not truly random. Moreover, even if you could drop them randomly,
    it would take a very large number of needles to get an approximation of `π` as
    good as even the *Bible*'s. Fortunately, computers can randomly drop simulated
    needles at a ferocious rate.[^(132)](#c18-fn-0009)
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 18-6](#c18-fig-0013) contains a program that estimates `π` using the
    Buffon-Laplace method. For simplicity, it considers only those needles that fall
    in the upper-right quadrant of the square.'
  prefs: []
  type: TYPE_NORMAL
- en: '![c18-fig-0006.jpg](../images/c18-fig-0006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 18-6](#c18-fig-0013a) Estimating π'
  prefs: []
  type: TYPE_NORMAL
- en: The function `throw_needles` simulates dropping a needle by first using `random.random`
    to get a pair of positive Cartesian coordinates (`x` and `y` values) representing
    the position of the needle with respect to the center of the square. It then uses
    the Pythagorean theorem to compute the hypotenuse of the right triangle with base
    `x` and height `y`. This is the distance of the tip of the needle from the origin
    (the center of the square). Since the radius of the circle is `1`, we know that
    the needle lies within the circle if and only if the distance from the origin
    is no greater than `1`. We use this fact to count the number of needles in the
    circle.
  prefs: []
  type: TYPE_NORMAL
- en: The function `get_est` uses `throw_needles` to find an estimate of *π* by first
    dropping `num_needles` needles, and then averaging the result over `num_trials`
    trials. It then returns the mean and standard deviation of the trials.
  prefs: []
  type: TYPE_NORMAL
- en: The function `est_pi` calls `get_est` with an ever-growing number of needles
    until the standard deviation returned by `get_est` is no larger than `precision/1.96\.`
    Under the assumption that the errors are normally distributed, this implies that
    `95%` of the values lie within `precision` of the mean.
  prefs: []
  type: TYPE_NORMAL
- en: When we ran `est_pi(0.01, 100)`, it printed
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As we would expect, the standard deviations decreased monotonically as we increased
    the number of samples. In the beginning the estimates of the value of `π` also
    improved steadily. Some were above the true value and some below, but each increase
    in `num_needles` led to an improved estimate. With `1000` samples per trial, the
    simulation's estimate was already better than those of the *Bible* and the *Rhind
    Papyrus*.
  prefs: []
  type: TYPE_NORMAL
- en: Curiously, the estimate got worse when the number of needles increased from
    `8,000` to `16,000`, since `3.14135` is farther from the true value of `π` than
    is `3.14143`. However, if we look at the ranges defined by one standard deviation
    around each of the means, both ranges contain the true value of *π*, and the range
    associated with the larger sample size is smaller. Even though the estimate generated
    with `16,000` samples happens to be farther from the actual value of *π*, we should
    have more confidence in its accuracy. This is an extremely important notion. It
    is not sufficient to produce a good answer. We have to have a valid reason to
    be confident that it is in fact a good answer. And when we drop a large enough
    number of needles, the small standard deviation gives us reason to be confident
    that we have a correct answer. Right?
  prefs: []
  type: TYPE_NORMAL
- en: Not exactly. Having a small standard deviation is a necessary condition for
    having confidence in the validity of the result. It is not a sufficient condition.
    The notion of a statistically valid conclusion should never be confused with the
    notion of a correct conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: Each statistical analysis starts with a set of assumptions. The key assumption
    here is that our simulation is an accurate model of reality. Recall that the design
    of our Buffon-Laplace simulation started with a little algebra demonstrating how
    we could use the ratio of two areas to find the value of *π*. We then translated
    this idea into code that depended upon a little geometry and on the randomness
    of `random.random`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what happens if we get any of this wrong. Suppose, for example, we
    replace the `4` in the last line of the function `throw_needles` by a `2`, and
    again run `est_pi(0.01, 100)`. This time it prints
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The standard deviation for a mere `32,000` needles suggests that we should
    have a fair amount of confidence in the estimate. But what does that really mean?
    It means that we can be reasonably confident that if we were to draw more samples
    from the same distribution, we would get a similar value. It says nothing about
    whether this value is close to the actual value of *π*. If you are going to remember
    only one thing about statistics, remember this: a statistically valid conclusion
    should not be confused with a correct conclusion!'
  prefs: []
  type: TYPE_NORMAL
- en: Before believing the results of a simulation, we need to have confidence both
    that our conceptual model is correct and that we have correctly implemented that
    model. Whenever possible, you should attempt to validate results against reality.
    In this case, you could use some other means to compute an approximation to the
    area of a circle (e.g., physical measurement) and check that the computed value
    of *π* is at least in the right neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: 18.5 Some Closing Remarks about Simulation Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For most of the history of science, theorists used mathematical techniques to
    construct purely analytical models that could be used to predict the behavior
    of a system from a set of parameters and initial conditions. This led to the development
    of important mathematical tools ranging from calculus to probability theory. These
    tools helped scientists develop a reasonably accurate understanding of the macroscopic
    physical world.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the twentieth century progressed, the limitations of this approach became
    increasingly clear. Reasons for this include:'
  prefs: []
  type: TYPE_NORMAL
- en: An increased interest in the social sciences, e.g., economics, led to a desire
    to construct good models of systems that were not mathematically tractable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the systems to be modeled grew increasingly complex, it seemed easier to
    successively refine a series of simulation models than to construct accurate analytic
    models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is often easier to extract useful intermediate results from a simulation
    than from an analytical model, e.g., to play “what if” games.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The availability of computers made it feasible to run large-scale simulations.
    Until the advent of the modern computer in the middle of the twentieth century
    the utility of simulation was limited by the time required to perform calculations
    by hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simulation models are **descriptive**, not **prescriptive**. They tell how a
    system works under given conditions; not how to arrange the conditions to make
    the system work best. A simulation does not optimize, it merely describes. That
    is not to say that simulation cannot be used as part of an optimization process.
    For example, simulation is often used as part of a search process in finding an
    optimal set of parameter settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simulation models can be classified along three dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: Deterministic versus stochastic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static versus dynamic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discrete versus continuous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The behavior of a **deterministic simulation** is completely defined by the
    model. Rerunning a simulation will not change the outcome. Deterministic simulations
    are typically used when the system being modeled is itself deterministic but is
    too complex to analyze analytically, e.g., the performance of a processor chip.
    **Stochastic simulations** incorporate randomness in the model. Multiple runs
    of the same model may generate different values. This random element forces us
    to generate many outcomes to see the range of possibilities. The question of whether
    to generate `10` or `1000` or `100,000` outcomes is a statistical question, as
    discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: In a **static model**, time plays no essential role. The needle-dropping simulation
    used to estimate `π` in this chapter is an example of a static simulation. In
    a **dynamic model**, time, or some analog, plays an essential role. In the series
    of random walks simulated in Chapter 16, the number of steps taken was used as
    a surrogate for time.
  prefs: []
  type: TYPE_NORMAL
- en: In a **discrete model**, the values of pertinent variables are enumerable, e.g.,
    they are integers. In a **continuous model**, the values of pertinent variables
    range over non-enumerable sets, e.g., the real numbers. Imagine analyzing the
    flow of traffic along a highway. We might choose to model each individual car,
    in which case we have a discrete model. Alternatively, we might choose to treat
    traffic as a flow, where changes in the flow can be described by differential
    equations. This leads to a continuous model. In this example, the discrete model
    more closely resembles the physical situation (nobody drives half a car, though
    some cars are half the size of others), but is more computationally complex than
    a continuous one. In practice, models often have both discrete and continuous
    components. For example, we might choose to model the flow of blood through the
    human body using a discrete model for blood (i.e., modeling individual corpuscles)
    and a continuous model for blood pressure.
  prefs: []
  type: TYPE_NORMAL
- en: 18.6 Terms Introduced in Chapter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monte Carlo simulation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: return on investment (ROI)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: table lookup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: time/space tradeoff
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: descriptive model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: prescriptive model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deterministic simulation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: stochastic simulation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: static model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dynamic model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: discrete model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: continuous model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
