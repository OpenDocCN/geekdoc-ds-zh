<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Efficient Buffering in Go¶</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Efficient Buffering in Go¶</h1>
<blockquote>原文：<a href="https://goperf.dev/01-common-patterns/buffered-io/">https://goperf.dev/01-common-patterns/buffered-io/</a></blockquote>
                
                  


  
  



<p>Buffering is a core performance technique in systems programming. In Go, it's especially relevant when working with I/O—file access, network communication, and stream processing. Without buffering, many operations incur excessive system calls or synchronization overhead. Proper buffering reduces the frequency of such interactions, improves throughput, and smooths latency spikes.</p>
<h2 id="why-buffering-matters">Why Buffering Matters<a class="headerlink" href="#why-buffering-matters" title="Permanent link">¶</a></h2>
<p>Every time you read from or write to a file or socket, there’s a good chance you’re triggering a system call—and that’s not cheap. System calls move control from user space into kernel space, which means crossing a boundary that comes with overhead: entering kernel mode, possible context switches, interacting with I/O buffers, and sometimes queuing operations behind the scenes. Doing that once in a while is fine. Doing it thousands of times per second? That’s a problem. Buffering helps by batching small reads or writes into larger chunks, reducing how often you cross that boundary and making far better use of each syscall.</p>
<p>For example, writing to a file in a loop without buffering, like this:</p>
<div class="highlight"><pre><code>f, _ := os.Create("output.txt")
for i := 0; i &lt; 10000; i++ {
    f.Write([]byte("line\n"))
}
</code></pre></div>
<p>This can easily result in <strong>10,000 separate system calls</strong>, each carrying its own overhead and dragging down performance. On top of that, a flood of small writes tends to fragment disk operations, which puts extra pressure on I/O subsystems and wastes CPU cycles handling what could have been a single, efficient batch.</p>
<h3 id="with-buffering">With Buffering<a class="headerlink" href="#with-buffering" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><code>f, _ := os.Create("output.txt")
buf := bufio.NewWriter(f)
for i := 0; i &lt; 10000; i++ {
    buf.WriteString("line\n")
}
buf.Flush() // ensure all buffered data is written
</code></pre></div>
<p>This version significantly reduces the number of system calls. The <code>bufio.Writer</code> accumulates writes in an internal memory buffer (typically 4KB or more). It only triggers a syscall when the buffer is full or explicitly flushed. As a result, you achieve faster I/O, reduced CPU usage, and improved performance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code>bufio.Writer</code> does not automatically flush when closed. If you forget to call <code>Flush()</code>, any unwritten data remaining in the buffer will be lost. Always call <code>Flush()</code> before closing or returning from a function, especially if the total written size is smaller than the buffer capacity.</p>
</div>
<h3 id="controlling-buffer-capacity">Controlling Buffer Capacity<a class="headerlink" href="#controlling-buffer-capacity" title="Permanent link">¶</a></h3>
<p>By default, <code>bufio.NewWriter()</code> allocates a 4096-byte (4 KB) buffer. This size aligns with the common block size of file systems and the standard memory page size on most operating systems (such as Linux, BSD, and macOS). Reading or writing in 4 KB increments minimizes page faults, aligns with kernel read-ahead strategies, and maps efficiently onto underlying disk I/O operations.</p>
<p>While 4 KB is a practical general-purpose default, it might not be optimal for all workloads. For high-throughput scenarios—such as streaming large files or generating extensive logs—a larger buffer can help reduce syscall frequency further:</p>
<div class="highlight"><pre><code>f, _ := os.Create("output.txt")
buf := bufio.NewWriterSize(f, 16*1024) // 16 KB buffer
</code></pre></div>
<p>Conversely, if latency is more critical than throughput (e.g., interactive systems or command-line utilities), a smaller buffer may be more appropriate, as it flushes data more frequently.</p>
<p>Similar logic applies when reading data:</p>
<div class="highlight"><pre><code>reader := bufio.NewReaderSize(f, 32*1024) // 32 KB buffer for input
</code></pre></div>
<p>Buffer size isn’t something to guess at—it’s something to measure. The ideal size depends on too many variables to hard-code: whether you’re writing to SSDs or spinning disks, how your filesystem buffers writes, how much CPU cache is available, and what else is competing for resources on the system. Profiling and benchmarking are the only reliable ways to dial it in. What works well on one setup might be suboptimal—or even harmful—on another.</p>
<h2 id="benchmarking-impact">Benchmarking Impact<a class="headerlink" href="#benchmarking-impact" title="Permanent link">¶</a></h2>
<p>Buffered writes and reads consistently demonstrate significant performance gains under load. Benchmarks measuring system calls, memory allocations, and CPU usage typically show that buffered I/O operations are faster and more efficient than unbuffered counterparts. For example, writing one million lines to disk might exhibit up to an order-of-magnitude improvement using <code>bufio.Writer</code> compared to direct <code>os.File.Write()</code> calls. The more structured and bursty your I/O operations, the more substantial the benefits from buffering.</p>
<details class="example">
<summary>Show the benchmark file</summary>
<div class="highlight"><pre><code>package perf

import (
    "bufio"
    "io"
    "os"
    "strconv"
    "sync"
    "testing"
)

type Data struct {
    Value []byte
}

var dataPool = sync.Pool{
    New: func() any {
        return &amp;Data{Value: make([]byte, 0, 32)}
    },
}

const N = 10000

func writeNotBuffered(w io.Writer, count int) {
    for i := 0; i &lt; count; i++ {
        d := dataPool.Get().(*Data)
        d.Value = strconv.AppendInt(d.Value[:0], int64(i), 10)
        w.Write(d.Value)
        w.Write([]byte(":val\n"))
        dataPool.Put(d)
    }
}

func writeBuffered(w io.Writer, count int) {
    buf := bufio.NewWriterSize(w, 16*1024)
    for i := 0; i &lt; count; i++ {
        d := dataPool.Get().(*Data)
        d.Value = strconv.AppendInt(d.Value[:0], int64(i), 10)
        buf.Write(d.Value)
        buf.Write([]byte(":val\n"))
        dataPool.Put(d)
    }
    buf.Flush()
}

func BenchmarkWriteNotBuffered(b *testing.B) {
    for b.Loop() {
        f, _ := os.CreateTemp("", "nobuf")
        writeNotBuffered(f, N)
        f.Close()
        os.Remove(f.Name())
    }
}

func BenchmarkWriteBuffered(b *testing.B) {
    for b.Loop() {
        f, _ := os.CreateTemp("", "buf")
        writeBuffered(f, N)
        f.Close()
        os.Remove(f.Name())
    }
}
</code></pre></div>
</details>
<p>Results:</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Iterations</th>
<th>Time per op (ns)</th>
<th>Bytes per op</th>
<th>Allocs per op</th>
</tr>
</thead>
<tbody>
<tr>
<td>BenchmarkWriteNotBuffered-14</td>
<td>49</td>
<td>23,672,792</td>
<td>53,773</td>
<td>10,007</td>
</tr>
<tr>
<td>BenchmarkWriteBuffered-14</td>
<td>3241</td>
<td>379,703</td>
<td>70,127</td>
<td>10,008</td>
</tr>
</tbody>
</table>
<h2 id="when-to-buffer">When To Buffer<a class="headerlink" href="#when-to-buffer" title="Permanent link">¶</a></h2>
<p><svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8c.76 0 1.5.11 2.2.31l1.57-1.57A9.8 9.8 0 0 0 12 2 10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10M7.91 10.08 6.5 11.5 11 16 21 6l-1.41-1.42L11 13.17z"/></svg> Use buffering when:</p>
<ul>
<li>Performing frequent, small-sized I/O operations. Buffering groups small writes or reads into larger batches, which reduces the overhead of each individual operation.</li>
<li>Reducing syscall overhead is crucial. Fewer syscalls mean lower context-switching costs and improved performance, especially in I/O-heavy applications.</li>
<li>High throughput is more important than minimal latency. Buffered I/O can increase total data processed per second, even if it introduces slight delays in delivery.</li>
</ul>
<p><svg viewbox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M448 128H270.4c1 5.2 1.6 10.5 1.6 16v16h176c8.8 0 16-7.2 16-16s-7.2-16-16-16m-224 16c0-17.7-14.3-32-32-32h-24c-66.3 0-120 53.7-120 120v48c0 52.5 33.7 97.1 80.7 113.4-.5-3.1-.7-6.2-.7-9.4 0-20 9.2-37.9 23.6-49.7-4.9-9-7.6-19.4-7.6-30.3 0-15.1 5.3-29 14-40-8.8-11-14-24.9-14-40v-40c0-13.3 10.7-24 24-24s24 10.7 24 24v40c0 8.8 7.2 16 16 16s16-7.2 16-16zm-32-80c18 0 34.6 6 48 16h208c35.3 0 64 28.7 64 64s-28.7 64-64 64h-82c1.3 5.1 2 10.5 2 16 0 25.3-14.7 47.2-36 57.6 2.6 7 4 14.5 4 22.4 0 20-9.2 37.9-23.6 49.7 4.9 9 7.6 19.4 7.6 30.3 0 35.3-28.7 64-64 64h-88C75.2 448 0 372.8 0 280v-48C0 139.2 75.2 64 168 64zm64 336c8.8 0 16-7.2 16-16s-7.2-16-16-16h-64c-8.8 0-16 7.2-16 16s7.2 16 16 16zm16-176c0 5.5-.7 10.9-2 16h34c8.8 0 16-7.2 16-16s-7.2-16-16-16h-32zm-24 64h-40c-8.8 0-16 7.2-16 16s7.2 16 16 16h64c8.8 0 16-7.2 16-16s-7.2-16-16-16z"/></svg> Avoid buffering when:</p>
<ul>
<li>Immediate data availability and low latency are critical. Buffers introduce delays by design, which can be unacceptable in real-time or interactive systems.</li>
<li>Buffering excessively might lead to uncontrolled memory usage. Without limits or proper flushing, buffers can grow large and put pressure on system memory.</li>
</ul>









  




                
                  
</body>
</html>