- en: Memory-Level Parallelism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/cpu-cache/mlp/](https://en.algorithmica.org/hpc/cpu-cache/mlp/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Memory requests can overlap in time: while you wait for a read request to complete,
    you can send a few others, which will be executed concurrently with it. This is
    the main reason why [linear iteration](../bandwidth) is so much faster than [pointer
    jumping](../latency): the CPU knows which memory locations it needs to fetch next
    and sends memory requests far ahead of time.'
  prefs: []
  type: TYPE_NORMAL
- en: The number of concurrent memory operations is large but limited, and it is different
    for different types of memory. When designing algorithms and especially data structures,
    you may want to know this number, as it limits the amount of parallelism your
    computation can achieve.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find this limit theoretically for a specific memory type, you can multiply
    its latency (time to fetch a cache line) by its bandwidth (number of cache lines
    fetched per second), which gives you the average number of memory operations in
    progress:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/140f45accd593c65f4ed6d9695db7d77.png)'
  prefs: []
  type: TYPE_IMG
- en: The latency of the L1/L2 caches is small, so there is no need for a long pipeline
    of pending requests, but larger memory types can sustain up to 25-40 concurrent
    read operations.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/cpu-cache/mlp/#direct-experiment)Direct
    Experiment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to measure available memory parallelism more directly by modifying
    our pointer chasing benchmark so that we loop around $D$ separate cycles in parallel
    instead of just one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Fixing the sum of the cycle lengths constant at a few select sizes and trying
    different $D$, we get slightly different results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d0a280245a088fb7de18b7aa488862e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The L2 cache run is limited by ~6 concurrent operations, as predicted, but
    larger memory types all max out between 13 and 17\. You can’t make use of more
    memory lanes as there is a conflict over logical registers. When the number of
    lanes is fewer than the number of registers, you can issue just one read instruction
    per lane:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'But when it is over ~15, you have to use temporary memory storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You don’t always get to the maximum possible level of memory parallelism, but
    for most applications, a dozen concurrent requests are more than enough. [← Memory
    Sharing](https://en.algorithmica.org/hpc/cpu-cache/sharing/)[Prefetching →](https://en.algorithmica.org/hpc/cpu-cache/prefetching/)
  prefs: []
  type: TYPE_NORMAL
