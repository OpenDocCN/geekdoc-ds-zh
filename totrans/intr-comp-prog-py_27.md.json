["```py\n﻿import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport sklearn.linear_model as sklm\nimport sklearn.metrics as skm\n```", "```py\n﻿﻿examples = build_marathon_examples('bm_results2012.csv')\ntraining, test_set = divide_80_20(examples)   \ntrue_pos, false_pos, true_neg, false_neg =\\\n        k_nearest_classify(training, test_set, 'M', 9)\nget_stats(true_pos, false_pos, true_neg, false_neg)\n```", "```py\n﻿Accuracy = 0.65\nSensitivity = 0.715\nSpecificity = 0.563\nPos. Pred. Val. = 0.684\n```", "```py\n﻿ ﻿Accuracy = 0.514\n Sensitivity = 0.593\n Specificity = 0.41\n Pos. Pred. Val. = 0.57\n```", "```py\n﻿﻿reduced_training = random.sample(training, len(training)//10)\ntrue_pos, false_pos, true_neg, false_neg =\\\n        k_nearest_classify(reduced_training, test_set, 'M', 9)\nget_stats(true_pos, false_pos, true_neg, false_neg)\n```", "```py\n﻿Accuracy = 0.638\nSensitivity = 0.667\nSpecificity = 0.599\nPos. Pred. Val. = 0.687\n```", "```py\nAccuracy = 0.614\nSensitivity = 0.684\nSpecificity = 0.523\nPos. Pred. Val. = 0.654 \n```", "```py\n﻿model.classes_ = ['A' 'B' 'C' ‘D']\nFor label A feature weights = [-4.7229 -4.3618  0.0595]\nFor label B feature weights = [-3.3346  4.7875  0.0149]\nFor label C feature weights = [ 3.7026 -4.4966 -0.0176]\nFor label D feature weights = [ 4.3548  4.0709 -0.0568]\n[0, 0] probs = [9.998e-01 0.000e+00 2.000e-04 0.000e+00]\n[0, 2] probs = [2.60e-03 9.97e-01 0.00e+00 4.00e-04]\n[2, 0] probs = [3.000e-04 0.000e+00 9.996e-01 2.000e-04]\n[2, 2] probs = [0.000e+00 5.000e-04 2.000e-04 9.992e-01]\n```", "```py\n﻿﻿model.coef = [[6.7081 6.5737]]\n[0, 0] probs = [1\\. 0.]\n[0, 2] probs = [0.5354 0.4646]\n[2, 0] probs = [0.4683 0.5317]\n[2, 2] probs = [0\\. 1.]\n```", "```py\n﻿Feature weights for label M: age = 0.055, time = -0.011\nAccuracy = 0.636\nSensitivity = 0.831\nSpecificity = 0.377\nPos. Pred. Val. = 0.638\n```", "```py\nAccuracy = 0.65\nSensitivity = 0.715\nSpecificity = 0.563\nPos. Pred. Val. = 0.684\n```", "```py\nAccuracy = 0.659\nSensitivity = 0.715\nSpecificity = 0.586\nPos. Pred. Val. = 0.695\n```", "```py\nClass,Age,Gender,Survived,Last Name,Other Names\n1,29.0,F,1,Allen, Miss. Elisabeth Walton\n1,0.92,M,1,Allison, Master. Hudson Trevor\n1,2.0,F,0,Allison, Miss. Helen Loraine\n```", "```py\n﻿manifest = pd.read_csv('TitanicPassengers.csv')\nprint(manifest.corr().round(2))\n```", "```py\n﻿          Class   Age  Survived\nClass      1.00 -0.41     -0.32\nAge       -0.41  1.00     -0.06\nSurvived  -0.32 -0.06      1.00\n```", "```py\n﻿﻿﻿﻿manifest['Gender'] = (manifest['Gender'].\n                      apply(lambda g: 1 if g == 'M' else 0))\nprint(manifest.corr().round(2))\n```", "```py\n﻿          Class   Age  Gender  Survived\nClass      1.00 -0.41    0.14     -0.32\nAge       -0.41  1.00    0.06     -0.06\nGender     0.14  0.06    1.00     -0.54\nSurvived  -0.32 -0.06   -0.54      1.00\n```", "```py\n﻿Averages for 100 trials\n Mean accuracy = 0.783, 95% conf. int. = 0.736 to 0.83\n Mean sensitivity = 0.702, 95% conf. int. = 0.603 to 0.801\n Mean specificity = 0.783, 95% conf. int. = 0.736 to 0.83\n Mean pos. pred. val. = 0.702, 95% conf. int. = 0.603 to 0.801\n Mean AUROC = 0.839, 95% conf. int. = 0.789 to 0.889\n```", "```py\n﻿﻿﻿Averages for 100 trials\n Mean weight 1st Class = 1.145, 95% conf. int. = 1.02 to 1.27\n Mean weight 2nd Class = -0.083, 95% conf. int. = -0.185 to 0.019\n Mean weight 3rd Class = -1.062, 95% conf. int. = -1.179 to -0.945\n Mean weight age = -0.034, 95% conf. int. = -0.04 to -0.028\n Mean weight male = -2.404, 95% conf. int. = -2.542 to -2.266\n```"]