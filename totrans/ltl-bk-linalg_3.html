<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Little Book of Linear Algebra</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The Little Book of Linear Algebra</h1>
<blockquote>原文：<a href="https://little-book-of.github.io/linear-algebra/index.html">https://little-book-of.github.io/linear-algebra/index.html</a></blockquote>

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">

<p class="subtitle lead">Version 0.3.0</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Duc-Tam Nguyen </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 26, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="content" class="level1">
<h1>Content</h1>
<section id="chapter-1.-vectors-scalars-and-geometry" class="level4">
<h4 class="anchored" data-anchor-id="chapter-1.-vectors-scalars-and-geometry">Chapter 1. Vectors, Scalars, and Geometry</h4>
<ol type="1">
<li>Scalars, vectors, and coordinate systems (what they are, why we care)</li>
<li>Vector notation, components, and arrows (reading and writing vectors)</li>
<li>Vector addition and scalar multiplication (the two basic moves)</li>
<li>Linear combinations and span (building new vectors from old ones)</li>
<li>Length (norm) and distance (how big and how far)</li>
<li>Dot product (algebraic and geometric views)</li>
<li>Angles between vectors and cosine (measuring alignment)</li>
<li>Projections and decompositions (splitting along a direction)</li>
<li>Cauchy–Schwarz and triangle inequalities (two fundamental bounds)</li>
<li>Orthonormal sets in ℝ²/ℝ³ (nice bases you already know)</li>
</ol>
</section>
<section id="chapter-2.-matrices-and-basic-operations" class="level4">
<h4 class="anchored" data-anchor-id="chapter-2.-matrices-and-basic-operations">Chapter 2. Matrices and Basic Operations</h4>
<ol start="11" type="1">
<li>Matrices as tables and as machines (two mental models)</li>
<li>Matrix shapes, indexing, and block views (seeing structure)</li>
<li>Matrix addition and scalar multiplication (componentwise rules)</li>
<li>Matrix–vector product (linear combos of columns)</li>
<li>Matrix–matrix product (composition of linear steps)</li>
<li>Identity, inverse, and transpose (three special friends)</li>
<li>Symmetric, diagonal, triangular, and permutation matrices (special families)</li>
<li>Trace and basic matrix properties (quick invariants)</li>
<li>Affine transforms and homogeneous coordinates (translations included)</li>
<li>Computing with matrices (cost counts and simple speedups)</li>
</ol>
</section>
<section id="chapter-3.-linear-systems-and-elimination" class="level4">
<h4 class="anchored" data-anchor-id="chapter-3.-linear-systems-and-elimination">Chapter 3. Linear Systems and Elimination</h4>
<ol start="21" type="1">
<li>From equations to matrices (augmenting and encoding)</li>
<li>Row operations (legal moves that keep solutions)</li>
<li>Row-echelon and reduced row-echelon forms (target shapes)</li>
<li>Pivots, free variables, and leading ones (reading solutions)</li>
<li>Solving consistent systems (unique vs. infinite solutions)</li>
<li>Detecting inconsistency (when no solution exists)</li>
<li>Gaussian elimination by hand (a disciplined procedure)</li>
<li>Back substitution and solution sets (finishing cleanly)</li>
<li>Rank and its first meaning (pivots as information)</li>
<li>LU factorization (elimination captured as L and U)</li>
</ol>
</section>
<section id="chapter-4.-vector-spaces-and-subspaces" class="level4">
<h4 class="anchored" data-anchor-id="chapter-4.-vector-spaces-and-subspaces">Chapter 4. Vector Spaces and Subspaces</h4>
<ol start="31" type="1">
<li>Axioms of vector spaces (what “space” really means)</li>
<li>Subspaces, column space, and null space (where solutions live)</li>
<li>Span and generating sets (coverage of a space)</li>
<li>Linear independence and dependence (no redundancy vs. redundancy)</li>
<li>Basis and coordinates (naming every vector uniquely)</li>
<li>Dimension (how many directions)</li>
<li>Rank–nullity theorem (dimensions that add up)</li>
<li>Coordinates relative to a basis (changing the “ruler”)</li>
<li>Change-of-basis matrices (moving between coordinate systems)</li>
<li>Affine subspaces (lines and planes not through the origin)</li>
</ol>
</section>
<section id="chapter-5.-linear-transformations-and-structure" class="level4">
<h4 class="anchored" data-anchor-id="chapter-5.-linear-transformations-and-structure">Chapter 5. Linear Transformations and Structure</h4>
<ol start="41" type="1">
<li>Linear transformations (preserving lines and sums)</li>
<li>Matrix representation of a linear map (choosing a basis)</li>
<li>Kernel and image (inputs that vanish; outputs we can reach)</li>
<li>Invertibility and isomorphisms (perfectly reversible maps)</li>
<li>Composition, powers, and iteration (doing it again and again)</li>
<li>Similarity and conjugation (same action, different basis)</li>
<li>Projections and reflections (idempotent and involutive maps)</li>
<li>Rotations and shear (geometric intuition)</li>
<li>Rank and operator viewpoint (rank beyond elimination)</li>
<li>Block matrices and block maps (divide and conquer structure)</li>
</ol>
</section>
<section id="chapter-6.-determinants-and-volume" class="level4">
<h4 class="anchored" data-anchor-id="chapter-6.-determinants-and-volume">Chapter 6. Determinants and Volume</h4>
<ol start="51" type="1">
<li>Areas, volumes, and signed scale factors (geometric entry point)</li>
<li>Determinant via linear rules (multilinearity, sign, normalization)</li>
<li>Determinant and row operations (how each move changes det)</li>
<li>Triangular matrices and product of diagonals (fast wins)</li>
<li>det(AB) = det(A)det(B) (multiplicative magic)</li>
<li>Invertibility and zero determinant (flat vs. full volume)</li>
<li>Cofactor expansion (Laplace’s method)</li>
<li>Permutations and sign (the combinatorial core)</li>
<li>Cramer’s rule (solving with determinants, and when not to use it)</li>
<li>Computing determinants in practice (use LU, mind stability)</li>
</ol>
</section>
<section id="chapter-7.-eigenvalues-eigenvectors-and-dynamics" class="level4">
<h4 class="anchored" data-anchor-id="chapter-7.-eigenvalues-eigenvectors-and-dynamics">Chapter 7. Eigenvalues, Eigenvectors, and Dynamics</h4>
<ol start="61" type="1">
<li>Eigenvalues and eigenvectors (directions that stay put)</li>
<li>Characteristic polynomial (where eigenvalues come from)</li>
<li>Algebraic vs. geometric multiplicity (how many and how independent)</li>
<li>Diagonalization (when a matrix becomes simple)</li>
<li>Powers of a matrix (long-term behavior via eigenvalues)</li>
<li>Real vs. complex spectra (rotations and oscillations)</li>
<li>Defective matrices and a peek at Jordan form (when diagonalization fails)</li>
<li>Stability and spectral radius (grow, decay, or oscillate)</li>
<li>Markov chains and steady states (probabilities as linear algebra)</li>
<li>Linear differential systems (solutions via eigen-decomposition)</li>
</ol>
</section>
<section id="chapter-8.-orthogonality-least-squares-and-qr" class="level4">
<h4 class="anchored" data-anchor-id="chapter-8.-orthogonality-least-squares-and-qr">Chapter 8. Orthogonality, Least Squares, and QR</h4>
<ol start="71" type="1">
<li>Inner products beyond dot product (custom notions of angle)</li>
<li>Orthogonality and orthonormal bases (perpendicular power)</li>
<li>Gram–Schmidt process (constructing orthonormal bases)</li>
<li>Orthogonal projections onto subspaces (closest point principle)</li>
<li>Least-squares problems (fit when exact solve is impossible)</li>
<li>Normal equations and geometry of residuals (why it works)</li>
<li>QR factorization (stable least squares via orthogonality)</li>
<li>Orthogonal matrices (length-preserving transforms)</li>
<li>Fourier viewpoint (expanding in orthogonal waves)</li>
<li>Polynomial and multifeature least squares (fitting more flexibly)</li>
</ol>
</section>
<section id="chapter-9.-svd-pca-and-conditioning" class="level4">
<h4 class="anchored" data-anchor-id="chapter-9.-svd-pca-and-conditioning">Chapter 9. SVD, PCA, and Conditioning</h4>
<ol start="81" type="1">
<li>Singular values and SVD (universal factorization)</li>
<li>Geometry of SVD (rotations + stretching)</li>
<li>Relation to eigen-decompositions (ATA and AAT)</li>
<li>Low-rank approximation (best small models)</li>
<li>Principal component analysis (variance and directions)</li>
<li>Pseudoinverse (Moore–Penrose) and solving ill-posed systems</li>
<li>Conditioning and sensitivity (how errors amplify)</li>
<li>Matrix norms and singular values (measuring size properly)</li>
<li>Regularization (ridge/Tikhonov to tame instability)</li>
<li>Rank-revealing QR and practical diagnostics (what rank really is)</li>
</ol>
</section>
<section id="chapter-10.-applications-and-computation" class="level4">
<h4 class="anchored" data-anchor-id="chapter-10.-applications-and-computation">Chapter 10. Applications and Computation</h4>
<ol start="91" type="1">
<li>2D/3D geometry pipelines (cameras, rotations, and transforms)</li>
<li>Computer graphics and robotics (homogeneous tricks in action)</li>
<li>Graphs, adjacency, and Laplacians (networks via matrices)</li>
<li>Data preprocessing as linear ops (centering, whitening, scaling)</li>
<li>Linear regression and classification (from model to matrix)</li>
<li>PCA in practice (dimensionality reduction workflow)</li>
<li>Recommender systems and low-rank models (fill the missing entries)</li>
<li>PageRank and random walks (ranking with eigenvectors)</li>
<li>Numerical linear algebra essentials (floating point, BLAS/LAPACK)</li>
<li>Capstone problem sets and next steps (a roadmap to mastery)</li>
</ol>


</section>
</section>

    
</body>
</html>