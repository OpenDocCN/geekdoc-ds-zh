- en: Program Simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/profiling/simulation/](https://en.algorithmica.org/hpc/profiling/simulation/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The last approach to profiling (or rather a group of them) is not to gather
    the data by actually running the program but to analyze what should happen by
    *simulating* it with specialized tools.
  prefs: []
  type: TYPE_NORMAL
- en: There are many subcategories of such profilers, differing in which aspect of
    computation is simulated. In this article, we are going to focus on [caching](/hpc/cpu-cache)
    and [branch prediction](/hpc/pipelining/branching), and use [Cachegrind](https://valgrind.org/docs/manual/cg-manual.html)
    for that, which is a profiling-oriented part of [Valgrind](https://valgrind.org/),
    a well-established tool for memory leak detection and memory debugging in general.
  prefs: []
  type: TYPE_NORMAL
- en: '### [#](https://en.algorithmica.org/hpc/profiling/simulation/#profiling-with-cachegrind)Profiling
    with Cachegrind'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cachegrind essentially inspects the binary for “interesting” instructions —
    that perform memory reads / writes and conditional / indirect jumps — and replaces
    them with code that simulates corresponding hardware operations using software
    data structures. It therefore doesn’t need access to the source code and can work
    with already compiled programs, and can be run on any program like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'It instruments all involved binaries, runs them, and outputs a summary similar
    to [perf stat](../events):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ve fed Cachegrind exactly the same example code as in [the previous section](../events):
    we create an array of a million random integers, sort it, and then perform a million
    binary searches on it. Cachegrind shows roughly the same numbers as perf does,
    except that that perf’s measured numbers of memory reads and branches are slightly
    inflated due to [speculative execution](/hpc/pipelining): they really happen in
    hardware and thus increment hardware counters, but are discarded and don’t affect
    actual performance, and thus ignored in the simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cachegrind only models the first (`D1` for data, `I1` for instructions) and
    the last (`LL`, unified) levels of cache, the characteristics of which are inferred
    from the system. It doesn’t limit you in any way as you can also set them from
    the command line, e g., to model the L2 cache: `--LL=<size>,<associativity>,<line
    size>`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It seems like it only slowed down our program so far and hasn’t provided us
    any information that `perf stat` couldn’t. To get more out of it than just the
    summary info, we can inspect a special file with profiling info, which it dumps
    by default in the same directory named as `cachegrind.out.<pid>`. It is human-readable,
    but is expected to be read via the `cg_annotate` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'First it shows the parameters that were used during the run, including the
    characteristics of the cache system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It didn’t get the L3 cache quite right: it is not unified (8M in total, but
    a single core only sees 4M) and also 16-way associative, but we will ignore that
    for now.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, it outputs a per-function summary similar to `perf report`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You can see there are a lot of branch mispredicts in the sorting stage, and
    also a lot of both L1 cache misses and branch mispredicts during binary searching.
    We couldn’t get this information with perf — it would only tell use these counts
    for the whole program.
  prefs: []
  type: TYPE_NORMAL
- en: Another great feature that Cachegrind has is the line-by-line annotation of
    source code. For that, you need to compile the program with debug information
    (`-g`) and either explicitly tell `cg_annotate` which source files to annotate
    or just pass the `--auto=yes` option so that it annotates everything it can reach
    (including the standard library source code).
  prefs: []
  type: TYPE_NORMAL
- en: 'The whole source-to-analysis process would therefore go like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the glibc implementations are not the most readable, for exposition purposes,
    we replace `lower_bound` with our own binary search, which will be annotated like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, Cachegrind only tracks memory accesses and branches. When the
    bottleneck is caused by something else, we need [other simulation tools](../mca).
    [← Statistical Profiling](https://en.algorithmica.org/hpc/profiling/events/)[Machine
    Code Analyzers →](https://en.algorithmica.org/hpc/profiling/mca/)
  prefs: []
  type: TYPE_NORMAL
