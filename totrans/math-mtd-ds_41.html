<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>5.6. Erdős-Rényi random graph and stochastic blockmodel#</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>5.6. Erdős-Rényi random graph and stochastic blockmodel#</h1>
<blockquote>原文：<a href="https://mmids-textbook.github.io/chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.html">https://mmids-textbook.github.io/chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.html</a></blockquote>

<p>A natural way to test an algorithm is by running it on a simulated dataset whose “ground truth” is known. We encountered this idea for instance in clustering, where we used a mixture of Gaussians; there, the ground truth was the mixture component from which a data point was generated. What is an appropriate stochastic model in the context of network analysis?</p>
<p>In fact there are many models of random graphs, i.e., graphs whose edges are picked at random. Which one to use depends on the task at hand. For graph partitioning, one requires a graph with a “planted partition”. The stochastic blockmodel is a canonical example of such a model. We begin with a more general setting.</p>
<section id="inhomogeneous-erdos-renyi-random-graph">
<h2><span class="section-number">5.6.1. </span>Inhomogeneous Erdős-Rényi random graph<a class="headerlink" href="#inhomogeneous-erdos-renyi-random-graph" title="Link to this heading">#</a></h2>
<p>A simple approach to generating a random graph is to include each edge <em>independently</em>. More precisely, let <span class="math notranslate nohighlight">\(V = [n]\)</span> be a set of <span class="math notranslate nohighlight">\(n\)</span> vertices. Consider a symmetric matrix <span class="math notranslate nohighlight">\(M = (m_{i,j}) \in [0,1]^{n \times n}\)</span> with arbitrary entries in <span class="math notranslate nohighlight">\([0,1]\)</span>. The entry <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i}\)</span> is the probability that edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present (i.e., that <span class="math notranslate nohighlight">\(\{i,j\} \in E\)</span>), independently of all other edges. The outcome is a random graph <span class="math notranslate nohighlight">\(G = (V, E)\)</span> with random adjacency matrix <span class="math notranslate nohighlight">\(A = (A_{i,j}) \in \{0,1\}^{n \times n}\)</span>. This model is known as an inhomogeneous Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{inhomogeneous Erdős-Rényi random graph}\xdi\)</span>.</p>
<p>Observe that</p>
<div class="math notranslate nohighlight">
\[
\E[A_{i,j}]
= 1 \cdot m_{i,j} + 0 \cdot (1 - m_{i,j})
= m_{i,j}.
\]</div>
<p>Indeed each entry <span class="math notranslate nohighlight">\(A_{i,j}\)</span> is a Bernoulli random variable with success probability <span class="math notranslate nohighlight">\(m_{i,j}\)</span>. In other words, in matrix form, we have</p>
<div class="math notranslate nohighlight">
\[
\E[A]
= M,
\]</div>
<p>that is, <span class="math notranslate nohighlight">\(M\)</span> is the expected adjacency matrix. Note in particular that <span class="math notranslate nohighlight">\(M\)</span> is deterministic while <span class="math notranslate nohighlight">\(A\)</span> is random (which is why we use lowercase entries for <span class="math notranslate nohighlight">\(M\)</span> but uppercase entries for <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>An important special case is obtained when <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i} = p \in (0,1)\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span> and <span class="math notranslate nohighlight">\(m_{k,k} = 0\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>. That is, each possible edge between two distinct vertices is present with the same probability <span class="math notranslate nohighlight">\(p\)</span>. This model is known simply as an Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{Erdős-Rényi random graph}\xdi\)</span>. Put differently,</p>
<div class="math notranslate nohighlight">
\[
\E[A] = M = p (J - I_{n \times n}), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(J \in \mathbb{R}^{n \times n}\)</span> is the all-one matrix. In this calculation, we subtract the identity matrix to account for the fact that the diagonal is <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>The properties of this model are very well-studied. We give a couple of examples next. For an event <span class="math notranslate nohighlight">\(\mathcal{F}\)</span>, the indicator random variable <span class="math notranslate nohighlight">\(\mathbf{1}_{\mathcal{F}}\)</span> is <span class="math notranslate nohighlight">\(1\)</span> if <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> occurs, and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<p><strong>EXAMPLE:</strong> Let <span class="math notranslate nohighlight">\(G = (V, E)\)</span> be an ER graph with <span class="math notranslate nohighlight">\(n\)</span> vertices. The parameter <span class="math notranslate nohighlight">\(p\)</span> can be interpreted as an edge density. Indeed, let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|E|]
&amp;= \E \left[\sum_{i &lt; j} \mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \sum_{i &lt; j} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \binom{n}{2} p.
\end{align*}\]</div>
<p>Or, put differently, we have shown that the expected edge density <span class="math notranslate nohighlight">\(\E\left[|E|/\binom{n}{2}\right]\)</span> is <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>A similar calculation gives the expected number of triangles. Denote by <span class="math notranslate nohighlight">\(T_3\)</span> the number of triangles in <span class="math notranslate nohighlight">\(G\)</span>, that is, the number of triples <span class="math notranslate nohighlight">\(i, j , k\)</span> of distinct vertices such that <span class="math notranslate nohighlight">\(\{i,j\}, \{j,k\}, \{i,k\} \in E\)</span> (i.e., all edges between them are present). Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|T_3|]
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\}, \{j,k\}, \{i,k\} \in E}\right]\\
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\} \in E}
\mathbf{1}_{\{j,k\} \in E} \mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \sum_{i &lt; j &lt; k} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]
\E \left[\mathbf{1}_{\{j,k\} \in E}\right] \E\left[\mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \binom{n}{3} p^3.
\end{align*}\]</div>
<p>We used the independence of the edges on the third line. Or, put differently, we have shown that the expected triangle density <span class="math notranslate nohighlight">\(\E\left[|T_3|/\binom{n}{3}\right]\)</span> is <span class="math notranslate nohighlight">\(p^3\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We implement the generation of an inhomogeneous ER graph using NetworkX. We first initialize a pseudorandom number generator <code class="docutils literal notranslate"><span class="pre">rng</span></code>. To determine whether an edge is present between <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span></code>, we generate a uniform random variable <code class="docutils literal notranslate"><span class="pre">rng.random()</span></code> (see <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.random</span></code></a>) and add the edge with <code class="docutils literal notranslate"><span class="pre">G.add_edge(i,</span> <span class="pre">j)</span></code> if the random variable is <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">M[i,</span> <span class="pre">j]</span></code> – an event which indeed occurs with the desired probability (check it!).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>

    <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]:</span>
                <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">G</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We generate probabilities <span class="math notranslate nohighlight">\(m_{i,j}\)</span> uniformly at random between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">])</span>
<span class="n">M</span> <span class="o">=</span> <span class="p">(</span><span class="n">M</span> <span class="o">+</span> <span class="n">M</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># ensures symmetry of M (why?)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the resulting graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a5a1fbd0498f23ac9641301349d2049a81e0c0429cbc15d654f9a3d72005ae43.png" src="../Images/c257b8bf58fbbcb0fd5cc44a281cb855.png" data-original-src="https://mmids-textbook.github.io/_images/a5a1fbd0498f23ac9641301349d2049a81e0c0429cbc15d654f9a3d72005ae43.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following subroutine generates an ER graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To confirm our previous calculations, below is the implementation of a routine to estimate the edge density for an ER graph with a fixed parameter <span class="math notranslate nohighlight">\(p\)</span>. Recall that the edge density is defined as the number of edges present divided by the number of possible edges (i.e., the number of pairs of distinct vertices). The routine takes advantage of the <em>Law of Large Numbers</em> by generating a large number of sample graphs, computing their edge density, and then taking the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">total_edges</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_possible_edges</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="n">total_edges</span> <span class="o">+=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span>
    
    <span class="n">average_edges</span> <span class="o">=</span> <span class="n">total_edges</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="n">edge_density</span> <span class="o">=</span> <span class="n">average_edges</span> <span class="o">/</span> <span class="n">total_possible_edges</span>
    <span class="k">return</span> <span class="n">edge_density</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> On a small example, we indeed get that the edge density is roughly <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">estimated_density</span> <span class="o">=</span> <span class="n">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Estimated edge density for an ER graph with n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> and p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">estimated_density</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Estimated edge density for an ER graph with n=10 and p=0.3: 0.3004888888888889
</pre></div>
</div>
</div>
</div>
<p><strong>TRY IT!</strong> Modify the code above to estimate the density of triangles. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>When <span class="math notranslate nohighlight">\(n\)</span>, the number of vertices, is large, random graphs tend to exhibit large-scale emergent behavior. One classical example involves the probability of being connected in an ER graph. To illustrate, below is code to estimate that probability over a range of edge densities <span class="math notranslate nohighlight">\(p\)</span> (with help from Claude and ChatGPT).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">connected_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">is_connected</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="n">connected_count</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">connected_probability</span> <span class="o">=</span> <span class="n">connected_count</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="k">return</span> <span class="n">connected_probability</span>

<span class="k">def</span> <span class="nf">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_values</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
        <span class="n">probabilities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_values</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$p$'</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated probability of being connected'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We run the code for <code class="docutils literal notranslate"><span class="pre">n</span></code> equal to <code class="docutils literal notranslate"><span class="pre">100</span></code>. What do you observe?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/04efd601c9047c499cb95d5acf06604fe4f0dda7ba32a3531fb3632e84836f7f.png" src="../Images/a6ba5ed9893af4c1125c90607e734d1d.png" data-original-src="https://mmids-textbook.github.io/_images/04efd601c9047c499cb95d5acf06604fe4f0dda7ba32a3531fb3632e84836f7f.png"/>
</div>
</div>
<p>The probability of being connected starts out at <span class="math notranslate nohighlight">\(0\)</span> when <span class="math notranslate nohighlight">\(p\)</span> is small, which is not surprising since it implies that the graph has a relatively small number of edges. But then that probability increases – rapidly – to <span class="math notranslate nohighlight">\(1\)</span> as <span class="math notranslate nohighlight">\(p\)</span> crosses a threshold. This is referred to as the phase transition of the ER graph.</p>
<p>It can be shown rigorously that the transition occurs at roughly <span class="math notranslate nohighlight">\(p = \log n/n\)</span>. That is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>0.04605170185988092
</pre></div>
</div>
</div>
</div>
<p>which is consistent with the plot.</p>
<p><strong>TRY IT!</strong> Taking a larger <code class="docutils literal notranslate"><span class="pre">n</span></code> would produce a sharper transition. Try it for yourself. Also try drawing one random sample for increasing values of <span class="math notranslate nohighlight">\(p\)</span> around the threshold. What do you observe? (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><strong>TRY IT!</strong> Many other properties exhibit such sharp threshold behavior. Modify the code to to estimate the probability that a clique of size 4 exists in the graph. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
</section>
<section id="stochastic-blockmodel">
<h2><span class="section-number">5.6.2. </span>Stochastic blockmodel<a class="headerlink" href="#stochastic-blockmodel" title="Link to this heading">#</a></h2>
<p>We return to our original motivation. How can we create a random graph with a planted partition? The stochastic blockmodel (SBM) is such a model. Here we imagine that <span class="math notranslate nohighlight">\([n]\)</span> is partitioned into two disjoint sets <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span>, referred to as blocks. We set <span class="math notranslate nohighlight">\(z(i) = j\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is in block <span class="math notranslate nohighlight">\(C_j\)</span>. We also encode the block assignment with a matrix <span class="math notranslate nohighlight">\(Z \in \{0,1\}^{n \times 2}\)</span> where row <span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(\mathbf{e}_j^T\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(b_{i,j} \in [0,1]\)</span> be the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge, independently of all other edges. We enforce <span class="math notranslate nohighlight">\(b_{1,2} = b_{2,1}\)</span>. We collect these probabilities in the following matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
B = \begin{pmatrix}
b_{1,1} &amp; b_{1,2}\\
b_{2,1} &amp; b_{2,2}
\end{pmatrix}.
\end{split}\]</div>
<p>By our assumption, the matrix <span class="math notranslate nohighlight">\(B\)</span> is symmetric.</p>
<p>We typically take</p>
<div class="math notranslate nohighlight">
\[
\min\{b_{1,1}, b_{2,2}\} &gt; b_{1,2},
\]</div>
<p>that is, edges are more likely between vertices in the same block than between vertices in different blocks. That corresponds to the intuition that, in social networks or other types of networks, members of the same group (i.e., block) tend to interact more frequently with each other than with members of different groups. For instance, friends within the same social circle are more likely to be connected than with people outside their circle. That is related to the concept of homophily which describes the tendency of individuals to associate and bond with similar others.</p>
<p>This is a special case of the inhomogeneous ER graph model. What is the corresponding <span class="math notranslate nohighlight">\(M\)</span> matrix? Note that, for each pair of vertex <span class="math notranslate nohighlight">\(1 \leq i &lt; j \leq n\)</span>, edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present in <span class="math notranslate nohighlight">\(E\)</span> with probability</p>
<div class="math notranslate nohighlight">
\[
m_{i,j}
:= b_{z(i), z(j)}
= Z_{i,\cdot} B Z_{j,\cdot}^T
\]</div>
<p>where recall that <span class="math notranslate nohighlight">\(Z_{i,\cdot}\)</span> is row <span class="math notranslate nohighlight">\(i\)</span> of matrix <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>In matrix form, this is saying that</p>
<div class="math notranslate nohighlight">
\[
M = Z B Z^T.
\]</div>
<p>So, given <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>, we can generate an SBM as a special case of an inhomogeneous ER graph.</p>
<p>We implement the SBM model. We use blocks numbered <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>

    <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">B</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span>
    
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We first pick a block assignment at random. Specifically, blocks are assigned randomly with <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.choice</span></code></a>. It produces two blocks by assigning each vertex with equal probability to either block, independently of all other choices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the graph with colored nodes based on block assignments. The “good” cut is clearly visible in this layout.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'rainbow'</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d1593cbfb628739bb8775c68e246ec22340e23b00f2eb233dba14c8732005001.png" src="../Images/201aa17bc70e38e3e3d759bd8e23f659.png" data-original-src="https://mmids-textbook.github.io/_images/d1593cbfb628739bb8775c68e246ec22340e23b00f2eb233dba14c8732005001.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>We introduce a subroutine which assigns blocks at random as follows. Let <span class="math notranslate nohighlight">\(\beta_1, \beta_2 \in [0,1]\)</span> with <span class="math notranslate nohighlight">\(\beta_1 + \beta_2 = 1\)</span> be the probability that a vertex belongs respectively to block <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(2\)</span>. We collect these probabilities in the following vector</p>
<div class="math notranslate nohighlight">
\[
\bbeta = (\beta_1, \beta_2).
\]</div>
<p>We pick block <span class="math notranslate nohighlight">\(z(i) \in \{1,2\}\)</span> for each vertex <span class="math notranslate nohighlight">\(1 \leq i \leq n\)</span> according to the distribution <span class="math notranslate nohighlight">\(\bbeta\)</span>, independently of all other vertices <span class="math notranslate nohighlight">\(\neq i\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Observe that the blocks are more unbalanced this time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">rainbow</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e6e9218d9f5e632ff4be76353cc005764f4073c93101c433f9f5d807555d263b.png" src="../Images/5a952a9ded70a63b063836a0fbfee569.png" data-original-src="https://mmids-textbook.github.io/_images/e6e9218d9f5e632ff4be76353cc005764f4073c93101c433f9f5d807555d263b.png"/>
</div>
</div>
<p>To test our spectral partitioning algorithm, we run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>, which indeed recovers the ground truth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">mmids</span><span class="o">.</span><span class="n">viz_cut</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/15d02996eaea304f0dcdfdd6ab0c5fbec79eb564e0310ff803ea4e6321a23e34.png" src="../Images/c37ee75c9c1055f8bebc79a73fe4606f.png" data-original-src="https://mmids-textbook.github.io/_images/15d02996eaea304f0dcdfdd6ab0c5fbec79eb564e0310ff803ea4e6321a23e34.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following code computes the fraction of incorrectly assigned vertices. Note that it considers <em>two</em> assignments corresponding to swapping the labels <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> which cannot be inferred.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">inferred_s</span><span class="p">,</span> <span class="n">inferred_sc</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">)</span>
    
    <span class="n">inferred_assignments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_s</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_sc</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">incorrect_assignments_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">!=</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">incorrect_assignments_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">==</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">incorrect_assignments_1</span><span class="p">,</span> <span class="n">incorrect_assignments_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We confirm on our previous example that the ground truth was perfectly recovered.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of incorrectly assigned vertices: 0.0
</pre></div>
</div>
</div>
</div>
<p>One expects that the ground truth is harder to recover if the probability of an edge between blocks is close to that within blocks, which makes the community structure more murky. To test this hypothesis, we modify our previous example by significantly increasing the inter-block probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>. It recovers the ground truth only partially this time.</p>
<div class="cell tag_colab-keep docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of incorrectly assigned vertices: 0.22
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> In a stochastic blockmodel (SBM), what does <span class="math notranslate nohighlight">\(b_{i,j}\)</span> represent?</p>
<p>a) The probability that vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>b) The probability that there is an edge between any two vertices.</p>
<p>c) The probability that there is an edge between a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>d) The weight of the edge between vertex <span class="math notranslate nohighlight">\(i\)</span> and vertex <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p><strong>2</strong> Consider the following graph generated using NetworkX in Python:</p>
<p><img alt="Graph" src="../Images/3b340cd5c7599903fa112649b21082f5.png" data-original-src="https://mmids-textbook.github.io/_images/quiz-5_6-graph1.png"/></p>
<p>Which of the following models could have produced this graph?</p>
<p>a) An Erdős-Rényi (ER) random graph.</p>
<p>b) A stochastic blockmodel (SBM) with two communities.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with two equal-sized communities (i.e., where in addition <span class="math notranslate nohighlight">\(b_{1,1} = b_{2,2}\)</span>).</p>
<p>d) All of the above.</p>
<p><strong>3</strong> Consider an Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p\)</span>. The expected number of edges in the graph is:</p>
<p>a) <span class="math notranslate nohighlight">\(n^2p\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\binom{n}{2}p\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(np\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(n(n-1)p\)</span></p>
<p><strong>4</strong> Consider the following Python code snippet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.4</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</pre></div>
</div>
<p>Which of the following best describes the graph generated by this code?</p>
<p>a) An Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>b) A stochastic blockmodel (SBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and intra-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and inter-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>d) An inhomogeneous Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probabilities given by a matrix <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p><strong>5</strong> In the stochastic blockmodel, what happens to the difficulty of recovering the community structure if the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>?</p>
<p>a) It becomes easier.</p>
<p>b) It remains unchanged.</p>
<p>c) It becomes harder.</p>
<p>d) None of the above.</p>
<p>Answer for 1: c. Justification: The text defines <span class="math notranslate nohighlight">\(b_{i,j}\)</span> as “the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge.”</p>
<p>Answer for 2: d. Justification: The graph consists of two cliques (complete subgraphs) of size 3 each, one with vertices 0, 1, and 2 and another with vertices 3, 4, and 5. There are no edges between the two cliques. It has a positive probability of occurring under any ER, SBM, or SSBM random graph model where all edge probabilities are in <span class="math notranslate nohighlight">\((0,1)\)</span>.</p>
<p>Answer for 3: b. Justification: The text states: “Let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have <span class="math notranslate nohighlight">\(\mathbb{E}[|E|] = \mathbb{E} [\sum_{i&lt;j} \mathbf{1}_{\{i,j\} \in E}] = \sum_{i&lt;j} \mathbb{E} [\mathbf{1}_{\{i,j\} \in E}] = \binom{n}{2}p\)</span>.”</p>
<p>Answer for 4: a. Justification: The code generates an ER random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices, where each edge is included independently with probability <span class="math notranslate nohighlight">\(p=0.4\)</span>. This is evident from the nested loop structure and the condition <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">rng.random()</span> <span class="pre">&lt;</span> <span class="pre">p</span></code> for adding edges.</p>
<p>Answer for 5: c. Justification: When the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>, the community structure becomes harder to recover because the distinction between the blocks is less clear.</p>
</section>
&#13;

<h2><span class="section-number">5.6.1. </span>Inhomogeneous Erdős-Rényi random graph<a class="headerlink" href="#inhomogeneous-erdos-renyi-random-graph" title="Link to this heading">#</a></h2>
<p>A simple approach to generating a random graph is to include each edge <em>independently</em>. More precisely, let <span class="math notranslate nohighlight">\(V = [n]\)</span> be a set of <span class="math notranslate nohighlight">\(n\)</span> vertices. Consider a symmetric matrix <span class="math notranslate nohighlight">\(M = (m_{i,j}) \in [0,1]^{n \times n}\)</span> with arbitrary entries in <span class="math notranslate nohighlight">\([0,1]\)</span>. The entry <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i}\)</span> is the probability that edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present (i.e., that <span class="math notranslate nohighlight">\(\{i,j\} \in E\)</span>), independently of all other edges. The outcome is a random graph <span class="math notranslate nohighlight">\(G = (V, E)\)</span> with random adjacency matrix <span class="math notranslate nohighlight">\(A = (A_{i,j}) \in \{0,1\}^{n \times n}\)</span>. This model is known as an inhomogeneous Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{inhomogeneous Erdős-Rényi random graph}\xdi\)</span>.</p>
<p>Observe that</p>
<div class="math notranslate nohighlight">
\[
\E[A_{i,j}]
= 1 \cdot m_{i,j} + 0 \cdot (1 - m_{i,j})
= m_{i,j}.
\]</div>
<p>Indeed each entry <span class="math notranslate nohighlight">\(A_{i,j}\)</span> is a Bernoulli random variable with success probability <span class="math notranslate nohighlight">\(m_{i,j}\)</span>. In other words, in matrix form, we have</p>
<div class="math notranslate nohighlight">
\[
\E[A]
= M,
\]</div>
<p>that is, <span class="math notranslate nohighlight">\(M\)</span> is the expected adjacency matrix. Note in particular that <span class="math notranslate nohighlight">\(M\)</span> is deterministic while <span class="math notranslate nohighlight">\(A\)</span> is random (which is why we use lowercase entries for <span class="math notranslate nohighlight">\(M\)</span> but uppercase entries for <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>An important special case is obtained when <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i} = p \in (0,1)\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span> and <span class="math notranslate nohighlight">\(m_{k,k} = 0\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>. That is, each possible edge between two distinct vertices is present with the same probability <span class="math notranslate nohighlight">\(p\)</span>. This model is known simply as an Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{Erdős-Rényi random graph}\xdi\)</span>. Put differently,</p>
<div class="math notranslate nohighlight">
\[
\E[A] = M = p (J - I_{n \times n}), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(J \in \mathbb{R}^{n \times n}\)</span> is the all-one matrix. In this calculation, we subtract the identity matrix to account for the fact that the diagonal is <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>The properties of this model are very well-studied. We give a couple of examples next. For an event <span class="math notranslate nohighlight">\(\mathcal{F}\)</span>, the indicator random variable <span class="math notranslate nohighlight">\(\mathbf{1}_{\mathcal{F}}\)</span> is <span class="math notranslate nohighlight">\(1\)</span> if <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> occurs, and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<p><strong>EXAMPLE:</strong> Let <span class="math notranslate nohighlight">\(G = (V, E)\)</span> be an ER graph with <span class="math notranslate nohighlight">\(n\)</span> vertices. The parameter <span class="math notranslate nohighlight">\(p\)</span> can be interpreted as an edge density. Indeed, let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|E|]
&amp;= \E \left[\sum_{i &lt; j} \mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \sum_{i &lt; j} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \binom{n}{2} p.
\end{align*}\]</div>
<p>Or, put differently, we have shown that the expected edge density <span class="math notranslate nohighlight">\(\E\left[|E|/\binom{n}{2}\right]\)</span> is <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>A similar calculation gives the expected number of triangles. Denote by <span class="math notranslate nohighlight">\(T_3\)</span> the number of triangles in <span class="math notranslate nohighlight">\(G\)</span>, that is, the number of triples <span class="math notranslate nohighlight">\(i, j , k\)</span> of distinct vertices such that <span class="math notranslate nohighlight">\(\{i,j\}, \{j,k\}, \{i,k\} \in E\)</span> (i.e., all edges between them are present). Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|T_3|]
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\}, \{j,k\}, \{i,k\} \in E}\right]\\
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\} \in E}
\mathbf{1}_{\{j,k\} \in E} \mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \sum_{i &lt; j &lt; k} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]
\E \left[\mathbf{1}_{\{j,k\} \in E}\right] \E\left[\mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \binom{n}{3} p^3.
\end{align*}\]</div>
<p>We used the independence of the edges on the third line. Or, put differently, we have shown that the expected triangle density <span class="math notranslate nohighlight">\(\E\left[|T_3|/\binom{n}{3}\right]\)</span> is <span class="math notranslate nohighlight">\(p^3\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We implement the generation of an inhomogeneous ER graph using NetworkX. We first initialize a pseudorandom number generator <code class="docutils literal notranslate"><span class="pre">rng</span></code>. To determine whether an edge is present between <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span></code>, we generate a uniform random variable <code class="docutils literal notranslate"><span class="pre">rng.random()</span></code> (see <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.random</span></code></a>) and add the edge with <code class="docutils literal notranslate"><span class="pre">G.add_edge(i,</span> <span class="pre">j)</span></code> if the random variable is <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">M[i,</span> <span class="pre">j]</span></code> – an event which indeed occurs with the desired probability (check it!).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>

    <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]:</span>
                <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">G</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We generate probabilities <span class="math notranslate nohighlight">\(m_{i,j}\)</span> uniformly at random between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">])</span>
<span class="n">M</span> <span class="o">=</span> <span class="p">(</span><span class="n">M</span> <span class="o">+</span> <span class="n">M</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># ensures symmetry of M (why?)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the resulting graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a5a1fbd0498f23ac9641301349d2049a81e0c0429cbc15d654f9a3d72005ae43.png" src="../Images/c257b8bf58fbbcb0fd5cc44a281cb855.png" data-original-src="https://mmids-textbook.github.io/_images/a5a1fbd0498f23ac9641301349d2049a81e0c0429cbc15d654f9a3d72005ae43.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following subroutine generates an ER graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To confirm our previous calculations, below is the implementation of a routine to estimate the edge density for an ER graph with a fixed parameter <span class="math notranslate nohighlight">\(p\)</span>. Recall that the edge density is defined as the number of edges present divided by the number of possible edges (i.e., the number of pairs of distinct vertices). The routine takes advantage of the <em>Law of Large Numbers</em> by generating a large number of sample graphs, computing their edge density, and then taking the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">total_edges</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_possible_edges</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="n">total_edges</span> <span class="o">+=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span>
    
    <span class="n">average_edges</span> <span class="o">=</span> <span class="n">total_edges</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="n">edge_density</span> <span class="o">=</span> <span class="n">average_edges</span> <span class="o">/</span> <span class="n">total_possible_edges</span>
    <span class="k">return</span> <span class="n">edge_density</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> On a small example, we indeed get that the edge density is roughly <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">estimated_density</span> <span class="o">=</span> <span class="n">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Estimated edge density for an ER graph with n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> and p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">estimated_density</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Estimated edge density for an ER graph with n=10 and p=0.3: 0.3004888888888889
</pre></div>
</div>
</div>
</div>
<p><strong>TRY IT!</strong> Modify the code above to estimate the density of triangles. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>When <span class="math notranslate nohighlight">\(n\)</span>, the number of vertices, is large, random graphs tend to exhibit large-scale emergent behavior. One classical example involves the probability of being connected in an ER graph. To illustrate, below is code to estimate that probability over a range of edge densities <span class="math notranslate nohighlight">\(p\)</span> (with help from Claude and ChatGPT).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">connected_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">is_connected</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="n">connected_count</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">connected_probability</span> <span class="o">=</span> <span class="n">connected_count</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="k">return</span> <span class="n">connected_probability</span>

<span class="k">def</span> <span class="nf">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_values</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
        <span class="n">probabilities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_values</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$p$'</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Estimated probability of being connected'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We run the code for <code class="docutils literal notranslate"><span class="pre">n</span></code> equal to <code class="docutils literal notranslate"><span class="pre">100</span></code>. What do you observe?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/04efd601c9047c499cb95d5acf06604fe4f0dda7ba32a3531fb3632e84836f7f.png" src="../Images/a6ba5ed9893af4c1125c90607e734d1d.png" data-original-src="https://mmids-textbook.github.io/_images/04efd601c9047c499cb95d5acf06604fe4f0dda7ba32a3531fb3632e84836f7f.png"/>
</div>
</div>
<p>The probability of being connected starts out at <span class="math notranslate nohighlight">\(0\)</span> when <span class="math notranslate nohighlight">\(p\)</span> is small, which is not surprising since it implies that the graph has a relatively small number of edges. But then that probability increases – rapidly – to <span class="math notranslate nohighlight">\(1\)</span> as <span class="math notranslate nohighlight">\(p\)</span> crosses a threshold. This is referred to as the phase transition of the ER graph.</p>
<p>It can be shown rigorously that the transition occurs at roughly <span class="math notranslate nohighlight">\(p = \log n/n\)</span>. That is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>0.04605170185988092
</pre></div>
</div>
</div>
</div>
<p>which is consistent with the plot.</p>
<p><strong>TRY IT!</strong> Taking a larger <code class="docutils literal notranslate"><span class="pre">n</span></code> would produce a sharper transition. Try it for yourself. Also try drawing one random sample for increasing values of <span class="math notranslate nohighlight">\(p\)</span> around the threshold. What do you observe? (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><strong>TRY IT!</strong> Many other properties exhibit such sharp threshold behavior. Modify the code to to estimate the probability that a clique of size 4 exists in the graph. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
&#13;

<h2><span class="section-number">5.6.2. </span>Stochastic blockmodel<a class="headerlink" href="#stochastic-blockmodel" title="Link to this heading">#</a></h2>
<p>We return to our original motivation. How can we create a random graph with a planted partition? The stochastic blockmodel (SBM) is such a model. Here we imagine that <span class="math notranslate nohighlight">\([n]\)</span> is partitioned into two disjoint sets <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span>, referred to as blocks. We set <span class="math notranslate nohighlight">\(z(i) = j\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is in block <span class="math notranslate nohighlight">\(C_j\)</span>. We also encode the block assignment with a matrix <span class="math notranslate nohighlight">\(Z \in \{0,1\}^{n \times 2}\)</span> where row <span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(\mathbf{e}_j^T\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(b_{i,j} \in [0,1]\)</span> be the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge, independently of all other edges. We enforce <span class="math notranslate nohighlight">\(b_{1,2} = b_{2,1}\)</span>. We collect these probabilities in the following matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
B = \begin{pmatrix}
b_{1,1} &amp; b_{1,2}\\
b_{2,1} &amp; b_{2,2}
\end{pmatrix}.
\end{split}\]</div>
<p>By our assumption, the matrix <span class="math notranslate nohighlight">\(B\)</span> is symmetric.</p>
<p>We typically take</p>
<div class="math notranslate nohighlight">
\[
\min\{b_{1,1}, b_{2,2}\} &gt; b_{1,2},
\]</div>
<p>that is, edges are more likely between vertices in the same block than between vertices in different blocks. That corresponds to the intuition that, in social networks or other types of networks, members of the same group (i.e., block) tend to interact more frequently with each other than with members of different groups. For instance, friends within the same social circle are more likely to be connected than with people outside their circle. That is related to the concept of homophily which describes the tendency of individuals to associate and bond with similar others.</p>
<p>This is a special case of the inhomogeneous ER graph model. What is the corresponding <span class="math notranslate nohighlight">\(M\)</span> matrix? Note that, for each pair of vertex <span class="math notranslate nohighlight">\(1 \leq i &lt; j \leq n\)</span>, edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present in <span class="math notranslate nohighlight">\(E\)</span> with probability</p>
<div class="math notranslate nohighlight">
\[
m_{i,j}
:= b_{z(i), z(j)}
= Z_{i,\cdot} B Z_{j,\cdot}^T
\]</div>
<p>where recall that <span class="math notranslate nohighlight">\(Z_{i,\cdot}\)</span> is row <span class="math notranslate nohighlight">\(i\)</span> of matrix <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>In matrix form, this is saying that</p>
<div class="math notranslate nohighlight">
\[
M = Z B Z^T.
\]</div>
<p>So, given <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>, we can generate an SBM as a special case of an inhomogeneous ER graph.</p>
<p>We implement the SBM model. We use blocks numbered <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>

    <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">B</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span>
    
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We first pick a block assignment at random. Specifically, blocks are assigned randomly with <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.choice</span></code></a>. It produces two blocks by assigning each vertex with equal probability to either block, independently of all other choices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the graph with colored nodes based on block assignments. The “good” cut is clearly visible in this layout.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'rainbow'</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d1593cbfb628739bb8775c68e246ec22340e23b00f2eb233dba14c8732005001.png" src="../Images/201aa17bc70e38e3e3d759bd8e23f659.png" data-original-src="https://mmids-textbook.github.io/_images/d1593cbfb628739bb8775c68e246ec22340e23b00f2eb233dba14c8732005001.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>We introduce a subroutine which assigns blocks at random as follows. Let <span class="math notranslate nohighlight">\(\beta_1, \beta_2 \in [0,1]\)</span> with <span class="math notranslate nohighlight">\(\beta_1 + \beta_2 = 1\)</span> be the probability that a vertex belongs respectively to block <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(2\)</span>. We collect these probabilities in the following vector</p>
<div class="math notranslate nohighlight">
\[
\bbeta = (\beta_1, \beta_2).
\]</div>
<p>We pick block <span class="math notranslate nohighlight">\(z(i) \in \{1,2\}\)</span> for each vertex <span class="math notranslate nohighlight">\(1 \leq i \leq n\)</span> according to the distribution <span class="math notranslate nohighlight">\(\bbeta\)</span>, independently of all other vertices <span class="math notranslate nohighlight">\(\neq i\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Observe that the blocks are more unbalanced this time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">rainbow</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e6e9218d9f5e632ff4be76353cc005764f4073c93101c433f9f5d807555d263b.png" src="../Images/5a952a9ded70a63b063836a0fbfee569.png" data-original-src="https://mmids-textbook.github.io/_images/e6e9218d9f5e632ff4be76353cc005764f4073c93101c433f9f5d807555d263b.png"/>
</div>
</div>
<p>To test our spectral partitioning algorithm, we run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>, which indeed recovers the ground truth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">mmids</span><span class="o">.</span><span class="n">viz_cut</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/15d02996eaea304f0dcdfdd6ab0c5fbec79eb564e0310ff803ea4e6321a23e34.png" src="../Images/c37ee75c9c1055f8bebc79a73fe4606f.png" data-original-src="https://mmids-textbook.github.io/_images/15d02996eaea304f0dcdfdd6ab0c5fbec79eb564e0310ff803ea4e6321a23e34.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following code computes the fraction of incorrectly assigned vertices. Note that it considers <em>two</em> assignments corresponding to swapping the labels <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> which cannot be inferred.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">inferred_s</span><span class="p">,</span> <span class="n">inferred_sc</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">)</span>
    
    <span class="n">inferred_assignments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_s</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_sc</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">incorrect_assignments_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">!=</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">incorrect_assignments_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">==</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">incorrect_assignments_1</span><span class="p">,</span> <span class="n">incorrect_assignments_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We confirm on our previous example that the ground truth was perfectly recovered.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of incorrectly assigned vertices: 0.0
</pre></div>
</div>
</div>
</div>
<p>One expects that the ground truth is harder to recover if the probability of an edge between blocks is close to that within blocks, which makes the community structure more murky. To test this hypothesis, we modify our previous example by significantly increasing the inter-block probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>. It recovers the ground truth only partially this time.</p>
<div class="cell tag_colab-keep docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>Fraction of incorrectly assigned vertices: 0.22
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> In a stochastic blockmodel (SBM), what does <span class="math notranslate nohighlight">\(b_{i,j}\)</span> represent?</p>
<p>a) The probability that vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>b) The probability that there is an edge between any two vertices.</p>
<p>c) The probability that there is an edge between a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>d) The weight of the edge between vertex <span class="math notranslate nohighlight">\(i\)</span> and vertex <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p><strong>2</strong> Consider the following graph generated using NetworkX in Python:</p>
<p><img alt="Graph" src="../Images/3b340cd5c7599903fa112649b21082f5.png" data-original-src="https://mmids-textbook.github.io/_images/quiz-5_6-graph1.png"/></p>
<p>Which of the following models could have produced this graph?</p>
<p>a) An Erdős-Rényi (ER) random graph.</p>
<p>b) A stochastic blockmodel (SBM) with two communities.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with two equal-sized communities (i.e., where in addition <span class="math notranslate nohighlight">\(b_{1,1} = b_{2,2}\)</span>).</p>
<p>d) All of the above.</p>
<p><strong>3</strong> Consider an Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p\)</span>. The expected number of edges in the graph is:</p>
<p>a) <span class="math notranslate nohighlight">\(n^2p\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\binom{n}{2}p\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(np\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(n(n-1)p\)</span></p>
<p><strong>4</strong> Consider the following Python code snippet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span/><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.4</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</pre></div>
</div>
<p>Which of the following best describes the graph generated by this code?</p>
<p>a) An Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>b) A stochastic blockmodel (SBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and intra-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and inter-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>d) An inhomogeneous Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probabilities given by a matrix <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p><strong>5</strong> In the stochastic blockmodel, what happens to the difficulty of recovering the community structure if the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>?</p>
<p>a) It becomes easier.</p>
<p>b) It remains unchanged.</p>
<p>c) It becomes harder.</p>
<p>d) None of the above.</p>
<p>Answer for 1: c. Justification: The text defines <span class="math notranslate nohighlight">\(b_{i,j}\)</span> as “the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge.”</p>
<p>Answer for 2: d. Justification: The graph consists of two cliques (complete subgraphs) of size 3 each, one with vertices 0, 1, and 2 and another with vertices 3, 4, and 5. There are no edges between the two cliques. It has a positive probability of occurring under any ER, SBM, or SSBM random graph model where all edge probabilities are in <span class="math notranslate nohighlight">\((0,1)\)</span>.</p>
<p>Answer for 3: b. Justification: The text states: “Let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have <span class="math notranslate nohighlight">\(\mathbb{E}[|E|] = \mathbb{E} [\sum_{i&lt;j} \mathbf{1}_{\{i,j\} \in E}] = \sum_{i&lt;j} \mathbb{E} [\mathbf{1}_{\{i,j\} \in E}] = \binom{n}{2}p\)</span>.”</p>
<p>Answer for 4: a. Justification: The code generates an ER random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices, where each edge is included independently with probability <span class="math notranslate nohighlight">\(p=0.4\)</span>. This is evident from the nested loop structure and the condition <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">rng.random()</span> <span class="pre">&lt;</span> <span class="pre">p</span></code> for adding edges.</p>
<p>Answer for 5: c. Justification: When the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>, the community structure becomes harder to recover because the distinction between the blocks is less clear.</p>
    
</body>
</html>