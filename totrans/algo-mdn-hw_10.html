<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Machine Code Layout</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Machine Code Layout</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/architecture/layout/">https://en.algorithmica.org/hpc/architecture/layout/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>Computer engineers like to mentally split the <a href="/hpc/pipelining">pipeline of a CPU</a> into two parts: the <em>front-end</em>, where instructions are fetched from memory and decoded, and the <em>back-end</em>, where they are scheduled and finally executed. Typically, the performance is bottlenecked by the execution stage, and for this reason, most of our efforts in this book are going to be spent towards optimizing around the back-end.</p><p>But sometimes the reverse can happen when the front-end doesn’t feed instructions to the back-end fast enough to saturate it. This can happen for many reasons, all ultimately having something to do with how the machine code is laid out in memory, and affect performance in anecdotal ways, such as removing unused code, swapping “if” branches, or even changing the order of function declarations causing performance to either improve or deteriorate.</p><span class="anchor" id="cpu-front-end"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/architecture/layout/#cpu-front-end">#</a>CPU Front-End</h3><p>Before the machine code gets transformed into instructions, and the CPU understands what the programmer wants, it first needs to go through two important stages that we are interested in: <em>fetch</em> and <em>decode</em>.</p><p>During the <strong>fetch</strong> stage, the CPU simply loads a fixed-size chunk of bytes from the main memory, which contains the binary encodings of some number of instructions. This block size is typically 32 bytes on x86, although it may vary on different machines. An important nuance is that this block has to be <a href="/hpc/cpu-cache/cache-lines">aligned</a>: the address of the chunk must be multiple of its size (32B, in our case).</p><p>Next comes the <strong>decode</strong> stage: the CPU looks at this chunk of bytes, discards everything that comes before the instruction pointer, and splits the rest of them into instructions. Machine instructions are encoded using a variable number of bytes: something simple and very common like <code>inc rax</code> takes one byte, while some obscure instruction with encoded constants and behavior-modifying prefixes may take up to 15. So, from a 32-byte block, a variable number of instructions may be decoded, but no more than a certain machine-dependent limit called the <em>decode width</em>. On my CPU (a <a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2">Zen 2</a>), the decode width is 4, which means that on each cycle, up to 4 instructions can be decoded and passed to the next stage.</p><p>The stages work in a pipelined fashion: if the CPU can tell (or <a href="/hpc/pipelining/branching/">predict</a>) which instruction block it needs next, then the fetch stage doesn’t wait for the last instruction in the current block to be decoded and loads the next one right away.</p><span class="anchor" id="code-alignment"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/architecture/layout/#code-alignment">#</a>Code Alignment</h3><p>Other things being equal, compilers typically prefer instructions with shorter machine code, because this way more instructions can fit in a single 32B fetch block, and also because it reduces the size of the binary. But sometimes the reverse is prefereable, due to the fact that the fetched instructions’ blocks must be aligned.</p><p>Imagine that you need to execute an instruction sequence that starts on the last byte of a 32B-aligned block. You may be able to execute the first instruction without additional delay, but for the subsequent ones, you have to wait for one additional cycle to do another instruction fetch. If the code block was aligned on a 32B boundary, then up to 4 instructions could be decoded and then executed concurrently (unless they are extra long or interdependent).</p><p>Having this in mind, compilers often do a seemingly harmful optimization: they sometimes prefer instructions with longer machine codes, and even insert dummy instructions that do nothing<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> in order to get key jump locations aligned on a suitable power-of-two boundary.</p><p>In GCC, you can use <code>-falign-labels=n</code> flag to specify a particular alignment policy, <a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">replacing</a> <code>-labels</code> with <code>-function</code>, <code>-loops</code>, or <code>-jumps</code> if you want to be more selective. On <code>-O2</code> and <code>-O3</code> levels of optimization, it is enabled by default — without setting a particular alignment, in which case it uses a (usually reasonable) machine-dependent default value.</p><span class="anchor" id="instruction-cache"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/architecture/layout/#instruction-cache">#</a>Instruction Cache</h3><p>The instructions are stored and fetched using largely the same <a href="/hpc/cpu-cache">memory system</a> as for the data, except maybe the lower layers of cache are replaced with a separate <em>instruction cache</em> (because you wouldn’t want a random data read to kick out the code that processes it).</p><p>The instruction cache is crucial in situations when you either:</p><ul><li>don’t know what instructions you are going to execute next, and need to fetch the next block with <a href="/hpc/cpu-cache/latency">low latency</a>,</li><li>or are executing a long sequence of verbose-but-quick-to-process instructions, and need <a href="/hpc/cpu-cache/bandwidth">high bandwidth</a>.</li></ul><p>The memory system can therefore become the bottleneck for programs with large machine code. This consideration limits the applicability of the optimization techniques we’ve previously discussed:</p><ul><li><a href="../functions">Inlining functions</a> is not always optimal, because it reduces code sharing and increases the binary size, requiring more instruction cache.</li><li><a href="../loops">Unrolling loops</a> is only beneficial up to some extent, even if the number of iterations is known during compile time: at some point, the CPU would have to fetch both instructions and data from the main memory, in which case it will likely be bottlenecked by the memory bandwidth.</li><li>Huge <a href="#code-alignment">code alignments</a> increase the binary size, again requiring more instruction cache. Spending one more cycle on fetch is a minor penalty compared to missing the cache and waiting for the instructions to be fetched from the main memory.</li></ul><p>Another aspect is that placing frequently used instruction sequences on the same <a href="/hpc/cpu-cache/cache-lines">cache lines</a> and <a href="/hpc/cpu-cache/paging">memory pages</a> improves <a href="/hpc/external-memory/locality">cache locality</a>. To improve instruction cache utilization, you should group hot code with hot code and cold code with cold code, and remove dead (unused) code if possible. If you want to explore this idea further, check out Facebook’s <a href="https://engineering.fb.com/2018/06/19/data-infrastructure/accelerate-large-scale-applications-with-bolt/">Binary Optimization and Layout Tool</a>, which was recently <a href="https://github.com/llvm/llvm-project/commit/4c106cfdf7cf7eec861ad3983a3dd9a9e8f3a8ae">merged</a> into LLVM.</p><span class="anchor" id="unequal-branches"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/architecture/layout/#unequal-branches">#</a>Unequal Branches</h3><p>Suppose that for some reason you need a helper function that calculates the length of an integer interval. It takes two arguments, $x$ and $y$, but for convenience, it may correspond to either $[x, y]$ or $[y, x]$, depending on which one is non-empty. In plain C, you would probably write something like this:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">length</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>In x86 assembly, there is a lot more variability to how you can implement it, noticeably impacting performance. Let’s start with trying to map this code directly into assembly:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl"><span class="nl">length:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmp</span>  <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jle</span>  <span class="nv">less</span>
</span></span><span class="line"><span class="cl">    <span class="c1">; x &gt; y</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>  <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">eax</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl"><span class="nl">done:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">ret</span>
</span></span><span class="line"><span class="cl"><span class="nl">less:</span>
</span></span><span class="line"><span class="cl">    <span class="c1">; x &lt;= y</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>  <span class="nb">esi</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">eax</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jmp</span>  <span class="nv">done</span>
</span></span></code></pre></div><p>While the initial C code seems very symmetrical, the assembly version isn’t. This results in an interesting quirk that one branch can be executed slightly faster than the other: if <code>x &gt; y</code>, then the CPU can just execute the 5 instructions between <code>cmp</code> and <code>ret</code>, which, if the function is aligned, are all going to be fetched in one go; while in case of <code>x &lt;= y</code>, two more jumps are required.</p><p>It may be reasonable to assume that the <code>x &gt; y</code> case is <em>unlikely</em> (why would anyone calculate the length of an inverted interval?), more like an exception that mostly never happens. We can detect this case, and simply swap <code>x</code> and <code>y</code>:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">length</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">swap</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>The assembly would go like this, as it typically does for the if-without-else patterns:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl"><span class="nl">length:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmp</span>  <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jle</span>  <span class="nv">normal</span>     <span class="c1">; if x &lt;= y, no swap is needed, and we can skip the xchg</span>
</span></span><span class="line"><span class="cl">    <span class="nf">xchg</span> <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl"><span class="nl">normal:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>  <span class="nb">esi</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">eax</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">ret</span>
</span></span></code></pre></div><p>The total instruction length is 6 now, down from 8. But it is still not quite optimized for our assumed case: if we think that <code>x &gt; y</code> never happens, then we are wasteful when loading the <code>xchg edi, esi</code> instruction that is never going to be executed. We can solve this by moving it outside the normal execution path:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl"><span class="nl">length:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmp</span>  <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jg</span>   <span class="nv">swap</span>
</span></span><span class="line"><span class="cl"><span class="nl">normal:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>  <span class="nb">esi</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">eax</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">ret</span>
</span></span><span class="line"><span class="cl"><span class="nl">swap:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">xchg</span> <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jmp</span> <span class="nv">normal</span>
</span></span></code></pre></div><p>This technique is quite handy when handling exceptions cases in general, and in high-level code, you can give the compiler a <a href="/hpc/compilation/situational">hint</a> that a certain branch is more likely than the other:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">length</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">y</span><span class="p">)</span> <span class="na">[[unlikely]]</span>
</span></span><span class="line"><span class="cl">        <span class="n">swap</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>This optimization is only beneficial when you know that a branch is very rarely taken. When this is not the case, there are <a href="/hpc/pipelining/hazards">other aspects</a> more important than the code layout, that compel compilers to avoid any branching at all — in this case by replacing it with a special “conditional move” instruction, roughly corresponding to the ternary expression <code>(x &gt; y ? y - x : x - y)</code> or calling <code>abs(x - y)</code>:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl"><span class="nl">length:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>   <span class="nb">edx</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>   <span class="nb">eax</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>   <span class="nb">edx</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sub</span>   <span class="nb">eax</span><span class="p">,</span> <span class="nb">edi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmp</span>   <span class="nb">edi</span><span class="p">,</span> <span class="nb">esi</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmovg</span> <span class="nb">eax</span><span class="p">,</span> <span class="nb">edx</span>  <span class="c1">; "mov if edi &gt; esi"</span>
</span></span><span class="line"><span class="cl">    <span class="nf">ret</span>
</span></span></code></pre></div><p>Eliminating branches is an important topic, and we will spend <a href="/hpc/pipelining/branching">much of the next chapter</a> discussing it in more detail.</p><section class="footnotes" role="doc-endnotes"><hr/><ol><li id="fn:1" role="doc-endnote"><p>Such instructions are called no-op, or NOP instructions. On x86, the “official way” of doing nothing is <code>xchg rax, rax</code> (swap a register with itself): the CPU recognizes it and doesn’t spend extra cycles executing it, except for the decode stage. The <code>nop</code> shorthand maps to the same machine code. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">↩︎</a></p></li></ol></section></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/architecture/indirect/" id="prev-article">← Indirect Branching</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/pipelining/" id="next-article">../Instruction-Level Parallelism →</a></div></div>    
</body>
</html>