<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Statistical Profiling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Statistical Profiling</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/profiling/events/">https://en.algorithmica.org/hpc/profiling/events/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p><a href="../instrumentation">Instrumentation</a> is a rather tedious way of doing profiling, especially if you are interested in multiple small sections of the program. And even if it can be partially automated by the tooling, it still won’t help you gather some fine-grained statistics because of its inherent overhead.</p><p>Another, less invasive approach to profiling is to interrupt the execution of a program at random intervals and look where the instruction pointer is. The number of times the pointer stopped in each function’s block would be roughly proportional to the total time spent executing these functions. You can also get some other useful information this way, like finding out which functions are called by which functions by inspecting <a href="/hpc/architecture/functions">the call stack</a>.</p><p>This could, in principle, be done by just running a program with <code>gdb</code> and <code>ctrl+c</code>‘ing it at random intervals but modern CPUs and operating systems provide special utilities for this type of profiling.</p><span class="anchor" id="hardware-events"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/profiling/events/#hardware-events">#</a>Hardware Events</h3><p>Hardware <em>performance counters</em> are special registers built into microprocessors that can store the counts of certain hardware-related activities. They are cheap to add on a microchip, as they are basically just binary counters with an activation wire connected to them.</p><p>Each performance counter is connected to a large subset of circuitry and can be configured to be incremented on a particular hardware event, such as a branch mispredict or a cache miss. You can reset a counter at the start of a program, run it, and output its stored value at the end, and it will be equal to the exact number of times a certain event has been triggered throughout the execution.</p><p>You can also keep track of multiple events by multiplexing between them, that is, stopping the program in even intervals and reconfiguring the counters. The result in this case will not be exact, but a statistical approximation. One nuance here is that its accuracy can’t be improved by simply increasing the sampling frequency because it would affect the performance too much and thus skew the distribution, so to collect multiple statistics, you would need to run the program for longer periods of time.</p><p>Overall, event-driven statistical profiling is usually the most effective and easy way to diagnose performance issues.</p><span class="anchor" id="profiling-with-perf"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/profiling/events/#profiling-with-perf">#</a>Profiling with perf</h3><p>Performance analysis tools that rely on the event sampling techniques described above are called <em>statistical profilers</em>. There are many of them, but the one we will mainly use in this book is <a href="https://perf.wiki.kernel.org/">perf</a>, which is a statistical profiler shipped with the Linux kernel. On non-Linux systems, you can use <a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html#gs.cuc0ks">VTune</a> from Intel, which provides roughly the same functionality for our purposes. It is available for free, although it is proprietary, and you need to refresh your community license every 90 days, while perf is free as in freedom.</p><p>Perf is a command-line application that generates reports based on the live execution of programs. It does not need the source and can profile a very wide range of applications, even those that involve multiple processes and interaction with the operating system.</p><p>For explanation purposes, I have written a small program that creates an array of a million random integers, sorts it, and then does a million binary searches on it:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">setup</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">n</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">query</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">checksum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">lower_bound</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="n">rand</span><span class="p">())</span> <span class="o">-</span> <span class="n">a</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">checksum</span> <span class="o">+=</span> <span class="n">idx</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">checksum</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>After compiling it (<code>g++ -O3 -march=native example.cc -o run</code>), we can run it with <code>perf stat ./run</code>, which outputs the counts of basic performance events during its execution:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="w"> </span><span class="nt">Performance counter stats for './run'</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="m">646.07</span><span class="w"> </span><span class="l">msec task-clock:u              </span><span class="w"> </span><span class="c"># 0.997 CPUs utilized          </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">             </span><span class="m">0</span><span class="w">      </span><span class="l">context-switches:u        </span><span class="w"> </span><span class="c"># 0.000 K/sec                  </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">             </span><span class="m">0</span><span class="w">      </span><span class="l">cpu-migrations:u          </span><span class="w"> </span><span class="c"># 0.000 K/sec                  </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">         </span><span class="m">1</span><span class="p">,</span><span class="m">096</span><span class="w">      </span><span class="l">page-faults:u             </span><span class="w"> </span><span class="c"># 0.002 M/sec                  </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">852</span><span class="p">,</span><span class="m">125</span><span class="p">,</span><span class="m">255</span><span class="w">      </span><span class="l">cycles:u                  </span><span class="w"> </span><span class="c"># 1.319 GHz (83.35%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="m">28</span><span class="p">,</span><span class="m">475</span><span class="p">,</span><span class="m">954</span><span class="w">      </span><span class="l">stalled-cycles-frontend:u </span><span class="w"> </span><span class="c"># 3.34% frontend cycles idle (83.30%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="m">10</span><span class="p">,</span><span class="m">460</span><span class="p">,</span><span class="m">937</span><span class="w">      </span><span class="l">stalled-cycles-backend:u  </span><span class="w"> </span><span class="c"># 1.23% backend cycles idle (83.28%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">479</span><span class="p">,</span><span class="m">175</span><span class="p">,</span><span class="m">388</span><span class="w">      </span><span class="l">instructions:u            </span><span class="w"> </span><span class="c"># 0.56  insn per cycle         </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                                               </span><span class="c"># 0.06  stalled cycles per insn (83.28%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">122</span><span class="p">,</span><span class="m">705</span><span class="p">,</span><span class="m">572</span><span class="w">      </span><span class="l">branches:u                </span><span class="w"> </span><span class="c"># 189.925 M/sec (83.32%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="m">19</span><span class="p">,</span><span class="m">229</span><span class="p">,</span><span class="m">451</span><span class="w">      </span><span class="l">branch-misses:u           </span><span class="w"> </span><span class="c"># 15.67% of all branches (83.47%)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">0.647801770</span><span class="w"> </span><span class="l">seconds time elapsed</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">0.647278000</span><span class="w"> </span><span class="l">seconds user</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="m">0.000000000</span><span class="w"> </span><span class="l">seconds sys</span><span class="w">
</span></span></span></code></pre></div><p>You can see that the execution took 0.53 seconds or 852M cycles at an effective 1.32 GHz clock rate, over which 479M instructions were executed. There were also 122.7M branches, and 15.7% of them were mispredicted.</p><p>You can get a list of all supported events with <code>perf list</code>, and then specify a list of specific events you want with the <code>-e</code> option. For example, for diagnosing binary search, we mostly care about cache misses:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="l">&gt; perf stat -e cache-references,cache-misses ./run</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"/><span class="m">91</span><span class="p">,</span><span class="m">002</span><span class="p">,</span><span class="m">054</span><span class="w">      </span><span class="l">cache-references:u                                          </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"/><span class="m">44</span><span class="p">,</span><span class="m">991</span><span class="p">,</span><span class="m">746</span><span class="w">      </span><span class="l">cache-misses:u     </span><span class="w"> </span><span class="c"># 49.440 % of all cache refs</span><span class="w">
</span></span></span></code></pre></div><p>By itself, <code>perf stat</code> simply sets up performance counters for the whole program. It can tell you the total number of branch mispredictions, but it won’t tell you <em>where</em> they are happening, let alone <em>why</em> they are happening.</p><p>To try the stop-the-world approach we discussed previously, we need to use <code>perf record &lt;cmd&gt;</code>, which records profiling data and dumps it as a <code>perf.data</code> file, and then call <code>perf report</code> to inspect it. I highly advise you to go and try it yourselves because the last command is interactive and colorful, but for those that can’t do it right now, I’ll try to describe it the best I can.</p><p>When you call <code>perf report</code>, it first displays a <code>top</code>-like interactive report that tells you which functions are taking how much time:</p><pre tabindex="0"><code>Overhead  Command  Shared Object        Symbol
  63.08%  run      run                  [.] query
  24.98%  run      run                  [.] std::__introsort_loop&lt;...&gt;
   5.02%  run      libc-2.33.so         [.] __random
   3.43%  run      run                  [.] setup
   1.95%  run      libc-2.33.so         [.] __random_r
   0.80%  run      libc-2.33.so         [.] rand
</code></pre><p>Note that, for each function, just its <em>overhead</em> is listed and not the total running time (e.g., <code>setup</code> includes <code>std::__introsort_loop</code> but only its own overhead is accounted as 3.43%). There are tools for constructing <a href="https://www.brendangregg.com/flamegraphs.html">flame graphs</a> out of perf reports to make them more clear. You also need to account for possible inlining, which is apparently what happened with <code>std::lower_bound</code> here. Perf also tracks shared libraries (like <code>libc</code>) and, in general, any other spawned processes: if you want, you can launch a web browser with perf and see what’s happening inside.</p><p>Next, you can “zoom in” on any of these functions, and, among others things, it will offer to show you its disassembly with an associated heatmap. For example, here is the assembly for <code>query</code>:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-asm" data-lang="asm"><span class="line"><span class="cl">       <span class="err">│20:</span> <span class="err">→</span> <span class="nf">call</span>   <span class="no">rand@plt</span>
</span></span><span class="line"><span class="cl">       <span class="err">│</span>      <span class="nf">mov</span>    <span class="nv">%r12</span><span class="p">,</span><span class="nv">%rsi</span>
</span></span><span class="line"><span class="cl">       <span class="err">│</span>      <span class="nf">mov</span>    <span class="nv">%eax</span><span class="p">,</span><span class="nv">%edi</span>
</span></span><span class="line"><span class="cl">       <span class="err">│</span>      <span class="nf">mov</span>    <span class="no">$0xf4240</span><span class="p">,</span><span class="nv">%eax</span>
</span></span><span class="line"><span class="cl">       <span class="err">│</span>      <span class="nf">nop</span>    
</span></span><span class="line"><span class="cl">       <span class="err">│</span><span class="mi">30</span><span class="p">:</span>   <span class="no">test</span>   <span class="nv">%rax</span><span class="p">,</span><span class="nv">%rax</span>
</span></span><span class="line"><span class="cl">  <span class="err">4</span><span class="nf">.57</span> <span class="err">│</span>    <span class="err">↓</span> <span class="no">jle</span>    <span class="mi">52</span>
</span></span><span class="line"><span class="cl">       <span class="err">│35:</span>   <span class="nf">mov</span>    <span class="nv">%rax</span><span class="p">,</span><span class="nv">%rdx</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.52</span> <span class="err">│</span>      <span class="no">sar</span>    <span class="nv">%rdx</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.33</span> <span class="err">│</span>      <span class="no">lea</span>    <span class="p">(</span><span class="nv">%rsi</span><span class="p">,</span><span class="nv">%rdx</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="nv">%rcx</span>
</span></span><span class="line"><span class="cl">  <span class="err">4</span><span class="nf">.30</span> <span class="err">│</span>      <span class="no">cmp</span>    <span class="p">(</span><span class="nv">%rcx</span><span class="p">),</span><span class="nv">%edi</span>
</span></span><span class="line"><span class="cl"> <span class="err">65</span><span class="nf">.39</span> <span class="err">│</span>    <span class="err">↓</span> <span class="no">jle</span>    <span class="no">b0</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.07</span> <span class="err">│</span>      <span class="no">sub</span>    <span class="nv">%rdx</span><span class="p">,</span><span class="nv">%rax</span>
</span></span><span class="line"><span class="cl">  <span class="err">9</span><span class="nf">.32</span> <span class="err">│</span>      <span class="no">lea</span>    <span class="mi">0x4</span><span class="p">(</span><span class="nv">%rcx</span><span class="p">),</span><span class="nv">%rsi</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.06</span> <span class="err">│</span>      <span class="no">dec</span>    <span class="nv">%rax</span>
</span></span><span class="line"><span class="cl">  <span class="err">1</span><span class="nf">.37</span> <span class="err">│</span>      <span class="no">test</span>   <span class="nv">%rax</span><span class="p">,</span><span class="nv">%rax</span>
</span></span><span class="line"><span class="cl">  <span class="err">1</span><span class="nf">.11</span> <span class="err">│</span>    <span class="err">↑</span> <span class="no">jg</span>     <span class="mi">35</span>
</span></span><span class="line"><span class="cl">       <span class="err">│52:</span>   <span class="nf">sub</span>    <span class="nv">%r12</span><span class="p">,</span><span class="nv">%rsi</span>
</span></span><span class="line"><span class="cl">  <span class="err">2</span><span class="nf">.22</span> <span class="err">│</span>      <span class="no">sar</span>    <span class="no">$0x2</span><span class="p">,</span><span class="nv">%rsi</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.33</span> <span class="err">│</span>      <span class="no">add</span>    <span class="nv">%esi</span><span class="p">,</span><span class="nv">%ebp</span>
</span></span><span class="line"><span class="cl">  <span class="err">0</span><span class="nf">.20</span> <span class="err">│</span>      <span class="no">dec</span>    <span class="nv">%ebx</span>
</span></span><span class="line"><span class="cl">       <span class="err">│</span>    <span class="err">↑</span> <span class="nf">jne</span>    <span class="mi">20</span>
</span></span></code></pre></div><p>On the left column is the fraction of times that the instruction pointer stopped on a specific line. You can see that we spend ~65% of the time on the jump instruction because it has a comparison operator before it, indicating that the control flow waits there for this comparison to be decided.</p><p>Because of intricacies such as <a href="/hpc/pipelining">pipelining</a> and out-of-order execution, “now” is not a well-defined concept in modern CPUs, so the data is slightly inaccurate as the instruction pointer drifts a little bit forward. The instruction-level data is still useful, but at the individual cycle level, we need to switch to <a href="../simulation">something more precise</a>.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/profiling/instrumentation/" id="prev-article">← Instrumentation</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/profiling/simulation/" id="next-article">Program Simulation →</a></div></div>    
</body>
</html>