<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>External Memory</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>External Memory</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/external-memory/">https://en.algorithmica.org/hpc/external-memory/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>How long does it take to add two numbers together? Being one of the most frequently used instructions, <code>add</code> by itself only takes one cycle to execute. So, if the data is already loaded into registers, it takes one just cycle.</p><p>But in the general case (<code>*c = *a + *b</code>), we need to fetch its operands from memory first:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl"><span class="nf">mov</span> <span class="nb">eax</span><span class="p">,</span> <span class="kt">DWORD</span> <span class="nv">PTR</span> <span class="p">[</span><span class="nb">rsi</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nf">add</span> <span class="nb">eax</span><span class="p">,</span> <span class="kt">DWORD</span> <span class="nv">PTR</span> <span class="p">[</span><span class="nb">rdi</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nf">mov</span> <span class="kt">DWORD</span> <span class="nv">PTR</span> <span class="p">[</span><span class="nb">rdx</span><span class="p">],</span> <span class="nb">eax</span>
</span></span></code></pre></div><p>When you fetch anything from memory, there is always some latency before the data arrives. Moreover, the request doesn’t go directly to its ultimate storage location, but it first goes through a complex system of address translation units and caching layers designed to both help in memory management and reduce latency.</p><p>Therefore, the only correct answer to this question is “it depends” — primarily on where the operands are stored:</p><ul><li>If the data is stored in the main memory (RAM), it will take around ~100ns, or about 200 cycles, to fetch it, and then another 200 cycles to write it back.</li><li>If it was accessed recently, it is probably <em>cached</em> and will take less than that to fetch, depending on how long ago it was accessed — it could be ~50 cycles for the slowest layer of cache and around 4-5 cycles for the fastest.</li><li>But it could also be stored on some type of <em>external memory</em> such as a hard drive, and in this case, it will take around 5ms, or roughly $10^7$ cycles (!) to access it.</li></ul><p>Such a high variance of memory performance is caused by the fact that memory hardware doesn’t follow the same <a href="/hpc/complexity/hardware">laws of silicon scaling</a> as CPU chips do. Memory is still improving through other means, but if 50 years ago memory timings were roughly on the same scale with the instruction latencies, nowadays they lag far behind.</p><p><figure><img src="../Images/45a70362bd76c5497d92f72512eb0c4a.png" data-original-src="https://en.algorithmica.org/hpc/external-memory/img/memory-vs-compute.png"/><figcaption/></figure></p><p>To be less of a limiting factor, modern memory systems are becoming increasingly <a href="hierarchy">hierarchical</a>, where the higher layers trade off some of their capacity for reduced latency. As these characteristics may change in the orders of magnitude between the layers — especially in the case of external memory types — it became crucial for many memory-intensive algorithms to optimize their I/O operations before anything else.</p><p>This prompted the creation of a new cost model, called the <em>external memory model</em>, whose only primitive operations are block reads and writes, and everything else has zero cost as long as it only involves data stored in a limited-sized local memory. It spawned an exciting new field of <em>external memory algorithms</em>, which we will study in this chapter.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/number-theory/montgomery/" id="prev-article">← Montgomery Multiplication</a><br/><a href="https://en.algorithmica.org/hpc/number-theory/">← ../Number Theory</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/external-memory/hierarchy/" id="next-article">Memory Hierarchy →</a><br/><a href="https://en.algorithmica.org/hpc/cpu-cache/">../RAM &amp; CPU Caches →</a></div></div>    
</body>
</html>