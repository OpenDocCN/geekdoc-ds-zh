<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>7.2. Background: elements of finite Markov chains#</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>7.2. Background: elements of finite Markov chains#</h1>
<blockquote>原文：<a href="https://mmids-textbook.github.io/chap07_rwmc/02_mcdefs/roch-mmids-rwmc-mcdefs.html">https://mmids-textbook.github.io/chap07_rwmc/02_mcdefs/roch-mmids-rwmc-mcdefs.html</a></blockquote>

<p>As we mentioned, we are interested in analyzing the behavior of a random walk “diffusing” on a graph. Before we develop such techniques, it will be worthwhile to cast them in the more general framework of discrete-time Markov chains on a finite state space. Indeed Markov chains have many more applications in data science.</p>
<section id="basic-definitions">
<h2><span class="section-number">7.2.1. </span>Basic definitions<a class="headerlink" href="#basic-definitions" title="Link to this heading">#</a></h2>
<p>A discrete-time Markov chain<span class="math notranslate nohighlight">\(\idx{Markov chain}\xdi\)</span> is a stochastic process<span class="math notranslate nohighlight">\(\idx{stochastic process}\xdi\)</span>, i.e., a collection of random variables in this case indexed by time. We assume that the random variables take values in a common finite state space <span class="math notranslate nohighlight">\(\S\)</span>. What makes it “Markovian” is that “it forgets the past” in the sense that “its future only depends on its present state.” More formally:</p>
<p><strong>DEFINITION</strong> <strong>(Discrete-Time Markov Chain)</strong> The sequence of random variables <span class="math notranslate nohighlight">\((X_t)_{t \geq 0} = (X_0, X_1, X_2, \ldots)\)</span> taking values in the finite state space <span class="math notranslate nohighlight">\(\S\)</span> is a Markov chain if: for all <span class="math notranslate nohighlight">\(t \geq 1\)</span> and all <span class="math notranslate nohighlight">\(x_0,x_1,\ldots,x_t \in \S\)</span></p>
<div class="math notranslate nohighlight">
\[
(*)\qquad\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]
= \P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
\]</div>
<p>provided the conditional probabilities are well-defined. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>To be clear, the event in the conditioning is</p>
<div class="math notranslate nohighlight">
\[
\{X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0\}
= \{X_{t-1} = x_{t-1}\} \cap \{X_{t-2} = x_{t-2}\} \cap \cdots \cap \{X_0 = x_0\}.
\]</div>
<p>It will sometimes be convenient to assume that the common state space <span class="math notranslate nohighlight">\(\S\)</span> is of the form <span class="math notranslate nohighlight">\([m] = \{1,\ldots,m\}\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model)</strong> Here is a simple weather model. Every day is either <span class="math notranslate nohighlight">\(\mathrm{Dry}\)</span> or <span class="math notranslate nohighlight">\(\mathrm{Wet}\)</span>. We model the transitions as Markovian; intuitively, we assume that tomorrow’s weather only depends - in a random fashion independent of the past - on today’s weather. Say the weather changes with <span class="math notranslate nohighlight">\(25\%\)</span> chance. More formally, let <span class="math notranslate nohighlight">\(X_t \in \mathcal{S}\)</span> be the weather on day <span class="math notranslate nohighlight">\(t\)</span> with <span class="math notranslate nohighlight">\(\mathcal{S} = \{\mathrm{Dry}, \mathrm{Wet}\}\)</span>. Assume that <span class="math notranslate nohighlight">\(X_0 = \mathrm{Dry}\)</span> and let <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span> be an i.i.d. (i.e., independent, identically distributed) sequence of random variables taking values in <span class="math notranslate nohighlight">\(\{\mathrm{Same}, \mathrm{Change}\}\)</span> satisfying</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Z_t = \mathrm{Same}] = 1 - \mathbb{P}[Z_t = \mathrm{Change}] = 3/4.
\]</div>
<p>Then define for all <span class="math notranslate nohighlight">\(t \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
X_{t+1}
= f(X_t, Z_t)
= \begin{cases}
X_t &amp; \text{if $Z_t = \mathrm{Same}$},\\
\mathrm{Wet} &amp; \text{if $X_t = \mathrm{Dry}$ and $Z_t = \mathrm{Change}$},\\
\mathrm{Dry} &amp; \text{if $X_t = \mathrm{Wet}$ and $Z_t = \mathrm{Change}$}.
\end{cases}
\end{split}\]</div>
<p>We claim that <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a Markov chain. We use two observations:</p>
<p>1- By composition,</p>
<div class="math notranslate nohighlight">
\[
X_1 = f(X_0, Z_0),
\]</div>
<div class="math notranslate nohighlight">
\[
X_2 = f(X_1,Z_1) = f(f(X_0,Z_0),Z_1),
\]</div>
<div class="math notranslate nohighlight">
\[
X_3 = f(X_2,Z_2) = f(f(X_1,Z_1),Z_2) = f(f(f(X_0,Z_0),Z_1),Z_2),
\]</div>
<p>and, more generally,</p>
<div class="math notranslate nohighlight">
\[
X_t
= f(X_{t-1},Z_{t-1})
= f(f(X_{t-2},Z_{t-2}),Z_{t-1})
= f(f(\cdots f(f(X_0,Z_0),Z_1),\cdots),Z_{t-1})
\]</div>
<p>is a deterministic function of <span class="math notranslate nohighlight">\(X_0 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(Z_0,\ldots,Z_{t-1}\)</span>.</p>
<p>2- For any <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>, there is precisely one value of <span class="math notranslate nohighlight">\(z \in \{\mathrm{Same}, \mathrm{Change}\}\)</span> such that <span class="math notranslate nohighlight">\(x_t = f(x_{t-1}, z)\)</span>, i.e., if <span class="math notranslate nohighlight">\(x_t = x_{t-1}\)</span> we must have <span class="math notranslate nohighlight">\(z = \mathrm{Same}\)</span> and if <span class="math notranslate nohighlight">\(x_t \neq x_{t-1}\)</span> we must have <span class="math notranslate nohighlight">\(z = \mathrm{Change}\)</span>.</p>
<p>Fix <span class="math notranslate nohighlight">\(x_0 = \mathrm{Dry}\)</span>. For any <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>, letting <span class="math notranslate nohighlight">\(z\)</span> be as in Observation 2,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[f(X_{t-1}, Z_{t-1}) = x_t \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[f(x_{t-1}, Z_{t-1}) = x_t \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[Z_{t-1} = z \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[Z_{t-1} = z],
\end{align*}\]</div>
<p>where we used that <span class="math notranslate nohighlight">\(Z_{t-1}\)</span> is independent of <span class="math notranslate nohighlight">\(Z_{t-2},\ldots,Z_0\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> (which is deterministic), and therefore is independent of <span class="math notranslate nohighlight">\(X_{t-1},\ldots,X_0\)</span> by Observation 1. The same argument shows that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \P[Z_{t-1} = z],
\]</div>
<p>and that proves the claim.</p>
<p>More generally, one can pick <span class="math notranslate nohighlight">\(X_0\)</span> according to an initial distribution, independently from the sequence <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span>. The argument above can be adapted to this case. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Random Walk on the Petersen Graph)</strong> Let <span class="math notranslate nohighlight">\(G = (V,E)\)</span> be the Petersen graph. Each vertex <span class="math notranslate nohighlight">\(i\)</span> has degree <span class="math notranslate nohighlight">\(3\)</span>, that is, it has three neighbors which we denote <span class="math notranslate nohighlight">\(v_{i,1}, v_{i,2}, v_{i,3}\)</span> in some arbitrary order. For instance, denoting the vertices by <span class="math notranslate nohighlight">\(1,\ldots, 10\)</span> as above, vertex <span class="math notranslate nohighlight">\(9\)</span> has neighbors <span class="math notranslate nohighlight">\(v_{9,1} = 4, v_{9,2} = 6, v_{9,3} = 7\)</span>.</p>
<p>We consider the following random walk on <span class="math notranslate nohighlight">\(G\)</span>. We start at <span class="math notranslate nohighlight">\(X_0 = 1\)</span>. Then, for each <span class="math notranslate nohighlight">\(t\geq 0\)</span>, we let <span class="math notranslate nohighlight">\(X_{t+1}\)</span> be a uniformly chosen neighbor of <span class="math notranslate nohighlight">\(X_t\)</span>, independently of the previous history. That is, we jump at random from neighbor to neighbor. Formally, fix <span class="math notranslate nohighlight">\(X_0 = 1\)</span> and let <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span> be an i.i.d. sequence of random variables taking values in <span class="math notranslate nohighlight">\(\{1,2,3\}\)</span> satisfying</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Z_t = 1] = \mathbb{P}[Z_t = 2] = \mathbb{P}[Z_t = 3] = 1/3.
\]</div>
<p>Then define, for all <span class="math notranslate nohighlight">\(t \geq 0\)</span>, <span class="math notranslate nohighlight">\(X_{t+1} = f(X_t, Z_t) = v_{i,Z_t}\)</span> if <span class="math notranslate nohighlight">\(X_t = v_i\)</span>.</p>
<p>By an argument similar to the previous example, <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a Markov chain.
Also as in the previous example, one can pick <span class="math notranslate nohighlight">\(X_0\)</span> according to an initial distribution, independently from the sequence <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>There are various useful generalizations of the condition <span class="math notranslate nohighlight">\((*)\)</span> in the definition of a Markov chain. These are all special cases of what is referred to as the <em>Markov Property</em><span class="math notranslate nohighlight">\(\idx{Markov property}\xdi\)</span> which can be summarized as: the past and the future are independent given the present. We record a version general enough for us here. Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain on the state space <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. For any integer <span class="math notranslate nohighlight">\(h \geq 0\)</span>, <span class="math notranslate nohighlight">\(x_{t-1}\in \mathcal{S}\)</span> and subsets <span class="math notranslate nohighlight">\(\mathcal{P} \subseteq \mathcal{S}^{t-1}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{F} \subseteq \mathcal{S}^{h+1}\)</span> of state sequences of length <span class="math notranslate nohighlight">\(t-1\)</span> and <span class="math notranslate nohighlight">\(h+1\)</span> respectively, it holds that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[(X_t,\ldots,X_{t+h}) \in \mathcal{F}\,|\,X_{t-1} = x_{t-1}, (X_0,\ldots,X_{t-2}) \in \mathcal{P}]
&amp;= \P[(X_t,\ldots,X_{t+h}) \in \mathcal{F}\,|\,X_{t-1} = x_{t-1}].
\end{align*}\]</div>
<p>One important implication of the <em>Markov Property</em> is that the distribution of a sample path, i.e., an event of the form <span class="math notranslate nohighlight">\(\{X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T\}\)</span>, simplifies considerably.</p>
<p><strong>THEOREM</strong> <strong>(Distribution of a Sample Path)</strong> <span class="math notranslate nohighlight">\(\idx{distribution of a sample path}\xdi\)</span> For any <span class="math notranslate nohighlight">\(x_0, x_1, \ldots, x_T \in \mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p><span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof idea:</em> We use the <em>Multiplication Rule</em> and the <em>Markov Property</em>.</p>
<p><em>Proof:</em> We first apply the <em>Multiplication Rule</em></p>
<div class="math notranslate nohighlight">
\[
\P\left[\cap_{i=1}^r A_i\right]
= \prod_{i=1}^r \P\left[A_i \,\middle|\, \cap_{j=1}^{i-1} A_j \right].
\]</div>
<p>with <span class="math notranslate nohighlight">\(A_i = \{X_{i-1} = x_{i-1}\}\)</span> and <span class="math notranslate nohighlight">\(r = T+1\)</span>. That gives</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]\\
&amp;= \P[X_0 = x_0] \,\prod_{t=1}^T \P[X_t = x_t\,|\,X_{t-1} = x_{t-1},
\ldots, X_0 = x_0].
\end{align*}\]</div>
<p>Then we use the <em>Markov Property</em> to simplify each term in the product. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Going back to the weather model from a previous example, fix <span class="math notranslate nohighlight">\(x_0 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>. Then, by the <em>Distribution of a Sample Path</em>,</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p>By assumption <span class="math notranslate nohighlight">\(\P[X_0 = x_0] = 1\)</span>. Moreover, we have previously shown that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \P[Z_{t-1} = z_{t-1}],
\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{t-1} = \mathrm{Same}\)</span> if <span class="math notranslate nohighlight">\(x_t = x_{t-1}\)</span> and <span class="math notranslate nohighlight">\(z_{t-1} = \mathrm{Change}\)</span> if <span class="math notranslate nohighlight">\(x_t \neq x_{t-1}\)</span>.</p>
<p>Hence, using the distribution of <span class="math notranslate nohighlight">\(Z_t\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \begin{cases}
3/4 &amp; \text{if $x_t = x_{t-1}$},\\
1/4 &amp; \text{if $x_t \neq x_{t-1}$}.
\end{cases}
\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(n_T = |\{0 &lt; t \leq T : x_t = x_{t-1}\}|\)</span> be the number of transitions without change. Then,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
&amp;= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]\\
&amp;= \prod_{t=1}^T\P[Z_{t-1} = z_{t-1}]\\
&amp;= (3/4)^{n_T} (1/4)^{T - n_T}.
\end{align*}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>It will be useful later on to observe that the <em>Distribution of a Sample Path</em> generalizes to</p>
<div class="math notranslate nohighlight">
\[
\P[X_{s+1} = x_{s+1}, X_{s+2} = x_{s+2}, \ldots, X_T = x_T\,|\,X_s = x_s]
= \prod_{t=s+1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p>Based on the <em>Distribution of a Sample Path</em>, in order to specify the distribution of the process it suffices to specify</p>
<ol class="arabic simple">
<li><p>the <em>initial distribution</em><span class="math notranslate nohighlight">\(\idx{initial distribution}\xdi\)</span> <span class="math notranslate nohighlight">\(\mu_x := \P[X_0 = x]\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>; and</p></li>
<li><p>the <em>transition probabilities</em><span class="math notranslate nohighlight">\(\idx{transition probability}\xdi\)</span> <span class="math notranslate nohighlight">\(\P[X_{t+1} = x\,|\,X_{t} = x']\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(x'\)</span>.</p></li>
</ol>
</section>
<section id="time-homogeneous-case-transition-matrix">
<h2><span class="section-number">7.2.2. </span>Time-homogeneous case: transition matrix<a class="headerlink" href="#time-homogeneous-case-transition-matrix" title="Link to this heading">#</a></h2>
<p>It is common to further assume that the process is <em>time-homogeneous</em><span class="math notranslate nohighlight">\(\idx{time-homogeneous process}\xdi\)</span>, which means that the transition probabilities do not depend on <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\P[X_{t+1} =x\,|\,X_{t} = x']
= \P[X_1 =x\,|\,X_{0} = x']
=: p_{x',x},
\quad \forall t=1,\ldots
\]</div>
<p>where the last equality is a definition. We can then collect the transition probabilities into a matrix.</p>
<p><strong>DEFINITION</strong> <strong>(Transition Matrix)</strong> <span class="math notranslate nohighlight">\(\idx{transition matrix}\xdi\)</span> The matrix</p>
<div class="math notranslate nohighlight">
\[
P = (p_{x',x})_{x,x' \in \S}
\]</div>
<p>is called the transition matrix of the chain. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>We also let <span class="math notranslate nohighlight">\(\mu_{x} = \P[X_0 = x]\)</span> and we think of <span class="math notranslate nohighlight">\(\bmu = (\mu_{x})_{x \in \S}\)</span> as a vector. The convention in Markov chain theory is to think of probability distributions such as <span class="math notranslate nohighlight">\(\bmu\)</span> as <em>row vectors</em>. We will see later why it simplifies the notation somewhat.</p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Going back to the weather model, let us number the states as follows: <span class="math notranslate nohighlight">\(1 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(2 = \mathrm{Wet}\)</span>. Then the transition matrix is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P
= \begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}.
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Random Walk on the Petersen Graph, continued)</strong> Consider again the random walk on the Petersen graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span>. We number the vertices <span class="math notranslate nohighlight">\(1, 2,\ldots, 10\)</span>. To compute the transition matrix, we list for each vertex its neighbors and put the value <span class="math notranslate nohighlight">\(1/3\)</span> in the corresponding columns. For instance, vertex <span class="math notranslate nohighlight">\(1\)</span> has neighbors <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(5\)</span> and <span class="math notranslate nohighlight">\(6\)</span>, so row <span class="math notranslate nohighlight">\(1\)</span> has <span class="math notranslate nohighlight">\(1/3\)</span> in columns <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(5\)</span>, and <span class="math notranslate nohighlight">\(6\)</span>. And so on.</p>
<p>We get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = \begin{pmatrix}
0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0\\
1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3\\
1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0\\
0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3\\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3\\
0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0
\end{pmatrix}
\end{split}\]</div>
<p>We have already encountered a matrix that encodes the neighbors of each vertex, the adjacency matrix. Here we can recover the transition matrix by multiplying the adjacency matrix by <span class="math notranslate nohighlight">\(1/3\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>Transition matrices have a very special structure.</p>
<p><strong>THEOREM</strong> <strong>(Transition Matrix is Stochastic)</strong> <span class="math notranslate nohighlight">\(\idx{transition matrix is stochastic theorem}\xdi\)</span> The transition matrix <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix<span class="math notranslate nohighlight">\(\idx{stochastic matrix}\xdi\)</span>, that is, all its entries are nonnegative and all its rows sum to one. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof:</em> Indeed,</p>
<div class="math notranslate nohighlight">
\[
\sum_{x \in \S} p_{x',x} = \sum_{x \in \S} \P[X_1 = x\,|\,X_{0} = x'] = \P[X_1 \in \S \,|\,X_{0} = x'] = 1
\]</div>
<p>by the properties of the conditional probability. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>In matrix form, the condition can be stated as <span class="math notranslate nohighlight">\(P \mathbf{1} = \mathbf{1}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is an all-one vector of the appropriate size.</p>
<p>We have seen that any transition matrix is stochastic. Conversely, any stochastic matrix is the transition matrix of a Markov chain. That is, we can specify a Markov chain by choosing the number of states <span class="math notranslate nohighlight">\(n\)</span>, an initial distribution over <span class="math notranslate nohighlight">\(\mathcal{S} = [n]\)</span> and a stochastic matrix <span class="math notranslate nohighlight">\(P \in \mathbb{R}^{n\times n}\)</span>. Row <span class="math notranslate nohighlight">\(i\)</span> of <span class="math notranslate nohighlight">\(P\)</span> stipulates the probability distribution of the next state given that we are currently at state <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(Robot Vacuum)</strong> Suppose a robot vacuum roams around a large mansion with the following rooms: <span class="math notranslate nohighlight">\(1=\mathrm{Study}\)</span>, <span class="math notranslate nohighlight">\(2=\mathrm{Hall}\)</span>, <span class="math notranslate nohighlight">\(3=\mathrm{Lounge}\)</span>, <span class="math notranslate nohighlight">\(4=\mathrm{Library}\)</span>, <span class="math notranslate nohighlight">\(5=\mathrm{Billiard\ Room}\)</span>, <span class="math notranslate nohighlight">\(6=\mathrm{Dining\ Room}\)</span>, <span class="math notranslate nohighlight">\(7=\mathrm{Conservatory}\)</span>, <span class="math notranslate nohighlight">\(8=\mathrm{Ball\ Room}\)</span>, <span class="math notranslate nohighlight">\(9=\mathrm{Kitchen}\)</span>.</p>
<p><strong>Figure:</strong> A wrench (<em>Credit:</em> Made with <a class="reference external" href="https://www.midjourney.com/">Midjourney</a>)</p>
<p><img alt="Roomba" src="../Images/208cda012f226f8db1d9e4a27b9cbdc4.png" data-original-src="https://mmids-textbook.github.io/_images/Roomba_and_a_wrench-small.png"/></p>
<p><span class="math notranslate nohighlight">\(\bowtie\)</span></p>
<p>Once it is done cleaning a room, it moves to another one nearby according to the following stochastic matrix (check it is stochastic!):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = \begin{pmatrix}
0 &amp; 0.8 &amp; 0 &amp; 0.2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.3 &amp; 0 &amp; 0.2 &amp; 0 &amp; 0 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0.6 &amp; 0 &amp; 0 &amp; 0 &amp; 0.4 &amp; 0 &amp; 0 &amp; 0\\
0.1 &amp; 0.1 &amp; 0 &amp; 0 &amp; 0.8 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0.25 &amp; 0 &amp; 0 &amp; 0.75 &amp; 0 &amp; 0\\
0 &amp; 0.15 &amp; 0.15 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.35 &amp; 0.35\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.3 &amp; 0.4 &amp; 0.2 &amp; 0 &amp; 0.1\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
\end{split}\]</div>
<p>Suppose the initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> is uniform over the state space and let <span class="math notranslate nohighlight">\(X_t\)</span> be the room the vacuum is in at iteration <span class="math notranslate nohighlight">\(t\)</span>. Then <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> is a Markov chain. Unlike our previous examples, <span class="math notranslate nohighlight">\(P\)</span> is not symmetric. In particular, its rows sum to <span class="math notranslate nohighlight">\(1\)</span> but its columns do not. (Check it!) <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>When both rows and columns sum to <span class="math notranslate nohighlight">\(1\)</span>, we say that <span class="math notranslate nohighlight">\(P\)</span> is doubly stochastic.</p>
<p>With the notation just introduced, the distribution of a sample path simplifies further to</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}.
\]</div>
<p>This formula has a remarkable consequence. The marginal distribution of <span class="math notranslate nohighlight">\(X_s\)</span> is a matrix power of <span class="math notranslate nohighlight">\(P\)</span>. As usual, we denote by <span class="math notranslate nohighlight">\(P^s\)</span> the <span class="math notranslate nohighlight">\(s\)</span>-th matrix power of <span class="math notranslate nohighlight">\(P\)</span>. Recall also that <span class="math notranslate nohighlight">\(\bmu\)</span> is a row vector.</p>
<p><strong>THEOREM</strong> <strong>(Time Marginals)</strong> <span class="math notranslate nohighlight">\(\idx{time marginals theorem}\xdi\)</span> For any <span class="math notranslate nohighlight">\(s \geq 1\)</span> and <span class="math notranslate nohighlight">\(x_s \in \S\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_s = x_s]
= \left(\bmu P^s\right)_{x_s}.
\]</div>
<p><span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof idea:</em> The idea is to think of <span class="math notranslate nohighlight">\(\P[X_s = x_s]\)</span> as the time <span class="math notranslate nohighlight">\(s\)</span> marginal over all trajectories up to time <span class="math notranslate nohighlight">\(s\)</span> – quantities we know how to compute the probabilities of. Then we use the <em>Distribution of a Sample Path</em> and “pushe the sums in.” This is easier seen on a simple case. We do the case <span class="math notranslate nohighlight">\(s=2\)</span> first.</p>
<p>Summing over all trajectories up to time <span class="math notranslate nohighlight">\(2\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_2 = x_2]\\
&amp;= \sum_{x_0 \in \S} \sum_{x_{1} \in \S}
\P[X_0 = x_0, X_1 = x_1, X_2 = x_2]\\
&amp;= \sum_{x_0 \in \S} \sum_{x_{1} \in \S}
\mu_{x_0} p_{x_{0},x_1} p_{x_{1},x_2},
\end{align*}\]</div>
<p>where we used the <em>Distribution of a Sample Path</em>.</p>
<p>Pushing the sum over <span class="math notranslate nohighlight">\(x_1\)</span> in, this becomes</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;= \sum_{x_0 \in \S} 
\mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_1} p_{x_{1},x_2}\\
&amp;= \sum_{x_0 \in \S} 
\mu_{x_0} (P^2)_{x_{0},x_2},
\end{align*}\]</div>
<p>where we recognized the definition of a matrix product – here <span class="math notranslate nohighlight">\(P^2\)</span>. The result then follows.</p>
<p><em>Proof:</em> For any <span class="math notranslate nohighlight">\(s\)</span>, by definition of a marginal,</p>
<div class="math notranslate nohighlight">
\[
\P[X_s = x_s]
= \sum_{x_0, \ldots, x_{s-1} \in \S}
\P[X_0 = x_0, X_1 = x_1,\ldots,X_{s-1} = x_{s-1}, X_s = x_s].
\]</div>
<p>Using the <em>Distribution of a Sample Path</em> in the time-homogeneous case, this evaluates to</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[X_s = x_s]
&amp;= \sum_{x_0, \ldots, x_{s-1} \in \S}
\mu_{x_0} \prod_{t=1}^s p_{x_{t-1},x_t}.
\end{align*}\]</div>
<p>The sum can be simplified by pushing the individual sums as far into the summand as possible</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\sum_{x_0, \ldots, x_{s-1} \in \S} \mu_{x_0} \prod_{t=1}^{s} p_{x_{t-1},x_t}\\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-2} \in \S} p_{x_{s-3},x_{s-2}} \sum_{x_{s-1} \in \S}  p_{x_{s-2},x_{s-1}} \,p_{x_{s-1},x_s}\\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-2} \in \S} p_{x_{s-3},x_{s-2}} \, \left(P^2\right)_{x_{s-2}, x_s} \\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-3} \in \S} p_{x_{s-4},x_{s-3}} \, \left(P^3\right)_{x_{s-3}, x_s} \\
&amp; \quad = \cdots \\
&amp; \quad = \left(\bmu P^s\right)_{x_s},
\end{align*}\]</div>
<p>where on the second line we recognized the innermost sum as a matrix product, then proceeded similarly. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>The special case <span class="math notranslate nohighlight">\(\bmu = \mathbf{e}_x^T\)</span> gives that for any <span class="math notranslate nohighlight">\(x, y \in [n]\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_s = y\,|\,X_0 = x]
= (\boldsymbol{\mu} P^s)_y
= (\mathbf{e}_x^T P^s)_y
= (P^s)_{x,y}.
\]</div>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Suppose day <span class="math notranslate nohighlight">\(0\)</span> is <span class="math notranslate nohighlight">\(\mathrm{Dry}\)</span>, that is, the initial distribution is <span class="math notranslate nohighlight">\(\bmu = (1,0)^T\)</span>. What is the probability that it is <span class="math notranslate nohighlight">\(\mathrm{Wet}\)</span> on day <span class="math notranslate nohighlight">\(2\)</span>? We apply the formula above to get <span class="math notranslate nohighlight">\(\P[X_2 = 2]
= \left(\bmu P^2\right)_{2}\)</span>. Note that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\bmu P^2
&amp;= (1,0)^T  
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}\\
&amp;= (3/4,1/4)^T
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}\\
&amp;= (10/16,6/16)^T\\
&amp;= (5/8,3/8)^T.
\end{align*}\]</div>
<p>So the answer is <span class="math notranslate nohighlight">\(3/8\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>It will be useful later on to observe that the <em>Time Marginals Theorem</em> generalizes to</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_s = x_s]
= (P^{t-s})_{x_s,x_t},
\]</div>
<p>for <span class="math notranslate nohighlight">\(s \leq t\)</span>.</p>
<p>In the time-homogeneous case, an alternative way to represent a transition matrix is with a directed graph showing all possible transitions.</p>
<p><strong>DEFINITION</strong> <strong>(Transition Graph)</strong> <span class="math notranslate nohighlight">\(\idx{transition graph}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain over the state space <span class="math notranslate nohighlight">\(\mathcal{S} = [n]\)</span> with transition matrix <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j=1}^{n}\)</span>. The transition graph (or state transition diagram) of <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a directed graph with vertices <span class="math notranslate nohighlight">\([n]\)</span> and a directed edge from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span> if and only if <span class="math notranslate nohighlight">\(p_{i,j} &gt; 0\)</span>. We often associate a weight <span class="math notranslate nohighlight">\(p_{i,j}\)</span> to that edge. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>NUMERICAL CORNER:</strong> Returning to our <em>Robot Vacuum Example</em>, the transition graph of the chain can be obtained by thinking of <span class="math notranslate nohighlight">\(P\)</span> as the weighted adjacency matrix of the transition graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">P_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>We define a graph from its adjancency matrix. See <a class="reference external" href="https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_numpy_array.html"><code class="docutils literal notranslate"><span class="pre">networkx.from_numpy_array()</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">G_robot</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">P_robot</span><span class="p">,</span> <span class="n">create_using</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Drawing edge weights on a directed graph in a readable fashion is not straighforward. We will not do this here.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_robot</span> <span class="o">=</span> <span class="n">P_robot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G_robot</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">circular_layout</span><span class="p">(</span><span class="n">G_robot</span><span class="p">),</span> 
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)},</span> 
                 <span class="n">node_color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span> 
                 <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">'arc3, rad = 0.2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/3ed7b79c7b64ae82a443d682f19bec765a062c280a163d9734fd0ce480d6d157.png" src="../Images/e3496ddf45cc8074ed0952cee5403722.png" data-original-src="https://mmids-textbook.github.io/_images/3ed7b79c7b64ae82a443d682f19bec765a062c280a163d9734fd0ce480d6d157.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>Once we have specified a transition matrix (and an initial distribution), we can simulate the corresponding Markov chain. This is useful to compute (approximately) probabilities of complex events through the law of large numbers. Here is some code to generate one sample path up to some given time <span class="math notranslate nohighlight">\(T\)</span>. We assume that the state space is <span class="math notranslate nohighlight">\([n]\)</span>. We use <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html"><code class="docutils literal notranslate"><span class="pre">rng.choice</span></code></a> to generate each transition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="n">P</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">),:])</span>
            
    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Let’s try with our <em>Robot Vacuum</em>. We take the initial distribution to be the uniform distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[9. 6. 3. 6. 8. 6. 2. 1. 2. 6. 8.]
</pre></div>
</div>
</div>
</div>
<p>For example, we can use a simulation to approximate the expected number of times that room <span class="math notranslate nohighlight">\(9\)</span> is visited up to time <span class="math notranslate nohighlight">\(10\)</span>. To do this, we run the simulation a large number of times (say <span class="math notranslate nohighlight">\(1000\)</span>) and count the average number of visits to <span class="math notranslate nohighlight">\(9\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">z</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">N_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">visits_to_z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_samples</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_samples</span><span class="p">):</span>
    <span class="n">visits_to_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="n">z</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">visits_to_z</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>1.193
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>CHAT &amp; LEARN</strong> Markov Decision Processes (MDPs) are a framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. Ask your favorite AI chatbot to explain the basic components of an MDP and how they relate to Markov chains. Discuss some applications of MDPs, such as in robotics or game theory. <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> Which of the following is true about the transition matrix <span class="math notranslate nohighlight">\(P\)</span> of a Markov chain?</p>
<p>a) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and all columns sum to one.</p>
<p>b) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and all rows sum to one.</p>
<p>c) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and both rows and columns sum to one.</p>
<p>d) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and either rows or columns sum to one, but not both.</p>
<p><strong>2</strong> What is the <em>Markov Property</em>?</p>
<p>a) The past and future are independent.</p>
<p>b) The past and future are independent given the present.</p>
<p>c) The present and future are independent given the past.</p>
<p>d) The past, present, and future are all independent.</p>
<p><strong>3</strong> Consider a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t \ge 0}\)</span> on state space <span class="math notranslate nohighlight">\(S\)</span>. Which of the following equations is a direct consequence of the <em>Markov Property</em>?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t] = \mathbb{P}[X_{t+1} = x_{t+1}]\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t, X_{t-1} = x_{t-1}] = \mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t]\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t] = \mathbb{P}[X_{t+1} = x_{t+1} | X_0 = x_0]\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t, X_{t-1} = x_{t-1}] = \mathbb{P}[X_{t+1} = x_{t+1}]\)</span></p>
<p><strong>4</strong> Consider a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t\geq0}\)</span> with transition matrix <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j}\)</span> and initial distribution <span class="math notranslate nohighlight">\(\mu\)</span>. Which of the following is true about the distribution of a sample path <span class="math notranslate nohighlight">\((X_0, X_1, \ldots, X_T)\)</span>?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \sum_{t=1}^T p_{x_{t-1},x_t}\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \prod_{t=0}^T \mu_{x_t}\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \sum_{t=0}^T \mu_{x_t}\)</span></p>
<p><strong>5</strong> In the random walk on the Petersen graph example, if the current state is vertex 9, what is the probability of transitioning to vertex 4 in the next step?</p>
<p>a) 0</p>
<p>b) 1/10</p>
<p>c) 1/3</p>
<p>d) 1</p>
<p>Answer for 1: b. Justification: The text states that “the transition matrix <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, that is, all its entries are nonnegative and all its rows sum to one.”</p>
<p>Answer for 2: b. Justification: The text summarizes the <em>Markov Property</em> as “the past and the future are independent given the present.”</p>
<p>Answer for 3: b. Justification: This is a direct statement of the <em>Markov Property</em>, where the future state <span class="math notranslate nohighlight">\(X_{t+1}\)</span> depends only on the present state <span class="math notranslate nohighlight">\(X_t\)</span> and not on the past state <span class="math notranslate nohighlight">\(X_{t-1}\)</span>.</p>
<p>Answer for 4: a. Justification: The text states the <em>Distribution of a Sample Path</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}.
\]</div>
<p>Answer for 5: c. Justification: In the Petersen graph, each vertex has 3 neighbors, and the random walk chooses one uniformly at random.</p>
</section>
&#13;

<h2><span class="section-number">7.2.1. </span>Basic definitions<a class="headerlink" href="#basic-definitions" title="Link to this heading">#</a></h2>
<p>A discrete-time Markov chain<span class="math notranslate nohighlight">\(\idx{Markov chain}\xdi\)</span> is a stochastic process<span class="math notranslate nohighlight">\(\idx{stochastic process}\xdi\)</span>, i.e., a collection of random variables in this case indexed by time. We assume that the random variables take values in a common finite state space <span class="math notranslate nohighlight">\(\S\)</span>. What makes it “Markovian” is that “it forgets the past” in the sense that “its future only depends on its present state.” More formally:</p>
<p><strong>DEFINITION</strong> <strong>(Discrete-Time Markov Chain)</strong> The sequence of random variables <span class="math notranslate nohighlight">\((X_t)_{t \geq 0} = (X_0, X_1, X_2, \ldots)\)</span> taking values in the finite state space <span class="math notranslate nohighlight">\(\S\)</span> is a Markov chain if: for all <span class="math notranslate nohighlight">\(t \geq 1\)</span> and all <span class="math notranslate nohighlight">\(x_0,x_1,\ldots,x_t \in \S\)</span></p>
<div class="math notranslate nohighlight">
\[
(*)\qquad\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]
= \P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
\]</div>
<p>provided the conditional probabilities are well-defined. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>To be clear, the event in the conditioning is</p>
<div class="math notranslate nohighlight">
\[
\{X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0\}
= \{X_{t-1} = x_{t-1}\} \cap \{X_{t-2} = x_{t-2}\} \cap \cdots \cap \{X_0 = x_0\}.
\]</div>
<p>It will sometimes be convenient to assume that the common state space <span class="math notranslate nohighlight">\(\S\)</span> is of the form <span class="math notranslate nohighlight">\([m] = \{1,\ldots,m\}\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model)</strong> Here is a simple weather model. Every day is either <span class="math notranslate nohighlight">\(\mathrm{Dry}\)</span> or <span class="math notranslate nohighlight">\(\mathrm{Wet}\)</span>. We model the transitions as Markovian; intuitively, we assume that tomorrow’s weather only depends - in a random fashion independent of the past - on today’s weather. Say the weather changes with <span class="math notranslate nohighlight">\(25\%\)</span> chance. More formally, let <span class="math notranslate nohighlight">\(X_t \in \mathcal{S}\)</span> be the weather on day <span class="math notranslate nohighlight">\(t\)</span> with <span class="math notranslate nohighlight">\(\mathcal{S} = \{\mathrm{Dry}, \mathrm{Wet}\}\)</span>. Assume that <span class="math notranslate nohighlight">\(X_0 = \mathrm{Dry}\)</span> and let <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span> be an i.i.d. (i.e., independent, identically distributed) sequence of random variables taking values in <span class="math notranslate nohighlight">\(\{\mathrm{Same}, \mathrm{Change}\}\)</span> satisfying</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Z_t = \mathrm{Same}] = 1 - \mathbb{P}[Z_t = \mathrm{Change}] = 3/4.
\]</div>
<p>Then define for all <span class="math notranslate nohighlight">\(t \geq 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
X_{t+1}
= f(X_t, Z_t)
= \begin{cases}
X_t &amp; \text{if $Z_t = \mathrm{Same}$},\\
\mathrm{Wet} &amp; \text{if $X_t = \mathrm{Dry}$ and $Z_t = \mathrm{Change}$},\\
\mathrm{Dry} &amp; \text{if $X_t = \mathrm{Wet}$ and $Z_t = \mathrm{Change}$}.
\end{cases}
\end{split}\]</div>
<p>We claim that <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a Markov chain. We use two observations:</p>
<p>1- By composition,</p>
<div class="math notranslate nohighlight">
\[
X_1 = f(X_0, Z_0),
\]</div>
<div class="math notranslate nohighlight">
\[
X_2 = f(X_1,Z_1) = f(f(X_0,Z_0),Z_1),
\]</div>
<div class="math notranslate nohighlight">
\[
X_3 = f(X_2,Z_2) = f(f(X_1,Z_1),Z_2) = f(f(f(X_0,Z_0),Z_1),Z_2),
\]</div>
<p>and, more generally,</p>
<div class="math notranslate nohighlight">
\[
X_t
= f(X_{t-1},Z_{t-1})
= f(f(X_{t-2},Z_{t-2}),Z_{t-1})
= f(f(\cdots f(f(X_0,Z_0),Z_1),\cdots),Z_{t-1})
\]</div>
<p>is a deterministic function of <span class="math notranslate nohighlight">\(X_0 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(Z_0,\ldots,Z_{t-1}\)</span>.</p>
<p>2- For any <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>, there is precisely one value of <span class="math notranslate nohighlight">\(z \in \{\mathrm{Same}, \mathrm{Change}\}\)</span> such that <span class="math notranslate nohighlight">\(x_t = f(x_{t-1}, z)\)</span>, i.e., if <span class="math notranslate nohighlight">\(x_t = x_{t-1}\)</span> we must have <span class="math notranslate nohighlight">\(z = \mathrm{Same}\)</span> and if <span class="math notranslate nohighlight">\(x_t \neq x_{t-1}\)</span> we must have <span class="math notranslate nohighlight">\(z = \mathrm{Change}\)</span>.</p>
<p>Fix <span class="math notranslate nohighlight">\(x_0 = \mathrm{Dry}\)</span>. For any <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>, letting <span class="math notranslate nohighlight">\(z\)</span> be as in Observation 2,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[f(X_{t-1}, Z_{t-1}) = x_t \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[f(x_{t-1}, Z_{t-1}) = x_t \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[Z_{t-1} = z \,|\, X_{t-1} = x_{t-1}, X_{t-2} = x_{t-2},\ldots,X_0 = x_0]\\
&amp;= \P[Z_{t-1} = z],
\end{align*}\]</div>
<p>where we used that <span class="math notranslate nohighlight">\(Z_{t-1}\)</span> is independent of <span class="math notranslate nohighlight">\(Z_{t-2},\ldots,Z_0\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> (which is deterministic), and therefore is independent of <span class="math notranslate nohighlight">\(X_{t-1},\ldots,X_0\)</span> by Observation 1. The same argument shows that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \P[Z_{t-1} = z],
\]</div>
<p>and that proves the claim.</p>
<p>More generally, one can pick <span class="math notranslate nohighlight">\(X_0\)</span> according to an initial distribution, independently from the sequence <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span>. The argument above can be adapted to this case. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Random Walk on the Petersen Graph)</strong> Let <span class="math notranslate nohighlight">\(G = (V,E)\)</span> be the Petersen graph. Each vertex <span class="math notranslate nohighlight">\(i\)</span> has degree <span class="math notranslate nohighlight">\(3\)</span>, that is, it has three neighbors which we denote <span class="math notranslate nohighlight">\(v_{i,1}, v_{i,2}, v_{i,3}\)</span> in some arbitrary order. For instance, denoting the vertices by <span class="math notranslate nohighlight">\(1,\ldots, 10\)</span> as above, vertex <span class="math notranslate nohighlight">\(9\)</span> has neighbors <span class="math notranslate nohighlight">\(v_{9,1} = 4, v_{9,2} = 6, v_{9,3} = 7\)</span>.</p>
<p>We consider the following random walk on <span class="math notranslate nohighlight">\(G\)</span>. We start at <span class="math notranslate nohighlight">\(X_0 = 1\)</span>. Then, for each <span class="math notranslate nohighlight">\(t\geq 0\)</span>, we let <span class="math notranslate nohighlight">\(X_{t+1}\)</span> be a uniformly chosen neighbor of <span class="math notranslate nohighlight">\(X_t\)</span>, independently of the previous history. That is, we jump at random from neighbor to neighbor. Formally, fix <span class="math notranslate nohighlight">\(X_0 = 1\)</span> and let <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span> be an i.i.d. sequence of random variables taking values in <span class="math notranslate nohighlight">\(\{1,2,3\}\)</span> satisfying</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Z_t = 1] = \mathbb{P}[Z_t = 2] = \mathbb{P}[Z_t = 3] = 1/3.
\]</div>
<p>Then define, for all <span class="math notranslate nohighlight">\(t \geq 0\)</span>, <span class="math notranslate nohighlight">\(X_{t+1} = f(X_t, Z_t) = v_{i,Z_t}\)</span> if <span class="math notranslate nohighlight">\(X_t = v_i\)</span>.</p>
<p>By an argument similar to the previous example, <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a Markov chain.
Also as in the previous example, one can pick <span class="math notranslate nohighlight">\(X_0\)</span> according to an initial distribution, independently from the sequence <span class="math notranslate nohighlight">\((Z_t)_{t \geq 0}\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>There are various useful generalizations of the condition <span class="math notranslate nohighlight">\((*)\)</span> in the definition of a Markov chain. These are all special cases of what is referred to as the <em>Markov Property</em><span class="math notranslate nohighlight">\(\idx{Markov property}\xdi\)</span> which can be summarized as: the past and the future are independent given the present. We record a version general enough for us here. Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain on the state space <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. For any integer <span class="math notranslate nohighlight">\(h \geq 0\)</span>, <span class="math notranslate nohighlight">\(x_{t-1}\in \mathcal{S}\)</span> and subsets <span class="math notranslate nohighlight">\(\mathcal{P} \subseteq \mathcal{S}^{t-1}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{F} \subseteq \mathcal{S}^{h+1}\)</span> of state sequences of length <span class="math notranslate nohighlight">\(t-1\)</span> and <span class="math notranslate nohighlight">\(h+1\)</span> respectively, it holds that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[(X_t,\ldots,X_{t+h}) \in \mathcal{F}\,|\,X_{t-1} = x_{t-1}, (X_0,\ldots,X_{t-2}) \in \mathcal{P}]
&amp;= \P[(X_t,\ldots,X_{t+h}) \in \mathcal{F}\,|\,X_{t-1} = x_{t-1}].
\end{align*}\]</div>
<p>One important implication of the <em>Markov Property</em> is that the distribution of a sample path, i.e., an event of the form <span class="math notranslate nohighlight">\(\{X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T\}\)</span>, simplifies considerably.</p>
<p><strong>THEOREM</strong> <strong>(Distribution of a Sample Path)</strong> <span class="math notranslate nohighlight">\(\idx{distribution of a sample path}\xdi\)</span> For any <span class="math notranslate nohighlight">\(x_0, x_1, \ldots, x_T \in \mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p><span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof idea:</em> We use the <em>Multiplication Rule</em> and the <em>Markov Property</em>.</p>
<p><em>Proof:</em> We first apply the <em>Multiplication Rule</em></p>
<div class="math notranslate nohighlight">
\[
\P\left[\cap_{i=1}^r A_i\right]
= \prod_{i=1}^r \P\left[A_i \,\middle|\, \cap_{j=1}^{i-1} A_j \right].
\]</div>
<p>with <span class="math notranslate nohighlight">\(A_i = \{X_{i-1} = x_{i-1}\}\)</span> and <span class="math notranslate nohighlight">\(r = T+1\)</span>. That gives</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]\\
&amp;= \P[X_0 = x_0] \,\prod_{t=1}^T \P[X_t = x_t\,|\,X_{t-1} = x_{t-1},
\ldots, X_0 = x_0].
\end{align*}\]</div>
<p>Then we use the <em>Markov Property</em> to simplify each term in the product. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Going back to the weather model from a previous example, fix <span class="math notranslate nohighlight">\(x_0 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(x_1,\ldots,x_t \in \S\)</span>. Then, by the <em>Distribution of a Sample Path</em>,</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p>By assumption <span class="math notranslate nohighlight">\(\P[X_0 = x_0] = 1\)</span>. Moreover, we have previously shown that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \P[Z_{t-1} = z_{t-1}],
\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{t-1} = \mathrm{Same}\)</span> if <span class="math notranslate nohighlight">\(x_t = x_{t-1}\)</span> and <span class="math notranslate nohighlight">\(z_{t-1} = \mathrm{Change}\)</span> if <span class="math notranslate nohighlight">\(x_t \neq x_{t-1}\)</span>.</p>
<p>Hence, using the distribution of <span class="math notranslate nohighlight">\(Z_t\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]
= \begin{cases}
3/4 &amp; \text{if $x_t = x_{t-1}$},\\
1/4 &amp; \text{if $x_t \neq x_{t-1}$}.
\end{cases}
\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(n_T = |\{0 &lt; t \leq T : x_t = x_{t-1}\}|\)</span> be the number of transitions without change. Then,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
&amp;= \P[X_0 = x_0] \,\prod_{t=1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}]\\
&amp;= \prod_{t=1}^T\P[Z_{t-1} = z_{t-1}]\\
&amp;= (3/4)^{n_T} (1/4)^{T - n_T}.
\end{align*}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>It will be useful later on to observe that the <em>Distribution of a Sample Path</em> generalizes to</p>
<div class="math notranslate nohighlight">
\[
\P[X_{s+1} = x_{s+1}, X_{s+2} = x_{s+2}, \ldots, X_T = x_T\,|\,X_s = x_s]
= \prod_{t=s+1}^T \,\P[X_t = x_t\,|\,X_{t-1} = x_{t-1}].
\]</div>
<p>Based on the <em>Distribution of a Sample Path</em>, in order to specify the distribution of the process it suffices to specify</p>
<ol class="arabic simple">
<li><p>the <em>initial distribution</em><span class="math notranslate nohighlight">\(\idx{initial distribution}\xdi\)</span> <span class="math notranslate nohighlight">\(\mu_x := \P[X_0 = x]\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>; and</p></li>
<li><p>the <em>transition probabilities</em><span class="math notranslate nohighlight">\(\idx{transition probability}\xdi\)</span> <span class="math notranslate nohighlight">\(\P[X_{t+1} = x\,|\,X_{t} = x']\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(x'\)</span>.</p></li>
</ol>
&#13;

<h2><span class="section-number">7.2.2. </span>Time-homogeneous case: transition matrix<a class="headerlink" href="#time-homogeneous-case-transition-matrix" title="Link to this heading">#</a></h2>
<p>It is common to further assume that the process is <em>time-homogeneous</em><span class="math notranslate nohighlight">\(\idx{time-homogeneous process}\xdi\)</span>, which means that the transition probabilities do not depend on <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\P[X_{t+1} =x\,|\,X_{t} = x']
= \P[X_1 =x\,|\,X_{0} = x']
=: p_{x',x},
\quad \forall t=1,\ldots
\]</div>
<p>where the last equality is a definition. We can then collect the transition probabilities into a matrix.</p>
<p><strong>DEFINITION</strong> <strong>(Transition Matrix)</strong> <span class="math notranslate nohighlight">\(\idx{transition matrix}\xdi\)</span> The matrix</p>
<div class="math notranslate nohighlight">
\[
P = (p_{x',x})_{x,x' \in \S}
\]</div>
<p>is called the transition matrix of the chain. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>We also let <span class="math notranslate nohighlight">\(\mu_{x} = \P[X_0 = x]\)</span> and we think of <span class="math notranslate nohighlight">\(\bmu = (\mu_{x})_{x \in \S}\)</span> as a vector. The convention in Markov chain theory is to think of probability distributions such as <span class="math notranslate nohighlight">\(\bmu\)</span> as <em>row vectors</em>. We will see later why it simplifies the notation somewhat.</p>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Going back to the weather model, let us number the states as follows: <span class="math notranslate nohighlight">\(1 = \mathrm{Dry}\)</span> and <span class="math notranslate nohighlight">\(2 = \mathrm{Wet}\)</span>. Then the transition matrix is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P
= \begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}.
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(Random Walk on the Petersen Graph, continued)</strong> Consider again the random walk on the Petersen graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span>. We number the vertices <span class="math notranslate nohighlight">\(1, 2,\ldots, 10\)</span>. To compute the transition matrix, we list for each vertex its neighbors and put the value <span class="math notranslate nohighlight">\(1/3\)</span> in the corresponding columns. For instance, vertex <span class="math notranslate nohighlight">\(1\)</span> has neighbors <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(5\)</span> and <span class="math notranslate nohighlight">\(6\)</span>, so row <span class="math notranslate nohighlight">\(1\)</span> has <span class="math notranslate nohighlight">\(1/3\)</span> in columns <span class="math notranslate nohighlight">\(2\)</span>, <span class="math notranslate nohighlight">\(5\)</span>, and <span class="math notranslate nohighlight">\(6\)</span>. And so on.</p>
<p>We get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = \begin{pmatrix}
0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0\\
1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3\\
1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0\\
0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 1/3\\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3\\
0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 0 &amp; 0
\end{pmatrix}
\end{split}\]</div>
<p>We have already encountered a matrix that encodes the neighbors of each vertex, the adjacency matrix. Here we can recover the transition matrix by multiplying the adjacency matrix by <span class="math notranslate nohighlight">\(1/3\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>Transition matrices have a very special structure.</p>
<p><strong>THEOREM</strong> <strong>(Transition Matrix is Stochastic)</strong> <span class="math notranslate nohighlight">\(\idx{transition matrix is stochastic theorem}\xdi\)</span> The transition matrix <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix<span class="math notranslate nohighlight">\(\idx{stochastic matrix}\xdi\)</span>, that is, all its entries are nonnegative and all its rows sum to one. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof:</em> Indeed,</p>
<div class="math notranslate nohighlight">
\[
\sum_{x \in \S} p_{x',x} = \sum_{x \in \S} \P[X_1 = x\,|\,X_{0} = x'] = \P[X_1 \in \S \,|\,X_{0} = x'] = 1
\]</div>
<p>by the properties of the conditional probability. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>In matrix form, the condition can be stated as <span class="math notranslate nohighlight">\(P \mathbf{1} = \mathbf{1}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is an all-one vector of the appropriate size.</p>
<p>We have seen that any transition matrix is stochastic. Conversely, any stochastic matrix is the transition matrix of a Markov chain. That is, we can specify a Markov chain by choosing the number of states <span class="math notranslate nohighlight">\(n\)</span>, an initial distribution over <span class="math notranslate nohighlight">\(\mathcal{S} = [n]\)</span> and a stochastic matrix <span class="math notranslate nohighlight">\(P \in \mathbb{R}^{n\times n}\)</span>. Row <span class="math notranslate nohighlight">\(i\)</span> of <span class="math notranslate nohighlight">\(P\)</span> stipulates the probability distribution of the next state given that we are currently at state <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(Robot Vacuum)</strong> Suppose a robot vacuum roams around a large mansion with the following rooms: <span class="math notranslate nohighlight">\(1=\mathrm{Study}\)</span>, <span class="math notranslate nohighlight">\(2=\mathrm{Hall}\)</span>, <span class="math notranslate nohighlight">\(3=\mathrm{Lounge}\)</span>, <span class="math notranslate nohighlight">\(4=\mathrm{Library}\)</span>, <span class="math notranslate nohighlight">\(5=\mathrm{Billiard\ Room}\)</span>, <span class="math notranslate nohighlight">\(6=\mathrm{Dining\ Room}\)</span>, <span class="math notranslate nohighlight">\(7=\mathrm{Conservatory}\)</span>, <span class="math notranslate nohighlight">\(8=\mathrm{Ball\ Room}\)</span>, <span class="math notranslate nohighlight">\(9=\mathrm{Kitchen}\)</span>.</p>
<p><strong>Figure:</strong> A wrench (<em>Credit:</em> Made with <a class="reference external" href="https://www.midjourney.com/">Midjourney</a>)</p>
<p><img alt="Roomba" src="../Images/208cda012f226f8db1d9e4a27b9cbdc4.png" data-original-src="https://mmids-textbook.github.io/_images/Roomba_and_a_wrench-small.png"/></p>
<p><span class="math notranslate nohighlight">\(\bowtie\)</span></p>
<p>Once it is done cleaning a room, it moves to another one nearby according to the following stochastic matrix (check it is stochastic!):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = \begin{pmatrix}
0 &amp; 0.8 &amp; 0 &amp; 0.2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.3 &amp; 0 &amp; 0.2 &amp; 0 &amp; 0 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0.6 &amp; 0 &amp; 0 &amp; 0 &amp; 0.4 &amp; 0 &amp; 0 &amp; 0\\
0.1 &amp; 0.1 &amp; 0 &amp; 0 &amp; 0.8 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0.25 &amp; 0 &amp; 0 &amp; 0.75 &amp; 0 &amp; 0\\
0 &amp; 0.15 &amp; 0.15 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.35 &amp; 0.35\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.3 &amp; 0.4 &amp; 0.2 &amp; 0 &amp; 0.1\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
\end{split}\]</div>
<p>Suppose the initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> is uniform over the state space and let <span class="math notranslate nohighlight">\(X_t\)</span> be the room the vacuum is in at iteration <span class="math notranslate nohighlight">\(t\)</span>. Then <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> is a Markov chain. Unlike our previous examples, <span class="math notranslate nohighlight">\(P\)</span> is not symmetric. In particular, its rows sum to <span class="math notranslate nohighlight">\(1\)</span> but its columns do not. (Check it!) <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>When both rows and columns sum to <span class="math notranslate nohighlight">\(1\)</span>, we say that <span class="math notranslate nohighlight">\(P\)</span> is doubly stochastic.</p>
<p>With the notation just introduced, the distribution of a sample path simplifies further to</p>
<div class="math notranslate nohighlight">
\[
\P[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T]
= \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}.
\]</div>
<p>This formula has a remarkable consequence. The marginal distribution of <span class="math notranslate nohighlight">\(X_s\)</span> is a matrix power of <span class="math notranslate nohighlight">\(P\)</span>. As usual, we denote by <span class="math notranslate nohighlight">\(P^s\)</span> the <span class="math notranslate nohighlight">\(s\)</span>-th matrix power of <span class="math notranslate nohighlight">\(P\)</span>. Recall also that <span class="math notranslate nohighlight">\(\bmu\)</span> is a row vector.</p>
<p><strong>THEOREM</strong> <strong>(Time Marginals)</strong> <span class="math notranslate nohighlight">\(\idx{time marginals theorem}\xdi\)</span> For any <span class="math notranslate nohighlight">\(s \geq 1\)</span> and <span class="math notranslate nohighlight">\(x_s \in \S\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_s = x_s]
= \left(\bmu P^s\right)_{x_s}.
\]</div>
<p><span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof idea:</em> The idea is to think of <span class="math notranslate nohighlight">\(\P[X_s = x_s]\)</span> as the time <span class="math notranslate nohighlight">\(s\)</span> marginal over all trajectories up to time <span class="math notranslate nohighlight">\(s\)</span> – quantities we know how to compute the probabilities of. Then we use the <em>Distribution of a Sample Path</em> and “pushe the sums in.” This is easier seen on a simple case. We do the case <span class="math notranslate nohighlight">\(s=2\)</span> first.</p>
<p>Summing over all trajectories up to time <span class="math notranslate nohighlight">\(2\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\P[X_2 = x_2]\\
&amp;= \sum_{x_0 \in \S} \sum_{x_{1} \in \S}
\P[X_0 = x_0, X_1 = x_1, X_2 = x_2]\\
&amp;= \sum_{x_0 \in \S} \sum_{x_{1} \in \S}
\mu_{x_0} p_{x_{0},x_1} p_{x_{1},x_2},
\end{align*}\]</div>
<p>where we used the <em>Distribution of a Sample Path</em>.</p>
<p>Pushing the sum over <span class="math notranslate nohighlight">\(x_1\)</span> in, this becomes</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;= \sum_{x_0 \in \S} 
\mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_1} p_{x_{1},x_2}\\
&amp;= \sum_{x_0 \in \S} 
\mu_{x_0} (P^2)_{x_{0},x_2},
\end{align*}\]</div>
<p>where we recognized the definition of a matrix product – here <span class="math notranslate nohighlight">\(P^2\)</span>. The result then follows.</p>
<p><em>Proof:</em> For any <span class="math notranslate nohighlight">\(s\)</span>, by definition of a marginal,</p>
<div class="math notranslate nohighlight">
\[
\P[X_s = x_s]
= \sum_{x_0, \ldots, x_{s-1} \in \S}
\P[X_0 = x_0, X_1 = x_1,\ldots,X_{s-1} = x_{s-1}, X_s = x_s].
\]</div>
<p>Using the <em>Distribution of a Sample Path</em> in the time-homogeneous case, this evaluates to</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\P[X_s = x_s]
&amp;= \sum_{x_0, \ldots, x_{s-1} \in \S}
\mu_{x_0} \prod_{t=1}^s p_{x_{t-1},x_t}.
\end{align*}\]</div>
<p>The sum can be simplified by pushing the individual sums as far into the summand as possible</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\sum_{x_0, \ldots, x_{s-1} \in \S} \mu_{x_0} \prod_{t=1}^{s} p_{x_{t-1},x_t}\\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-2} \in \S} p_{x_{s-3},x_{s-2}} \sum_{x_{s-1} \in \S}  p_{x_{s-2},x_{s-1}} \,p_{x_{s-1},x_s}\\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-2} \in \S} p_{x_{s-3},x_{s-2}} \, \left(P^2\right)_{x_{s-2}, x_s} \\
&amp; \quad = \sum_{x_0 \in \S} \mu_{x_0} \sum_{x_{1} \in \S} p_{x_{0},x_{1}} \cdots \sum_{x_{s-3} \in \S} p_{x_{s-4},x_{s-3}} \, \left(P^3\right)_{x_{s-3}, x_s} \\
&amp; \quad = \cdots \\
&amp; \quad = \left(\bmu P^s\right)_{x_s},
\end{align*}\]</div>
<p>where on the second line we recognized the innermost sum as a matrix product, then proceeded similarly. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>The special case <span class="math notranslate nohighlight">\(\bmu = \mathbf{e}_x^T\)</span> gives that for any <span class="math notranslate nohighlight">\(x, y \in [n]\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_s = y\,|\,X_0 = x]
= (\boldsymbol{\mu} P^s)_y
= (\mathbf{e}_x^T P^s)_y
= (P^s)_{x,y}.
\]</div>
<p><strong>EXAMPLE:</strong> <strong>(Weather Model, continued)</strong> Suppose day <span class="math notranslate nohighlight">\(0\)</span> is <span class="math notranslate nohighlight">\(\mathrm{Dry}\)</span>, that is, the initial distribution is <span class="math notranslate nohighlight">\(\bmu = (1,0)^T\)</span>. What is the probability that it is <span class="math notranslate nohighlight">\(\mathrm{Wet}\)</span> on day <span class="math notranslate nohighlight">\(2\)</span>? We apply the formula above to get <span class="math notranslate nohighlight">\(\P[X_2 = 2]
= \left(\bmu P^2\right)_{2}\)</span>. Note that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\bmu P^2
&amp;= (1,0)^T  
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}\\
&amp;= (3/4,1/4)^T
\begin{pmatrix}
3/4 &amp; 1/4\\
1/4 &amp; 3/4
\end{pmatrix}\\
&amp;= (10/16,6/16)^T\\
&amp;= (5/8,3/8)^T.
\end{align*}\]</div>
<p>So the answer is <span class="math notranslate nohighlight">\(3/8\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>It will be useful later on to observe that the <em>Time Marginals Theorem</em> generalizes to</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = x_t\,|\,X_s = x_s]
= (P^{t-s})_{x_s,x_t},
\]</div>
<p>for <span class="math notranslate nohighlight">\(s \leq t\)</span>.</p>
<p>In the time-homogeneous case, an alternative way to represent a transition matrix is with a directed graph showing all possible transitions.</p>
<p><strong>DEFINITION</strong> <strong>(Transition Graph)</strong> <span class="math notranslate nohighlight">\(\idx{transition graph}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain over the state space <span class="math notranslate nohighlight">\(\mathcal{S} = [n]\)</span> with transition matrix <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j=1}^{n}\)</span>. The transition graph (or state transition diagram) of <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is a directed graph with vertices <span class="math notranslate nohighlight">\([n]\)</span> and a directed edge from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span> if and only if <span class="math notranslate nohighlight">\(p_{i,j} &gt; 0\)</span>. We often associate a weight <span class="math notranslate nohighlight">\(p_{i,j}\)</span> to that edge. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>NUMERICAL CORNER:</strong> Returning to our <em>Robot Vacuum Example</em>, the transition graph of the chain can be obtained by thinking of <span class="math notranslate nohighlight">\(P\)</span> as the weighted adjacency matrix of the transition graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">P_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>We define a graph from its adjancency matrix. See <a class="reference external" href="https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_numpy_array.html"><code class="docutils literal notranslate"><span class="pre">networkx.from_numpy_array()</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">G_robot</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy_array</span><span class="p">(</span><span class="n">P_robot</span><span class="p">,</span> <span class="n">create_using</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Drawing edge weights on a directed graph in a readable fashion is not straighforward. We will not do this here.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">n_robot</span> <span class="o">=</span> <span class="n">P_robot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G_robot</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">circular_layout</span><span class="p">(</span><span class="n">G_robot</span><span class="p">),</span> 
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)},</span> 
                 <span class="n">node_color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">'white'</span><span class="p">,</span> 
                 <span class="n">connectionstyle</span><span class="o">=</span><span class="s1">'arc3, rad = 0.2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/3ed7b79c7b64ae82a443d682f19bec765a062c280a163d9734fd0ce480d6d157.png" src="../Images/e3496ddf45cc8074ed0952cee5403722.png" data-original-src="https://mmids-textbook.github.io/_images/3ed7b79c7b64ae82a443d682f19bec765a062c280a163d9734fd0ce480d6d157.png"/>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>Once we have specified a transition matrix (and an initial distribution), we can simulate the corresponding Markov chain. This is useful to compute (approximately) probabilities of complex events through the law of large numbers. Here is some code to generate one sample path up to some given time <span class="math notranslate nohighlight">\(T\)</span>. We assume that the state space is <span class="math notranslate nohighlight">\([n]\)</span>. We use <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html"><code class="docutils literal notranslate"><span class="pre">rng.choice</span></code></a> to generate each transition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">def</span> <span class="nf">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">p</span><span class="o">=</span><span class="n">P</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">),:])</span>
            
    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Let’s try with our <em>Robot Vacuum</em>. We take the initial distribution to be the uniform distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[9. 6. 3. 6. 8. 6. 2. 1. 2. 6. 8.]
</pre></div>
</div>
</div>
</div>
<p>For example, we can use a simulation to approximate the expected number of times that room <span class="math notranslate nohighlight">\(9\)</span> is visited up to time <span class="math notranslate nohighlight">\(10\)</span>. To do this, we run the simulation a large number of times (say <span class="math notranslate nohighlight">\(1000\)</span>) and count the average number of visits to <span class="math notranslate nohighlight">\(9\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">z</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">N_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">visits_to_z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_samples</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_samples</span><span class="p">):</span>
    <span class="n">visits_to_z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="n">z</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">visits_to_z</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>1.193
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>CHAT &amp; LEARN</strong> Markov Decision Processes (MDPs) are a framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. Ask your favorite AI chatbot to explain the basic components of an MDP and how they relate to Markov chains. Discuss some applications of MDPs, such as in robotics or game theory. <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> Which of the following is true about the transition matrix <span class="math notranslate nohighlight">\(P\)</span> of a Markov chain?</p>
<p>a) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and all columns sum to one.</p>
<p>b) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and all rows sum to one.</p>
<p>c) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and both rows and columns sum to one.</p>
<p>d) All entries of <span class="math notranslate nohighlight">\(P\)</span> are non-negative, and either rows or columns sum to one, but not both.</p>
<p><strong>2</strong> What is the <em>Markov Property</em>?</p>
<p>a) The past and future are independent.</p>
<p>b) The past and future are independent given the present.</p>
<p>c) The present and future are independent given the past.</p>
<p>d) The past, present, and future are all independent.</p>
<p><strong>3</strong> Consider a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t \ge 0}\)</span> on state space <span class="math notranslate nohighlight">\(S\)</span>. Which of the following equations is a direct consequence of the <em>Markov Property</em>?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t] = \mathbb{P}[X_{t+1} = x_{t+1}]\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t, X_{t-1} = x_{t-1}] = \mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t]\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t] = \mathbb{P}[X_{t+1} = x_{t+1} | X_0 = x_0]\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\mathbb{P}[X_{t+1} = x_{t+1} | X_t = x_t, X_{t-1} = x_{t-1}] = \mathbb{P}[X_{t+1} = x_{t+1}]\)</span></p>
<p><strong>4</strong> Consider a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t\geq0}\)</span> with transition matrix <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j}\)</span> and initial distribution <span class="math notranslate nohighlight">\(\mu\)</span>. Which of the following is true about the distribution of a sample path <span class="math notranslate nohighlight">\((X_0, X_1, \ldots, X_T)\)</span>?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \sum_{t=1}^T p_{x_{t-1},x_t}\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \prod_{t=0}^T \mu_{x_t}\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \sum_{t=0}^T \mu_{x_t}\)</span></p>
<p><strong>5</strong> In the random walk on the Petersen graph example, if the current state is vertex 9, what is the probability of transitioning to vertex 4 in the next step?</p>
<p>a) 0</p>
<p>b) 1/10</p>
<p>c) 1/3</p>
<p>d) 1</p>
<p>Answer for 1: b. Justification: The text states that “the transition matrix <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, that is, all its entries are nonnegative and all its rows sum to one.”</p>
<p>Answer for 2: b. Justification: The text summarizes the <em>Markov Property</em> as “the past and the future are independent given the present.”</p>
<p>Answer for 3: b. Justification: This is a direct statement of the <em>Markov Property</em>, where the future state <span class="math notranslate nohighlight">\(X_{t+1}\)</span> depends only on the present state <span class="math notranslate nohighlight">\(X_t\)</span> and not on the past state <span class="math notranslate nohighlight">\(X_{t-1}\)</span>.</p>
<p>Answer for 4: a. Justification: The text states the <em>Distribution of a Sample Path</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[X_0 = x_0, X_1 = x_1, \ldots, X_T = x_T] = \mu_{x_0} \prod_{t=1}^T p_{x_{t-1},x_t}.
\]</div>
<p>Answer for 5: c. Justification: In the Petersen graph, each vertex has 3 neighbors, and the random walk chooses one uniformly at random.</p>
    
</body>
</html>