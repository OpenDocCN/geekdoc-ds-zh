- en: Chapter 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting Up CUDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter is here for anyone who is completely new to CUDA. We look at how
    to install CUDA on the various OSs, what tools you can use, and how CUDA compiles.
    Finally, we look at how to have the API help you identify the coding and API errors
    everyone makes.
  prefs: []
  type: TYPE_NORMAL
- en: 'CUDA is supported on three major OSs: Windows, Mac, and Linux. By far the easiest
    platform to use and learn CUDA with is the OS you are most familiar with using
    for programming development. For an absolute beginner, the Windows OS in conjunction
    with Microsoft Visual C++ is likely to be the best choice. Both the Windows and
    Mac installations are fairly much point and click. Both provide fairly standard
    integrated development environments that work well with CUDA.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Sdk Under Windows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To install CUDA onto a PC running Windows, you’ll need to download the following
    components from the NVIDIA developer portal at [*http://developer.nvidia.com/cuda-toolkit-41*](http://developer.nvidia.com/cuda-toolkit-41).
    Note by the time this book hit the press release 5 of the toolkit was in its release
    candidate phase. Please check the NVIDIA website for the latest version.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need an already installed version of Microsoft Visual Studio 2005,
    2008, or 2010\. The first step is to download and install the latest set of NVIDIA
    development drivers for your relevant operating system from the previous link.
    Then you will need either the 32- or 64-bit version of the CUDA toolkit and GPU
    computing and SDK code samples. Make sure you pick the correct version for your
    OS. Install them in this order:'
  prefs: []
  type: TYPE_NORMAL
- en: 1. NVIDIA development drivers
  prefs: []
  type: TYPE_NORMAL
- en: 2. CUDA toolkit
  prefs: []
  type: TYPE_NORMAL
- en: 3. CUDA SDK
  prefs: []
  type: TYPE_NORMAL
- en: 4. GPU computing SDK
  prefs: []
  type: TYPE_NORMAL
- en: 5. Parallel Nsight debugger
  prefs: []
  type: TYPE_NORMAL
- en: Under Windows 7, the SDK installs all of its files into “ProgramData,” which
    is a hidden directory of the C drive. To view the files you either need to always
    go via the CUDA SDK icon created on the desktop or go to “Folder Options” in Windows
    and tell it to show hidden files ([Figure 4.1](#F0010)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-01-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 “Folder Options” to see hidden files.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CUDA supports Visual Studio versions from 2005 to 2010 including, for the most
    part, the express versions. The express versions are available free of charge
    from Microsoft. The professional versions are also available to registered students
    free of charge via the DreamSpark program at [*https://www.dreamspark.com*](https://www.dreamspark.com).
  prefs: []
  type: TYPE_NORMAL
- en: To register all you need to do is supply your university or college details
    and identification numbers and you can download Visual Studio and many other programming
    tools. The program is also not just restricted to U.S.-based academic institutions,
    but available to students worldwide.
  prefs: []
  type: TYPE_NORMAL
- en: On the whole, Visual Studio 2008 has the best support for CUDA and compiles
    somewhat quicker than Visual Studio 2010\. Visual Studio 2010 has, however, one
    very useful feature, which is automatic syntax checking of source code. Thus,
    if you use a type that is not defined, it underlines the error in red, just as
    Microsoft Word underlines spelling errors. This is an incredibly useful feature
    as it saves a lot of unnecessary compilation cycles for obvious issues. Thus,
    I’d recommend the 2010 version, especially if you can download it for free from
    DreamSpark.
  prefs: []
  type: TYPE_NORMAL
- en: Projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One quick way of creating a project is to take one of the SDK examples, remove
    all the unnecessary project files, and insert your own source files. Note your
    CUDA source code should have a “.cu” extension so that it will be compiled by
    the NVIDIA compiler instead of Visual C. However, as we see later, you can also
    simply create a basic project framework using the project template wizard.
  prefs: []
  type: TYPE_NORMAL
- en: 64-bit users
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When using Windows 64-bit version, be aware that some of the project files
    are set up to run as 32-bit applications by default. Thus, when you try to build
    them you may get the error message: Fatal Error LNK1181: cannot open input file
    ‘cutil32D.lib’.'
  prefs: []
  type: TYPE_NORMAL
- en: This was not installed, as you most likely installed only the 64-bit version
    of the SDK along with the 64-bit version of Windows. To correct this issue all
    we have to do is set the target from 64 bits to 32 bits, which we do using the
    Build menu in Visual Studio, and then change the platform to X64 as shown in [Figure
    4.2](#F0015).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-02-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 Visual C platform selection.
  prefs: []
  type: TYPE_NORMAL
- en: You may be prompted at the point you initiate a rebuild to save the project.
    Just add “_X86” to the end of the project name and save. The project will then
    build under a 64-bit environment and link in the correct library files.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may also find an issue with a missing library, such as “cutil32.lib,” for
    example. When the SDK is installed, it sets an environment variable, `$(CUDA_LIB_PATH)`.
    This is usually set to: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\lib\X64.'
  prefs: []
  type: TYPE_NORMAL
- en: You may find the path setup in the default project files may not have `$(CUDA_LIB_PATH)`
    as one of the entries. To add it, click on the project and then select “Project→Properties.”
    This brings up the dialog box shown in [Figure 4.3](#F0020).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-03-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 Additional library path.
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on the “…” button on the far right brings up a dialog where you can
    add the library path ([Figure 4.4](#F0025)). Simply add “$(CUDA_LIB_PATH)” as
    a new line and the project should now link.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-04-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 Adding library directories.
  prefs: []
  type: TYPE_NORMAL
- en: If you wish to build both 64-bit CUDA applications and 32-bit CUDA applications,
    both the 32- and 64-bit CUDA toolkits need to be installed. The samples from the
    SDK also require both the 32- and 64-bit versions of the SDK to be installed to
    be able to build both 32- and 64-bit versions of the samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can build the necessary libraries by going to the following directories
    and building the solution files:'
  prefs: []
  type: TYPE_NORMAL
- en: C:\ProgramData\NVIDIA Corporation\NVIDIA GPU Computing SDK 4.1\C\common
  prefs: []
  type: TYPE_NORMAL
- en: C:\ProgramData\NVIDIA Corporation\NVIDIA GPU Computing SDK 4.1\shared
  prefs: []
  type: TYPE_NORMAL
- en: You will find the necessary libraries in
  prefs: []
  type: TYPE_NORMAL
- en: C:\ProgramData\NVIDIA Corporation\NVIDIA GPU Computing SDK 4.1\C\common\lib\X64.
  prefs: []
  type: TYPE_NORMAL
- en: You can also add these manually to any project that is missing them. Unfortunately,
    the SDK samples are not set up so they automatically build the necessary libraries
    when needed. The binaries for the libraries also are not supplied, which makes
    actually building the SDK samples a little frustrating.
  prefs: []
  type: TYPE_NORMAL
- en: Creating projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To create a new CUDA-enabled application, simply create a CUDA application using
    the “File→New→Project Wizard” as shown in [Figure 4.5](#F0030). The wizard will
    then create a single project containing the file “kernel.cu,” which contains a
    mix of code, some of which executes on the CPU and some of which executes on the
    GPU. The GPU code is contained in the function `addKernel`. This function simply
    takes a pointer to a destination array, `c`, and a couple of pointers to two input
    arrays, `a` and `b`. It then adds the contents of the `a` and `b` arrays together
    and stores the result in the destination array, `c`. It’s a very simple example
    of the framework needed to execute a CUDA program.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-05-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 CUDA Project Wizard.
  prefs: []
  type: TYPE_NORMAL
- en: Also included is the basic code to copy data to a device, invoke the kernel,
    and copy data back from the device to the host. It’s a very useful starter project
    to get you compiling something under CUDA. We cover the standard framework needed
    to get a CUDA program working later in the text. It’s useful to look at the code
    and try to understand it if you can. However, don’t worry at this stage if it
    doesn’t make sense as we’ll build gradually on how to write programs for CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Linux
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CUDA is supported for the following Linux distributions. The supported versions
    will vary depending on which version of the CUDA toolkit you are installing.
  prefs: []
  type: TYPE_NORMAL
- en: • Fedora 14
  prefs: []
  type: TYPE_NORMAL
- en: • Redhat 6.0 and 5.5/CentOS 6.2 (the free version of Redhat)
  prefs: []
  type: TYPE_NORMAL
- en: • Ubuntu 11.04
  prefs: []
  type: TYPE_NORMAL
- en: • OpenSUSE 11.2
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in installing CUDA on a Linux platform is to make sure you have
    the latest set of kernel software. Use the following command from a terminal window
    to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `sudo` command will log you in as the administrator. The `yum` command is
    the standard installation tool for the Linux RPM package. You are simply asking
    it to check for all installed packages and see if any updates are available. This
    ensures your system is fully up to date before installing any drivers. Many of
    the GUI-based installations also have GUI-based versions of the software updates
    that replace the older command line update interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the kernel has been updated to the latest level, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo yum install gcc-c++ kernel-devel`'
  prefs: []
  type: TYPE_NORMAL
- en: This will install the standard GNU C++ environment as well as the kernel source
    you’ll need to rebuild the kernel. Be aware that package names are case-sensitive.
    This will prompt you for around a 21 MB download and take a couple of minutes
    to install. Again, if you prefer, you can install the package via the GUI software
    installer for the particular OS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, as you are likely to be drawing some graphical output, you’ll need
    an OpenGL development environment. Install this with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now you’re ready to install the CUDA drivers. Make sure you install at least
    version 4.1 of the CUDA toolkit. There are a number of ways to install the updated
    NVIDIA drivers. NVIDIA does not release the source code to the drivers, so by
    default most Linux distributions install a very basic graphics driver.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel base driver installation (CentOS, Ubuntu 10.4)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The CUDA releases should be used with a specific set of *development* drivers.
    Installing drivers by methods other than the one listed here may result in CUDA
    not working. Note the versions of the OS supported for the given version of the
    CUDA toolkit. These may not be the latest version of the particular Linux distribution.
    Using a later distribution will likely *not* work. Thus, the first installation
    step is to replace any existing drivers with the version specified for your specific
    Linux distribution. See [Figure 4.6](#F0035).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-06-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 Supported Linux downloads and supported driver versions as of September
    2012.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the download is complete, you need to boot Linux in text-only mode. Unlike
    Windows, which is always in graphics mode, text mode is required to install the
    drivers under Linux. You can make the system boot into text on most distributions
    using the following command from a Terminal window (usually under the Systems
    menu in the GUI):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will reboot the Linux machine and bring it back up in text mode. You can
    use `sudo init 5` to restore the graphics mode later.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you get an error such as “User <user_name> is not in sudoers file,” login
    as root using the `su` command. Edit the “/etc/sudoers” file and append the following
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Be careful to replace `your_user_name` with your login name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Certain distributions (e.g., Ubuntu) insist on booting to the GUI, regardless
    of the `init` mode. One method of resolving is as follows, from a text window.
    Edit the grub startup file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: to
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`GRUB_CMDLINE_LINUX_DEFAULT="text"`'
  prefs: []
  type: TYPE_NORMAL
- en: Now update grub using
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Finally, reboot your machine and it should come up in text-only mode. Use the
    original lines to boot to the GUI again once the drivers are installed.
  prefs: []
  type: TYPE_NORMAL
- en: Now navigate to the area you stored the “.run” file you downloaded from the
    NVIDIA website. Then type
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo sh NVIDIA-Linux-x86_64-285.05.33.run`'
  prefs: []
  type: TYPE_NORMAL
- en: The exact version of the driver you download will of course be different. You
    will be asked to agree to the NVIDIA license and will then have to wait a few
    minutes while everything installs. During this process the installer will attempt
    to replace the default Nouveau driver with the necessary NVIDIA drivers. If asked
    if you want to do this, select “Yes.” This is an error-prone process and not every
    distribution works out of the box. If the NVIDIA installer is unable to remove
    the Nouveau driver then it may be necessary to blacklist the driver so the NVIDIA
    installer can install the correct drivers.
  prefs: []
  type: TYPE_NORMAL
- en: When you have the NVIDIA drivers installed correctly, type
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The machine will then reboot into the regular graphics mode. See earlier for
    Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: The next task is to install the toolkit. There are a number available—select
    Fedora, Red Hat, Ubuntu, OpenSUSE, or SUSE depending on your distribution. As
    before, simply navigate to where you installed the SDK and run it by typing
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'where `<sdk_version>` is the file you downloaded. It will then install all
    the tools needed and print a message saying the installation was successful. It
    then mentions you have to update the `PATH` and `LD_LIBRARY_PATH` environment
    variables, which you have to do by hand. To do this, you need to edit the “/etc/profile”
    startup file. Add the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that the file has to be writable. Use the “sudo chmod +w /etc/profile”
    to make it writable if required. You can edit this file with your favorite editor
    using such a command as “sudo nano/etc/profile”.
  prefs: []
  type: TYPE_NORMAL
- en: Now log out and log back in again and type
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This will list all of the current environment variable settings. Check for the
    two new entries you just amended. CUDA is now installed into the “/usr/local/bin”
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: Next we’ll need the GNU C++ compiler. Install the package “g++” from whatever
    software installer you are using on your system.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to install the SDK sample codes, so we have something to build
    and test. Download these from the NVIDIA site and run them, again using the `sh
    sdk_version.run` command (replace `sdk_version` with the actual one you download).
    Do *not* run this install as root as you will otherwise have to be logged in as
    root to build any of the samples.
  prefs: []
  type: TYPE_NORMAL
- en: By default the SDK will install to a subdirectory of your user account area.
    It may complain it can’t find the CUDA installation and will use the default directory
    (the same one CUDA was installed to earlier). You can safely ignore this message.
  prefs: []
  type: TYPE_NORMAL
- en: Once the GPU computing SDK is installed, you then need to go to the “Common”
    subdirectory and run `make` to create a set of libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Once this is done the SDK samples should build, allowing you to execute your
    first CUDA program in Linux and of course see if the driver is working correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Mac
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Macintosh version is available, as with the other versions, from [*http://developer.nvidia.com/cuda-toolkit-41*](http://developer.nvidia.com/cuda-toolkit-41).
    Simply download and install the packages in the following order:'
  prefs: []
  type: TYPE_NORMAL
- en: • Development drivers
  prefs: []
  type: TYPE_NORMAL
- en: • CUDA toolkit
  prefs: []
  type: TYPE_NORMAL
- en: • CUDA tools SDK and code samples
  prefs: []
  type: TYPE_NORMAL
- en: CUDA 4.1 requires Mac OS release 10.6.8 (Snow Leopard) or later. The latest
    release (10.7.x) or Lion release is available as a download from the Apple store
    or via a separate purchase from Apple.
  prefs: []
  type: TYPE_NORMAL
- en: The SDK installs into the “GPU Computing” directory under the “Developer” higher-level
    directory. Simply browse the “Developer/GPU Computing/C/bin/darwin/release” directory
    and you will find precompiled executables. Running the `deviceQuery` tool is useful
    to verify you have correctly installed the drivers and runtime environment.
  prefs: []
  type: TYPE_NORMAL
- en: To compile the samples, you will need XCode installed. This is the equivalent
    of GCC (GNU C Compiler) for the Mac. XCode can be downloaded from the Apple store.
    It’s not a free product, but is available free of charge to anyone on the Apple
    Developer program, which includes both development of Macintosh and iPhone/iPad
    applications. It was also released shortly after the Lion OS as a free download
    for Lion OS owners.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once XCode is installed, simply open a terminal window. To do this, go to Finder,
    open Utilities, and then double-click on the Terminal window. Type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Replace `project` with the name of the particular SDK application you wish to
    compile. If you receive compilation errors, you have either not downloaded the
    XCode package or have an older version than is required.
  prefs: []
  type: TYPE_NORMAL
- en: Installing a Debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CUDA provides a debug environment called Parallel Nsight on the Windows platform.
    This provides support for debugging CPU and GPU code and highlights areas where
    things are working less than efficiently. It also helps tremendously when trying
    to debug multithreaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: Nsight is completely free and is a hugely useful tool. All it requires is that
    you register as a CUDA-registered developer, which is again entirely free. Once
    registered, you will be able to download the tool from the NVIDIA website.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you must have Visual Studio 2008 or later (not the express version)
    and you must have installed Service Pack 1\. There is a link within the release
    notes of Nsight to the SP1 download you need to install.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel Nsight comes as two parts, an application that integrates itself into
    Visual Studio as shown in [Figure 4.7](#F0040), and a separate monitoring application.
    The monitoring application works in conjunction with the main application. The
    monitor is usually resident, but does not have to be, on the same machine as the
    Visual Studio environment. Parallel Nsight works best with two CUDA capable GPUs,
    a dedicated GPU to run the code on and one to use as the regular display. Thus,
    the GPU running the target code cannot be used to run a second display. As most
    GPU cards have dual-monitor outputs, you can simply run two monitors off the display
    card should you have a dual-monitor setup. Note in the latest release, 2.2, the
    need for two GPUs was dropped.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-07-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 Nsight integrated into Microsoft Visual Studio.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also possible to set up the tool to acquire data from a remote GPU. However,
    in most cases it’s easier to buy a low-end GPU and install it into your PC or
    workstation. The first step needed to set up Parallel Nsight on Windows is to
    disable TDR ([Figure 4.8](#F0045)). TDR (Timeout Detection and Recovery) is a
    mechanism in Windows that detects crashes in the driver-level code. If the driver
    stops responding to events, Windows resets the driver. As the driver will halt
    when you define a breakpoint, this feature needs to be disabled.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-08-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 Disabling Windows kernel timeout.
  prefs: []
  type: TYPE_NORMAL
- en: To set the value, simply run the monitor and click on the “Nsight Monitor Options”
    hyperlink at the bottom right of the monitor dialog box. This will bring up the
    dialog shown in [Figure 4.8](#F0045). Setting the “WDDM TDR enabled” will modify
    the registry to disable this feature. Reboot your PC, and Parallel Nsight will
    no longer warn you TDR is enabled.
  prefs: []
  type: TYPE_NORMAL
- en: To use Parallel Nsight on a remote machine, simply install the monitor package
    only on the remote Windows PC. When you first run the monitor, it will warn you
    Windows Firewall has blocked “Public network” (Internet based) access to the monitor,
    which is entirely what you want. However, the tool needs to have access to the
    local network, so allow this exception to any firewall rules you have set up on
    the monitor machine. As with a local node, you will have to fix the TDR issue
    and reboot once installed.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to run Visual Studio on the host PC and select a new analysis
    activity. You will see a section near the top of the window that looks like [Figure
    4.9](#F0050). Notice the “Connection Name” says `localhost`, which just means
    your local machine. Open Windows Explorer and browse the local network to see
    the name of the Windows PC you would like to use to remotely debug. Replace `localhost`
    with the name shown in Windows Explorer. Then press the “Connect” button. You
    should see two confirmations that the connection has been made as shown in [Figure
    4.10](#F0055).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-09-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 Parallel Nsight remote connection.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-10-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 Parallel Nsight connected remotely.
  prefs: []
  type: TYPE_NORMAL
- en: First, the “Connect” button will change to a “Disconnect.” Second, the “Connection
    Status” box should turn green and show all the possible GPUs on the target machine
    ([Figure 4.11](#F0060)). In this case we’re connecting to a test PC that has five
    GTX470 GPU cards set up on it.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/F000041f04-11-9780124159334.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 Parallel Nsight connection status.
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on the “Launch” button on the “Application Control” panel next to the
    “Connection Status” panel will remotely launch the application on the target machine.
    However, prior to this all the necessary files need to be copied to the remote
    machine. This takes a few seconds or so, but is all automatic. Overall, it’s a
    remarkably simple way of analyzing/debugging a remote application.
  prefs: []
  type: TYPE_NORMAL
- en: You may wish to set up Parallel Nsight in this manner if, for example, you have
    a laptop and wish to debug, or simply remotely run, an application that will run
    on a GPU server. Such usage includes when a GPU server or servers are shared by
    people who use it at different times, teaching classes, for example. You may also
    have remote developers who need to run code on specially set up test servers,
    perhaps because those servers also contain huge quantities of data and it’s not
    practical or desirable to transfer that data to a local development machine. It
    also means you don’t need to install Visual C++ on each of the remote servers
    you might have.
  prefs: []
  type: TYPE_NORMAL
- en: On the Linux and Mac side the debugger environment is CUDA-GDB. This provides
    an extended GNU debugger package. As with Parallel Nsight it allows debugging
    of both host and CUDA code, which includes setting a breakpoint in the CUDA code,
    single step, select a debug thread, etc. Both CUDA-GDB and the Visual Profiler
    tools are installed by default when you install the SDK, rather than being a separate
    download as with Parallel Nsight. As of 2012, Parallel Nsight was also released
    under the Eclipse environment for Linux.
  prefs: []
  type: TYPE_NORMAL
- en: The major difference between Windows and Mac/Linux was the profiling tool support.
    The Parallel Nsight tool is in this respect vastly superior to the Visual Profiler.
    The Visual Profiler is also available on Windows. It provides a fairly high-level
    overview and recommendations as to what to address in the code, and therefore
    is very suited to those starting out using CUDA. Parallel Nsight, by contrast,
    is aimed at a far more advanced user. We cover usage of both Parallel Nsight and
    Visual Profiler later in subsequent chapters. However, the focus throughout this
    text is on the use of Parallel Nsight as the primary debugging/analysis tool for
    GPU development.
  prefs: []
  type: TYPE_NORMAL
- en: For advanced CUDA development I’d strongly recommend using Parallel Nsight for
    debugging and analysis. For most people new to CUDA the combination of the Visual
    Profiler and CUDA-GDB work well enough to allow for development.
  prefs: []
  type: TYPE_NORMAL
- en: Compilation Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The NVIDIA compiler, NVCC, sits in the background and is invoked when a CUDA
    source file needs to be compiled. The file extensions shown in [Table 4.1](#T0010)
    are used to define files as with CUDA source files or regular source files. This
    determines which compiler will be invoked, NVCC or the host compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.1 Different CUDA File Types
  prefs: []
  type: TYPE_NORMAL
- en: '| File Extension | Meaning | Processed By |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| .cu | Mixed host and device source file. | NVCC |'
  prefs: []
  type: TYPE_TB
- en: '| .cup | A preprocessed expanded version of .cu file. | NVCC |'
  prefs: []
  type: TYPE_TB
- en: '| .c, .cc, .cpp | A host C or C++ source file. | Host compiler |'
  prefs: []
  type: TYPE_TB
- en: '| .ptx, .gpu | Intermediate virtual assembly files. | NVCC |'
  prefs: []
  type: TYPE_TB
- en: '| .cubin | Binary image of GPU code. | NVCC |'
  prefs: []
  type: TYPE_TB
- en: The generated executable file, or fat binary, contains one or more binary executable
    images for the different GPU generations. It also contains a PTX image, allowing
    the CUDA runtime to do just-in-time (JIT) compilation. This is very similar to
    Java byte code where the target is a virtual architecture, and this is compiled
    to the actual target hardware at the point the program is invoked. The PTX JIT
    compilation only happens if the executable does not contain a binary image that
    is identical to the GPU in use. Consequently, all future architectures are backward
    compatible with the basic-level virtual architecture. Even GPUs for which the
    program was not compiled will execute legacy GPU code by simply compiling at runtime
    the PTX code embedded in the executable.
  prefs: []
  type: TYPE_NORMAL
- en: Just as with Java, code depositories are supported. Defining the environment
    variable `CUDA_DEVCODE_CACHE` to point to a directory will cause the runtime to
    save the compiled binary for later use, thus avoiding the startup delay necessary
    to compile the PTX code for the unknown GPU variant every time it is invoked.
  prefs: []
  type: TYPE_NORMAL
- en: We cover in the later chapters how you can view the real target assembly code,
    the result of the PTX to target translation.
  prefs: []
  type: TYPE_NORMAL
- en: Error Handling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Error handling in CUDA, as with C in general, is not as good as it could be.
    There are few runtime checks performed, and if you do something stupid, the runtime
    will usually allow it. This results in GPU programs that exit strangely. If you
    are lucky, you will get an error message which, like compiler errors, you learn
    to interpret over time.
  prefs: []
  type: TYPE_NORMAL
- en: Almost all function calls in CUDA return the error type `cudaError_t`, which
    is simply an integer value. Any value other than `cudaSuccess` will indicate a
    fatal error. This is usually caused by your program not setting up something correctly
    prior to use, or using an object after it has been destroyed. It can also be caused
    by the GPU kernel timeout present in Microsoft Windows if the kernel runs for
    more than a few seconds and you have not disabled this when installing tools such
    as Parallel Nsight (see previous section). Out-of-bounds memory accesses may generate
    exceptions that will often print various error messages to `stderr` (standard
    error output).
  prefs: []
  type: TYPE_NORMAL
- en: As every function returns an error code, every function call must be checked
    and some handler written. This makes for very tiresome and highly indented programming.
    For example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To avoid this type of repetitive programming, throughout the book we will use
    the following macro definition to making calls to the CUDA API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: What this macro does is to allow you to specify `x` as some function call, for
    example,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This then creates a temporary variable `a` and assigns to it the return value
    of the function, which is of type `cudaError_t`. It then checks if this is not
    equal to `cudaSuccess`, that is, the call encountered some error. If there was
    an error detected, it prints to the screen the error returned plus a short description
    of what the error means. It also uses the assert macro, which identifies the source
    file and line in which the error occurs so you can easily track down the point
    at which the error is being detected.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique works for all the CUDA calls except for the invocation of kernels.
    Kernels are the programs you write to run on the GPU. These are executed using
    the `<<<` and `>>>` operators as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For error checking of kernels, we’ll use the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This function should be called immediately after executing the kernel call.
    It checks for any immediate errors, and if so, prints an error message, resets
    the GPU, optionally waits for a key press via the `wait_exit` function, and then
    exits the program.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is not foolproof, as the kernel call is asynchronous with the
    CPU code. That is, the GPU code is running in the background at the time we call
    `cudaPeekAtLastError`. If there has been no error detected *at this time*, then
    we see no error printed and the function continues to the next code line. Often
    that next code line will be a copy back from GPU memory to CPU memory. The error
    in the kernel may cause a subsequent API call to fail, which is almost always
    the next API call after the kernel call. Surrounding all calls to the API with
    the `CUDA_CALL` macro will flag the error at this point.
  prefs: []
  type: TYPE_NORMAL
- en: You can also force the kernel to complete prior to the error checking by simply
    inserting a call to `cudaDeviceSynchronize` prior to the `cudaPeekAtLastError`
    call. However, only do this on the debug version of the program or where you want
    the CPU to idle while the GPU is busy. As you should understand by the end of
    this text, such synchronous operation is good for debugging, but will harm performance,
    so you should be careful these calls do not remain in production code if they
    were inserted solely for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should now have a working installation of the CUDA SDK, including the GPU
    computing SDK samples and a debugging environment. You should be able to build
    a simple GPU SDK sample, such as the `deviceQuery` project, and have it identify
    the GPUs in your system when run.
  prefs: []
  type: TYPE_NORMAL
