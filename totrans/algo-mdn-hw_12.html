<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Pipeline Hazards</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Pipeline Hazards</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/pipelining/hazards/">https://en.algorithmica.org/hpc/pipelining/hazards/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p><a href="../">Pipelining</a> lets you hide the latencies of instructions by running them concurrently, but also creates some potential obstacles of its own — characteristically called <em>pipeline hazards</em>, that is, situations when the next instruction cannot execute on the following clock cycle.</p><p>There are multiple ways this may happen:</p><ul><li>A <em>structural hazard</em> happens when two or more instructions need the same part of CPU (e.g., an execution unit).</li><li>A <em>data hazard</em> happens when you have to wait for an operand to be computed from some previous step.</li><li>A <em>control hazard</em> happens when a CPU can’t tell which instructions it needs to execute next.</li></ul><p>The only way to resolve a hazard is to have a <em>pipeline stall</em>: stop the progress of all previous steps until the cause of congestion is gone. This creates <em>bubbles</em> in the pipeline — analogous with air bubbles in fluid pipes — a time-propagating condition when execution units are idling and no useful work is done.</p><p><figure><img src="../Images/b5c812bf3b053324998324c493b67e59.png" data-original-src="https://en.algorithmica.org/hpc/pipelining/img/bubble.png"/><figcaption>Pipeline stall on the execution stage</figcaption></figure></p><p>Different hazards have different penalties:</p><ul><li>In structural hazards, you have to wait (usually one more cycle) until the execution unit is ready. They are fundamental bottlenecks on performance and can’t be avoided — you have to engineer around them.</li><li>In data hazards, you have to wait for the required data to be computed (the latency of the <em>critical path</em>). Data hazards are solved by restructuring computations so that the critical path is shorter.</li><li>In control hazards, you generally have to flush the entire pipeline and start over, wasting a whole 15-20 cycles. They are solved by either removing branches completely, or making them predictable so that the CPU can effectively <em>speculate</em> on what is going to be executed next.</li></ul><p>As they have very different impacts on performance, we are going to go in the reversed order and start with the more grave ones.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/pipelining/" id="prev-article">← ../Instruction-Level Parallelism</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/pipelining/branching/" id="next-article">The Cost of Branching →</a></div></div>    
</body>
</html>