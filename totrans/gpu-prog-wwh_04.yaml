- en: Why GPUs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://enccs.github.io/gpu-programming/1-gpu-history/](https://enccs.github.io/gpu-programming/1-gpu-history/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*[GPU programming: why, when and how?](../)* **   Why GPUs?'
  prefs: []
  type: TYPE_NORMAL
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/1-gpu-history.rst)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs: []
  type: TYPE_NORMAL
- en: What is Moore’s law?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What problems do GPUs solve?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objectives
  prefs: []
  type: TYPE_NORMAL
- en: Explain the historical development of microprocessors and how GPUs enable continued
    scaling in computational power
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instructor note
  prefs: []
  type: TYPE_NORMAL
- en: 15 min teaching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 min exercises
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moore’s law
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It states that the number of transistors in a dense integrated circuit doubles
    about every two years. More transistors means smaller size of a single element,
    so higher core frequency can be achieved. However, power consumption scales with
    frequency to the third power, therefore the growth in the core frequency has slowed
    down significantly. Higher performance of a single node has to rely on its more
    complicated structure and can still be achieved with SIMD (single instruction
    multiple data), branch prediction, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/microprocessor-trend-data.png](../Images/f2be4440984524ab75d46846f1f2567d.png)'
  prefs: []
  type: TYPE_IMG
- en: The evolution of microprocessors. The number of transistors per chip doubles
    roughly every 2 years. However, it can no longer be explored by the core frequency
    due to the power consumption limits. Before 2000, the increase in the single core
    clock frequency was the major source of the increase in the performance. Mid 2000
    mark a transition towards multi-core processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing performance has been sustained with two main strategies over the
    years:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Increase the single processor performance:'
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: More recently, increase the number of physical cores.
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing in parallel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The underlying idea of parallel computing is to split a computational problem
    into smaller subtasks. Many subtasks can then be solved *simultaneously* by multiple
    processing units.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/compp.png](../Images/73377a40a5b11000e154cc02c6a95c93.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: How a problem is split into smaller subtasks strongly depends on the problem.
    There are various paradigms and programming approaches to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Graphics processing units
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphics processing units (GPU) have been the most common accelerators during
    the last few years, the term GPU sometimes is used interchangeably with the term
    *accelerator*. GPUs were initially developed for highly-parallel tasks of graphic
    processing. But over the years, they were used more and more in high-performance
    computing (HPC).
  prefs: []
  type: TYPE_NORMAL
- en: 'GPUs are a specialized parallel hardware for floating point operations. They
    are basically co-processors (helpers) for traditional CPUs: a CPU still controls
    the work flow but it delegates highly parallel tasks to the GPU. GPUs are based
    on highly parallel architectures, which allows taking advantage of the increasing
    number of transistors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GPUs allows one to achieve extreme performance per node. As a result,
    a single GPU-equipped workstation can outperform small CPU-based clusters for
    some types of computational tasks. The drawback is: usually major rewrites of
    programs are required with an accompanying change in the programming paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: Host vs device
  prefs: []
  type: TYPE_NORMAL
- en: GPU-enabled systems require a heterogeneous programming model that involves
    both CPU and GPU, where the CPU and its memory are referred to as the host, and
    the GPU and its memory as the device.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/CPU_and_GPU_separated.png](../Images/46819c90dafc7b2c29de61c8e3e002a6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure adapted from the Carpentry [GPU Programming lesson](https://carpentries-incubator.github.io/lesson-gpu-programming/).
  prefs: []
  type: TYPE_NORMAL
- en: A look at the TOP500 list
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [TOP500 project](https://www.top500.org/) ranks and details the 500 most
    powerful non-distributed computer systems in the world. The project was started
    in 1993 and publishes an updated list of the supercomputers twice a year. The
    snapshot below shows the top-5 HPC systems as of June 2025, where the columns
    show:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cores** - Number of processors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rmax** - Maximal LINPACK performance achieved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rpeak** - Theoretical peak performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power** - Power consumption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../_images/top-5.png](../Images/d6ce0baa5ab71bc74512f07814e92c25.png)'
  prefs: []
  type: TYPE_IMG
- en: Snapshot from the [TOP500 list from June, 2025](https://www.top500.org/lists/top500/2024/05/).
  prefs: []
  type: TYPE_NORMAL
- en: All systems in the top-5 positions contain GPUs from AMD, Intel, or NVIDIA.
  prefs: []
  type: TYPE_NORMAL
- en: Why GPUs?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Speed**: GPU computing can significantly accelerate many types of scientific
    workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved energy efficiency**: Compared to CPUs, GPUs can perform more calculations
    per watt of power consumed, which can result in significant energy savings. This
    is indeed evident from the [GREEN500 list](https://www.top500.org/lists/green500/2025/06/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: GPUs can be more cost-effective than traditional CPU-based
    systems for certain workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations and drawbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Only for certain workloads**: Not all workloads can be efficiently parallelized
    and accelerated on GPUs. Certain types of workloads, such as those with irregular
    data access patterns or high branching behavior, may not see significant performance
    improvements on GPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steeper learning curve**: Depending on the GPU programming API that you choose,
    GPU computing could require specialized skills in GPU programming and knowledge
    of GPU architecture, leading to a steeper learning curve compared to CPU programming.
    Fortunately, if you study this training material closely you will become productive
    with GPU programming quickly!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keypoints
  prefs: []
  type: TYPE_NORMAL
- en: GPUs are accelerators for some types of tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly parallelizable compute-intensive tasks are suitable for GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU-based systems dominate the top spots of the TOP500 list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New programming skills are needed to use GPUs efficiently [Previous](../0-setup/
    "Setup") [Next](../2-gpu-ecosystem/ "The GPU hardware and software ecosystem")
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: © Copyright 2023-2024, The contributors.
  prefs: []
  type: TYPE_NORMAL
- en: Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). Questions
  prefs: []
  type: TYPE_NORMAL
- en: What is Moore’s law?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What problems do GPUs solve?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objectives
  prefs: []
  type: TYPE_NORMAL
- en: Explain the historical development of microprocessors and how GPUs enable continued
    scaling in computational power
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instructor note
  prefs: []
  type: TYPE_NORMAL
- en: 15 min teaching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0 min exercises
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moore’s law
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It states that the number of transistors in a dense integrated circuit doubles
    about every two years. More transistors means smaller size of a single element,
    so higher core frequency can be achieved. However, power consumption scales with
    frequency to the third power, therefore the growth in the core frequency has slowed
    down significantly. Higher performance of a single node has to rely on its more
    complicated structure and can still be achieved with SIMD (single instruction
    multiple data), branch prediction, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/microprocessor-trend-data.png](../Images/f2be4440984524ab75d46846f1f2567d.png)'
  prefs: []
  type: TYPE_IMG
- en: The evolution of microprocessors. The number of transistors per chip doubles
    roughly every 2 years. However, it can no longer be explored by the core frequency
    due to the power consumption limits. Before 2000, the increase in the single core
    clock frequency was the major source of the increase in the performance. Mid 2000
    mark a transition towards multi-core processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing performance has been sustained with two main strategies over the
    years:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Increase the single processor performance:'
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: More recently, increase the number of physical cores.
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing in parallel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The underlying idea of parallel computing is to split a computational problem
    into smaller subtasks. Many subtasks can then be solved *simultaneously* by multiple
    processing units.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/compp.png](../Images/73377a40a5b11000e154cc02c6a95c93.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: How a problem is split into smaller subtasks strongly depends on the problem.
    There are various paradigms and programming approaches to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Graphics processing units
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphics processing units (GPU) have been the most common accelerators during
    the last few years, the term GPU sometimes is used interchangeably with the term
    *accelerator*. GPUs were initially developed for highly-parallel tasks of graphic
    processing. But over the years, they were used more and more in high-performance
    computing (HPC).
  prefs: []
  type: TYPE_NORMAL
- en: 'GPUs are a specialized parallel hardware for floating point operations. They
    are basically co-processors (helpers) for traditional CPUs: a CPU still controls
    the work flow but it delegates highly parallel tasks to the GPU. GPUs are based
    on highly parallel architectures, which allows taking advantage of the increasing
    number of transistors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GPUs allows one to achieve extreme performance per node. As a result,
    a single GPU-equipped workstation can outperform small CPU-based clusters for
    some types of computational tasks. The drawback is: usually major rewrites of
    programs are required with an accompanying change in the programming paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: Host vs device
  prefs: []
  type: TYPE_NORMAL
- en: GPU-enabled systems require a heterogeneous programming model that involves
    both CPU and GPU, where the CPU and its memory are referred to as the host, and
    the GPU and its memory as the device.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/CPU_and_GPU_separated.png](../Images/46819c90dafc7b2c29de61c8e3e002a6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure adapted from the Carpentry [GPU Programming lesson](https://carpentries-incubator.github.io/lesson-gpu-programming/).
  prefs: []
  type: TYPE_NORMAL
- en: A look at the TOP500 list
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [TOP500 project](https://www.top500.org/) ranks and details the 500 most
    powerful non-distributed computer systems in the world. The project was started
    in 1993 and publishes an updated list of the supercomputers twice a year. The
    snapshot below shows the top-5 HPC systems as of June 2025, where the columns
    show:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cores** - Number of processors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rmax** - Maximal LINPACK performance achieved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rpeak** - Theoretical peak performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power** - Power consumption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../_images/top-5.png](../Images/d6ce0baa5ab71bc74512f07814e92c25.png)'
  prefs: []
  type: TYPE_IMG
- en: Snapshot from the [TOP500 list from June, 2025](https://www.top500.org/lists/top500/2024/05/).
  prefs: []
  type: TYPE_NORMAL
- en: All systems in the top-5 positions contain GPUs from AMD, Intel, or NVIDIA.
  prefs: []
  type: TYPE_NORMAL
- en: Why GPUs?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Speed**: GPU computing can significantly accelerate many types of scientific
    workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved energy efficiency**: Compared to CPUs, GPUs can perform more calculations
    per watt of power consumed, which can result in significant energy savings. This
    is indeed evident from the [GREEN500 list](https://www.top500.org/lists/green500/2025/06/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: GPUs can be more cost-effective than traditional CPU-based
    systems for certain workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations and drawbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Only for certain workloads**: Not all workloads can be efficiently parallelized
    and accelerated on GPUs. Certain types of workloads, such as those with irregular
    data access patterns or high branching behavior, may not see significant performance
    improvements on GPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steeper learning curve**: Depending on the GPU programming API that you choose,
    GPU computing could require specialized skills in GPU programming and knowledge
    of GPU architecture, leading to a steeper learning curve compared to CPU programming.
    Fortunately, if you study this training material closely you will become productive
    with GPU programming quickly!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keypoints
  prefs: []
  type: TYPE_NORMAL
- en: GPUs are accelerators for some types of tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly parallelizable compute-intensive tasks are suitable for GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU-based systems dominate the top spots of the TOP500 list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New programming skills are needed to use GPUs efficiently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moore’s law
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It states that the number of transistors in a dense integrated circuit doubles
    about every two years. More transistors means smaller size of a single element,
    so higher core frequency can be achieved. However, power consumption scales with
    frequency to the third power, therefore the growth in the core frequency has slowed
    down significantly. Higher performance of a single node has to rely on its more
    complicated structure and can still be achieved with SIMD (single instruction
    multiple data), branch prediction, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/microprocessor-trend-data.png](../Images/f2be4440984524ab75d46846f1f2567d.png)'
  prefs: []
  type: TYPE_IMG
- en: The evolution of microprocessors. The number of transistors per chip doubles
    roughly every 2 years. However, it can no longer be explored by the core frequency
    due to the power consumption limits. Before 2000, the increase in the single core
    clock frequency was the major source of the increase in the performance. Mid 2000
    mark a transition towards multi-core processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing performance has been sustained with two main strategies over the
    years:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Increase the single processor performance:'
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: More recently, increase the number of physical cores.
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing in parallel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The underlying idea of parallel computing is to split a computational problem
    into smaller subtasks. Many subtasks can then be solved *simultaneously* by multiple
    processing units.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/compp.png](../Images/73377a40a5b11000e154cc02c6a95c93.png)'
  prefs: []
  type: TYPE_IMG
- en: Computing in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: How a problem is split into smaller subtasks strongly depends on the problem.
    There are various paradigms and programming approaches to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Graphics processing units
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphics processing units (GPU) have been the most common accelerators during
    the last few years, the term GPU sometimes is used interchangeably with the term
    *accelerator*. GPUs were initially developed for highly-parallel tasks of graphic
    processing. But over the years, they were used more and more in high-performance
    computing (HPC).
  prefs: []
  type: TYPE_NORMAL
- en: 'GPUs are a specialized parallel hardware for floating point operations. They
    are basically co-processors (helpers) for traditional CPUs: a CPU still controls
    the work flow but it delegates highly parallel tasks to the GPU. GPUs are based
    on highly parallel architectures, which allows taking advantage of the increasing
    number of transistors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using GPUs allows one to achieve extreme performance per node. As a result,
    a single GPU-equipped workstation can outperform small CPU-based clusters for
    some types of computational tasks. The drawback is: usually major rewrites of
    programs are required with an accompanying change in the programming paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: Host vs device
  prefs: []
  type: TYPE_NORMAL
- en: GPU-enabled systems require a heterogeneous programming model that involves
    both CPU and GPU, where the CPU and its memory are referred to as the host, and
    the GPU and its memory as the device.
  prefs: []
  type: TYPE_NORMAL
- en: '![../_images/CPU_and_GPU_separated.png](../Images/46819c90dafc7b2c29de61c8e3e002a6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure adapted from the Carpentry [GPU Programming lesson](https://carpentries-incubator.github.io/lesson-gpu-programming/).
  prefs: []
  type: TYPE_NORMAL
- en: A look at the TOP500 list
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [TOP500 project](https://www.top500.org/) ranks and details the 500 most
    powerful non-distributed computer systems in the world. The project was started
    in 1993 and publishes an updated list of the supercomputers twice a year. The
    snapshot below shows the top-5 HPC systems as of June 2025, where the columns
    show:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cores** - Number of processors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rmax** - Maximal LINPACK performance achieved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rpeak** - Theoretical peak performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power** - Power consumption'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![../_images/top-5.png](../Images/d6ce0baa5ab71bc74512f07814e92c25.png)'
  prefs: []
  type: TYPE_IMG
- en: Snapshot from the [TOP500 list from June, 2025](https://www.top500.org/lists/top500/2024/05/).
  prefs: []
  type: TYPE_NORMAL
- en: All systems in the top-5 positions contain GPUs from AMD, Intel, or NVIDIA.
  prefs: []
  type: TYPE_NORMAL
- en: Why GPUs?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Speed**: GPU computing can significantly accelerate many types of scientific
    workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved energy efficiency**: Compared to CPUs, GPUs can perform more calculations
    per watt of power consumed, which can result in significant energy savings. This
    is indeed evident from the [GREEN500 list](https://www.top500.org/lists/green500/2025/06/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: GPUs can be more cost-effective than traditional CPU-based
    systems for certain workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations and drawbacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Only for certain workloads**: Not all workloads can be efficiently parallelized
    and accelerated on GPUs. Certain types of workloads, such as those with irregular
    data access patterns or high branching behavior, may not see significant performance
    improvements on GPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steeper learning curve**: Depending on the GPU programming API that you choose,
    GPU computing could require specialized skills in GPU programming and knowledge
    of GPU architecture, leading to a steeper learning curve compared to CPU programming.
    Fortunately, if you study this training material closely you will become productive
    with GPU programming quickly!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keypoints
  prefs: []
  type: TYPE_NORMAL
- en: GPUs are accelerators for some types of tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly parallelizable compute-intensive tasks are suitable for GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU-based systems dominate the top spots of the TOP500 list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New programming skills are needed to use GPUs efficiently*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
