<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Memory Paging</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Memory Paging</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/cpu-cache/paging/">https://en.algorithmica.org/hpc/cpu-cache/paging/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>Consider <a href="../associativity">yet again</a> the strided incrementing loop:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">13</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">a</span><span class="p">[</span><span class="n">D</span> <span class="o">*</span> <span class="n">N</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">D</span> <span class="o">*</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">D</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
</span></span></code></pre></div><p>We change the stride $D$ and increase the array size proportionally so that the total number of iterations $N$ remains constant. As the total number of memory accesses also remains constant, for all $D \geq 16$, we should be fetching exactly $N$ cache lines — or $64 \cdot N = 2^6 \cdot 2^{13} = 2^{19}$ bytes, to be exact. This precisely fits into the L2 cache, regardless of the step size, and the throughput graph should look flat.</p><p>This time, we consider a larger range of $D$ values, up to 1024. Starting from around 256, the graph is definitely not flat:</p><p><figure><img src="../Images/b651bca2cb9d842c46dee30f3adfcf8d.png" data-original-src="https://en.algorithmica.org/hpc/cpu-cache/img/strides.svg"/><figcaption/></figure></p><p>This anomaly is also due to the cache system, although the standard L1-L3 data caches have nothing to do with it. <a href="/hpc/external-memory/virtual">Virtual memory</a> is at fault, in particular the <em>translation lookaside buffer</em> (TLB), which is a cache responsible for retrieving the physical addresses of the virtual memory pages.</p><p>On <a href="https://en.wikichip.org/wiki/amd/microarchitectures/zen_2">my CPU</a>, there are two levels of TLB:</p><ul><li>The L1 TLB has 64 entries, and if the page size is 4K, then it can handle $64 \times 4K = 512K$ of active memory without going to the L2 TLB.</li><li>The L2 TLB has 2048 entries, and it can handle $2048 \times 4K = 8M$ of memory without going to the page table.</li></ul><p>How much memory is allocated when $D$ becomes equal to 256? You’ve guessed it: $8K \times 256 \times 4B = 8M$, exactly the limit of what the L2 TLB can handle. When $D$ gets larger than that, some requests start getting redirected to the main page table, which has a large latency and very limited throughput, which bottlenecks the whole computation.</p><span class="anchor" id="changing-page-size"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/cpu-cache/paging/#changing-page-size">#</a>Changing Page Size</h3><p>That 8MB of slowdown-free memory seems like a very tight restriction. While we can’t change the characteristics of the hardware to lift it, we <em>can</em> increase the page size, which would in turn reduce the pressure on the TLB capacity.</p><p>Modern operating systems allow us to set the page size both globally and for individual allocations. CPUs only support a defined set of page sizes — mine, for example, can use either 4K or 2M pages. Another typical page size is 1G — it is usually only relevant for server-grade hardware with hundreds of gigabytes of RAM. Anything over the default 4K is called <em>huge pages</em> on Linux and <em>large pages</em> on Windows.</p><p>On Linux, there is a special system file that governs the allocation of huge pages. Here is how to make the kernel give you huge pages on every allocation:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ <span class="nb">echo</span> always &gt; /sys/kernel/mm/transparent_hugepage/enabled
</span></span></code></pre></div><p>Enabling huge pages globally like this isn’t always a good idea because it decreases memory granularity and raises the minimum memory that a process consumes — and some environments have more processes than free megabytes of memory. So, in addition to <code>always</code> and <code>never</code>, there is a third option in that file:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ cat /sys/kernel/mm/transparent_hugepage/enabled
</span></span><span class="line"><span class="cl">always <span class="o">[</span>madvise<span class="o">]</span> never
</span></span></code></pre></div><p><code>madvise</code> is a special system call that lets the program advise the kernel on whether to use huge pages or not, which can be used for allocating huge pages on-demand. If it is enabled, you can use it in C++ like this:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;sys/mman.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"/>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">aligned_alloc</span><span class="p">(</span><span class="n">page_size</span><span class="p">,</span> <span class="n">array_size</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">madvise</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">array_size</span><span class="p">,</span> <span class="n">MADV_HUGEPAGE</span><span class="p">);</span>
</span></span></code></pre></div><p>You can only request a memory region to be allocated using huge pages if it has the corresponding alignment.</p><p>Windows has similar functionality. Its memory API combines these two functions into one:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">"memoryapi.h"</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"/>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">VirtualAlloc</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="n">array_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">MEM_RESERVE</span> <span class="o">|</span> <span class="n">MEM_COMMIT</span> <span class="o">|</span> <span class="n">MEM_LARGE_PAGES</span><span class="p">,</span> <span class="n">PAGE_READWRITE</span><span class="p">);</span>
</span></span></code></pre></div><p>In both cases, <code>array_size</code> should be a multiple of <code>page_size</code>.</p><span class="anchor" id="impact-of-huge-pages"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/cpu-cache/paging/#impact-of-huge-pages">#</a>Impact of Huge Pages</h3><p>Both variants of allocating huge pages immediately flatten the curve:</p><p><figure><img src="../Images/0ec1bff689bffbef53892443318cc4f6.png" data-original-src="https://en.algorithmica.org/hpc/cpu-cache/img/strides-hugepages.svg"/><figcaption/></figure></p><p>Enabling huge pages also improves <a href="../latency">latency</a> by up to 10-15% for arrays that don’t fit into the L2 cache:</p><p><figure><img src="../Images/e0a470f7d9fd055e77703ed863939964.png" data-original-src="https://en.algorithmica.org/hpc/cpu-cache/img/permutation-hugepages.svg"/><figcaption/></figure></p><p>In general, enabling huge pages is a good idea when you have any sort of sparse reads, as they usually slightly improve and (<a href="../aos-soa">almost</a>) never hurt performance.</p><p>That said, you shouldn’t rely on huge pages if possible, as they aren’t always available due to either hardware or computing environment restrictions. There are <a href="../cache-lines">many</a> <a href="../prefetching">other</a> <a href="../aos-soa">reasons</a> why grouping data accesses spatially may be beneficial, which automatically solves the paging problem.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/cpu-cache/associativity/" id="prev-article">← Cache Associativity</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/cpu-cache/aos-soa/" id="next-article">AoS and SoA →</a></div></div>    
</body>
</html>