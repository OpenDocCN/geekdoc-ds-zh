<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>17.5¬†Moravian Spanning Treesüîó</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>17.5¬†Moravian Spanning Treesüîó</h1>
<blockquote>ÂéüÊñáÔºö<a href="https://dcic-world.org/2025-08-27/mst.html">https://dcic-world.org/2025-08-27/mst.html</a></blockquote><table cellspacing="0" cellpadding="0"><tr><td><p><span class="hspace">¬†¬†¬†¬†</span><a href="#%28part._.The_.Problem%29" class="toclink" data-pltdoc="x">17.5.1<span class="hspace">¬†</span>The Problem</a></p></td></tr><tr><td><p><span class="hspace">¬†¬†¬†¬†</span><a href="#%28part._.A_.Greedy_.Solution%29" class="toclink" data-pltdoc="x">17.5.2<span class="hspace">¬†</span>A Greedy Solution</a></p></td></tr><tr><td><p><span class="hspace">¬†¬†¬†¬†</span><a href="#%28part._.Another_.Greedy_.Solution%29" class="toclink" data-pltdoc="x">17.5.3<span class="hspace">¬†</span>Another Greedy Solution</a></p></td></tr><tr><td><p><span class="hspace">¬†¬†¬†¬†</span><a href="#%28part._.A_.Third_.Solution%29" class="toclink" data-pltdoc="x">17.5.4<span class="hspace">¬†</span>A Third Solution</a></p></td></tr><tr><td><p><span class="hspace">¬†¬†¬†¬†</span><a href="#%28part._union-find-functional%29" class="toclink" data-pltdoc="x">17.5.5<span class="hspace">¬†</span>Checking Component Connectedness</a></p></td></tr></table><p>At the turn of the milennium, the US National Academy of Engineering
surveyed its members to determine the ‚ÄúGreatest Engineering
Achievements of the 20th Century‚Äù. The list contained the usual
suspects: electronics, computers, the Internet, and so on. But a
perhaps surprising idea topped the list: (rural)
<span class="emph">electrification</span>.<span class="refelem"><span class="refcolumn"><span class="refcontent">Read more about it
<a href="http://www.greatachievements.org/">on their site</a>.</span></span></span></p><section class="SsectionLevel4" id="section 17.5.1"><h4 class="heading">17.5.1<span class="stt">¬†</span><a name="(part._.The_.Problem)"/>The Problem<span class="button-group"><a href="#(part._.The_.Problem)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>To understand the history of national electrical grids, it helps to go
back to <a href="http://en.wikipedia.org/wiki/Moravia">Moravia</a>
in the 1920s. Like many parts of the world, it was beginning to
realize the benefits of electricity and intended to spread it around
the region. A Moravian academia named Otakar Bor≈Øvka heard about the
problem, and in a remarkable effort, described the problem abstractly,
so that it could be understood without reference to Moravia or
electrical networks. He modeled it as a problem <span class="emph">about graphs</span>.</p><p/><div class="SIntrapara">Bor≈Øvka observed that at least initially, any solution to the problem
of creating a network must have the following characteristics:
</div><div class="SIntrapara"><ul><li><p>The electrical network must reach all the towns intended to be
covered by it. In graph terms, the solution must be <span class="emph">spanning</span>,
meaning it must visit every node in the graph.</p></li><li><p>Redundancy is a valuable property in any network: that way, if
one set of links goes down, there might be another way to get a
payload to its destination. When starting out, however, redundancy
may be too expensive, especially if it comes at the cost of not
giving someone a payload at all. Thus, the initial solution was best
set up without loops or even redundant paths. In graph terms, the
solution had to be a <span class="emph">tree</span>.</p></li><li><p>Finally, the goal was to solve this problem for the least cost
possible. In graph terms, the graph would be weighted, and the
solution had to be a <span class="emph">minimum</span>.</p></li></ul></div><div class="SIntrapara">Thus Bor≈Øvka defined the Moravian Spanning Tree (<span class="Smaller">MST</span>) problem.</div></section><section class="SsectionLevel4" id="section 17.5.2"><h4 class="heading">17.5.2<span class="stt">¬†</span><a name="(part._.A_.Greedy_.Solution)"/>A Greedy Solution<span class="button-group"><a href="#(part._.A_.Greedy_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p/><div class="SIntrapara">Bor≈Øvka had published his problem, and another Czech mathematician,
<a href="http://en.wikipedia.org/wiki/Vojt%C4%9Bch_Jarn%C3%ADk">Vojtƒõch Jarn√≠k</a>,
came across it. Jarn√≠k came up with a solution that should sound
familiar:
</div><div class="SIntrapara"><ul><li><p>Begin with a solution consisting of a single node, chosen
arbitrarily. For the graph consisting of this one node, this
solution is clearly a minimum, spanning, and a tree.</p></li><li><p>Of all the edges incident on nodes in the solution that
connect to a node not already in the solution, pick the edge with
the least weight.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note that we consider only the
incident edges, not their weight added to the weight of the node to
which they are incident.</span></span></span></p></li><li><p>Add this edge to the solution. The claim is that for the new
solution will be a tree (by construction), spanning (also by
construction), and a minimum. The minimality follows by an argument
similar to that used for Dijkstra‚Äôs Algorithm.</p></li></ul></div><p>Jarn√≠k had the misfortune of publishing this work in Czech in 1930,
and it went largely ignored. It was rediscovered by others, most
notably by R.C. Prim in 1957, and is now generally known as
<span class="emph">Prim‚Äôs Algorithm</span>, though calling it <span class="emph">Jarn√≠k‚Äôs Algorithm</span>
would attribute credit in the right place.</p><p>Implementing this algorithm is pretty easy. At each point, we need to
know the lightest edge incident on the current solution tree. Finding
the lightest edge takes time linear in the number of these edges, but
the very lightest one may create a cycle. We therefore need to
efficiently check for whether adding an edge would create a cycle, a
problem we will return to multiple times [<a href="#%28part._union-find-functional%29" data-pltdoc="x">Checking Component Connectedness</a>].
Assuming we can do
that effectively, we then want to add the lightest edge and
iterate. Even given an efficient solution for checking cyclicity, this
would seem to require an operation linear in the number of edges for
each node. With better representations we can improve on this
complexity, but let‚Äôs look at other ideas first.</p></section><section class="SsectionLevel4" id="section 17.5.3"><h4 class="heading">17.5.3<span class="stt">¬†</span><a name="(part._.Another_.Greedy_.Solution)"/>Another Greedy Solution<span class="button-group"><a href="#(part._.Another_.Greedy_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>Recall that Jarn√≠k presented his algorithm in 1930, when computers
didn‚Äôt exist, and Prim his in 1957, when they were very much in their
infancy. Programming computers to track heaps was a non-trivial
problem, and many algorithms were implemented by hand, where keeping
track of a complex data structure without making errors was harder
still. There was need for a solution that was required less manual
bookkeeping (literally speaking).</p><p>In 1956,
<a href="http://en.wikipedia.org/wiki/Joseph_Kruskal">Joseph Kruskal</a>
presented such a solution. His idea was elegantly simple. The Jarn√≠k
algorithm suffers from the problem that each time the tree grows, we
have to revise the content of the heap, which is already a messy
structure to track. Kruskal noted the following.</p><p>To obtain a minimum solution, surely we want to include one of the
edges of least weight in the graph. Because if not, we can take an
otherwise minimal solution, add this edge, and remove one other edge;
the graph would still be just as connected, but the overall weight
would be no more and, if the removed edge were heavier, would be
less.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note the careful wording: there may be many edges
of the same least weight, so adding one of them may remove another,
and therefore not produce a lighter tree; but the key point is that it
certainly will not produce a heavier one.</span></span></span> By the same argument we can
add the next lightest edge, and the next lightest, and so on. The only
time we cannot add the next lightest edge is when it would create a
cycle (that problem again!).</p><p>Therefore, Kruskal‚Äôs algorithm is utterly straightforward. We first
sort all the edges, ordered by ascending weight. We then take each
edge in ascending weight order and add it to the solution provided it
will not create a cycle. When we have thus processed all the edges, we
will have a solution that is a tree (by construction), spanning
(because every connected vertex must be the endpoint of some edge),
and of minimum weight (by the argument above). The complexity is that
of sorting (which is \([e \rightarrow e \log e]\) where \(e\) is the
size of the edge set. We then iterate over each element in \(e\),
which takes time linear in the size of that set‚Äî<wbr/>modulo the time to
check for cycles. This algorithm is also easy to implement on paper,
because we sort all the edges once, then keep checking them off in
order, crossing out the ones that create cycles‚Äî<wbr/>with no dynamic
updating of the list needed.</p></section><section class="SsectionLevel4" id="section 17.5.4"><h4 class="heading">17.5.4<span class="stt">¬†</span><a name="(part._.A_.Third_.Solution)"/>A Third Solution<span class="button-group"><a href="#(part._.A_.Third_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>Both the Jarn√≠k and Kruskal solutions have one flaw: they require a
centralized data structure (the priority heap, or the sorted list) to
incrementally build the solution. As parallel computers became
available, and graph problems grew large, computer scientists looked
for solutions that could be implemented more efficiently in
parallel‚Äî<wbr/>which typically meant avoiding any centralized points of
synchronization, such as these centralized data structures.</p><p>In 1965, M. Sollin constructed an algorithm that met these needs
beautifully. In this algorithm, instead of constructing a single
solution, we grow multiple solution components (potentially in
parallel if we so wish). Each node starts out as a solution component
(as it was at the first step of Jarn√≠k‚Äôs Algorithm). Each node
considers the edges incident to it, and picks the lightest one that
connects to a different component (that problem <span class="emph">again</span>!). If
such an edge can be found, the edge becomes part of the solution, and
the two components combine to become a single component. The entire
process repeats.</p><p>Because every node begins as part of the solution, this algorithm
naturally spans. Because it checks for cycles and avoids them, it
naturally forms a tree.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note that avoiding cycles yields
a <span class="Smaller">DAG</span> and is not automatically guaranteed to yield a tree. We have
been a bit lax about this difference throughout this section.</span></span></span>
Finally, minimality follows through similar reasoning as we used in
the case of Jarn√≠k‚Äôs Algorithm, which we have essentially run in
parallel, once from each node, until the parallel solution components
join up to produce a global solution.</p><p>Of course, maintaining the data for this algorithm by hand is a
nightmare. Therefore, it would be no surprise that this algorithm was
coined in the digital age. The real surprise, therefore, is that it
was not: it was originally created by
<a href="http://en.wikipedia.org/wiki/Otakar_Bor%C5%AFvka">Otakar Bor≈Øvka</a>
himself.</p><p/><div class="SIntrapara">Bor≈Øvka, you see, had figured it all out. He‚Äôd not only understood the
problem, he had:
</div><div class="SIntrapara"><ul><li><p>pinpointed the real problem lying underneath the
electrification problem so it could be viewed in a
context-independent way,</p></li><li><p>created a descriptive language of graph theory to define it
precisely, and</p></li><li><p>even <span class="emph">solved</span> the problem in addition to defining it.</p></li></ul></div><div class="SIntrapara">He‚Äôd just come up with a solution so complex to implement by hand that
Jarn√≠k had in essence de-parallelized it so it could be done
sequentially. And thus this algorithm lay unnoticed until it was
reinvented
(<a href="http://en.wikipedia.org/wiki/Bor%C5%AFvka's_algorithm">several times, actually</a>)
by Sollin in time for parallel computing folks to notice a need for
it. But now we can just call this <span class="emph">Bor≈Øvka‚Äôs Algorithm</span>, which is
only fitting.</div><p>As you might have guessed by now, this problem is indeed called the
<span class="Smaller">MST</span> in other textbooks, but ‚ÄúM‚Äù stands not for Moravia but for
‚ÄúMinimum‚Äù. But given Bor≈Øvka‚Äôs forgotten place in history, we prefer
the more whimsical name.</p></section><section class="SsectionLevel4" id="section 17.5.5"><h4 class="heading">17.5.5<span class="stt">¬†</span><a name="(part._union-find-functional)"/>Checking Component Connectedness<span class="button-group"><a href="#(part._union-find-functional)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>As we‚Äôve seen, we need to be able to efficiently tell whether two
nodes are in the same component. One way to do this is to conduct a
depth-first traversal (or breadth-first traversal) starting from the
first node and checking whether we ever visit the second one. (Using
one of these traversal strategies ensures that we terminate in the
presence of loops.) Unfortunately, this takes a linear amount of time
(in the size of the graph) for <span class="emph">every pair of nodes</span>‚Äî<wbr/>and
depending on the graph and choice of node, we might do this for every
node in the graph on every edge addition! So we‚Äôd clearly like to do
this better.</p><p>It is helpful to reduce this problem from graph connectivity to a more
general one: of <span style="font-style: italic">disjoint-set structure</span> (colloquially known as
<span style="font-style: italic">union-find</span> for reasons that will soon be clear). If we think of
each connected component as a set, then we‚Äôre asking whether two nodes
are in the same set. But casting it as a set membership problem makes
it applicable in several other applications as well.</p><p>The setup is as follows. For arbitrary values, we want the ability to
think of them as elements in a set.
We are interested in two operations. One is obviously <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>,
which merges two sets into one. The other would seem to be something
like <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-in-same-set</code></span> that takes two elements and determines
whether they‚Äôre in the same set. Over time, however, it has proven
useful to instead define the operator <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find</code></span> that, given an
element, ‚Äúnames‚Äù the set (more on this in a moment) that the element
belongs to. To check whether two elements are in the same set, we then
have to get the ‚Äúset name‚Äù for each element, and check whether these
names are the same. This certainly sounds more roundabout, but this
means we have a primitive that may be useful in other contexts, and
from which we can easily implement <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-in-same-set</code></span>.</p><p/><div class="SIntrapara">Now the question is, how do we name sets? The real question we should
ask is, what operations do we care to perform on these names? All we
care about is, given two names, they represent the same set precisely
when the names are the same. Therefore, we could construct a new
string, or number, or something else, but we have another option:
simply pick some element of the set to represent it, i.e., to serve as
its name. Thus we will associate each set element with an
indicator of the ‚Äúset name‚Äù for that element; if there isn‚Äôt one,
then its name is itself (the <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span> case of <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span>):
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">data Element&lt;T&gt;:
  | elt(val :: T, parent :: Option&lt;Element&gt;)
end</code></pre></div></div></div><div class="SIntrapara">We will assume we have some equality predicate for checking when two
elements are the same, which we do by comparing their value parts,
ignoring their parent values:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun is-same-element(e1, e2): e1.val &lt;=&gt; e2.val end</code></pre></div></div></div><blockquote class="Incercise"><p class="IncerciseHeader">Do Now!</p><blockquote class="IncerciseBody"><p>Why do we check only the value parts?</p></blockquote></blockquote><p/><div class="SIntrapara">We will assume that for a given set, we always return the
<span class="emph">same</span> representative element. (Otherwise, equality will fail
even though we have the same set.) Thus:<span class="refelem"><span class="refcolumn"><span class="refcontent">We‚Äôve used the
name <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fynd</code></span> because <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find</code></span> is already defined to mean
something else in Pyret. If you don‚Äôt like the misspelling, you‚Äôre
welcome to use a longer name like <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find-root</code></span>.</span></span></span>
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun is-in-same-set(e1 :: Element, e2 :: Element, s :: Sets)
    -&gt; Boolean:
  s1 = fynd(e1, s)
  s2 = fynd(e2, s)
  identical(s1, s2)
end</code></pre></div></div></div><div class="SIntrapara">where <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">Sets</code></span> is the list of all elements:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">type Sets = List&lt;Element&gt;</code></pre></div></div></div><p/><div class="SIntrapara">How do we find the representative element for a set? We first find it
using <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-same-element</code></span>; when we do, we check the
element‚Äôs <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span> field. If it is <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span>, that means this
very element names its set; this can happen either because the element
is a singleton set (we‚Äôll initialize all elements with <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span>),
or it‚Äôs the name for some larger set. Either way, we‚Äôre
done. Otherwise, we have to recursively find the parent:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun fynd(e :: Element, s :: Sets) -&gt; Element:
  cases (List) s:
    | empty =&gt; raise("fynd: shouldn't have gotten here")
    | link(f, r) =&gt;
      if is-same-element(f, e):
        cases (Option) f.parent:
          | none =&gt; f
          | some(p) =&gt; fynd(p, s)
        end
      else:
        fynd(e, r)
      end
  end
end</code></pre></div></div></div><blockquote class="Exercise"><p class="ExerciseHeader">Exercise</p><blockquote class="ExerciseBody"><p>Why is there a recursive call in the nested <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">cases</code></span>?</p></blockquote></blockquote><p/><div class="SIntrapara">What‚Äôs left is to implement <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>. For this, we find the
representative elements of the two sets we‚Äôre trying to union; if they
are the same, then the two sets are already in a union; otherwise, we
have to update the data structure:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun union(e1 :: Element, e2 :: Element, s :: Sets) -&gt; Sets:
  s1 = fynd(e1, s)
  s2 = fynd(e2, s)
  if identical(s1, s2):
    s
  else:
    update-set-with(s, s1, s2)
  end
end</code></pre></div></div></div><div class="SIntrapara">To update, we arbitrarily choose one of the set names to be the name
of the new compound set. We then have to update the parent of the
other set‚Äôs name element to be this one:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun update-set-with(s :: Sets, child :: Element, parent :: Element)
    -&gt; Sets:
  cases (List) s:
    | empty =&gt; raise("update: shouldn't have gotten here")
    | link(f, r) =&gt;
      if is-same-element(f, child):
        link(elt(f.val, some(parent)), r)
      else:
        link(f, update-set-with(r, child, parent))
      end
  end
end</code></pre></div></div></div><div class="SIntrapara">Here are some tests to illustrate this working:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">check:
  s0 = map(elt(_, none), [list: 0, 1, 2, 3, 4, 5, 6, 7])
  s1 = union(get(s0, 0), get(s0, 2), s0)
  s2 = union(get(s1, 0), get(s1, 3), s1)
  s3 = union(get(s2, 3), get(s2, 5), s2)
  print(s3)
  is-same-element(fynd(get(s0, 0), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 2), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 3), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 5), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 7), s3), fynd(get(s0, 7), s3)) is true
end</code></pre></div></div></div><p/><div class="SIntrapara">Unfortunately, this implementation suffers from two major problems:
</div><div class="SIntrapara"><ul><li><p>First, because we are performing functional updates, the value
of the <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span> reference keeps ‚Äúchanging‚Äù, but these changes
are not visible to older copies of the ‚Äúsame‚Äù value. An element
from different stages of unioning has different parent references,
even though it is arguably the same element throughout. This is a
place where functional programming hurts.</p></li><li><p>Relatedly, the performance of this implementation is quite
bad. <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fynd</code></span> recursively traverses parents to find the set‚Äôs
name, but the elements traversed are not updated to record this new
name. We certainly could update them by reconstructing the set
afresh each time, but that complicates the implementation and, as we
will soon see, we can do much better.</p></li></ul></div><div class="SIntrapara">Even worse, it may not even be correct!</div><blockquote class="Exercise"><p class="ExerciseHeader">Exercise</p><blockquote class="ExerciseBody"><p>Is it? Consider constructing <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>s that are not quite so skewed as
above, and see whether you get the results you expect.</p></blockquote></blockquote><p>The bottom line is that <span class="emph">pure functional programming is not a
great fit with this problem</span>. We need a better implementation
strategy: <a href="union-find.html" data-pltdoc="x">Union-Find</a>.</p></section>&#13;
<h4 class="heading">17.5.1<span class="stt">¬†</span><a name="(part._.The_.Problem)"/>The Problem<span class="button-group"><a href="#(part._.The_.Problem)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>To understand the history of national electrical grids, it helps to go
back to <a href="http://en.wikipedia.org/wiki/Moravia">Moravia</a>
in the 1920s. Like many parts of the world, it was beginning to
realize the benefits of electricity and intended to spread it around
the region. A Moravian academia named Otakar Bor≈Øvka heard about the
problem, and in a remarkable effort, described the problem abstractly,
so that it could be understood without reference to Moravia or
electrical networks. He modeled it as a problem <span class="emph">about graphs</span>.</p><p/><div class="SIntrapara">Bor≈Øvka observed that at least initially, any solution to the problem
of creating a network must have the following characteristics:
</div><div class="SIntrapara"><ul><li><p>The electrical network must reach all the towns intended to be
covered by it. In graph terms, the solution must be <span class="emph">spanning</span>,
meaning it must visit every node in the graph.</p></li><li><p>Redundancy is a valuable property in any network: that way, if
one set of links goes down, there might be another way to get a
payload to its destination. When starting out, however, redundancy
may be too expensive, especially if it comes at the cost of not
giving someone a payload at all. Thus, the initial solution was best
set up without loops or even redundant paths. In graph terms, the
solution had to be a <span class="emph">tree</span>.</p></li><li><p>Finally, the goal was to solve this problem for the least cost
possible. In graph terms, the graph would be weighted, and the
solution had to be a <span class="emph">minimum</span>.</p></li></ul></div><div class="SIntrapara">Thus Bor≈Øvka defined the Moravian Spanning Tree (<span class="Smaller">MST</span>) problem.</div>&#13;
<h4 class="heading">17.5.2<span class="stt">¬†</span><a name="(part._.A_.Greedy_.Solution)"/>A Greedy Solution<span class="button-group"><a href="#(part._.A_.Greedy_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p/><div class="SIntrapara">Bor≈Øvka had published his problem, and another Czech mathematician,
<a href="http://en.wikipedia.org/wiki/Vojt%C4%9Bch_Jarn%C3%ADk">Vojtƒõch Jarn√≠k</a>,
came across it. Jarn√≠k came up with a solution that should sound
familiar:
</div><div class="SIntrapara"><ul><li><p>Begin with a solution consisting of a single node, chosen
arbitrarily. For the graph consisting of this one node, this
solution is clearly a minimum, spanning, and a tree.</p></li><li><p>Of all the edges incident on nodes in the solution that
connect to a node not already in the solution, pick the edge with
the least weight.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note that we consider only the
incident edges, not their weight added to the weight of the node to
which they are incident.</span></span></span></p></li><li><p>Add this edge to the solution. The claim is that for the new
solution will be a tree (by construction), spanning (also by
construction), and a minimum. The minimality follows by an argument
similar to that used for Dijkstra‚Äôs Algorithm.</p></li></ul></div><p>Jarn√≠k had the misfortune of publishing this work in Czech in 1930,
and it went largely ignored. It was rediscovered by others, most
notably by R.C. Prim in 1957, and is now generally known as
<span class="emph">Prim‚Äôs Algorithm</span>, though calling it <span class="emph">Jarn√≠k‚Äôs Algorithm</span>
would attribute credit in the right place.</p><p>Implementing this algorithm is pretty easy. At each point, we need to
know the lightest edge incident on the current solution tree. Finding
the lightest edge takes time linear in the number of these edges, but
the very lightest one may create a cycle. We therefore need to
efficiently check for whether adding an edge would create a cycle, a
problem we will return to multiple times [<a href="#%28part._union-find-functional%29" data-pltdoc="x">Checking Component Connectedness</a>].
Assuming we can do
that effectively, we then want to add the lightest edge and
iterate. Even given an efficient solution for checking cyclicity, this
would seem to require an operation linear in the number of edges for
each node. With better representations we can improve on this
complexity, but let‚Äôs look at other ideas first.</p>&#13;
<h4 class="heading">17.5.3<span class="stt">¬†</span><a name="(part._.Another_.Greedy_.Solution)"/>Another Greedy Solution<span class="button-group"><a href="#(part._.Another_.Greedy_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>Recall that Jarn√≠k presented his algorithm in 1930, when computers
didn‚Äôt exist, and Prim his in 1957, when they were very much in their
infancy. Programming computers to track heaps was a non-trivial
problem, and many algorithms were implemented by hand, where keeping
track of a complex data structure without making errors was harder
still. There was need for a solution that was required less manual
bookkeeping (literally speaking).</p><p>In 1956,
<a href="http://en.wikipedia.org/wiki/Joseph_Kruskal">Joseph Kruskal</a>
presented such a solution. His idea was elegantly simple. The Jarn√≠k
algorithm suffers from the problem that each time the tree grows, we
have to revise the content of the heap, which is already a messy
structure to track. Kruskal noted the following.</p><p>To obtain a minimum solution, surely we want to include one of the
edges of least weight in the graph. Because if not, we can take an
otherwise minimal solution, add this edge, and remove one other edge;
the graph would still be just as connected, but the overall weight
would be no more and, if the removed edge were heavier, would be
less.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note the careful wording: there may be many edges
of the same least weight, so adding one of them may remove another,
and therefore not produce a lighter tree; but the key point is that it
certainly will not produce a heavier one.</span></span></span> By the same argument we can
add the next lightest edge, and the next lightest, and so on. The only
time we cannot add the next lightest edge is when it would create a
cycle (that problem again!).</p><p>Therefore, Kruskal‚Äôs algorithm is utterly straightforward. We first
sort all the edges, ordered by ascending weight. We then take each
edge in ascending weight order and add it to the solution provided it
will not create a cycle. When we have thus processed all the edges, we
will have a solution that is a tree (by construction), spanning
(because every connected vertex must be the endpoint of some edge),
and of minimum weight (by the argument above). The complexity is that
of sorting (which is \([e \rightarrow e \log e]\) where \(e\) is the
size of the edge set. We then iterate over each element in \(e\),
which takes time linear in the size of that set‚Äî<wbr/>modulo the time to
check for cycles. This algorithm is also easy to implement on paper,
because we sort all the edges once, then keep checking them off in
order, crossing out the ones that create cycles‚Äî<wbr/>with no dynamic
updating of the list needed.</p>&#13;
<h4 class="heading">17.5.4<span class="stt">¬†</span><a name="(part._.A_.Third_.Solution)"/>A Third Solution<span class="button-group"><a href="#(part._.A_.Third_.Solution)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>Both the Jarn√≠k and Kruskal solutions have one flaw: they require a
centralized data structure (the priority heap, or the sorted list) to
incrementally build the solution. As parallel computers became
available, and graph problems grew large, computer scientists looked
for solutions that could be implemented more efficiently in
parallel‚Äî<wbr/>which typically meant avoiding any centralized points of
synchronization, such as these centralized data structures.</p><p>In 1965, M. Sollin constructed an algorithm that met these needs
beautifully. In this algorithm, instead of constructing a single
solution, we grow multiple solution components (potentially in
parallel if we so wish). Each node starts out as a solution component
(as it was at the first step of Jarn√≠k‚Äôs Algorithm). Each node
considers the edges incident to it, and picks the lightest one that
connects to a different component (that problem <span class="emph">again</span>!). If
such an edge can be found, the edge becomes part of the solution, and
the two components combine to become a single component. The entire
process repeats.</p><p>Because every node begins as part of the solution, this algorithm
naturally spans. Because it checks for cycles and avoids them, it
naturally forms a tree.<span class="refelem"><span class="refcolumn"><span class="refcontent">Note that avoiding cycles yields
a <span class="Smaller">DAG</span> and is not automatically guaranteed to yield a tree. We have
been a bit lax about this difference throughout this section.</span></span></span>
Finally, minimality follows through similar reasoning as we used in
the case of Jarn√≠k‚Äôs Algorithm, which we have essentially run in
parallel, once from each node, until the parallel solution components
join up to produce a global solution.</p><p>Of course, maintaining the data for this algorithm by hand is a
nightmare. Therefore, it would be no surprise that this algorithm was
coined in the digital age. The real surprise, therefore, is that it
was not: it was originally created by
<a href="http://en.wikipedia.org/wiki/Otakar_Bor%C5%AFvka">Otakar Bor≈Øvka</a>
himself.</p><p/><div class="SIntrapara">Bor≈Øvka, you see, had figured it all out. He‚Äôd not only understood the
problem, he had:
</div><div class="SIntrapara"><ul><li><p>pinpointed the real problem lying underneath the
electrification problem so it could be viewed in a
context-independent way,</p></li><li><p>created a descriptive language of graph theory to define it
precisely, and</p></li><li><p>even <span class="emph">solved</span> the problem in addition to defining it.</p></li></ul></div><div class="SIntrapara">He‚Äôd just come up with a solution so complex to implement by hand that
Jarn√≠k had in essence de-parallelized it so it could be done
sequentially. And thus this algorithm lay unnoticed until it was
reinvented
(<a href="http://en.wikipedia.org/wiki/Bor%C5%AFvka's_algorithm">several times, actually</a>)
by Sollin in time for parallel computing folks to notice a need for
it. But now we can just call this <span class="emph">Bor≈Øvka‚Äôs Algorithm</span>, which is
only fitting.</div><p>As you might have guessed by now, this problem is indeed called the
<span class="Smaller">MST</span> in other textbooks, but ‚ÄúM‚Äù stands not for Moravia but for
‚ÄúMinimum‚Äù. But given Bor≈Øvka‚Äôs forgotten place in history, we prefer
the more whimsical name.</p>&#13;
<h4 class="heading">17.5.5<span class="stt">¬†</span><a name="(part._union-find-functional)"/>Checking Component Connectedness<span class="button-group"><a href="#(part._union-find-functional)" class="heading-anchor" title="Link to here">üîó</a><span style="visibility: hidden"> </span></span></h4><p>As we‚Äôve seen, we need to be able to efficiently tell whether two
nodes are in the same component. One way to do this is to conduct a
depth-first traversal (or breadth-first traversal) starting from the
first node and checking whether we ever visit the second one. (Using
one of these traversal strategies ensures that we terminate in the
presence of loops.) Unfortunately, this takes a linear amount of time
(in the size of the graph) for <span class="emph">every pair of nodes</span>‚Äî<wbr/>and
depending on the graph and choice of node, we might do this for every
node in the graph on every edge addition! So we‚Äôd clearly like to do
this better.</p><p>It is helpful to reduce this problem from graph connectivity to a more
general one: of <span style="font-style: italic">disjoint-set structure</span> (colloquially known as
<span style="font-style: italic">union-find</span> for reasons that will soon be clear). If we think of
each connected component as a set, then we‚Äôre asking whether two nodes
are in the same set. But casting it as a set membership problem makes
it applicable in several other applications as well.</p><p>The setup is as follows. For arbitrary values, we want the ability to
think of them as elements in a set.
We are interested in two operations. One is obviously <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>,
which merges two sets into one. The other would seem to be something
like <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-in-same-set</code></span> that takes two elements and determines
whether they‚Äôre in the same set. Over time, however, it has proven
useful to instead define the operator <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find</code></span> that, given an
element, ‚Äúnames‚Äù the set (more on this in a moment) that the element
belongs to. To check whether two elements are in the same set, we then
have to get the ‚Äúset name‚Äù for each element, and check whether these
names are the same. This certainly sounds more roundabout, but this
means we have a primitive that may be useful in other contexts, and
from which we can easily implement <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-in-same-set</code></span>.</p><p/><div class="SIntrapara">Now the question is, how do we name sets? The real question we should
ask is, what operations do we care to perform on these names? All we
care about is, given two names, they represent the same set precisely
when the names are the same. Therefore, we could construct a new
string, or number, or something else, but we have another option:
simply pick some element of the set to represent it, i.e., to serve as
its name. Thus we will associate each set element with an
indicator of the ‚Äúset name‚Äù for that element; if there isn‚Äôt one,
then its name is itself (the <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span> case of <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span>):
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">data Element&lt;T&gt;:
  | elt(val :: T, parent :: Option&lt;Element&gt;)
end</code></pre></div></div></div><div class="SIntrapara">We will assume we have some equality predicate for checking when two
elements are the same, which we do by comparing their value parts,
ignoring their parent values:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun is-same-element(e1, e2): e1.val &lt;=&gt; e2.val end</code></pre></div></div></div><blockquote class="Incercise"><p class="IncerciseHeader">Do Now!</p><blockquote class="IncerciseBody"><p>Why do we check only the value parts?</p></blockquote></blockquote><p/><div class="SIntrapara">We will assume that for a given set, we always return the
<span class="emph">same</span> representative element. (Otherwise, equality will fail
even though we have the same set.) Thus:<span class="refelem"><span class="refcolumn"><span class="refcontent">We‚Äôve used the
name <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fynd</code></span> because <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find</code></span> is already defined to mean
something else in Pyret. If you don‚Äôt like the misspelling, you‚Äôre
welcome to use a longer name like <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">find-root</code></span>.</span></span></span>
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun is-in-same-set(e1 :: Element, e2 :: Element, s :: Sets)
    -&gt; Boolean:
  s1 = fynd(e1, s)
  s2 = fynd(e2, s)
  identical(s1, s2)
end</code></pre></div></div></div><div class="SIntrapara">where <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">Sets</code></span> is the list of all elements:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">type Sets = List&lt;Element&gt;</code></pre></div></div></div><p/><div class="SIntrapara">How do we find the representative element for a set? We first find it
using <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">is-same-element</code></span>; when we do, we check the
element‚Äôs <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span> field. If it is <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span>, that means this
very element names its set; this can happen either because the element
is a singleton set (we‚Äôll initialize all elements with <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">none</code></span>),
or it‚Äôs the name for some larger set. Either way, we‚Äôre
done. Otherwise, we have to recursively find the parent:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun fynd(e :: Element, s :: Sets) -&gt; Element:
  cases (List) s:
    | empty =&gt; raise("fynd: shouldn't have gotten here")
    | link(f, r) =&gt;
      if is-same-element(f, e):
        cases (Option) f.parent:
          | none =&gt; f
          | some(p) =&gt; fynd(p, s)
        end
      else:
        fynd(e, r)
      end
  end
end</code></pre></div></div></div><blockquote class="Exercise"><p class="ExerciseHeader">Exercise</p><blockquote class="ExerciseBody"><p>Why is there a recursive call in the nested <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">cases</code></span>?</p></blockquote></blockquote><p/><div class="SIntrapara">What‚Äôs left is to implement <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>. For this, we find the
representative elements of the two sets we‚Äôre trying to union; if they
are the same, then the two sets are already in a union; otherwise, we
have to update the data structure:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun union(e1 :: Element, e2 :: Element, s :: Sets) -&gt; Sets:
  s1 = fynd(e1, s)
  s2 = fynd(e2, s)
  if identical(s1, s2):
    s
  else:
    update-set-with(s, s1, s2)
  end
end</code></pre></div></div></div><div class="SIntrapara">To update, we arbitrarily choose one of the set names to be the name
of the new compound set. We then have to update the parent of the
other set‚Äôs name element to be this one:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fun update-set-with(s :: Sets, child :: Element, parent :: Element)
    -&gt; Sets:
  cases (List) s:
    | empty =&gt; raise("update: shouldn't have gotten here")
    | link(f, r) =&gt;
      if is-same-element(f, child):
        link(elt(f.val, some(parent)), r)
      else:
        link(f, update-set-with(r, child, parent))
      end
  end
end</code></pre></div></div></div><div class="SIntrapara">Here are some tests to illustrate this working:
</div><div class="SIntrapara"><p/><div class="sourceCodeWrapper"><span data-label="Pyret" class="sourceLangLabel"/><div class="sourceCode"><pre data-lang="pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">check:
  s0 = map(elt(_, none), [list: 0, 1, 2, 3, 4, 5, 6, 7])
  s1 = union(get(s0, 0), get(s0, 2), s0)
  s2 = union(get(s1, 0), get(s1, 3), s1)
  s3 = union(get(s2, 3), get(s2, 5), s2)
  print(s3)
  is-same-element(fynd(get(s0, 0), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 2), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 3), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 5), s3), fynd(get(s0, 5), s3)) is true
  is-same-element(fynd(get(s0, 7), s3), fynd(get(s0, 7), s3)) is true
end</code></pre></div></div></div><p/><div class="SIntrapara">Unfortunately, this implementation suffers from two major problems:
</div><div class="SIntrapara"><ul><li><p>First, because we are performing functional updates, the value
of the <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">parent</code></span> reference keeps ‚Äúchanging‚Äù, but these changes
are not visible to older copies of the ‚Äúsame‚Äù value. An element
from different stages of unioning has different parent references,
even though it is arguably the same element throughout. This is a
place where functional programming hurts.</p></li><li><p>Relatedly, the performance of this implementation is quite
bad. <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">fynd</code></span> recursively traverses parents to find the set‚Äôs
name, but the elements traversed are not updated to record this new
name. We certainly could update them by reconstructing the set
afresh each time, but that complicates the implementation and, as we
will soon see, we can do much better.</p></li></ul></div><div class="SIntrapara">Even worse, it may not even be correct!</div><blockquote class="Exercise"><p class="ExerciseHeader">Exercise</p><blockquote class="ExerciseBody"><p>Is it? Consider constructing <span title="Pyret" class="sourceCode"><code data-lang="pyret" class="sourceCode">union</code></span>s that are not quite so skewed as
above, and see whether you get the results you expect.</p></blockquote></blockquote><p>The bottom line is that <span class="emph">pure functional programming is not a
great fit with this problem</span>. We need a better implementation
strategy: <a href="union-find.html" data-pltdoc="x">Union-Find</a>.</p>    
</body>
</html>