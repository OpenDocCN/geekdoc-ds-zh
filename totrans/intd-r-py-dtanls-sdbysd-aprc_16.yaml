- en: Chapter 12 Reshaping and Combining Data Sets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 重塑和组合数据集
- en: 原文：[https://randpythonbook.netlify.app/reshaping-and-combining-data-sets](https://randpythonbook.netlify.app/reshaping-and-combining-data-sets)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://randpythonbook.netlify.app/reshaping-and-combining-data-sets](https://randpythonbook.netlify.app/reshaping-and-combining-data-sets)
- en: 12.1 Ordering and Sorting Data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 数据的排序和排序
- en: Sorting a data set, in ascending order, say, is a common task. You might need
    to do it because
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 按升序排序数据集，例如，是一个常见的任务。你可能需要这样做，因为
- en: ordering and ranking is commonly done in *nonparametric statistics*,
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 排序和排名通常在*非参数统计*中完成，
- en: you want to inspect the most “extreme” observations in a data set,
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你想检查数据集中最“极端”的观测值，
- en: it’s a pre-processing step before generating visualizations.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是生成可视化之前的预处理步骤。
- en: 'In R, it all starts with `vector`s. There are two common functions you should
    know: `sort()` and `order()`. `sort()` returns the sorted *data*, while `order()`
    returns the *order indexes*.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，一切始于`向量`s。你应该了解两个常见的函数：`sort()`和`order()`。`sort()`返回排序后的*数据*，而`order()`返回*排序索引*。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`order()` is useful if you’re sorting a data frame by a particularly column.
    Below, we inspect the top 5 most expensive cars in an example data set (“SAS ^(Viya
    ^(Example Data Sets” [2021](#ref-sas_cars)))). Notice that we need to clean up
    the `MSRP` (a `character` vector) a little first. We use the function `gsub()`
    to find patterns in the text, and replace them with the empty string.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`order()`函数在按特定列对数据框进行排序时非常有用。下面，我们检查了一个示例数据集（“SAS ^ (Viya ^ (Example Data
    Sets）[2021](#ref-sas_cars)））中前5辆最昂贵的汽车。请注意，我们首先需要稍微清理一下`MSRP`（一个`字符向量`）。我们使用`gsub()`函数在文本中查找模式，并用空字符串替换它们。'
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In Python, Numpy has [`np.argsort()`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)
    and [`np.sort()`](https://numpy.org/doc/stable/reference/generated/numpy.sort.html).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，Numpy有`np.argsort()`（[https://numpy.org/doc/stable/reference/generated/numpy.argsort.html](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)）和`np.sort()`（[https://numpy.org/doc/stable/reference/generated/numpy.sort.html](https://numpy.org/doc/stable/reference/generated/numpy.sort.html)）。
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For Pandas’ `DataFrame`s, most of the functions I find useful are methods attached
    to the `DataFrame` class. That means that, as long as something is inside a `DataFrame`,
    you can use dot notation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Pandas的`DataFrame`s，我发现大多数有用的函数都是附加到`DataFrame`类的方法。这意味着，只要某物在`DataFrame`内部，你就可以使用点符号。
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Pandas’ `DataFrame`s and `Series` have a [`.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html)
    method. We use this to remove dollar signs and commas from the MSRP column. Note
    that we had to access the `.str` attribute of the `Series` column before we used
    it. After the string was processed, we converted it to a `Series` of `float`s
    with the `astype()` method.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas的`DataFrame`s和`Series`有一个[`.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html)方法。我们使用这个方法从MSRP列中删除美元符号和逗号。请注意，在使用它之前，我们必须访问`Series`列的`.str`属性。字符串处理完毕后，我们使用`astype()`方法将其转换为`float`s类型的`Series`。
- en: Finally, sorting the overall data frame could have been done with the same approach
    as the code we used in R (i.e. raw subsetting by row indexes), but there is a
    built-in method called [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)
    that will do it for us.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用与我们在R中使用的相同方法（即通过行索引进行原始子集选择）对整个数据框进行排序可能已经完成，但有一个内置的方法叫做`sort_values()`（[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)）可以为我们完成这项工作。
- en: 12.2 Stacking Data Sets and Placing Them Shoulder to Shoulder
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 数据集堆叠和并排放置
- en: Stacking data sets on top of each other is a common task. You might need to
    do it if
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集堆叠在一起是一个常见的任务。你可能需要这样做，如果
- en: you need to add a new row (or many rows) to a data frame,
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要向数据框中添加一行（或多行），
- en: you need to recombine data sets (e.g. recombine a train/test split), or
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要重新组合数据集（例如，重新组合训练/测试分割），或者
- en: you’re creating a matrix in a step-by-step way.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在逐步创建一个矩阵。
- en: In R, this can be done with `rbind()` (short for “row bind”). Consider the following
    example that makes use of GIS data queried from (Albemarle County Geographic Data
    Services Office [2021](#ref-albemarle_county_gis_web)) and cleaned with code from
    (Ford [2016](#ref-clay_ford)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，这可以通过`rbind()`（即“行绑定”）来完成。考虑以下示例，它使用了从（Albemarle County Geographic Data
    Services Office [2021](#ref-albemarle_county_gis_web)）查询的GIS数据，并使用（Ford [2016](#ref-clay_ford)）的代码进行了清理。
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The above example was with `data.frame`s. This example of `rbind()` is with
    `matrix` objects.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例是关于`data.frame`s的。以下`rbind()`的示例是关于`matrix`对象的。
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In Python, you can stack data frames with [`pd.concat()`](https://www.google.com/search?client=safari&rls=en&q=pandas+concat&ie=UTF-8&oe=UTF-8).
    It has a lot of options, so feel free to peruse them. You can also replace the
    call to `pd.concat()` below with [`test.append(train)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html).
    Consider the example below that uses the Albemarle County real estate data (Albemarle
    County Geographic Data Services Office [2021](#ref-albemarle_county_gis_web))
    (Ford [2016](#ref-clay_ford)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，你可以使用`pd.concat()`函数来堆叠数据框（[pd.concat()](https://www.google.com/search?client=safari&rls=en&q=pandas+concat&ie=UTF-8&oe=UTF-8)）。它有很多选项，所以请随意浏览它们。你也可以将下面的`pd.concat()`调用替换为`test.append(train)`（[test.append(train)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html)）。考虑以下示例，它使用了阿尔伯马尔县房地产数据（阿尔伯马尔县地理数据服务办公室
    [2021](#ref-albemarle_county_gis_web)）（福特 [2016](#ref-clay_ford)）。
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Take note of the extra square brackets when we create `test`. If you use `real_estate.iloc[0,]`
    instead, it will return a `Series` with all the elements coerced to the same type,
    and this won’t `pd.concat()` properly with the rest of the data!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意当我们创建`test`时额外的方括号。如果你使用`real_estate.iloc[0,]`代替，它将返回一个包含所有元素强制转换为相同类型的`Series`，并且这不会与剩余的数据`pd.concat()`正确地合并！
- en: 12.3 Merging or Joining Data Sets
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 合并或连接数据集
- en: If you have two different data sets that provide information about the same
    experimental units, you can put the two data sets together using a **`merge`**
    (aka **`join`**) operation. In R, you can use the [`merge()` function](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/merge).
    In Python, you can use the [`.merge()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas-dataframe-merge).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有两个不同的数据集，它们提供了关于相同实验单位的信息，你可以使用**`merge`**（也称为**`join`**）操作将这两个数据集合并在一起。在R中，你可以使用`merge()`函数（[merge()
    函数](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/merge)）。在Python中，你可以使用[`.merge()`
    方法](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas-dataframe-merge)。
- en: Merging (or joining) data sets is not the same as placing them shoulder to shoulder.
    Placing data sets shoulder to shoulder will not reorder the rows of your data
    and the operation requires that both input data sets have the same number of rows
    to start off with. On the other hand, merging data takes care to match rows together
    in an intelligent way, and it can handle situations of missing or duplicate matches.
    In both cases, the resulting data set is wider, but with merging, the output might
    end contain either more or fewer rows.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 合并（或连接）数据集与并排放置它们不同。并排放置数据集不会重新排序你的数据行，并且该操作要求两个输入数据集在开始时具有相同数量的行。另一方面，合并数据会智能地匹配行，并且它可以处理缺失或重复匹配的情况。在这两种情况下，结果数据集更宽，但合并时，输出可能包含更多或更少的行。
- en: Here’s a clarifying example. Suppose you have to sets of supposedly anonymized
    data about individual accounts on some online platforms.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个澄清的例子。假设你有一些关于某些在线平台上个人账户的匿名数据集。
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The first thing you need to ask yourself is *“which column is the unique identifier
    that is shared between these two data sets?”* In our case, they both have an “identification
    number” column. However, these two data sets are coming from different online
    platforms, and these two places use different schemes to number their users.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要问自己的第一件事是**“这两个数据集之间共享的唯一标识符是哪一列？”**在我们的例子中，它们都有一个“识别号”列。然而，这两个数据集来自不同的在线平台，这两个地方使用不同的方案来编号他们的用户。
- en: In this case, it is better to merge on the email addresses. Users might be using
    different email addresses on these two platforms, but there’s a stronger guarantee
    that matched email addresses means that you’re matching the right accounts. The
    columns are named differently in each data set, so we must specify them by name.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最好按电子邮件地址进行合并。用户可能在这两个平台上使用不同的电子邮件地址，但匹配的电子邮件地址意味着你匹配了正确的账户。每个数据集中的列名都不同，因此我们必须按名称指定它们。
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In Python, `merge()` is a method attached to each `DataFrame` instance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，`merge()`是每个`DataFrame`实例附加的方法。
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The email addresses `anotherfake@gmail.com` and `notreal@gmail.com` exist in
    both data sets, so each of these email addresses will end up in the result data
    frame. The rows in the result data set are wider and have more attributes for
    each individual.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件地址`anotherfake@gmail.com`和`notreal@gmail.com`在两个数据集中都存在，所以每个这些电子邮件地址最终都会出现在结果数据框中。结果数据集中的行更宽，并且每个个人都有更多的属性。
- en: Notice the duplicate email address, too. In this case, either the user signed
    up for two accounts using the same email, or one person signed up for an account
    with another person’s email address. In the case of duplicates, both rows will
    match with the same rows in the other data frame.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意重复的电子邮件地址。在这种情况下，用户可能使用相同的电子邮件地址注册了两个账户，或者一个人使用另一个人的电子邮件地址注册了账户。在重复的情况下，两行将与另一个数据框中的相同行匹配。
- en: Also, in this case, all email addresses that weren’t found in both data sets
    were thrown away. This does not necessarily need to be the intended behavior.
    For instance, if we wanted to make sure no rows were thrown away, that would be
    possible. In this case, though, for email addresses that weren’t found in both
    data sets, some information will be missing. Recall that Python and R handle missing
    data differently (see [3.8.2](/r-vectors-versus-numpy-arrays-and-pandas-series#how-r-and-python-handle-missing-values)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在这种情况下，所有在两个数据集中都没有找到的电子邮件地址都被丢弃了。这不一定需要是预期的行为。例如，如果我们想确保没有行被丢弃，那是可能的。然而，在这种情况下，对于在两个数据集中都没有找到的电子邮件地址，将缺少一些信息。回想一下，Python和R处理缺失数据的方式不同（见[3.8.2](/r-vectors-versus-numpy-arrays-and-pandas-series#how-r-and-python-handle-missing-values)）。
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can see it’s slightly more concise in Python. If you are familiar with SQL,
    you might have heard of inner and outer joins. This is where Pandas [takes some
    of its argument names from](https://pandas.pydata.org/pandas-docs/version/0.15/merging.html#database-style-dataframe-joining-merging).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，这会稍微简洁一些。如果你熟悉SQL，你可能听说过内连接和外连接。这就是Pandas从其中获取一些参数名称的地方（见[12.4.1](https://pandas.pydata.org/pandas-docs/version/0.15/merging.html#database-style-dataframe-joining-merging)）。
- en: Finally, if both data sets have multiple values in the column you’re joining
    on, the result can have more rows than either table. This is because *every possible
    match* shows up.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果连接的列中两个数据集都有多个值，结果可以比任一表有更多的行。这是因为**所有可能的匹配**都会出现。
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 12.4 Long Versus Wide Data
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 长格式与宽格式数据
- en: 12.4.1 Long Versus Wide in R
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.1 R中的长格式与宽格式
- en: Many types of data can be stored in either a **wide** or **long** format.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 许多类型的数据可以存储在**宽格式**或**长格式**中。
- en: The classical example is data from a *longitudinal study.* If an experimental
    unit (in the example below this is a person) is repeatedly measured over time,
    each row would correspond to an experimental unit *and* an observation time in
    a data set in a long form.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的例子是来自**纵向研究**的数据。如果一个实验单位（在下面的例子中是一个人）在一段时间内被反复测量，每行将对应于一个实验单位和一个数据集中长格式下的观察时间。
- en: '[PRE15]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: A long format can also be used if you have multiple observations (at a single
    time point) on an experimental unit. Here is another example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对实验单位有多个观察（在单个时间点），也可以使用长格式。这里还有一个例子。
- en: '[PRE16]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: If you would like to reshape the long data sets into a wide format, you can
    use the `reshape()` function. You will need to specify which columns correspond
    with the experimental unit, and which column is the “factor” variable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要将长数据集重塑为宽格式，可以使用`reshape()`函数。你需要指定哪些列对应于实验单位，以及哪一列是“因子”变量。
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`reshape()` will also go in the other direction: it can take wide data and
    convert it into long data'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`reshape()`也可以进行相反的操作：它可以将宽数据转换为长数据。'
- en: '[PRE19]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 12.4.2 Long Versus Wide in Python
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.2 Python中的长格式与宽格式
- en: With Pandas, we can take make long data wide with [`pd.DataFrame.pivot()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html#),
    and we can go in the other direction with [`pd.DataFrame.melt()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html?highlight=melt).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Pandas，我们可以使用`pd.DataFrame.pivot()`将长数据转换为宽数据，并且我们可以使用`pd.DataFrame.melt()`进行相反的操作。
- en: When going from long to wide, make sure to use the [`pd.DataFrame.reset_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html#)
    method afterwards to reshape the data and remove the index. Here is an example
    similar to the one above.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从长格式转换为宽格式后，请确保使用`pd.DataFrame.reset_index()`方法重新塑形数据并删除索引。这里有一个与上面类似的示例。
- en: '[PRE20]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here’s one more example showing the same functionality–going from long to wide
    format.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个更多示例，展示了相同的功能——从长格式转换为宽格式。
- en: '[PRE21]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here are some examples of going in the other direction: from wide to long with
    [`pd.DataFrame.melt()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html?highlight=melt).
    The first example specifies value columns by integers.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些从宽到长的其他方向的例子：使用[`pd.DataFrame.melt()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html?highlight=melt)。第一个示例通过整数指定值列。
- en: '[PRE22]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The second example uses strings to specify value columns.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个示例使用字符串指定值列。
- en: '[PRE23]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 12.5 Exercises
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 练习
- en: 12.5.1 R Questions
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.1 R 问题
- en: Recall the `car.data` data set (“Car Evaluation” [1997](#ref-misc_car_evaluation_19)),
    which is hosted by (Dua and Graff [2017](#ref-uci_data)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆`car.data`数据集（“汽车评估” [1997](#ref-misc_car_evaluation_19)），由（Dua 和 Graff [2017](#ref-uci_data)）托管。
- en: Read in the data set as `carData`.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集读取为`carData`。
- en: Convert the third and fourth columns to *ordered* `factor`s.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第三列和第四列转换为*有序*的`因子`。
- en: Order the data by the third and then the fourth column (simultaneously). Do
    not change the data in place. Instead store it under the name `ordCarData1`
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按第三列然后是第四列（同时）对数据进行排序。不要就地更改数据。相反，将其存储在`ordCarData1`下。
- en: Order the data by the fourth and then the third column (simultaneously). Do
    not change the data in place. Instead store it under the name `ordCarData2`
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按第四列然后是第三列（同时）对数据进行排序。不要就地更改数据。相反，将其存储在`ordCarData2`下。
- en: '[PRE24]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Pretend `day1Data` and `day2Data` are two separate data sets that possess the
    same type of measures but on different experimental units. Stack `day1Data` on
    top of `day2Data` and call the result `stackedData`.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设`day1Data`和`day2Data`是两个具有相同类型测量但实验单位不同的独立数据集。将`day1Data`堆叠在`day2Data`之上，并将结果命名为`stackedData`。
- en: Pretend `day1Data` and `day2Data` are different measurements on the same experimental
    units. Place them shoulder to shoulder and call the result `sideBySide`. Put `day1Data`
    first, and `day2Data` second.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设`day1Data`和`day2Data`是在相同实验单位上的不同测量值。将它们肩并肩放置，并将结果命名为`sideBySide`。将`day1Data`放在第一位，`day2Data`放在第二位。
- en: If you are dealing with random matrices, you might need to **vectorize** a matrix
    object. This is not the same as “vectorization” in programming. Instead, it means
    you write the matrix as a big column vector by stacking the columns on top of
    each other. Specifically, if you have a \(n \times p\) real-valued matrix \(\mathbf{X}\),
    then
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你处理的是随机矩阵，你可能需要**向量化**一个矩阵对象。这不同于编程中的“向量化”。相反，这意味着你将矩阵写成一个大列向量，通过将列堆叠在一起。具体来说，如果你有一个\(n
    \times p\)的实值矩阵\(\mathbf{X}\)，那么
- en: \[\begin{equation} \text{vec}(\mathbf{X}) =\begin{bmatrix} \mathbf{X}_1 \\ \vdots
    \\ \mathbf{X}_p \end{bmatrix} \end{equation}\]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \text{vec}(\mathbf{X}) =\begin{bmatrix} \mathbf{X}_1 \\ \vdots
    \\ \mathbf{X}_p \end{bmatrix} \end{equation}\]
- en: where \(\mathbf{X}_i\) is the \(i\)th column as an \(n \times 1\) column vector.
    There is another operator that we will use, the **Kronecker product:**
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(\mathbf{X}_i\)是第\(i\)列作为一个\(n \times 1\)列向量。我们还将使用另一个运算符，**克罗内克积**：
- en: \[\begin{equation} \mathbf{A} \otimes \mathbf{B} = \begin{bmatrix} a_{11} \mathbf{B}
    & \cdots & a_{1n} \mathbf{B} \\ \vdots & \ddots & \vdots \\ a_{m1} \mathbf{B}
    & \cdots & a_{mn} \mathbf{B} \\ \end{bmatrix}. \end{equation}\]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \mathbf{A} \otimes \mathbf{B} = \begin{bmatrix} a_{11} \mathbf{B}
    & \cdots & a_{1n} \mathbf{B} \\ \vdots & \ddots & \vdots \\ a_{m1} \mathbf{B}
    & \cdots & a_{mn} \mathbf{B} \\ \end{bmatrix}. \end{equation}\]
- en: If \(\mathbf{A}\) is \(m \times n\) and \(\mathbf{B}\) is \(p \times q\), then
    \(\mathbf{A} \otimes \mathbf{B}\) is \(pm \times qn\).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果\(\mathbf{A}\)是\(m \times n\)且\(\mathbf{B}\)是\(p \times q\)，那么\(\mathbf{A}
    \otimes \mathbf{B}\)是\(pm \times qn\)。
- en: 'Write a function called `vec(myMatrix)`. Its input should be one `matrix` object.
    It’s output should be a `vector`. Hint: `matrix` objects are stored in column-major
    order.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个名为`vec(myMatrix)`的函数。它的输入应该是一个`矩阵`对象。它的输出应该是一个`向量`。提示：`矩阵`对象以列主序存储。
- en: Write a function called `unVec(myVector, nRows)` that takes in the vectorized
    matrix as a `vector`, splits that into elements with `nRows` elements, and then
    places them together shoulder-to-shoulder as a `matrix`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个名为`unVec(myVector, nRows)`的函数，该函数接受一个向量化的矩阵作为`向量`，将其分割成具有`nRows`个元素的元素，然后将它们肩并肩地作为一个`矩阵`放置在一起。
- en: Write a function called `stackUp(m, BMat)` that returns \(\mathbf{1}_m \otimes
    \mathbf{B}\) where \(\mathbf{1}_m\) is a length \(m\) column vector of ones. You
    may check your work with `%x%`, but do not use this in your function.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个名为`stackUp(m, BMat)`的函数，该函数返回\(\mathbf{1}_m \otimes \mathbf{B}\)，其中\(\mathbf{1}_m\)是一个长度为\(m\)的由一组成的列向量。你可以用`%x%`来检查你的工作，但不要在函数中使用它。
- en: Write a function called `shoulderToShoulder(n, BMat)` that returns \(\mathbf{1}^\intercal_n
    \otimes \mathbf{B}\) where \(\mathbf{1}_n^\intercal\) is a length \(n\) row vector
    of ones. You may check your work with `%x%`, but do not use this in your function.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个名为 `shoulderToShoulder(n, BMat)` 的函数，该函数返回 \(\mathbf{1}^\intercal_n \otimes
    \mathbf{B}\)，其中 \(\mathbf{1}_n^\intercal\) 是长度为 \(n\) 的全一列向量。你可以用 `%x%` 来检查你的工作，但不要在函数中使用它。
- en: This problem uses the Militarized Interstate Disputes (v5.0) (Palmer et al.)
    data set from [The Correlates of War Project](https://correlatesofwar.org/). There
    are four `.csv` files we use for this problem. `MIDA 5.0.csv` contains the essential
    attributes of each militarized interstate dispute from 1/1/1816 through 12/31/2014\.
    `MIDB 5.0.csv` describes the participants in each of those disputes. `MIDI 5.0.csv`
    contains the essential elements of each militarized interstate incident, and `MIDIP
    5.0.csv` describes the participants in each of those incidents.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此问题使用的是来自 [The Correlates of War Project](https://correlatesofwar.org/) 的军事化州际争端（v5.0）数据集（Palmer
    等人）。我们为此问题使用了四个 `.csv` 文件。`MIDA 5.0.csv` 包含了从 1/1/1816 到 12/31/2014 的每个军事化州际争端的必要属性。`MIDB
    5.0.csv` 描述了这些争端中的参与者。`MIDI 5.0.csv` 包含了每个军事化州际事件的必要要素，而 `MIDIP 5.0.csv` 描述了这些事件中的参与者。
- en: Read in the four data sets and give them the names `mida`, `midb`, `midi`, and
    `midp`. Take care to convert all instances of `-9` to `NA`.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读入四个数据集，并将它们命名为 `mida`、`midb`、`midi` 和 `midp`。注意将所有 `-9` 实例转换为 `NA`。
- en: Examine all rows of `midb` where its `dispnum` column equals `2`. Do not change
    `midb` permanently. Are these two rows corresponding to the same conflict? If
    so, assign `TRUE` to `sameConflict`. Otherwise, assign `FALSE`.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `midb` 中 `dispnum` 列等于 `2` 的所有行。不要永久更改 `midb`。这两行是否对应同一冲突？如果是，将 `sameConflict`
    赋值为 `TRUE`。否则，赋值为 `FALSE`。
- en: Join the first two data sets together on the dispute number column (`dispnum`).
    Call the resulting `data.frame` `join1`. Do not address any concerns about duplicate
    columns.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前两个数据集在争端编号列（`dispnum`）上合并。将得到的 `data.frame` 命名为 `join1`。不要处理任何关于重复列的问题。
- en: Is there any difference between doing an inner join and an outer join in the
    previous question? If there was a difference, assign `TRUE` to `theyAreNotTheSame`.
    Otherwise, assign `FALSE` to it.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一个问题中，内连接和外连接有什么区别？如果有区别，将 `theyAreNotTheSame` 赋值为 `TRUE`。否则，将其赋值为 `FALSE`。
- en: Join the last two data sets together by `incidnum` and call the result `join2`.
    Is there any difference between an inner and an outer join for this problem? Why
    or why not? Do not address any concerns about duplicate columns.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `incidnum` 将最后两个数据集合并，结果命名为 `join2`。对于这个问题，内连接和外连接有什么区别？为什么？不要处理任何关于重复列的问题。
- en: The codebook mentions that the last two data sets don’t go as far back in time
    as the first two. Suppose then that we only care about the events in `join2`.
    Merge `join2` and `join1` in a way where all undesired rows from `join1` are discarded,
    and all rows from `join2` are kept. Call the resulting `data.frame` `midData`.
    Do not address any concerns about duplicate columns.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码手册提到，最后两个数据集的时间跨度不如前两个数据集长。那么，我们只关心 `join2` 中的事件。以丢弃 `join1` 中所有不需要的行，并保留
    `join2` 中所有行的方式合并 `join2` 和 `join1`。将得到的 `data.frame` 命名为 `midData`。不要处理任何关于重复列的问题。
- en: Use a scatterplot to display the relationship between the maximum duration and
    the end year. Plot each country as a different color.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用散点图显示最大持续时间和结束年份之间的关系。将每个国家用不同的颜色表示。
- en: 'Create a `data.frame` called `longData` that has the following three columns
    from `midp`: `incidnum` (incident identification number) `stabb` (state abbreviation
    of participant) and `fatalpre` (precise number of fatalities). Convert this to
    “wide” format. Make the new table called `wideData`. Use the incident number row
    as a unique row-identifying variable.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `longData` 的 `data.frame`，其中包含 `midp` 的以下三个列：`incidnum`（事件识别号）`stabb`（参与者的州简称）和
    `fatalpre`（精确的死亡人数）。将其转换为“宽”格式。将新表命名为 `wideData`。使用事件编号行作为唯一的行标识变量。
- en: 'Bonus Question: identify all column pairs that contain duplicate information
    in `midData`, remove all but one of the columns, and change the column name back
    to its original name.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 奖励问题：识别 `midData` 中包含重复信息的所有列对，删除除了一个之外的所有列，并将列名改回原始名称。
- en: 12.5.2 Python Questions
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.2 Python 问题
- en: Once again, recall the `"car.data"` data set (“Car Evaluation” [1997](#ref-misc_car_evaluation_19)).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回想一下 `"car.data"` 数据集（“Car Evaluation” [1997](#ref-misc_car_evaluation_19)）。
- en: Read in the data set as `car_data`.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集读入为 `car_data`。
- en: Order the data by the third and then the fourth column. Do not change the data
    in place. Instead store it under the name `ord_car_data1`
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照第三列和第四列的顺序对数据进行排序。不要在原地进行数据更改。相反，将其存储在名为 `ord_car_data1` 的名称下。
- en: Order the data by the fourth and then the third column. Do not change the data
    in place. Instead store it under the name `ord_car_data2`
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照第四列和第三列的顺序对数据进行排序。不要在原地进行数据更改。相反，将其存储在名为 `ord_car_data2` 的名称下。
- en: Consider the following random data set.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下随机数据集。
- en: '[PRE25]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Pretend `d1` and `d2` are two separate data sets that possess the same type
    of measures but on different experimental units. Stack `d1` on top of `d2` and
    call the result `stacked_data_sets`. Make sure the `index` of the result is the
    numbers \(0\) through \(39\)
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设 `d1` 和 `d2` 是两个具有相同类型测量但位于不同实验单位上的独立数据集。将 `d1` 堆叠在 `d2` 之上，并将结果称为 `stacked_data_sets`。确保结果的
    `index` 是数字 \(0\) 到 \(39\)。
- en: Pretend `d1` and `d2` are different measurements on the same experimental units.
    Place them shoulder to shoulder and call the result `side_by_side_data_sets`.
    Put `d1` first, and `d2` second.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设 `d1` 和 `d2` 是对相同实验单位的两种不同测量。将它们并排放置，并将结果称为 `side_by_side_data_sets`。将 `d1`
    放在第一位，`d2` 放在第二位。
- en: 'Consider the following two data sets:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下两个数据集：
- en: '[PRE26]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Join/merge the two data sets together in such a way that there is a row for
    every dog, whether or not both tables have information for that dog. Call the
    result `merged1`.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以这种方式合并/连接两个数据集，使得每只狗都有一行，无论两个表是否都有关于该狗的信息。将结果称为 `merged1`。
- en: Join/merge the two data sets together in such a way that there are only rows
    for every dog in `dataset1`, whether or not there is information about these dogs’
    breeds. Call the result `merged2`.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以这种方式合并/连接两个数据集，使得 `dataset1` 中的每只狗都只有一行，无论是否有关于这些狗品种的信息。将结果称为 `merged2`。
- en: Join/merge the two data sets together in such a way that there are only rows
    for every dog in `dataset2`, whether or not there is information about the dogs’
    nicknames. Call the result `merged3`.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以这种方式合并/连接两个数据集，使得 `dataset2` 中的每只狗都只有一行，无论是否有关于狗昵称的信息。将结果称为 `merged3`。
- en: Join/merge the two data sets together in such a way that all rows possess complete
    information. Call the result `merged4`.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以这种方式合并/连接两个数据集，使得所有行都拥有完整的信息。将结果称为 `merged4`。
- en: Let’s consider Fisher’s “Iris” data set (Fisher [1988](#ref-misc_iris_53)) again.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次考虑费舍尔的“鸢尾花”数据集（Fisher [1988](#ref-misc_iris_53)）。
- en: Read in `iris.csv` and store the `DataFrame` with the name `iris`. Let it have
    the column names `'a'`,`'b'`,`'c'`, `'d'` and `'e'`.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `iris.csv` 并将 `DataFrame` 存储为名为 `iris`。让它有列名 `'a'`、`'b'`、`'c'`、`'d'` 和 `'e'`。
- en: Create a `DataFrame` called `name_key` that stores correspondences between long
    names and short names. It should have three rows and two columns. The long names
    are the unique values of column five of `iris`. The short names are either `'s'`,
    `'vers'` or `'virg'`. Use the column names `'long name'` and `'short name'`.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `name_key` 的 `DataFrame`，用于存储长名称和短名称之间的对应关系。它应该有 3 行和 2 列。长名称是 `iris`
    第五列的唯一值。短名称可以是 `'s'`、`'vers'` 或 `'virg'`。使用列名 `'long name'` 和 `'short name'`。
- en: 'Merge/join the two data sets together to give `iris` a new column with information
    about short names. Do not overwrite `iris`. Rather, give the `DataFrame` a new
    name: `iris_with_short_names`. Remove any columns with duplicate information.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这两个数据集合并/连接在一起，为 `iris` 添加一个包含短名称信息的新列。不要覆盖 `iris`。相反，给 `DataFrame` 起一个新的名字：`iris_with_short_names`。删除任何包含重复信息的列。
- en: Change the first four column names of `iris_with_short_names` to `s_len`, `s_wid`,
    `p_len`, and `p_wid`. Use Matplotlib to create a figure with 4 subplots arranged
    into a \(2 \times 2\) grid. On each subplot, plot a histogram of these four columns.
    Make sure to use x-axis labels so viewers can tell which column is being plotted
    in each subplot.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `iris_with_short_names` 的前四列列名更改为 `s_len`、`s_wid`、`p_len` 和 `p_wid`。使用 Matplotlib
    创建一个包含 4 个子图，排列成 \(2 \times 2\) 网格的图形。在每个子图上，绘制这四个列的直方图。确保使用 x 轴标签，以便观众可以知道每个子图正在绘制哪个列。
- en: Let’s go back to `iris`. Change that to long format. Store it as a `DataFrame`
    called `long_iris`. Make the column names `row`, `variable` and `value`, in that
    order. Last, make sure it is sorted (simultaneously/once) by `row` and then `variable`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们回到 `iris`。将其更改为长格式。将其存储为名为 `long_iris` 的 `DataFrame`。按顺序将列名设置为 `row`、`variable`
    和 `value`。最后，确保它按 `row` 和 `variable` 排序（同时/一次）。
- en: References
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: Albemarle County Geographic Data Services Office. 2021\. “Albemarle County GIS
    Web.” [https://www.albemarle.org/government/community-development/gis-mapping/gis-data](https://www.albemarle.org/government/community-development/gis-mapping/gis-data).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 阿尔贝马尔县地理数据服务办公室。2021\. “阿尔贝马尔县GIS网站。” [https://www.albemarle.org/government/community-development/gis-mapping/gis-data](https://www.albemarle.org/government/community-development/gis-mapping/gis-data).
- en: “Car Evaluation.” 1997\. UCI Machine Learning Repository.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: “汽车评估。” 1997\. UCI机器学习库。
- en: Dua, Dheeru, and Casey Graff. 2017\. “UCI Machine Learning Repository.” University
    of California, Irvine, School of Information; Computer Sciences. [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 杜阿，德鲁，和凯西·格拉夫。2017\. “UCI机器学习库。” 加州大学欧文分校，信息学院；计算机科学系。[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
- en: Fisher, Test, R.A. & Creator. 1988\. “Iris.” UCI Machine Learning Repository.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 费舍尔，测试，R.A. & 创作者。1988\. “鸢尾花。” UCI机器学习库。
- en: 'Ford, Clay. 2016\. “ggplot: Files for UVA StatLab workshop, Fall 2016.” *GitHub
    Repository*. [https://github.com/clayford/ggplot2](https://github.com/clayford/ggplot2);
    GitHub.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '福特，克莱。2016\. “ggplot: UVA StatLab研讨会，2016年秋季的文件。” *GitHub仓库*。[https://github.com/clayford/ggplot2](https://github.com/clayford/ggplot2);
    GitHub.'
- en: 'Palmer, Glenn, Roseanne W McManus, Vito D’Orazio, Michael R Kenwick, Mikaela
    Karstens, Chase Bloch, Nick Dietrich, Kayla Kahn, Kellan Ritter, and Michael J
    Soules“The Mid5 Dataset, 2011–2014: Procedures, Coding Rules, and Description.”
    *Conflict Management and Peace Science* 0 (0): 0738894221995743\. [https://doi.org/10.1177/0738894221995743](https://doi.org/10.1177/0738894221995743).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '帕尔默，格伦，罗珊·W·麦克曼斯，维托·多拉齐奥，迈克尔·R·肯威克，米凯拉·卡尔滕斯，查斯·布洛克，尼克·迪特里希，凯拉·卡恩，凯兰·里特，迈克尔·J·索尔斯“The
    Mid5数据集，2011–2014：程序，编码规则和描述。” *冲突管理与和平科学* 0 (0): 0738894221995743\. [https://doi.org/10.1177/0738894221995743](https://doi.org/10.1177/0738894221995743).'
- en: “SAS ^(Viya ^(Example Data Sets.” 2021\. [https://support.sas.com/documentation/onlinedoc/viya/examples.htm](https://support.sas.com/documentation/onlinedoc/viya/examples.htm).))
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: “SAS^(Viya^(示例数据集。” 2021\. [https://support.sas.com/documentation/onlinedoc/viya/examples.htm](https://support.sas.com/documentation/onlinedoc/viya/examples.htm).))
