- en: 10.1¬†Introduction to Pandasüîó
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://dcic-world.org/2025-08-27/python-tables-Pandas.html](https://dcic-world.org/2025-08-27/python-tables-Pandas.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| ¬†¬†¬†¬†[10.1.1¬†Pandas Table Basics](#%28part._.Pandas_.Table_.Basics%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[10.1.1.1¬†Core Datatypes: DataFrame and Series](#%28part._.Core_.Datatypes__.Data.Frame_and_.Series%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[10.1.1.2¬†Creating and Loading DataFrames](#%28part._.Creating_and_.Loading_.Data.Frames%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[10.1.1.3¬†Using Labels and Indices to Access Cells](#%28part._.Using_.Labels_and_.Indices_to_.Access_.Cells%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.2¬†Filtering Rows](#%28part._.Filtering_.Rows%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.3¬†Cleaning and Normalizing Data](#%28part._.Cleaning_and_.Normalizing_.Data%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[10.1.3.1¬†Clearing out unknown values](#%28part._.Clearing_out_unknown_values%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[10.1.3.2¬†Repairing Values and Column Types](#%28part._.Repairing_.Values_and_.Column_.Types%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.4¬†Computing New Columns](#%28part._.Computing_.New_.Columns%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.5¬†Aggregating and Grouping Columns](#%28part._.Aggregating_and_.Grouping_.Columns%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.6¬†Wide Versus Tall Data](#%28part._.Wide_.Versus_.Tall_.Data%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[Converting Between Wide and Tall Data](#%28part._.Converting_.Between_.Wide_and_.Tall_.Data%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.7¬†Plotting Data](#%28part._.Plotting_.Data%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[10.1.8¬†Takeaways](#%28part._.Takeaways%29) |'
  prefs: []
  type: TYPE_TB
- en: Now it‚Äôs time to transfer what we learned about tables in Pyret over to Python.
    Pandas is a popular package, and you‚Äôll find many tutorial and help sites for
    it online. In general, Python usually provides many ways to approach a given task.
    As such, there are many ways to do common operations in Pandas. We have chosen
    to present a certain collection of ways that align with the concepts as we covered
    them in Pyret.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work in Pandas, you‚Äôll need to include the following line at the top of
    your file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 10.1.1¬†Pandas Table Basics[üîó](#(part._.Pandas_.Table_.Basics) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '10.1.1.1¬†Core Datatypes: DataFrame and Series[üîó](#(part._.Core_.Datatypes__.Data.Frame_and_.Series)
    "Link to here")'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pandas uses the term DataFrame for a table with rows and columns. DataFrames
    are built out of two more basic types:'
  prefs: []
  type: TYPE_NORMAL
- en: An array is a sequence of values that can be accessed by position (e.g., 0,
    1, ... up to one less than the length of the array). Like lists, arrays capture
    a linear (ordered) collection of values. Unlike lists, arrays are created with
    a limit on the number of elements that they contain. In practice, lists are more
    commonly used when elements are frequently added or removed whereas arrays are
    more commonly used when elements frequently get accessed by their position. Nearly
    every programming language offers both lists and arrays; a detailed contrast is
    beyond the scope of this book (this information would be covered in a data structures
    class).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Series is an array in which the positions optionally have labels in addition
    to the position numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Pandas, a row is a Series in which an array of the cell values is labeled
    with the column headers (this is similar to the ‚ÄòRow‚Äò datatype in Pyret). A DataFrame
    is a series of these rows.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.2¬†Creating and Loading DataFrames[üîó](#(part._.Creating_and_.Loading_.Data.Frames)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'DataFrames can be created manually or loaded in from a file, as we did in Pyret.
    Here‚Äôs a simple example of creating one by hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`data` is a dictionary that maps column names to values. Calling `pd.DataFrame`
    creates a DataFrame from the dictionary. (There are other ways to create DataFrames
    manually which you can find by searching online.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load a DataFrame from a CSV file, you need either the path to the file on
    your computer or the url where you can get the CSV file online. Here‚Äôs an example
    of the url version. In this example, we have the following CSV contents and we
    want to change the header names when loading the file:'
  prefs: []
  type: TYPE_NORMAL
- en: The following `read_csv` command says that the CSV file is at `url`, that there
    are headers in the first row (numbered `0`), and that we want to use the values
    in `names` as the column labels (this will ignore whatever might be in the header
    row in the CSV file).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted to use the headers in the CSV file as the column headers, we would
    leave out the `names=[...]` part. If the CSV had no header row, we would write
    `header=None` instead of `header=0`. (There are many more configuration options
    in the [Pandas documentation](https://Pandas.pydata.org/docs/reference/api/Pandas.read_csv.html),
    but you won‚Äôt need them for the examples in this book.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, the loaded DataFrame is as follows, with the labels shown in
    blue and the indicies (positions) show in yellow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d63a7003f02c1f4bfd00ac93817af463.png)'
  prefs: []
  type: TYPE_IMG
- en: Since we did not specify labels for the rows, Pandas has used numeric labels
    by default. At the moment, the positions and the labels are the same for each
    row, but we will see that this is not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: (If you look at the actual loaded table, some of the blank cells in the discount
    column will contain `NaN`, which is the standard Python value for ‚Äúmissing information‚Äù.
    We will deal with that information shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.3¬†Using Labels and Indices to Access Cells[üîó](#(part._.Using_.Labels_and_.Indices_to_.Access_.Cells)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Rows, columns, and cells can be accessed using either their (numeric) positions
    or their labels. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we used different notation for accessing a cell depending on whether
    we accessed the row first or the column first. This is because we are showing
    you how to access data through either position indices or labels. Using `.loc`
    tells Pandas that you are using a label to access a row. If you want to use the
    position instead, you need to use `iloc` (the `i` stands for ‚Äúinteger‚Äù). If you
    are using a programmer-supplied label instead, you can just use the label directly.
  prefs: []
  type: TYPE_NORMAL
- en: In a DataFrame, both rows and columns always have position indices and may have
    labels. The `.loc` notation works on either rows or columns, we just happened
    to illustrate the notation on the rows since we had already created labels on
    the columns when we loaded `events`.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.2¬†Filtering Rows[üîó](#(part._.Filtering_.Rows) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Back in Pyret, we filtered rows from a table by writing a function from `Row`
    to `Boolean`. The `filter-with` function applied that function to every row in
    the table, returning a new table with those rows for which the predicate were
    true.
  prefs: []
  type: TYPE_NORMAL
- en: In Pandas, we select rows by providing an array of Booleans that has the same
    length as the number of rows in the DataFrame. Filtering keeps those rows for
    which the corresponding array entry is `True`. For example, here‚Äôs our DataFrame
    diagram from before, this time with an array to the right indicating that we want
    to keep rows 0, 2, and 6.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0958f43b8192439a6fd898de3fbe50fb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The ‚Äúkeep‚Äù array is not part of the DataFrame. Here is the corresponding array
    expressed in code, followed by the notation to use the array to filter the DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the array of booleans, we use it to extract a collection of rows
    using similar notation that we previously used to extract a column. Just as we
    wrote `events[''numtix'']` to select the `''numtix''` column, we can write `events[keep]`
    to select a collection of rows. The DataFrame that results from filtering (along
    with the `True` cells of the `keep` array for illustration) appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0baa50e0adf5a889a71a977667d9c7e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'How does Pandas know whether we want to select rows or columns? It depends
    on what we provide in the square brackets: if we provide a single label, we get
    the column or row with that label; if we provide an array of booleans, we get
    the rows for which the corresponding row (by position) is `True`.'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Look at the returned DataFrame. Do you notice anything interesting?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the row labels and indices: the labels have been retained from the
    original DataFrame (0, 2, and 6), while the indices are a sequence of consecutive
    numbers starting from 0\. Having both ways to reference rows‚Äî<wbr>one based on
    raw order and the other based on programmer-provided labels‚Äî<wbr>provides a lot
    of flexibility as we use filter to isolate parts of tables that we want to work
    on.'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Does filtering rows this way in Python keep the original `events` DataFrame
    intact? Try it out!
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Arrays of booleans that are used for filtering out other arrays are called masks.
    Here, we have shown a simple mask that we constructed by hand. If we had a long
    DataFrame, however, we would not want to construct a mask for it by hand. Fortunately,
    we don‚Äôt have to. Python provides notations that let us construct masks via expressions
    over a series.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that we wanted to filter the `events` table down to those rows with
    delivery method `''email''`. To create a mask for this, we first select the delivery
    column as a series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we use the series in a boolean expression that states the constraint
    that we want on each element of the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Wait, what‚Äôs going on here? `events['deliver']` is a Series (a labeled array
    of strings). `'email'` is a string. What does it even mean to ask whether two
    values of different types be considered equal, especially when one has many component
    values and the other does not?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the `==` doesn‚Äôt mean ‚Äúare these equal‚Äù? Instead, Python applies
    `== 'email'` to every element of the `events['delivery']` Series, constructing
    a new Series of the results. This idea of applying an operation to all elements
    of an array is known as ‚Äúlifting‚Äù. It is one of the shortcuts that Python provides
    to help experienced programmers do simple common tasks quickly and easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a Series of booleans (for which events will be picked up by
    email), we can use it to select those rows from the `events` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The inner use of `events` is for creating the mask, while the outer one is for
    filtering the table with that mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a warning: if you search online for information on how to filter or process
    DataFrame, you might find code samples that do this using for loops. While that
    approach works, it isn‚Äôt considered good Pandas (or general programming) practice.
    Most modern languages provide built-in constructs for iterating over lists and
    other sequence-style data. These operations have more descriptive names than generic
    loops (which makes them easier for other programmers to read), and are often engineered
    to run more efficiently under the hood. As a general rule, only default to basic
    loops if there is no built-in operator to do the computation that you have in
    mind.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.3¬†Cleaning and Normalizing Data[üîó](#(part._.Cleaning_and_.Normalizing_.Data)
    "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The same operator-lifting idea that we just saw when creating masks from DataFrames
    also comes into play for normalizing data. Recall that when we worked with the
    `events` table in Pyret, we converted all of the discount codes to lowercase.
    Here‚Äôs the code that does this in Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Look at the above code. Break it down and try to articulate what each part does.
    Do any parts seem new or different from things we‚Äôve done so far in Pandas?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the right side of the `=`, we are extracting the Series of discount codes
    (`events['discount']`), then using the lowercase operation on strings `str.lower()`
    to convert each one, building up a Series of the results. Normally, given a string
    (such as `'BIRTHDAY'`), we could get a lowercase version of it by writing just
    `'BIRTHDAY'.lower()`. What‚Äôs the extra `str` doing in there?
  prefs: []
  type: TYPE_NORMAL
- en: This is a nuance about lifting. Python can evaluate `'BIRTHDAY'.lower()` because
    `lower()` is defined directly on strings. `lower()` is not, however, directly
    defined on Series. To bridge the gap between having Series data and wanting to
    use a string operation on it, we insert `str` before `lower()`. Effectively, this
    tells Python where to find the `lower()` operation (in the collection of operations
    defined on strings).
  prefs: []
  type: TYPE_NORMAL
- en: 'The left side of the above code looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells Pandas to replace the current contents of the `''discount''` series
    with the series on the right side of the `=`. It is similar to `transform-column`
    from Pyret, but with a fundamental difference: in Pyret, `transform-column` left
    the old table intact and produced a new table with the new column values. Instead,
    in Pandas the old column gets replaced, thus destroying the original table. There
    are many nuances to having operations destroy and replace data; the chapter on
    [Mutating Structures](mutating-structures.html) studies them in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.3.1¬†Clearing out unknown values[üîó](#(part._.Clearing_out_unknown_values)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now let‚Äôs try a different cleaning and normalization problem: we want the discount
    column to contain only known discount codes or empty strings. The `none` entry
    in line 3 of the table should be converted to an empty string, and we should make
    sure that all of the `NaN` and seemingly empty entries in the discount cells are
    also converted to empty strings (as opposed to strings of multiple spaces).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plan out how you might do this task using mask expressions. Even if you don‚Äôt
    know all the specific notation for the operations you need, you can still work
    out a plan for completing this task.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you planned out the tasks, you might have a todo list like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: create a mask of rows with known discount codes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: invert that mask (swap the false and true values)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: filter the DataFrame to rows without a known discount code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: replace all the discount column values in that DataFrame with an empty string
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have seen how to do parts of steps 1 and 3, but neither of steps 2 and 4\.
    Let‚Äôs work through the steps one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs the code for step 1, which creates a mask for the rows with known discount
    codes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use a lifted `isin` operator on lists to compute the mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'For step 2, we have to swap the true and false values. We can do this by using
    the negation operator `~` on the mask from step 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'For step 3, we want to filter `events` with this mask. Just to keep the code
    easier to read, we‚Äôll give the mask a name and then perform the filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use `=` to set the discount column of the filtered DataFrame to
    the empty string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Whoops ‚Äì this seems to have generated an error message that says something
    about a ‚ÄúSettingWithCopyWarning‚Äù. This is a subtlety that has to do with what
    happens when data gets updated under the hood (we‚Äôll learn about subtleties of
    mutation in [Mutable Lists](mutable-lists.html)). For now, we‚Äôll use this alternate
    form that avoids the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, the entire program looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Summarizing, the code pattern for updating values for a column in some rows
    of a DataFrame is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: make a boolean series mask for which rows to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the mask to select just the rows where the mask is true
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `.loc` with the mask and column name to select the series of cells to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `=` to give those cells their new value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Follow the above pattern to transform all delivery values of `'yes'` to `'pickup'`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 10.1.3.2¬†Repairing Values and Column Types[üîó](#(part._.Repairing_.Values_and_.Column_.Types)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The source file for the `events` table contained an error in which someone
    entered the string `''three''` in place of the number `3` for the number of tickets
    in the last row. We can repair errors like this manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Make this repair and ask your Python environment to show you the corrected table.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that the `''numtix''` column contains only numbers, we can total the number
    of tickets that were sold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What did you get? Why?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Because Python environments print strings without quotation marks, the numtix
    column appears to contain numbers. The failure of `sum` shows that this is indeed
    not the case. We can inspect the types that Python has determined for the numtix
    values using the `type` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: What happened here? During the original call to `read_csv`, Python detected
    both numeric and string data in the numtix column. It therefore read in all the
    values as strings. Our manual repair that replaced the string `'three'` with the
    number `3` fixed the value and type for one row, but the remaining values in that
    column have still been read in as integers.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Python provides an operation to change the type of data within
    a series. The following code converts the values in the `events['numtix']` series
    to integers, updating the series within the DataFrame in the process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 10.1.4¬†Computing New Columns[üîó](#(part._.Computing_.New_.Columns) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let‚Äôs extend the events table with the total cost of tickets, while also accounting
    for a discount. We‚Äôll start by building a column for the ticket price without
    any discounts. This is a straightforward application of lifting as we‚Äôve seen
    it so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Use masks, operator lifting, filtering, and series updating to give a 10% discount
    to everyone with the ‚Äúbirthday‚Äù discount code.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: We do this by creating a mask for the ‚Äúbirthday‚Äù discount, then updating just
    that part of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the notation for computing new columns and updating existing ones
    is the same (unlike in Pyret, where we had different operations `build-column`
    and `transform-column`). In Pandas, a new column is created if the given column
    name doesn‚Äôt already exist in the DataFrame; otherwise, the existing column with
    the given name gets updated.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.5¬†Aggregating and Grouping Columns[üîó](#(part._.Aggregating_and_.Grouping_.Columns)
    "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pandas has built-in operations for doing standard mathematical computations
    over series. For example, to total the number of tickets sold or to compute the
    average number of tickets per order, we can write
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: These are the same built-in operations that apply to Python lists.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine now that we wanted a finer-grained look at total ticket sales. Rather
    than just the total sold overall, we‚Äôd like the total sold per discount category.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How might you compute this?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: We could imagine constructing a list of the discount codes, filtering the ticket
    sales table to each code, then using `sum` on each filtered table. This feels
    like a lot of work, however. Producing summaries of one column (e.g., [PRE23])
    around the values in another (e.g., [PRE24]) is a common technique in data analysis.
    Spreadsheets typically provide a feature called a ‚Äúpivot table‚Äù that supports
    such a view of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Pandas, we can do a computation like this using an operation called `groupby`.
    Here‚Äôs are two examples. The first reports how many sales (rows) were made with
    each discount code, while the second summarize the total number of tickets sold
    by discount code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`groupby` takes the name of the column whose values will be used to cluster
    rows. It returns a special type of data (called `GroupBy`). From there, we can
    select a column and perform an operation on it. The column selection and operation
    are performed on each collection of rows in the `GroupBy`. The results of the
    second expression in the above code are reported in a new DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b9ecb1c08c84c777f66a57137d73fb3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this DataFrame, discount labels a column. The first row has the empty string
    in the discount column, with 14 tickets purchased without discount codes. There
    were 2 tickets purchased with a birthday discount and 8 with a student discount.
  prefs: []
  type: TYPE_NORMAL
- en: The Pandas documentation provides a large collection of operations that can
    used on `GroupBy` data; these cover computations such as counting, mean, finding
    largest and smallest values, and performing various other statistical operations.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.6¬†Wide Versus Tall Data[üîó](#(part._.Wide_.Versus_.Tall_.Data) "Link to
    here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let‚Äôs try grouping data on a different dataset. Here‚Äôs a table showing sales
    data across several regions during each month of the year:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec0e7f8f6b70454dec5da967061e0316.png)'
  prefs: []
  type: TYPE_IMG
- en: Copy the following code to load this table for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here are several questions that we might want to ask from this dataset. For
    each one, develop a plan that indicates which Pandas operations you would use
    to answer it. If a question seems hard to answer with the operations you have,
    explain what‚Äôs difficult about answering that question.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: In which month did the northwest region have the lowest sales?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: What were the total sales per month across all regions?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which region had the highest sales in April?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which region had the highest sales for the entire year?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: For question 1, we can sort the table by northwest sales in decreasing order,
    then see which month is listed in the first row.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What value would we have gotten had we used `loc` instead of `iloc` in the above
    code?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did sorting the `sales` table change the row order permanently? Check by having
    Python show you the value of `sales` after you run `sort_values`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For question 2, we could build a new column that stores the sales data across
    each row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did computing the `total` column change the row order permanently? Check by
    having Python show you the value of `sales` after you run the code.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: (If you want to remove the new `total` column, you can do this with `sales =
    sales.drop(columns='total')`.)
  prefs: []
  type: TYPE_NORMAL
- en: Question 3 is more challenging because we want to sort on the regions, which
    are in columns rather than rows. Question 4 is even more challenging because we
    want to produce sums of columns, then compare regions. Both of these feel a bit
    like problems we might know how to solve if the rows corresponded to regions rather
    than months, but that isn‚Äôt how our data are organized. And even if we did flip
    the table around (we could, the technical term for this is `transpose`), problem
    4 would still feel a bit complicated by the time we computed annual sales per
    region and sorted them.
  prefs: []
  type: TYPE_NORMAL
- en: What if instead our table had looked like the following? Would questions 3 and
    4 get any easier?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b8815a10314d9cdee7892b1e09f891d.png)'
  prefs: []
  type: TYPE_IMG
- en: With the data organized this way, question 3 can be answered with a combination
    of row selection and `sort_values`. Question 4 becomes easy to answer with a `groupby`.
    Even the code for Question 2 gets cleaner.
  prefs: []
  type: TYPE_NORMAL
- en: The contrast between these two tables highlights that how our data are organized
    can determine how easy or hard it is to process them with the standard operations
    provided by table-processing packages such as Pandas (what we‚Äôre discussing here
    applies to other languages that support tables, such as Pyret and R).
  prefs: []
  type: TYPE_NORMAL
- en: In general, the operations in table-processing packages were designed to assume
    that there is one core observation per row (about which we might have many smaller
    details or attributes), and that we will want to aggregate and display data across
    rows, not across columns. Our original treated each month as an observation, with
    the regions being details. For questions 1 and 2, which focused on months, the
    built-in operations sufficed to process the table. But for questions 3 and 4,
    which focused on regions or combinations of regions and months, it helps to have
    each month and region data be in its own row.
  prefs: []
  type: TYPE_NORMAL
- en: Tables like the original `sales` data are called wide tables, whereas the second
    form are termed tall tables. At the extremes, wide tables have every variable
    in its own column whereas tall tables have only one column for a single value
    of interest, with a separate row for each variable that contributed to that value.
    Wide tables tend to be easier for people to read; as we have seen with our sales
    data, tall tables can be easier to process in code, depending on how our questions
    align with our variables.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Between Wide and Tall Data[üîó](#(part._.Converting_.Between_.Wide_and_.Tall_.Data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Table-processing packages generally provide built-in operators for converting
    between wide and tall data formats. The following Pandas expression converts the
    (original) wide-format `sales` table into a tall-format table, retaining the month
    of the year and the product division as a label on every datapoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This basic `melt` expression uses default column names of `variable` and `value`
    for the new columns. We can customize those names as part of the `melt` call if
    we wish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Let‚Äôs put the wide and tall tables side by side to visualize what `melt` is
    doing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a8f49b403e48f063552947c7f7f252d.png)'
  prefs: []
  type: TYPE_IMG
- en: The columns named in `id_vars` remain in the original table. For each column
    not named in `id_vars`, a row is created with the `id_vars` columns, the melted-column
    name, and the melted-column value for the `id_vars`. The above figure color codes
    how cells from the wide table are arranged in the melted tall table.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the tall table in hand, we can proceed to answer questions 3 and 4, as
    well as to redo our solution to question 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The solution to question 4 uses a new Pandas operator called `reset_index`,
    which is needed if you want to manipulate the output of a `group-by` as a regular
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.7¬†Plotting Data[üîó](#(part._.Plotting_.Data) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let‚Äôs continue with the sales data as we explore plotting in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs say we now want to take a seasonal view, rather than a monthly view, and
    look at sales within seasons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs say we wanted to see how summer sales varied over the years. This is
    a good situation in which to use a line plot. To create this, we first need to
    load `matplotlib`, the Python graphic library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Next, to generate the line plots, we call the `plt.plot` function on the series
    of numbers that we want to form the points on the plot. We can also specify the
    values on the axes, as shown the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Pandas will put both line plots in the same display window. In general, each
    time you call `plt.figure()`, you create a new window in which subsequent plot
    commands will appear (at least until you ask for a plot that does not nicely overlay
    with the previous plot type).
  prefs: []
  type: TYPE_NORMAL
- en: The `matplotlib` package offers many kinds of charts and customizations to graph
    layouts. A more comprehensive look is beyond the scope of this book; see the [matplotlib
    website](https://matplotlib.org/stable/index.html) for tutorials and many examples
    of more sophisticated plots.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.8¬†Takeaways[üîó](#(part._.Takeaways) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This chapter has been designed to give you an overview of Pandas while pointing
    out key concepts in programming for data science. It is by no means a comprehensive
    Pandas tutorial or reference guide: for those, see the [Pandas website](https://pandas.pydata.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, we hope you will take away three high-level ideas from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two notions for how to access specific cells in tables and DataFrames:
    by numeric position (e.g., first row, second column) or by labeled index (e.g.,
    numtix). Both have their roles in professional-grade data analysis programming.
    Filter-like operations that extract rows from tables maintain labeled indices,
    but renumber the positional ones (so that every DataFrame has a sequence of consecutively-numbered
    rows).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Professional-grade programming languages sometimes ‚Äúlift‚Äù operations from single
    values to collections of values (e.g., using `+` to add elements within similarly-sized
    series). Lifting can be a powerful and timesaving tool for programmers, but they
    can also lead to type confusions for both novices and experienced programmers.
    You should be aware that this feature exists as you learn new languages and packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different table organizations (for the same data) are better in different situations.
    Wide and tall tables are two general shapes, each with their own affordances.
    You should be aware that table-processing packages provide a variety of tools
    to help you automatically reformat tables. If the computation you are trying to
    do feels too complicated, stop and consider whether the problem would be easier
    with a different organization of the same data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10.1.1¬†Pandas Table Basics[üîó](#(part._.Pandas_.Table_.Basics) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '10.1.1.1¬†Core Datatypes: DataFrame and Series[üîó](#(part._.Core_.Datatypes__.Data.Frame_and_.Series)
    "Link to here")'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pandas uses the term DataFrame for a table with rows and columns. DataFrames
    are built out of two more basic types:'
  prefs: []
  type: TYPE_NORMAL
- en: An array is a sequence of values that can be accessed by position (e.g., 0,
    1, ... up to one less than the length of the array). Like lists, arrays capture
    a linear (ordered) collection of values. Unlike lists, arrays are created with
    a limit on the number of elements that they contain. In practice, lists are more
    commonly used when elements are frequently added or removed whereas arrays are
    more commonly used when elements frequently get accessed by their position. Nearly
    every programming language offers both lists and arrays; a detailed contrast is
    beyond the scope of this book (this information would be covered in a data structures
    class).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Series is an array in which the positions optionally have labels in addition
    to the position numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Pandas, a row is a Series in which an array of the cell values is labeled
    with the column headers (this is similar to the ‚ÄòRow‚Äò datatype in Pyret). A DataFrame
    is a series of these rows.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.2¬†Creating and Loading DataFrames[üîó](#(part._.Creating_and_.Loading_.Data.Frames)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'DataFrames can be created manually or loaded in from a file, as we did in Pyret.
    Here‚Äôs a simple example of creating one by hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '`data` is a dictionary that maps column names to values. Calling `pd.DataFrame`
    creates a DataFrame from the dictionary. (There are other ways to create DataFrames
    manually which you can find by searching online.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load a DataFrame from a CSV file, you need either the path to the file on
    your computer or the url where you can get the CSV file online. Here‚Äôs an example
    of the url version. In this example, we have the following CSV contents and we
    want to change the header names when loading the file:'
  prefs: []
  type: TYPE_NORMAL
- en: The following `read_csv` command says that the CSV file is at `url`, that there
    are headers in the first row (numbered `0`), and that we want to use the values
    in `names` as the column labels (this will ignore whatever might be in the header
    row in the CSV file).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted to use the headers in the CSV file as the column headers, we would
    leave out the `names=[...]` part. If the CSV had no header row, we would write
    `header=None` instead of `header=0`. (There are many more configuration options
    in the [Pandas documentation](https://Pandas.pydata.org/docs/reference/api/Pandas.read_csv.html),
    but you won‚Äôt need them for the examples in this book.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, the loaded DataFrame is as follows, with the labels shown in
    blue and the indicies (positions) show in yellow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d63a7003f02c1f4bfd00ac93817af463.png)'
  prefs: []
  type: TYPE_IMG
- en: Since we did not specify labels for the rows, Pandas has used numeric labels
    by default. At the moment, the positions and the labels are the same for each
    row, but we will see that this is not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: (If you look at the actual loaded table, some of the blank cells in the discount
    column will contain `NaN`, which is the standard Python value for ‚Äúmissing information‚Äù.
    We will deal with that information shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.3¬†Using Labels and Indices to Access Cells[üîó](#(part._.Using_.Labels_and_.Indices_to_.Access_.Cells)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Rows, columns, and cells can be accessed using either their (numeric) positions
    or their labels. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we used different notation for accessing a cell depending on whether
    we accessed the row first or the column first. This is because we are showing
    you how to access data through either position indices or labels. Using `.loc`
    tells Pandas that you are using a label to access a row. If you want to use the
    position instead, you need to use `iloc` (the `i` stands for ‚Äúinteger‚Äù). If you
    are using a programmer-supplied label instead, you can just use the label directly.
  prefs: []
  type: TYPE_NORMAL
- en: In a DataFrame, both rows and columns always have position indices and may have
    labels. The `.loc` notation works on either rows or columns, we just happened
    to illustrate the notation on the rows since we had already created labels on
    the columns when we loaded `events`.
  prefs: []
  type: TYPE_NORMAL
- en: '10.1.1.1¬†Core Datatypes: DataFrame and Series[üîó](#(part._.Core_.Datatypes__.Data.Frame_and_.Series)
    "Link to here")'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pandas uses the term DataFrame for a table with rows and columns. DataFrames
    are built out of two more basic types:'
  prefs: []
  type: TYPE_NORMAL
- en: An array is a sequence of values that can be accessed by position (e.g., 0,
    1, ... up to one less than the length of the array). Like lists, arrays capture
    a linear (ordered) collection of values. Unlike lists, arrays are created with
    a limit on the number of elements that they contain. In practice, lists are more
    commonly used when elements are frequently added or removed whereas arrays are
    more commonly used when elements frequently get accessed by their position. Nearly
    every programming language offers both lists and arrays; a detailed contrast is
    beyond the scope of this book (this information would be covered in a data structures
    class).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Series is an array in which the positions optionally have labels in addition
    to the position numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Pandas, a row is a Series in which an array of the cell values is labeled
    with the column headers (this is similar to the ‚ÄòRow‚Äò datatype in Pyret). A DataFrame
    is a series of these rows.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.2¬†Creating and Loading DataFrames[üîó](#(part._.Creating_and_.Loading_.Data.Frames)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'DataFrames can be created manually or loaded in from a file, as we did in Pyret.
    Here‚Äôs a simple example of creating one by hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '`data` is a dictionary that maps column names to values. Calling `pd.DataFrame`
    creates a DataFrame from the dictionary. (There are other ways to create DataFrames
    manually which you can find by searching online.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load a DataFrame from a CSV file, you need either the path to the file on
    your computer or the url where you can get the CSV file online. Here‚Äôs an example
    of the url version. In this example, we have the following CSV contents and we
    want to change the header names when loading the file:'
  prefs: []
  type: TYPE_NORMAL
- en: The following `read_csv` command says that the CSV file is at `url`, that there
    are headers in the first row (numbered `0`), and that we want to use the values
    in `names` as the column labels (this will ignore whatever might be in the header
    row in the CSV file).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted to use the headers in the CSV file as the column headers, we would
    leave out the `names=[...]` part. If the CSV had no header row, we would write
    `header=None` instead of `header=0`. (There are many more configuration options
    in the [Pandas documentation](https://Pandas.pydata.org/docs/reference/api/Pandas.read_csv.html),
    but you won‚Äôt need them for the examples in this book.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, the loaded DataFrame is as follows, with the labels shown in
    blue and the indicies (positions) show in yellow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d63a7003f02c1f4bfd00ac93817af463.png)'
  prefs: []
  type: TYPE_IMG
- en: Since we did not specify labels for the rows, Pandas has used numeric labels
    by default. At the moment, the positions and the labels are the same for each
    row, but we will see that this is not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: (If you look at the actual loaded table, some of the blank cells in the discount
    column will contain `NaN`, which is the standard Python value for ‚Äúmissing information‚Äù.
    We will deal with that information shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.1.3¬†Using Labels and Indices to Access Cells[üîó](#(part._.Using_.Labels_and_.Indices_to_.Access_.Cells)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Rows, columns, and cells can be accessed using either their (numeric) positions
    or their labels. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we used different notation for accessing a cell depending on whether
    we accessed the row first or the column first. This is because we are showing
    you how to access data through either position indices or labels. Using `.loc`
    tells Pandas that you are using a label to access a row. If you want to use the
    position instead, you need to use `iloc` (the `i` stands for ‚Äúinteger‚Äù). If you
    are using a programmer-supplied label instead, you can just use the label directly.
  prefs: []
  type: TYPE_NORMAL
- en: In a DataFrame, both rows and columns always have position indices and may have
    labels. The `.loc` notation works on either rows or columns, we just happened
    to illustrate the notation on the rows since we had already created labels on
    the columns when we loaded `events`.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.2¬†Filtering Rows[üîó](#(part._.Filtering_.Rows) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Back in Pyret, we filtered rows from a table by writing a function from `Row`
    to `Boolean`. The `filter-with` function applied that function to every row in
    the table, returning a new table with those rows for which the predicate were
    true.
  prefs: []
  type: TYPE_NORMAL
- en: In Pandas, we select rows by providing an array of Booleans that has the same
    length as the number of rows in the DataFrame. Filtering keeps those rows for
    which the corresponding array entry is `True`. For example, here‚Äôs our DataFrame
    diagram from before, this time with an array to the right indicating that we want
    to keep rows 0, 2, and 6.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0958f43b8192439a6fd898de3fbe50fb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The ‚Äúkeep‚Äù array is not part of the DataFrame. Here is the corresponding array
    expressed in code, followed by the notation to use the array to filter the DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the array of booleans, we use it to extract a collection of rows
    using similar notation that we previously used to extract a column. Just as we
    wrote `events[''numtix'']` to select the `''numtix''` column, we can write `events[keep]`
    to select a collection of rows. The DataFrame that results from filtering (along
    with the `True` cells of the `keep` array for illustration) appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0baa50e0adf5a889a71a977667d9c7e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'How does Pandas know whether we want to select rows or columns? It depends
    on what we provide in the square brackets: if we provide a single label, we get
    the column or row with that label; if we provide an array of booleans, we get
    the rows for which the corresponding row (by position) is `True`.'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Look at the returned DataFrame. Do you notice anything interesting?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the row labels and indices: the labels have been retained from the
    original DataFrame (0, 2, and 6), while the indices are a sequence of consecutive
    numbers starting from 0\. Having both ways to reference rows‚Äî<wbr>one based on
    raw order and the other based on programmer-provided labels‚Äî<wbr>provides a lot
    of flexibility as we use filter to isolate parts of tables that we want to work
    on.'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Does filtering rows this way in Python keep the original `events` DataFrame
    intact? Try it out!
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Arrays of booleans that are used for filtering out other arrays are called masks.
    Here, we have shown a simple mask that we constructed by hand. If we had a long
    DataFrame, however, we would not want to construct a mask for it by hand. Fortunately,
    we don‚Äôt have to. Python provides notations that let us construct masks via expressions
    over a series.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that we wanted to filter the `events` table down to those rows with
    delivery method `''email''`. To create a mask for this, we first select the delivery
    column as a series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we use the series in a boolean expression that states the constraint
    that we want on each element of the series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Wait, what‚Äôs going on here? `events['deliver']` is a Series (a labeled array
    of strings). `'email'` is a string. What does it even mean to ask whether two
    values of different types be considered equal, especially when one has many component
    values and the other does not?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the `==` doesn‚Äôt mean ‚Äúare these equal‚Äù? Instead, Python applies
    `== 'email'` to every element of the `events['delivery']` Series, constructing
    a new Series of the results. This idea of applying an operation to all elements
    of an array is known as ‚Äúlifting‚Äù. It is one of the shortcuts that Python provides
    to help experienced programmers do simple common tasks quickly and easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a Series of booleans (for which events will be picked up by
    email), we can use it to select those rows from the `events` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The inner use of `events` is for creating the mask, while the outer one is for
    filtering the table with that mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a warning: if you search online for information on how to filter or process
    DataFrame, you might find code samples that do this using for loops. While that
    approach works, it isn‚Äôt considered good Pandas (or general programming) practice.
    Most modern languages provide built-in constructs for iterating over lists and
    other sequence-style data. These operations have more descriptive names than generic
    loops (which makes them easier for other programmers to read), and are often engineered
    to run more efficiently under the hood. As a general rule, only default to basic
    loops if there is no built-in operator to do the computation that you have in
    mind.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.3¬†Cleaning and Normalizing Data[üîó](#(part._.Cleaning_and_.Normalizing_.Data)
    "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The same operator-lifting idea that we just saw when creating masks from DataFrames
    also comes into play for normalizing data. Recall that when we worked with the
    `events` table in Pyret, we converted all of the discount codes to lowercase.
    Here‚Äôs the code that does this in Pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Look at the above code. Break it down and try to articulate what each part does.
    Do any parts seem new or different from things we‚Äôve done so far in Pandas?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the right side of the `=`, we are extracting the Series of discount codes
    (`events['discount']`), then using the lowercase operation on strings `str.lower()`
    to convert each one, building up a Series of the results. Normally, given a string
    (such as `'BIRTHDAY'`), we could get a lowercase version of it by writing just
    `'BIRTHDAY'.lower()`. What‚Äôs the extra `str` doing in there?
  prefs: []
  type: TYPE_NORMAL
- en: This is a nuance about lifting. Python can evaluate `'BIRTHDAY'.lower()` because
    `lower()` is defined directly on strings. `lower()` is not, however, directly
    defined on Series. To bridge the gap between having Series data and wanting to
    use a string operation on it, we insert `str` before `lower()`. Effectively, this
    tells Python where to find the `lower()` operation (in the collection of operations
    defined on strings).
  prefs: []
  type: TYPE_NORMAL
- en: 'The left side of the above code looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells Pandas to replace the current contents of the `''discount''` series
    with the series on the right side of the `=`. It is similar to `transform-column`
    from Pyret, but with a fundamental difference: in Pyret, `transform-column` left
    the old table intact and produced a new table with the new column values. Instead,
    in Pandas the old column gets replaced, thus destroying the original table. There
    are many nuances to having operations destroy and replace data; the chapter on
    [Mutating Structures](mutating-structures.html) studies them in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.3.1¬†Clearing out unknown values[üîó](#(part._.Clearing_out_unknown_values)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now let‚Äôs try a different cleaning and normalization problem: we want the discount
    column to contain only known discount codes or empty strings. The `none` entry
    in line 3 of the table should be converted to an empty string, and we should make
    sure that all of the `NaN` and seemingly empty entries in the discount cells are
    also converted to empty strings (as opposed to strings of multiple spaces).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plan out how you might do this task using mask expressions. Even if you don‚Äôt
    know all the specific notation for the operations you need, you can still work
    out a plan for completing this task.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you planned out the tasks, you might have a todo list like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: create a mask of rows with known discount codes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: invert that mask (swap the false and true values)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: filter the DataFrame to rows without a known discount code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: replace all the discount column values in that DataFrame with an empty string
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have seen how to do parts of steps 1 and 3, but neither of steps 2 and 4\.
    Let‚Äôs work through the steps one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs the code for step 1, which creates a mask for the rows with known discount
    codes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use a lifted `isin` operator on lists to compute the mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'For step 2, we have to swap the true and false values. We can do this by using
    the negation operator `~` on the mask from step 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'For step 3, we want to filter `events` with this mask. Just to keep the code
    easier to read, we‚Äôll give the mask a name and then perform the filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use `=` to set the discount column of the filtered DataFrame to
    the empty string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Whoops ‚Äì this seems to have generated an error message that says something
    about a ‚ÄúSettingWithCopyWarning‚Äù. This is a subtlety that has to do with what
    happens when data gets updated under the hood (we‚Äôll learn about subtleties of
    mutation in [Mutable Lists](mutable-lists.html)). For now, we‚Äôll use this alternate
    form that avoids the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, the entire program looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Summarizing, the code pattern for updating values for a column in some rows
    of a DataFrame is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: make a boolean series mask for which rows to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the mask to select just the rows where the mask is true
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `.loc` with the mask and column name to select the series of cells to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `=` to give those cells their new value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Follow the above pattern to transform all delivery values of `'yes'` to `'pickup'`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 10.1.3.2¬†Repairing Values and Column Types[üîó](#(part._.Repairing_.Values_and_.Column_.Types)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The source file for the `events` table contained an error in which someone
    entered the string `''three''` in place of the number `3` for the number of tickets
    in the last row. We can repair errors like this manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Make this repair and ask your Python environment to show you the corrected table.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that the `''numtix''` column contains only numbers, we can total the number
    of tickets that were sold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What did you get? Why?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Because Python environments print strings without quotation marks, the numtix
    column appears to contain numbers. The failure of `sum` shows that this is indeed
    not the case. We can inspect the types that Python has determined for the numtix
    values using the `type` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: What happened here? During the original call to `read_csv`, Python detected
    both numeric and string data in the numtix column. It therefore read in all the
    values as strings. Our manual repair that replaced the string `'three'` with the
    number `3` fixed the value and type for one row, but the remaining values in that
    column have still been read in as integers.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Python provides an operation to change the type of data within
    a series. The following code converts the values in the `events['numtix']` series
    to integers, updating the series within the DataFrame in the process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 10.1.3.1¬†Clearing out unknown values[üîó](#(part._.Clearing_out_unknown_values)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now let‚Äôs try a different cleaning and normalization problem: we want the discount
    column to contain only known discount codes or empty strings. The `none` entry
    in line 3 of the table should be converted to an empty string, and we should make
    sure that all of the `NaN` and seemingly empty entries in the discount cells are
    also converted to empty strings (as opposed to strings of multiple spaces).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plan out how you might do this task using mask expressions. Even if you don‚Äôt
    know all the specific notation for the operations you need, you can still work
    out a plan for completing this task.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you planned out the tasks, you might have a todo list like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: create a mask of rows with known discount codes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: invert that mask (swap the false and true values)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: filter the DataFrame to rows without a known discount code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: replace all the discount column values in that DataFrame with an empty string
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have seen how to do parts of steps 1 and 3, but neither of steps 2 and 4\.
    Let‚Äôs work through the steps one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs the code for step 1, which creates a mask for the rows with known discount
    codes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use a lifted `isin` operator on lists to compute the mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'For step 2, we have to swap the true and false values. We can do this by using
    the negation operator `~` on the mask from step 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'For step 3, we want to filter `events` with this mask. Just to keep the code
    easier to read, we‚Äôll give the mask a name and then perform the filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use `=` to set the discount column of the filtered DataFrame to
    the empty string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Whoops ‚Äì this seems to have generated an error message that says something
    about a ‚ÄúSettingWithCopyWarning‚Äù. This is a subtlety that has to do with what
    happens when data gets updated under the hood (we‚Äôll learn about subtleties of
    mutation in [Mutable Lists](mutable-lists.html)). For now, we‚Äôll use this alternate
    form that avoids the error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Putting it all together, the entire program looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Summarizing, the code pattern for updating values for a column in some rows
    of a DataFrame is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: make a boolean series mask for which rows to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the mask to select just the rows where the mask is true
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `.loc` with the mask and column name to select the series of cells to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use `=` to give those cells their new value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Follow the above pattern to transform all delivery values of `'yes'` to `'pickup'`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 10.1.3.2¬†Repairing Values and Column Types[üîó](#(part._.Repairing_.Values_and_.Column_.Types)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The source file for the `events` table contained an error in which someone
    entered the string `''three''` in place of the number `3` for the number of tickets
    in the last row. We can repair errors like this manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Make this repair and ask your Python environment to show you the corrected table.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that the `''numtix''` column contains only numbers, we can total the number
    of tickets that were sold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What did you get? Why?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Because Python environments print strings without quotation marks, the numtix
    column appears to contain numbers. The failure of `sum` shows that this is indeed
    not the case. We can inspect the types that Python has determined for the numtix
    values using the `type` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: What happened here? During the original call to `read_csv`, Python detected
    both numeric and string data in the numtix column. It therefore read in all the
    values as strings. Our manual repair that replaced the string `'three'` with the
    number `3` fixed the value and type for one row, but the remaining values in that
    column have still been read in as integers.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Python provides an operation to change the type of data within
    a series. The following code converts the values in the `events['numtix']` series
    to integers, updating the series within the DataFrame in the process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 10.1.4¬†Computing New Columns[üîó](#(part._.Computing_.New_.Columns) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let‚Äôs extend the events table with the total cost of tickets, while also accounting
    for a discount. We‚Äôll start by building a column for the ticket price without
    any discounts. This is a straightforward application of lifting as we‚Äôve seen
    it so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Use masks, operator lifting, filtering, and series updating to give a 10% discount
    to everyone with the ‚Äúbirthday‚Äù discount code.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: We do this by creating a mask for the ‚Äúbirthday‚Äù discount, then updating just
    that part of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the notation for computing new columns and updating existing ones
    is the same (unlike in Pyret, where we had different operations `build-column`
    and `transform-column`). In Pandas, a new column is created if the given column
    name doesn‚Äôt already exist in the DataFrame; otherwise, the existing column with
    the given name gets updated.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.5¬†Aggregating and Grouping Columns[üîó](#(part._.Aggregating_and_.Grouping_.Columns)
    "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pandas has built-in operations for doing standard mathematical computations
    over series. For example, to total the number of tickets sold or to compute the
    average number of tickets per order, we can write
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: These are the same built-in operations that apply to Python lists.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine now that we wanted a finer-grained look at total ticket sales. Rather
    than just the total sold overall, we‚Äôd like the total sold per discount category.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How might you compute this?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: We could imagine constructing a list of the discount codes, filtering the ticket
    sales table to each code, then using `sum` on each filtered table. This feels
    like a lot of work, however. Producing summaries of one column (e.g., [PRE69])
    around the values in another (e.g., [PRE70]) is a common technique in data analysis.
    Spreadsheets typically provide a feature called a ‚Äúpivot table‚Äù that supports
    such a view of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Pandas, we can do a computation like this using an operation called `groupby`.
    Here‚Äôs are two examples. The first reports how many sales (rows) were made with
    each discount code, while the second summarize the total number of tickets sold
    by discount code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '`groupby` takes the name of the column whose values will be used to cluster
    rows. It returns a special type of data (called `GroupBy`). From there, we can
    select a column and perform an operation on it. The column selection and operation
    are performed on each collection of rows in the `GroupBy`. The results of the
    second expression in the above code are reported in a new DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b9ecb1c08c84c777f66a57137d73fb3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this DataFrame, discount labels a column. The first row has the empty string
    in the discount column, with 14 tickets purchased without discount codes. There
    were 2 tickets purchased with a birthday discount and 8 with a student discount.
  prefs: []
  type: TYPE_NORMAL
- en: The Pandas documentation provides a large collection of operations that can
    used on `GroupBy` data; these cover computations such as counting, mean, finding
    largest and smallest values, and performing various other statistical operations.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.6¬†Wide Versus Tall Data[üîó](#(part._.Wide_.Versus_.Tall_.Data) "Link to
    here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let‚Äôs try grouping data on a different dataset. Here‚Äôs a table showing sales
    data across several regions during each month of the year:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec0e7f8f6b70454dec5da967061e0316.png)'
  prefs: []
  type: TYPE_IMG
- en: Copy the following code to load this table for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here are several questions that we might want to ask from this dataset. For
    each one, develop a plan that indicates which Pandas operations you would use
    to answer it. If a question seems hard to answer with the operations you have,
    explain what‚Äôs difficult about answering that question.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: In which month did the northwest region have the lowest sales?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: What were the total sales per month across all regions?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which region had the highest sales in April?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which region had the highest sales for the entire year?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: For question 1, we can sort the table by northwest sales in decreasing order,
    then see which month is listed in the first row.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What value would we have gotten had we used `loc` instead of `iloc` in the above
    code?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did sorting the `sales` table change the row order permanently? Check by having
    Python show you the value of `sales` after you run `sort_values`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For question 2, we could build a new column that stores the sales data across
    each row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did computing the `total` column change the row order permanently? Check by
    having Python show you the value of `sales` after you run the code.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: (If you want to remove the new `total` column, you can do this with `sales =
    sales.drop(columns='total')`.)
  prefs: []
  type: TYPE_NORMAL
- en: Question 3 is more challenging because we want to sort on the regions, which
    are in columns rather than rows. Question 4 is even more challenging because we
    want to produce sums of columns, then compare regions. Both of these feel a bit
    like problems we might know how to solve if the rows corresponded to regions rather
    than months, but that isn‚Äôt how our data are organized. And even if we did flip
    the table around (we could, the technical term for this is `transpose`), problem
    4 would still feel a bit complicated by the time we computed annual sales per
    region and sorted them.
  prefs: []
  type: TYPE_NORMAL
- en: What if instead our table had looked like the following? Would questions 3 and
    4 get any easier?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b8815a10314d9cdee7892b1e09f891d.png)'
  prefs: []
  type: TYPE_IMG
- en: With the data organized this way, question 3 can be answered with a combination
    of row selection and `sort_values`. Question 4 becomes easy to answer with a `groupby`.
    Even the code for Question 2 gets cleaner.
  prefs: []
  type: TYPE_NORMAL
- en: The contrast between these two tables highlights that how our data are organized
    can determine how easy or hard it is to process them with the standard operations
    provided by table-processing packages such as Pandas (what we‚Äôre discussing here
    applies to other languages that support tables, such as Pyret and R).
  prefs: []
  type: TYPE_NORMAL
- en: In general, the operations in table-processing packages were designed to assume
    that there is one core observation per row (about which we might have many smaller
    details or attributes), and that we will want to aggregate and display data across
    rows, not across columns. Our original treated each month as an observation, with
    the regions being details. For questions 1 and 2, which focused on months, the
    built-in operations sufficed to process the table. But for questions 3 and 4,
    which focused on regions or combinations of regions and months, it helps to have
    each month and region data be in its own row.
  prefs: []
  type: TYPE_NORMAL
- en: Tables like the original `sales` data are called wide tables, whereas the second
    form are termed tall tables. At the extremes, wide tables have every variable
    in its own column whereas tall tables have only one column for a single value
    of interest, with a separate row for each variable that contributed to that value.
    Wide tables tend to be easier for people to read; as we have seen with our sales
    data, tall tables can be easier to process in code, depending on how our questions
    align with our variables.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Between Wide and Tall Data[üîó](#(part._.Converting_.Between_.Wide_and_.Tall_.Data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Table-processing packages generally provide built-in operators for converting
    between wide and tall data formats. The following Pandas expression converts the
    (original) wide-format `sales` table into a tall-format table, retaining the month
    of the year and the product division as a label on every datapoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'This basic `melt` expression uses default column names of `variable` and `value`
    for the new columns. We can customize those names as part of the `melt` call if
    we wish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Let‚Äôs put the wide and tall tables side by side to visualize what `melt` is
    doing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a8f49b403e48f063552947c7f7f252d.png)'
  prefs: []
  type: TYPE_IMG
- en: The columns named in `id_vars` remain in the original table. For each column
    not named in `id_vars`, a row is created with the `id_vars` columns, the melted-column
    name, and the melted-column value for the `id_vars`. The above figure color codes
    how cells from the wide table are arranged in the melted tall table.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the tall table in hand, we can proceed to answer questions 3 and 4, as
    well as to redo our solution to question 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The solution to question 4 uses a new Pandas operator called `reset_index`,
    which is needed if you want to manipulate the output of a `group-by` as a regular
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Between Wide and Tall Data[üîó](#(part._.Converting_.Between_.Wide_and_.Tall_.Data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Table-processing packages generally provide built-in operators for converting
    between wide and tall data formats. The following Pandas expression converts the
    (original) wide-format `sales` table into a tall-format table, retaining the month
    of the year and the product division as a label on every datapoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'This basic `melt` expression uses default column names of `variable` and `value`
    for the new columns. We can customize those names as part of the `melt` call if
    we wish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Let‚Äôs put the wide and tall tables side by side to visualize what `melt` is
    doing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a8f49b403e48f063552947c7f7f252d.png)'
  prefs: []
  type: TYPE_IMG
- en: The columns named in `id_vars` remain in the original table. For each column
    not named in `id_vars`, a row is created with the `id_vars` columns, the melted-column
    name, and the melted-column value for the `id_vars`. The above figure color codes
    how cells from the wide table are arranged in the melted tall table.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the tall table in hand, we can proceed to answer questions 3 and 4, as
    well as to redo our solution to question 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: The solution to question 4 uses a new Pandas operator called `reset_index`,
    which is needed if you want to manipulate the output of a `group-by` as a regular
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.7¬†Plotting Data[üîó](#(part._.Plotting_.Data) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let‚Äôs continue with the sales data as we explore plotting in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs say we now want to take a seasonal view, rather than a monthly view, and
    look at sales within seasons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs say we wanted to see how summer sales varied over the years. This is
    a good situation in which to use a line plot. To create this, we first need to
    load `matplotlib`, the Python graphic library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Next, to generate the line plots, we call the `plt.plot` function on the series
    of numbers that we want to form the points on the plot. We can also specify the
    values on the axes, as shown the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Pandas will put both line plots in the same display window. In general, each
    time you call `plt.figure()`, you create a new window in which subsequent plot
    commands will appear (at least until you ask for a plot that does not nicely overlay
    with the previous plot type).
  prefs: []
  type: TYPE_NORMAL
- en: The `matplotlib` package offers many kinds of charts and customizations to graph
    layouts. A more comprehensive look is beyond the scope of this book; see the [matplotlib
    website](https://matplotlib.org/stable/index.html) for tutorials and many examples
    of more sophisticated plots.
  prefs: []
  type: TYPE_NORMAL
- en: 10.1.8¬†Takeaways[üîó](#(part._.Takeaways) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This chapter has been designed to give you an overview of Pandas while pointing
    out key concepts in programming for data science. It is by no means a comprehensive
    Pandas tutorial or reference guide: for those, see the [Pandas website](https://pandas.pydata.org/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conceptually, we hope you will take away three high-level ideas from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two notions for how to access specific cells in tables and DataFrames:
    by numeric position (e.g., first row, second column) or by labeled index (e.g.,
    numtix). Both have their roles in professional-grade data analysis programming.
    Filter-like operations that extract rows from tables maintain labeled indices,
    but renumber the positional ones (so that every DataFrame has a sequence of consecutively-numbered
    rows).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Professional-grade programming languages sometimes ‚Äúlift‚Äù operations from single
    values to collections of values (e.g., using `+` to add elements within similarly-sized
    series). Lifting can be a powerful and timesaving tool for programmers, but they
    can also lead to type confusions for both novices and experienced programmers.
    You should be aware that this feature exists as you learn new languages and packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different table organizations (for the same data) are better in different situations.
    Wide and tall tables are two general shapes, each with their own affordances.
    You should be aware that table-processing packages provide a variety of tools
    to help you automatically reformat tables. If the computation you are trying to
    do feels too complicated, stop and consider whether the problem would be easier
    with a different organization of the same data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
