["```py\nlibrary(astrologer)\nlibrary(beepr)\nlibrary(fs)\nlibrary(gutenbergr)\nlibrary(quanteda)\nlibrary(stm)\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(tinytable)\n```", "```py\nlast_samurai <-\"My father's father was a Methodist minister.\"\n\nbeloved <- \"124 was spiteful. Full of Baby's venom.\"\n\njane_eyre <- \"There was no possibility of taking a walk that day.\"\n\nbookshelf <-\n tibble(\n book = c(\"Last Samurai\", \"Beloved\", \"Jane Eyre\"),\n first_sentence = c(last_samurai, beloved, jane_eyre)\n )\n\nbookshelf\n```", "```py\n# A tibble: 3 × 2\n  book         first_sentence                                     \n  <chr>        <chr>                                              \n1 Last Samurai My father's father was a Methodist minister.       \n2 Beloved      124 was spiteful. Full of Baby's venom.            \n3 Jane Eyre    There was no possibility of taking a walk that day.\n```", "```py\nbooks_corpus <-\n corpus(bookshelf, \n docid_field = \"book\", \n text_field = \"first_sentence\")\n\nbooks_corpus\n```", "```py\nCorpus consisting of 3 documents.\nLast Samurai :\n\"My father's father was a Methodist minister.\"\n\nBeloved :\n\"124 was spiteful. Full of Baby's venom.\"\n\nJane Eyre :\n\"There was no possibility of taking a walk that day.\"\n```", "```py\nbooks_dfm <-\n books_corpus |>\n tokens() |>\n dfm()\n\nbooks_dfm\n```", "```py\nDocument-feature matrix of: 3 documents, 21 features (57.14% sparse) and 0 docvars.\n              features\ndocs           my father's father was a methodist minister . 124 spiteful\n  Last Samurai  1        1      1   1 1         1        1 1   0        0\n  Beloved       0        0      0   1 0         0        0 2   1        1\n  Jane Eyre     0        0      0   1 1         0        0 1   0        0\n[ reached max_nfeat ... 11 more features ]\n```", "```py\nstopwords(source = \"snowball\")[1:10]\n```", "```py\n [1] \"i\"         \"me\"        \"my\"        \"myself\"    \"we\"        \"our\"      \n [7] \"ours\"      \"ourselves\" \"you\"       \"your\" \n```", "```py\nstop_word_list <-\n paste(stopwords(source = \"snowball\"), collapse = \" | \")\n\nbookshelf |>\n mutate(no_stops = str_replace_all(\n string = first_sentence,\n pattern = stop_word_list,\n replacement = \" \")\n ) |>\n select(no_stops, first_sentence)\n```", "```py\n# A tibble: 3 × 2\n  no_stops                                 first_sentence                       \n  <chr>                                    <chr>                                \n1 My father's father a Methodist minister. My father's father was a Methodist m…\n2 124 spiteful. Full Baby's venom.         124 was spiteful. Full of Baby's ven…\n3 There no possibility taking walk day.    There was no possibility of taking a…\n```", "```py\nstop_word_list_updated <-\n paste(\n \"Methodist |\",\n \"spiteful |\",\n \"possibility |\",\n stop_word_list,\n collapse = \" | \"\n )\n\nbookshelf |>\n mutate(no_stops = str_replace_all(\n string = first_sentence,\n pattern = stop_word_list_updated,\n replacement = \" \")\n ) |>\n select(no_stops)\n```", "```py\n# A tibble: 3 × 1\n  no_stops                        \n  <chr>                           \n1 My father's father a  minister. \n2 124 spiteful. Full Baby's venom.\n3 There no of taking walk day. \n```", "```py\nbooks_dfm |>\n dfm_remove(stopwords(source = \"snowball\"))\n```", "```py\nDocument-feature matrix of: 3 documents, 14 features (61.90% sparse) and 0 docvars.\n              features\ndocs           father's father methodist minister . 124 spiteful full baby's\n  Last Samurai        1      1         1        1 1   0        0    0      0\n  Beloved             0      0         0        0 2   1        1    1      1\n  Jane Eyre           0      0         0        0 1   0        0    0      0\n              features\ndocs           venom\n  Last Samurai     0\n  Beloved          1\n  Jane Eyre        0\n[ reached max_nfeat ... 4 more features ]\n```", "```py\nbookshelf |>\n mutate(lower_sentence = str_to_lower(string = first_sentence)) |>\n select(lower_sentence)\n```", "```py\n# A tibble: 3 × 1\n  lower_sentence                                     \n  <chr>                                              \n1 my father's father was a methodist minister.       \n2 124 was spiteful. full of baby's venom.            \n3 there was no possibility of taking a walk that day.\n```", "```py\nbookshelf |>\n mutate(no_punctuation_numbers = str_replace_all(\n string = first_sentence,\n pattern = \"[:punct:]|[:digit:]\",\n replacement = \" \"\n )) |>\n select(no_punctuation_numbers)\n```", "```py\n# A tibble: 3 × 1\n  no_punctuation_numbers                               \n  <chr>                                                \n1 \"My father s father was a Methodist minister \"       \n2 \"    was spiteful  Full of Baby s venom \"            \n3 \"There was no possibility of taking a walk that day \"\n```", "```py\nbooks_corpus |>\n tokens(remove_numbers = TRUE, remove_punct = TRUE)\n```", "```py\nTokens consisting of 3 documents.\nLast Samurai :\n[1] \"My\"        \"father's\"  \"father\"    \"was\"       \"a\"         \"Methodist\"\n[7] \"minister\" \n\nBeloved :\n[1] \"was\"      \"spiteful\" \"Full\"     \"of\"       \"Baby's\"   \"venom\"   \n\nJane Eyre :\n [1] \"There\"       \"was\"         \"no\"          \"possibility\" \"of\"         \n [6] \"taking\"      \"a\"           \"walk\"        \"that\"        \"day\" \n```", "```py\nbooks_corpus |>\n tokens(remove_numbers = TRUE, remove_punct = TRUE) |>\n dfm(tolower = TRUE) |>\n dfm_trim(min_termfreq = 2)\n```", "```py\nDocument-feature matrix of: 3 documents, 3 features (22.22% sparse) and 0 docvars.\n              features\ndocs           was a of\n  Last Samurai   1 1  0\n  Beloved        1 0  1\n  Jane Eyre      1 1  1\n```", "```py\nsome_places <- c(\"British Columbia\", \n \"New Hampshire\", \n \"United Kingdom\", \n \"Port Hedland\")\na_sentence <-\nc(\"Vancouver is in British Columbia and New Hampshire is not\")\n\ntokens(a_sentence) |>\n tokens_compound(pattern = phrase(some_places))\n```", "```py\nTokens consisting of 1 document.\ntext1 :\n[1] \"Vancouver\"        \"is\"               \"in\"               \"British_Columbia\"\n[5] \"and\"              \"New_Hampshire\"    \"is\"               \"not\" \n```", "```py\njane_eyre <- read_csv(\n \"jane_eyre.csv\",\n col_types = cols(\n gutenberg_id = col_integer(),\n text = col_character()\n )\n)\n\njane_eyre\n```", "```py\n# A tibble: 21,001 × 2\n   gutenberg_id text                           \n          <int> <chr>                          \n 1         1260 JANE EYRE                      \n 2         1260 AN AUTOBIOGRAPHY               \n 3         1260 <NA>                           \n 4         1260 by Charlotte Brontë            \n 5         1260 <NA>                           \n 6         1260 _ILLUSTRATED BY F. H. TOWNSEND_\n 7         1260 <NA>                           \n 8         1260 London                         \n 9         1260 SERVICE & PATON                \n10         1260 5 HENRIETTA STREET             \n# ℹ 20,991 more rows\n```", "```py\njane_eyre <- \n jane_eyre |> \n filter(!is.na(text))\n```", "```py\njane_eyre_text <- tibble(\n book = \"Jane Eyre\",\n text = paste(jane_eyre$text, collapse = \" \") |>\n str_replace_all(pattern = \"[:punct:]\",\n replacement = \" \") |>\n str_replace_all(pattern = stop_word_list,\n replacement = \" \")\n)\n\njane_eyre_corpus <-\n corpus(jane_eyre_text, docid_field = \"book\", text_field = \"text\")\nngrams <- tokens_ngrams(tokens(jane_eyre_corpus), n = 2)\nngram_counts <-\n tibble(ngrams = unlist(ngrams)) |>\n count(ngrams, sort = TRUE)\n\nhead(ngram_counts)\n```", "```py\n# A tibble: 6 × 2\n  ngrams           n\n  <chr>        <int>\n1 I_not          344\n2 Mr_Rochester   332\n3 I_thought      136\n4 St_John        132\n5 don_t          126\n6 I_saw          122\n```", "```py\nchar_wordstem(c(\"Canadians\", \"Canadian\", \"Canada\"))\n```", "```py\n[1] \"Canadian\" \"Canadian\" \"Canada\" \n```", "```py\nbooks_corpus |>\n tokens(remove_numbers = TRUE, remove_punct = TRUE) |>\n dfm(tolower = TRUE) |>\n dfm_wordstem()\n```", "```py\nDocument-feature matrix of: 3 documents, 18 features (59.26% sparse) and 0 docvars.\n              features\ndocs           my father was a methodist minist spite full of babi\n  Last Samurai  1      2   1 1         1      1     0    0  0    0\n  Beloved       0      0   1 0         0      0     1    1  1    1\n  Jane Eyre     0      0   1 1         0      0     0    0  1    0\n[ reached max_nfeat ... 8 more features ]\n```", "```py\nhoroscopes\n```", "```py\n# A tibble: 1,272 × 4\n   startdate  zodiacsign  horoscope                                        url  \n   <date>     <fct>       <chr>                                            <chr>\n 1 2015-01-05 Aries       Considering the fact that this past week (espec… http…\n 2 2015-01-05 Taurus      It's time Taurus. You aren't one to be rushed a… http…\n 3 2015-01-05 Gemini      Soon it will be time to review what you know, t… http…\n 4 2015-01-05 Cancer      Feeling  feelings and being full of flavorful s… http…\n 5 2015-01-05 Leo         Look, listen, watch, meditate and engage in pra… http…\n 6 2015-01-05 Virgo       Last week's astrology is still reverberating th… http…\n 7 2015-01-05 Libra       Get out your markers and your glue sticks. Get … http…\n 8 2015-01-05 Scorpio     Time to pay extra attention to the needs of you… http…\n 9 2015-01-05 Sagittarius Everything right now is about how you say it, h… http…\n10 2015-01-05 Capricorn   The full moon on January 4th/5th was a healthy … http…\n# ℹ 1,262 more rows\n```", "```py\nhoroscopes |>\n count(zodiacsign)\n```", "```py\n# A tibble: 12 × 2\n   zodiacsign      n\n   <fct>       <int>\n 1 Aries         106\n 2 Taurus        106\n 3 Gemini        106\n 4 Cancer        106\n 5 Leo           106\n 6 Virgo         106\n 7 Libra         106\n 8 Scorpio       106\n 9 Sagittarius   106\n10 Capricorn     106\n11 Aquarius      106\n12 Pisces        106\n```", "```py\nhoroscopes_by_word <-\n horoscopes |>\n select(-startdate,-url) |>\n unnest_tokens(output = word,\n input = horoscope,\n token = \"words\")\n\nhoroscopes_counts_by_word <-\n horoscopes_by_word |>\n count(zodiacsign, word, sort = TRUE)\n\nhoroscopes_counts_by_word\n```", "```py\n# A tibble: 41,850 × 3\n   zodiacsign  word      n\n   <fct>       <chr> <int>\n 1 Cancer      to     1440\n 2 Sagittarius to     1377\n 3 Aquarius    to     1357\n 4 Aries       to     1335\n 5 Pisces      to     1313\n 6 Leo         to     1302\n 7 Libra       to     1270\n 8 Sagittarius you    1264\n 9 Virgo       to     1262\n10 Scorpio     to     1260\n# ℹ 41,840 more rows\n```", "```py\nhoroscopes_counts_by_word_tf_idf <-\n horoscopes_counts_by_word |>\n bind_tf_idf(\n term = word,\n document = zodiacsign,\n n = n\n ) |>\n arrange(-tf_idf)\n\nhoroscopes_counts_by_word_tf_idf\n```", "```py\n# A tibble: 41,850 × 6\n   zodiacsign  word            n       tf   idf   tf_idf\n   <fct>       <chr>       <int>    <dbl> <dbl>    <dbl>\n 1 Capricorn   goat            6 0.000236  2.48 0.000585\n 2 Pisces      pisces         14 0.000531  1.10 0.000584\n 3 Sagittarius sagittarius    10 0.000357  1.39 0.000495\n 4 Cancer      cancer         10 0.000348  1.39 0.000483\n 5 Gemini      gemini          7 0.000263  1.79 0.000472\n 6 Taurus      bulls           5 0.000188  2.48 0.000467\n 7 Aries       warns           5 0.000186  2.48 0.000463\n 8 Cancer      organize        7 0.000244  1.79 0.000437\n 9 Cancer      overwork        5 0.000174  2.48 0.000433\n10 Taurus      let's          10 0.000376  1.10 0.000413\n# ℹ 41,840 more rows\n```", "```py\nhoroscopes_counts_by_word_tf_idf |>\n slice(1:5,\n .by = zodiacsign) |>\n select(zodiacsign, word) |>\n summarise(all = paste0(word, collapse = \"; \"),\n .by = zodiacsign) |>\n tt() |> \n style_tt(j = 1:2, align = \"lr\") |> \n setNames(c(\"Zodiac sign\", \"Most common words unique to that sign\"))\n```", "```py\nfiles_of_interest <-\n dir_ls(path = \"2018/\", glob = \"*.csv\", recurse = 2)\n\nhansard_canada_2018 <-\n read_csv(\n files_of_interest,\n col_types = cols(\n basepk = col_integer(),\n speechdate = col_date(),\n speechtext = col_character(),\n speakerparty = col_character(),\n speakerriding = col_character(),\n speakername = col_character()\n ),\n col_select = \n c(basepk, speechdate, speechtext, speakername, speakerparty, \n speakerriding)) |>\n filter(!is.na(speakername))\n\nhansard_canada_2018\n```", "```py\n# A tibble: 33,105 × 6\n    basepk speechdate speechtext          speakername speakerparty speakerriding\n     <int> <date>     <chr>               <chr>       <chr>        <chr>        \n 1 4732776 2018-01-29 \"Mr. Speaker, I wo… Julie Dabr… Liberal      Toronto—Danf…\n 2 4732777 2018-01-29 \"Mr. Speaker, I wa… Matthew Du… New Democra… Beloeil—Cham…\n 3 4732778 2018-01-29 \"Mr. Speaker, I am… Stephanie … Conservative Calgary Midn…\n 4 4732779 2018-01-29 \"Resuming debate.\\… Anthony Ro… Liberal      Nipissing—Ti…\n 5 4732780 2018-01-29 \"Mr. Speaker, we a… Alain Rayes Conservative Richmond—Art…\n 6 4732781 2018-01-29 \"The question is o… Anthony Ro… Liberal      Nipissing—Ti…\n 7 4732782 2018-01-29 \"Agreed.\\n No.\"     Some hon. … <NA>         <NA>         \n 8 4732783 2018-01-29 \"All those in favo… Anthony Ro… Liberal      Nipissing—Ti…\n 9 4732784 2018-01-29 \"Yea.\"              Some hon. … <NA>         <NA>         \n10 4732785 2018-01-29 \"All those opposed… Anthony Ro… Liberal      Nipissing—Ti…\n# ℹ 33,095 more rows\n```", "```py\nhansard_canada_2018_corpus <-\n corpus(hansard_canada_2018, \n docid_field = \"basepk\", \n text_field = \"speechtext\")\n```", "```py\nWarning: NA is replaced by empty string\n```", "```py\nhansard_canada_2018_corpus\n```", "```py\nCorpus consisting of 33,105 documents and 4 docvars.\n4732776 :\n\"Mr. Speaker, I would like to wish everyone in this place a h...\"\n\n4732777 :\n\"Mr. Speaker, I want to thank my colleague from Richmond—Arth...\"\n\n4732778 :\n\"Mr. Speaker, I am here today to discuss a motion that asks t...\"\n\n4732779 :\n\"Resuming debate. There being no further debate, the hon. mem...\"\n\n4732780 :\n\"Mr. Speaker, we are nearing the end of the discussion and de...\"\n\n4732781 :\n\"The question is on the motion. Is the pleasure of the House ...\"\n\n[ reached max_ndoc ... 33,099 more documents ]\n```", "```py\nhansard_dfm <-\n hansard_canada_2018_corpus |>\n tokens(\n remove_punct = TRUE,\n remove_symbols = TRUE\n ) |>\n dfm() |>\n dfm_trim(min_termfreq = 2, min_docfreq = 2) |>\n dfm_remove(stopwords(source = \"snowball\"))\n\nhansard_dfm\n```", "```py\nDocument-feature matrix of: 33,105 documents, 29,432 features (99.77% sparse) and 4 docvars.\n         features\ndocs      mr speaker like wish everyone place happy new year great\n  4732776  1       1    2    1        1     4     2   3    5     1\n  4732777  1       1    5    0        1     1     0   0    0     1\n  4732778  1       1    2    0        0     1     0   0    4     1\n  4732779  0       0    0    0        0     0     0   0    0     0\n  4732780  1       1    4    0        1     1     0   0    2     0\n  4732781  0       0    0    0        0     0     0   0    0     0\n[ reached max_ndoc ... 33,099 more documents, reached max_nfeat ... 29,422 more features ]\n```", "```py\nhansard_topics <- stm(documents = hansard_dfm, K = 10)\n\nbeepr::beep()\n\nwrite_rds(\n hansard_topics,\n file = \"hansard_topics.rda\"\n)\n```", "```py\nhansard_topics <- read_rds(\n file = \"hansard_topics.rda\"\n)\n```", "```py\nlabelTopics(hansard_topics)\n```", "```py\nTopic 1 Top Words:\n     Highest Prob: indigenous, government, communities, bill, first, development, nations \n     FREX: fisheries, fish, oceans, marine, habitat, coastal, plastic \n     Lift: 10-knot, 13-storey, 167.4, 1885, 2,560, 200-mile, 2016-19 \n     Score: indigenous, fisheries, oceans, fish, marine, environmental, peoples \nTopic 2 Top Words:\n     Highest Prob: community, people, canada, mr, housing, speaker, many \n     FREX: latin, celebrate, filipino, sikh, anniversary, cancer, celebrating \n     Lift: #myfeminism, 1897, 1904, 1915, 1925, 1941, 1943 \n     Score: latin, housing, filipino, sikh, celebrate, heritage, enverga \nTopic 3 Top Words:\n     Highest Prob: bill, justice, system, criminal, victims, court, violence \n     FREX: justice, criminal, crime, firearms, offences, c-75, gun \n     Lift: 1608, 2,465, 202, 273, 273.1, 3.01, 302-page \n     Score: criminal, justice, c-75, firearms, offences, correctional, crime \nTopic 4 Top Words:\n     Highest Prob: carbon, energy, pipeline, climate, government, oil, canada \n     FREX: carbon, emissions, pipelines, greenhouse, pricing, fuel, fossil \n     Lift: emitters, ipcc, pricing, -30, 0822, 1.3-billion, 1.62 \n     Score: carbon, pipeline, oil, energy, emissions, climate, pollution \nTopic 5 Top Words:\n     Highest Prob: canada, government, canadians, workers, canadian, new, tax \n     FREX: tariffs, steel, postal, cptpp, cra, nafta, aluminum \n     Lift: ip, wages, 0.6, 0.9, 1,090, 1.26-billion, 1.84 \n     Score: tax, workers, economy, cptpp, tariffs, postal, growth \nTopic 6 Top Words:\n     Highest Prob: member, speaker, mr, minister, house, hon, question \n     FREX: ethics, yea, resuming, hon, briefing, fundraisers, secretary \n     Lift: khan, norman, 1,525, 100-plus, 13.1, 1316, 13198 \n     Score: hon, member, prime, question, ethics, nay, minister \nTopic 7 Top Words:\n     Highest Prob: government, minister, liberals, liberal, prime, canadians, veterans \n     FREX: deficit, deficits, phoenix, veterans, promises, promised, davie \n     Lift: 0.23, 12.50, 14-billion, 148.6, 20-billion, 2045, 2051 \n     Score: liberals, veterans, prime, tax, liberal, budget, deficit \nTopic 8 Top Words:\n     Highest Prob: canada, motion, government, rights, mr, house, speaker \n     FREX: petition, refugees, pursuant, asylum, refugee, iran, israel \n     Lift: cfia, pre-clearance, terror, c-350, consular, crossers, deferred \n     Score: iran, immigration, pursuant, asylum, refugees, petition, petitioners \nTopic 9 Top Words:\n     Highest Prob: bill, committee, act, legislation, canadians, canada, information \n     FREX: amendment, harassment, organ, cannabis, tobacco, c-59, c-65 \n     Lift: 240.1, a36, anti-tobacco, appropriations, beadonor.ca, calibrated, carvin \n     Score: bill, amendments, elections, harassment, organ, amendment, c-76 \nTopic 10 Top Words:\n     Highest Prob: people, one, can, want, us, get, going \n     FREX: things, think, lot, something, see, really, look \n     Lift: 22-year-old, 980,000, backtracking, balloting, carolina, disenfranchise, enfranchisement \n     Score: people, going, forward, legislation, things, voter, think \n```"]