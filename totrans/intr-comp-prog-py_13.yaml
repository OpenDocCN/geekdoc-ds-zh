- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: SOME SIMPLE ALGORITHMS AND DATA STRUCTURES
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一些简单的算法和数据结构
- en: Though we expend a fair number of pages in this book talking about efficiency,
    the goal is not to make you expert in designing efficient programs. There are
    many long books (and even some good long books) devoted exclusively to that topic.[^(68)](#c12-fn-0001)
    In Chapter 11, we introduced some of the basic concepts underlying complexity
    analysis. In this chapter, we use those concepts to look at the complexity of
    a few classic algorithms. The goal of this chapter is to help you develop some
    general intuitions about how to approach questions of efficiency. By the time
    you get through this chapter, you should understand why some programs complete
    in the blink of an eye, why some need to run overnight, and why some wouldn't
    complete in your lifetime.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在本书中花了相当多的页面讨论效率，但目标并不是让你成为设计高效程序的专家。还有许多专门讨论这一主题的长书（甚至一些不错的长书）。在第11章中，我们介绍了一些复杂性分析的基本概念。在这一章中，我们利用这些概念来考察几个经典算法的复杂性。本章的目标是帮助你培养一些关于如何处理效率问题的一般直觉。当你完成本章时，你应该理解为什么有些程序瞬间完成，为什么有些需要整夜运行，以及为什么有些在你的一生中都无法完成。
- en: The first algorithms we looked at in this book were based on brute-force exhaustive
    enumeration. We argued that modern computers are so fast that it is often the
    case that employing clever algorithms is a waste of time. Writing code that is
    simple and obviously correct is often the right way to go.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们首次探讨的算法是基于穷举法的。我们认为现代计算机如此快速，以至于采用巧妙的算法往往是浪费时间。编写简单且显然正确的代码通常是正确的做法。
- en: We then looked at some problems (e.g., finding an approximation to the roots
    of a polynomial) where the search space was too large to make brute force practical.
    This led us to consider more efficient algorithms such as bisection search and
    Newton–Raphson. The major point was that the key to efficiency is a good algorithm,
    not clever coding tricks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着研究了一些问题（例如，寻找多项式根的近似值），在这些问题中，搜索空间太大，无法通过穷举法进行实际处理。这使我们考虑了更高效的算法，如二分法和牛顿-拉夫森法。关键在于，效率的关键是一个好的算法，而不是巧妙的编码技巧。
- en: In the sciences (physical, life, and social), programmers often start by quickly
    coding a simple algorithm to test the plausibility of a hypothesis about a data
    set, and then run it on a small amount of data. If this yields encouraging results,
    the hard work of producing an implementation that can be run (perhaps over and
    over again) on large data sets begins. Such implementations need to be based on
    efficient algorithms.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学（物理、生物和社会科学）中，程序员通常首先快速编码一个简单的算法，以测试关于数据集的假设的合理性，然后在少量数据上运行。如果这产生了令人鼓舞的结果，那么就开始了在大数据集上运行（或许是反复运行）可实施方案的艰苦工作。这种实施需要基于高效的算法。
- en: Efficient algorithms are hard to invent. Successful professional computer scientists
    might invent one algorithm during their whole career—if they are lucky. Most of
    us never invent a novel algorithm. What we do instead is learn to reduce the most
    complex aspects of the problems we are faced with to previously solved problems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 高效的算法很难发明。成功的职业计算机科学家可能在整个职业生涯中只发明一个算法——如果他们幸运的话。我们大多数人从未发明过新算法。相反，我们学习将面临的复杂问题简化为之前解决过的问题。
- en: More specifically, we
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们
- en: Develop an understanding of the inherent complexity of the problem.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解问题的内在复杂性。
- en: Think about how to break that problem up into subproblems.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑如何将这个问题分解为子问题。
- en: Relate those subproblems to other problems for which efficient algorithms already
    exist.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些子问题与其他已经存在高效算法的问题关联起来。
- en: This chapter contains a few examples intended to give you some intuition about
    algorithm design. Many other algorithms appear elsewhere in the book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含一些示例，旨在让你对算法设计有一些直观的理解。书中还有许多其他算法。
- en: Keep in mind that the most efficient algorithm is not always the algorithm of
    choice. A program that does everything in the most efficient possible way is often
    needlessly difficult to understand. It is often a good strategy to start by solving
    the problem at hand in the most straightforward manner possible, instrument it
    to find any computational bottlenecks, and then look for ways to improve the computational
    complexity of those parts of the program contributing to the bottlenecks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，最有效的算法并不总是首选算法。以最有效的方式完成所有事情的程序往往会让人难以理解。通常，从最直接的方式解决手头的问题是一个好策略，记录以找到任何计算瓶颈，然后寻找改善程序中导致瓶颈的部分的计算复杂性的方法。
- en: 12.1 Search Algorithms
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 搜索算法
- en: A **search algorithm** is a method for finding an item or group of items with
    specific properties within a collection of items. We refer to the collection of
    items as a **search space**. The search space might be something concrete, such
    as a set of electronic medical records, or something abstract, such as the set
    of all integers. A large number of problems that occur in practice can be formulated
    as search problems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**搜索算法**是一种在项目集合中查找具有特定属性的单个项目或一组项目的方法。我们将项目集合称为**搜索空间**。搜索空间可以是一些具体的东西，如一组电子病历，也可以是一些抽象的东西，如所有整数的集合。许多实际发生的问题都可以表述为搜索问题。'
- en: Many of the algorithms presented earlier in this book can be viewed as search
    algorithms. In Chapter 3, we formulated finding an approximation to the roots
    of a polynomial as a search problem and looked at three algorithms—exhaustive
    enumeration, bisection search, and Newton–Raphson—for searching the space of possible
    answers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中早期提出的许多算法可以视为搜索算法。在第三章中，我们将寻找多项式根的近似值表述为一个搜索问题，并考察了三种算法——穷举枚举、二分搜索和牛顿-拉夫森法——用于搜索可能答案的空间。
- en: In this section, we will examine two algorithms for searching a list. Each meets
    the specification
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究两种搜索列表的算法。每种算法都符合规范。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The astute reader might wonder if this is not semantically equivalent to the
    Python expression `e in L`. The answer is yes, it is. And if you are unconcerned
    about the efficiency of discovering whether `e` is in `L`, you should simply write
    that expression.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 机智的读者可能会想，这是否与Python表达式`e in L`在语义上等价。答案是肯定的，是的。如果你不关心发现`e`是否在`L`中的效率，你应该简单地写出该表达式。
- en: 12.1.1 Linear Search and Using Indirection to Access Elements
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 线性搜索和使用间接访问元素
- en: 'Python uses the following algorithm to determine if an element is in a list:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Python使用以下算法来确定元素是否在列表中：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If the element `e` is not in the list, the algorithm will perform *θ*`(len(L))`
    tests, i.e., the complexity is at best linear in the length of `L`. Why “at best”
    linear? It will be linear only if each operation inside the loop can be done in
    constant time. That raises the question of whether Python retrieves the `i`^(th)
    element of a list in constant time. Since our model of computation assumes that
    fetching the contents of an address is a constant-time operation, the question
    becomes whether we can compute the address of the `i`^(th) element of a list in
    constant time.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果元素`e`不在列表中，算法将执行*θ*`(len(L))`次测试，即复杂度在`L`的长度上至多为线性。为什么说“至多”线性？只有在循环内部的每个操作都可以在常数时间内完成时，它才是线性的。这引出了一个问题：Python是否能在常数时间内检索列表的第`i`^(th)个元素。由于我们的计算模型假设获取地址内容是常数时间操作，问题就变成了我们是否能在常数时间内计算列表第`i`^(th)个元素的地址。
- en: Let's start by considering the simple case where each element of the list is
    an integer. This implies that each element of the list is the same size, e.g.,
    four units of memory (four 8-bit bytes[^(69)](#c12-fn-0002)). Assuming that the
    elements of the list are stored contiguously, the address in memory of the `i`^(th)
    element of the list is simply `start + 4`*`i`, where `start` is the address of
    the start of the list. Therefore we can assume that Python could compute the address
    of the `i`^(th) element of a list of integers in constant time.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先考虑每个列表元素都是整数的简单情况。这意味着列表中的每个元素大小相同，例如，占用四个内存单元（四个8位字节[^(69)](#c12-fn-0002)）。假设列表元素连续存储，列表第`i`^(th)个元素在内存中的地址为`start
    + 4`*`i`，其中`start`是列表起始地址。因此，我们可以假设Python能够在常数时间内计算出整数列表第`i`^(th)个元素的地址。
- en: Of course, we know that Python lists can contain objects of types other than
    `int`, and that the same list can contain objects of many types and sizes. You
    might think that this would present a problem, but it does not.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们知道Python列表可以包含除`int`之外的其他类型的对象，而且同一个列表可以包含多种类型和大小的对象。你可能会认为这会带来问题，但事实并非如此。
- en: In Python, a list is represented as a length (the number of objects in the list)
    and a sequence of fixed-size **pointers**[^(70)](#c12-fn-0003) to objects. [Figure
    12-1](#c12-fig-0001) illustrates the use of these pointers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，列表由一个长度（列表中对象的数量）和一系列固定大小的**指针**[^(70)](#c12-fn-0003)表示对象。[图 12-1](#c12-fig-0001)说明了这些指针的使用。
- en: '![c12-fig-0001.jpg](../images/c12-fig-0001.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0001.jpg](../images/c12-fig-0001.jpg)'
- en: '[Figure 12-1](#c12-fig-0001a) Implementing lists'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-1](#c12-fig-0001a) 实现列表'
- en: The shaded region represents a list containing four elements. The leftmost shaded
    box contains a pointer to an integer indicating the length of the list. Each of
    the other shaded boxes contains a pointer to an object in the list.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 被阴影区域表示的列表包含四个元素。最左边的阴影框包含一个指向整数的指针，指示列表的长度。其他阴影框中的每一个都包含一个指向列表中对象的指针。
- en: If the length field occupies four units of memory, and each pointer (address)
    occupies four units of memory, the address of the `i`^(th) element of the list
    is stored at the address `start + 4 + 4`*`i`. Again, this address can be found
    in constant time, and then the value stored at that address can be used to access
    the `i`^(th)element. This access too is a constant-time operation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果长度字段占用四个内存单元，而每个指针（地址）占用四个内存单元，则列表的`i`^(th)元素的地址存储在地址`start + 4 + 4`*`i`中。同样，这个地址可以在常数时间内找到，然后可以使用该地址存储的值来访问`i`^(th)元素。这个访问也是一个常数时间的操作。
- en: 'This example illustrates one of the most important implementation techniques
    used in computing: **indirection**.[^(71)](#c12-fn-0004) Generally speaking, indirection
    involves accessing something by first accessing something else that contains a
    reference to the thing initially sought. This is what happens each time we use
    a variable to refer to the object to which that variable is bound. When we use
    a variable to access a list and then a reference stored in that list to access
    another object, we are going through two levels of indirection.[^(72)](#c12-fn-0005)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子说明了计算中使用的最重要的实现技术之一：**间接寻址**。[^(71)](#c12-fn-0004)一般来说，间接寻址涉及先访问包含所寻物体引用的其他内容，然后再访问所需物体。每次我们使用变量引用与该变量绑定的对象时，都会发生这种情况。当我们使用变量访问列表，然后通过列表中存储的引用访问另一个对象时，我们通过两个级别的间接寻址。[^(72)](#c12-fn-0005)
- en: 12.1.2 Binary Search and Exploiting Assumptions
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 二分搜索和利用假设
- en: Getting back to the problem of implementing `search(L, e)`, is *θ*`(len(L))`
    the best we can do? Yes, if we know nothing about the relationship of the values
    of the elements in the list and the order in which they are stored. In the worst
    case, we have to look at each element in `L` to determine whether `L` contains
    `e`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 回到实现`search(L, e)`的问题，*θ*`(len(L))`是我们能做的最好的吗？是的，如果我们对列表中元素的值和它们的存储顺序没有任何了解。在最坏的情况下，我们必须查看`L`中的每个元素，以确定`L`是否包含`e`。
- en: But suppose we know something about the order in which elements are stored,
    e.g., suppose we know that we have a list of integers stored in ascending order.
    We could change the implementation so that the search stops when it reaches a
    number larger than the number for which it is searching, as in [Figure 12-2](#c12-fig-0002).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设我们对元素存储的顺序有所了解，例如，假设我们知道我们有一个按升序存储的整数列表。我们可以改变实现，使得搜索在遇到一个大于要搜索的数字时停止，如[图
    12-2](#c12-fig-0002)所示。
- en: '![c12-fig-0002.jpg](../images/c12-fig-0002.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0002.jpg](../images/c12-fig-0002.jpg)'
- en: '[Figure 12-2](#c12-fig-0002a) Linear search of a sorted list'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-2](#c12-fig-0002a) 有序列表的线性搜索'
- en: This would improve the average running time. However, it would not change the
    worst-case complexity of the algorithm, since in the worst case each element of
    `L` is examined.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这将改善平均运行时间。然而，这不会改变算法的最坏情况复杂度，因为在最坏情况下，每个`L`中的元素都要被检查。
- en: We can, however, get a considerable improvement in the worst-case complexity
    by using an algorithm, **binary search**, that is similar to the bisection search
    algorithm used in Chapter 3 to find an approximation to the square root of a floating-point
    number. There we relied upon the fact that there is an intrinsic total ordering
    on floating-point numbers. Here we rely on the assumption that the list is ordered.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以通过使用一种类似于第3章中用于找到浮点数平方根近似值的二分搜索算法的**二分查找**算法，显著改善最坏情况下的复杂性。在那里，我们依赖于浮点数之间固有的全序关系。在这里，我们依赖于列表已排序的假设。
- en: 'The idea is simple:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法很简单：
- en: 1\. Pick an index, `i`, that divides the list `L` roughly in half.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1\. 选择一个索引`i`，大致将列表`L`分为两半。
- en: 2\. Ask if `L[i] == e`.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2\. 询问`L[i] == e`。
- en: 3\. If not, ask whether `L[i]` is larger or smaller than `e`.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3\. 如果没有，询问`L[i]`是否大于或小于`e`。
- en: 4\. Depending upon the answer, search either the left or right half of `L` for
    `e`.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4\. 根据答案，搜索`L`的左半部分或右半部分以查找`e`。
- en: Given the structure of this algorithm, it is not surprising that the most straightforward
    implementation of binary search uses recursion, as shown in [Figure 12-3](#c12-fig-0003).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于该算法的结构，二分查找最直接的实现使用递归，这并不令人惊讶，如[图12-3](#c12-fig-0003)所示。
- en: The outer function in [Figure 12-3](#c12-fig-0003), `search(L, e)`, has the
    same arguments and specification as the function defined in [Figure 12-2](#c12-fig-0002).
    The specification says that the implementation may assume that `L` is sorted in
    ascending order. The burden of making sure that this assumption is satisfied lies
    with the caller of `search`. If the assumption is not satisfied, the implementation
    has no obligation to behave well. It could work, but it could also crash or return
    an incorrect answer. Should `search` be modified to check that the assumption
    is satisfied? This might eliminate a source of errors, but it would defeat the
    purpose of using binary search, since checking the assumption would itself take
    `O(len(L))` time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-3](#c12-fig-0003)中的外部函数`search(L, e)`具有与[图12-2](#c12-fig-0002)中定义的函数相同的参数和规范。规范表明实现可以假定`L`是按升序排序的。确保这一假设成立的责任在于`search`的调用者。如果假设不成立，实现没有义务表现良好。它可能会工作，但也可能崩溃或返回错误的答案。是否应该修改`search`以检查假设是否成立？这可能消除错误来源，但会违背使用二分查找的目的，因为检查假设本身将耗时`O(len(L))`。'
- en: '![c12-fig-0003.jpg](../images/c12-fig-0003.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0003.jpg](../images/c12-fig-0003.jpg)'
- en: '[Figure 12-3](#c12-fig-0003a) Recursive binary search'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-3](#c12-fig-0003a) 递归二分查找'
- en: Functions such as `search` are often called **wrapper functions**. The function
    provides a nice interface for client code, but is essentially a pass-through that
    does no serious computation. Instead, it calls the helper function `bSearch` with
    appropriate arguments. This raises the question of why not eliminate `search`
    and have clients call `bin_search` directly? The reason is that the parameters
    `low` and `high` have nothing to do with the abstraction of searching a list for
    an element. They are implementation details that should be hidden from those writing
    programs that call `search`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 像`search`这样的函数通常被称为**包装函数**。这个函数为客户端代码提供了一个良好的接口，但本质上是一个不进行复杂计算的通过函数。相反，它使用适当的参数调用辅助函数`bSearch`。这引出了一个问题：为什么不消除`search`，让客户端直接调用`bin_search`呢？原因是参数`low`和`high`与搜索列表中元素的抽象无关。它们是实现细节，应当对调用`search`的程序员隐藏。
- en: Let us now analyze the complexity of `bin_search`. We showed in the last section
    that list access takes constant time. Therefore, we can see that excluding the
    recursive call, each instance of `bSearch` is *θ*`(1)`. Therefore, the complexity
    of `bin_search` depends only upon the number of recursive calls.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们分析`bin_search`的复杂性。我们在上一节中展示了列表访问是常量时间。因此，可以看出，除了递归调用之外，`bSearch`的每个实例都是*θ*`(1)`。因此，`bin_search`的复杂性仅依赖于递归调用的次数。
- en: 'If this were a book about algorithms, we would now dive into a careful analysis
    using something called a recurrence relation. But since it isn''t, we will take
    a much less formal approach that starts with the question “How do we know that
    the program terminates?” Recall that in Chapter 3 we asked the same question about
    a `while` loop. We answered the question by providing a decrementing function
    for the loop. We do the same thing here. In this context, the decrementing function
    has the properties:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一本关于算法的书，我们将深入分析一个称为递归关系的内容。但因为这不是，我们将采取一个不那么正式的方法，从“我们如何知道程序终止？”这个问题开始。回想一下在第三章中，我们对`while`循环问了同样的问题。我们通过提供循环的递减函数来回答了这个问题。这里我们也做同样的事情。在这个上下文中，递减函数具有以下性质：
- en: It maps the values to which the formal parameters are bound to a nonnegative
    integer.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将正式参数绑定的值映射到一个非负整数。
- en: When its value is `0`, the recursion terminates.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当其值为`0`时，递归终止。
- en: For each recursive call, the value of the decrementing function is less than
    the value of the decrementing function on entry to the instance of the function
    making the call.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个递归调用，递减函数的值小于调用该函数实例时的递减函数的值。
- en: The decrementing function for `bin_search` is `high`–`low`. The `if` statement
    in `search` ensures that the value of this decrementing function is at least `0`
    the first time `bSearch` is called (decrementing function property 1).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`bin_search`的递减函数是`high`–`low`。`search`中的`if`语句确保第一次调用`bSearch`时，该递减函数的值至少为`0`（递减函数性质
    1）。'
- en: When `bin_search` is entered, if `high`–`low` is exactly `0`, the function makes
    no recursive call—simply returning the value `L[low] == e` (satisfying decrementing
    function property 2).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当进入`bin_search`时，如果`high`–`low`恰好为`0`，则该函数不进行递归调用—直接返回值`L[low] == e`（满足递减函数性质
    2）。
- en: The function `bin_search` contains two recursive calls. One call uses arguments
    that cover all the elements to the left of `mid`, and the other call uses arguments
    that cover all the elements to the right of `mid`. In either case, the value of
    `high`–`low` is cut in half (satisfying decrementing function property 3).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`bin_search`函数包含两个递归调用。一个调用使用的参数覆盖`mid`左侧的所有元素，另一个调用使用的参数覆盖`mid`右侧的所有元素。在这两种情况下，`high`–`low`的值都减半（满足递减函数性质
    3）。'
- en: We now understand why the recursion terminates. The next question is how many
    times can the value of `high–low` be cut in half before `high–low == 0`? Recall
    that `log`[y]`(x)` is the number of times that `y` has to be multiplied by itself
    to reach `x`. Conversely, if `x` is divided by `y log`[y]`(x)` times, the result
    is `1`. This implies that `high–low` can be cut in half using floor division at
    most `log`[2]`(``high–low``)` times before it reaches `0`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在明白了为什么递归会终止。下一个问题是，在`high–low == 0`之前，`high–low`的值可以被减半多少次？回想一下，`log`[y]`(x)`是将`y`自身相乘多少次才能达到`x`。相反，如果将`x`除以`y
    log`[y]`(x)`次，结果是`1`。这意味着`high–low`最多可以通过向下取整的除法被减半`log`[2]`(``high–low``)`次，直到达到`0`。
- en: Finally, we can answer the question, what is the algorithmic complexity of binary
    search? Since when `search` calls `bSearch` the value of `high`–`low` is equal
    to `len(L)-1`, the complexity of `search` is *θ*`(log(len(``L``)))`.[^(73)](#c12-fn-0006)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以回答这个问题，二分查找的算法复杂度是什么？由于当`search`调用`bSearch`时，`high`–`low`的值等于`len(L)-1`，因此`search`的复杂度是*θ*`(log(len(``L``)))`。[^(73)](#c12-fn-0006)
- en: '**Finger exercise:** Why does the code use `mid+1` rather than `mid` in the
    second recursive call?'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习题：** 为什么代码在第二个递归调用中使用`mid+1`而不是`mid`？'
- en: 12.2 Sorting Algorithms
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 排序算法
- en: We have just seen that if we happen to know a list is sorted, we can exploit
    that information to greatly reduce the time needed to search a list. Does this
    mean that when asked to search a list we should first sort it and then perform
    the search?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到，如果我们知道一个列表是排序好的，我们可以利用这一信息大大减少搜索该列表所需的时间。这是否意味着当被要求搜索一个列表时，我们应该先对其进行排序，然后再进行搜索？
- en: Let *θ*`(sortComplexity(L))` be a tight bound on the complexity of sorting a
    list. Since we know that we can search an unsorted list in *θ*`(len(L))` time,
    the question of whether we should first sort and then search boils down to the
    question, is `sortComplexity(L) + log(len(L))` less than `len(L)`? The answer,
    sadly, is no. It is impossible sort a list without looking at each element in
    the list at least once, so it is not possible to sort a list in sub-linear time.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让*θ*`(sortComplexity(L))`成为对排序列表复杂度的紧密界限。因为我们知道可以在*θ*`(len(L))`时间内搜索一个无序列表，因此，是否应该先排序再搜索的问题归结为，`sortComplexity(L)
    + log(len(L))`是否小于`len(L)`？可悲的是，答案是否定的。要排序一个列表，至少必须查看列表中的每个元素一次，因此不可能在次线性时间内对列表进行排序。
- en: Does this mean that binary search is an intellectual curiosity of no practical
    import? Happily, no. Suppose that we expect to search the same list many times.
    It might well make sense to pay the overhead of sorting the list once, and then
    **amortize** the cost of the sort over many searches. If we expect to search the
    list `k` times, the relevant question becomes, is `sortComplexity(L) + k`*`log(len(L))`
    less than `k`*`len(L)`?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着二分搜索是一个没有实际意义的智力好奇？幸运的是，答案是否定的。假设我们期望多次搜索同一列表。一次性对列表进行排序的开销可能是值得的，然后在多次搜索中**摊销**排序的成本。如果我们期望搜索列表`k`次，相关的问题变为，`sortComplexity(L)
    + k`*`log(len(L))`是否小于`k`*`len(L)`？
- en: As `k` becomes large, the time required to sort the list becomes increasingly
    irrelevant. How big `k` needs to be depends upon how long it takes to sort a list.
    If, for example, sorting were exponential in the size of the list, `k` would have
    to be quite large.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着`k`变得较大，排序列表所需的时间变得越来越不相关。`k`需要多大取决于排序列表所需的时间。例如，如果排序在列表大小上是指数级的，`k`必须相当大。
- en: Fortunately, sorting can be done rather efficiently. For example, the standard
    implementation of sorting in most Python implementations runs in roughly `O(n`*`log(n))`
    time, where `n` is the length of the list. In practice, you will rarely need to
    implement your own sort function. In most cases, the right thing to do is to use
    either Python's built-in `sort` method (`L.sort()` sorts the list `L`) or its
    built-in function `sorted` (`sorted(L)` returns a list with the same elements
    as `L`, but does not mutate `L`). We present sorting algorithms here primarily
    to provide some practice in thinking about algorithm design and complexity analysis.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，排序可以相当高效地完成。例如，大多数Python实现中标准的排序实现大约在`O(n`*`log(n))`时间内运行，其中`n`是列表的长度。实际上，您很少需要实现自己的排序函数。在大多数情况下，正确的做法是使用Python的内置`sort`方法（`L.sort()`对列表`L`进行排序）或其内置函数`sorted`（`sorted(L)`返回一个与`L`具有相同元素的列表，但不会修改`L`）。我们在此呈现排序算法，主要是为了提供一些思考算法设计和复杂性分析的练习。
- en: We begin with a simple but inefficient algorithm, **selection sort**. Selection
    sort, [Figure 12-4](#c12-fig-0004), works by maintaining the **loop invariant**
    that, given a partitioning of the list into a prefix (`L[0:i]`) and a suffix (`L[i+1:len(L)]`),
    the prefix is sorted and no element in the prefix is larger than the smallest
    element in the suffix.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个简单但低效的算法开始，即**选择排序**。选择排序，[图12-4](#c12-fig-0004)，通过保持**循环不变量**来工作，给定将列表划分为前缀（`L[0:i]`）和后缀（`L[i+1:len(L)]`），前缀是排序的，并且前缀中的没有任何元素大于后缀中的最小元素。
- en: We use induction to reason about loop invariants.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用归纳法推理循环不变量。
- en: 'Base case: At the start of the first iteration, the prefix is empty, i.e.,
    the suffix is the entire list. Therefore, the invariant is (trivially) true.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础情况：在第一次迭代开始时，前缀为空，即后缀是整个列表。因此，不变量（显然）成立。
- en: 'Induction step: At each step of the algorithm, we move one element from the
    suffix to the prefix. We do this by appending a minimum element of the suffix
    to the end of the prefix. Because the invariant held before we moved the element,
    we know that after we append the element the prefix is still sorted. We also know
    that since we removed the smallest element in the suffix, no element in the prefix
    is larger than the smallest element in the suffix.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归纳步骤：在算法的每一步中，我们将一个元素从后缀移动到前缀。我们通过将后缀中的最小元素附加到前缀的末尾来实现这一点。由于在移动元素之前不变量成立，我们知道在附加元素后，前缀仍然是排序的。我们还知道，由于我们移除了后缀中的最小元素，前缀中的没有任何元素大于后缀中的最小元素。
- en: 'Termination: When the loop is exited, the prefix includes the entire list,
    and the suffix is empty. Therefore, the entire list is now sorted in ascending
    order.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终止：当退出循环时，前缀包括整个列表，而后缀为空。因此，整个列表现在按升序排序。
- en: '![c12-fig-0004.jpg](../images/c12-fig-0004.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0004.jpg](../images/c12-fig-0004.jpg)'
- en: '[Figure 12-4](#c12-fig-0004a) Selection sort'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-4](#c12-fig-0004a) 选择排序'
- en: It's hard to imagine a simpler or more obviously correct sorting algorithm.
    Unfortunately, it is rather inefficient.[^(74)](#c12-fn-0007) The complexity of
    the inner loop is *θ*`(len(L))`. The complexity of the outer loop is also *θ*`(len(L))`.
    So, the complexity of the entire function is *θ*`(len(L)`²`)`. I.e., it is quadratic
    in the length of `L`.[^(75)](#c12-fn-0008)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 很难想象有比这更简单或更明显正确的排序算法。不幸的是，它的效率相当低下。[^(74)](#c12-fn-0007) 内部循环的复杂度是*θ*`(len(L))`。外部循环的复杂度也是*θ*`(len(L))`。因此，整个函数的复杂度是*θ*`(len(L)`²`)`。即，它在`L`的长度上是二次的。[^(75)](#c12-fn-0008)
- en: 12.2.1 Merge Sort
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 归并排序
- en: Fortunately, we can do a lot better than quadratic time using a **divide-and-conquer**
    **algorithm**. The basic idea is to combine solutions of simpler instances of
    the original problem. In general, a divide-and-conquer algorithm is characterized
    by
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以使用**分治** **算法**来比二次时间表现得更好。基本思想是组合原问题的简单实例的解决方案。一般来说，分治算法的特点是
- en: A threshold input size, below which the problem is not subdivided
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个阈值输入大小，低于此大小的问题不进行细分。
- en: The size and number of sub-instances into which an instance is split
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个实例分割成的子实例的大小和数量。
- en: The algorithm used to combine sub-solutions.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于组合子解决方案的算法。
- en: The threshold is sometimes called the **recursive base**. For item 2, it is
    usual to consider the ratio of initial problem size to the sub-instance size.
    In most of the examples we've seen so far, the ratio was `2`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值有时称为**递归基**。对于项目2，通常考虑初始问题大小与子实例大小的比率。在我们到目前为止看到的大多数例子中，比率为`2`。
- en: '**Merge sort** is a prototypical divide-and-conquer algorithm. It was invented
    in 1945, by John von Neumann, and is still widely used. Like many divide-and-conquer
    algorithms it is most easily described recursively:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**归并排序**是一个典型的分治算法。它于1945年由约翰·冯·诺依曼发明，至今仍广泛使用。像许多分治算法一样，它最容易以递归方式描述：'
- en: 1\. If the list is of length `0` or `1`, it is already sorted.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1\. 如果列表长度为`0`或`1`，则已排序。
- en: 2\. If the list has more than one element, split the list into two lists, and
    use merge sort to sort each of them.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2\. 如果列表有多个元素，则将列表拆分为两个列表，并使用归并排序对每个列表进行排序。
- en: 3\. Merge the results.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3\. 合并结果。
- en: 'The key observation made by von Neumann is that two sorted lists can be efficiently
    merged into a single sorted list. The idea is to look at the first element of
    each list and move the smaller of the two to the end of the result list. When
    one of the lists is empty, all that remains is to copy the remaining items from
    the other list. Consider, for example, merging the two lists `L_1 =` `[1,5,12,18,19,20]`
    and `L_2 =` `[2,3,4,17]`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 冯·诺依曼的关键观察是，可以高效地将两个已排序的列表合并为一个已排序的列表。这个想法是查看每个列表的第一个元素，并将较小的一个移动到结果列表的末尾。当其中一个列表为空时，只需将另一个列表中剩余的项目复制过来。例如，考虑合并两个列表`L_1
    =` `[1,5,12,18,19,20]`和`L_2 =` `[2,3,4,17]`：
- en: '| Remaining in L_1 | Remaining in L_2 | Result |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| L_1中剩余 | L_2中剩余 | 结果 |'
- en: '| --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `[1,5,12,18,19,20]` | `[2,3,4,17]` | `[]` |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `[1,5,12,18,19,20]` | `[2,3,4,17]` | `[]` |'
- en: '| `[5,12,18,19,20]` | `[2,3,4,17]` | `[1]` |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `[5,12,18,19,20]` | `[2,3,4,17]` | `[1]` |'
- en: '| `[5,12,18,19,20]` | `[3,4,17]` | `[1,2]` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `[5,12,18,19,20]` | `[3,4,17]` | `[1,2]` |'
- en: '| `[5,12,18,19,20]` | `[4,17]` | `[1,2,3]` |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `[5,12,18,19,20]` | `[4,17]` | `[1,2,3]` |'
- en: '| `[5,12,18,19,20]` | `[17]` | `[1,2,3,4]` |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `[5,12,18,19,20]` | `[17]` | `[1,2,3,4]` |'
- en: '| `[12,18,19,20]` | `[17]` | `[1,2,3,4,5]` |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `[12,18,19,20]` | `[17]` | `[1,2,3,4,5]` |'
- en: '| `[18,19,20]` | `[17]` | `[1,2,3,4,5,12]` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `[18,19,20]` | `[17]` | `[1,2,3,4,5,12]` |'
- en: '| `[18,19,20]` | `[]` | `[1,2,3,4,5,12,17]` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `[18,19,20]` | `[]` | `[1,2,3,4,5,12,17]` |'
- en: '| `[]` | `[]` | `[1,2,3,4,5,12,17,18,19,20]` |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `[]` | `[]` | `[1,2,3,4,5,12,17,18,19,20]` |'
- en: What is the complexity of the merge process? It involves two constant-time operations,
    comparing the values of elements and copying elements from one list to another.
    The number of comparisons is order *θ*`(len(L))`, where `L` is the longer of the
    two lists. The number of copy operations is order *θ*`(len(L1) + len(L2))`, because
    each element is copied exactly once. (The time to copy an element depends on the
    size of the element. However, this does not affect the order of the growth of
    sort as a function of the number of elements in the list.) Therefore, merging
    two sorted lists is linear in the length of the lists.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 合并过程的复杂度是什么？它涉及两个常数时间操作，比较元素的值和从一个列表复制元素到另一个列表。比较的数量是*θ*`(len(L))`，其中`L`是两个列表中较长的一个。复制操作的数量是*θ*`(len(L1)
    + len(L2))`，因为每个元素正好复制一次。（复制一个元素的时间取决于元素的大小。然而，这不会影响排序的增长顺序，作为列表中元素数量的函数。）因此，合并两个已排序的列表在列表长度上是线性的。
- en: '[Figure 12-5](#c12-fig-0005) contains an implementation of the merge sort algorithm.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-5](#c12-fig-0005)包含了合并排序算法的实现。'
- en: '![c12-fig-0005.jpg](../images/c12-fig-0005.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0005.jpg](../images/c12-fig-0005.jpg)'
- en: '[Figure 12-5](#c12-fig-0005a) Merge sort'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-5](#c12-fig-0005a) 合并排序'
- en: Notice that we have made the comparison operator a parameter of the `merge_sort`
    function and written a lambda expression to supply a default value. So, for example,
    the code
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们将比较操作符作为`merge_sort`函数的参数，并编写了一个lambda表达式来提供默认值。因此，例如，代码
- en: '[PRE2]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: prints
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 打印
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's analyze the complexity of `merge_sort`. We already know that the time
    complexity of `merge` is order *θ*`(len(L))`. At each level of recursion the total
    number of elements to be merged is `len(L)`. Therefore, the time complexity of
    `merge_sort` is order *θ*`(len(``L``))` multiplied by the number of levels of
    recursion. Since `merge_sort` divides the list in half each time, we know that
    the number of levels of recursion is `order` *θ*`(log(len(``L``))`. Therefore,
    the time complexity of `merge_sort` is *θ*`(n`*`log(n))`, where `n` is `len(L)`.[^(76)](#c12-fn-0009)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下`merge_sort`的复杂度。我们已经知道`merge`的时间复杂度是*θ*`(len(L))`。在每一层递归中，要合并的元素总数是`len(L)`。因此，`merge_sort`的时间复杂度是*θ*`(len(``L``))`乘以递归层数。由于`merge_sort`每次将列表分成两半，我们知道递归层数是*θ*`(log(len(``L``)))`。因此，`merge_sort`的时间复杂度是*θ*`(n`*`log(n))`，其中`n`是`len(L)`。[^(76)](#c12-fn-0009)
- en: This is a lot better than selection sort's *θ*`(len(``L``)`²`)`. For example,
    if `L` has `10,000` elements, `len(``L``)`² is `100` million but `len(``L``)`*`log`[2]`(len(``L``))`
    is about `130,000`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这比选择排序的*θ*`(len(``L``)`²`)好得多。例如，如果`L`有`10,000`个元素，`len(``L``)`²是`100`百万，但`len(``L``)`*`log`[2]`(len(``L``))`大约是`130,000`。
- en: This improvement in time complexity comes with a price. Selection sort is an
    example of an **in-place** sorting algorithm. Because it works by swapping the
    place of elements within the list, it uses only a constant amount of extra storage
    (one element in our implementation). In contrast, the merge sort algorithm involves
    making copies of the list. This means that its space complexity is order *θ*`(len(``L``))`.
    This can be an issue for large lists.[^(77)](#c12-fn-0010)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这种时间复杂度的改进是有代价的。选择排序是**就地**排序算法的一个例子。因为它通过交换列表中的元素位置来工作，所以只使用了常量数量的额外存储（在我们的实现中是一个元素）。相比之下，合并排序算法涉及对列表的复制。这意味着它的空间复杂度是*θ*`(len(``L``))`。这对于大型列表来说可能是一个问题。[^(77)](#c12-fn-0010)
- en: Suppose we want to sort a list of names written as first name followed by last
    name, e.g., the list `['Chris Terman', ‘Tom Brady', 'Eric Grimson', 'Gisele Bundchen']`.
    [Figure 12-6](#c12-fig-0006) defines two ordering functions, and then uses these
    to sort a list in two different ways. Each function uses the `split` method of
    type `str`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想对以名字和姓氏书写的名字列表进行排序，例如，列表`['Chris Terman', ‘Tom Brady', 'Eric Grimson',
    'Gisele Bundchen']`。[图12-6](#c12-fig-0006)定义了两个排序函数，然后用这两个函数以两种不同方式对列表进行排序。每个函数使用了`str`类型的`split`方法。
- en: '![c12-fig-0006.jpg](../images/c12-fig-0006.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0006.jpg](../images/c12-fig-0006.jpg)'
- en: '[Figure 12-6](#c12-fig-0006a) Sorting a list of names'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-6](#c12-fig-0006a) 对名字列表进行排序'
- en: When the code in [Figure 12-6](#c12-fig-0006) is run, it prints
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行[图12-6](#c12-fig-0006)中的代码时，它打印
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Finger exercise**: Use `merge_sort` to sort a list to tuples of integers.
    The sorting order should be determined by the sum of the integers in the tuple.
    For example, `(5, 2)` should precede `(1, 8)` and follow `(1, 2, 3)`.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**手指练习**：使用`merge_sort`对整数元组列表进行排序。排序顺序应由元组中整数的总和决定。例如，`(5, 2)`应在`(1, 8)`之前，并在`(1,
    2, 3)`之后。'
- en: 12.2.2 Sorting in Python
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.2 Python中的排序
- en: The sorting algorithm used in most Python implementations is called **timsort**.[^(78)](#c12-fn-0011)
    The key idea is to take advantage of the fact that in a lot of data sets, the
    data are already partially sorted. Timsort's worst-case performance is the same
    as merge sort's, but on average it performs considerably better.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数Python实现中使用的排序算法称为**timsort**。[^(78)](#c12-fn-0011) 关键思想是利用许多数据集中数据已经部分排序的事实。Timsort的最坏情况性能与归并排序相同，但平均性能明显更好。
- en: As mentioned earlier, the Python method `list.sort` takes a list as its first
    argument and modifies that list. In contrast, the Python function `sorted` takes
    an iterable object (e.g., a list or a view) as its first argument and returns
    a new sorted list. For example, the code
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Python方法`list.sort`将列表作为第一个参数并修改该列表。相比之下，Python函数`sorted`将可迭代对象（例如列表或视图）作为第一个参数并返回一个新的排序列表。例如，代码
- en: '[PRE5]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: will print
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 将打印
- en: '[PRE6]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice that when the `sorted` function is applied to a dictionary, it returns
    a sorted list of the keys of the dictionary. In contrast, when the `sort` method
    is applied to a dictionary, it causes an exception to be raised since there is
    no method `dict.sort`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当`sorted`函数应用于字典时，它返回字典键的排序列表。相比之下，当对字典应用`sort`方法时，会引发异常，因为没有`dict.sort`方法。
- en: 'Both the `list.sort` method and the `sorted` function can have two additional
    parameters. The `key` parameter plays the same role as `compare` in our implementation
    of merge sort: it supplies the comparison function to be used. The `reverse` parameter
    specifies whether the list is to be sorted in ascending or descending order relative
    to the comparison function. For example, the code'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`list.sort`方法和`sorted`函数可以有两个额外参数。`key`参数在我们实现的归并排序中与`compare`的作用相同：它提供要使用的比较函数。`reverse`参数指定列表是相对于比较函数按升序还是降序排序。例如，代码'
- en: '[PRE7]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: sorts the elements of `L` in reverse order of length and prints
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 按长度反向顺序对`L`的元素进行排序并打印
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Both the `list.sort` method and the `sorted` function provide **stable sorts**.
    This means that if two elements are equal with respect to the comparison (`len`
    in this example) used in the sort, their relative ordering in the original list
    (or other iterable object) is preserved in the final list. (Since no key can occur
    more than once in a `dict`, the question of whether `sorted` is stable when applied
    to a `dict` is moot.)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`list.sort`方法和`sorted`函数都提供**稳定排序**。这意味着如果两个元素在排序中根据比较（在这个例子中是`len`）是相等的，它们在原始列表（或其他可迭代对象）中的相对顺序会在最终列表中保留。（由于在`dict`中没有键可以出现多次，应用于`dict`时`sorted`是否稳定的问题无关紧要。）'
- en: '**Finger exercise**: Is `merge_sort` a stable sort?'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**指尖练习**：`merge_sort`是稳定排序吗？'
- en: 12.3 Hash Tables
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 哈希表
- en: If we put merge sort together with binary search, we have a nice way to search
    lists. We use merge sort to preprocess the list in order *θ*`(n`*`log(n))` time,
    and then we use binary search to test whether elements are in the list in order
    *θ*`log(n))` time. If we search the list `k` times, the overall time complexity
    is order *θ*`(n`*`log(n) + k`*`log(n))`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将归并排序与二分搜索结合起来，就有了一种很好的方式来搜索列表。我们使用归并排序在*θ*`(n`*`log(n))` 时间内预处理列表，然后用二分搜索测试元素是否在列表中，这样的时间复杂度是*θ*`log(n))`。如果我们搜索列表`k`次，总体时间复杂度是*θ*`(n`*`log(n)
    + k`*`log(n))`。
- en: This is good, but we can still ask, is logarithmic the best that we can do for
    search when we are willing to do some preprocessing?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但我们仍然可以问，当我们愿意进行一些预处理时，是否对搜索来说对数是我们能做到的最佳？
- en: When we introduced the type `dict` in Chapter 5, we said that dictionaries use
    a technique called hashing to do the lookup in time that is nearly independent
    of the size of the dictionary. The basic idea behind a **hash table** is simple.
    We convert the key to an integer, and then use that integer to index into a list,
    which can be done in constant time. In principle, values of any type can be easily
    converted to an integer. After all, we know that the internal representation of
    each object is a sequence of bits, and any sequence of bits can be viewed as representing
    an integer. For example, the internal representation of the string `'abc'` is
    the sequence of bits `011000010110001001100011`, which can be viewed as a representation
    of the decimal integer `6,382,179`. Of course, if we want to use the internal
    representation of strings as indices into a list, the list is going to have to
    be pretty darn long.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在第5章介绍类型`dict`时，我们提到字典使用一种称为哈希的技术，以几乎与字典大小无关的时间进行查找。**哈希表**的基本思想很简单。我们将键转换为整数，然后使用该整数在列表中进行索引，这可以在常数时间内完成。原则上，任何类型的值都可以轻松转换为整数。毕竟，我们知道每个对象的内部表示是一系列位，任何位序列都可以视为表示一个整数。例如，字符串`'abc'`的内部表示是位序列`011000010110001001100011`，可以视为十进制整数`6,382,179`的表示。当然，如果我们想将字符串的内部表示用作列表的索引，列表将不得不相当长。
- en: What about situations where the keys are already integers? Imagine, for the
    moment, that we are implementing a dictionary all of whose keys are U.S. Social
    Security numbers, which are nine-digit integers. If we represented the dictionary
    by a list with `10`⁹ elements and used Social Security numbers to index into the
    list, we could do lookups in constant time. Of course, if the dictionary contained
    entries for only ten thousand (`10`⁴) people, this would waste quite a lot of
    space.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当键已经是整数时呢？暂时想象一下，我们正在实现一个字典，所有键都是美国社会安全号码，九位整数。如果我们用包含`10`⁹个元素的列表来表示字典，并使用社会安全号码作为索引，我们可以以常数时间进行查找。当然，如果字典只包含一万（`10`⁴）人的条目，这将浪费很多空间。
- en: Which gets us to the subject of hash functions. A **hash function** maps a large
    space of inputs (e.g., all natural numbers) to a smaller space of outputs (e.g.,
    the natural numbers between `0` and `5000`). Hash functions can be used to convert
    a large space of keys to a smaller space of integer indices.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们进入哈希函数的话题。**哈希函数**将大量输入空间（例如，所有自然数）映射到较小的输出空间（例如，介于`0`和`5000`之间的自然数）。哈希函数可以用来将大量键转换为较小的整数索引空间。
- en: Since the space of possible outputs is smaller than the space of possible inputs,
    a hash function is a **many-to-one mapping**, i.e., multiple different inputs
    may be mapped to the same output. When two inputs are mapped to the same output,
    it is called a **collision**—a topic we will return to shortly. A good hash function
    produces a **uniform distribution**; i.e., every output in the range is equally
    probable, which minimizes the probability of collisions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可能输出的空间小于可能输入的空间，哈希函数是一种**多对一映射**，即多个不同的输入可能映射到相同的输出。当两个输入映射到相同的输出时，这被称为**碰撞**——我们将很快回到这个话题。一个好的哈希函数产生**均匀分布**；即范围内的每个输出都是同样可能的，从而最小化碰撞的概率。
- en: '[Figure 12-7](#c12-fig-0007) uses a simple hash function (recall that `i%j`
    returns the remainder when the integer `i` is divided by the integer `j`) to implement
    a dictionary with integers as keys.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12-7](#c12-fig-0007)使用了一个简单的哈希函数（回忆一下`i%j`返回整数`i`除以整数`j`的余数）来实现一个以整数为键的字典。'
- en: The basic idea is to represent an instance of class `Int_dict` by a list of
    **hash** **buckets**, where each bucket is a list of key/value pairs implemented
    as tuples. By making each bucket a list, we handle collisions by storing all of
    the values that hash to the same bucket in the list.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是通过一组**哈希****桶**表示`Int_dict`类的实例，其中每个桶是实现为元组的键/值对的列表。通过将每个桶作为列表，我们通过将所有哈希到同一桶的值存储在列表中来处理碰撞。
- en: 'The hash table works as follows: The instance variable `buckets` is initialized
    to a list of `num_buckets` empty lists. To store or look up an entry with key
    `key`, we use the hash function `%` to convert `key` into an integer and use that
    integer to index into `buckets` to find the hash bucket associated with `key`.
    We then search that bucket (which, remember, is a list) linearly to see if there
    is an entry with the key `key`. If we are doing a lookup and there is an entry
    with the key, we simply return the value stored with that key. If there is no
    entry with that key, we return `None`. If a value is to be stored, we first check
    if there is already an entry with that key in the hash bucket. If so, we replace
    the entry with a new tuple; otherwise we append a new entry to the bucket.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表的工作原理如下：实例变量`buckets`被初始化为一个包含`num_buckets`个空列表的列表。要存储或查找具有键`key`的条目，我们使用哈希函数`%`将`key`转换为整数，并使用该整数索引到`buckets`中以找到与`key`关联的哈希桶。然后我们在线性搜索该桶（记住，它是一个列表），以查看是否有与键`key`的条目。如果我们正在查找并且有该键的条目，我们就简单地返回存储的值。如果没有该键的条目，我们返回`None`。如果要存储一个值，我们首先检查哈希桶中是否已经存在该键的条目。如果是，我们用一个新的元组替换该条目；否则我们将新的条目追加到桶中。
- en: There are many other ways to handle collisions, some considerably more efficient
    than using lists. But this is probably the simplest mechanism, and it works fine
    if the hash table is large enough relative to the number of elements stored in
    it, and the hash function provides a good enough approximation to a uniform distribution.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 处理碰撞还有许多其他方法，有些比使用列表高效得多。但这可能是最简单的机制，如果哈希表相对于存储的元素数量足够大，并且哈希函数提供了足够好的均匀分布近似，这种方法效果很好。
- en: '![c12-fig-0007.jpg](../images/c12-fig-0007.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![c12-fig-0007.jpg](../images/c12-fig-0007.jpg)'
- en: '[Figure 12-7](#c12-fig-0007a) Implementing dictionaries using hashing'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-7](#c12-fig-0007a) 使用哈希实现字典'
- en: Notice that the `__str__` method produces a representation of a dictionary that
    is unrelated to the order in which elements were added to it, but is instead ordered
    by the values to which the keys happen to hash.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`__str__`方法产生的字典表示与添加元素的顺序无关，而是按键的哈希值的顺序排列。
- en: The following code first constructs an `Int_dict` with 17 buckets and 20 entries.
    The values of the entries are the integers `0` to `19`. The keys are chosen at
    random, using `random.choice`, from integers in the range `0` to `10`⁵ `- 1`.
    (We discuss the `random` module in Chapters 16 and 17.) The code then prints the
    `Int_dict` using the `__str__` method defined in the class.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码首先构造一个包含17个桶和20个条目的`Int_dict`。条目的值是整数`0`到`19`。键是随机选择的，使用`random.choice`从范围`0`到`10`⁵
    `- 1`的整数中选择。（我们在第16章和第17章讨论`random`模块。）然后代码使用类中定义的`__str__`方法打印`Int_dict`。
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: When we ran this code it printed[^(79)](#c12-fn-0012)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码时，它打印了[^(79)](#c12-fn-0012)
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The following code prints the individual hash buckets by iterating over `D.buckets`.
    (This is a terrible violation of information hiding, but pedagogically useful.)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码通过迭代`D.buckets`打印各个哈希桶。（这严重违反了信息隐藏，但在教学上是有用的。）
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When we ran this code it printed
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码时，它打印了
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: When we violate the abstraction barrier and peek at the representation of the
    `Int_dict`, we see that some of the hash buckets are empty. Others contain one
    or more entries—depending upon the number of collisions that occurred.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们违反抽象边界并查看`Int_dict`的表示时，我们看到一些哈希桶是空的。其他桶则包含一个或多个条目——这取决于发生的碰撞数量。
- en: What is the complexity of `get_value`? If there were no collisions it would
    be `constant time b`ecause each hash bucket would be of length 0 or 1\. But, of
    course, there might be collisions. If everything hashed to the same bucket, it
    would be `linear in` the number of entries in the dictionary, because the code
    would perform a linear search on that hash bucket. By making the hash table large
    enough, we can reduce the number of collisions sufficiently to allow us to treat
    the complexity as `constant time.` That is, we can trade space for time. But what
    is the tradeoff? To answer this question, we need to use a tiny bit of probability,
    so we defer the answer to Chapter 17.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_value`的复杂度是什么？如果没有碰撞，它将是`常数时间`，因为每个哈希桶的长度将是0或1。但当然，可能会发生碰撞。如果所有内容都哈希到同一个桶，它将在字典中的条目数量上是`线性的`，因为代码将在该哈希桶上执行线性搜索。通过使哈希表足够大，我们可以减少碰撞的数量，从而将复杂度视为`常数时间`。也就是说，我们可以用空间换取时间。但是，这种权衡是什么？要回答这个问题，我们需要使用一点概率，所以我们将答案推迟到第17章。'
- en: 12.4 Terms Introduced in Chapter
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 在章节中介绍的术语
- en: search algorithm
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索算法
- en: search space
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索空间
- en: pointer
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指针
- en: indirection
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 间接寻址
- en: binary search
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二分查找
- en: wrapper function
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包装函数
- en: amortized complexity
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平摊复杂度
- en: selection sort
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择排序
- en: loop invariant
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环不变式
- en: divide and conquer algorithms
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分治算法
- en: recursive base
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归基
- en: merge sort
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归并排序
- en: in-place sort
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原地排序
- en: quicksort
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速排序
- en: timsort
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TimSort
- en: stable sort
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳定排序
- en: hash table
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哈希表
- en: hash function
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哈希函数
- en: many-to-one mapping
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多对一映射
- en: collision
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冲突
- en: uniform distribution
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均匀分布
- en: hash bucket
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哈希桶
