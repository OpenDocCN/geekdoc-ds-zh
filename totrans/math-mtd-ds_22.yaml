- en: 3.5\. Gradient descent and its convergence analysis#
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap03_opt/05_gd/roch-mmids-opt-gd.html](https://mmids-textbook.github.io/chap03_opt/05_gd/roch-mmids-opt-gd.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We consider a natural approach for solving optimization problems numerically:
    a class of algorithms known as descent methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let \(f : \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable. We
    restrict ourselves to unconstrained minimization problems of the form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{\mathbf{x} \in \mathbb{R}^d} f(\mathbf{x}). \]
  prefs: []
  type: TYPE_NORMAL
- en: Ideally one would like to identify a global minimizer of \(f\). A naive approach
    might be to evaluate \(f\) at a large number of points \(\mathbf{x}\), say on
    a dense grid. However, even if we were satisfied with an approximate solution
    and limited ourselves to a bounded subset of the domain of \(f\), this type of
    [exhaustive search](https://en.wikipedia.org/wiki/Brute-force_search) is wasteful
    and impractical in large dimension \(d\), as the number of points interrogated
    grows exponentially with \(d\).
  prefs: []
  type: TYPE_NORMAL
- en: A less naive approach might be to find all stationary points of \(f\), that
    is, those \(\mathbf{x}\) such that \(\nabla f(\mathbf{x}) = \mathbf{0}\). And
    then choose an \(\mathbf{x}\) among them that produces the smallest value of \(f(\mathbf{x})\).
    This indeed works in many problems, like the following example we have encountered
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(Least Squares)** Consider again the least squares problem\(\idx{least
    squares problem}\xdi\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{\mathbf{x} \in \mathbb{R}^d} \|A \mathbf{x} - \mathbf{b}\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(A \in \mathbb{R}^{n \times d}\) has full column rank and \(\mathbf{b}
    \in \mathbb{R}^n\). In particular, \(d \leq n\). We saw in a previous example
    that the objective function is a quadratic function
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}) = \frac{1}{2} \mathbf{x}^T P \mathbf{x} + \mathbf{q}^T \mathbf{x}
    + r, \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(P = 2 A^T A\) is symmetric, \(\mathbf{q} = - 2 A^T \mathbf{b}\), and
    \(r= \mathbf{b}^T \mathbf{b} = \|\mathbf{b}\|^2\). We also showed that \(f\) is
    \(\mu\)-strongly convex. So there is a unique global minimizer.
  prefs: []
  type: TYPE_NORMAL
- en: By a previous calculation,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \nabla f(\mathbf{x}) = P \mathbf{x} + \mathbf{q} = 2 A^T A \mathbf{x} - 2
    A^T \mathbf{b}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So the stationary points satisfy
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^T A \mathbf{x} = A^T \mathbf{b} \]
  prefs: []
  type: TYPE_NORMAL
- en: which you may recognize as the normal equations\(\idx{normal equations}\xdi\)
    for the least-squares problem. \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, identifying stationary points often leads to systems of nonlinear
    equations that do not have explicit solutions. Hence we resort to a different
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.1\. Gradient descent[#](#gradient-descent "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In gradient descent, we attempt to find smaller values of \(f\) by successively
    following directions in which \(f\) decreases locally. As we have seen in the
    proof of the *First-Order Necessary Optimality Condition*, \(- \nabla f\) provides
    such a direction. In fact, it is the direction of steepest descent in the following
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: Recall from the *Descent Direction and Directional Derivative Lemma* that \(\mathbf{v}\)
    is a descent direction at \(\mathbf{x}_0\) if the directional derivative of \(f\)
    at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is negative.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Steepest Descent)** \(\idx{steepest descent lemma}\xdi\) Let \(f
    : \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable at \(\mathbf{x}_0\).
    For any unit vector \(\mathbf{v} \in \mathbb{R}^d\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} \geq \frac{\partial
    f (\mathbf{x}_0)}{\partial \mathbf{v}^*} \]
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{v}^* = - \frac{\nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* This is an immediate application of the *Cauchy-Schwarz inequality*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By the *Cauchy-Schwarz inequality*, since \(\mathbf{v}\) has unit
    norm,'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \left|\frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}\right|
    &= \left|\nabla f(\mathbf{x}_0)^T \mathbf{v}\right|\\ &\leq \|\nabla f(\mathbf{x}_0)\|
    \|\mathbf{v}\|\\ &= \|\nabla f(\mathbf{x}_0)\|. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Or, put differently,
  prefs: []
  type: TYPE_NORMAL
- en: \[ - \|\nabla f(\mathbf{x}_0)\| \leq \frac{\partial f (\mathbf{x}_0)}{\partial
    \mathbf{v}} \leq \|\nabla f(\mathbf{x}_0)\|. \]
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, by the choice of \(\mathbf{v}^*\),
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}^*} &=
    \nabla f(\mathbf{x}_0)^T \left(- \frac{\nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \left(\frac{\nabla f(\mathbf{x}_0)^T \nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \left(\frac{\|\nabla f(\mathbf{x}_0)\|^2}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \|\nabla f(\mathbf{x}_0)\|. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The last two displays combined give the result. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: At each iteration of gradient descent, we take a step in the direction of the
    negative of the gradient, that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{x}^{t+1} = \mathbf{x}^t - \alpha_t \nabla f(\mathbf{x}^t), \quad
    t=0,1,2\ldots \]
  prefs: []
  type: TYPE_NORMAL
- en: for a sequence of step sizes \(\alpha_t > 0\). Choosing the right step size
    (also known as steplength or learning rate) is a large subject in itself. We will
    only consider the case of fixed step size here.
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Ask your favorite AI chatbot about the different approaches
    for selecting a step size in gradient descent methods. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, we will not be able to guarantee that a global minimizer is reached
    in the limit, even if one exists. Our goal for now is more modest: to find a point
    where the gradient of \(f\) approximately vanishes.'
  prefs: []
  type: TYPE_NORMAL
- en: We implement gradient descent\(\idx{gradient descent}\xdi\) in Python. We assume
    that a function `f` and its gradient `grad_f` are provided. We first code the
    basic steepest descent step with a step size\(\idx{step size}\xdi\) \(\idx{learning
    rate}\xdi\) \(\alpha =\) `alpha`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**NUMERICAL CORNER:** We illustrate on a simple example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/0697c218312ddc584b4a0edc5e583702b6afa69be250f4eac766440ceda0f7d2.png](../Images/8fbfd5ba011f320f65a37c311822755c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We found a global minmizer in this case.
  prefs: []
  type: TYPE_NORMAL
- en: The next example shows that a different local minimizer may be reached depending
    on the starting point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/48729baf93e6b40366984a812582a50a90890a4c4e42f79a718f921c414b5b55.png](../Images/c2b85b3ea7eba3a62567ae4ff6962fca.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**TRY IT!** In this last example, does changing the step size affect the outcome?
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: In the final example, we end up at a stationary point that is not a local minimizer.
    Here both the first and second derivatives are zero. This is known as a [saddle
    point](https://en.wikipedia.org/wiki/Saddle_point).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/68a876bde430631abb6621a64c476ac59b86424854df7da519e2a8ba40834bcf.png](../Images/b3363868479c1ce17160f5f595b4b954.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.2\. Convergence analysis[#](#convergence-analysis "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we prove some results about the convergence\(\idx{convergence
    analysis}\xdi\) of gradient descent. We start with the smooth case.
  prefs: []
  type: TYPE_NORMAL
- en: '**Smooth case** Informally, a function is smooth if its gradient does not change
    too fast. The formal definition we will use here follows. We restrict ourselves
    to the twice continuously differentiable case.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Smooth Function)** \(\idx{smooth function}\xdi\) Let \(f
    : \mathbb{R}^d \to \mathbb{R}\) be twice continuously differentiable. We say that
    \(f\) is \(L\)-smooth if'
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L I_{d \times d} \preceq H_f(\mathbf{x}) \preceq L I_{d \times d}, \quad
    \forall \mathbf{x} \in \mathbb{R}^d. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: In the single-variable case, this reduces to \(- L \leq f''(x) \leq L\) for
    all \(x \in \mathbb{R}\). More generally, recall that
  prefs: []
  type: TYPE_NORMAL
- en: \[ A \preceq B \iff \mathbf{z}^T A\mathbf{z} \leq \mathbf{z}^T B\mathbf{z},
    \qquad \forall \mathbf{z} \in \mathbb{R}^{d}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So the condition above is equivalent to
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \|\mathbf{z}\|^2 \leq \mathbf{z}^T H_f(\mathbf{x}) \,\mathbf{z} \leq
    L \|\mathbf{z}\|^2, \quad \forall \mathbf{x}, \mathbf{z} \in \mathbb{R}^d. \]
  prefs: []
  type: TYPE_NORMAL
- en: A different way to put this is that the second directional derivative satisfies
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \leq \frac{\partial^2 f (\mathbf{x})}{\partial \mathbf{v}^2} \leq L \]
  prefs: []
  type: TYPE_NORMAL
- en: for all \(\mathbf{x} \in \mathbb{R}^d\) and all unit vectors \(\mathbf{v} \in
    \mathbb{R}^d\).
  prefs: []
  type: TYPE_NORMAL
- en: Combined with *Taylor’s Theorem*, this gives immediately the following.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Quadratic Bound for Smooth Functions)** \(\idx{quadratic bound
    for smooth functions}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\) be twice continuously
    differentiable. Then \(f\) is \(L\)-smooth if and only if for all \(\mathbf{x},
    \mathbf{y} \in \mathbb{R}^d\) it holds that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|f(\mathbf{y}) - \{f(\mathbf{x}) + \nabla f(\mathbf{x})^T(\mathbf{y}
    - \mathbf{x})\}\right| \leq \frac{L}{2} \|\mathbf{y} - \mathbf{x}\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* We apply the *Taylor’s Theorem*, then bound the second-order
    term.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By *Taylor’s Theorem*, for any \(\alpha > 0\) there is \(\xi_\alpha
    \in (0,1)\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x} + \alpha \mathbf{p}) = f(\mathbf{x}) + \alpha \nabla f(\mathbf{x})^T
    \mathbf{p} + \frac{1}{2} \alpha^2 \mathbf{p}^T \,H_f(\mathbf{x} + \xi_\alpha \alpha
    \mathbf{p}) \,\mathbf{p} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{p} = \mathbf{y} - \mathbf{x}\).
  prefs: []
  type: TYPE_NORMAL
- en: If \(f\) is \(L\)-smooth, then at \(\alpha = 1\) by the observation above
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \|\mathbf{p}\|^2 \leq \mathbf{p}^T \,H_f(\mathbf{x} + \xi_1 \mathbf{p})
    \,\mathbf{p} \leq L \|\mathbf{p}\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: That implies the inequality in the statement.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if that inequality holds, by combining with the Taylor expansion
    above we get
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|\,\frac{1}{2} \alpha^2 \mathbf{p}^T \,H_f(\mathbf{x} + \xi_\alpha \alpha
    \mathbf{p}) \,\mathbf{p}\,\right| \leq \frac{L}{2} \alpha^2 \|\mathbf{p}\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(\|\alpha \mathbf{p}\| = \alpha \|\mathbf{p}\|\) by absolute
    homogeneity of the norm. Dividing by \(\alpha^2/2\), then taking \(\alpha \to
    0\) and using the continuity of the Hessian gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|\, \mathbf{p}^T \,H_f(\mathbf{x}) \,\mathbf{p} \,\right| \leq L \|\mathbf{p}\|^2.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: By the observation above again, that implies that \(f\) is \(L\)-smooth. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We show next that, in the smooth case, steepest descent with an appropriately
    chosen step size produces a sequence of points whose objective values decrease
    (or stay the same) and whose gradients vanish in the limit. We also give a quantitative
    convergence rate. Note that this result does not imply convergence to a local
    (or global) minimizer.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence of Gradient Descent in the Smooth Case)** \(\idx{convergence
    of gradient descent in the smooth case}\xdi\) Suppose that \(f : \mathbb{R}^d
    \to \mathbb{R}\) is \(L\)-smooth and bounded from below, that is, there is \(\bar{f}
    > - \infty\) such that \(f(\mathbf{x}) \geq \bar{f}\), \(\forall \mathbf{x} \in
    \mathbb{R}^d\). Then gradient descent with step size \(\alpha_t = \alpha := 1/L\)
    started from any \(\mathbf{x}^0\) produces a sequence \(\mathbf{x}^t\), \(t=1,2,\ldots\)
    such that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t), \quad \forall t \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} \|\nabla f(\mathbf{x}^t)\| = 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, after \(S\) steps, there is a \(t\) in \(\{0,\ldots,S\}\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2 L \left[\,f(\mathbf{x}^0) -
    \bar{f}\,\right]}{S}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: The assumption that a lower bound on \(f\) is known may seem far-fetched. But
    there are in fact many settings where this is natural. For instance, in the case
    of the least-squares problem, the objective function \(f\) is non-negative by
    definition and therefore we can take \(\bar{f} = 0\).
  prefs: []
  type: TYPE_NORMAL
- en: A different way to put the claim above regarding the convergence rate is the
    following. Take any \(\epsilon > 0\). If our goal is to find a point \(\mathbf{x}\)
    such that \(\|\nabla f(\mathbf{x})\| \leq \epsilon\), then we are guaranteed to
    find one if we perform \(S\) steps such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{t = 0,\ldots, S-1} \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2 L
    \left[\,f(\mathbf{x}^0) - \bar{f}\,\right]}{S}} \leq \epsilon, \]
  prefs: []
  type: TYPE_NORMAL
- en: that is, after rearranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ S \geq \frac{2L [f(\mathbf{x}^0) - \bar{f}]}{\epsilon^2}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The heart of the proof is the following fundamental inequality. It also informs
    the choice of step size.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Descent Guarantee in the Smooth Case)** \(\idx{descent guarantee
    in the smooth case}\xdi\) Suppose that \(f : \mathbb{R}^d \to \mathbb{R}\) is
    \(L\)-smooth. For any \(\mathbf{x} \in \mathbb{R}^d\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f\left(\mathbf{x} - \frac{1}{L} \nabla f(\mathbf{x})\right) \leq f(\mathbf{x})
    - \frac{1}{2 L} \|\nabla f(\mathbf{x})\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Descent Guarantee in the Smooth Case):* Intuitively, the *Quadratic
    Bound for Smooth Functions* shows that \(f\) is well approximated by a quadratic
    function in a neighborhood of \(\mathbf{x}\) whose size depends on the smoothness
    parameter \(L\). Choosing a step size that minimizes this approximation leads
    to a guaranteed improvement. The approach taken here is a special case of what
    is referred to as [Majorize-Minimization (MM)](https://en.wikipedia.org/wiki/MM_algorithm)\(\idx{Majorize-Minimization}\xdi\).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Descent Guarantee in the Smooth Case)* By the *Quadratic Bound for
    Smooth Functions*, letting \(\mathbf{p} = - \nabla f(\mathbf{x})\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x} + \alpha \mathbf{p}) &\leq f(\mathbf{x}) + \nabla
    f(\mathbf{x})^T (\alpha \mathbf{p}) + \frac{L}{2} \|\alpha \mathbf{p}\|^2\\ &=
    f(\mathbf{x}) - \alpha \|\nabla f(\mathbf{x})\|^2 + \alpha^2 \frac{L}{2} \|\nabla
    f(\mathbf{x})\|^2\\ &= f(\mathbf{x}) + \left( - \alpha + \alpha^2 \frac{L}{2}
    \right) \|\nabla f(\mathbf{x})\|^2. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The quadratic function in parentheses is convex and minimized at the stationary
    point \(\alpha\) satisfying
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\mathrm{d}}{\mathrm{d} \alpha}\left( - \alpha + \alpha^2 \frac{L}{2}
    \right) = -1 + \alpha L = 0\. \]
  prefs: []
  type: TYPE_NORMAL
- en: Taking \(\alpha = 1/L\), where \(-\alpha + \alpha^2 \frac{L}{2} = - \frac{1}{2L}\),
    and replacing in the inequality above gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ f\left(\mathbf{x} - \frac{1}{L} \nabla f(\mathbf{x})\right) \leq f(\mathbf{x})
    - \frac{1}{2L}\|\nabla f(\mathbf{x})\|^2, \]
  prefs: []
  type: TYPE_NORMAL
- en: as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We return to the proof of the theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Convergence of Gradient Descent in the Smooth Case):* We use a
    telescoping argument to write \(f(\mathbf{x}^S)\) as a sum of stepwise increments,
    each of which can be bounded by the previous lemma. Because \(f(\mathbf{x}^S)\)
    is bounded from below, it then follows that the gradients must vanish in the limit.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Convergence of Gradient Descent in the Smooth Case)* By the *Descent
    Guarantee in the Smooth Case*,'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t) - \frac{1}{2 L}\|\nabla f(\mathbf{x}^t)\|^2
    \leq f(\mathbf{x}^t), \quad \forall t. \]
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, using a telescoping sum, we get
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x}^S) &= f(\mathbf{x}^0) + \sum_{t=0}^{S-1} [f(\mathbf{x}^{t+1})
    - f(\mathbf{x}^t)]\\ &\leq f(\mathbf{x}^0) - \frac{1}{2 L}\sum_{t=0}^{S-1} \|\nabla
    f(\mathbf{x}^t)\|^2\. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Rearranging and using \(f(\mathbf{x}^S) \geq \bar{f}\) leads to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{t=0}^{S-1} \|\nabla f(\mathbf{x}^t)\|^2 \leq 2L [f(\mathbf{x}^0) -
    \bar{f}]. \]
  prefs: []
  type: TYPE_NORMAL
- en: We get the quantitative bound
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \min_{t=0,\ldots, S-1} \|\nabla f(\mathbf{x}^t)\|^2 & \leq
    \frac{1}{S} \sum_{t=0}^{S-1} \|\nabla f(\mathbf{x}^t)\|^2\\ &\leq \frac{2L [f(\mathbf{x}^0)
    - \bar{f}]}{S} \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: as the minimum is necessarily less or equal than the average. Moreover, as \(S
    \to +\infty\), we must have \(\|\nabla f(\mathbf{x}^S)\|^2 \to 0\) by standard
    [analytical](https://math.stackexchange.com/questions/62389/relationships-between-bounded-and-convergent-series)
    [arguments](https://math.stackexchange.com/questions/107961/if-a-series-converges-then-the-sequence-of-terms-converges-to-0).
    That proves the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**Smooth and strongly convex case** With stronger assumptions, we obtain stronger
    convergence results. One such assumption is strong convexity, which we defined
    in the previous section for twice continuously differentiable functions.'
  prefs: []
  type: TYPE_NORMAL
- en: We prove a convergence result for smooth, strongly convex functions. We show
    something stronger this time. We control the value of \(f\) itself and obtain
    a much faster rate of convergence. If \(f\) is \(m\)-strongly convex and has a
    global minimizer \(\mathbf{x}^*\), then the global minimizer is unique and characterized
    by \(\nabla f(\mathbf{x}^*) = \mathbf{0}\). Strong convexity allows us to relate
    the value of the function at a point \(\mathbf{x}\) and the gradient of \(f\)
    at that point. This is proved in the following lemma, which is key to our convergence
    result.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Relating a function and its gradient)** \(\idx{relating a function
    and its gradient lemma}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\) be twice
    continuously differentiable, \(m\)-strongly convex with a global minimizer at
    \(\mathbf{x}^*\). Then for any \(\mathbf{x} \in \mathbb{R}^d\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}) - f(\mathbf{x}^*) \leq \frac{\|\nabla f(\mathbf{x})\|^2}{2
    m}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By the *Quadratic Bound for Strongly Convex Functions*,'
  prefs: []
  type: TYPE_NORMAL
- en: '\[\begin{align*} f(\mathbf{x}^*) &\geq f(\mathbf{x}) + \nabla f(\mathbf{x})^T
    (\mathbf{x}^* - \mathbf{x}) + \frac{m}{2} \|\mathbf{x}^* - \mathbf{x}\|^2\\ &=
    f(\mathbf{x}) + \nabla f(\mathbf{x})^T \mathbf{w} + \frac{1}{2} \mathbf{w}^T (m
    I_{d \times d}) \,\mathbf{w}\\ &=: r + \mathbf{q}^T \mathbf{w} + \frac{1}{2} \mathbf{w}^T
    P \,\mathbf{w} \end{align*}\]'
  prefs: []
  type: TYPE_NORMAL
- en: where on the second line we defined \(\mathbf{w} = \mathbf{x}^* - \mathbf{x}\).
    The right-hand side is a quadratic function in \(\mathbf{w}\) (for \(\mathbf{x}\)
    fixed), and on the third line we used our previous notation \(P\), \(\mathbf{q}\)
    and \(r\) for such a function. So the inequality is still valid if we replace
    \(\mathbf{w}\) with the global minimizer \(\mathbf{w}^*\) of that quadratic function.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix \(P = m I_{d \times d}\) is positive definite. By a previous example,
    we know that the minimizer is achieved when the gradient \(\frac{1}{2}[P + P^T]\mathbf{w}^*
    + \mathbf{q} = \mathbf{0}\), which is equivalent to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{w}^* = - (m I_{d \times d})^{-1} \nabla f(\mathbf{x}) = - (m^{-1}
    I_{d \times d}) \nabla f(\mathbf{x}) = - \frac{1}{m} \nabla f(\mathbf{x}). \]
  prefs: []
  type: TYPE_NORMAL
- en: So, replacing \(\mathbf{w}\) with \(\mathbf{w}^*\), we have the inequality
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x}^*) & \geq f(\mathbf{x}) + \nabla f(\mathbf{x})^T
    \left\{- \frac{1}{m} \nabla f(\mathbf{x})\right\}\\ & \quad \quad+ \frac{1}{2}
    \left\{- \frac{1}{m} \nabla f(\mathbf{x})\right\}^T (m I_{d \times d}) \left\{-
    \frac{1}{m} \nabla f(\mathbf{x})\right\}\\ & = f(\mathbf{x}) - \frac{1}{2m} \|\nabla
    f(\mathbf{x})\|^2. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Rearranging gives the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We can now state our convergence result.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence of Gradient Descent in the Strongly Convex Case)**
    \(\idx{convergence of gradient descent in the strongly convex case}\xdi\) Suppose
    that \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and \(m\)-strongly convex
    with a global minimizer at \(\mathbf{x}^*\). Then gradient descent with step size
    \(\alpha = 1/L\) started from any \(\mathbf{x}^0\) produces a sequence \(\mathbf{x}^t\),
    \(t=1,2,\ldots\) such that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} f(\mathbf{x}^t) = f(\mathbf{x}^*). \]
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, after \(S\) steps, we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)^S [f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Observe that \(f(\mathbf{x}^S) - f(\mathbf{x}^*)\) decreases exponentially fast
    in \(S\). A related bound can be proved for \(\|\mathbf{x}^S - \mathbf{x}^*\|\).
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, fix any \(\epsilon > 0\). If our goal is to find a point \(\mathbf{x}\)
    such that \(f(\mathbf{x}) - f(\mathbf{x}^*) \leq \epsilon\), then we are guaranteed
    to find one if we perform \(S\) steps such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)^S [f(\mathbf{x}^0)
    - f(\mathbf{x}^*)] \leq \epsilon \]
  prefs: []
  type: TYPE_NORMAL
- en: that is, after rearranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ S \geq \frac{\log \epsilon^{-1} + \log(f(\mathbf{x}^0) - \bar{f})}{\log \left(1
    - \frac{m}{L}\right)^{-1}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Convergence of Gradient Descent in the Strongly Convex Case):*
    We apply the *Descent Guarantee for Smooth Functions* together with the lemma
    above.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Convergence of Gradient Descent in the Strongly Convex Case)* By
    the *Descent Guarantee for Smooth Functions* together with the lemma above, we
    have for all \(t\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t) - \frac{1}{2L} \|\nabla f(\mathbf{x}^t)\|^2
    \leq f(\mathbf{x}^t) - \frac{m}{L} [f(\mathbf{x}^t) - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: Subtracting \(f(\mathbf{x}^*)\) on both sides gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)[f(\mathbf{x}^t)
    - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: Recursing this is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \leq \left(1 - \frac{m}{L}\right)^2[f(\mathbf{x}^{t-1}) - f(\mathbf{x}^*)],
    \]
  prefs: []
  type: TYPE_NORMAL
- en: and so on. That gives the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We revisit our first simple single-variable example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The second derivative is \(f''(x) = 2\). Hence, this \(f\) is \(L\)-smooth and
    \(m\)-strongly convex with \(L = m = 2\). The theory we developed suggests taking
    step size \(\alpha_t = \alpha = 1/L = 1/2\). It also implies that
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(x^1) - f(x^*) \leq \left(1 - \frac{m}{L}\right) [f(x^0) - f(x^*)] = 0.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We converge in one step! And that holds for any starting point \(x^0\).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try this!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Let’s try a different starting point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** In the gradient descent update rule \(\mathbf{x}^{t+1} = \mathbf{x}^t
    - \alpha_t \nabla f(\mathbf{x}^t)\), what does \(\alpha_t\) represent?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The gradient of \(f\) at \(\mathbf{x}^t\)
  prefs: []
  type: TYPE_NORMAL
- en: b) The step size or learning rate
  prefs: []
  type: TYPE_NORMAL
- en: c) The direction of steepest ascent
  prefs: []
  type: TYPE_NORMAL
- en: d) The Hessian matrix of \(f\) at \(\mathbf{x}^t\)
  prefs: []
  type: TYPE_NORMAL
- en: '**2** A function \(f : \mathbb{R}^d \to \mathbb{R}\) is said to be \(L\)-smooth
    if:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\|\nabla f(\mathbf{x})\| \leq L\) for all \(\mathbf{x} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(-LI_{d\times d} \preceq \mathbf{H}_f(\mathbf{x}) \preceq LI_{d\times d}\)
    for all \(\mathbf{x} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(f(\mathbf{y}) \leq f(\mathbf{x}) + \nabla f(\mathbf{x})^T(\mathbf{y} -
    \mathbf{x}) + \frac{L}{2}\|\mathbf{y} - \mathbf{x}\|^2\) for all \(\mathbf{x},
    \mathbf{y} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: d) Both b) and c)
  prefs: []
  type: TYPE_NORMAL
- en: '**3** Suppose \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and bounded
    from below. According to the *Convergence of Gradient Descent in the Smooth Case*
    theorem, gradient descent with step size \(\alpha_t = 1/L\) started from any \(\mathbf{x}^0\)
    produces a sequence \(\{\mathbf{x}^t\}\) such that'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\lim_{t \to +\infty} f(\mathbf{x}^t) = 0\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\lim_{t \to +\infty} \|\nabla f(\mathbf{x}^t)\| = 0\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(\min_{t=0,\ldots,S-1} \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2L[f(\mathbf{x}^0)
    - \bar{f}]}{S}}\) after \(S\) steps
  prefs: []
  type: TYPE_NORMAL
- en: d) Both b) and c)
  prefs: []
  type: TYPE_NORMAL
- en: '**4** Suppose \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and \(m\)-strongly
    convex with a global minimizer at \(\mathbf{x}^*\). According to the *Convergence
    of Gradient Descent in th Strongly Convex Case* theorem, gradient descent with
    step size \(\alpha = 1/L\) started from any \(\mathbf{x}^0\) produces a sequence
    \(\{\mathbf{x}^t\}\) such that after \(S\) steps:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq (1 - \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \geq (1 - \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq (1 + \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \geq (1 + \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: '**5** If a function \(f\) is \(m\)-strongly convex, what can we say about its
    global minimizer?'
  prefs: []
  type: TYPE_NORMAL
- en: a) It may not exist.
  prefs: []
  type: TYPE_NORMAL
- en: b) It exists and is unique.
  prefs: []
  type: TYPE_NORMAL
- en: c) It exists but may not be unique.
  prefs: []
  type: TYPE_NORMAL
- en: d) It always occurs at the origin.
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: b. Justification: The text states “At each iteration of gradient
    descent, we take a step in the direction of the negative of the gradient, that
    is, \(\mathbf{x}^{t+1} = \mathbf{x}^t - \alpha_t \nabla f(\mathbf{x}^t), t = 0,
    1, 2, \ldots\) for a sequence of step sizes \(\alpha_t > 0\).”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: d. Justification: The text provides both the definition in terms
    of the Hessian matrix (option b) and the equivalent characterization in terms
    of the quadratic bound (option c).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: d. Justification: The theorem states both the asymptotic convergence
    of the gradients to zero (option b) and the quantitative bound on the minimum
    gradient norm after \(S\) steps (option c).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: This is the convergence rate stated in the
    theorem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: b. Justification: The text states that if \(f\) is \(m\)-strongly
    convex, then “the global minimizer is unique.”'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.1\. Gradient descent[#](#gradient-descent "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In gradient descent, we attempt to find smaller values of \(f\) by successively
    following directions in which \(f\) decreases locally. As we have seen in the
    proof of the *First-Order Necessary Optimality Condition*, \(- \nabla f\) provides
    such a direction. In fact, it is the direction of steepest descent in the following
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: Recall from the *Descent Direction and Directional Derivative Lemma* that \(\mathbf{v}\)
    is a descent direction at \(\mathbf{x}_0\) if the directional derivative of \(f\)
    at \(\mathbf{x}_0\) in the direction \(\mathbf{v}\) is negative.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Steepest Descent)** \(\idx{steepest descent lemma}\xdi\) Let \(f
    : \mathbb{R}^d \to \mathbb{R}\) be continuously differentiable at \(\mathbf{x}_0\).
    For any unit vector \(\mathbf{v} \in \mathbb{R}^d\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}} \geq \frac{\partial
    f (\mathbf{x}_0)}{\partial \mathbf{v}^*} \]
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{v}^* = - \frac{\nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* This is an immediate application of the *Cauchy-Schwarz inequality*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By the *Cauchy-Schwarz inequality*, since \(\mathbf{v}\) has unit
    norm,'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \left|\frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}}\right|
    &= \left|\nabla f(\mathbf{x}_0)^T \mathbf{v}\right|\\ &\leq \|\nabla f(\mathbf{x}_0)\|
    \|\mathbf{v}\|\\ &= \|\nabla f(\mathbf{x}_0)\|. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Or, put differently,
  prefs: []
  type: TYPE_NORMAL
- en: \[ - \|\nabla f(\mathbf{x}_0)\| \leq \frac{\partial f (\mathbf{x}_0)}{\partial
    \mathbf{v}} \leq \|\nabla f(\mathbf{x}_0)\|. \]
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, by the choice of \(\mathbf{v}^*\),
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \frac{\partial f (\mathbf{x}_0)}{\partial \mathbf{v}^*} &=
    \nabla f(\mathbf{x}_0)^T \left(- \frac{\nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \left(\frac{\nabla f(\mathbf{x}_0)^T \nabla f(\mathbf{x}_0)}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \left(\frac{\|\nabla f(\mathbf{x}_0)\|^2}{\|\nabla f(\mathbf{x}_0)\|}\right)\\
    &= - \|\nabla f(\mathbf{x}_0)\|. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The last two displays combined give the result. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: At each iteration of gradient descent, we take a step in the direction of the
    negative of the gradient, that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{x}^{t+1} = \mathbf{x}^t - \alpha_t \nabla f(\mathbf{x}^t), \quad
    t=0,1,2\ldots \]
  prefs: []
  type: TYPE_NORMAL
- en: for a sequence of step sizes \(\alpha_t > 0\). Choosing the right step size
    (also known as steplength or learning rate) is a large subject in itself. We will
    only consider the case of fixed step size here.
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Ask your favorite AI chatbot about the different approaches
    for selecting a step size in gradient descent methods. \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, we will not be able to guarantee that a global minimizer is reached
    in the limit, even if one exists. Our goal for now is more modest: to find a point
    where the gradient of \(f\) approximately vanishes.'
  prefs: []
  type: TYPE_NORMAL
- en: We implement gradient descent\(\idx{gradient descent}\xdi\) in Python. We assume
    that a function `f` and its gradient `grad_f` are provided. We first code the
    basic steepest descent step with a step size\(\idx{step size}\xdi\) \(\idx{learning
    rate}\xdi\) \(\alpha =\) `alpha`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**NUMERICAL CORNER:** We illustrate on a simple example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/0697c218312ddc584b4a0edc5e583702b6afa69be250f4eac766440ceda0f7d2.png](../Images/8fbfd5ba011f320f65a37c311822755c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We found a global minmizer in this case.
  prefs: []
  type: TYPE_NORMAL
- en: The next example shows that a different local minimizer may be reached depending
    on the starting point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/48729baf93e6b40366984a812582a50a90890a4c4e42f79a718f921c414b5b55.png](../Images/c2b85b3ea7eba3a62567ae4ff6962fca.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '**TRY IT!** In this last example, does changing the step size affect the outcome?
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: In the final example, we end up at a stationary point that is not a local minimizer.
    Here both the first and second derivatives are zero. This is known as a [saddle
    point](https://en.wikipedia.org/wiki/Saddle_point).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/68a876bde430631abb6621a64c476ac59b86424854df7da519e2a8ba40834bcf.png](../Images/b3363868479c1ce17160f5f595b4b954.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.2\. Convergence analysis[#](#convergence-analysis "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we prove some results about the convergence\(\idx{convergence
    analysis}\xdi\) of gradient descent. We start with the smooth case.
  prefs: []
  type: TYPE_NORMAL
- en: '**Smooth case** Informally, a function is smooth if its gradient does not change
    too fast. The formal definition we will use here follows. We restrict ourselves
    to the twice continuously differentiable case.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Smooth Function)** \(\idx{smooth function}\xdi\) Let \(f
    : \mathbb{R}^d \to \mathbb{R}\) be twice continuously differentiable. We say that
    \(f\) is \(L\)-smooth if'
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L I_{d \times d} \preceq H_f(\mathbf{x}) \preceq L I_{d \times d}, \quad
    \forall \mathbf{x} \in \mathbb{R}^d. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: In the single-variable case, this reduces to \(- L \leq f''(x) \leq L\) for
    all \(x \in \mathbb{R}\). More generally, recall that
  prefs: []
  type: TYPE_NORMAL
- en: \[ A \preceq B \iff \mathbf{z}^T A\mathbf{z} \leq \mathbf{z}^T B\mathbf{z},
    \qquad \forall \mathbf{z} \in \mathbb{R}^{d}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So the condition above is equivalent to
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \|\mathbf{z}\|^2 \leq \mathbf{z}^T H_f(\mathbf{x}) \,\mathbf{z} \leq
    L \|\mathbf{z}\|^2, \quad \forall \mathbf{x}, \mathbf{z} \in \mathbb{R}^d. \]
  prefs: []
  type: TYPE_NORMAL
- en: A different way to put this is that the second directional derivative satisfies
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \leq \frac{\partial^2 f (\mathbf{x})}{\partial \mathbf{v}^2} \leq L \]
  prefs: []
  type: TYPE_NORMAL
- en: for all \(\mathbf{x} \in \mathbb{R}^d\) and all unit vectors \(\mathbf{v} \in
    \mathbb{R}^d\).
  prefs: []
  type: TYPE_NORMAL
- en: Combined with *Taylor’s Theorem*, this gives immediately the following.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Quadratic Bound for Smooth Functions)** \(\idx{quadratic bound
    for smooth functions}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\) be twice continuously
    differentiable. Then \(f\) is \(L\)-smooth if and only if for all \(\mathbf{x},
    \mathbf{y} \in \mathbb{R}^d\) it holds that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|f(\mathbf{y}) - \{f(\mathbf{x}) + \nabla f(\mathbf{x})^T(\mathbf{y}
    - \mathbf{x})\}\right| \leq \frac{L}{2} \|\mathbf{y} - \mathbf{x}\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* We apply the *Taylor’s Theorem*, then bound the second-order
    term.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By *Taylor’s Theorem*, for any \(\alpha > 0\) there is \(\xi_\alpha
    \in (0,1)\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x} + \alpha \mathbf{p}) = f(\mathbf{x}) + \alpha \nabla f(\mathbf{x})^T
    \mathbf{p} + \frac{1}{2} \alpha^2 \mathbf{p}^T \,H_f(\mathbf{x} + \xi_\alpha \alpha
    \mathbf{p}) \,\mathbf{p} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\mathbf{p} = \mathbf{y} - \mathbf{x}\).
  prefs: []
  type: TYPE_NORMAL
- en: If \(f\) is \(L\)-smooth, then at \(\alpha = 1\) by the observation above
  prefs: []
  type: TYPE_NORMAL
- en: \[ - L \|\mathbf{p}\|^2 \leq \mathbf{p}^T \,H_f(\mathbf{x} + \xi_1 \mathbf{p})
    \,\mathbf{p} \leq L \|\mathbf{p}\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: That implies the inequality in the statement.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if that inequality holds, by combining with the Taylor expansion
    above we get
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|\,\frac{1}{2} \alpha^2 \mathbf{p}^T \,H_f(\mathbf{x} + \xi_\alpha \alpha
    \mathbf{p}) \,\mathbf{p}\,\right| \leq \frac{L}{2} \alpha^2 \|\mathbf{p}\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(\|\alpha \mathbf{p}\| = \alpha \|\mathbf{p}\|\) by absolute
    homogeneity of the norm. Dividing by \(\alpha^2/2\), then taking \(\alpha \to
    0\) and using the continuity of the Hessian gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ \left|\, \mathbf{p}^T \,H_f(\mathbf{x}) \,\mathbf{p} \,\right| \leq L \|\mathbf{p}\|^2.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: By the observation above again, that implies that \(f\) is \(L\)-smooth. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We show next that, in the smooth case, steepest descent with an appropriately
    chosen step size produces a sequence of points whose objective values decrease
    (or stay the same) and whose gradients vanish in the limit. We also give a quantitative
    convergence rate. Note that this result does not imply convergence to a local
    (or global) minimizer.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence of Gradient Descent in the Smooth Case)** \(\idx{convergence
    of gradient descent in the smooth case}\xdi\) Suppose that \(f : \mathbb{R}^d
    \to \mathbb{R}\) is \(L\)-smooth and bounded from below, that is, there is \(\bar{f}
    > - \infty\) such that \(f(\mathbf{x}) \geq \bar{f}\), \(\forall \mathbf{x} \in
    \mathbb{R}^d\). Then gradient descent with step size \(\alpha_t = \alpha := 1/L\)
    started from any \(\mathbf{x}^0\) produces a sequence \(\mathbf{x}^t\), \(t=1,2,\ldots\)
    such that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t), \quad \forall t \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} \|\nabla f(\mathbf{x}^t)\| = 0. \]
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, after \(S\) steps, there is a \(t\) in \(\{0,\ldots,S\}\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2 L \left[\,f(\mathbf{x}^0) -
    \bar{f}\,\right]}{S}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: The assumption that a lower bound on \(f\) is known may seem far-fetched. But
    there are in fact many settings where this is natural. For instance, in the case
    of the least-squares problem, the objective function \(f\) is non-negative by
    definition and therefore we can take \(\bar{f} = 0\).
  prefs: []
  type: TYPE_NORMAL
- en: A different way to put the claim above regarding the convergence rate is the
    following. Take any \(\epsilon > 0\). If our goal is to find a point \(\mathbf{x}\)
    such that \(\|\nabla f(\mathbf{x})\| \leq \epsilon\), then we are guaranteed to
    find one if we perform \(S\) steps such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min_{t = 0,\ldots, S-1} \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2 L
    \left[\,f(\mathbf{x}^0) - \bar{f}\,\right]}{S}} \leq \epsilon, \]
  prefs: []
  type: TYPE_NORMAL
- en: that is, after rearranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ S \geq \frac{2L [f(\mathbf{x}^0) - \bar{f}]}{\epsilon^2}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The heart of the proof is the following fundamental inequality. It also informs
    the choice of step size.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Descent Guarantee in the Smooth Case)** \(\idx{descent guarantee
    in the smooth case}\xdi\) Suppose that \(f : \mathbb{R}^d \to \mathbb{R}\) is
    \(L\)-smooth. For any \(\mathbf{x} \in \mathbb{R}^d\),'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f\left(\mathbf{x} - \frac{1}{L} \nabla f(\mathbf{x})\right) \leq f(\mathbf{x})
    - \frac{1}{2 L} \|\nabla f(\mathbf{x})\|^2. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Descent Guarantee in the Smooth Case):* Intuitively, the *Quadratic
    Bound for Smooth Functions* shows that \(f\) is well approximated by a quadratic
    function in a neighborhood of \(\mathbf{x}\) whose size depends on the smoothness
    parameter \(L\). Choosing a step size that minimizes this approximation leads
    to a guaranteed improvement. The approach taken here is a special case of what
    is referred to as [Majorize-Minimization (MM)](https://en.wikipedia.org/wiki/MM_algorithm)\(\idx{Majorize-Minimization}\xdi\).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Descent Guarantee in the Smooth Case)* By the *Quadratic Bound for
    Smooth Functions*, letting \(\mathbf{p} = - \nabla f(\mathbf{x})\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x} + \alpha \mathbf{p}) &\leq f(\mathbf{x}) + \nabla
    f(\mathbf{x})^T (\alpha \mathbf{p}) + \frac{L}{2} \|\alpha \mathbf{p}\|^2\\ &=
    f(\mathbf{x}) - \alpha \|\nabla f(\mathbf{x})\|^2 + \alpha^2 \frac{L}{2} \|\nabla
    f(\mathbf{x})\|^2\\ &= f(\mathbf{x}) + \left( - \alpha + \alpha^2 \frac{L}{2}
    \right) \|\nabla f(\mathbf{x})\|^2. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: The quadratic function in parentheses is convex and minimized at the stationary
    point \(\alpha\) satisfying
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\mathrm{d}}{\mathrm{d} \alpha}\left( - \alpha + \alpha^2 \frac{L}{2}
    \right) = -1 + \alpha L = 0\. \]
  prefs: []
  type: TYPE_NORMAL
- en: Taking \(\alpha = 1/L\), where \(-\alpha + \alpha^2 \frac{L}{2} = - \frac{1}{2L}\),
    and replacing in the inequality above gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ f\left(\mathbf{x} - \frac{1}{L} \nabla f(\mathbf{x})\right) \leq f(\mathbf{x})
    - \frac{1}{2L}\|\nabla f(\mathbf{x})\|^2, \]
  prefs: []
  type: TYPE_NORMAL
- en: as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We return to the proof of the theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Convergence of Gradient Descent in the Smooth Case):* We use a
    telescoping argument to write \(f(\mathbf{x}^S)\) as a sum of stepwise increments,
    each of which can be bounded by the previous lemma. Because \(f(\mathbf{x}^S)\)
    is bounded from below, it then follows that the gradients must vanish in the limit.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Convergence of Gradient Descent in the Smooth Case)* By the *Descent
    Guarantee in the Smooth Case*,'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t) - \frac{1}{2 L}\|\nabla f(\mathbf{x}^t)\|^2
    \leq f(\mathbf{x}^t), \quad \forall t. \]
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, using a telescoping sum, we get
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x}^S) &= f(\mathbf{x}^0) + \sum_{t=0}^{S-1} [f(\mathbf{x}^{t+1})
    - f(\mathbf{x}^t)]\\ &\leq f(\mathbf{x}^0) - \frac{1}{2 L}\sum_{t=0}^{S-1} \|\nabla
    f(\mathbf{x}^t)\|^2\. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Rearranging and using \(f(\mathbf{x}^S) \geq \bar{f}\) leads to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \sum_{t=0}^{S-1} \|\nabla f(\mathbf{x}^t)\|^2 \leq 2L [f(\mathbf{x}^0) -
    \bar{f}]. \]
  prefs: []
  type: TYPE_NORMAL
- en: We get the quantitative bound
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \min_{t=0,\ldots, S-1} \|\nabla f(\mathbf{x}^t)\|^2 & \leq
    \frac{1}{S} \sum_{t=0}^{S-1} \|\nabla f(\mathbf{x}^t)\|^2\\ &\leq \frac{2L [f(\mathbf{x}^0)
    - \bar{f}]}{S} \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: as the minimum is necessarily less or equal than the average. Moreover, as \(S
    \to +\infty\), we must have \(\|\nabla f(\mathbf{x}^S)\|^2 \to 0\) by standard
    [analytical](https://math.stackexchange.com/questions/62389/relationships-between-bounded-and-convergent-series)
    [arguments](https://math.stackexchange.com/questions/107961/if-a-series-converges-then-the-sequence-of-terms-converges-to-0).
    That proves the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**Smooth and strongly convex case** With stronger assumptions, we obtain stronger
    convergence results. One such assumption is strong convexity, which we defined
    in the previous section for twice continuously differentiable functions.'
  prefs: []
  type: TYPE_NORMAL
- en: We prove a convergence result for smooth, strongly convex functions. We show
    something stronger this time. We control the value of \(f\) itself and obtain
    a much faster rate of convergence. If \(f\) is \(m\)-strongly convex and has a
    global minimizer \(\mathbf{x}^*\), then the global minimizer is unique and characterized
    by \(\nabla f(\mathbf{x}^*) = \mathbf{0}\). Strong convexity allows us to relate
    the value of the function at a point \(\mathbf{x}\) and the gradient of \(f\)
    at that point. This is proved in the following lemma, which is key to our convergence
    result.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Relating a function and its gradient)** \(\idx{relating a function
    and its gradient lemma}\xdi\) Let \(f : \mathbb{R}^d \to \mathbb{R}\) be twice
    continuously differentiable, \(m\)-strongly convex with a global minimizer at
    \(\mathbf{x}^*\). Then for any \(\mathbf{x} \in \mathbb{R}^d\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}) - f(\mathbf{x}^*) \leq \frac{\|\nabla f(\mathbf{x})\|^2}{2
    m}. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* By the *Quadratic Bound for Strongly Convex Functions*,'
  prefs: []
  type: TYPE_NORMAL
- en: '\[\begin{align*} f(\mathbf{x}^*) &\geq f(\mathbf{x}) + \nabla f(\mathbf{x})^T
    (\mathbf{x}^* - \mathbf{x}) + \frac{m}{2} \|\mathbf{x}^* - \mathbf{x}\|^2\\ &=
    f(\mathbf{x}) + \nabla f(\mathbf{x})^T \mathbf{w} + \frac{1}{2} \mathbf{w}^T (m
    I_{d \times d}) \,\mathbf{w}\\ &=: r + \mathbf{q}^T \mathbf{w} + \frac{1}{2} \mathbf{w}^T
    P \,\mathbf{w} \end{align*}\]'
  prefs: []
  type: TYPE_NORMAL
- en: where on the second line we defined \(\mathbf{w} = \mathbf{x}^* - \mathbf{x}\).
    The right-hand side is a quadratic function in \(\mathbf{w}\) (for \(\mathbf{x}\)
    fixed), and on the third line we used our previous notation \(P\), \(\mathbf{q}\)
    and \(r\) for such a function. So the inequality is still valid if we replace
    \(\mathbf{w}\) with the global minimizer \(\mathbf{w}^*\) of that quadratic function.
  prefs: []
  type: TYPE_NORMAL
- en: The matrix \(P = m I_{d \times d}\) is positive definite. By a previous example,
    we know that the minimizer is achieved when the gradient \(\frac{1}{2}[P + P^T]\mathbf{w}^*
    + \mathbf{q} = \mathbf{0}\), which is equivalent to
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mathbf{w}^* = - (m I_{d \times d})^{-1} \nabla f(\mathbf{x}) = - (m^{-1}
    I_{d \times d}) \nabla f(\mathbf{x}) = - \frac{1}{m} \nabla f(\mathbf{x}). \]
  prefs: []
  type: TYPE_NORMAL
- en: So, replacing \(\mathbf{w}\) with \(\mathbf{w}^*\), we have the inequality
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} f(\mathbf{x}^*) & \geq f(\mathbf{x}) + \nabla f(\mathbf{x})^T
    \left\{- \frac{1}{m} \nabla f(\mathbf{x})\right\}\\ & \quad \quad+ \frac{1}{2}
    \left\{- \frac{1}{m} \nabla f(\mathbf{x})\right\}^T (m I_{d \times d}) \left\{-
    \frac{1}{m} \nabla f(\mathbf{x})\right\}\\ & = f(\mathbf{x}) - \frac{1}{2m} \|\nabla
    f(\mathbf{x})\|^2. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: Rearranging gives the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: We can now state our convergence result.
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Convergence of Gradient Descent in the Strongly Convex Case)**
    \(\idx{convergence of gradient descent in the strongly convex case}\xdi\) Suppose
    that \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and \(m\)-strongly convex
    with a global minimizer at \(\mathbf{x}^*\). Then gradient descent with step size
    \(\alpha = 1/L\) started from any \(\mathbf{x}^0\) produces a sequence \(\mathbf{x}^t\),
    \(t=1,2,\ldots\) such that'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lim_{t \to +\infty} f(\mathbf{x}^t) = f(\mathbf{x}^*). \]
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, after \(S\) steps, we have
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)^S [f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: Observe that \(f(\mathbf{x}^S) - f(\mathbf{x}^*)\) decreases exponentially fast
    in \(S\). A related bound can be proved for \(\|\mathbf{x}^S - \mathbf{x}^*\|\).
  prefs: []
  type: TYPE_NORMAL
- en: Put differently, fix any \(\epsilon > 0\). If our goal is to find a point \(\mathbf{x}\)
    such that \(f(\mathbf{x}) - f(\mathbf{x}^*) \leq \epsilon\), then we are guaranteed
    to find one if we perform \(S\) steps such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)^S [f(\mathbf{x}^0)
    - f(\mathbf{x}^*)] \leq \epsilon \]
  prefs: []
  type: TYPE_NORMAL
- en: that is, after rearranging,
  prefs: []
  type: TYPE_NORMAL
- en: \[ S \geq \frac{\log \epsilon^{-1} + \log(f(\mathbf{x}^0) - \bar{f})}{\log \left(1
    - \frac{m}{L}\right)^{-1}}. \]
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea (Convergence of Gradient Descent in the Strongly Convex Case):*
    We apply the *Descent Guarantee for Smooth Functions* together with the lemma
    above.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* *(Convergence of Gradient Descent in the Strongly Convex Case)* By
    the *Descent Guarantee for Smooth Functions* together with the lemma above, we
    have for all \(t\)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) \leq f(\mathbf{x}^t) - \frac{1}{2L} \|\nabla f(\mathbf{x}^t)\|^2
    \leq f(\mathbf{x}^t) - \frac{m}{L} [f(\mathbf{x}^t) - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: Subtracting \(f(\mathbf{x}^*)\) on both sides gives
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(\mathbf{x}^{t+1}) - f(\mathbf{x}^*) \leq \left(1 - \frac{m}{L}\right)[f(\mathbf{x}^t)
    - f(\mathbf{x}^*)]. \]
  prefs: []
  type: TYPE_NORMAL
- en: Recursing this is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \leq \left(1 - \frac{m}{L}\right)^2[f(\mathbf{x}^{t-1}) - f(\mathbf{x}^*)],
    \]
  prefs: []
  type: TYPE_NORMAL
- en: and so on. That gives the claim. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We revisit our first simple single-variable example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The second derivative is \(f''(x) = 2\). Hence, this \(f\) is \(L\)-smooth and
    \(m\)-strongly convex with \(L = m = 2\). The theory we developed suggests taking
    step size \(\alpha_t = \alpha = 1/L = 1/2\). It also implies that
  prefs: []
  type: TYPE_NORMAL
- en: \[ f(x^1) - f(x^*) \leq \left(1 - \frac{m}{L}\right) [f(x^0) - f(x^*)] = 0.
    \]
  prefs: []
  type: TYPE_NORMAL
- en: We converge in one step! And that holds for any starting point \(x^0\).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try this!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Let’s try a different starting point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** In the gradient descent update rule \(\mathbf{x}^{t+1} = \mathbf{x}^t
    - \alpha_t \nabla f(\mathbf{x}^t)\), what does \(\alpha_t\) represent?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The gradient of \(f\) at \(\mathbf{x}^t\)
  prefs: []
  type: TYPE_NORMAL
- en: b) The step size or learning rate
  prefs: []
  type: TYPE_NORMAL
- en: c) The direction of steepest ascent
  prefs: []
  type: TYPE_NORMAL
- en: d) The Hessian matrix of \(f\) at \(\mathbf{x}^t\)
  prefs: []
  type: TYPE_NORMAL
- en: '**2** A function \(f : \mathbb{R}^d \to \mathbb{R}\) is said to be \(L\)-smooth
    if:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\|\nabla f(\mathbf{x})\| \leq L\) for all \(\mathbf{x} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(-LI_{d\times d} \preceq \mathbf{H}_f(\mathbf{x}) \preceq LI_{d\times d}\)
    for all \(\mathbf{x} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(f(\mathbf{y}) \leq f(\mathbf{x}) + \nabla f(\mathbf{x})^T(\mathbf{y} -
    \mathbf{x}) + \frac{L}{2}\|\mathbf{y} - \mathbf{x}\|^2\) for all \(\mathbf{x},
    \mathbf{y} \in \mathbb{R}^d\)
  prefs: []
  type: TYPE_NORMAL
- en: d) Both b) and c)
  prefs: []
  type: TYPE_NORMAL
- en: '**3** Suppose \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and bounded
    from below. According to the *Convergence of Gradient Descent in the Smooth Case*
    theorem, gradient descent with step size \(\alpha_t = 1/L\) started from any \(\mathbf{x}^0\)
    produces a sequence \(\{\mathbf{x}^t\}\) such that'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(\lim_{t \to +\infty} f(\mathbf{x}^t) = 0\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(\lim_{t \to +\infty} \|\nabla f(\mathbf{x}^t)\| = 0\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(\min_{t=0,\ldots,S-1} \|\nabla f(\mathbf{x}^t)\| \leq \sqrt{\frac{2L[f(\mathbf{x}^0)
    - \bar{f}]}{S}}\) after \(S\) steps
  prefs: []
  type: TYPE_NORMAL
- en: d) Both b) and c)
  prefs: []
  type: TYPE_NORMAL
- en: '**4** Suppose \(f : \mathbb{R}^d \to \mathbb{R}\) is \(L\)-smooth and \(m\)-strongly
    convex with a global minimizer at \(\mathbf{x}^*\). According to the *Convergence
    of Gradient Descent in th Strongly Convex Case* theorem, gradient descent with
    step size \(\alpha = 1/L\) started from any \(\mathbf{x}^0\) produces a sequence
    \(\{\mathbf{x}^t\}\) such that after \(S\) steps:'
  prefs: []
  type: TYPE_NORMAL
- en: a) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq (1 - \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: b) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \geq (1 - \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: c) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \leq (1 + \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: d) \(f(\mathbf{x}^S) - f(\mathbf{x}^*) \geq (1 + \frac{m}{L})^S[f(\mathbf{x}^0)
    - f(\mathbf{x}^*)]\)
  prefs: []
  type: TYPE_NORMAL
- en: '**5** If a function \(f\) is \(m\)-strongly convex, what can we say about its
    global minimizer?'
  prefs: []
  type: TYPE_NORMAL
- en: a) It may not exist.
  prefs: []
  type: TYPE_NORMAL
- en: b) It exists and is unique.
  prefs: []
  type: TYPE_NORMAL
- en: c) It exists but may not be unique.
  prefs: []
  type: TYPE_NORMAL
- en: d) It always occurs at the origin.
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: b. Justification: The text states “At each iteration of gradient
    descent, we take a step in the direction of the negative of the gradient, that
    is, \(\mathbf{x}^{t+1} = \mathbf{x}^t - \alpha_t \nabla f(\mathbf{x}^t), t = 0,
    1, 2, \ldots\) for a sequence of step sizes \(\alpha_t > 0\).”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: d. Justification: The text provides both the definition in terms
    of the Hessian matrix (option b) and the equivalent characterization in terms
    of the quadratic bound (option c).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: d. Justification: The theorem states both the asymptotic convergence
    of the gradients to zero (option b) and the quantitative bound on the minimum
    gradient norm after \(S\) steps (option c).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: a. Justification: This is the convergence rate stated in the
    theorem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: b. Justification: The text states that if \(f\) is \(m\)-strongly
    convex, then “the global minimizer is unique.”'
  prefs: []
  type: TYPE_NORMAL
