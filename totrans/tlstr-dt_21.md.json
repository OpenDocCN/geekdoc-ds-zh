["```py\nlibrary(arrow)\nlibrary(janitor)\nlibrary(lubridate)\nlibrary(mice)\nlibrary(modelsummary)\nlibrary(naniar)\nlibrary(opendatatoronto)\nlibrary(tidyverse)\nlibrary(tinytable)\n```", "```py\nus_populations <-\n state.x77 |>\n as_tibble() |>\n clean_names() |>\n mutate(state = rownames(state.x77)) |>\n select(state, population, income)\n\nus_populations\n```", "```py\n# A tibble: 50 × 3\n   state       population income\n   <chr>            <dbl>  <dbl>\n 1 Alabama           3615   3624\n 2 Alaska             365   6315\n 3 Arizona           2212   4530\n 4 Arkansas          2110   3378\n 5 California       21198   5114\n 6 Colorado          2541   4884\n 7 Connecticut       3100   5348\n 8 Delaware           579   4809\n 9 Florida           8277   4815\n10 Georgia           4931   4091\n# ℹ 40 more rows\n```", "```py\nus_populations |>\n head()\n```", "```py\n# A tibble: 6 × 3\n  state      population income\n  <chr>           <dbl>  <dbl>\n1 Alabama          3615   3624\n2 Alaska            365   6315\n3 Arizona          2212   4530\n4 Arkansas         2110   3378\n5 California      21198   5114\n6 Colorado         2541   4884\n```", "```py\nus_populations |>\n tail()\n```", "```py\n# A tibble: 6 × 3\n  state         population income\n  <chr>              <dbl>  <dbl>\n1 Vermont              472   3907\n2 Virginia            4981   4701\n3 Washington          3559   4864\n4 West Virginia       1799   3617\n5 Wisconsin           4589   4468\n6 Wyoming              376   4566\n```", "```py\nus_populations |>\n slice_sample(n = 6)\n```", "```py\n# A tibble: 6 × 3\n  state      population income\n  <chr>           <dbl>  <dbl>\n1 Michigan         9111   4751\n2 Missouri         4767   4254\n3 Louisiana        3806   3545\n4 Colorado         2541   4884\n5 Virginia         4981   4701\n6 Washington       3559   4864\n```", "```py\nus_populations |>\n glimpse()\n```", "```py\nRows: 50\nColumns: 3\n$ state      <chr> \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"…\n$ population <dbl> 3615, 365, 2212, 2110, 21198, 2541, 3100, 579, 8277, 4931, …\n$ income     <dbl> 3624, 6315, 4530, 3378, 5114, 4884, 5348, 4809, 4815, 4091,…\n```", "```py\nus_populations |>\n summary()\n```", "```py\n state             population        income    \n Length:50          Min.   :  365   Min.   :3098  \n Class :character   1st Qu.: 1080   1st Qu.:3993  \n Mode  :character   Median : 2838   Median :4519  \n                    Mean   : 4246   Mean   :4436  \n                    3rd Qu.: 4968   3rd Qu.:4814  \n                    Max.   :21198   Max.   :6315 \n```", "```py\nsample_means <- tibble(seed = c(), mean = c(), states_ignored = c())\n\nfor (i in c(1:5)) {\n set.seed(i)\n dont_get <- c(sample(x = state.name, size = 5))\n sample_means <-\n sample_means |>\n rbind(tibble(\n seed = i,\n mean =\n us_populations |>\n filter(!state %in% dont_get) |>\n summarise(mean = mean(population)) |>\n pull(),\n states_ignored = str_c(dont_get, collapse = \", \")\n ))\n}\n\nsample_means |>\n tt() |> \n style_tt(j = 1:3, align = \"lrr\") |> \n format_tt(digits = 0, num_mark_big = \",\", num_fmt = \"decimal\") |> \n setNames(c(\"Seed\", \"Mean\", \"Ignored states\"))\n```", "```py\nset.seed(853)\n\nremove_random_states <-\n sample(x = state.name, size = 3, replace = FALSE)\n\nus_states_MCAR <-\n us_populations |>\n mutate(\n population =\n if_else(state %in% remove_random_states, NA_real_, population)\n )\n\nsummary(us_states_MCAR)\n```", "```py\n state             population        income    \n Length:50          Min.   :  365   Min.   :3098  \n Class :character   1st Qu.: 1174   1st Qu.:3993  \n Mode  :character   Median : 2861   Median :4519  \n                    Mean   : 4308   Mean   :4436  \n                    3rd Qu.: 4956   3rd Qu.:4814  \n                    Max.   :21198   Max.   :6315  \n                    NA's   :3 \n```", "```py\nhighest_income_states <-\n us_populations |>\n slice_max(income, n = 3) |>\n pull(state)\n\nus_states_MAR <-\n us_populations |>\n mutate(population =\n if_else(state %in% highest_income_states, NA_real_, population)\n )\n\nsummary(us_states_MAR)\n```", "```py\n state             population        income    \n Length:50          Min.   :  376   Min.   :3098  \n Class :character   1st Qu.: 1101   1st Qu.:3993  \n Mode  :character   Median : 2816   Median :4519  \n                    Mean   : 4356   Mean   :4436  \n                    3rd Qu.: 5147   3rd Qu.:4814  \n                    Max.   :21198   Max.   :6315  \n                    NA's   :3 \n```", "```py\nhighest_population_states <-\n us_populations |>\n slice_max(population, n = 3) |>\n pull(state)\n\nus_states_MNAR <-\n us_populations |>\n mutate(population =\n if_else(state %in% highest_population_states,\n NA_real_,\n population))\n\nus_states_MNAR\n```", "```py\n# A tibble: 50 × 3\n   state       population income\n   <chr>            <dbl>  <dbl>\n 1 Alabama           3615   3624\n 2 Alaska             365   6315\n 3 Arizona           2212   4530\n 4 Arkansas          2110   3378\n 5 California          NA   5114\n 6 Colorado          2541   4884\n 7 Connecticut       3100   5348\n 8 Delaware           579   4809\n 9 Florida           8277   4815\n10 Georgia           4931   4091\n# ℹ 40 more rows\n```", "```py\nmultiple_imputation <-\n mice(\n us_states_MCAR,\n print = FALSE\n )\n\nmice_estimates <-\n complete(multiple_imputation) |>\n as_tibble()\n```", "```py\nall_2021_ttc_data <-\n list_package_resources(\"996cfe8d-fb35-40ce-b569-698d51fc683b\") |>\n filter(name == \"ttc-subway-delay-data-2021\") |>\n get_resource() |>\n bind_rows() |>\n clean_names()\n\nwrite_csv(all_2021_ttc_data, \"all_2021_ttc_data.csv\")\n\nall_2021_ttc_data\n```", "```py\n# A tibble: 16,370 × 10\n   date                time   day    station code  min_delay min_gap bound line \n   <dttm>              <time> <chr>  <chr>   <chr>     <dbl>   <dbl> <chr> <chr>\n 1 2021-01-01 00:00:00 00:33  Friday BLOOR … MUPAA         0       0 N     YU   \n 2 2021-01-01 00:00:00 00:39  Friday SHERBO… EUCO          5       9 E     BD   \n 3 2021-01-01 00:00:00 01:07  Friday KENNED… EUCD          5       9 E     BD   \n 4 2021-01-01 00:00:00 01:41  Friday ST CLA… MUIS          0       0 <NA>  YU   \n 5 2021-01-01 00:00:00 02:04  Friday SHEPPA… MUIS          0       0 <NA>  YU   \n 6 2021-01-01 00:00:00 02:35  Friday KENNED… MUIS          0       0 <NA>  BD   \n 7 2021-01-01 00:00:00 02:39  Friday VAUGHA… MUIS          0       0 <NA>  YU   \n 8 2021-01-01 00:00:00 06:00  Friday TORONT… MUO           0       0 <NA>  YU   \n 9 2021-01-01 00:00:00 06:00  Friday TORONT… MUO           0       0 <NA>  SHP  \n10 2021-01-01 00:00:00 06:00  Friday TORONT… MRO           0       0 <NA>  SRT  \n# ℹ 16,360 more rows\n# ℹ 1 more variable: vehicle <dbl>\n```", "```py\n# Data codebook\ndelay_codebook <-\n list_package_resources(\n \"996cfe8d-fb35-40ce-b569-698d51fc683b\"\n ) |>\n filter(name == \"ttc-subway-delay-data-readme\") |>\n get_resource() |>\n clean_names()\n\nwrite_csv(delay_codebook, \"delay_codebook.csv\")\n\n# Explanation for delay codes\ndelay_codes <-\n list_package_resources(\n \"996cfe8d-fb35-40ce-b569-698d51fc683b\"\n ) |>\n filter(name == \"ttc-subway-delay-codes\") |>\n get_resource() |>\n clean_names()\n\nwrite_csv(delay_codes, \"delay_codes.csv\")\n```", "```py\nunique(all_2021_ttc_data$day)\n```", "```py\n[1] \"Friday\"    \"Saturday\"  \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\"\n[7] \"Thursday\" \n```", "```py\nunique(all_2021_ttc_data$line)\n```", "```py\n [1] \"YU\"                     \"BD\"                     \"SHP\"                   \n [4] \"SRT\"                    \"YU/BD\"                  NA                      \n [7] \"YONGE/UNIVERSITY/BLOOR\" \"YU / BD\"                \"YUS\"                   \n[10] \"999\"                    \"SHEP\"                   \"36 FINCH WEST\"         \n[13] \"YUS & BD\"               \"YU & BD LINES\"          \"35 JANE\"               \n[16] \"52\"                     \"41 KEELE\"               \"YUS/BD\" \n```", "```py\ntable(all_2021_ttc_data$day)\n```", "```py\n Friday    Monday  Saturday    Sunday  Thursday   Tuesday Wednesday \n     2600      2434      2073      1942      2425      2481      2415 \n```", "```py\ntable(all_2021_ttc_data$line)\n```", "```py\n 35 JANE          36 FINCH WEST               41 KEELE \n                     1                      1                      1 \n                    52                    999                     BD \n                     1                      1                   5734 \n                  SHEP                    SHP                    SRT \n                     1                    657                    656 \nYONGE/UNIVERSITY/BLOOR                     YU                YU / BD \n                     1                   8880                     17 \n         YU & BD LINES                  YU/BD                    YUS \n                     1                    346                     18 \n              YUS & BD                 YUS/BD \n                     1                      1 \n```", "```py\ndelay_codebook |>\n filter(field_name == \"Line\")\n```", "```py\n# A tibble: 1 × 3\n  field_name description                               example\n  <chr>      <chr>                                     <chr>  \n1 Line       TTC subway line i.e. YU, BD, SHP, and SRT YU \n```", "```py\nall_2021_ttc_data_filtered_lines <-\n all_2021_ttc_data |>\n filter(line %in% c(\"YU\", \"BD\", \"SHP\", \"SRT\"))\n```", "```py\nget_dupes(all_2021_ttc_data_filtered_lines)\n```", "```py\n# A tibble: 36 × 11\n   date                time   day    station code  min_delay min_gap bound line \n   <dttm>              <time> <chr>  <chr>   <chr>     <dbl>   <dbl> <chr> <chr>\n 1 2021-09-13 00:00:00 06:00  Monday TORONT… MRO           0       0 <NA>  SRT  \n 2 2021-09-13 00:00:00 06:00  Monday TORONT… MRO           0       0 <NA>  SRT  \n 3 2021-09-13 00:00:00 06:00  Monday TORONT… MRO           0       0 <NA>  SRT  \n 4 2021-09-13 00:00:00 06:00  Monday TORONT… MUO           0       0 <NA>  SHP  \n 5 2021-09-13 00:00:00 06:00  Monday TORONT… MUO           0       0 <NA>  SHP  \n 6 2021-09-13 00:00:00 06:00  Monday TORONT… MUO           0       0 <NA>  SHP  \n 7 2021-03-31 00:00:00 05:45  Wedne… DUNDAS… MUNCA         0       0 <NA>  BD   \n 8 2021-03-31 00:00:00 05:45  Wedne… DUNDAS… MUNCA         0       0 <NA>  BD   \n 9 2021-06-08 00:00:00 14:40  Tuesd… VAUGHA… MUNOA         3       6 S     YU   \n10 2021-06-08 00:00:00 14:40  Tuesd… VAUGHA… MUNOA         3       6 S     YU   \n# ℹ 26 more rows\n# ℹ 2 more variables: vehicle <dbl>, dupe_count <int>\n```", "```py\nall_2021_ttc_data_no_dupes <-\n all_2021_ttc_data_filtered_lines |>\n distinct()\n```", "```py\nall_2021_ttc_data_no_dupes |>\n count(station) |>\n filter(str_detect(station, \"WEST\"))\n```", "```py\n# A tibble: 17 × 2\n   station                    n\n   <chr>                  <int>\n 1 DUNDAS WEST STATION      198\n 2 EGLINTON WEST STATION    142\n 3 FINCH WEST STATION       126\n 4 FINCH WEST TO LAWRENCE     3\n 5 FINCH WEST TO WILSON       1\n 6 LAWRENCE WEST CENTRE       1\n 7 LAWRENCE WEST STATION    127\n 8 LAWRENCE WEST TO EGLIN     1\n 9 SHEPPARD WEST - WILSON     1\n10 SHEPPARD WEST STATION    210\n11 SHEPPARD WEST TO LAWRE     3\n12 SHEPPARD WEST TO ST CL     2\n13 SHEPPARD WEST TO WILSO     7\n14 ST CLAIR WEST STATION    205\n15 ST CLAIR WEST TO ST AN     1\n16 ST. CLAIR WEST TO KING     1\n17 ST.CLAIR WEST TO ST.A      1\n```", "```py\nall_2021_ttc_data_no_dupes <-\n all_2021_ttc_data_no_dupes |>\n mutate(\n station_clean =\n case_when(\n str_starts(station, \"ST\") &\n str_detect(station, \"WEST\") ~ word(station, 1, 3),\n str_starts(station, \"ST\") ~ word(station, 1, 2),\n str_detect(station, \"WEST\") ~ word(station, 1, 2),\n TRUE ~ word(station, 1)\n )\n )\n\nall_2021_ttc_data_no_dupes\n```", "```py\n# A tibble: 15,908 × 11\n   date                time   day    station code  min_delay min_gap bound line \n   <dttm>              <time> <chr>  <chr>   <chr>     <dbl>   <dbl> <chr> <chr>\n 1 2021-01-01 00:00:00 00:33  Friday BLOOR … MUPAA         0       0 N     YU   \n 2 2021-01-01 00:00:00 00:39  Friday SHERBO… EUCO          5       9 E     BD   \n 3 2021-01-01 00:00:00 01:07  Friday KENNED… EUCD          5       9 E     BD   \n 4 2021-01-01 00:00:00 01:41  Friday ST CLA… MUIS          0       0 <NA>  YU   \n 5 2021-01-01 00:00:00 02:04  Friday SHEPPA… MUIS          0       0 <NA>  YU   \n 6 2021-01-01 00:00:00 02:35  Friday KENNED… MUIS          0       0 <NA>  BD   \n 7 2021-01-01 00:00:00 02:39  Friday VAUGHA… MUIS          0       0 <NA>  YU   \n 8 2021-01-01 00:00:00 06:00  Friday TORONT… MUO           0       0 <NA>  YU   \n 9 2021-01-01 00:00:00 06:00  Friday TORONT… MUO           0       0 <NA>  SHP  \n10 2021-01-01 00:00:00 06:00  Friday TORONT… MRO           0       0 <NA>  SRT  \n# ℹ 15,898 more rows\n# ℹ 2 more variables: vehicle <dbl>, station_clean <chr>\n```", "```py\nall_2021_ttc_data_no_dupes |>\n ggplot(aes(x = min_delay)) +\n geom_histogram(bins = 30)\n\nall_2021_ttc_data_no_dupes |>\n ggplot(aes(x = min_delay)) +\n geom_histogram(bins = 30) +\n scale_x_log10()\n```", "```py\nfix_organization_of_codes <-\n rbind(\n delay_codes |>\n select(sub_rmenu_code, code_description_3) |>\n mutate(type = \"sub\") |>\n rename(\n code = sub_rmenu_code,\n code_desc = code_description_3\n ),\n delay_codes |>\n select(srt_rmenu_code, code_description_7) |>\n mutate(type = \"srt\") |>\n rename(\n code = srt_rmenu_code,\n code_desc = code_description_7\n )\n )\n\nall_2021_ttc_data_no_dupes_with_explanation <-\n all_2021_ttc_data_no_dupes |>\n mutate(type = if_else(line == \"SRT\", \"srt\", \"sub\")) |>\n left_join(\n fix_organization_of_codes,\n by = c(\"type\", \"code\")\n )\n\nall_2021_ttc_data_no_dupes_with_explanation |>\n select(station_clean, code, min_delay, code_desc) |>\n arrange(-min_delay)\n```", "```py\n# A tibble: 15,908 × 4\n   station_clean code  min_delay code_desc                                  \n   <chr>         <chr>     <dbl> <chr>                                      \n 1 MUSEUM        PUTTP       348 Traction Power Rail Related                \n 2 EGLINTON      PUSTC       343 Signals - Track Circuit Problems           \n 3 WOODBINE      MUO         312 Miscellaneous Other                        \n 4 MCCOWAN       PRSL        275 Loop Related Failures                      \n 5 SHEPPARD WEST PUTWZ       255 Work Zone Problems - Track                 \n 6 ISLINGTON     MUPR1       207 Priority One - Train in Contact With Person\n 7 SHEPPARD WEST MUPR1       191 Priority One - Train in Contact With Person\n 8 ROYAL         SUAP        182 Assault / Patron Involved                  \n 9 ROYAL         MUPR1       180 Priority One - Train in Contact With Person\n10 SHEPPARD      MUPR1       171 Priority One - Train in Contact With Person\n# ℹ 15,898 more rows\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n ggplot() +\n geom_histogram(\n aes(\n x = min_delay,\n y = ..density..,\n fill = line\n ),\n position = \"dodge\",\n bins = 10\n ) +\n scale_x_log10()\n\nall_2021_ttc_data_no_dupes_with_explanation |>\n ggplot() +\n geom_histogram(\n aes(x = min_delay, fill = line),\n position = \"dodge\",\n bins = 10\n ) +\n scale_x_log10()\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n ggplot() +\n geom_histogram(\n aes(x = min_delay, fill = line),\n position = \"dodge\",\n bins = 10\n ) +\n scale_x_log10() +\n facet_wrap(vars(day)) +\n theme(legend.position = \"bottom\")\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n summarise(mean_delay = mean(min_delay), n_obs = n(),\n .by = c(line, station_clean)) |>\n filter(n_obs > 1) |>\n arrange(line, -mean_delay) |>\n slice(1:5, .by = line) |>\n ggplot(aes(station_clean, mean_delay)) +\n geom_col() +\n coord_flip() +\n facet_wrap(vars(line), scales = \"free_y\")\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n filter(min_delay > 0) |>\n mutate(week = week(date)) |>\n summarise(mean_delay = mean(min_delay),\n .by = c(week, line)) |>\n ggplot(aes(week, mean_delay, color = line)) +\n geom_point() +\n geom_smooth() +\n facet_wrap(vars(line), scales = \"free_y\")\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n mutate(week = week(date)) |>\n summarise(prop_delay = sum(min_delay > 10) / n(),\n .by = c(week, line)) |>\n ggplot(aes(week, prop_delay, color = line)) +\n geom_point() +\n geom_smooth() +\n facet_wrap(vars(line), scales = \"free_y\")\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n ggplot(aes(x = min_delay, y = min_gap, alpha = 0.1)) +\n geom_point() +\n scale_x_log10() +\n scale_y_log10()\n```", "```py\nall_2021_ttc_data_no_dupes_with_explanation |>\n summarise(mean_delay = mean(min_delay),\n .by = c(line, code_desc)) |>\n arrange(-mean_delay) |>\n slice(1:5) |>\n ggplot(aes(x = code_desc, y = mean_delay)) +\n geom_col() +\n facet_wrap(vars(line), scales = \"free_y\", nrow = 4) +\n coord_flip()\n```", "```py\nurl <-\n paste0(\n \"http://data.insideairbnb.com/united-kingdom/england/\",\n \"london/2023-03-14/data/listings.csv.gz\"\n )\n\nairbnb_data <-\n read_csv(\n file = url,\n guess_max = 20000\n )\n\nwrite_csv(airbnb_data, \"airbnb_data.csv\")\n\nairbnb_data\n```", "```py\nairbnb_data_selected <-\n airbnb_data |>\n select(\n host_id,\n host_response_time,\n host_is_superhost,\n host_total_listings_count,\n neighbourhood_cleansed,\n bathrooms,\n bedrooms,\n price,\n number_of_reviews,\n review_scores_rating,\n review_scores_accuracy,\n review_scores_value\n )\n\nwrite_parquet(\n x = airbnb_data_selected, \n sink = \n \"2023-03-14-london-airbnblistings-select_variables.parquet\"\n )\n\nrm(airbnb_data)\n```", "```py\nairbnb_data_selected$price |>\n head()\n```", "```py\n[1] \"$100.00\" \"$65.00\"  \"$132.00\" \"$100.00\" \"$120.00\" \"$43.00\" \n```", "```py\nairbnb_data_selected$price |>\n str_split(\"\") |>\n unlist() |>\n unique()\n```", "```py\n [1] \"$\" \"1\" \"0\" \".\" \"6\" \"5\" \"3\" \"2\" \"4\" \"9\" \"8\" \"7\" \",\"\n```", "```py\nairbnb_data_selected |>\n select(price) |>\n filter(str_detect(price, \",\"))\n```", "```py\n# A tibble: 1,629 × 1\n   price    \n   <chr>    \n 1 $3,070.00\n 2 $1,570.00\n 3 $1,480.00\n 4 $1,000.00\n 5 $1,100.00\n 6 $1,433.00\n 7 $1,800.00\n 8 $1,000.00\n 9 $1,000.00\n10 $1,000.00\n# ℹ 1,619 more rows\n```", "```py\nairbnb_data_selected <-\n airbnb_data_selected |>\n mutate(\n price = str_remove_all(price, \"[\\\\$,]\"),\n price = as.integer(price)\n )\n```", "```py\nairbnb_data_selected |>\n ggplot(aes(x = price)) +\n geom_histogram(binwidth = 10) +\n theme_classic() +\n labs(\n x = \"Price per night\",\n y = \"Number of properties\"\n )\n\nairbnb_data_selected |>\n filter(price > 1000) |>\n ggplot(aes(x = price)) +\n geom_histogram(binwidth = 10) +\n theme_classic() +\n labs(\n x = \"Price per night\",\n y = \"Number of properties\"\n ) +\n scale_y_log10()\n```", "```py\nairbnb_data_selected |>\n filter(price < 1000) |>\n ggplot(aes(x = price)) +\n geom_histogram(binwidth = 10) +\n theme_classic() +\n labs(\n x = \"Price per night\",\n y = \"Number of properties\"\n )\n\nairbnb_data_selected |>\n filter(price > 90) |>\n filter(price < 210) |>\n ggplot(aes(x = price)) +\n geom_histogram(binwidth = 1) +\n theme_classic() +\n labs(\n x = \"Price per night\",\n y = \"Number of properties\"\n )\n```", "```py\nairbnb_data_less_1000 <-\n airbnb_data_selected |>\n filter(price < 1000)\n```", "```py\nairbnb_data_less_1000 |>\n filter(is.na(host_is_superhost))\n```", "```py\n# A tibble: 13 × 12\n     host_id host_response_time host_is_superhost host_total_listings_count\n       <dbl> <chr>              <lgl>                                 <dbl>\n 1 317054510 within an hour     NA                                        5\n 2 316090383 within an hour     NA                                        6\n 3 315016947 within an hour     NA                                        2\n 4 374424554 within an hour     NA                                        2\n 5  97896300 N/A                NA                                       10\n 6 316083765 within an hour     NA                                        7\n 7 310628674 N/A                NA                                        5\n 8 179762278 N/A                NA                                       10\n 9 315037299 N/A                NA                                        1\n10 316090018 within an hour     NA                                        6\n11 375515965 within an hour     NA                                        2\n12 341372520 N/A                NA                                        7\n13 180634347 within an hour     NA                                        5\n# ℹ 8 more variables: neighbourhood_cleansed <chr>, bathrooms <lgl>,\n#   bedrooms <dbl>, price <int>, number_of_reviews <dbl>,\n#   review_scores_rating <dbl>, review_scores_accuracy <dbl>,\n#   review_scores_value <dbl>\n```", "```py\nairbnb_data_no_superhost_nas <-\n airbnb_data_less_1000 |>\n filter(!is.na(host_is_superhost)) |>\n mutate(\n host_is_superhost_binary =\n as.numeric(host_is_superhost)\n )\n```", "```py\nairbnb_data_no_superhost_nas |>\n ggplot(aes(x = review_scores_rating)) +\n geom_bar() +\n theme_classic() +\n labs(\n x = \"Review scores rating\",\n y = \"Number of properties\"\n )\n```", "```py\nairbnb_data_no_superhost_nas |>\n filter(is.na(review_scores_rating)) |>\n nrow()\n```", "```py\n[1] 17681\n```", "```py\nairbnb_data_no_superhost_nas |>\n filter(is.na(review_scores_rating)) |>\n select(number_of_reviews) |>\n table()\n```", "```py\nnumber_of_reviews\n    0 \n17681 \n```", "```py\nairbnb_data_no_superhost_nas |>\n filter(!is.na(review_scores_rating)) |>\n ggplot(aes(x = review_scores_rating)) +\n geom_histogram(binwidth = 1) +\n theme_classic() +\n labs(\n x = \"Average review score\",\n y = \"Number of properties\"\n )\n```", "```py\nairbnb_data_has_reviews <-\n airbnb_data_no_superhost_nas |>\n filter(!is.na(review_scores_rating))\n```", "```py\nairbnb_data_has_reviews |>\n count(host_response_time)\n```", "```py\n# A tibble: 5 × 2\n  host_response_time     n\n  <chr>              <int>\n1 N/A                19479\n2 a few days or more   712\n3 within a day        4512\n4 within a few hours  6894\n5 within an hour     24321\n```", "```py\nairbnb_data_has_reviews <-\n airbnb_data_has_reviews |>\n mutate(\n host_response_time = if_else(\n host_response_time == \"N/A\",\n NA_character_,\n host_response_time\n ),\n host_response_time = factor(host_response_time)\n )\n```", "```py\nairbnb_data_has_reviews |>\n filter(is.na(host_response_time)) |>\n ggplot(aes(x = review_scores_rating)) +\n geom_histogram(binwidth = 1) +\n theme_classic() +\n labs(\n x = \"Average review score\",\n y = \"Number of properties\"\n )\n```", "```py\nairbnb_data_has_reviews |>\n ggplot(aes(\n x = host_response_time,\n y = review_scores_accuracy\n )) +\n geom_miss_point() +\n labs(\n x = \"Host response time\",\n y = \"Review score accuracy\",\n color = \"Is missing?\"\n ) +\n theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```", "```py\nairbnb_data_selected <-\n airbnb_data_has_reviews |>\n filter(!is.na(host_response_time))\n```", "```py\nairbnb_data_selected |>\n ggplot(aes(x = host_total_listings_count)) +\n geom_histogram() +\n scale_x_log10() +\n labs(\n x = \"Total number of listings, by host\",\n y = \"Number of hosts\"\n )\n```", "```py\nairbnb_data_selected |>\n filter(host_total_listings_count >= 500) |>\n head()\n```", "```py\n# A tibble: 6 × 13\n    host_id host_response_time host_is_superhost host_total_listings_count\n      <dbl> <fct>              <lgl>                                 <dbl>\n1 439074505 within an hour     FALSE                                  3627\n2 156158778 within an hour     FALSE                                   558\n3 156158778 within an hour     FALSE                                   558\n4 156158778 within an hour     FALSE                                   558\n5 156158778 within an hour     FALSE                                   558\n6 156158778 within an hour     FALSE                                   558\n# ℹ 9 more variables: neighbourhood_cleansed <chr>, bathrooms <lgl>,\n#   bedrooms <dbl>, price <int>, number_of_reviews <dbl>,\n#   review_scores_rating <dbl>, review_scores_accuracy <dbl>,\n#   review_scores_value <dbl>, host_is_superhost_binary <dbl>\n```", "```py\nairbnb_data_selected <-\n airbnb_data_selected |>\n add_count(host_id) |>\n filter(n == 1) |>\n select(-n)\n```", "```py\nairbnb_data_selected |>\n filter(number_of_reviews > 1) |>\n ggplot(aes(x = price, y = review_scores_rating, \n color = host_is_superhost)) +\n geom_point(size = 1, alpha = 0.1) +\n theme_classic() +\n labs(\n x = \"Price per night\",\n y = \"Average review score\",\n color = \"Superhost\"\n ) +\n scale_color_brewer(palette = \"Set1\")\n```", "```py\nairbnb_data_selected |>\n count(host_is_superhost) |>\n mutate(\n proportion = n / sum(n),\n proportion = round(proportion, digits = 2)\n )\n```", "```py\n# A tibble: 2 × 3\n  host_is_superhost     n proportion\n  <lgl>             <int>      <dbl>\n1 FALSE             10480       0.74\n2 TRUE               3672       0.26\n```", "```py\nairbnb_data_selected |>\n tabyl(host_response_time, host_is_superhost) |>\n adorn_percentages(\"col\") |>\n adorn_pct_formatting(digits = 0) |>\n adorn_ns() |>\n adorn_title()\n```", "```py\n host_is_superhost            \n host_response_time             FALSE        TRUE\n a few days or more        5%   (489)  0%     (8)\n       within a day       22% (2,322) 11%   (399)\n within a few hours       23% (2,440) 25%   (928)\n     within an hour       50% (5,229) 64% (2,337)\n```", "```py\nairbnb_data_selected |>\n tabyl(neighbourhood_cleansed) |>\n adorn_pct_formatting() |>\n arrange(-n) |>\n filter(n > 100) |>\n adorn_totals(\"row\") |>\n head()\n```", "```py\n neighbourhood_cleansed    n percent\n                Hackney 1172    8.3%\n            Westminster  965    6.8%\n          Tower Hamlets  956    6.8%\n              Southwark  939    6.6%\n                Lambeth  914    6.5%\n             Wandsworth  824    5.8%\n```", "```py\nlogistic_reg_superhost_response_review <-\n glm(\n host_is_superhost ~\n host_response_time +\n review_scores_rating,\n data = airbnb_data_selected,\n family = binomial\n )\n```", "```py\nmodelsummary(logistic_reg_superhost_response_review)\n```", "```py\nwrite_parquet(\n x = airbnb_data_selected, \n sink = \"2023-05-05-london-airbnblistings-analysis_dataset.parquet\"\n )\n```", "```py\nexample_project/\n├── .gitignore\n├── Example project.Rproj\n├── scripts\n│   ├── simulate data.R\n│   ├── DownloadData.R\n│   ├── data-cleaning.R\n│   ├── test(new)data.R\n```", "```py\nset.seed(853)\n\ntidy_anscombe <-\n anscombe |>\n pivot_longer(everything(),\n names_to = c(\".value\", \"set\"),\n names_pattern = \"(.)(.)\")\n\ntidy_anscombe_MCAR <-\n tidy_anscombe |>\n mutate(row_number = row_number()) |>\n mutate(\n x = if_else(row_number %in% sample(\n x = 1:nrow(tidy_anscombe), size = 10\n ), NA_real_, x),\n y = if_else(row_number %in% sample(\n x = 1:nrow(tidy_anscombe), size = 10\n ), NA_real_, y)\n ) |>\n select(-row_number)\n\ntidy_anscombe_MCAR\n```", "```py\n# A tibble: 44 × 3\n   set       x     y\n   <chr> <dbl> <dbl>\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        NA NA   \n 4 4         8 NA   \n 5 1         8  6.95\n 6 2         8  8.14\n 7 3         8  6.77\n 8 4         8  5.76\n 9 1        NA  7.58\n10 2        13  8.74\n# ℹ 34 more rows\n```", "```py\n# ADD CODE HERE\n```", "```py\ntidy_anscombe_MNAR <-\n tidy_anscombe |>\n arrange(desc(x)) |>\n mutate(\n ordered_x_rows = 1:nrow(tidy_anscombe),\n x = if_else(ordered_x_rows %in% 1:10, NA_real_, x)\n ) |>\n select(-ordered_x_rows) |>\n arrange(desc(y)) |>\n mutate(\n ordered_y_rows = 1:nrow(tidy_anscombe),\n y = if_else(ordered_y_rows %in% 1:10, NA_real_, y)\n ) |>\n arrange(set) |>\n select(-ordered_y_rows)\n\ntidy_anscombe_MNAR\n```", "```py\n# A tibble: 44 × 3\n   set       x     y\n   <chr> <dbl> <dbl>\n 1 1        NA NA   \n 2 1        NA NA   \n 3 1         9 NA   \n 4 1        11  8.33\n 5 1        10  8.04\n 6 1        NA  7.58\n 7 1         6  7.24\n 8 1         8  6.95\n 9 1         5  5.68\n10 1         7  4.82\n# ℹ 34 more rows\n```", "```py\n# ADD CODE HERE\n```", "```py\ndownload.file(url = \"https://doi.org/10.1371/journal.pbio.3001946.s005\",\n destfile = \"data.xlsx\")\n\ndata <-\n read_xlsx(path = \"data.xlsx\",\n col_types = \"text\") |>\n clean_names() |>\n mutate(date = convert_to_date(date))\n```"]