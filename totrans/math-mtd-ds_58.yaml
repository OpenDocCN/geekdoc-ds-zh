- en: '7.6\. Further applications: Gibbs sampling and generating images#'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7.6\. 进一步应用：吉布斯采样和生成图像#
- en: 原文：[https://mmids-textbook.github.io/chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html](https://mmids-textbook.github.io/chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html](https://mmids-textbook.github.io/chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html)
- en: In this section, we derive an important application of Markov chains known as
    Markov Chain Monte Carlo (MCMC). We specialize it to Gibbs sampling and apply
    it to the generation of handwritten digits using a Restricted Boltzmann Machine
    (RBM).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们推导出马尔可夫链的一个重要应用，称为马尔可夫链蒙特卡洛（MCMC）。我们将它专门化到吉布斯采样，并应用于使用受限玻尔兹曼机（RBM）生成手写数字。
- en: 7.6.1\. Markov chain Monte Carlo (MCMC)[#](#markov-chain-monte-carlo-mcmc "Link
    to this heading")
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6.1\. 马尔可夫链蒙特卡洛（MCMC）[#](#markov-chain-monte-carlo-mcmc "链接到这个标题")
- en: 'Suppose we are interested in generating samples from a target distribution
    \(\bpi = (\pi_i)_{i \in \S}\) over a set \(\S\). We have done this before. For
    instance, we generated samples from a mixture of Gaussians to test \(k\)-means
    clustering in different dimensions. There are many more applications. A canonical
    one is to estimate the mean of a function \(f\) under \(\bpi\): generate \(n\)
    independent samples \(Z_1,\ldots,Z_n\), all distributed according to \(\pi\),
    then compute'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们感兴趣的是从目标分布 \(\bpi = (\pi_i)_{i \in \S}\) 在集合 \(\S\) 上生成样本。我们之前已经做过。例如，我们生成了高斯混合的样本来测试不同维度下的
    \(k\) 均值聚类。还有更多应用。一个典型应用是估计函数 \(f\) 在 \(\bpi\) 下的均值：生成 \(n\) 个独立的样本 \(Z_1,\ldots,Z_n\)，所有样本都按照
    \(\pi\) 分布，然后计算
- en: \[ \frac{1}{n} \sum_{i=1}^n f(Z_i), \]
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n f(Z_i), \]
- en: which is approximately \(\E[f(Z_1)]\) by the law of large numbers, provided
    \(n\) is sufficiently large. Furthermore, this type of problem plays an important
    role in [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这根据大数定律，近似等于 \(\E[f(Z_1)]\)，前提是 \(n\) 足够大。此外，这类问题在 [贝叶斯推断](https://en.wikipedia.org/wiki/Bayesian_inference)
    中扮演着重要角色。
- en: '**Sampling from simple distributions** When \(\bpi\) is a standard distribution
    or \(\S\) is relatively small, this can be done efficiently by using a random
    number generator, as we have done previously.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**从简单分布中进行采样** 当 \(\bpi\) 是标准分布或 \(\S\) 相对较小时，这可以通过使用随机数生成器有效地完成，就像我们之前做的那样。'
- en: '**NUMERICAL CORNER:** Recall how this works. We first initialize the random
    number generator and use a `seed` for reproducibility.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落**：回想一下这是如何工作的。我们首先初始化随机数生成器，并使用 `seed` 来保证可重复性。'
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To generate, say \(1000\), samples from a multivariate normal, say with mean
    \((0, 0)\) and covariance \(\begin{pmatrix}5 & 0\\0 & 1\end{pmatrix}\), we use
    [`numpy.random.Generator.multivariate_normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal)
    as follows. The `.T` below transposes the output to separate the \(x\) and \(y\)
    coordinates into individual arrays.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成，比如说 \(1000\) 个多元正态分布的样本，比如说均值为 \((0, 0)\) 和协方差 \(\begin{pmatrix}5 & 0\\0
    & 1\end{pmatrix}\)，我们使用 `numpy.random.Generator.multivariate_normal`（https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal）如下。下面的
    `.T` 将输出转置，将 \(x\) 和 \(y\) 坐标分别分离到单独的数组中。
- en: '`rng.multivariate_normal(mean, cov, 1000)` returns a `(1000, 2)` array where
    each row is one sample:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`rng.multivariate_normal(mean, cov, 1000)` 返回一个 `(1000, 2)` 的数组，其中每一行是一个样本：'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `.T` transposes this to `(2, 1000)`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`.T` 将其转置为 `(2, 1000)`：'
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now `x, y = ...` unpacks the two rows, giving you:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 `x, y = ...` 解包这两行，给你：
- en: '`x = [x1, x2, x3, ..., x1000]` (all x-coordinates)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x = [x1, x2, x3, ..., x1000]` （所有 x 坐标）'
- en: '`y = [y1, y2, y3, ..., y1000]` (all y-coordinates)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y = [y1, y2, y3, ..., y1000]` （所有 y 坐标）'
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Computing the mean of each component we get:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个分量的均值，我们得到：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is somewhat close to the expected answer: \((0,0)\).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这与预期的答案有些接近：\((0,0)\)。
- en: Using a larger number of samples, say \(10,000\), gives a better result.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更多的样本数量，比如 \(10,000\)，可以得到更好的结果。
- en: '[PRE8]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Sampling from an arbitrary distribution on a finite set is also straightforward
    – as long as the set is not too big. This can be done using [`numpy.random.Generator.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html).
    Borrowing the example from the documentation, the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从有限集合上的任意分布进行采样也很简单——只要集合不是太大。这可以使用 `numpy.random.Generator.choice`（https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html）来完成。借用文档中的例子，以下：
- en: '[PRE10]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: generates \(5\) samples from the set \(\S = \{\tt{pooh}, \tt{rabbit}, \tt{piglet},
    \tt{christopher}\}\) with respective probabilities \(0.5, 0.1, 0.1, 0.3\).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从集合 \(\S = \{\tt{pooh}, \tt{rabbit}, \tt{piglet}, \tt{christopher}\}\) 中生成 \(5\)
    个样本，相应的概率为 \(0.5, 0.1, 0.1, 0.3\)。
- en: But this may not be practical when the state space \(\S\) is very large. As
    an example, later in this section, we will learn a “realistic” distribution of
    handwritten digits. We will do so using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但当状态空间 \(\S\) 非常大时，这可能并不实用。作为一个例子，在本节的后面，我们将学习一个“现实”的手写数字分布。我们将使用 [MNIST 数据集](https://en.wikipedia.org/wiki/MNIST_database)
    来实现这一点。
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源代码
    隐藏代码单元格源代码</summary>
- en: '[PRE12]</details>'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE12]</details>'
- en: Each image is \(28 \times 28\), so the total number of (black and white) pixels
    is \(784\).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像是 \(28 \times 28\)，所以（黑白）像素的总数是 \(784\)。
- en: '[PRE13]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: To specify a distribution over all possible black and white images of this size,
    we need in principle to assign a probability to a very large number of states.
    Our space here is \(\S = \{0,1\}^{784}\), imagining that \(0\) encodes white and
    \(1\) encodes black and that we have ordered the pixels in some arbitrary way.
    How big is this space?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定所有可能的大小为该尺寸的黑白图像的分布，从原则上讲，我们需要为大量状态分配一个概率。我们在这里的空间是 \(\S = \{0,1\}^{784}\)，想象
    \(0\) 编码白色，\(1\) 编码黑色，并且我们以某种任意方式对像素进行了排序。这个空间有多大？
- en: 'Answer: \(2^{784}\).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：\(2^{784}\)。
- en: 'Or in base \(10\), we compute \(\log_{10}(2^{784})\), which is:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在基 \(10\) 中，我们计算 \(\log_{10}(2^{784})\)，结果是：
- en: '[PRE17]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: So a little more than \(10^{236}\).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总数略大于 \(10^{236}\)。
- en: This is much too large to naively plug into `rng.choice`!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于直接插入 `rng.choice` 来说是太大了！
- en: \(\unlhd\)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: So how to proceed? Instead we’ll use a Markov chain, as detailed next.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么接下来该如何进行呢？我们将使用马尔可夫链，具体内容将在下文中详细说明。
- en: '**General setting** The idea behind MCMC\(\idx{Markov chain Monte Carlo}\xdi\)
    is simple. To generate samples from \(\bpi\), use a Markov chain \((X_t)_{t \geq
    0}\) for which *it is the stationary distribution*. Indeed, we know from the *Convergence
    to Equilibrium Theorem* that if the chain is irreducible and aperiodic, then the
    distribution at time \(t\) is close to \(\bpi\) when \(t\) is large enough; and
    this holds for any initial dsitribution. Repeating this multiple times produces
    many independent, approximate samples from \(\bpi\).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般设置** MCMC（马尔可夫链蒙特卡洛）背后的思想很简单。要从 \(\bpi\) 中生成样本，使用一个马尔可夫链 \((X_t)_{t \geq
    0}\)，其 *平稳分布* 正是 \(\bpi\)。实际上，根据 *收敛到平衡定理*，我们知道如果链是不可约的且非周期的，那么当 \(t\) 足够大时，时间
    \(t\) 的分布将接近 \(\bpi\)；这对于任何初始分布都成立。重复多次会产生许多独立、近似的 \(\bpi\) 样本。'
- en: 'The question is now:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是：
- en: How to construct a transition matrix \(P\) whose stationary distribution is
    given target distribution \(\bpi\)?
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何构建一个平稳分布为给定目标分布 \(\bpi\) 的转移矩阵 \(P\)？
- en: How to ensure that this Markov chain is relatively easy to simulate?
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何确保这个马尔可夫链相对容易模拟？
- en: 'Regarding the first question, we have seen how to compute the stationary distribution
    of a transition matrix (provided it exists and is unique). How do we invert the
    process? Note one difficulty: many transition matrices can have the same stationary
    distribution. This is in fact a blessing, as it gives room for designing a “good”
    Markov chain.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第一个问题，我们已经看到如何计算转移矩阵的平稳分布（假设它存在且唯一）。我们如何逆转这个过程？注意一个困难：许多转移矩阵可以具有相同的平稳分布。这实际上是一个祝福，因为它为设计一个“好”的马尔可夫链提供了空间。
- en: '**KNOWLEDGE CHECK:** Construct two distinct transition matrices on \(2\) states
    whose stationary distribution is uniform. \(\checkmark\)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 构建两个具有均匀平稳分布的、状态为 \(2\) 的不同转移矩阵。 \(\checkmark\)'
- en: Regarding the second question, note that an obvious chain answering the first
    question is one that ignores the current state and chooses the next state according
    to \(\bpi\). We have already seen that this can be a problematic choice.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第二个问题，请注意，一个显然的满足第一个问题的链是忽略当前状态，并根据 \(\bpi\) 选择下一个状态的链。我们已经看到这可能会是一个有问题的选择。
- en: '**KNOWLEDGE CHECK:** Show that this chain has the desired stationary distribution.
    \(\checkmark\)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 证明这个链具有所需的平稳分布。 \(\checkmark\)'
- en: '**Metropolis-Hastings** We develop one standard technique that helps answer
    these two questions. It is known as the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)\(\idx{Metropolis-Hastings}\xdi\).
    It consists in two steps. We assume that \(\bpi > 0\), that is, \(\pi_i > 0, \forall
    i \in \S\).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastings** 我们开发了一种标准技术，帮助回答这两个问题。它被称为 [Metropolis-Hastings 算法](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)\(\idx{Metropolis-Hastings}\xdi\)。它包括两个步骤。我们假设
    \(\bpi > 0\)，即 \(\pi_i > 0, \forall i \in \S\)。'
- en: '*Proposal distribution:* We first define a proposal chain, that is, a transition
    matrix \(Q\) on the space \(\S\). This chain *does not* need to have stationary
    distribution \(\bpi\). But it is typically a chain that is easy to simulate. A
    different way to think of this chain is that, for each state \(x \in \S\), we
    have a proposal distribution \(Q(x,\,\cdot\,)\) for the next state.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*建议分布:* 我们首先定义一个建议链，即在 \(\S\) 空间上的一个转移矩阵 \(Q\)。这个链 *不需要* 具有稳态分布 \(\bpi\)。但它通常是易于模拟的链。另一种思考这个链的方式是，对于每个状态
    \(x \in \S\)，我们都有一个建议分布 \(Q(x,\,\cdot\,)\) 用于下一个状态。'
- en: For instance, on the space of \(28 \times 28\) black-and-white images, we might
    pick a pixel uniformly at random and flip its value with probability \(1/2\).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 \(28 \times 28\) 灰度图像的空间中，我们可能会随机均匀地选择一个像素，并以 \(1/2\) 的概率翻转其值。
- en: '**KNOWLEDGE CHECK:** In the previous example, what is the stationary distribution?'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查:** 在前面的例子中，稳态分布是什么？'
- en: a) All-white with probability \(1/2\), all-black with probability \(1/2\).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: a) 全白概率为 \(1/2\)，全黑概率为 \(1/2\)。
- en: b) Uniform.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: b) 均匀分布。
- en: c) Too complex to compute.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: c) 太复杂而无法计算。
- en: d) What is a stationary distribution?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: d) 稳态分布是什么？
- en: \(\checkmark\)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \(\checkmark\)
- en: '*Hastings correction:*\(\idx{Hastings correction}\xdi\) At each step, we first
    pick a state according to \(Q\), given the current state. Then we accept or reject
    this move according to a specially defined probability that depends on \(Q\) as
    well as \(\bpi\). This is where the target distribution \(\bpi\) enters the picture,
    and the rejection probability is chosen to ensure that the new chain has the right
    stationary distribution, as we will see later. But first we define the full algorithm.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hastings 修正:* \(\idx{Hastings correction}\xdi\) 在每一步，我们首先根据 \(Q\) 选择一个状态，给定当前状态。然后根据一个特别定义的概率接受或拒绝这次移动，这个概率依赖于
    \(Q\) 以及 \(\bpi\)。这就是目标分布 \(\bpi\) 进入画面的时候，拒绝概率被选择以确保新链具有正确的稳态分布，正如我们稍后将会看到的。但首先我们定义完整的算法。'
- en: Formally, the algorithm goes as follows. Let \(x_0 \in \S\) be an arbitrary
    starting point and set \(X_0 := x_0\).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，算法如下。设 \(x_0 \in \S\) 为一个任意起点，并设置 \(X_0 := x_0\)。
- en: 'At each time \(t \geq 1\):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间 \(t \geq 1\)：
- en: 1- Pick a state \(Y\) according to the distribution \(Q(X_{t-1}, \,\cdot\,)\),
    that is, row \(X_{t-1}\) of \(Q\).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 根据分布 \(Q(X_{t-1}, \,\cdot\,)\) 选择一个状态 \(Y\)，即 \(Q\) 的第 \(X_{t-1}\) 行。
- en: 2- With probability
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 以概率
- en: \[ \min\left\{1, \frac{\pi_{Y}}{\pi_{X_{t-1}}} \frac{Q(Y, X_{t-1})}{Q(X_{t-1},
    Y)} \right\} \]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min\left\{1, \frac{\pi_{Y}}{\pi_{X_{t-1}}} \frac{Q(Y, X_{t-1})}{Q(X_{t-1},
    Y)} \right\} \]
- en: we set \(X_{t} := Y\) (i.e., we accept the move), and otherwise we set \(X_{t}
    := X_{t-1}\) (i.e., we reject the move).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 \(X_{t} := Y\)（即，我们接受这次移动），否则我们将 \(X_{t} := X_{t-1}\)（即，我们拒绝这次移动）。
- en: '**KNOWLEDGE CHECK:** Should we worry about the denominator \(\pi_{X_{t-1}}
    Q(X_{t-1}, Y)\) being \(0\)? \(\checkmark\)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查:** 我们应该担心分母 \(\pi_{X_{t-1}} Q(X_{t-1}, Y)\) 为 \(0\) 吗？ \(\checkmark\)'
- en: 'We make three observations:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做出三个观察：
- en: Taking a minimum with \(1\) ensures that acceptance probability is indeed between
    \(0\) and \(1\).
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用 \(1\) 取最小值确保接受概率确实在 \(0\) 和 \(1\) 之间。
- en: We only need to know \(\bpi\) *up to a scaling factor* since the chain depends
    only on the ratio \(\frac{\pi_{Y}}{\pi_{X_{t-1}}}\). The scaling factor cancels
    out. This turns out to be critical in many applications of MCMC. We will see an
    example in the next subsection.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只需要知道 \(\bpi\) 的一个缩放因子，因为链只依赖于比率 \(\frac{\pi_{Y}}{\pi_{X_{t-1}}}\)。缩放因子会相互抵消。这在
    MCMC 的许多应用中变得至关重要。我们将在下一小节中看到一个例子。
- en: If \(Q\) is symmetric, that is, \(Q(x,y) = Q(y,x)\) for all \(x, y \in \S\),
    then the ratio \(\frac{Q(Y, X_{t-1})}{Q(X_{t-1}, Y)}\) is just \(1\), leading
    to a simpler formula for the acceptance probability. In particular, in that case,
    moving to a state with a larger probability under \(\bpi\) is *always* accepted.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 \(Q\) 是对称的，即 \(Q(x,y) = Q(y,x)\) 对于所有 \(x, y \in \S\) 都成立，那么比率 \(\frac{Q(Y,
    X_{t-1})}{Q(X_{t-1}, Y)}\) 就是 \(1\)，从而得到一个更简单的接受概率公式。特别是，在这种情况下，向具有更大概率的 \(\bpi\)
    状态转移总是被接受。
- en: '**NUMERICAL CORNER:** Suppose \(\S = \{1,\cdots, n\} = [n]\) for some positive
    integer \(n\) and \(\bpi\) is proportional to a Poisson distribution with mean
    \(\lambda > 0\). That is,'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：** 假设 \(\S = \{1,\cdots, n\} = [n]\) 对于某个正整数 \(n\)，且 \(\bpi\) 与均值为 \(\lambda
    > 0\) 的泊松分布成比例。也就是说，'
- en: \[ \pi_i = C e^{-\lambda} \frac{\lambda^i}{i!}, \quad \forall i \in \S \]
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \pi_i = C e^{-\lambda} \frac{\lambda^i}{i!}, \quad \forall i \in \S \]
- en: for some constant \(C\) chosen so that \(\sum_{i=1}^{n} \pi_i = 1\). Recall
    that we do not need to determine \(C\) as it is enough to know the target distribution
    up to a scaling factor by the previous remark.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个常数 \(C\)，使得 \(\sum_{i=1}^{n} \pi_i = 1\)。回想一下，我们不需要确定 \(C\)，因为根据前面的评论，我们只需要知道目标分布的缩放因子。
- en: To apply Metropolis-Hastings, we need a proposal chain. Consider the following
    choice. For each \(1 < i < n\), move to \(i+1\) or \(i-1\) with probability \(1/2\)
    each. For \(i=1\) (respectively \(i = n\)), move to \(2\) (respectively \(n-1\))
    with probability \(1/2\), otherwise stay where you are. For instance, if \(n =
    4\), then
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用 Metropolis-Hastings 算法，我们需要一个提议链。考虑以下选择。对于每个 \(1 < i < n\)，以 \(1/2\) 的概率移动到
    \(i+1\) 或 \(i-1\)。对于 \(i=1\)（分别 \(i = n\)），以 \(1/2\) 的概率移动到 \(2\)（分别 \(n-1\)），否则保持在当前位置。例如，如果
    \(n = 4\)，那么
- en: \[\begin{split} Q = \begin{pmatrix} 1/2 & 1/2 & 0 & 0\\ 1/2 & 0 & 1/2 & 0\\
    0 & 1/2 & 0 & 1/2\\ 0 & 0 & 1/2 & 1/2 \end{pmatrix}, \end{split}\]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Q = \begin{pmatrix} 1/2 & 1/2 & 0 & 0\\ 1/2 & 0 & 1/2 & 0\\
    0 & 1/2 & 0 & 1/2\\ 0 & 0 & 1/2 & 1/2 \end{pmatrix}, \end{split}\]
- en: which is indeed a stochastic matrix. It is also symmetric, so it does not enter
    into the acceptance probability by the previous remark.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个随机矩阵。它也是对称的，所以根据前面的评论，它不会进入接受概率。
- en: To compute the acceptance probability, we only need to consider pairs of adjacent
    integers as they are the only one that have non-zero probability under \(Q\).
    Consider state \(1 < i < n\). Observe that
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算接受概率，我们只需要考虑相邻整数对，因为它们是唯一在 \(Q\) 下具有非零概率的。考虑状态 \(1 < i < n\)。观察如下
- en: \[ \frac{\pi_{i+1}}{\pi_{i}} = \frac{C e^{-\lambda} \lambda^{i+1}/(i+1)!}{C
    e^{-\lambda} \lambda^{i}/i!} = \frac{\lambda}{i+1} \]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\pi_{i+1}}{\pi_{i}} = \frac{C e^{-\lambda} \lambda^{i+1}/(i+1)!}{C
    e^{-\lambda} \lambda^{i}/i!} = \frac{\lambda}{i+1} \]
- en: so a move to \(i+1\) happens with probability
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，移动到 \(i+1\) 的概率为
- en: \[ \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}, \]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}, \]
- en: where the \(1/2\) factor from the proposal distribution. Similarly, it can be
    checked (try it!) that a move to \(i-1\) occurs with probability
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 其中包含提议分布中的 \(1/2\) 因子。同样，可以检查（试一试！）移动到 \(i-1\) 发生的概率
- en: \[ \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}. \]
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}. \]
- en: And we stay at \(i\) with probability \(1 - \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}
    - \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}\). (Why is this guaranteed
    to be a probability?)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以概率 \(1 - \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\} - \frac{1}{2}
    \min\left\{1, \frac{i}{\lambda}\right\}\) 留在 \(i\)。 (为什么这保证了它是一个概率？)
- en: A similar formula applies to \(i = 1, n\). (Try it!)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(i = 1, n\) 也适用相同的公式。（试一试！）
- en: We are ready to apply Metropolis-Hastings.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备应用 Metropolis-Hastings 算法。
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Take \(\lambda = 1\) and \(n = 6\). We get the following transition matrix.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\lambda = 1\) 和 \(n = 6\)。我们得到以下转移矩阵。
- en: '[PRE20]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**TRY IT!** Rewrite the function `mh_transition_poisson` without an explicit
    loop by using [broadcasting and vectorization](https://numpy.org/doc/stable/user/basics.broadcasting.html).
    ([Open in Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试一下！** 不使用显式循环，通过使用 [广播和向量化](https://numpy.org/doc/stable/user/basics.broadcasting.html)
    重写函数 `mh_transition_poisson`。（[在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb)）'
- en: We use our simulator from a previous section. We start from the uniform distribution
    and take \(100\) steps.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上一节中的模拟器。我们从均匀分布开始，进行 \(100\) 次步骤。
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Our sample is the final state of the trajectory.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的样本是轨迹的最终状态。
- en: '[PRE24]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We repeat \(1000\) times.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复 \(1000\) 次。
- en: '[PRE26]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We plot the frequencies.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制频率图。
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源代码
    隐藏代码单元格源代码</summary>
- en: '[PRE27]</details> ![../../_images/d6e38b4f33052e917d7a2b6a03db11bd9c511daf60b88e2534f0a8be833345b9.png](../Images/4cb2314254f27c2be1f23bd733b95e2d.png)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE27]</details> ![../../_images/d6e38b4f33052e917d7a2b6a03db11bd9c511daf60b88e2534f0a8be833345b9.png](../Images/4cb2314254f27c2be1f23bd733b95e2d.png)'
- en: If we increase the parameter \(\lambda\) (which is not quite the mean; why?),
    what would you expect will happen to the sampled distribution?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们增加参数 \(\lambda\)（这并不是平均值；为什么？），你预计样本分布会发生什么变化？
- en: '**TRY IT!** Redo the simulations, but this time implement a general Metropolis-Hastings
    algorithm rather than specifying the transition matrix directly. That is, implement
    the algorithm for an arbitrary \(\bpi\) and \(Q\). Assume the state space is \([n]\).
    ([Open in Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试一下！** 重新进行模拟，但这次实现一个通用的 Metropolis-Hastings 算法而不是直接指定转移矩阵。也就是说，实现一个任意 \(\bpi\)
    和 \(Q\) 的算法。假设状态空间是 \([n]\)。([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
- en: \(\unlhd\)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: It remains to prove that \(\bpi\) is needed the stationary distribution of the
    Metropolis-Hastings algorithm. We restrict ourselves to the symmetric case, that
    is, \(Q(x,y) = Q(y,x)\) for all \(x,y\).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的任务是证明 \(\bpi\) 是 Metropolis-Hastings 算法的平稳分布。我们限制自己考虑对称情况，即对于所有 \(x,y\)，\(Q(x,y)
    = Q(y,x)\)。
- en: '**THEOREM** **(Correctness of Metropolis-Hastings)** \(\idx{correctness of
    Metropolis-Hastings}\xdi\) Consider the Metropolis-Hastings algorithm with target
    distribution \(\bpi\) over finite state space \(\S\) and symmetric proposal chain
    \(Q\). Assume further that \(\bpi\) is strictly positive and \(Q\) is irreducible
    over \(\S\). The resulting Markov chain is irreducible and reversible with respect
    to \(\bpi\). \(\sharp\)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(Metropolis-Hastings 的正确性)** \(\idx{Metropolis-Hastings 的正确性}\xdi\)
    考虑在有限状态空间 \(\S\) 上具有目标分布 \(\bpi\) 和对称提议链 \(Q\) 的 Metropolis-Hastings 算法。进一步假设
    \(\bpi\) 是严格正的，且 \(Q\) 在 \(\S\) 上是不可约的。结果马尔可夫链相对于 \(\bpi\) 是不可约的和可逆的。 \(\sharp\)'
- en: '*Proof idea:* It is just a matter of writing down the resulting transition
    matrix \(P\) and checking the detailed balance conditions. Because of the minimum
    in the acceptance probability, one has to consider two cases each time.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 这只是写下结果转移矩阵 \(P\) 并检查详细平衡条件的问题。由于接受概率的最小值，每次都必须考虑两种情况。'
- en: '*Proof:* Let \(P\) denote the transition matrix of the resulting Markov chain.
    Our first task is to compute \(P\).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 令 \(P\) 表示结果马尔可夫链的转移矩阵。我们的第一个任务是计算 \(P\)。'
- en: Let \(x, y \in \S\) be a pair of distinct states such that \(Q(x, y) = Q(y,
    x) = 0\). Then, from \(x\) (respectively \(y\)), the proposal chain never picks
    \(y\) (respectively \(x\)) as the possible next state. Hence \(P(x,y) = P(y, x)
    = 0\) in that case.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(x, y \in \S\) 是一对不同的状态，使得 \(Q(x, y) = Q(y, x) = 0\)。那么，从 \(x\)（分别 \(y\)），提议链永远不会选择
    \(y\)（分别 \(x\)）作为可能的下一个状态。因此，在这种情况下，\(P(x,y) = P(y, x) = 0\)。
- en: So let \(x, y \in \S\) be a pair of distinct states such that \(Q(x, y) = Q(y,
    x) > 0\). Applying the Hastings correction, we get that the overall probability
    of moving to \(y\) from current state \(x\) is
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，设 \(x, y \in \S\) 是一对不同的状态，使得 \(Q(x, y) = Q(y, x) > 0\)。应用 Hastings 修正，我们得到从当前状态
    \(x\) 移动到 \(y\) 的整体概率是
- en: \[ P(x, y) = Q(x, y) \left(1 \land \frac{\pi_{y}}{\pi_{x}}\right) > 0, \]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x, y) = Q(x, y) \left(1 \land \frac{\pi_{y}}{\pi_{x}}\right) > 0, \]
- en: where we used the symmetry of \(Q\) and the notation \(a \land b = \min\{a,b\}\).
    Similarly,
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了 \(Q\) 的对称性和记号 \(a \land b = \min\{a,b\}\)。同样，
- en: \[ P(y, x) = Q(y, x) \left(1 \land \frac{\pi_{x}}{\pi_{y}}\right) > 0. \]
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(y, x) = Q(y, x) \left(1 \land \frac{\pi_{x}}{\pi_{y}}\right) > 0. \]
- en: Since \(P(x,y)\) is strictly positive exactly when \(Q(x,y)\) is strictly positive
    (for distinct \(x,y\)), the chain \(P\) has the same transition graph as the chain
    \(Q\). Hence, because \(Q\) is irreducible, so is \(P\).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 \(P(x,y)\) 在 \(Q(x,y)\) 严格正的情况下严格正（对于不同的 \(x,y\)），链 \(P\) 与链 \(Q\) 具有相同的转移图。因此，因为
    \(Q\) 是不可约的，所以 \(P\) 也是不可约的。
- en: It remains to check the detailed balance conditions. There are two cases. Without
    loss of generality, say \(\pi_x \leq \pi_y\). Then the previous formulas for \(P\)
    simplify to
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的任务是检查详细平衡条件。有两种情况。不失一般性，假设 \(\pi_x \leq \pi_y\)。那么 \(P\) 的前面公式简化为
- en: \[ P(x, y) = Q(x, y) \quad\text{and}\quad P(y, x) = Q(y, x) \frac{\pi_{x}}{\pi_{y}}.
    \]
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x, y) = Q(x, y) \quad\text{和}\quad P(y, x) = Q(y, x) \frac{\pi_{x}}{\pi_{y}}.
    \]
- en: Hence,
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: \[ \pi_x P(x,y) = \pi_x Q(x,y) = \pi_x Q(y,x) = \pi_x \frac{\pi_y}{\pi_y} Q(y,x)
    = \pi_y P(y,x), \]
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \pi_x P(x,y) = \pi_x Q(x,y) = \pi_x Q(y,x) = \pi_x \frac{\pi_y}{\pi_y} Q(y,x)
    = \pi_y P(y,x), \]
- en: where we used the symmetry of \(Q\) to obtain the second equality. That establishes
    the reversibility of \(P\) and concludes the proof. \(\square\)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了 \(Q\) 的对称性来获得第二个等式。这确立了 \(P\) 的可逆性并完成了证明。 \(\square\)
- en: '**CHAT & LEARN** The Metropolis-Hastings algorithm can be used for Bayesian
    inference. Ask your favorite AI chatbot to explain how MCMC methods are used in
    Bayesian inference and to provide an example of using the Metropolis-Hastings
    algorithm for parameter estimation in a simple Bayesian model. \(\ddagger\)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 梅特罗波利斯-哈斯蒂斯算法可以用于贝叶斯推理。请你的心仪AI聊天机器人解释MCMC方法在贝叶斯推理中的应用，并提供一个使用梅特罗波利斯-哈斯蒂斯算法在简单贝叶斯模型中进行参数估计的例子。
    \(\ddagger\)'
- en: 7.6.2\. Gibbs sampling[#](#gibbs-sampling "Link to this heading")
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6.2\. 吉布斯采样[#](#gibbs-sampling "链接到这个标题")
- en: We have seen that one challenge of the Metropolis-Hastings approach is to choose
    a good proposal chain. Gibbs sampling\(\idx{Gibbs sampling}\xdi\) is a canonical
    way of addressing this issue that has many applications. It applies in cases where
    the states are vectors, typically with a large number of coordinates, and where
    the target distribution has the kind of conditional independence properties we
    have encountered previously in the previous chapter.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，梅特罗波利斯-哈斯蒂斯方法的一个挑战是选择一个好的建议链。吉布斯采样\(\idx{Gibbs sampling}\xdi\) 是解决此问题的经典方法，具有许多应用。它适用于状态是向量的情况，通常具有大量坐标，并且目标分布具有我们在前一章中遇到的类似条件独立性属性。
- en: '**General setting** Here we will assume that \(\S = \Z^d\) where \(\Z\) is
    a finite set and \(d\) is the dimension. To emphasize that states are vectors,
    we will boldface letters, e.g., \(\bx = (x_i)_{i=1}^d\), \(\by = (y_i)_{i=1}^d\),
    etc., to denote them.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般设置** 在这里，我们将假设 \(\S = \Z^d\)，其中 \(\Z\) 是一个有限集合，\(d\) 是维度。为了强调状态是向量，我们将使用粗体字母，例如，\(\bx
    = (x_i)_{i=1}^d\)，\(\by = (y_i)_{i=1}^d\) 等，以表示它们。'
- en: We will need the following special notation. For a vector \(\bx \in \Z^d\) and
    an index \(i \in [d]\), we write
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要以下特殊符号。对于向量 \(\bx \in \Z^d\) 和索引 \(i \in [d]\)，我们写
- en: \[ \bx_{-i} = (x_1, \ldots,x_{i-1}, x_{i+1}, \ldots, x_d) \]
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bx_{-i} = (x_1, \ldots,x_{i-1}, x_{i+1}, \ldots, x_d) \]
- en: for the vector \(\bx\) where the coordinate \(x_i\) is dropped.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 对于删除了坐标 \(x_i\) 的向量 \(\bx\)。
- en: If \(\boldsymbol{\pi}\) is the target distribution, we let \(\pi_i(x_i|\bx_{-i})\)
    be the conditional probability that \(X_i = x_i\) given that \(\bX_{-i} = \bx_{-i}\)
    under the distribution \(\boldsymbol{\pi}\), i.e., \(\bX = (X_1,\ldots,X_d) \sim
    \boldsymbol{\pi}\). We assume that \(\pi_{\bx} > 0\) for all \(\bx \in \Z^d\).
    As a result, \(\pi_i(x_i|\bx_{-i}) > 0\) as well (prove it!).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 \(\boldsymbol{\pi}\) 是目标分布，我们让 \(\pi_i(x_i|\bx_{-i})\) 表示在分布 \(\boldsymbol{\pi}\)
    下，给定 \(\bX_{-i} = \bx_{-i}\) 时 \(X_i = x_i\) 的条件概率，即 \(\bX = (X_1,\ldots,X_d)
    \sim \boldsymbol{\pi}\)。我们假设对于所有 \(\bx \in \Z^d\)，\(\pi_{\bx} > 0\)。因此，\(\pi_i(x_i|\bx_{-i})
    > 0\) 也成立（请证明！）。
- en: A basic version of the Gibbs sampler generates a sequence of vectors \(\bX_0,
    \bX_1, \ldots, \bX_t, \ldots\) in \(\Z^d\) as follows. We denote the coordinates
    of \(\bX_t\) by \((X_{t,1}, \ldots, X_{t,d})\). We denote the vector of all coordinates
    of \(\bX_t\) except \(i\) by \(\bX_{t,-i}\).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 吉布斯采样的基本版本生成一个向量序列 \(\bX_0, \bX_1, \ldots, \bX_t, \ldots\) 在 \(\Z^d\) 中，如下所示。我们用
    \((X_{t,1}, \ldots, X_{t,d})\) 表示 \(\bX_t\) 的坐标。我们用 \(\bX_{t,-i}\) 表示除了 \(i\)
    之外的所有 \(\bX_t\) 坐标的向量。
- en: Pick \(\bX_0\) according to an arbitrary initial distribution \(\boldsymbol{\mu}\)
    over \(\Z^d\).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 根据在 \(\Z^d\) 上的任意初始分布 \(\boldsymbol{\mu}\) 选择 \(\bX_0\)。
- en: 'At each time \(t \geq 1\):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间 \(t \geq 1\)：
- en: 1- Pick a coordinate \(i\) uniformly at random in \([d]\).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 在 \([d]\) 中随机均匀地选择一个坐标 \(i\)。
- en: 2- Update coordinate \(X_{t,i}\) according to \(\pi_i(\,\cdot\,|\bX_{t-1,-i})\)
    while leaving all other coordinates unchanged.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 根据条件概率 \(\pi_i(\,\cdot\,|\bX_{t-1,-i})\) 更新坐标 \(X_{t,i}\)，同时保持所有其他坐标不变。
- en: We will implement it in a special case in the next subsection. But first we
    argue that it has the desired stationary distribution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一小节中特别处理这个实现。但首先，我们论证它具有期望的平稳分布。
- en: It suffices to establish that the Gibbs sampler is a special case of the Metropolis-Hastings
    algorithm. For this, we must identify the appropriate proposal chain \(Q\).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 只需证明吉布斯采样是梅特罗波利斯-哈斯蒂斯算法的一个特例。为此，我们必须确定适当的建议链 \(Q\)。
- en: 'We claim that the following choice works: for \(\bx \neq \by\),'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称以下选择是有效的：对于 \(\bx \neq \by\)，
- en: \[\begin{split} Q(\bx, \by) = \begin{cases} \frac{1}{d} \pi_i(y_i|\bx_{-i})
    & \text{if $\by_{-i} = \bx_{-i}$ for some $i \in [d]$}\\ 0 & \text{o.w.} \end{cases}
    \end{split}\]
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Q(\bx, \by) = \begin{cases} \frac{1}{d} \pi_i(y_i|\bx_{-i})
    & \text{if $\by_{-i} = \bx_{-i}$ for some $i \in [d]$}\\ 0 & \text{o.w.} \end{cases}
    \end{split}\]
- en: The condition “\(\by_{-i} = \bx_{-i}\) for some \(i \in [d]\)” ensures that
    we only consider moves that affect a single coordinate \(i\). The factor \(1/d\)
    means that we pick that coordinate uniformly at random among all coordinates.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 条件“\(\by_{-i} = \bx_{-i}\) 对于某些 \(i \in [d]\)”确保我们只考虑影响单个坐标 \(i\) 的移动。因子 \(1/d\)
    表示我们在所有坐标中均匀随机选择该坐标。
- en: For each \(\bx\), we stay put with the remaining probability.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个 \(\bx\)，我们以剩余的概率保持原位。
- en: '**KNOWLEDGE CHECK:** Write down explicitly the staying probability \(Q(\bx,
    \bx)\) and check it is indeed in \([0,1]\). \(\checkmark\)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 明确写出停留概率 \(Q(\bx, \bx)\) 并检查它确实在 \([0,1]\) 范围内。\(\checkmark\)'
- en: In general, this \(Q\) is not symmetric. For \(\bx \neq \by\) with \(Q(\bx,
    \by) > 0\) where \(i\) is the non-matching coordinate, the acceptance probability
    is
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这个 \(Q\) 不是对称的。对于 \(\bx \neq \by\) 且 \(Q(\bx, \by) > 0\) 的非匹配坐标 \(i\)，接受概率是
- en: \[\begin{align*} \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{Q(\by, \bx)}{Q(\bx,
    \by)} \right\} &= \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\frac{1}{d}
    \pi_i(x_i|\by_{-i})}{\frac{1}{d} \pi_i(y_i|\bx_{-i})} \right\}\\ &= \min\left\{1,
    \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})} \right\},
    \end{align*}\]
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{Q(\by, \bx)}{Q(\bx,
    \by)} \right\} &= \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\frac{1}{d}
    \pi_i(x_i|\by_{-i})}{\frac{1}{d} \pi_i(y_i|\bx_{-i})} \right\}\\ &= \min\left\{1,
    \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})} \right\},
    \end{align*}\]
- en: where we used that \(\bx_{-i} = \by_{-i}\) in the second equality.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个等式中，我们使用了 \(\bx_{-i} = \by_{-i}\) 这一事实。
- en: 'Recall the definition of the conditional probability as a ratio: \(\P[A|B]
    = \P[A\cap B]/\P[B]\). Applying that definition, both conditional probabilities
    \(\pi_i(x_i|\bx_{-i})\) and \(\pi_i(y_i|\bx_{-i})\) have the *same denominator*.
    Their respective numerators on the other hand are \(\pi_{\bx}\) and \(\pi_{\by}\).
    Hence,'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆条件概率的定义，即一个比率：\(\P[A|B] = \P[A\cap B]/\P[B]\)。应用该定义，条件概率 \(\pi_i(x_i|\bx_{-i})\)
    和 \(\pi_i(y_i|\bx_{-i})\) 具有相同的分母。另一方面，它们的分子分别是 \(\pi_{\bx}\) 和 \(\pi_{\by}\)。因此，
- en: \[ \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})}
    \right\} = \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_{\bx}}{\pi_{\by}}
    \right\} = 1. \]
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})}
    \right\} = \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_{\bx}}{\pi_{\by}}
    \right\} = 1. \]
- en: In other words, the proposed move is always accepted! Therefore \(P = Q\), which
    is indeed the Gibbs sampler. It also establishes by *Correctness of Metropolis-Hastings*
    that \(P\) is reversible with respect to \(\pi\). It is also irreducible (Why?).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，提出的移动总是被接受！因此 \(P = Q\)，这确实是吉布斯采样。它还通过 *Metropolis-Hastings 正确性* 建立了 \(P\)
    相对于 \(\pi\) 是可逆的。它也是不可约的（为什么？）。
- en: Here we picked a coordinate at random. It turns out that other choices are possible.
    For example, one could update each coordinate in some deterministic order, or
    one could update blocks of coordinates at a time. Under some conditions, these
    schemes can still produce an algorithm simulating the desired distribution. We
    will not detail this here, but our implementation below does use a block scheme.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们随机选择了一个坐标。实际上，还有其他选择。例如，可以按某种确定性顺序更新每个坐标，或者可以一次更新坐标块。在某些条件下，这些方案仍然可以产生模拟所需分布的算法。我们在此不会详细说明，但我们的实现下面确实使用了块方案。
- en: '**An example: restricted Boltzmann machines (RBM)** We implement the Gibbs
    sampler on a specific probabilistic model, a so-called restricted Boltzmann machine
    (RBM)\(\idx{restricted Boltzmann machine}\xdi\), and apply it to the generation
    of random images from a “realistic” distribution. For more on Boltzmann machines,
    including their restricted and deep versions, see [here](https://en.wikipedia.org/wiki/Boltzmann_machine).
    We will not describe them in great details here, but only use them as an example
    of a complex distribution.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：限制性玻尔兹曼机（RBM）** 我们在特定的概率模型上实现吉布斯采样，即所谓的限制性玻尔兹曼机（RBM）\(\idx{restricted
    Boltzmann machine}\xdi\)，并将其应用于从“现实”分布生成随机图像。有关玻尔兹曼机的更多信息，包括它们的限制性和深度版本，请参阅[这里](https://en.wikipedia.org/wiki/Boltzmann_machine)。我们在此不会详细描述它们，但仅将它们用作复杂分布的示例。'
- en: '*Probabilistic model:* An RBM has \(m\) visible units (i.e., observed variables)
    and \(n\) hidden units (i.e., hidden variables). It is represented by a complete
    bipartite graph between the two.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率模型:* RBM（限制性玻尔兹曼机）有 \(m\) 个可见单元（即观测变量）和 \(n\) 个隐藏单元（即隐藏变量）。它由两个部分之间的完全二部图表示。'
- en: '![An RBM (with help from ChatGPT; code converted and adapted from Source)](../Images/4fb58292c78ce9956928cadb68b7af09.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![一个 RBM（得益于 ChatGPT；代码从源转换并调整）](../Images/4fb58292c78ce9956928cadb68b7af09.png)'
- en: Visible unit \(i\) is associated a variable \(v_i\) and hidden unit \(j\) is
    associated a variable \(h_j\). We define the corresponding vectors \(\bv = (v_1,\ldots,v_m)\)
    and \(\bh = (h_1,\ldots,h_n)\). For our purposes, it will suffice to assume that
    \(\bv \in \{0,1\}^m\) and \(\bh \in \{0,1\}^n\). These are referred to as binary
    units.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 可见单元 \(i\) 与变量 \(v_i\) 相关联，隐藏单元 \(j\) 与变量 \(h_j\) 相关联。我们定义相应的向量 \(\bv = (v_1,\ldots,v_m)\)
    和 \(\bh = (h_1,\ldots,h_n)\)。对于我们的目的，假设 \(\bv \in \{0,1\}^m\) 和 \(\bh \in \{0,1\}^n\)
    就足够了。这些被称为二元单元。
- en: The probabilistic model has a number of parameters. Each visible unit \(i\)
    has an offset \(b_i \in \mathbb{R}\) and each hidden unit \(j\) has an offset
    \(c_j \in \mathbb{R}\). We write \(\bb = (b_1,\ldots,b_m)\) and \(\bc = (c_1,\ldots,c_n)\)
    for the offset vectors. For each pair \((i,j)\) of visible and hidden units (or,
    put differently, for each edge in the complete bipartite graph), there is a weight
    \(w_{i,j} \in \mathbb{R}\). We write \(W = (w_{i,j})_{i,j=1}^{m,n}\) for the weight
    matrix.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 概率模型具有多个参数。每个可见单元 \(i\) 有一个偏移量 \(b_i \in \mathbb{R}\)，每个隐藏单元 \(j\) 有一个偏移量 \(c_j
    \in \mathbb{R}\)。我们用 \(\bb = (b_1,\ldots,b_m)\) 和 \(\bc = (c_1,\ldots,c_n)\) 表示偏移向量。对于可见单元和隐藏单元的每一对
    \((i,j)\)（或者换句话说，对于完全二部图中的每条边），都有一个权重 \(w_{i,j} \in \mathbb{R}\)。我们用 \(W = (w_{i,j})_{i,j=1}^{m,n}\)
    表示权重矩阵。
- en: 'To define the probability distribution, we need the so-called [energy](https://en.wikipedia.org/wiki/Energy-based_model)\(\idx{energy-based
    model}\xdi\) (as you may have guessed, this terminology comes from related models
    in [physics](https://en.wikipedia.org/wiki/Boltzmann_distribution)): for \(\bv
    \in \{0,1\}^m\) and \(\bh \in \{0,1\}^n\),'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义概率分布，我们需要所谓的[能量](https://en.wikipedia.org/wiki/Energy-based_model)\(\idx{基于能量的模型}\xdi\)（正如你可能已经猜到的，这个术语来自物理学中的相关模型）：对于
    \(\bv \in \{0,1\}^m\) 和 \(\bh \in \{0,1\}^n\),
- en: \[\begin{align*} \cE(\bv, \bh) &= - \bv^T W \bh - \bb^T \bv - \bc^T \bh\\ &=
    - \sum_{i=1}^m \sum_{j=1}^n w_{i,j} v_i h_j - \sum_{i=1}^m b_i v_i - \sum_{j=1}^n
    c_j h_j. \end{align*}\]
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \cE(\bv, \bh) &= - \bv^T W \bh - \bb^T \bv - \bc^T \bh\\ &=
    - \sum_{i=1}^m \sum_{j=1}^n w_{i,j} v_i h_j - \sum_{i=1}^m b_i v_i - \sum_{j=1}^n
    c_j h_j. \end{align*}\]
- en: The joint distribution of \(\bv\) and \(\bh\) is
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bv\) 和 \(\bh\) 的联合分布为
- en: \[ \boldsymbol{\pi}(\bv, \bh) = \frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right),
    \]
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \boldsymbol{\pi}(\bv, \bh) = \frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right),
    \]
- en: where \(Z\), the [partition function](https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29)\(\idx{partition
    function}\xdi\) (a function of \(W,\bb,\bc\)), ensures that \(\boldsymbol{\pi}\)
    indeed sums to \(1\).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(Z\)，[配分函数](https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29)\(\idx{配分函数}\xdi\)（一个关于
    \(W,\bb,\bc\) 的函数），确保 \(\boldsymbol{\pi}\) 的和为 \(1\)。
- en: We will be interested in sampling from the marginal over visible units, that
    is,
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注从可见单元的边缘进行采样，即，
- en: \[ \rho(\bv) = \sum_{\bh \in \{0,1\}^n} \boldsymbol{\pi}(\bv, \bh). \]
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho(\bv) = \sum_{\bh \in \{0,1\}^n} \boldsymbol{\pi}(\bv, \bh). \]
- en: When \(m\) and/or \(n\) are large, computing \(\rho\) or \(\boldsymbol{\pi}\)
    explicitly – or even numerically – is impractical.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(m\) 和/或 \(n\) 很大时，显式地计算 \(\rho\) 或 \(\boldsymbol{\pi}\)（甚至数值上）是不切实际的。
- en: We develop the Gibbs sampler for this model next.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来为这个模型开发吉布斯采样器。
- en: '*Gibbs sampling:* We sample from the joint distribution \(\boldsymbol{\pi}\)
    and observe only \(\bv\).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*吉布斯采样*：我们从联合分布 \(\boldsymbol{\pi}\) 中采样，并且只观察 \(\bv\)。'
- en: We need to compute the conditional probabilities given every other variable.
    The sigmoid function, \(\sigma(x)\), will once again make an appearance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要计算给定其他每个变量的条件概率。sigmoid 函数，\(\sigma(x)\)，将再次出现。
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Fix a visible unit \(i \in [m]\). For a pair \((\bv, \bh)\), we denote by \((\bv_{[i]},
    \bh)\) the same pair where coordinate \(i\) of \(\bv\) is flipped. Given every
    other variable, i.e., \((\bv_{-i},\bh)\), and using a superscript \(\text{v}\)
    to indicate the probability of a visible unit, the conditional probability of
    \(v_i\) is
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 固定一个可见单元 \(i \in [m]\)。对于一对 \((\bv, \bh)\)，我们用 \((\bv_{[i]}, \bh)\) 表示相同的一对，其中
    \(\bv\) 的坐标 \(i\) 被翻转。给定其他每个变量，即 \((\bv_{-i},\bh)\)，并使用上标 \(\text{v}\) 来表示可见单元的概率，\(v_i\)
    的条件概率为
- en: \[\begin{align*} \pi^{\text{v}}_i(v_i|\bv_{-i},\bh) &= \frac{\boldsymbol{\pi}(\bv,
    \bh)}{\boldsymbol{\pi}(\bv, \bh) + \boldsymbol{\pi}(\bv_{[i]}, \bh)}\\ &= \frac{\frac{1}{Z}
    \exp\left(- \cE(\bv, \bh)\right)}{\frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right)
    + \frac{1}{Z} \exp\left(- \cE(\bv_{[i]}, \bh)\right)}. \end{align*}\]
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \pi^{\text{v}}_i(v_i|\bv_{-i},\bh) &= \frac{\boldsymbol{\pi}(\bv,
    \bh)}{\boldsymbol{\pi}(\bv, \bh) + \boldsymbol{\pi}(\bv_{[i]}, \bh)}\\ &= \frac{\frac{1}{Z}
    \exp\left(- \cE(\bv, \bh)\right)}{\frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right)
    + \frac{1}{Z} \exp\left(- \cE(\bv_{[i]}, \bh)\right)}. \end{align*}\]
- en: In this last ratio, the partition functions (the \(Z\)’s) cancel out. Moreover,
    all the terms in the exponentials *not depending* on the \(i\)-th visible unit
    actually factor out and cancel out as well – they are identical in all three exponentials.
    Similarly, the terms in the exponentials *depending only on \(\bh\)* also factor
    out and cancel out.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最后的比率中，配分函数（\(Z\)）相互抵消。此外，所有指数项中不依赖于第 \(i\) 个可见单元的项实际上都提取出来并相互抵消——它们在三个指数项中都是相同的。同样，仅依赖于
    \(\bh\) 的项也提取出来并相互抵消。
- en: 'What we are left with is:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们剩下的就是：
- en: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{\exp\left(\sum_{j=1}^n
    w_{i,j} v_i h_j + b_i v_i\right)} {\exp\left(\sum_{j=1}^n w_{i,j} v_i h_j + b_i
    v_i\right) + \exp\left(\sum_{j=1}^n w_{i,j} (1-v_i) h_j + b_i (1-v_i)\right)},
    \end{align*}\]
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{\exp\left(\sum_{j=1}^n
    w_{i,j} v_i h_j + b_i v_i\right)} {\exp\left(\sum_{j=1}^n w_{i,j} v_i h_j + b_i
    v_i\right) + \exp\left(\sum_{j=1}^n w_{i,j} (1-v_i) h_j + b_i (1-v_i)\right)},
    \end{align*}\]
- en: where we used the fact that flipping \(v_i \in \{0,1\}\) is the same as setting
    it to \(1 - v_i\), a transformation which indeed sends \(0\) to \(1\) and \(1\)
    to \(0\).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了翻转 \(v_i \in \{0,1\}\) 等同于将其设置为 \(1 - v_i\) 的事实，这种转换确实将 \(0\) 映射到 \(1\)，将
    \(1\) 映射到 \(0\)。
- en: This expression does not depend on \(\bv_{-i}\). In other words, the \(i\)-th
    visible unit is conditionally independent of all other visible units given the
    hidden units.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式不依赖于 \(\bv_{-i}\)。换句话说，第 \(i\) 个可见单元在给定隐藏单元的条件下与所有其他可见单元条件独立。
- en: We simplify the expression
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简化了以下表达式
- en: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{1} {1 + \exp\left(\sum_{j=1}^n
    w_{i,j} (1-2 v_i) h_j + b_i (1- 2v_i)\right)}\\ &= \sigma\left(\sum_{j=1}^n w_{i,j}
    (2 v_i-1) h_j + b_i (2v_i-1)\right). \end{align*}\]
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{1} {1 + \exp\left(\sum_{j=1}^n
    w_{i,j} (1-2 v_i) h_j + b_i (1- 2v_i)\right)}\\ &= \sigma\left(\sum_{j=1}^n w_{i,j}
    (2 v_i-1) h_j + b_i (2v_i-1)\right). \end{align*}\]
- en: In particular, the conditional mean of the \(i\)-th visible unit given everything
    else is
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，给定其他所有条件下的第 \(i\) 个可见单元的条件均值是
- en: \[\begin{align*} 0 \cdot \pi^{\text{v}}_i(0|\bv_{-i},\bh) + 1 \cdot \pi^{\text{v}}_i(1|\bv_{-i},\bh)
    &= \pi^{\text{v}}_i(1|\bv_{-i},\bh)\\ &= \sigma\left(\sum_{j=1}^n w_{i,j} h_j
    + b_i \right)\\ &= \sigma\left((W \bh + \bb)_i \right) \end{align*}\]
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 0 \cdot \pi^{\text{v}}_i(0|\bv_{-i},\bh) + 1 \cdot \pi^{\text{v}}_i(1|\bv_{-i},\bh)
    &= \pi^{\text{v}}_i(1|\bv_{-i},\bh)\\ &= \sigma\left(\sum_{j=1}^n w_{i,j} h_j
    + b_i \right)\\ &= \sigma\left((W \bh + \bb)_i \right) \end{align*}\]
- en: Similarly for the conditional probability of the \(j\)-th hidden unit given
    everything else, we have
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于给定其他所有条件下的第 \(j\) 个隐藏单元的条件概率，我们有
- en: \[\begin{align*} &\pi^{\text{h}}_j(h_j|\bv,\bh_{-j})\\ &= \sigma\left(\sum_{i=1}^m
    w_{i,j} v_i (2h_j -1) + c_j (2h_j -1)\right). \end{align*}\]
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{h}}_j(h_j|\bv,\bh_{-j})\\ &= \sigma\left(\sum_{i=1}^m
    w_{i,j} v_i (2h_j -1) + c_j (2h_j -1)\right). \end{align*}\]
- en: The conditional mean given everything else is
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 给定其他所有条件下的条件均值是
- en: \[\begin{align*} 0 \cdot \pi^{\text{h}}_j(0|\bv,\bh_{-j}) + 1 \cdot \pi^{\text{h}}_j(1|\bv,\bh_{-j})
    &= \pi^{\text{h}}_j(1|\bv,\bh_{-j}) = \sigma\left((W^T \bv + \bc)_j \right). \end{align*}\]
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 0 \cdot \pi^{\text{h}}_j(0|\bv,\bh_{-j}) + 1 \cdot \pi^{\text{h}}_j(1|\bv,\bh_{-j})
    &= \pi^{\text{h}}_j(1|\bv,\bh_{-j}) = \sigma\left((W^T \bv + \bc)_j \right). \end{align*}\]
- en: And the \(j\)-th hidden unit is conditionally independent of all other hidden
    units given the visible units.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 并且第 \(j\) 个隐藏单元在给定可见单元的条件下与所有其他隐藏单元条件独立。
- en: We implement the Gibbs sampler for an RBM. Rather than updating the units at
    random, we use a block approach. Specifically, we update all hidden units independently,
    given the visible units; then we update all visible units independently, given
    the hidden units. In each case, this is warranted by the conditional independence
    structure revealed above.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了 RBM 的吉布斯采样器。我们不是随机更新单元，而是使用块方法。具体来说，我们独立地更新所有隐藏单元，给定可见单元；然后我们独立地更新所有可见单元，给定隐藏单元。在每种情况下，这都由上面揭示的条件独立性结构所保证。
- en: We first implement the conditional means using the formulas previously derived.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用之前推导的公式实现条件均值。
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We next implement one step of the sampler, which consists in updating all hidden
    units, followed by updating all visible units.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们实现采样器的一步，这包括更新所有隐藏单元，然后更新所有可见单元。
- en: '[PRE30]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Finally, we repeat these steps `k` times. We only return the visible units `v`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们重复这些步骤`k`次。我们只返回可见单元`v`。
- en: '[PRE31]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here `v_0` is the initial visible unit states. We do not need to initialize
    the hidden ones as this is done automatically in the first update step. In the
    next subsection, we will take the initial distribution of \(\bv\) to be independent
    Bernoullis with success probability \(1/2\).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里`v_0`是初始可见单元状态。我们不需要初始化隐藏单元，因为这是在第一次更新步骤中自动完成的。在下一个小节中，我们将\(\bv\)的初始分布取为独立伯努利分布，成功概率为\(1/2\)。
- en: '**NUMERICAL CORNER:** We apply our Gibbs sampler to generating images. As mentioned
    previously, we use the MNIST dataset to learn a “realistic” distribution of handwritten
    digit images. Here the images are encoded by the visible units of an RBM. Then
    we sample from this model.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：**我们将我们的吉布斯采样器应用于生成图像。如前所述，我们使用MNIST数据集来学习手写数字图像的“现实”分布。这里的图像由RBM的可见单元编码。然后我们从该模型中采样。'
- en: We first need to train the model on the data. We will not show how this is done
    here, but instead use [`sklearn.neural_network.BernoulliRBM`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html).
    (Some details of how this training is done is provided [here](https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html#stochastic-maximum-likelihood-learning).)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要在数据上训练模型。我们不会在这里展示如何进行，而是使用[`sklearn.neural_network.BernoulliRBM`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html)。（有关如何进行此训练的一些细节，请参阅[这里](https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html#stochastic-maximum-likelihood-learning)。）
- en: '[PRE32]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: To simplify the analysis and speed up the training, we only keep digits \(0\),
    \(1\) and \(5\).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化分析和加快训练速度，我们只保留数字0、1和5。
- en: '[PRE33]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We flatten the images (which have already been “rounded” to black-and-white;
    see the first subsection).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像展平（这些图像已经被“四舍五入”为黑白；见第一小节）。
- en: '[PRE34]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We now fit the model. Choosing the hyperparameters of the training algorithm
    is tricky. The following seem to work reasonably well. (For a more systematic
    approach to tuning hyperparameters, see [here](https://scikit-learn.org/stable/modules/grid_search.html).)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们拟合模型。选择训练算法的超参数是棘手的。以下似乎效果相当好。（有关调整超参数的更系统方法，请参阅[这里](https://scikit-learn.org/stable/modules/grid_search.html)。）
- en: '[PRE35]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**In a Jupyter environment, please rerun this cell to show the HTML representation
    or trust the notebook.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Jupyter环境中，请重新运行此单元以显示HTML表示或信任笔记本。**'
- en: On GitHub, the HTML representation is unable to render, please try loading this
    page with nbviewer.org.**
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上，HTML表示无法渲染，请尝试使用nbviewer.org加载此页面。**
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We are ready to sample from the trained RBM. We extract the learned parameters
    from `rbm`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好从训练好的RBM中采样。我们从`rbm`中提取学习到的参数。
- en: '[PRE38]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: To generate \(25\) samples, we first generate \(25\) independent initial states.
    We stack them into a matrix, where each row is a different flattened random noise
    image.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成25个样本，我们首先生成25个独立的初始状态。我们将它们堆叠成一个矩阵，其中每一行是不同的展平随机噪声图像。
- en: '[PRE44]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: To process all samples simultaneously, we make a small change to the code. We
    use `numpy.newaxis` to make the offsets into column vectors, which are then automatically
    added to all columns of the resulting weighted sum.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为了同时处理所有样本，我们对代码进行了一些小的修改。我们使用`numpy.newaxis`将偏移量转换为列向量，然后这些向量自动添加到结果加权和中所有列的末尾。
- en: '[PRE45]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: For plotting, we use a script [adapted from here](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html)
    (with help from ChatGPT).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于绘图，我们使用了一个[从这里改编的脚本](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html)（在ChatGPT的帮助下）。
- en: '[PRE46]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We are now ready to run our Gibbs sampler. The outcome depends on the number
    of steps we take. After \(100\) steps, the outcome is somewhat realistic.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行我们的吉布斯采样器了。结果取决于我们采取的步骤数量。经过100步后，结果大致是现实的。
- en: '[PRE47]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![../../_images/aab5b59b73dc84d3b82547a838a8eadc75c8099fe134e50728fbf2920a04f55e.png](../Images/2abf435d81044deb01535f2ccdd32d63.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/aab5b59b73dc84d3b82547a838a8eadc75c8099fe134e50728fbf2920a04f55e.png](../Images/2abf435d81044deb01535f2ccdd32d63.png)'
- en: \(\unlhd\)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**CHAT & LEARN** The RBM can be stacked to form a [deep belief network (DBN)](#(https://en.wikipedia.org/wiki/Boltzmann_machine#Deep_Boltzmann_machine)).
    Ask your favorite AI chatbot about the process of greedy layer-wise pretraining
    of a DBN using RBMs. Discuss how this can be used for initializing the weights
    of a deep neural network and compare the performance with random initialization.
    \(\ddagger\)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** RBM可以堆叠形成[深度信念网络（DBN）](https://en.wikipedia.org/wiki/Boltzmann_machine#Deep_Boltzmann_machine)。向您最喜欢的AI聊天机器人询问使用RBM进行贪婪层预训练DBN的过程。讨论这如何用于初始化深度神经网络的权重，并比较与随机初始化的性能。
    \(\ddagger\)'
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(在Claude、Gemini和ChatGPT的帮助下)*'
- en: '**1** In the context of Markov Chain Monte Carlo (MCMC), what is the primary
    goal?'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 在马尔可夫链蒙特卡洛（MCMC）的背景下，主要目标是什么？'
- en: a) To find the maximum likelihood estimate of a parameter.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: a) 找到参数的最大似然估计值。
- en: b) To generate samples from a complex target distribution.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: b) 从复杂的目标分布中生成样本。
- en: c) To optimize a loss function using gradient descent.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用梯度下降优化损失函数。
- en: d) To cluster data points based on similarity.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: d) 根据相似性对数据点进行聚类。
- en: '**2** In the Metropolis-Hastings algorithm, what is the role of the proposal
    chain \(Q\)?'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 在Metropolis-Hastings算法中，提议链 \(Q\) 的作用是什么？'
- en: a) It determines the stationary distribution of the resulting Markov chain.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它决定了所得马尔可夫链的平稳分布。
- en: b) It is used to compute the acceptance probability for the proposed moves.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它用于计算提议移动的接受概率。
- en: c) It generates the candidate states for the next move in the Markov chain.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它为马尔可夫链的下一步移动生成候选状态。
- en: d) It ensures that the resulting Markov chain is irreducible and aperiodic.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它确保所得马尔可夫链是不可约的且非周期的。
- en: '**3** What is the purpose of the Hastings correction in the Metropolis-Hastings
    algorithm?'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** Metropolis-Hastings算法中Hastings校正的目的是什么？'
- en: a) To ensure that the proposal chain is symmetric.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: a) 确保提议链是对称的。
- en: b) To make the resulting Markov chain irreducible and aperiodic.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使所得马尔可夫链不可约且非周期。
- en: c) To ensure that the resulting Markov chain has the desired stationary distribution.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: c) 确保所得马尔可夫链具有所需的平稳分布。
- en: d) To improve the mixing time of the resulting Markov chain.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: d) 提高所得马尔可夫链的混合时间。
- en: '**4** What is the role of the energy function \(\mathcal{E}(\mathbf{v},\mathbf{h})\)
    in a Restricted Boltzmann Machine (RBM)?'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 在受限玻尔兹曼机（RBM）中，能量函数 \(\mathcal{E}(\mathbf{v},\mathbf{h})\) 的作用是什么？'
- en: a) It determines the acceptance probability in the Metropolis-Hastings algorithm.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它决定了Metropolis-Hastings算法中的接受概率。
- en: b) It defines the joint probability distribution of the visible and hidden units.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它定义了可见单元和隐藏单元的联合概率分布。
- en: c) It represents the cost function to be minimized during training.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它代表训练期间要最小化的成本函数。
- en: d) It controls the learning rate of the RBM.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它控制RBM的学习率。
- en: '**5** What is the partition function \(Z\) used for in the RBM’s joint probability
    distribution \(\boldsymbol{\pi}(\mathbf{v}, \mathbf{h})\)?'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 在RBM的联合概率分布 \(\boldsymbol{\pi}(\mathbf{v}, \mathbf{h})\) 中，分函数 \(Z\)
    用于什么？'
- en: a) It normalizes the energy function.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它标准化能量函数。
- en: b) It scales the weights matrix \(W\).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它缩放权重矩阵 \(W\)。
- en: c) It ensures that the probability distribution sums to one.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它确保概率分布的总和为1。
- en: d) It adjusts the biases \(\mathbf{b}\) and \(\mathbf{c}\).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它调整偏置 \(\mathbf{b}\) 和 \(\mathbf{c}\)。
- en: 'Answer for 1: b. Justification: The text states that “The idea behind MCMC
    is simple. To generate samples from \(\boldsymbol{\pi}\), use a Markov chain for
    which it is the stationary distribution.”'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 1的答案：b. 依据：文本中提到，“MCMC背后的想法很简单。要从 \(\boldsymbol{\pi}\) 中生成样本，使用一个马尔可夫链，其平稳分布就是
    \(\boldsymbol{\pi}\)。”
- en: 'Answer for 2: c. Justification: The text describes the proposal chain as follows:
    “We first define a proposal chain, that is, a transition matrix \(Q\) on the space
    \(\mathcal{S}\). This chain does not need to have stationary distribution \(\boldsymbol{\pi}\).
    But it is typically a chain that is easy to simulate.”'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 2的答案：c. 依据：文本中对提议链的描述如下：“我们首先定义一个提议链，即在空间 \(\mathcal{S}\) 上的转移矩阵 \(Q\)。这个链不需要有平稳分布
    \(\boldsymbol{\pi}\)。但它通常是一个容易模拟的链。”
- en: 'Answer for 3: c. Justification: The text states that the Hastings correction
    is “where the target distribution \(\boldsymbol{\pi}\) enters the picture, and
    the rejection probability is chosen to ensure that the new chain has the right
    stationary distribution, as we will see later.”'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 3 的答案：c. 证明：文本指出哈斯特斯校正“是目标分布 \(\boldsymbol{\pi}\) 进入画面，并且拒绝概率被选择以确保新链具有正确的平稳分布，正如我们稍后将会看到的。”
- en: 'Answer for 4: b. Justification: The text defines the joint distribution of
    \(v\) and \(h\) as \(\boldsymbol{\pi}(\mathbf{v},\mathbf{h}) = \frac{1}{Z} \exp(-\mathcal{E}(\mathbf{v},\mathbf{h}))\).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 4 的答案：b. 证明：文本定义了 \(v\) 和 \(h\) 的联合分布为 \(\boldsymbol{\pi}(\mathbf{v},\mathbf{h})
    = \frac{1}{Z} \exp(-\mathcal{E}(\mathbf{v},\mathbf{h}))\)。
- en: 'Answer for 5: c. Justification: The text explains that \(Z\), the partition
    function, “ensures that \(\boldsymbol{\pi}\) indeed sums to 1.”'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 5 的答案：c. 证明：文本解释说，\(Z\)，配分函数，“确保 \(\boldsymbol{\pi}\) 的总和确实为 1。”
- en: 7.6.1\. Markov chain Monte Carlo (MCMC)[#](#markov-chain-monte-carlo-mcmc "Link
    to this heading")
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6.1\. 马尔可夫链蒙特卡洛（MCMC）[#](#markov-chain-monte-carlo-mcmc "链接到这个标题")
- en: 'Suppose we are interested in generating samples from a target distribution
    \(\bpi = (\pi_i)_{i \in \S}\) over a set \(\S\). We have done this before. For
    instance, we generated samples from a mixture of Gaussians to test \(k\)-means
    clustering in different dimensions. There are many more applications. A canonical
    one is to estimate the mean of a function \(f\) under \(\bpi\): generate \(n\)
    independent samples \(Z_1,\ldots,Z_n\), all distributed according to \(\pi\),
    then compute'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们感兴趣的是从目标分布 \(\bpi = (\pi_i)_{i \in \S}\) 在集合 \(\S\) 上生成样本。我们之前已经这样做过了。例如，我们生成了高斯混合的样本来测试不同维度上的
    \(k\)-means 聚类。还有更多应用。一个典型应用是估计在 \(\bpi\) 下函数 \(f\) 的均值：生成 \(n\) 个独立的样本 \(Z_1,\ldots,Z_n\)，所有样本都服从
    \(\pi\)，然后计算
- en: \[ \frac{1}{n} \sum_{i=1}^n f(Z_i), \]
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n f(Z_i), \]
- en: which is approximately \(\E[f(Z_1)]\) by the law of large numbers, provided
    \(n\) is sufficiently large. Furthermore, this type of problem plays an important
    role in [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 根据大数定律，这大约等于 \(\E[f(Z_1)]\)，前提是 \(n\) 足够大。此外，这类问题在 [贝叶斯推断](https://en.wikipedia.org/wiki/Bayesian_inference)
    中起着重要作用。
- en: '**Sampling from simple distributions** When \(\bpi\) is a standard distribution
    or \(\S\) is relatively small, this can be done efficiently by using a random
    number generator, as we have done previously.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**从简单分布中采样** 当 \(\bpi\) 是标准分布或 \(\S\) 相对较小时，可以通过使用随机数生成器有效地完成，就像我们之前做的那样。'
- en: '**NUMERICAL CORNER:** Recall how this works. We first initialize the random
    number generator and use a `seed` for reproducibility.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 回想一下这是如何工作的。我们首先初始化随机数生成器，并使用一个 `seed` 来确保可重复性。'
- en: '[PRE48]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: To generate, say \(1000\), samples from a multivariate normal, say with mean
    \((0, 0)\) and covariance \(\begin{pmatrix}5 & 0\\0 & 1\end{pmatrix}\), we use
    [`numpy.random.Generator.multivariate_normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.multivariate_normal.html#numpy.random.Generator.multivariate_normal)
    as follows. The `.T` below transposes the output to separate the \(x\) and \(y\)
    coordinates into individual arrays.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 要从多元正态分布中生成，比如说 \(1000\) 个样本，均值 \((0, 0)\) 和协方差 \(\begin{pmatrix}5 & 0\\0 &
    1\end{pmatrix}\)，我们使用 `numpy.random.Generator.multivariate_normal` 如下。下面的 `.T`
    将输出转置，将 \(x\) 和 \(y\) 坐标分别分离到单独的数组中。
- en: '`rng.multivariate_normal(mean, cov, 1000)` returns a `(1000, 2)` array where
    each row is one sample:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`rng.multivariate_normal(mean, cov, 1000)` 返回一个 `(1000, 2)` 的数组，其中每一行是一个样本：'
- en: '[PRE49]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The `.T` transposes this to `(2, 1000)`:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`.T` 将其转置为 `(2, 1000)`：'
- en: '[PRE50]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now `x, y = ...` unpacks the two rows, giving you:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 `x, y = ...` 解包这两行，得到：
- en: '`x = [x1, x2, x3, ..., x1000]` (all x-coordinates)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x = [x1, x2, x3, ..., x1000]`（所有 x 坐标）'
- en: '`y = [y1, y2, y3, ..., y1000]` (all y-coordinates)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y = [y1, y2, y3, ..., y1000]`（所有 y 坐标）'
- en: '[PRE51]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Computing the mean of each component we get:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个分量的平均值，我们得到：
- en: '[PRE52]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This is somewhat close to the expected answer: \((0,0)\).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这与期望答案有些接近：\((0,0)\)。
- en: Using a larger number of samples, say \(10,000\), gives a better result.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更多的样本数量，比如 \(10,000\)，可以得到更好的结果。
- en: '[PRE56]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Sampling from an arbitrary distribution on a finite set is also straightforward
    – as long as the set is not too big. This can be done using [`numpy.random.Generator.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html).
    Borrowing the example from the documentation, the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 从有限集上的任意分布进行采样也很简单——只要集合不是太大。这可以使用 `numpy.random.Generator.choice` 来完成。借用文档中的例子，以下：
- en: '[PRE58]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: generates \(5\) samples from the set \(\S = \{\tt{pooh}, \tt{rabbit}, \tt{piglet},
    \tt{christopher}\}\) with respective probabilities \(0.5, 0.1, 0.1, 0.3\).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 从集合 \(\S = \{\tt{pooh}, \tt{rabbit}, \tt{piglet}, \tt{christopher}\}\) 中生成 \(5\)
    个样本，相应的概率为 \(0.5, 0.1, 0.1, 0.3\)。
- en: But this may not be practical when the state space \(\S\) is very large. As
    an example, later in this section, we will learn a “realistic” distribution of
    handwritten digits. We will do so using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 但当状态空间 \(\S\) 非常大时，这可能并不实用。例如，在本节的后面部分，我们将学习一个“现实”的手写数字分布。我们将使用 [MNIST 数据集](https://en.wikipedia.org/wiki/MNIST_database)
    来做到这一点。
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源
    隐藏代码单元格源</summary>
- en: '[PRE60]</details>'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE60]'
- en: Each image is \(28 \times 28\), so the total number of (black and white) pixels
    is \(784\).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像是 \(28 \times 28\)，所以（黑白）像素的总数是 \(784\)。
- en: '[PRE61]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: To specify a distribution over all possible black and white images of this size,
    we need in principle to assign a probability to a very large number of states.
    Our space here is \(\S = \{0,1\}^{784}\), imagining that \(0\) encodes white and
    \(1\) encodes black and that we have ordered the pixels in some arbitrary way.
    How big is this space?
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 为了指定所有可能黑白图像的分布，我们需要原则上为大量状态分配一个概率。我们在这里的空间是 \(\S = \{0,1\}^{784}\)，想象 \(0\)
    编码白色，\(1\) 编码黑色，并且我们以某种任意方式对像素进行了排序。这个空间有多大？
- en: 'Answer: \(2^{784}\).'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：\(2^{784}\)。
- en: 'Or in base \(10\), we compute \(\log_{10}(2^{784})\), which is:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在基 \(10\) 中，我们计算 \(\log_{10}(2^{784})\)，结果是：
- en: '[PRE65]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: So a little more than \(10^{236}\).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 所以略多于 \(10^{236}\)。
- en: This is much too large to naively plug into `rng.choice`!
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这太大，不能直接插入 `rng.choice`！
- en: \(\unlhd\)
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: So how to proceed? Instead we’ll use a Markov chain, as detailed next.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们该如何进行？相反，我们将使用一个马尔可夫链，如以下所述。
- en: '**General setting** The idea behind MCMC\(\idx{Markov chain Monte Carlo}\xdi\)
    is simple. To generate samples from \(\bpi\), use a Markov chain \((X_t)_{t \geq
    0}\) for which *it is the stationary distribution*. Indeed, we know from the *Convergence
    to Equilibrium Theorem* that if the chain is irreducible and aperiodic, then the
    distribution at time \(t\) is close to \(\bpi\) when \(t\) is large enough; and
    this holds for any initial dsitribution. Repeating this multiple times produces
    many independent, approximate samples from \(\bpi\).'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般设置** MCMC（马尔可夫链蒙特卡洛）背后的思想很简单。要从 \(\bpi\) 中生成样本，使用一个马尔可夫链 \((X_t)_{t \geq
    0}\)，其平稳分布是 \(\bpi\)。事实上，我们知道从 *收敛到平衡定理*，如果链是不可约的且非周期的，那么当 \(t\) 足够大时，时间 \(t\)
    的分布接近 \(\bpi\)；这对于任何初始分布都成立。重复多次会产生许多独立、近似的 \(\bpi\) 样本。'
- en: 'The question is now:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是：
- en: How to construct a transition matrix \(P\) whose stationary distribution is
    given target distribution \(\bpi\)?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何构造一个转移矩阵 \(P\)，其平稳分布是给定的目标分布 \(\bpi\)？
- en: How to ensure that this Markov chain is relatively easy to simulate?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何确保这个马尔可夫链相对容易模拟？
- en: 'Regarding the first question, we have seen how to compute the stationary distribution
    of a transition matrix (provided it exists and is unique). How do we invert the
    process? Note one difficulty: many transition matrices can have the same stationary
    distribution. This is in fact a blessing, as it gives room for designing a “good”
    Markov chain.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第一个问题，我们已经看到了如何计算转移矩阵的平稳分布（假设它存在且唯一）。我们如何逆转这个过程？注意一个困难：许多转移矩阵可以具有相同的平稳分布。这实际上是一种祝福，因为它为设计一个“良好”的马尔可夫链提供了空间。
- en: '**KNOWLEDGE CHECK:** Construct two distinct transition matrices on \(2\) states
    whose stationary distribution is uniform. \(\checkmark\)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查**：构造两个具有均匀平稳分布的 \(2\) 状态转移矩阵。 \(\checkmark\)'
- en: Regarding the second question, note that an obvious chain answering the first
    question is one that ignores the current state and chooses the next state according
    to \(\bpi\). We have already seen that this can be a problematic choice.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第二个问题，请注意，一个显然的链可以回答第一个问题，那就是忽略当前状态，并根据 \(\bpi\) 选择下一个状态。我们已经看到这可能会是一个有问题的选择。
- en: '**KNOWLEDGE CHECK:** Show that this chain has the desired stationary distribution.
    \(\checkmark\)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 证明这个链具有所需的平稳分布。 \(\checkmark\)'
- en: '**Metropolis-Hastings** We develop one standard technique that helps answer
    these two questions. It is known as the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)\(\idx{Metropolis-Hastings}\xdi\).
    It consists in two steps. We assume that \(\bpi > 0\), that is, \(\pi_i > 0, \forall
    i \in \S\).'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '**Metropolis-Hastings** 我们开发了一种标准技术，有助于回答这两个问题。它被称为 [Metropolis-Hastings 算法](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)\(\idx{Metropolis-Hastings}\xdi\)。它包括两个步骤。我们假设
    \(\bpi > 0\)，即 \(\pi_i > 0, \forall i \in \S\)。'
- en: '*Proposal distribution:* We first define a proposal chain, that is, a transition
    matrix \(Q\) on the space \(\S\). This chain *does not* need to have stationary
    distribution \(\bpi\). But it is typically a chain that is easy to simulate. A
    different way to think of this chain is that, for each state \(x \in \S\), we
    have a proposal distribution \(Q(x,\,\cdot\,)\) for the next state.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '*建议分布：* 我们首先定义一个建议链，即空间 \(\S\) 上的转移矩阵 \(Q\)。这个链 *不一定* 需要具有平稳分布 \(\bpi\)。但它通常是易于模拟的链。以另一种方式思考这个链是，对于每个状态
    \(x \in \S\)，我们都有一个建议分布 \(Q(x,\,\cdot\,)\) 用于下一个状态。'
- en: For instance, on the space of \(28 \times 28\) black-and-white images, we might
    pick a pixel uniformly at random and flip its value with probability \(1/2\).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 \(28 \times 28\) 的黑白图像空间中，我们可能会随机均匀选择一个像素，并以 \(1/2\) 的概率翻转其值。
- en: '**KNOWLEDGE CHECK:** In the previous example, what is the stationary distribution?'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 在前面的例子中，平稳分布是什么？'
- en: a) All-white with probability \(1/2\), all-black with probability \(1/2\).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: a) 以 \(1/2\) 的概率全白，以 \(1/2\) 的概率全黑。
- en: b) Uniform.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: b) 均匀分布。
- en: c) Too complex to compute.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: c) 太复杂而难以计算。
- en: d) What is a stationary distribution?
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: d) 什么是平稳分布？
- en: \(\checkmark\)
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: \(\checkmark\)
- en: '*Hastings correction:*\(\idx{Hastings correction}\xdi\) At each step, we first
    pick a state according to \(Q\), given the current state. Then we accept or reject
    this move according to a specially defined probability that depends on \(Q\) as
    well as \(\bpi\). This is where the target distribution \(\bpi\) enters the picture,
    and the rejection probability is chosen to ensure that the new chain has the right
    stationary distribution, as we will see later. But first we define the full algorithm.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hastings 修正：*\(\idx{Hastings correction}\xdi\) 在每一步，我们首先根据 \(Q\) 选择一个状态，给定当前状态。然后根据一个特殊定义的概率接受或拒绝这个移动，这个概率依赖于
    \(Q\) 以及 \(\bpi\)。这就是目标分布 \(\bpi\) 进入画面的时候，拒绝概率被选择以确保新链具有正确的平稳分布，正如我们稍后将会看到的。但首先我们定义完整的算法。'
- en: Formally, the algorithm goes as follows. Let \(x_0 \in \S\) be an arbitrary
    starting point and set \(X_0 := x_0\).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，算法如下。设 \(x_0 \in \S\) 为一个任意起点，并设置 \(X_0 := x_0\)。
- en: 'At each time \(t \geq 1\):'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间 \(t \geq 1\)：
- en: 1- Pick a state \(Y\) according to the distribution \(Q(X_{t-1}, \,\cdot\,)\),
    that is, row \(X_{t-1}\) of \(Q\).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 根据分布 \(Q(X_{t-1}, \,\cdot\,)\) 选择一个状态 \(Y\)，即 \(Q\) 的第 \(X_{t-1}\) 行。
- en: 2- With probability
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 以某种概率
- en: \[ \min\left\{1, \frac{\pi_{Y}}{\pi_{X_{t-1}}} \frac{Q(Y, X_{t-1})}{Q(X_{t-1},
    Y)} \right\} \]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min\left\{1, \frac{\pi_{Y}}{\pi_{X_{t-1}}} \frac{Q(Y, X_{t-1})}{Q(X_{t-1},
    Y)} \right\} \]
- en: we set \(X_{t} := Y\) (i.e., we accept the move), and otherwise we set \(X_{t}
    := X_{t-1}\) (i.e., we reject the move).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 \(X_{t} := Y\)（即我们接受这个移动），否则我们将 \(X_{t} := X_{t-1}\)（即我们拒绝这个移动）。
- en: '**KNOWLEDGE CHECK:** Should we worry about the denominator \(\pi_{X_{t-1}}
    Q(X_{t-1}, Y)\) being \(0\)? \(\checkmark\)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 我们应该担心分母 \(\pi_{X_{t-1}} Q(X_{t-1}, Y)\) 为 \(0\) 吗？ \(\checkmark\)'
- en: 'We make three observations:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做出三个观察：
- en: Taking a minimum with \(1\) ensures that acceptance probability is indeed between
    \(0\) and \(1\).
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 \(1\) 取最小值确保接受概率确实在 \(0\) 和 \(1\) 之间。
- en: We only need to know \(\bpi\) *up to a scaling factor* since the chain depends
    only on the ratio \(\frac{\pi_{Y}}{\pi_{X_{t-1}}}\). The scaling factor cancels
    out. This turns out to be critical in many applications of MCMC. We will see an
    example in the next subsection.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只需要知道 \(\bpi\) 的 *缩放因子*，因为链只依赖于比率 \(\frac{\pi_{Y}}{\pi_{X_{t-1}}}\)。缩放因子会相互抵消。这在
    MCMC 的许多应用中变得至关重要。我们将在下一小节中看到一个例子。
- en: If \(Q\) is symmetric, that is, \(Q(x,y) = Q(y,x)\) for all \(x, y \in \S\),
    then the ratio \(\frac{Q(Y, X_{t-1})}{Q(X_{t-1}, Y)}\) is just \(1\), leading
    to a simpler formula for the acceptance probability. In particular, in that case,
    moving to a state with a larger probability under \(\bpi\) is *always* accepted.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 \(Q\) 是对称的，即对于所有 \(x, y \in \S\)，有 \(Q(x,y) = Q(y,x)\)，那么比率和 \(\frac{Q(Y,
    X_{t-1})}{Q(X_{t-1}, Y)}\) 就是 \(1\)，从而得到一个更简单的接受概率公式。特别是，在这种情况下，在 \(\bpi\) 下移动到具有更大概率的状态总是被接受的。
- en: '**NUMERICAL CORNER:** Suppose \(\S = \{1,\cdots, n\} = [n]\) for some positive
    integer \(n\) and \(\bpi\) is proportional to a Poisson distribution with mean
    \(\lambda > 0\). That is,'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落:** 假设 \(\S = \{1,\cdots, n\} = [n]\) 对于某个正整数 \(n\)，并且 \(\bpi\) 与均值为
    \(\lambda > 0\) 的泊松分布成比例。也就是说，'
- en: \[ \pi_i = C e^{-\lambda} \frac{\lambda^i}{i!}, \quad \forall i \in \S \]
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \pi_i = C e^{-\lambda} \frac{\lambda^i}{i!}, \quad \forall i \in \S \]
- en: for some constant \(C\) chosen so that \(\sum_{i=1}^{n} \pi_i = 1\). Recall
    that we do not need to determine \(C\) as it is enough to know the target distribution
    up to a scaling factor by the previous remark.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个常数 \(C\)，使得 \(\sum_{i=1}^{n} \pi_i = 1\)。回想一下，我们不需要确定 \(C\)，因为根据之前的注释，只需要知道目标分布的缩放因子。
- en: To apply Metropolis-Hastings, we need a proposal chain. Consider the following
    choice. For each \(1 < i < n\), move to \(i+1\) or \(i-1\) with probability \(1/2\)
    each. For \(i=1\) (respectively \(i = n\)), move to \(2\) (respectively \(n-1\))
    with probability \(1/2\), otherwise stay where you are. For instance, if \(n =
    4\), then
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应用 Metropolis-Hastings 算法，我们需要一个提议链。考虑以下选择。对于每个 \(1 < i < n\)，以 \(1/2\) 的概率移动到
    \(i+1\) 或 \(i-1\)。对于 \(i=1\)（分别 \(i = n\)），以 \(1/2\) 的概率移动到 \(2\)（分别 \(n-1\)），否则保持在原地。例如，如果
    \(n = 4\)，那么
- en: \[\begin{split} Q = \begin{pmatrix} 1/2 & 1/2 & 0 & 0\\ 1/2 & 0 & 1/2 & 0\\
    0 & 1/2 & 0 & 1/2\\ 0 & 0 & 1/2 & 1/2 \end{pmatrix}, \end{split}\]
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Q = \begin{pmatrix} 1/2 & 1/2 & 0 & 0\\ 1/2 & 0 & 1/2 & 0\\
    0 & 1/2 & 0 & 1/2\\ 0 & 0 & 1/2 & 1/2 \end{pmatrix}, \end{split}\]
- en: which is indeed a stochastic matrix. It is also symmetric, so it does not enter
    into the acceptance probability by the previous remark.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个随机矩阵。它也是对称的，所以它不会通过之前的注释进入接受概率。
- en: To compute the acceptance probability, we only need to consider pairs of adjacent
    integers as they are the only one that have non-zero probability under \(Q\).
    Consider state \(1 < i < n\). Observe that
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算接受概率，我们只需要考虑相邻整数对，因为它们是唯一在 \(Q\) 下具有非零概率的。考虑状态 \(1 < i < n\)。观察如下
- en: \[ \frac{\pi_{i+1}}{\pi_{i}} = \frac{C e^{-\lambda} \lambda^{i+1}/(i+1)!}{C
    e^{-\lambda} \lambda^{i}/i!} = \frac{\lambda}{i+1} \]
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\pi_{i+1}}{\pi_{i}} = \frac{C e^{-\lambda} \lambda^{i+1}/(i+1)!}{C
    e^{-\lambda} \lambda^{i}/i!} = \frac{\lambda}{i+1} \]
- en: so a move to \(i+1\) happens with probability
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，向 \(i+1\) 的移动发生的概率
- en: \[ \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}, \]
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}, \]
- en: where the \(1/2\) factor from the proposal distribution. Similarly, it can be
    checked (try it!) that a move to \(i-1\) occurs with probability
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 其中包含来自提议分布的 \(1/2\) 因子。同样，可以检查（试试看！）向 \(i-1\) 的移动发生的概率
- en: \[ \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}. \]
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}. \]
- en: And we stay at \(i\) with probability \(1 - \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\}
    - \frac{1}{2} \min\left\{1, \frac{i}{\lambda}\right\}\). (Why is this guaranteed
    to be a probability?)
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 并且我们以概率 \(1 - \frac{1}{2} \min\left\{1, \frac{\lambda}{i+1}\right\} - \frac{1}{2}
    \min\left\{1, \frac{i}{\lambda}\right\}\) 停留在 \(i\) 处。（为什么这保证是一个概率？）
- en: A similar formula applies to \(i = 1, n\). (Try it!)
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(i = 1, n\) 也适用相同的公式。（试试看！）
- en: We are ready to apply Metropolis-Hastings.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备应用 Metropolis-Hastings 算法。
- en: '[PRE67]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Take \(\lambda = 1\) and \(n = 6\). We get the following transition matrix.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\lambda = 1\) 和 \(n = 6\)。我们得到以下转移矩阵。
- en: '[PRE68]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '**TRY IT!** Rewrite the function `mh_transition_poisson` without an explicit
    loop by using [broadcasting and vectorization](https://numpy.org/doc/stable/user/basics.broadcasting.html).
    ([Open in Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '**TRY IT!** 使用 [广播和向量化](https://numpy.org/doc/stable/user/basics.broadcasting.html)
    重写 `mh_transition_poisson` 函数，而不使用显式循环。（[在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
- en: We use our simulator from a previous section. We start from the uniform distribution
    and take \(100\) steps.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上一节中的模拟器。我们从均匀分布开始，并采取 \(100\) 步。
- en: '[PRE71]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Our sample is the final state of the trajectory.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的样本是轨迹的最终状态。
- en: '[PRE72]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: We repeat \(1000\) times.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复 \(1000\) 次。
- en: '[PRE74]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We plot the frequencies.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制频率图。
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源代码
    隐藏代码单元格源代码</summary>
- en: '[PRE75]</details> ![../../_images/d6e38b4f33052e917d7a2b6a03db11bd9c511daf60b88e2534f0a8be833345b9.png](../Images/4cb2314254f27c2be1f23bd733b95e2d.png)'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE75]</details> ![../../_images/d6e38b4f33052e917d7a2b6a03db11bd9c511daf60b88e2534f0a8be833345b9.png](../Images/4cb2314254f27c2be1f23bd733b95e2d.png)'
- en: If we increase the parameter \(\lambda\) (which is not quite the mean; why?),
    what would you expect will happen to the sampled distribution?
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们增加参数 \(\lambda\)（这并不是平均值；为什么？），你预计样本分布会发生什么变化？
- en: '**TRY IT!** Redo the simulations, but this time implement a general Metropolis-Hastings
    algorithm rather than specifying the transition matrix directly. That is, implement
    the algorithm for an arbitrary \(\bpi\) and \(Q\). Assume the state space is \([n]\).
    ([Open in Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试一下！** 重新进行模拟，但这次实现一个通用的Metropolis-Hastings算法，而不是直接指定转移矩阵。也就是说，实现一个针对任意
    \(\bpi\) 和 \(Q\) 的算法。假设状态空间是 \([n]\)。([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_prob_notebook.ipynb))'
- en: \(\unlhd\)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: It remains to prove that \(\bpi\) is needed the stationary distribution of the
    Metropolis-Hastings algorithm. We restrict ourselves to the symmetric case, that
    is, \(Q(x,y) = Q(y,x)\) for all \(x,y\).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的工作是证明 \(\bpi\) 是Metropolis-Hastings算法的平稳分布。我们限制在对称情况下，即 \(Q(x,y) = Q(y,x)\)
    对所有 \(x,y\) 成立。
- en: '**THEOREM** **(Correctness of Metropolis-Hastings)** \(\idx{correctness of
    Metropolis-Hastings}\xdi\) Consider the Metropolis-Hastings algorithm with target
    distribution \(\bpi\) over finite state space \(\S\) and symmetric proposal chain
    \(Q\). Assume further that \(\bpi\) is strictly positive and \(Q\) is irreducible
    over \(\S\). The resulting Markov chain is irreducible and reversible with respect
    to \(\bpi\). \(\sharp\)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(Metropolis-Hastings的正确性)** \(\idx{Metropolis-Hastings的正确性}\xdi\)
    考虑在有限状态空间 \(\S\) 上具有目标分布 \(\bpi\) 和对称提议链 \(Q\) 的Metropolis-Hastings算法。进一步假设 \(\bpi\)
    是严格正的，且 \(Q\) 在 \(\S\) 上是不可约的。所得马尔可夫链是不可约的，并且相对于 \(\bpi\) 是可逆的。 \(\sharp\)'
- en: '*Proof idea:* It is just a matter of writing down the resulting transition
    matrix \(P\) and checking the detailed balance conditions. Because of the minimum
    in the acceptance probability, one has to consider two cases each time.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路*: 这只是写下所得转移矩阵 \(P\) 并检查详细平衡条件的问题。由于接受概率中的最小值，每次都必须考虑两种情况。'
- en: '*Proof:* Let \(P\) denote the transition matrix of the resulting Markov chain.
    Our first task is to compute \(P\).'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 令 \(P\) 表示所得马尔可夫链的转移矩阵。我们的第一个任务是计算 \(P\).'
- en: Let \(x, y \in \S\) be a pair of distinct states such that \(Q(x, y) = Q(y,
    x) = 0\). Then, from \(x\) (respectively \(y\)), the proposal chain never picks
    \(y\) (respectively \(x\)) as the possible next state. Hence \(P(x,y) = P(y, x)
    = 0\) in that case.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 令 \(x, y \in \S\) 是一对不同的状态，使得 \(Q(x, y) = Q(y, x) = 0\)。然后，从 \(x\)（分别 \(y\)），提议链永远不会选择
    \(y\)（分别 \(x\)）作为可能的下一个状态。因此，在这种情况下 \(P(x,y) = P(y, x) = 0\)。
- en: So let \(x, y \in \S\) be a pair of distinct states such that \(Q(x, y) = Q(y,
    x) > 0\). Applying the Hastings correction, we get that the overall probability
    of moving to \(y\) from current state \(x\) is
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，令 \(x, y \in \S\) 是一对不同的状态，使得 \(Q(x, y) = Q(y, x) > 0\)。应用Hastings校正，我们得到从当前状态
    \(x\) 移动到 \(y\) 的整体概率是
- en: \[ P(x, y) = Q(x, y) \left(1 \land \frac{\pi_{y}}{\pi_{x}}\right) > 0, \]
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x, y) = Q(x, y) \left(1 \land \frac{\pi_{y}}{\pi_{x}}\right) > 0, \]
- en: where we used the symmetry of \(Q\) and the notation \(a \land b = \min\{a,b\}\).
    Similarly,
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了 \(Q\) 的对称性和记号 \(a \land b = \min\{a,b\}\)。同样，
- en: \[ P(y, x) = Q(y, x) \left(1 \land \frac{\pi_{x}}{\pi_{y}}\right) > 0. \]
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(y, x) = Q(y, x) \left(1 \land \frac{\pi_{x}}{\pi_{y}}\right) > 0. \]
- en: Since \(P(x,y)\) is strictly positive exactly when \(Q(x,y)\) is strictly positive
    (for distinct \(x,y\)), the chain \(P\) has the same transition graph as the chain
    \(Q\). Hence, because \(Q\) is irreducible, so is \(P\).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 \(P(x,y)\) 在 \(Q(x,y)\) 严格正的情况下严格正（对于不同的 \(x,y\)），因此 \(P\) 链与 \(Q\) 链具有相同的转移图。因此，因为
    \(Q\) 是不可约的，所以 \(P\) 也是不可约的。
- en: It remains to check the detailed balance conditions. There are two cases. Without
    loss of generality, say \(\pi_x \leq \pi_y\). Then the previous formulas for \(P\)
    simplify to
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的工作是检查详细平衡条件。有两种情况。不失一般性，假设 \(\pi_x \leq \pi_y\)。然后 \(P\) 的前述公式简化为
- en: \[ P(x, y) = Q(x, y) \quad\text{and}\quad P(y, x) = Q(y, x) \frac{\pi_{x}}{\pi_{y}}.
    \]
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(x, y) = Q(x, y) \quad\text{和}\quad P(y, x) = Q(y, x) \frac{\pi_{x}}{\pi_{y}}.
    \]
- en: Hence,
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，
- en: \[ \pi_x P(x,y) = \pi_x Q(x,y) = \pi_x Q(y,x) = \pi_x \frac{\pi_y}{\pi_y} Q(y,x)
    = \pi_y P(y,x), \]
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \pi_x P(x,y) = \pi_x Q(x,y) = \pi_x Q(y,x) = \pi_x \frac{\pi_y}{\pi_y} Q(y,x)
    = \pi_y P(y,x), \]
- en: where we used the symmetry of \(Q\) to obtain the second equality. That establishes
    the reversibility of \(P\) and concludes the proof. \(\square\)
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了 \(Q\) 的对称性来获得第二个等式。这确立了 \(P\) 的可逆性，从而完成了证明。\(\square\)
- en: '**CHAT & LEARN** The Metropolis-Hastings algorithm can be used for Bayesian
    inference. Ask your favorite AI chatbot to explain how MCMC methods are used in
    Bayesian inference and to provide an example of using the Metropolis-Hastings
    algorithm for parameter estimation in a simple Bayesian model. \(\ddagger\)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** Metropolis-Hastings 算法可以用于贝叶斯推断。请你的喜欢的 AI 聊天机器人解释 MCMC 方法在贝叶斯推断中的应用，并提供一个使用
    Metropolis-Hastings 算法在简单贝叶斯模型中进行参数估计的例子。\(\ddagger\)'
- en: 7.6.2\. Gibbs sampling[#](#gibbs-sampling "Link to this heading")
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6.2\. Gibbs 抽样[#](#gibbs-sampling "链接到这个标题")
- en: We have seen that one challenge of the Metropolis-Hastings approach is to choose
    a good proposal chain. Gibbs sampling\(\idx{Gibbs sampling}\xdi\) is a canonical
    way of addressing this issue that has many applications. It applies in cases where
    the states are vectors, typically with a large number of coordinates, and where
    the target distribution has the kind of conditional independence properties we
    have encountered previously in the previous chapter.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，Metropolis-Hastings 方法的一个挑战是选择一个好的建议链。Gibbs 抽样\(\idx{Gibbs sampling}\xdi\)
    是解决此问题的经典方法，它有广泛的应用。它适用于状态是向量的情况，通常具有大量的坐标，并且目标分布具有我们在上一章中先前遇到的某种条件独立性属性。
- en: '**General setting** Here we will assume that \(\S = \Z^d\) where \(\Z\) is
    a finite set and \(d\) is the dimension. To emphasize that states are vectors,
    we will boldface letters, e.g., \(\bx = (x_i)_{i=1}^d\), \(\by = (y_i)_{i=1}^d\),
    etc., to denote them.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般设置** 在这里，我们将假设 \(\S = \Z^d\)，其中 \(\Z\) 是一个有限集合，\(d\) 是维度。为了强调状态是向量，我们将使用粗体字母，例如，\(\bx
    = (x_i)_{i=1}^d\)，\(\by = (y_i)_{i=1}^d\) 等，以表示它们。'
- en: We will need the following special notation. For a vector \(\bx \in \Z^d\) and
    an index \(i \in [d]\), we write
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要以下特殊符号。对于向量 \(\bx \in \Z^d\) 和索引 \(i \in [d]\)，我们写
- en: \[ \bx_{-i} = (x_1, \ldots,x_{i-1}, x_{i+1}, \ldots, x_d) \]
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bx_{-i} = (x_1, \ldots,x_{i-1}, x_{i+1}, \ldots, x_d) \]
- en: for the vector \(\bx\) where the coordinate \(x_i\) is dropped.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 对于向量 \(\bx\)，其中坐标 \(x_i\) 被舍弃。
- en: If \(\boldsymbol{\pi}\) is the target distribution, we let \(\pi_i(x_i|\bx_{-i})\)
    be the conditional probability that \(X_i = x_i\) given that \(\bX_{-i} = \bx_{-i}\)
    under the distribution \(\boldsymbol{\pi}\), i.e., \(\bX = (X_1,\ldots,X_d) \sim
    \boldsymbol{\pi}\). We assume that \(\pi_{\bx} > 0\) for all \(\bx \in \Z^d\).
    As a result, \(\pi_i(x_i|\bx_{-i}) > 0\) as well (prove it!).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 \(\boldsymbol{\pi}\) 是目标分布，我们让 \(\pi_i(x_i|\bx_{-i})\) 是在分布 \(\boldsymbol{\pi}\)
    下，给定 \(\bX_{-i} = \bx_{-i}\) 时 \(X_i = x_i\) 的条件概率，即 \(\bX = (X_1,\ldots,X_d)
    \sim \boldsymbol{\pi}\)。我们假设对于所有 \(\bx \in \Z^d\)，\(\pi_{\bx} > 0\)。因此，\(\pi_i(x_i|\bx_{-i})
    > 0\) 也成立（证明它！）。
- en: A basic version of the Gibbs sampler generates a sequence of vectors \(\bX_0,
    \bX_1, \ldots, \bX_t, \ldots\) in \(\Z^d\) as follows. We denote the coordinates
    of \(\bX_t\) by \((X_{t,1}, \ldots, X_{t,d})\). We denote the vector of all coordinates
    of \(\bX_t\) except \(i\) by \(\bX_{t,-i}\).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: Gibbs 抽样的基本版本生成一个向量序列 \(\bX_0, \bX_1, \ldots, \bX_t, \ldots\) 在 \(\Z^d\) 中，如下所示。我们用
    \((X_{t,1}, \ldots, X_{t,d})\) 表示 \(\bX_t\) 的坐标。我们用 \(\bX_{t,-i}\) 表示 \(\bX_t\)
    除了 \(i\) 以外的所有坐标的向量。
- en: Pick \(\bX_0\) according to an arbitrary initial distribution \(\boldsymbol{\mu}\)
    over \(\Z^d\).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 \(\Z^d\) 上的任意初始分布 \(\boldsymbol{\mu}\) 选择 \(\bX_0\)。
- en: 'At each time \(t \geq 1\):'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间 \(t \geq 1\)：
- en: 1- Pick a coordinate \(i\) uniformly at random in \([d]\).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 在 \([d]\) 中随机均匀地选择一个坐标 \(i\)。
- en: 2- Update coordinate \(X_{t,i}\) according to \(\pi_i(\,\cdot\,|\bX_{t-1,-i})\)
    while leaving all other coordinates unchanged.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 根据分布 \(\pi_i(\,\cdot\,|\bX_{t-1,-i})\) 更新坐标 \(X_{t,i}\)，同时保持所有其他坐标不变。
- en: We will implement it in a special case in the next subsection. But first we
    argue that it has the desired stationary distribution.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一小节中实现它。但首先，我们论证它具有期望的平稳分布。
- en: It suffices to establish that the Gibbs sampler is a special case of the Metropolis-Hastings
    algorithm. For this, we must identify the appropriate proposal chain \(Q\).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 证明 Gibbs 抽样是 Metropolis-Hastings 算法的一个特例。为此，我们必须识别适当的建议链 \(Q\)。
- en: 'We claim that the following choice works: for \(\bx \neq \by\),'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称以下选择是有效的：对于 \(\bx \neq \by\)，
- en: \[\begin{split} Q(\bx, \by) = \begin{cases} \frac{1}{d} \pi_i(y_i|\bx_{-i})
    & \text{if $\by_{-i} = \bx_{-i}$ for some $i \in [d]$}\\ 0 & \text{o.w.} \end{cases}
    \end{split}\]
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Q(\bx, \by) = \begin{cases} \frac{1}{d} \pi_i(y_i|\bx_{-i})
    & \text{如果对于某些 \(i \in [d]\)，\(\by_{-i} = \bx_{-i}\)}\\ 0 & \text{否则} \end{cases}
    \end{split}\]
- en: The condition “\(\by_{-i} = \bx_{-i}\) for some \(i \in [d]\)” ensures that
    we only consider moves that affect a single coordinate \(i\). The factor \(1/d\)
    means that we pick that coordinate uniformly at random among all coordinates.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 条件“对于某些 \(i \in [d]\)，\(\by_{-i} = \bx_{-i}\)”确保我们只考虑影响单个坐标 \(i\) 的移动。因子 \(1/d\)
    表示我们在所有坐标中均匀随机选择该坐标。
- en: For each \(\bx\), we stay put with the remaining probability.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个 \(\bx\)，我们以剩余的概率保持原位。
- en: '**KNOWLEDGE CHECK:** Write down explicitly the staying probability \(Q(\bx,
    \bx)\) and check it is indeed in \([0,1]\). \(\checkmark\)'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识检查：** 明确写出保持概率 \(Q(\bx, \bx)\) 并检查它确实在 \([0,1]\) 范围内。 \(\checkmark\)'
- en: In general, this \(Q\) is not symmetric. For \(\bx \neq \by\) with \(Q(\bx,
    \by) > 0\) where \(i\) is the non-matching coordinate, the acceptance probability
    is
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这个 \(Q\) 不是对称的。对于 \(\bx \neq \by\) 且 \(Q(\bx, \by) > 0\) 的 \(i\) 是不匹配的坐标，接受概率是
- en: \[\begin{align*} \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{Q(\by, \bx)}{Q(\bx,
    \by)} \right\} &= \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\frac{1}{d}
    \pi_i(x_i|\by_{-i})}{\frac{1}{d} \pi_i(y_i|\bx_{-i})} \right\}\\ &= \min\left\{1,
    \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})} \right\},
    \end{align*}\]
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{Q(\by, \bx)}{Q(\bx,
    \by)} \right\} &= \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\frac{1}{d}
    \pi_i(x_i|\by_{-i})}{\frac{1}{d} \pi_i(y_i|\bx_{-i})} \right\}\\ &= \min\left\{1,
    \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})} \right\},
    \end{align*}\]
- en: where we used that \(\bx_{-i} = \by_{-i}\) in the second equality.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们在第二个等式中使用了 \(\bx_{-i} = \by_{-i}\)。
- en: 'Recall the definition of the conditional probability as a ratio: \(\P[A|B]
    = \P[A\cap B]/\P[B]\). Applying that definition, both conditional probabilities
    \(\pi_i(x_i|\bx_{-i})\) and \(\pi_i(y_i|\bx_{-i})\) have the *same denominator*.
    Their respective numerators on the other hand are \(\pi_{\bx}\) and \(\pi_{\by}\).
    Hence,'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆条件概率的定义为比：\(\P[A|B] = \P[A\cap B]/\P[B]\)。应用该定义，条件概率 \(\pi_i(x_i|\bx_{-i})\)
    和 \(\pi_i(y_i|\bx_{-i})\) 具有相同的分母。另一方面，它们的分子分别是 \(\pi_{\bx}\) 和 \(\pi_{\by}\)。因此，
- en: \[ \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})}
    \right\} = \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_{\bx}}{\pi_{\by}}
    \right\} = 1. \]
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_i(x_i|\bx_{-i})}{\pi_i(y_i|\bx_{-i})}
    \right\} = \min\left\{1, \frac{\pi_{\by}}{\pi_{\bx}} \frac{\pi_{\bx}}{\pi_{\by}}
    \right\} = 1. \]
- en: In other words, the proposed move is always accepted! Therefore \(P = Q\), which
    is indeed the Gibbs sampler. It also establishes by *Correctness of Metropolis-Hastings*
    that \(P\) is reversible with respect to \(\pi\). It is also irreducible (Why?).
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，提出的移动总是被接受！因此 \(P = Q\)，这确实是吉布斯采样器。它还通过 *Metropolis-Hastings 正确性* 建立了 \(P\)
    相对于 \(\pi\) 是可逆的。它也是不可约的（为什么？）。
- en: Here we picked a coordinate at random. It turns out that other choices are possible.
    For example, one could update each coordinate in some deterministic order, or
    one could update blocks of coordinates at a time. Under some conditions, these
    schemes can still produce an algorithm simulating the desired distribution. We
    will not detail this here, but our implementation below does use a block scheme.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们随机选择了一个坐标。结果，其他选择也是可能的。例如，可以按某种确定性顺序更新每个坐标，或者可以一次更新坐标块。在某些条件下，这些方案仍然可以产生模拟所需分布的算法。我们在此不会详细说明，但我们的实现下面确实使用了块方案。
- en: '**An example: restricted Boltzmann machines (RBM)** We implement the Gibbs
    sampler on a specific probabilistic model, a so-called restricted Boltzmann machine
    (RBM)\(\idx{restricted Boltzmann machine}\xdi\), and apply it to the generation
    of random images from a “realistic” distribution. For more on Boltzmann machines,
    including their restricted and deep versions, see [here](https://en.wikipedia.org/wiki/Boltzmann_machine).
    We will not describe them in great details here, but only use them as an example
    of a complex distribution.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：受限玻尔兹曼机 (RBM)** 我们在特定的概率模型上实现吉布斯采样器，即所谓的受限玻尔兹曼机 (RBM)\(\idx{受限玻尔兹曼机}\xdi\)，并将其应用于从“现实”分布生成随机图像。有关玻尔兹曼机的更多信息，包括其受限和深度版本，请参阅[这里](https://en.wikipedia.org/wiki/Boltzmann_machine)。我们在此不会详细描述它们，但仅将它们用作复杂分布的示例。'
- en: '*Probabilistic model:* An RBM has \(m\) visible units (i.e., observed variables)
    and \(n\) hidden units (i.e., hidden variables). It is represented by a complete
    bipartite graph between the two.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率模型:* RBM 有 \(m\) 个可见单元（即，观测变量）和 \(n\) 个隐藏单元（即，隐藏变量）。它由两个之间的完全二部图表示。'
- en: '![An RBM (with help from ChatGPT; code converted and adapted from Source)](../Images/4fb58292c78ce9956928cadb68b7af09.png)'
  id: totrans-410
  prefs: []
  type: TYPE_IMG
  zh: '![一个 RBM（得益于 ChatGPT 的帮助；代码从源转换并调整）](../Images/4fb58292c78ce9956928cadb68b7af09.png)'
- en: Visible unit \(i\) is associated a variable \(v_i\) and hidden unit \(j\) is
    associated a variable \(h_j\). We define the corresponding vectors \(\bv = (v_1,\ldots,v_m)\)
    and \(\bh = (h_1,\ldots,h_n)\). For our purposes, it will suffice to assume that
    \(\bv \in \{0,1\}^m\) and \(\bh \in \{0,1\}^n\). These are referred to as binary
    units.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 可见单元 \(i\) 与变量 \(v_i\) 相关联，隐藏单元 \(j\) 与变量 \(h_j\) 相关联。我们定义相应的向量 \(\bv = (v_1,\ldots,v_m)\)
    和 \(\bh = (h_1,\ldots,h_n)\)。对于我们的目的，假设 \(\bv \in \{0,1\}^m\) 和 \(\bh \in \{0,1\}^n\)
    就足够了。这些被称为二进制单元。
- en: The probabilistic model has a number of parameters. Each visible unit \(i\)
    has an offset \(b_i \in \mathbb{R}\) and each hidden unit \(j\) has an offset
    \(c_j \in \mathbb{R}\). We write \(\bb = (b_1,\ldots,b_m)\) and \(\bc = (c_1,\ldots,c_n)\)
    for the offset vectors. For each pair \((i,j)\) of visible and hidden units (or,
    put differently, for each edge in the complete bipartite graph), there is a weight
    \(w_{i,j} \in \mathbb{R}\). We write \(W = (w_{i,j})_{i,j=1}^{m,n}\) for the weight
    matrix.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 概率模型有许多参数。每个可见单元 \(i\) 有一个偏移量 \(b_i \in \mathbb{R}\)，每个隐藏单元 \(j\) 有一个偏移量 \(c_j
    \in \mathbb{R}\)。我们用 \(\bb = (b_1,\ldots,b_m)\) 和 \(\bc = (c_1,\ldots,c_n)\) 表示偏移向量。对于可见单元和隐藏单元的每一对
    \((i,j)\)（或者换句话说，对于完全二部图中的每条边），都有一个权重 \(w_{i,j} \in \mathbb{R}\)。我们用 \(W = (w_{i,j})_{i,j=1}^{m,n}\)
    表示权重矩阵。
- en: 'To define the probability distribution, we need the so-called [energy](https://en.wikipedia.org/wiki/Energy-based_model)\(\idx{energy-based
    model}\xdi\) (as you may have guessed, this terminology comes from related models
    in [physics](https://en.wikipedia.org/wiki/Boltzmann_distribution)): for \(\bv
    \in \{0,1\}^m\) and \(\bh \in \{0,1\}^n\),'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义概率分布，我们需要所谓的[能量](https://en.wikipedia.org/wiki/Energy-based_model)\(\idx{energy-based
    model}\xdi\)（正如你可能已经猜到的，这个术语来自物理学中的相关模型）：对于 \(\bv \in \{0,1\}^m\) 和 \(\bh \in
    \{0,1\}^n\)，
- en: \[\begin{align*} \cE(\bv, \bh) &= - \bv^T W \bh - \bb^T \bv - \bc^T \bh\\ &=
    - \sum_{i=1}^m \sum_{j=1}^n w_{i,j} v_i h_j - \sum_{i=1}^m b_i v_i - \sum_{j=1}^n
    c_j h_j. \end{align*}\]
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \cE(\bv, \bh) &= - \bv^T W \bh - \bb^T \bv - \bc^T \bh\\ &=
    - \sum_{i=1}^m \sum_{j=1}^n w_{i,j} v_i h_j - \sum_{i=1}^m b_i v_i - \sum_{j=1}^n
    c_j h_j. \end{align*}\]
- en: The joint distribution of \(\bv\) and \(\bh\) is
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bv\) 和 \(\bh\) 的联合分布是
- en: \[ \boldsymbol{\pi}(\bv, \bh) = \frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right),
    \]
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \boldsymbol{\pi}(\bv, \bh) = \frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right),
    \]
- en: where \(Z\), the [partition function](https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29)\(\idx{partition
    function}\xdi\) (a function of \(W,\bb,\bc\)), ensures that \(\boldsymbol{\pi}\)
    indeed sums to \(1\).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(Z\)，[配分函数](https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29)\(\idx{partition
    function}\xdi\)（一个关于 \(W,\bb,\bc\) 的函数），确保 \(\boldsymbol{\pi}\) 的和为 \(1\)。
- en: We will be interested in sampling from the marginal over visible units, that
    is,
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注从可见单元的边缘分布中进行采样，即，
- en: \[ \rho(\bv) = \sum_{\bh \in \{0,1\}^n} \boldsymbol{\pi}(\bv, \bh). \]
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \rho(\bv) = \sum_{\bh \in \{0,1\}^n} \boldsymbol{\pi}(\bv, \bh). \]
- en: When \(m\) and/or \(n\) are large, computing \(\rho\) or \(\boldsymbol{\pi}\)
    explicitly – or even numerically – is impractical.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(m\) 和/或 \(n\) 很大时，显式地计算 \(\rho\) 或 \(\boldsymbol{\pi}\)——甚至数值上——是不切实际的。
- en: We develop the Gibbs sampler for this model next.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来为这个模型开发吉布斯采样器。
- en: '*Gibbs sampling:* We sample from the joint distribution \(\boldsymbol{\pi}\)
    and observe only \(\bv\).'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '*吉布斯采样:* 我们从联合分布 \(\boldsymbol{\pi}\) 中采样，并且只观察 \(\bv\)。'
- en: We need to compute the conditional probabilities given every other variable.
    The sigmoid function, \(\sigma(x)\), will once again make an appearance.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要计算给定每个其他变量的条件概率。sigmoid 函数，\(\sigma(x)\)，将再次出现。
- en: '[PRE76]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Fix a visible unit \(i \in [m]\). For a pair \((\bv, \bh)\), we denote by \((\bv_{[i]},
    \bh)\) the same pair where coordinate \(i\) of \(\bv\) is flipped. Given every
    other variable, i.e., \((\bv_{-i},\bh)\), and using a superscript \(\text{v}\)
    to indicate the probability of a visible unit, the conditional probability of
    \(v_i\) is
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 固定一个可见单元 \(i \in [m]\)。对于一对 \((\bv, \bh)\)，我们用 \((\bv_{[i]}, \bh)\) 表示相同的一对，其中
    \(\bv\) 的坐标 \(i\) 被翻转。给定每个其他变量，即 \((\bv_{-i},\bh)\)，使用上标 \(\text{v}\) 来表示可见单元的概率，\(v_i\)
    的条件概率是
- en: \[\begin{align*} \pi^{\text{v}}_i(v_i|\bv_{-i},\bh) &= \frac{\boldsymbol{\pi}(\bv,
    \bh)}{\boldsymbol{\pi}(\bv, \bh) + \boldsymbol{\pi}(\bv_{[i]}, \bh)}\\ &= \frac{\frac{1}{Z}
    \exp\left(- \cE(\bv, \bh)\right)}{\frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right)
    + \frac{1}{Z} \exp\left(- \cE(\bv_{[i]}, \bh)\right)}. \end{align*}\]
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \pi^{\text{v}}_i(v_i|\bv_{-i},\bh) &= \frac{\boldsymbol{\pi}(\bv,
    \bh)}{\boldsymbol{\pi}(\bv, \bh) + \boldsymbol{\pi}(\bv_{[i]}, \bh)}\\ &= \frac{\frac{1}{Z}
    \exp\left(- \cE(\bv, \bh)\right)}{\frac{1}{Z} \exp\left(- \cE(\bv, \bh)\right)
    + \frac{1}{Z} \exp\left(- \cE(\bv_{[i]}, \bh)\right)}. \end{align*}\]
- en: In this last ratio, the partition functions (the \(Z\)’s) cancel out. Moreover,
    all the terms in the exponentials *not depending* on the \(i\)-th visible unit
    actually factor out and cancel out as well – they are identical in all three exponentials.
    Similarly, the terms in the exponentials *depending only on \(\bh\)* also factor
    out and cancel out.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最后的比率中，配分函数（\(Z\)）相互抵消。此外，所有不依赖于第 \(i\) 个可见单元的指数项实际上都分解出来并相互抵消——它们在三个指数中都是相同的。同样，只依赖于
    \(\bh\) 的指数项也分解出来并相互抵消。
- en: 'What we are left with is:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所剩下的就是：
- en: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{\exp\left(\sum_{j=1}^n
    w_{i,j} v_i h_j + b_i v_i\right)} {\exp\left(\sum_{j=1}^n w_{i,j} v_i h_j + b_i
    v_i\right) + \exp\left(\sum_{j=1}^n w_{i,j} (1-v_i) h_j + b_i (1-v_i)\right)},
    \end{align*}\]
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{\exp\left(\sum_{j=1}^n
    w_{i,j} v_i h_j + b_i v_i\right)} {\exp\left(\sum_{j=1}^n w_{i,j} v_i h_j + b_i
    v_i\right) + \exp\left(\sum_{j=1}^n w_{i,j} (1-v_i) h_j + b_i (1-v_i)\right)},
    \end{align*}\]
- en: where we used the fact that flipping \(v_i \in \{0,1\}\) is the same as setting
    it to \(1 - v_i\), a transformation which indeed sends \(0\) to \(1\) and \(1\)
    to \(0\).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了翻转 \(v_i \in \{0,1\}\) 等于将其设置为 \(1 - v_i\) 的事实，这种转换确实将 \(0\) 转换为 \(1\)，将
    \(1\) 转换为 \(0\)。
- en: This expression does not depend on \(\bv_{-i}\). In other words, the \(i\)-th
    visible unit is conditionally independent of all other visible units given the
    hidden units.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式不依赖于 \(\bv_{-i}\)。换句话说，第 \(i\) 个可见单元在给定隐藏单元的情况下与所有其他可见单元条件独立。
- en: We simplify the expression
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简化了表达式
- en: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{1} {1 + \exp\left(\sum_{j=1}^n
    w_{i,j} (1-2 v_i) h_j + b_i (1- 2v_i)\right)}\\ &= \sigma\left(\sum_{j=1}^n w_{i,j}
    (2 v_i-1) h_j + b_i (2v_i-1)\right). \end{align*}\]
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{v}}_i(v_i|\bv_{-i},\bh)\\ &= \frac{1} {1 + \exp\left(\sum_{j=1}^n
    w_{i,j} (1-2 v_i) h_j + b_i (1- 2v_i)\right)}\\ &= \sigma\left(\sum_{j=1}^n w_{i,j}
    (2 v_i-1) h_j + b_i (2v_i-1)\right). \end{align*}\]
- en: In particular, the conditional mean of the \(i\)-th visible unit given everything
    else is
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，给定其他所有条件的第 \(i\) 个可见单元的条件均值是
- en: \[\begin{align*} 0 \cdot \pi^{\text{v}}_i(0|\bv_{-i},\bh) + 1 \cdot \pi^{\text{v}}_i(1|\bv_{-i},\bh)
    &= \pi^{\text{v}}_i(1|\bv_{-i},\bh)\\ &= \sigma\left(\sum_{j=1}^n w_{i,j} h_j
    + b_i \right)\\ &= \sigma\left((W \bh + \bb)_i \right) \end{align*}\]
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 0 \cdot \pi^{\text{v}}_i(0|\bv_{-i},\bh) + 1 \cdot \pi^{\text{v}}_i(1|\bv_{-i},\bh)
    &= \pi^{\text{v}}_i(1|\bv_{-i},\bh)\\ &= \sigma\left(\sum_{j=1}^n w_{i,j} h_j
    + b_i \right)\\ &= \sigma\left((W \bh + \bb)_i \right) \end{align*}\]
- en: Similarly for the conditional probability of the \(j\)-th hidden unit given
    everything else, we have
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于给定其他所有条件的第 \(j\) 个隐藏单元的条件概率，我们有
- en: \[\begin{align*} &\pi^{\text{h}}_j(h_j|\bv,\bh_{-j})\\ &= \sigma\left(\sum_{i=1}^m
    w_{i,j} v_i (2h_j -1) + c_j (2h_j -1)\right). \end{align*}\]
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\pi^{\text{h}}_j(h_j|\bv,\bh_{-j})\\ &= \sigma\left(\sum_{i=1}^m
    w_{i,j} v_i (2h_j -1) + c_j (2h_j -1)\right). \end{align*}\]
- en: The conditional mean given everything else is
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 给定其他所有条件下的条件均值是
- en: \[\begin{align*} 0 \cdot \pi^{\text{h}}_j(0|\bv,\bh_{-j}) + 1 \cdot \pi^{\text{h}}_j(1|\bv,\bh_{-j})
    &= \pi^{\text{h}}_j(1|\bv,\bh_{-j}) = \sigma\left((W^T \bv + \bc)_j \right). \end{align*}\]
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 0 \cdot \pi^{\text{h}}_j(0|\bv,\bh_{-j}) + 1 \cdot \pi^{\text{h}}_j(1|\bv,\bh_{-j})
    &= \pi^{\text{h}}_j(1|\bv,\bh_{-j}) = \sigma\left((W^T \bv + \bc)_j \right). \end{align*}\]
- en: And the \(j\)-th hidden unit is conditionally independent of all other hidden
    units given the visible units.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 并且第 \(j\) 个隐藏单元在给定可见单元的情况下与所有其他隐藏单元条件独立。
- en: We implement the Gibbs sampler for an RBM. Rather than updating the units at
    random, we use a block approach. Specifically, we update all hidden units independently,
    given the visible units; then we update all visible units independently, given
    the hidden units. In each case, this is warranted by the conditional independence
    structure revealed above.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了 RBM 的吉布斯采样器。我们不是随机更新单元，而是使用了一种分块方法。具体来说，我们独立地更新所有隐藏单元，给定可见单元；然后我们独立地更新所有可见单元，给定隐藏单元。在每种情况下，这都由上面揭示的条件独立性结构所保证。
- en: We first implement the conditional means using the formulas previously derived.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用之前推导出的公式来实现条件均值。
- en: '[PRE77]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: We next implement one step of the sampler, which consists in updating all hidden
    units, followed by updating all visible units.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来实现采样器的一步，这包括更新所有隐藏单元，然后更新所有可见单元。
- en: '[PRE78]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Finally, we repeat these steps `k` times. We only return the visible units `v`.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们重复这些步骤 \(k\) 次。我们只返回可见单元 `v`。
- en: '[PRE79]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Here `v_0` is the initial visible unit states. We do not need to initialize
    the hidden ones as this is done automatically in the first update step. In the
    next subsection, we will take the initial distribution of \(\bv\) to be independent
    Bernoullis with success probability \(1/2\).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 \(v_0\) 是初始可见单元状态。我们不需要初始化隐藏单元，因为这是在第一次更新步骤中自动完成的。在下一小节中，我们将 \(\bv\) 的初始分布设为独立的伯努利分布，成功概率为
    \(1/2\)。
- en: '**NUMERICAL CORNER:** We apply our Gibbs sampler to generating images. As mentioned
    previously, we use the MNIST dataset to learn a “realistic” distribution of handwritten
    digit images. Here the images are encoded by the visible units of an RBM. Then
    we sample from this model.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：** 我们将我们的吉布斯采样器应用于生成图像。如前所述，我们使用 MNIST 数据集来学习手写数字图像的“真实”分布。这里的图像由 RBM
    的可见单元编码。然后我们从该模型中采样。'
- en: We first need to train the model on the data. We will not show how this is done
    here, but instead use [`sklearn.neural_network.BernoulliRBM`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html).
    (Some details of how this training is done is provided [here](https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html#stochastic-maximum-likelihood-learning).)
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要在数据上训练模型。我们不会在这里展示如何进行，而是使用 `sklearn.neural_network.BernoulliRBM`。 (有关如何进行此训练的详细信息，请参阅
    [此处](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html)。)
- en: '[PRE80]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: To simplify the analysis and speed up the training, we only keep digits \(0\),
    \(1\) and \(5\).
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化分析和加快训练速度，我们只保留数字 \(0\)、\(1\) 和 \(5\)。
- en: '[PRE81]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: We flatten the images (which have already been “rounded” to black-and-white;
    see the first subsection).
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像展平（这些图像已经被“四舍五入”为黑白；请参阅第一小节）。
- en: '[PRE82]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: We now fit the model. Choosing the hyperparameters of the training algorithm
    is tricky. The following seem to work reasonably well. (For a more systematic
    approach to tuning hyperparameters, see [here](https://scikit-learn.org/stable/modules/grid_search.html).)
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拟合模型。选择训练算法的超参数是棘手的。以下似乎效果相当好。（有关调整超参数的更系统方法，请参阅 [此处](https://scikit-learn.org/stable/modules/grid_search.html)。）
- en: '[PRE83]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '**In a Jupyter environment, please rerun this cell to show the HTML representation
    or trust the notebook.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '**在 Jupyter 环境中，请重新运行此单元格以显示 HTML 表示或信任笔记本。**'
- en: On GitHub, the HTML representation is unable to render, please try loading this
    page with nbviewer.org.**
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GitHub 上，HTML 表示无法渲染，请尝试使用 nbviewer.org 加载此页面。**
- en: '[PRE85]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We are ready to sample from the trained RBM. We extract the learned parameters
    from `rbm`.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好从训练好的 RBM 中采样。我们从 `rbm` 中提取学习到的参数。
- en: '[PRE86]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: To generate \(25\) samples, we first generate \(25\) independent initial states.
    We stack them into a matrix, where each row is a different flattened random noise
    image.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成 \(25\) 个样本，我们首先生成 \(25\) 个独立的初始状态。我们将它们堆叠成一个矩阵，其中每一行是一个不同的展平随机噪声图像。
- en: '[PRE92]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: To process all samples simultaneously, we make a small change to the code. We
    use `numpy.newaxis` to make the offsets into column vectors, which are then automatically
    added to all columns of the resulting weighted sum.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 为了同时处理所有样本，我们对代码进行了一些小的修改。我们使用 `numpy.newaxis` 将偏移量转换为列向量，然后这些向量自动添加到结果加权和中所有列。
- en: '[PRE93]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: For plotting, we use a script [adapted from here](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html)
    (with help from ChatGPT).
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 对于绘图，我们使用一个 [从此处改编的脚本](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html)（在
    ChatGPT 的帮助下）。
- en: '[PRE94]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: We are now ready to run our Gibbs sampler. The outcome depends on the number
    of steps we take. After \(100\) steps, the outcome is somewhat realistic.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好运行我们的吉布斯采样器。结果取决于我们采取的步骤数量。经过 \(100\) 步后，结果有些逼真。
- en: '[PRE95]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '![../../_images/aab5b59b73dc84d3b82547a838a8eadc75c8099fe134e50728fbf2920a04f55e.png](../Images/2abf435d81044deb01535f2ccdd32d63.png)'
  id: totrans-477
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/aab5b59b73dc84d3b82547a838a8eadc75c8099fe134e50728fbf2920a04f55e.png](../Images/2abf435d81044deb01535f2ccdd32d63.png)'
- en: \(\unlhd\)
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**CHAT & LEARN** The RBM can be stacked to form a [deep belief network (DBN)](#(https://en.wikipedia.org/wiki/Boltzmann_machine#Deep_Boltzmann_machine)).
    Ask your favorite AI chatbot about the process of greedy layer-wise pretraining
    of a DBN using RBMs. Discuss how this can be used for initializing the weights
    of a deep neural network and compare the performance with random initialization.
    \(\ddagger\)'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** RBM可以堆叠形成[深度信念网络（DBN）](https://en.wikipedia.org/wiki/Boltzmann_machine#Deep_Boltzmann_machine)。询问您最喜欢的AI聊天机器人关于使用RBM进行贪婪层预训练DBN的过程。讨论这如何用于初始化深度神经网络的权重，并比较与随机初始化的性能。
    \(\ddagger\)'
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(由Claude、Gemini和ChatGPT协助)*'
- en: '**1** In the context of Markov Chain Monte Carlo (MCMC), what is the primary
    goal?'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 在马尔可夫链蒙特卡洛（MCMC）的背景下，主要目标是什么？'
- en: a) To find the maximum likelihood estimate of a parameter.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: a) 为了找到参数的最大似然估计。
- en: b) To generate samples from a complex target distribution.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: b) 为了从复杂的目标分布中生成样本。
- en: c) To optimize a loss function using gradient descent.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用梯度下降优化损失函数。
- en: d) To cluster data points based on similarity.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: d) 根据相似性对数据点进行聚类。
- en: '**2** In the Metropolis-Hastings algorithm, what is the role of the proposal
    chain \(Q\)?'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 在Metropolis-Hastings算法中，提议链 \(Q\) 的作用是什么？'
- en: a) It determines the stationary distribution of the resulting Markov chain.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它确定生成的马尔可夫链的平稳分布。
- en: b) It is used to compute the acceptance probability for the proposed moves.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它用于计算提议移动的接受概率。
- en: c) It generates the candidate states for the next move in the Markov chain.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它生成马尔可夫链下一步的候选状态。
- en: d) It ensures that the resulting Markov chain is irreducible and aperiodic.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它确保生成的马尔可夫链是不可约的且非周期的。
- en: '**3** What is the purpose of the Hastings correction in the Metropolis-Hastings
    algorithm?'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** Metropolis-Hastings算法中Hastings校正的目的是什么？'
- en: a) To ensure that the proposal chain is symmetric.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: a) 确保提议链是对称的。
- en: b) To make the resulting Markov chain irreducible and aperiodic.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使生成的马尔可夫链不可约且非周期的。
- en: c) To ensure that the resulting Markov chain has the desired stationary distribution.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: c) 为了确保生成的马尔可夫链具有所需的平稳分布。
- en: d) To improve the mixing time of the resulting Markov chain.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: d) 为了提高生成的马尔可夫链的混合时间。
- en: '**4** What is the role of the energy function \(\mathcal{E}(\mathbf{v},\mathbf{h})\)
    in a Restricted Boltzmann Machine (RBM)?'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 在受限玻尔兹曼机（RBM）中，能量函数 \(\mathcal{E}(\mathbf{v},\mathbf{h})\) 的作用是什么？'
- en: a) It determines the acceptance probability in the Metropolis-Hastings algorithm.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它确定Metropolis-Hastings算法中的接受概率。
- en: b) It defines the joint probability distribution of the visible and hidden units.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它定义了可见单元和隐藏单元的联合概率分布。
- en: c) It represents the cost function to be minimized during training.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它代表训练期间要最小化的成本函数。
- en: d) It controls the learning rate of the RBM.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它控制RBM的学习率。
- en: '**5** What is the partition function \(Z\) used for in the RBM’s joint probability
    distribution \(\boldsymbol{\pi}(\mathbf{v}, \mathbf{h})\)?'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 在RBM的联合概率分布 \(\boldsymbol{\pi}(\mathbf{v}, \mathbf{h})\) 中，分函数 \(Z\)
    用于什么？'
- en: a) It normalizes the energy function.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它归一化能量函数。
- en: b) It scales the weights matrix \(W\).
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: b) 它缩放权重矩阵 \(W\)。
- en: c) It ensures that the probability distribution sums to one.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: c) 它确保概率分布的总和为1。
- en: d) It adjusts the biases \(\mathbf{b}\) and \(\mathbf{c}\).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: d) 它调整偏置 \(\mathbf{b}\) 和 \(\mathbf{c}\)。
- en: 'Answer for 1: b. Justification: The text states that “The idea behind MCMC
    is simple. To generate samples from \(\boldsymbol{\pi}\), use a Markov chain for
    which it is the stationary distribution.”'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 1的答案：b. 理由：文本中提到，“MCMC背后的想法很简单。要从 \(\boldsymbol{\pi}\) 中生成样本，使用一个马尔可夫链，使其平稳分布。”
- en: 'Answer for 2: c. Justification: The text describes the proposal chain as follows:
    “We first define a proposal chain, that is, a transition matrix \(Q\) on the space
    \(\mathcal{S}\). This chain does not need to have stationary distribution \(\boldsymbol{\pi}\).
    But it is typically a chain that is easy to simulate.”'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 2的答案：c. 理由：文本中对提议链的描述如下：“我们首先定义一个提议链，即在空间 \(\mathcal{S}\) 上的转移矩阵 \(Q\)。这个链不需要有平稳分布
    \(\boldsymbol{\pi}\)。但它通常是一个容易模拟的链。”
- en: 'Answer for 3: c. Justification: The text states that the Hastings correction
    is “where the target distribution \(\boldsymbol{\pi}\) enters the picture, and
    the rejection probability is chosen to ensure that the new chain has the right
    stationary distribution, as we will see later.”'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 答案3：c. 理由：文本中提到Hastings校正“是目标分布 \(\boldsymbol{\pi}\) 进入场景的地方，拒绝概率被选择以确保新链具有正确的平稳分布，正如我们稍后将会看到的。”
- en: 'Answer for 4: b. Justification: The text defines the joint distribution of
    \(v\) and \(h\) as \(\boldsymbol{\pi}(\mathbf{v},\mathbf{h}) = \frac{1}{Z} \exp(-\mathcal{E}(\mathbf{v},\mathbf{h}))\).'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 答案4：b. 理由：文本定义了 \(v\) 和 \(h\) 的联合分布为 \(\boldsymbol{\pi}(\mathbf{v},\mathbf{h})
    = \frac{1}{Z} \exp(-\mathcal{E}(\mathbf{v},\mathbf{h}))\).
- en: 'Answer for 5: c. Justification: The text explains that \(Z\), the partition
    function, “ensures that \(\boldsymbol{\pi}\) indeed sums to 1.”'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 答案5：c. 理由：文本解释说，配分函数 \(Z\) “确保 \(\boldsymbol{\pi}\) 的总和确实为1。”
