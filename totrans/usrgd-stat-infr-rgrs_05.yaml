- en: 2  Model-based inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 模型推断
- en: 原文：[https://mattblackwell.github.io/gov2002-book/estimation.html](https://mattblackwell.github.io/gov2002-book/estimation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mattblackwell.github.io/gov2002-book/estimation.html](https://mattblackwell.github.io/gov2002-book/estimation.html)
- en: '[Statistical Inference](./design.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[统计推断](./design.html)'
- en: '[2  Model-based inference](./estimation.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2 模型推断](./estimation.html)'
- en: 2.1 Introduction
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 简介
- en: Suppose you have been tasked with estimating the fraction of a population that
    supports increasing legal immigration limits. You have a sample of data on some
    individual respondents’ support for the policy, but you don’t know exactly how
    this data was sampled. How should you use the information you know (the data)
    to make a best guess about the information you don’t know (the fraction of the
    population)?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你被分配去估计支持增加合法移民限额的人口比例。你有一些关于个别受访者对政策支持的样本数据，但你不知道这些数据是如何被抽样的。你应该如何使用你所知道的信息（数据）来对不知道的信息（人口比例）做出最佳猜测？
- en: The design-based approach that we discussed in the previous chapter is a coherent
    and internally consistent framework for estimating quantities and quantifying
    uncertainty, but this crisp conceptual clarity comes from having exact knowledge
    of the sampling design. Going back to our immigration example, a reasonable approach
    is to use the fraction of the sample that supports the policy as the best guess
    about the fraction of the population. As we saw in the last chapter, a simple
    random sample would justify this approach.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一章讨论的设计方法是一个连贯且内部一致的框架，用于估计数量和量化不确定性，但这种清晰的概念性清晰来源于对抽样设计的精确知识。回到我们的移民例子，一个合理的方法是使用支持政策的样本比例作为对人口比例的最佳猜测。正如我们在上一章所看到的，一个简单的随机样本可以证明这种方法是合理的。
- en: But how does one perform estimation and inference when lacking complete information
    about the sampling design? How do we proceed with inference if outcomes are random
    due to nonresponse or measurement error? What if we would like to make inferences
    about a population not covered in the sampling frame? In these cases, inference
    requires additional information that can be incorporated via a **statistical model**.
    A model-based approach to statistical inference views the data \(X_1,\ldots, X_n\)
    as a set of random variables that follow some probability distribution. The measurements
    in the actual sample, \(x_1, \ldots, x_n\), are realizations of these random variables.
    The probability distribution of \(X_1,\ldots, X_n\) is the model for the data
    and all inferences are based on it. Models can be very specific – for example,
    a researcher might assume the data are normally distributed – or can be very general
    – for example, the distribution of the data has finite mean and variance.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但当缺乏关于抽样设计的完整信息时，我们如何进行估计和推断？如果由于非响应或测量误差导致结果随机，我们如何进行推断？如果我们想对抽样框架中未涵盖的总体进行推断怎么办？在这些情况下，推断需要额外的信息，这些信息可以通过**统计模型**来整合。基于模型的统计推断方法将数据
    \(X_1,\ldots, X_n\) 视为一组遵循某些概率分布的随机变量。实际样本中的测量值 \(x_1, \ldots, x_n\) 是这些随机变量的实现。\(X_1,\ldots,
    X_n\) 的概率分布是数据的模型，所有推断都基于它。模型可以是非常具体的——例如，研究人员可能假设数据是正态分布的——或者可以是非常一般的——例如，数据的分布具有有限的均值和方差。
- en: The focus of this chapter (and most of introductory statistics) will be on statistical
    models that assume units are **independent and identically distributed** or, more
    succinctly, **iid**. This assumption means that each unit gives us new information
    about the same underlying data-generating process. Because this assumption is
    often motivated by a probability sample from a population, some authors also refer
    to this as a **random sampling** assumption. The “sample” refers to the idea that
    our data is a subset of some larger **population**. The “random” modifier means
    that the subset was chosen by an uncertain process that did not favor one type
    of person versus another.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章（以及大多数入门统计学）的重点将放在假设单位是**独立同分布**的统计模型上，或者更简洁地说，**iid**。这个假设意味着每个单位都为我们提供了关于相同数据生成过程的新的信息。由于这个假设通常是由来自总体的概率样本所激发的，一些作者也将之称为**随机抽样**假设。“样本”指的是我们的数据是某个更大**总体**的子集。“随机”修饰语意味着这个子集是通过一个不确定的过程选择的，这个过程没有偏袒某一种类型的人而不是另一种类型的人。
- en: Why focus on iid/random samples even though many data sets are at least partially
    non-random or represent the entire population rather than a subset? Consider the
    famous story of a drunkard’s search for a two-dollar bill lost in downtown Boston:[¹](#fn1)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么即使许多数据集至少部分是非随机的或代表整个总体而不是子集，我们还要关注iid/随机样本？考虑一下著名的醉汉在波士顿市中心寻找丢失的两美元纸币的故事：[¹](#fn1)
- en: “I lost a $2 bill down on Atlantic Avenue,” said the man.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我在大西洋大道上丢失了两美元，”男人说。
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “What’s that?” asked the puzzled officer. “You lost a $2 bill on Atlantic Avenue?
    Then why are you hunting around here in Copley Square?”
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “那是什么？”困惑的警官问道。“你在大西洋大道上丢失了两美元？那么你为什么在这里的科普利广场四处寻找？”
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “Because,” said the man as he turned away and continued his hunt on his hands
    and knees, “the light’s better up here.”
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “因为，”男人一边转身继续用手和膝盖在地上寻找，一边说，“这里的光线更好。”
- en: Like the poor drunkard, we focus on searching an area (random samples) that
    are easier to search because there is more light or, more accurately, easier math.
    Unlike this apocryphal tale, our search will help us better understand the darkness
    of non-random samples because the core ideas and intuitions from random sampling
    form the basis for the theoretical extensions into more exotic settings.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就像那个可怜的醉汉一样，我们专注于搜索一个区域（随机样本），因为那里有更多的光线，或者更准确地说，数学更容易。与这个寓言故事不同，我们的搜索将帮助我们更好地理解非随机样本的黑暗面，因为随机抽样的核心思想和直觉是理论扩展到更奇特环境的基础。
- en: This chapter has two goals. First, we will introduce the entire model-based
    framework of estimation and estimators. We will discuss different ways to compare
    the properties of estimators. Most of these properties will be similar to those
    of the design-based framework, except the properties will be with respect to the
    model rather than the sampling design. (The core questions of quantitative research
    largely remain the same, but we replace specifying the sampling design with the
    specification of a probabilistic model for our data.) Second, we will establish
    key properties for a general class of estimators that can be written as a sample
    mean. These results are useful in their own right since these estimators are ubiquitous,
    but the derivations also provide examples of how we establish such results. Building
    comfort with these proofs helps us understand the arguments about novel estimators
    that we inevitably see over the course of our careers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有两个目标。首先，我们将介绍整个基于模型的估计和估计量框架。我们将讨论比较估计量性质的不同方法。这些性质中的大多数将与基于设计的框架相似，但性质将相对于模型而不是抽样设计。
    (定量研究的核心问题在很大程度上保持不变，但我们用我们数据的概率模型来代替指定抽样设计。) 第二，我们将为可以写成样本均值的通用类估计量建立关键性质。这些结果本身就有用，因为这些估计量无处不在，但推导也提供了我们如何建立此类结果的例子。对这些证明的熟悉有助于我们理解在我们职业生涯中不可避免地会看到的关于新估计量的论点。
- en: '2.2 Probability vs inference: the big picture'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 概率与推断：大局观
- en: Probability is the mathematical study of uncertain events and is the basis of
    the mathematical study of estimation. In probability, we assume we know the truth
    of the world (how many blue and red balls are in the urn) and calculate the probability
    of possible events (getting more than five red balls when drawing ten from the
    urn). Estimation works in reverse. Someone hands you five balls, 2 red and 3 blue,
    and your task is to guess the contents of the urn from which they came. With estimation,
    we use our observed data to make an **inference** about the data-generating process.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 概率是数学对不确定事件的研究，也是数学估计研究的基础。在概率论中，我们假设我们知道世界的真相（瓮中有多少蓝球和红球）并计算可能事件的概率（从瓮中抽取十个球时得到超过五个红球）。估计则是反向操作。有人给你五个球，其中两个是红球，三个是蓝球，你的任务是猜测这些球是从哪个瓮中取出的。在估计中，我们使用我们的观察数据来对数据生成过程做出**推断**。
- en: '![](../Images/b4b358d85ff8bfe30c8d3513ac72ac6a.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/b4b358d85ff8bfe30c8d3513ac72ac6a.png)'
- en: An estimator is a rule for converting our data into a best guess about some
    unknown quantity, such as the percent of balls in the urn, or, to use our example
    from the introduction, the fraction of the public supporting increasing legal
    immigration limits. For example, an estimator could be a rule that the proportion
    of red balls that you draw from the urn is a good guess for the proportion of
    red balls that you would find if you looked inside the urn.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 估计量是将我们的数据转换为对某些未知量的最佳猜测的规则，例如，量杯中球的比例，或者，使用我们介绍中的例子，支持增加合法移民限额的公众比例。例如，一个估计量可以是这样一个规则：从量杯中抽取的红球比例是对你如果查看量杯内部会发现的红球比例的好猜测。
- en: We prefer to use **good** estimators rather than **bad** estimators. But what
    makes an estimator good or bad? In our red ball example, an estimator that always
    returns the value 3 is probably bad. Still, it will be helpful for us to formally
    define and explore properties of estimators that will allow us to compare them
    and choose the good over the bad. We begin with an example that highlights two
    estimators that at first glance may seem similar.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们更倾向于使用**好的**估计量而不是**坏的**估计量。但什么使得一个估计量变得好或坏呢？在我们的红球例子中，总是返回值3的估计量可能是不好的。然而，对我们来说，正式定义并探索估计量的性质，这将使我们能够比较它们并选择好的而不是坏的，将会很有帮助。我们从这样一个例子开始，这个例子突出了两个看起来可能相似的估计量。
- en: '**Example 2.1 (Randomized control trial)** Suppose we are conducting a randomized
    experiment on framing effects. All respondents receive factual information about
    current immigration levels. Those in the treatment group (\(D_i = 1\)) receive
    additional information about the positive benefits of immigration, while those
    in the control group (\(D_i = 0\)) receive no additional framing. The outcome
    is a binary outcome, whether the respondent supports increasing legal immigration
    limits (\(Y_i = 1\)) or not (\(Y_i = 0\)). The observed data consists of \(n\)
    pairs of random variables, the outcome, and the treatment assignment: \(\{(Y_1,
    D_1), \ldots, (Y_n, D_n)\}\).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.1（随机对照试验）** 假设我们正在进行关于框架效应的随机实验。所有受访者都收到关于当前移民水平的实际情况。治疗组的受访者（\(D_i
    = 1\)）收到关于移民积极效益的额外信息，而对照组的受访者（\(D_i = 0\)）则没有收到额外的框架信息。结果是二元结果，即受访者是否支持增加合法移民限额（\(Y_i
    = 1\))或不是（\(Y_i = 0\))。观察到的数据包括\(n\)对随机变量，结果和治疗分配：\(\{(Y_1, D_1), \ldots, (Y_n,
    D_n)\}\)。'
- en: 'Define the two sample means/proportions in each group as \[ \Ybar_1 = \frac{1}{n_1}
    \sum_{i: D_i = 1} Y_i, \qquad\qquad \Ybar_0 = \frac{1}{n_0} \sum_{i: D_i = 0}
    Y_i, \] where \(n_1 = \sum_{i=1}^n D_i\) is the number of treated units and \(n_0
    = n - n_1\) is the number of control units.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '定义每个组中的两个样本均值/比例如下：\[ \Ybar_1 = \frac{1}{n_1} \sum_{i: D_i = 1} Y_i, \qquad\qquad
    \Ybar_0 = \frac{1}{n_0} \sum_{i: D_i = 0} Y_i, \] 其中 \(n_1 = \sum_{i=1}^n D_i\)
    是治疗单位的数量，\(n_0 = n - n_1\) 是控制单位的数量。'
- en: A standard estimator for the treatment effect in a study such as this would
    be the difference in means, \(\Ybar_1 - \Ybar_0\). But this is only one of many
    possible estimators. We could also estimate the effect by taking this difference
    in means separately by party identification and then averaging those party-specific
    effects by the size of those groups. This estimator is commonly called a **poststratification**
    estimator. Which of these two estimators we should prefer is at first glance unclear.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在此类研究中，一个标准的处理效应估计量是均值差异，\(\Ybar_1 - \Ybar_0\)。但这只是许多可能估计量中的一种。我们还可以通过分别按党派身份计算这个均值差异来估计效果，然后通过这些群体的大小对这些特定党派的效应进行平均。这种估计量通常称为**后分层**估计量。乍一看，我们更倾向于哪种估计量并不清楚。
- en: We now turn to the same key questions that we used to motivate design-based
    inference, but adapt these to consider model-based inference.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在转向我们用来激发基于设计推理的相同关键问题，但将这些调整以考虑基于模型的推理。
- en: '2.3 Question 1: Population'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 问题 1：总体
- en: The main advantage and disadvantage of relying on models is that they are abstract
    and theoretical, which means the connection between a model and the population
    it helps explain is less direct than with the design-based framework. Nevertheless,
    we need to clearly articulate our population of study – that is, who or what we
    want to learn about – since it is crucial for evaluating the types of modeling
    assumptions that will be sustainable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于模型的主要优点和缺点是它们是抽象和理论的，这意味着模型与其所帮助解释的总体之间的联系不如基于设计的框架直接。尽管如此，我们需要清楚地阐述我们的研究总体——也就是说，我们想要了解谁或什么——因为这对于评估将可持续的建模假设类型至关重要。
- en: As in the design-based setting, there is often a clear and distinct population
    such as “all registered voters” or “all Boston residents.” In other cases, the
    population may be more abstract. For example, a large multi-field literature has
    studied how the size of minority populations affects the views of the local majority
    population. Researchers in this space may be interested in making claims beyond
    the particular geographic region or minority/majority group, instead implicitly
    or explicitly considering a “superpopulation” of such cases that their model might
    explain. While there is nothing theoretically wrong with this approach, these
    ideas are often neglected in practice and the “scope conditions” of a particular
    model go unarticulated. The best quantitative work will be clear about what units
    or processes it is trying to learn about so that readers can evaluate how well
    the modeling assumptions fit that task.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于设计的设置中，通常有一个清晰且明确的总体，例如“所有注册选民”或“所有波士顿居民”。在其他情况下，总体可能更加抽象。例如，大量的多领域文献研究了少数群体的大小如何影响当地多数群体的观点。在这个领域的研究人员可能对超越特定地理区域或少数/多数群体做出主张感兴趣，而不是隐含或显性地考虑一个“超总体”，他们的模型可能解释这些情况。虽然这种做法在理论上是正确的，但在实践中这些想法往往被忽视，并且特定模型的“范围条件”没有明确阐述。最好的定量工作将清楚地说明它试图了解哪些单位或过程，以便读者可以评估建模假设与该任务拟合得有多好。
- en: '2.4 Question 2: Statistical model'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 问题2：统计模型
- en: Let’s begin by building a bare-bones probability model for how our data came
    to be. As an example, suppose we have a data set with a series of numbers representing
    the ages, political party affiliations, and policy opinions of 1000 survey respondents.
    But we know that row 58 of our data could have produced a different set of numbers
    if another respondent had been selected as row 58 or if the original respondent
    gave a different opinion about immigration because they happened to see an immigration
    news story just before responding. To reason about this type of uncertainty precisely,
    we write \(X_i\) as the random variable representing the value that row \(i\)
    of some variable will take, before we see the data. The distribution of this random
    variable would tell us what types of data we should expect to see.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从构建一个裸骨概率模型开始，这个模型描述了我们的数据是如何形成的。例如，假设我们有一个包含1000名调查受访者年龄、政党归属和政策观点的一系列数字的数据集。但我们知道，如果另一个受访者被选为第58行，或者如果原始受访者因为恰好在前一天看到了一条移民新闻而在移民问题上给出了不同的观点，那么我们的数据第58行可能会产生一组不同的数字。为了精确地推理这种不确定性，我们在看到数据之前将
    \(X_i\) 写作代表某个变量第 \(i\) 行值的随机变量。这个随机变量的分布将告诉我们我们应该期望看到哪些类型的数据。
- en: Why represent the data with random variables when we already know the value
    of the data itself? Why pretend we haven’t seen the data? The study of estimation
    from a frequentist perspective (which is the perspective of this book) focuses
    on the properties of estimators across **repeated samples**. In the example of
    the policy survey, this is akin to drawing a 1000 person sample repeatedly, each
    time including possibly different respondents in the sample. The random variable
    \(X_i\) represents our uncertainty about what value, say, age will take for respondent
    \(i\) in any of these samples, and the set \(\{X_{1}, \ldots, X_{n}\}\) represents
    our uncertainty about the entire column of ages for all \(n\) respondents. At
    the most general, the model-based approach says that these \(n\) random variables
    follow some joint distribution, \(F_{X_{1},\ldots,X_{n}}\), \[ \{X_{1}, \ldots,
    X_{n}\} \sim F_{X_{1},\ldots,X_{n}} \] The joint distribution \(F\) here represents
    the probability model for the data. We have made no assumptions about it so far,
    so it could be any joint probability distribution over \(n\) random variables.
    Note that this level of generality is difficult to work with in practice because
    there is essentially one draw from this joint distribution (the \(n\) measurements
    in the data). The core question of modeling is about what restrictions a researcher
    puts on this joint distribution to make learning about it more tractable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要在已知数据本身值的情况下，还要用随机变量来表示数据呢？为什么假装我们没有看到数据呢？从频率派的角度（即本书的视角）研究估计，关注的是在**重复样本**中估计量的性质。在政策调查的例子中，这就像反复抽取1000人的样本，每次样本中可能包含不同的受访者。随机变量
    \(X_i\) 代表我们对任何这些样本中受访者 \(i\) 的年龄等值的不确定性，而集合 \(\{X_{1}, \ldots, X_{n}\}\) 代表我们对所有
    \(n\) 个受访者的年龄列的不确定性。在最一般的情况下，基于模型的方法认为这些 \(n\) 个随机变量遵循某种联合分布，\(F_{X_{1},\ldots,X_{n}}\)，\[
    \{X_{1}, \ldots, X_{n}\} \sim F_{X_{1},\ldots,X_{n}} \] 联合分布 \(F\) 在这里代表数据的概率模型。我们迄今为止对此没有做出任何假设，因此它可以是
    \(n\) 个随机变量上的任何联合概率分布。请注意，这种一般性在实际操作中很难处理，因为实际上只有一个从这个联合分布中抽取的样本（数据中的 \(n\) 个测量值）。建模的核心问题是关于研究者对这种联合分布施加什么限制，以便使其更容易学习。
- en: We focus on a relatively simple setting where we assume the data \(\{X_1, \ldots,
    X_n\}\) are **independent and identically distributed** (iid) draws from a distribution
    with cumulative distribution function (cdf) \(F\). They are independent in that
    information about any subset of random variable is not informative about any other
    subset of random variables, or, more formally, \[ F_{X_{1},\ldots,X_{n}}(x_{1},
    \ldots, x_{n}) = F_{X_{1}}(x_{1})\cdots F_{X_{n}}(x_{n}) = \prod_{i=1}^n F(x_i)
    \] where \(F_{X_{1},\ldots,X_{n}}(x_{1}, \ldots, x_{n})\) is the joint cdf of
    the random variable and \(F_{X_{j}}(x_{j})\) is the marginal cdf of the \(j\)th
    random variable. They are “identically distributed” in the sense that each of
    the random variables \(X_i\) have the same marginal distribution, \(F\).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注一个相对简单的设置，其中我们假设数据 \(\{X_1, \ldots, X_n\}\) 是从具有累积分布函数（cdf） \(F\) 的分布中**独立同分布**（iid）抽取的。它们是独立的，因为关于任何随机变量子集的信息不会对其他随机变量子集的信息提供任何信息，或者说，更正式地，\[
    F_{X_{1},\ldots,X_{n}}(x_{1}, \ldots, x_{n}) = F_{X_{1}}(x_{1})\cdots F_{X_{n}}(x_{n})
    = \prod_{i=1}^n F(x_i) \] 其中 \(F_{X_{1},\ldots,X_{n}}(x_{1}, \ldots, x_{n})\)
    是随机变量的联合累积分布函数，\(F_{X_{j}}(x_{j})\) 是第 \(j\) 个随机变量的边缘累积分布函数。它们在“同分布”的意义上是一致的，即每个随机变量
    \(X_i\) 都有相同的边缘分布，\(F\)。
- en: Note that we are being purposely vague about this cdf—it simply represents the
    unknown distribution of the data, otherwise known as the **data generating process**
    (DGP). Sometimes \(F\) is also referred to as the **population distribution**
    or even just **population**, which has its roots in viewing the data as a random
    sample from some larger population.[^model] As a shorthand, we often say that
    the collection of random variables \(\{X_1, \ldots, X_n\}\) is a **random sample**
    from population \(F\) if \(\{X_1, \ldots, X_n\}\) is iid with distribution \(F\).
    The **sample size** \(n\) is the number of units in the sample.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们故意对此累积分布函数（cdf）含糊其辞——它仅仅代表数据的未知分布，也称为**数据生成过程**（DGP）。有时 \(F\) 也被称为**总体分布**或仅仅是**总体**，这源于将数据视为来自某个更大总体的随机样本。[^model]
    作为简写，我们经常说，如果 \(\{X_1, \ldots, X_n\}\) 是从总体 \(F\) 中抽取的随机样本，并且 \(\{X_1, \ldots,
    X_n\}\) 是具有分布 \(F\) 的独立同分布（iid）的，那么我们说这个随机变量的集合 \(\{X_1, \ldots, X_n\}\) 是从总体
    \(F\) 中抽取的**随机样本**。**样本大小** \(n\) 是样本中的单位数量。
- en: '*Note* *You might wonder why we reference the distribution of \(X_i\) with
    the cdf, \(F\). Mathematical statistics tends to do this to avoid having to deal
    with discrete and continuous random variables separately. Every random variable
    – whether discrete or continuous – has a cdf, and the cdf contains all information
    about the distribution of a random variable.*  *Two metaphors help build intuition
    behind viewing the data as an iid draw from \(F\):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* *你可能会想知道我们为什么用累积分布函数（cdf）\(F\)来引用\(X_i\)的分布。数学统计学倾向于这样做，以避免分别处理离散和连续随机变量。每个随机变量——无论是离散的还是连续的——都有一个累积分布函数，累积分布函数包含了关于随机变量分布的所有信息。*  *以下两个比喻有助于建立将数据视为从\(F\)中抽取的iid样本的直觉：'
- en: '**Random sampling**. Suppose we have a population of size \(N\) that is much
    larger than our sample size \(n\), and we take a random sample of size \(n\) from
    this population with replacement. The distribution of the data in the random sample
    will be iid draws from the population distribution of the variables we are sampling.
    For example, suppose the population proportion of Democratic party identifiers
    among U.S. citizens is 0.33\. If we randomly sample \(n = 100\) U.S. citizens,
    each data point \(X_i\) will be distributed Bernoulli with a probability of success
    (i.e., Democratic Party identifier) of 0.33.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机抽样**。假设我们有一个大小为\(N\)的总体，这个总体的大小远大于我们的样本大小\(n\)，并且我们从这个总体中以放回方式抽取一个大小为\(n\)的随机样本。随机样本中的数据分布将是来自我们抽样变量的总体分布的iid抽取。例如，假设美国公民中民主党标识者的总体比例是0.33。如果我们随机抽取\(n
    = 100\)名美国公民，每个数据点\(X_i\)将以成功概率（即民主党标识者）为0.33的伯努利分布。'
- en: Note that the last chapter explored simple random samples *without replacement*,
    which is a more common type of sampling – since generally people are selected
    into a survey once and they do not go back into the pool of potential survey takers.
    Sampling without replacement creates dependence across units, which would violate
    the iid assumption. However, if the population size \(N\) is very large relative
    to the sample size \(n\), this dependence will be very small, and the iid assumption
    will be relatively innocuous.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，上一章探讨了简单随机抽样*不放回*的情况，这是一种更常见的抽样类型——因为通常人们只会被选入一次调查，他们不会回到潜在调查对象的池中。不放回抽样会在单位之间产生依赖性，这将违反iid假设。然而，如果总体大小\(N\)相对于样本大小\(n\)非常大，这种依赖性将非常小，iid假设将相对无害。
- en: '**Groundhog Day**. Random sampling does not always make sense as a justification
    for iid data, especially when the units are not samples at all but rather countries,
    states, or subnational units. (In these cases, the population can be the same
    as the sample – for example, using all 50 states to draw conclusions on the efficacy
    of state policy.) In this case, we have to appeal to a thought experiment where
    \(F\) represents the fundamental uncertainty in the data-generating process. The
    metaphor here is that if we could re-run history many times, such as what happens
    to the protagonist played by Bill Murray in the 1993 American comedy movie *Groundhog
    Day* when he is magically forced to relive February 2 over and over again. Under
    this fiction, data and outcomes would change slightly due to the inherently stochastic
    nature of the world. In the movie, for example, Murray’s character starts off
    the same day in exactly the same way, but he begins to change his actions and
    the outcomes at the end of each day change in subtle ways. The iid assumption,
    then, is that each of the units in our data has the same DGP producing this data
    or the same distribution of outcomes under the *Groundhog Day* scenario. The set
    of all these infinite possible draws from the DGP is sometimes referred to as
    the **superpopulation**.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**土拨鼠日**。随机抽样并不总是作为独立同分布（iid）数据的合理依据，尤其是当单位根本不是样本，而是国家、州或次国家单位时。在这些情况下，总体可以与样本相同——例如，使用所有50个州来得出关于州政策有效性的结论。在这种情况下，我们必须求助于一个思想实验，其中
    \(F\) 代表数据生成过程中的基本不确定性。这里的比喻是，如果我们能够多次重演历史，比如1993年美国喜剧电影《土拨鼠日》中比尔·默瑞扮演的主角被神奇地强迫一次又一次地重温2月2日。在这个虚构的情况下，由于世界的本质随机性，数据和结果会略有变化。在电影中，例如，默瑞的角色每天开始时都以完全相同的方式开始，但他开始改变自己的行为，每天结束时结果以微妙的方式改变。因此，iid假设是，我们数据中的每个单位都有产生这些数据的相同数据生成过程（DGP）或是在“土拨鼠日”情景下的相同结果分布。从DGP中所有这些无限可能的抽取集合有时被称为**超总体**。'
- en: Note that there are other situations where the iid assumption is not appropriate,
    which we discuss in later chapters. But much of the innovation and growth in statistics
    over the last 50 years has been in figuring out how to make statistical inferences
    when iid does not hold. The solutions are often specific to the type of iid violation
    (e.g., spatial, time-series, network, clustered). As a rule of thumb, however,
    if the iid assumption may not be valid, any uncertainty statements will likely
    be overconfident. For example, confidence intervals, which we will cover in later
    chapters, are too small.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，还有其他情况下，独立同分布（iid）假设不适用，我们将在后面的章节中讨论。但过去50年来统计学的大部分创新和增长都集中在如何在独立同分布不成立的情况下进行统计推断。这些解决方案通常针对特定类型的独立同分布违规（例如，空间、时间序列、网络、聚类）。然而，作为一个经验法则，如果独立同分布假设可能不成立，任何不确定性声明都可能过于自信。例如，我们将在后面的章节中介绍的置信区间可能太小。
- en: Finally, we introduced the data as a scalar random variable, but often our data
    has multiple variables. In that case, we easily modify \(X_i\) to be a random
    vector (that is, a vector of random variables) and then \(F\) becomes the joint
    distribution of that random vector. Nothing substantive changes about the above
    discussion.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将数据作为标量随机变量引入，但我们的数据通常具有多个变量。在这种情况下，我们很容易将 \(X_i\) 修改为随机向量（即随机变量的向量），然后
    \(F\) 成为该随机向量的联合分布。上述讨论中的实质性内容没有发生变化。
- en: '*Warning* *Survey sampling is one of the most popular ways of obtaining samples
    from a population, but modern sampling practices rarely produce a “clean” set
    of \(n\) iid responses. There are several reasons for this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** **调查抽样是从人口中获得样本的最流行方式之一，但现代抽样实践很少产生“干净”的 \(n\) 个独立同分布（iid）响应集。这有几个原因：'
- en: Modern random sampling techniques generally do not select every unit with the
    same probability. We might *oversample* certain groups for which we want more
    precise estimates, leading those groups to have a higher likelihood of being in
    the sample.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代随机抽样技术通常不会以相同的概率选择每个单位。我们可能会对某些我们希望有更精确估计的群体进行**过度抽样**，导致这些群体在样本中出现的可能性更高。
- en: Response rates to surveys have been in steep decline and can often dip below
    10%. Such non-random selection into the observed sample might lead to problems.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查的回应率一直在急剧下降，通常可能低于10%。这种对观察样本的非随机选择可能会导致问题。
- en: Internet polling is less costly than other forms of polling, but obtaining a
    list of population email addresses (or other digital contact information) to randomly
    sample is basically impossible. Large survey firms instead recruit large groups
    of panelists with known demographic information from which they can randomly sample
    in a way that matches population demographic information. Because the initial
    opt-in panel is not randomly sampled from the population, this procedure does
    not produce a true “random sample,” but, under certain assumptions, we can treat
    it like it is.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互联网调查的成本低于其他形式的调查，但获取人口电子邮件地址列表（或其他数字联系方式）以进行随机抽样基本上是不可能的。大型调查公司反而会招募具有已知人口统计信息的庞大群体，从而可以以与人口人口统计信息相匹配的方式进行随机抽样。由于初始的自愿参与小组并非从人口中随机抽样，因此此程序不会产生真正的“随机样本”，但在某些假设下，我们可以将其视为如此。
- en: 'As discussed in the last chapter, there are ways to handle all of these issues
    (mostly through the use of survey weights), but it is important to realize that
    using a modern survey “as if” it was a simple random sample might lead to poor
    performance and incorrect inferences.**  **## 2.5 Question 3: Quantities of interest'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如上一章所述，有方法可以处理所有这些问题（主要通过使用调查权重），但重要的是要意识到，将现代调查“视为”简单随机样本可能会导致性能不佳和错误的推断。**  **##
    2.5 问题 3：感兴趣的量
- en: In model-based inference, our goal is to learn about the data-generating process.
    Each data point \(X_i\) represents a draw from a distribution, captured by the
    cdf \(F\), and we would like to know more about this distribution. We might be
    interested in estimating the cdf at a general level or only some feature of the
    distribution, like a mean or conditional expectation function. We call these numerical
    features the **quantities of interest**. (Similarly, in the design-based inference
    framework we discussed in the previous chapter, the quantity of interest was a
    numerical summary of the finite population.)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于模型的推理中，我们的目标是了解数据生成过程。每个数据点 \(X_i\) 代表从分布中抽取的一个样本，由累积分布函数 \(F\) 捕获，我们希望了解更多关于这个分布的信息。我们可能对估计累积分布函数的一般水平或分布的一些特征，如均值或条件期望函数感兴趣。我们把这些数值特征称为**感兴趣量**。（同样，在上一章中我们讨论的设计推理框架中，感兴趣量是有限总体的数值摘要。）
- en: 'The following are examples of frequently used quantities of interest:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常用的感兴趣量的例子：
- en: '**Example 2.2 (Population mean)** We may be interested in where the typical
    member of a population falls on some questions. Suppose we wanted to know the
    proportion of US citizens who support increasing legal immigration For citizen
    \(i\), denote support as \(Y_i = 1\). Our quantity of interest is then the mean
    of this random variable, \(\mu = \E[Y_i] = \P(Y_{i} = 1)\). This is the same as
    the probability of randomly drawing someone from the population who supports increasing
    legal immigration.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.2（总体均值）** 我们可能对总体成员在某个问题上的位置感兴趣。假设我们想知道支持增加合法移民的美国公民的比例。对于公民 \(i\)，将支持表示为
    \(Y_i = 1\)。那么，我们的感兴趣量就是这个随机变量的均值，\(\mu = \E[Y_i] = \P(Y_{i} = 1)\)。这等同于随机从总体中抽取一个人，他支持增加合法移民的概率。'
- en: '**Example 2.3 (Population variance)** We may also be interested in variation
    in the population. For example, feeling thermometer scores are a common way to
    assess how survey respondents feel about a particular person or group. These ask
    each respondent to say how warmly he or she feels toward a group on a scale from
    0 (cool) to 100 (warm), which we will denote \(Y_i\). We might be interested in
    how polarized views are toward a group in the population, and one measure of polarization
    could be the variance, or spread, of the distribution of \(Y_i\) around the mean.
    In this case, \(\sigma^2 = \V[Y_i] = \E[(Y_i - \E[Y_i])^2]\) would be our quantity
    of interest.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.3（总体方差）** 我们也可能对总体的变化感兴趣。例如，感觉温度计得分是评估调查受访者对特定个人或群体感受的一种常见方式。这些要求每个受访者就他们对某个群体在0（冷）到100（热）的量表上的温暖程度发表看法，我们将这个量表表示为
    \(Y_i\)。我们可能对总体中关于某个群体的观点的极化程度感兴趣，极化的一个度量可能是 \(Y_i\) 分布围绕均值的方差或扩散。在这种情况下，\(\sigma^2
    = \V[Y_i] = \E[(Y_i - \E[Y_i])^2]\) 将是我们的感兴趣量。'
- en: '**Example 2.4 (RCT continued)** [Example 2.1](#exm-rct) discussed a typical
    estimator for an experimental study with a binary treatment. The goal of that
    experiment is to learn about the difference between two conditional probabilities
    (or expectations): 1) the average support for increasing legal immigration in
    the treatment group, \(\mu_1 = \E[Y_i \mid D_i = 1]\), and 2) the same average
    in the control group, \(\mu_0 = \E[Y_i \mid D_i = 0]\). This difference, \(\mu_1
    - \mu_0\), is a function of unknown features of these two conditional distributions.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.4（RCT 继续讨论）** [示例 2.1](#exm-rct) 讨论了二元处理实验的典型估计量。该实验的目标是了解两个条件概率（或期望）之间的差异：1)
    处理组中支持增加合法移民的平均支持度，\(\mu_1 = \E[Y_i \mid D_i = 1]\)，和 2) 控制组中的相同平均支持度，\(\mu_0
    = \E[Y_i \mid D_i = 0]\)。这个差异，\(\mu_1 - \mu_0\)，是这两个条件分布未知特征的函数。'
- en: Each of these is a function of the (possibly joint) distribution of the data,
    \(F\). In each of these, we are not necessarily interested in the entire distribution,
    just summaries of it (central tendency, spread). Of course, there are situations
    where we are also interested in the complete distribution. To speak about estimation
    in general, we will let \(\theta\) represent some generic quantity of interest.
    **Point estimation** describes how we obtain a single “best guess” about \(\theta\).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是数据（可能是联合）分布 \(F\) 的函数。在这些情况中，我们不一定对整个分布感兴趣，只是对其摘要感兴趣（中心趋势，扩散）。当然，也有我们感兴趣的是整个分布的情况。为了一般性地讨论估计，我们将让
    \(\theta\) 代表某个通用的感兴趣量。**点估计**描述了如何获得关于 \(\theta\) 的单个“最佳猜测”。
- en: '*Note* *Some refer to quantities of interest as **parameters** or **estimands**
    (that is, the target of estimation).*  *## 2.6 Question 4: Estimator'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* *有些人将感兴趣的数量称为**参数**或**估计对象**（即估计的目标).*  *## 2.6 问题 4：估计量'
- en: 'Having a target in mind, we can estimate it with our data. To do so, we first
    need a rule or algorithm or function that takes as inputs the data and returns
    a best guess about the quantity of interest. One of the most popular and useful
    algorithm would be to sum all the data points and divide by the number of points:
    \[ \frac{X_1 + X_2 + \cdots + X_n}{n}. \] This, the much-celebrated sample mean,
    provides a rule for how produce a single-number summary of the data. To go one
    pedantic step further and define it as a function of the data more explicitly:
    \[ \textsf{mean}(X_1, X_2, \ldots, X_n) = \frac{X_1 + X_2 + \cdots + X_n}{n}.
    \] We can use this model to provide a definition for an arbitrary estimator for
    an arbitrary quantity of interest.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 心中有一个目标，我们可以用我们的数据来估计它。为此，我们首先需要一个规则或算法或函数，它以数据为输入，并返回对感兴趣数量的最佳猜测。最受欢迎且最有用的算法之一是将所有数据点相加，然后除以点的数量：\[
    \frac{X_1 + X_2 + \cdots + X_n}{n}. \] 这就是备受赞誉的样本均值，它提供了一种如何产生数据单数总结的规则。更进一步，更严格地将其定义为数据的函数：\[
    \textsf{mean}(X_1, X_2, \ldots, X_n) = \frac{X_1 + X_2 + \cdots + X_n}{n}. \]
    我们可以使用这个模型为任意感兴趣数量的任意估计量提供一个定义。
- en: '**Definition 2.1** An **estimator** \(\widehat{\theta}_n = \theta(X_1, \ldots,
    X_n)\) for some parameter \(\theta\), is a function of the data intended as a
    guess about \(\theta\).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义 2.1** 对于某个参数 \(\theta\)，一个**估计量** \(\widehat{\theta}_n = \theta(X_1, \ldots,
    X_n)\) 是一个关于 \(\theta\) 的猜测的数据函数。'
- en: '*Note* *It is widespread, though not universal, to use the “hat” notation to
    define an estimator and its estimand. For example, \(\widehat{\theta}\) (or “theta
    hat”) indicates that this estimator is targeting the parameter \(\theta\).*  ***Example
    2.5 (Estimators for the population mean)** Suppose our goal is to estimate the
    population mean of \(F\), which we will represent as \(\mu = \E[X_i]\). We could
    choose from several estimators, all with different properties. \[ \widehat{\theta}_{n,1}
    = \frac{1}{n} \sum_{i=1}^n X_i, \quad \widehat{\theta}_{n,2} = X_1, \quad \widehat{\theta}_{n,3}
    = \text{max}(X_1,\ldots,X_n), \quad \widehat{\theta}_{n,4} = 3 \] The first is
    just the sample mean, which is an intuitive and natural estimator for the population
    mean. The second just uses the first observation. While this seems silly, this
    is a valid statistic since it is a function of the data! The third takes the maximum
    value in the sample, and the fourth always returns three, regardless of the data.
    These are also valid statistics.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* *广泛使用（尽管不是普遍使用）“帽子”符号来定义估计量和其估计对象。例如，\(\widehat{\theta}\)（或“theta hat”）表示这个估计量是针对参数
    \(\theta\) 的.*  ***示例 2.5（对总体均值的估计量）*** 假设我们的目标是估计 \(F\) 的总体均值，我们将它表示为 \(\mu =
    \E[X_i]\)。我们可以选择几个估计量，它们具有不同的特性。\[ \widehat{\theta}_{n,1} = \frac{1}{n} \sum_{i=1}^n
    X_i, \quad \widehat{\theta}_{n,2} = X_1, \quad \widehat{\theta}_{n,3} = \text{max}(X_1,\ldots,X_n),
    \quad \widehat{\theta}_{n,4} = 3 \] 第一个就是样本均值，它是总体均值的一个直观且自然的估计量。第二个只使用了第一个观测值。虽然这似乎很愚蠢，但这是一个有效的统计量，因为它是一个数据函数！第三个取样本中的最大值，第四个无论数据如何总是返回三个。这些也是有效的统计量。'
- en: 'When we view the data \(\{X_{1}, \ldots, X_{n}\}\) as a collection of random
    variables, then any function of them is also a random variable. Thus, we can view
    \(\widehat{\theta}_n\) as a random variable that has a distribution induced by
    the randomness of the sample. Drawing two different samples of respondents will
    lead to two different estimates. For example, here we illustrate two samples of
    size \(n =5\) from the population distribution of a binary variable:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将数据 \(\{X_{1}, \ldots, X_{n}\}\) 视为一组随机变量时，那么它们的任何函数也是随机变量。因此，我们可以将 \(\widehat{\theta}_n\)
    视为一个随机变量，它具有由样本随机性引起的分布。抽取两个不同的样本将导致两个不同的估计值。例如，这里我们展示了从二元变量的总体分布中抽取的 \(n =5\)
    个样本：
- en: '![](../Images/931b4ec5b0186e973ee671bb0cfa2fe5.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/931b4ec5b0186e973ee671bb0cfa2fe5.png)'
- en: We can see that the mean of the variable depends on what exact values end up
    in our sample. We refer to the distribution of \(\widehat{\theta}_n\) across repeated
    samples as its **sampling distribution**. The sampling distribution of an estimator
    will be the basis for all of the formal statistical properties of an estimator.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，变量的均值取决于样本中最终出现的具体值。我们将 \(\widehat{\theta}_n\) 在重复样本中的分布称为其**抽样分布**。估计量的抽样分布将是估计量所有正式统计性质的基础。
- en: '*Warning* *One important distinction of jargon is between an estimator and
    an estimate. The estimator is a function of the data, whereas the **estimate**
    is the *realized value* of the estimator once we see the data (that is, the data
    are realized). The estimator is a random variable that has uncertainty over what
    value it will take, and we represent the estimator as a function of random variables,
    \(\widehat{\theta}_n = \theta(X_1, \ldots, X_n)\). An estimate is a single number,
    such as 0.38, that we calculated in R with our data (our draw from \(F\)). Formally,
    the estimate is \(\theta(x_1, \ldots, x_n)\) when the data is \(\{X_1, \ldots,
    X_n\} = \{x_1, \ldots, x_n\}\), whereas we represent the estimator as a function
    of random variables, \(\widehat{\theta}_n = \theta(X_1, \ldots, X_n)\).**  **##
    2.7 How to find estimators'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Where do estimators come from? That may seem like a question reserved for statisticians
    or methodologists or others responsible for “developing new methods.” But knowing
    how estimators are derived is valuable even if we never plan to do it ourselves.
    Knowing where an estimator comes from provides strong insights into its strengths
    and weaknesses. We will briefly introduce estimators based on parametric models,
    before turning to the main focus of this book, plug-in estimators.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.1 Parametric models and maximum likelihood
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first method for generating estimators relies on **parametric models**,
    in which the researcher specifies the exact distribution (up to some unknown parameters)
    of the DGP. Let \(\theta\) be the parameters of this distribution, where \(\{X_1,
    \ldots, X_n\}\) be iid draws from \(F_{\theta}\). We should also formally state
    the set of possible values the parameters can take, which we call the **parameter
    space**, denoted by \(\Theta\). Because we assume we know the distribution of
    the data, we can write the probability density function, or pdf, as \(f(X_i \mid
    \theta)\) and define the likelihood function as the product of these pdfs over
    the units as a function of the parameters: \[ L(\theta) = \prod_{i=1}^n f(X_i
    \mid \theta). \] We can then define the **maximum likelihood** estimator (MLE)
    for \(\theta\) as the values of the parameter that, well, maximize the likelihood:
    \[ \widehat{\theta}_{mle} = \argmax_{\theta \in \Theta} \; L(\theta) \] Sometimes
    we can use calculus to derive a closed-form expression for the MLE. At other times
    we use iterative techniques that search the parameter space for the maximum.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Maximum likelihood estimators have nice properties, especially in large samples.
    Unfortunately, they also require the correct knowledge of the parametric model,
    which is often difficult to justify. Do we really know if we should model a given
    event count variable as Poisson or Negative Binomial? The attractive properties
    of MLE are only as good as the ability to specify the parametric model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '*No free lunch* *Building up intuition about the **assumptions-precision tradeoff**
    is essential. Researchers can usually get more precise estimates if they make
    stronger and potentially more fragile assumptions. Conversely, they will almost
    always get less accurate estimates when weakening the assumptions.*  *### 2.7.2
    Plug-in estimators'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*没有免费的午餐* *建立对**假设-精度权衡**的直觉是至关重要的。研究人员如果做出更强和可能更脆弱的假设，通常可以得到更精确的估计。相反，当弱化假设时，他们几乎总是得到更不准确的估计。*  *###
    2.7.2 插值估计量'
- en: The second broad class of estimators is **semiparametric** in that we specify
    some finite-dimensional parameters of the DGP but leave the rest of the distribution
    unspecified. For example, we might define a population mean, \(\mu = \E[X_i]\)
    and a population variance, \(\sigma^2 = \V[X_i]\) but leave the shape of the distribution
    unrestricted. This ensures that our estimators will be less dependent on correctly
    specifying distributions about which we have little intuition or knowledge.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第二大类估计量是**半参数**的，因为我们指定了DGP的一些有限维参数，但将分布的其余部分留作未指定。例如，我们可能定义一个总体均值，\(\mu = \E[X_i]\)和一个总体方差，\(\sigma^2
    = \V[X_i]\)，但将分布的形状限制为不受限制。这确保了我们的估计量将不太依赖于正确指定我们对其知之甚少的分布。
- en: 'The primary method for constructing estimators in this setting is to use the
    **plug-in estimator**, or the estimator that replaces any population mean with
    a sample mean. Obviously, in the case of estimating the population mean, \(\mu\),
    we will use the **sample mean** as the estimate: \[ \Xbar_n = \frac{1}{n} \sum_{i=1}^n
    X_i \quad \text{estimates} \quad \E[X_i] = \int_{\mathcal{X}} x f(x)dx \] In plain
    language, we are replacing the unknown population distribution \(f(x)\) in the
    population mean with a discrete uniform distribution over our data points, with
    \(1/n\) probability assigned to each unit. Why do this? It encodes that, if we
    have a random sample, our best guess about the population distribution of \(X_i\)
    is the sample distribution in our observed data. If this intuition fails, you
    can hold onto an analog principle: sample means of random variables are natural
    estimators of population means.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个环境中构建估计量的主要方法是使用**插值估计量**，即用样本均值替换任何总体均值的估计量。显然，在估计总体均值\(\mu\)的情况下，我们将使用**样本均值**作为估计：\[
    \Xbar_n = \frac{1}{n} \sum_{i=1}^n X_i \quad \text{estimates} \quad \E[X_i] =
    \int_{\mathcal{X}} x f(x)dx \] 用简单的话说，我们是用我们的数据点上的离散均匀分布来替换总体均值中的未知总体分布\(f(x)\)，每个单位分配\(1/n\)的概率。为什么这样做呢？这是因为，如果我们有一个随机样本，我们对\(X_i\)的总体分布的最佳猜测就是观察到的样本分布。如果这种直觉失败，你可以坚持一个类似的原则：随机变量的样本均值是总体均值的自然估计量。
- en: 'What about estimating something more complicated, like the expected value of
    a function of the data, \(\theta = \E[r(X_i)]\)? The key is to see that \(r(X_i)\)
    is also a random variable. Let this random variable be \(Y_i = r(X_i)\). Now we
    can see that \(\theta\) is just the population expectation of this random variable.
    Using the plug-in estimator gives us: \[ \widehat{\theta} = \frac{1}{n} \sum_{i=1}^n
    Y_i = \frac{1}{n} \sum_{i=1}^n r(X_i). \]'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，估计更复杂的东西，比如数据的函数的期望值，\(\theta = \E[r(X_i)]\)呢？关键是看到\(r(X_i)\)也是一个随机变量。让这个随机变量为\(Y_i
    = r(X_i)\)。现在我们可以看到\(\theta\)只是这个随机变量的总体期望。使用插值估计量给我们：\[ \widehat{\theta} = \frac{1}{n}
    \sum_{i=1}^n Y_i = \frac{1}{n} \sum_{i=1}^n r(X_i). \]
- en: These facts enable us to describe a more general plug-in estimator. To estimate
    some quantity of interest that is a function of population means, we can generate
    a plug-in estimator by replacing any population mean with a sample mean. Formally,
    let \(\alpha = g\left(\E[r(X_i)]\right)\) be a parameter that is defined as a
    function of the population mean of a (possibly vector-valued) function of the
    data. We can then estimate this parameter by plugging in the sample mean for the
    population mean to get the **plug-in estimator**, \[ \widehat{\alpha} = g\left(
    \frac{1}{n} \sum_{i=1}^n r(X_i) \right) \quad \text{estimates} \quad \alpha =
    g\left(\E[r(X_i)]\right) \] This approach to plug-in estimation with sample means
    is very general and will allow us to derive estimators in various settings.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些事实使我们能够描述一个更一般的插值估计量。为了估计一个感兴趣的量，该量是总体均值的函数，我们可以通过用样本均值替换任何总体均值来生成一个插值估计量。形式上，让\(\alpha
    = g\left(\E[r(X_i)]\right)\)是一个参数，它被定义为数据（可能为向量值）的总体均值的函数。然后我们可以通过将样本均值插入总体均值来估计这个参数，得到**插值估计量**，\[
    \widehat{\alpha} = g\left( \frac{1}{n} \sum_{i=1}^n r(X_i) \right) \quad \text{estimates}
    \quad \alpha = g\left(\E[r(X_i)]\right) \] 这种使用样本均值的插值估计方法非常通用，将使我们能够在各种环境中推导出估计量。
- en: '**Example 2.6 (Estimating population variance)** The population variance of
    a random variable is \(\sigma^2 = \E[(X_i - \E[X_i])^2]\). To derive a plug-in
    estimator for this quantity, we replace the inner \(\E[X_i]\) with \(\Xbar_n\)
    and the outer expectation with another sample mean: \[ \widehat{\sigma}^2 = \frac{1}{n}
    \sum_{i=1}^n (X_i - \Xbar_n)^2. \] This plug-in estimator differs from the standard
    sample variance, which divides by \(n - 1\) rather than \(n\). This minor difference
    does not matter in moderate to large samples.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.6（估计总体方差）** 随机变量的总体方差是 \(\sigma^2 = \E[(X_i - \E[X_i])^2]\)。为了推导这个量的插值估计量，我们将内层的
    \(\E[X_i]\) 替换为 \(\Xbar_n\)，并将外层期望替换为另一个样本均值：\[ \widehat{\sigma}^2 = \frac{1}{n}
    \sum_{i=1}^n (X_i - \Xbar_n)^2. \] 这个插值估计量与标准样本方差不同，它除以 \(n - 1\) 而不是 \(n\)。这个小的差异在中等到大样本中并不重要。'
- en: '**Example 2.7 (Estimating population covariance)** Suppose we have two variables,
    \((X_i, Y_i)\). A natural quantity of interest here is the population covariance
    between these variables, \[ \sigma_{xy} = \text{Cov}[X_i,Y_i] = \E[(X_i - \E[X_i])(Y_i-\E[Y_i])],
    \] which has the plug-in estimator, \[ \widehat{\sigma}_{xy} = \frac{1}{n} \sum_{i=1}^n
    (X_i - \Xbar_n)(Y_i - \Ybar_n). \]'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.7（估计总体协方差）** 假设我们有两个变量，\((X_i, Y_i)\)。这里一个自然的感兴趣量是这两个变量之间的总体协方差，\[ \sigma_{xy}
    = \text{Cov}[X_i,Y_i] = \E[(X_i - \E[X_i])(Y_i-\E[Y_i])], \] 它的插值估计量为，\[ \widehat{\sigma}_{xy}
    = \frac{1}{n} \sum_{i=1}^n (X_i - \Xbar_n)(Y_i - \Ybar_n). \]'
- en: '*Notation alert* *Given the connection between the population mean and the
    sample mean, you may see the \(\E_n[\cdot]\) operator used as a shorthand for
    the sample average: \[ \E_n[r(X_i)] \equiv \frac{1}{n} \sum_{i=1}^n r(X_i). \]*  *Finally,
    plug-in estimation goes beyond just replacing population means with sample means.
    We can derive estimators of the population quantiles like the median with sample
    versions of those quantities. These approaches are unified in replacing the unknown
    population cdf, \(F\), with the empirical cdf, \[ \widehat{F}_n(x) = \frac{\sum_{i=1}^n
    \mathbb{I}(X_i \leq x)}{n}, \] where \(\mathbb{I}(A)\) is an *indicator function*
    that takes the value 1 if the event \(A\) occurs and 0 otherwise. For a more complete
    and technical treatment of these ideas, see Wasserman (2004) Chapter 7.**  **##
    2.8 The three distributions: population, empirical, and sampling'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*符号警告* *鉴于总体均值与样本均值之间的关系，你可能会看到 \(\E_n[\cdot]\) 运算符被用作样本平均的简称：\[ \E_n[r(X_i)]
    \equiv \frac{1}{n} \sum_{i=1}^n r(X_i). \]* *最后，插值估计不仅限于用样本均值替换总体均值。我们还可以推导出样本版本的这些量（如中位数）的总体分位数估计量。这些方法在用经验累积分布函数，\[
    \widehat{F}_n(x) = \frac{\sum_{i=1}^n \mathbb{I}(X_i \leq x)}{n}, \] 替换未知总体累积分布函数
    \(F\) 时统一起来，其中 \(\mathbb{I}(A)\) 是一个 *指示函数*，当事件 \(A\) 发生时取值为 1，否则为 0。对于这些想法的更完整和技术的处理，请参阅
    Wasserman (2004) 第 7 章。**  **## 2.8 三种分布：总体、经验性和抽样'
- en: Once we start to wade into estimation, there are several distributions to keep
    track of, and things can quickly become confusing. Three specific distributions
    are all related and easy to confuse, but keeping them distinct is crucial.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始涉足估计，就有几个分布需要跟踪，事情可能会很快变得混乱。三个特定的分布都是相关的，并且容易混淆，但保持它们之间的区别是至关重要的。
- en: The **population distribution** is the distribution of the random variable,
    \(X_i\), which we have labeled \(F\) and is our target of inference. The **empirical
    distribution** is the distribution of the actual realizations of the random variables
    in our samples, \(X_1, \ldots, X_n\) (that is, the values that we eventually observe
    in our data frame). Because this is a random sample from the population distribution
    and can serve as an estimator of \(F\), we sometimes call this \(\widehat{F}_n\).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体分布** 是随机变量 \(X_i\) 的分布，我们将其标记为 \(F\)，是我们推理的目标。**经验分布** 是我们样本中随机变量的实际实现值的分布，\(X_1,
    \ldots, X_n\)（即我们最终在数据框中观察到的值）。因为这是一个从总体分布中随机抽取的样本，可以充当 \(F\) 的估计量，所以我们有时称这个为
    \(\widehat{F}_n\)。'
- en: 'Separately from both is the **sampling distribution of an estimator**, which
    is the probability distribution of \(\widehat{\theta}_n\). This represents the
    uncertainty around our estimate before we see the data. Remember that our estimator
    is itself a random variable because it is a function of random variables: the
    data itself. That is, we defined the estimator as \(\widehat{\theta}_n = \theta(X_1,
    \ldots, X_n)\).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 独立于这两者的是 **估计量的抽样分布**，它是 \(\widehat{\theta}_n\) 的概率分布。这代表了我们看到数据之前估计的不确定性。记住，我们的估计量本身是一个随机变量，因为它是一个随机变量的函数：数据本身。也就是说，我们定义估计量为
    \(\widehat{\theta}_n = \theta(X_1, \ldots, X_n)\)。
- en: '**Example 2.8 (Likert responses)** Suppose \(X_i\) is the answer to the question
    “How much do you agree with the following statement: Immigrants are a net positive
    for the United States,” where \(X_i = 0\) is “strongly disagree,” \(X_i = 1\)
    is “disagree,” \(X_i = 2\) is “neither agree nor disagree,” \(X_i = 3\) is “agree,”
    and \(X_i = 4\) is “strongly agree.”'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.8（Likert 反应）** 假设 \(X_i\) 是对问题“你有多同意以下陈述：移民对美国是净正面的？”的回答，其中 \(X_i =
    0\) 表示“强烈不同意”，\(X_i = 1\) 表示“不同意”，\(X_i = 2\) 表示“既不同意也不反对”，\(X_i = 3\) 表示“同意”，\(X_i
    = 4\) 表示“强烈同意”。'
- en: The population distribution describes the probability of randomly selecting
    a person with each one of these values, \(\P(X_i = x)\). The empirical distribution
    would be the fraction of our observed data taking each value. And the sampling
    distribution of the sample mean, \(\Xbar_n\), would be the distribution of the
    sample mean recalculated across repeated samples from the population.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 种群分布描述了随机选择一个具有这些值中每一个的人的概率，\(\P(X_i = x)\)。经验分布将是我们的观察数据中每个值的比例。而样本均值 \(\Xbar_n\)
    的抽样分布将是通过对种群中重复样本的样本均值重新计算得到的分布。
- en: 'Suppose the population distribution of \(X_i\) followed a binomial distribution
    with five trials and probability of success in each trial of \(p = 0.4\). We could
    generate one sample with \(n = 10\) and thus one empirical distribution using
    `rbinom()`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 \(X_i\) 的种群分布遵循一个有五次试验的二项分布，每次试验成功的概率为 \(p = 0.4\)。我们可以生成一个包含 \(n = 10\)
    个样本的样本，从而得到一个使用 `rbinom()` 生成的经验分布：
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE1]'
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*[PRE3]**  **We obtain one draw from the sampling distribution of \(\Xbar_n\)
    by taking the mean of this sample:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE3]*  **我们通过取这个样本的平均值从 \(\Xbar_n\) 的抽样分布中抽取一个样本：'
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*[PRE5]*  *If we had a different sample,however, we would obtain a different
    empirical distribution and thus get a different estimate of the sample mean:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE5]*  *如果我们有一个不同的样本，那么我们会得到一个不同的经验分布，从而得到样本均值的不同的估计：'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*[PRE7]*  *The sampling distribution is the distribution of these sample means
    across repeated sampling.****  ***## 2.9 Finite-sample properties of estimators'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE7]*  *抽样分布是这些样本均值在重复抽样中的分布。****  ***## 2.9 估计量的有限样本性质'
- en: 'As discussed in our introduction to estimators, their usefulness depends on
    how well they help us learn about the quantity of interest. If we get an estimate
    \(\widehat{\theta} = 1.6\), we would like to know that this is “close” to the
    true parameter \(\theta\). The sampling distribution is key to answering these
    questions. Intuitively, we would like the sampling distribution of \(\widehat{\theta}_n\)
    to be as tightly clustered around the true \(\theta\) as possible. Here, though,
    we run into a problem: the sampling distribution depends on the population distribution
    since it is about repeated samples of the data from that distribution filtered
    through the function \(\theta()\). Since \(F\) is unknown, this implies that the
    sampling distribution will also usually be unknown.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在估计量介绍中讨论的那样，它们的有用性取决于它们帮助我们了解感兴趣的数量有多好。如果我们得到一个估计值 \(\widehat{\theta} =
    1.6\)，我们希望知道这是“接近”于真实参数 \(\theta\) 的。抽样分布是回答这些问题的关键。直观上，我们希望 \(\widehat{\theta}_n\)
    的抽样分布尽可能紧密地围绕真实 \(\theta\) 聚集。然而，这里我们遇到了一个问题：抽样分布依赖于种群分布，因为它涉及从该分布中重复抽取数据并通过函数
    \(\theta()\) 过滤。由于 \(F\) 是未知的，这意味着抽样分布通常也是未知的。
- en: Even though we cannot precisely pin down the entire sampling distribution, we
    can use assumptions to derive specific properties of the sampling distribution
    that are useful in comparing estimators. Note that the properties here will be
    very similar to the
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们无法精确确定整个抽样分布，但我们可以使用假设来推导抽样分布的特定属性，这些属性在比较估计量时非常有用。请注意，这里的属性将与
- en: 2.9.1 Bias
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.9.1 偏差
- en: The first property of the sampling distribution concerns its central tendency.
    In particular, we define the **bias** (or **estimation bias**) of estimator \(\widehat{\theta}\)
    for parameter \(\theta\) as \[ \text{bias}[\widehat{\theta}] = \E[\widehat{\theta}]
    - \theta, \] which is the difference between the mean of the estimator (across
    repeated samples) and the true parameter. All else equal, we would like the estimation
    bias to be as small as possible. The smallest possible bias, obviously, is 0,
    and we define an **unbiased estimator** as one with \(\text{bias}[\widehat{\theta}]
    = 0\) or equivalently, \(\E[\widehat{\theta}] = \theta\).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 样本分布的第一个性质是它的中心趋势。特别是，我们定义估计量 \(\widehat{\theta}\) 对于参数 \(\theta\) 的**偏差**（或**估计偏差**）为
    \[ \text{bias}[\widehat{\theta}] = \E[\widehat{\theta}] - \theta, \] 这是估计量的均值（在重复样本中）与真实参数之间的差异。在其他条件相同的情况下，我们希望估计偏差尽可能小。显然，可能的最小偏差是
    0，我们定义一个**无偏估计量**为具有 \(\text{bias}[\widehat{\theta}] = 0\) 或等价地，\(\E[\widehat{\theta}]
    = \theta\) 的估计量。
- en: However, all else is not always equal, and unbiasedness is not a property to
    which we should become overly attached. Many biased estimators have other attractive
    properties, and many popular modern estimators are biased.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在其他条件并不总是相同的情况下，无偏性不是一个我们应该过分依赖的性质。许多有偏估计量具有其他吸引人的性质，许多流行的现代估计量是有偏的。
- en: '**Example 2.9 (Unbiasedness of the sample mean)** The sample mean is unbiased
    for the population mean when the data is iid and \(\E|X| < \infty\). In particular,
    we apply the rules of expectations: \[\begin{aligned} \E\left[ \Xbar_n \right]
    &= \E\left[\frac{1}{n} \sum_{i=1}^n X_i\right] & (\text{definition of } \Xbar_n)
    \\ &= \frac{1}{n} \sum_{i=1}^n \E[X_i] & (\text{linearity of } \E)\\ &= \frac{1}{n}
    \sum_{i=1}^n \mu & (X_i \text{ identically distributed})\\ &= \mu. \end{aligned}\]
    Notice that we only used the “identically distributed” part of iid. Independence
    is not needed.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.9（样本均值的无偏性）** 当数据是独立同分布的（iid）且 \(\E|X| < \infty\) 时，样本均值对于总体均值是无偏的。特别是，我们应用期望规则：\[\begin{aligned}
    \E\left[ \Xbar_n \right] &= \E\left[\frac{1}{n} \sum_{i=1}^n X_i\right] & (\text{样本均值
    } \Xbar_n \text{ 的定义}) \\ &= \frac{1}{n} \sum_{i=1}^n \E[X_i] & (\E \text{ 的线性性})\\
    &= \frac{1}{n} \sum_{i=1}^n \mu & (X_i \text{ 同分布})\\ &= \mu. \end{aligned}\]
    注意，我们只使用了独立同分布（iid）中的“同分布”部分。独立性不是必需的。'
- en: '*Warning* *Properties like unbiasedness might only hold for a subset of DGPs.
    For example, we just showed that the sample mean is unbiased but only when the
    population mean is finite. There are probability distributions like the Cauchy
    that are not finite and where the expected value diverges. Thus, here we are dealing
    with a restricted class of DGPs that rules out such distributions. This is sometimes
    formalized by defining a class \(\mathcal{F}\) of distributions; unbiasedness
    might hold in that class if it is unbiased for all \(F \in \mathcal{F}\).*  *##
    2.10 Question 5: Uncertainty'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** *无偏性等性质可能只适用于 DGPs 的一个子集。例如，我们刚刚表明样本均值是无偏的，但仅当总体均值是有限的时。存在一些概率分布，如柯西分布，其值不是有限的，且期望值发散。因此，我们在这里处理的是一类受限制的
    DGPs，排除了这样的分布。这有时通过定义一个分布类 \(\mathcal{F}\) 来形式化；如果对于所有 \(F \in \mathcal{F}\) 都是无偏的，那么无偏性可能在该类中成立。*  **##
    2.10 问题 5：不确定性**'
- en: The spread of the sampling distribution is also important. We define the **sampling
    variance** as the variance of an estimator’s sampling distribution, \(\V[\widehat{\theta}]\),
    which measures how spread out the estimator is around its mean. For an unbiased
    estimator, lower sampling variance implies the distribution of \(\widehat{\theta}\)
    is more concentrated around the true value of the parameter.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 样本分布的分散程度也很重要。我们定义**抽样方差**为估计量的抽样分布的方差，\(\V[\widehat{\theta}]\)，它衡量估计量在其均值周围的分散程度。对于一个无偏估计量，较低的抽样方差意味着
    \(\widehat{\theta}\) 的分布更集中在参数的真实值周围。
- en: '**Example 2.10 (Sampling variance of the sample mean)** We can prove that the
    sampling variance of the sample mean of iid data for all \(F\) such that \(\V[X_i]\)
    is finite (more precisely, \(\E[X_i^2] < \infty\))'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2.10（样本均值的抽样方差）** 我们可以证明，对于所有 \(\V[X_i]\) 是有限的 \(F\)（更精确地说，\(\E[X_i^2]
    < \infty\)）的独立同分布数据的样本均值的抽样方差'
- en: \[\begin{aligned} \V\left[ \Xbar_n \right] &= \V\left[ \frac{1}{n} \sum_{i=1}^n
    X_i \right] & (\text{definition of } \Xbar_n) \\ &= \frac{1}{n^2} \V\left[ \sum_{i=1}^n
    X_i \right] & (\text{property of } \V) \\ &= \frac{1}{n^2} \sum_{i=1}^n \V[X_i]
    & (\text{independence}) \\ &= \frac{1}{n^2} \sum_{i=1}^n \sigma^2 & (X_i \text{
    identically distributed}) \\ &= \frac{\sigma^2}{n} \end{aligned}\]
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{aligned} \V\left[ \Xbar_n \right] &= \V\left[ \frac{1}{n} \sum_{i=1}^n
    X_i \right] & (\text{定义 } \Xbar_n) \\ &= \frac{1}{n^2} \V\left[ \sum_{i=1}^n X_i
    \right] & (\text{方差的性质 } \V) \\ &= \frac{1}{n^2} \sum_{i=1}^n \V[X_i] & (\text{独立性})
    \\ &= \frac{1}{n^2} \sum_{i=1}^n \sigma^2 & (X_i \text{ 同分布}) \\ &= \frac{\sigma^2}{n}
    \end{aligned}\]
- en: 'As we discussed before, an alternative measure of spread for any distribution
    is the standard deviation, which is on the same scale as the original random variable.
    The standard deviation of the sampling distribution of \(\widehat{\theta}\) is
    known as the **standard error** of \(\widehat{\theta}\): \(\se(\widehat{\theta})
    = \sqrt{\V[\widehat{\theta}]}\).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，任何分布的替代度量标准是标准差，它与原始随机变量的尺度相同。\(\widehat{\theta}\)的抽样分布的标准差被称为\(\widehat{\theta}\)的**标准误差**：\(\se(\widehat{\theta})
    = \sqrt{\V[\widehat{\theta}]}\)。
- en: Given the above derivation, the standard error of the sample mean under iid
    sampling is \(\sigma / \sqrt{n}\).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述推导，在独立同分布（iid）抽样下，样本均值的标准误差是\(\sigma / \sqrt{n}\)。
- en: 2.10.1 Mean squared error
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.10.1 均方误差
- en: Bias and sampling variance measure two properties of “good” estimators because
    they capture the fact that we want the estimator to be as close as possible to
    the true value. One summary measure of the quality of an estimator is the **mean
    squared error** or **MSE**, which is
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差和抽样方差衡量了“良好”估计量的两个属性，因为它们捕捉了我们希望估计量尽可能接近真实值的事实。估计量质量的一个总结度量是**均方误差**或**MSE**，它是
- en: \[ \text{MSE} = \E[(\widehat{\theta}_n-\theta)^2]. \] We would ideally have
    this be as small as possible!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{MSE} = \E[(\widehat{\theta}_n-\theta)^2]. \] 我们理想情况下希望这个值尽可能小！
- en: 'The MSE also relates to the bias and the sampling variance (provided it is
    finite) via the following decomposition result: \[ \text{MSE} = \text{bias}[\widehat{\theta}_n]^2
    + \V[\widehat{\theta}_n] \tag{2.1}\] This decomposition implies that, for unbiased
    estimators, MSE is the sampling variance. It also highlights why we might accept
    some bias for significant reductions in variance for lower overall MSE.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差（MSE）也与偏差和抽样方差（如果它是有限的）相关，通过以下分解结果：\[ \text{MSE} = \text{bias}[\widehat{\theta}_n]^2
    + \V[\widehat{\theta}_n] \tag{2.1}\] 这种分解意味着，对于无偏估计量，MSE就是抽样方差。它还突出了为什么我们可能会接受一些偏差，以换取方差显著降低并使总体MSE降低。
- en: '![](../Images/af81c9f8ce1a659fc6937891bb9e72ee.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af81c9f8ce1a659fc6937891bb9e72ee.png)'
- en: Two sampling distributions
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 两个抽样分布
- en: 'This figure shows the sampling distributions of two estimators: (1) \(\widehat{\theta}_a\),
    which is unbiased (centered on the true value \(\theta\)) but with a high sampling
    variance, and (2) \(\widehat{\theta}_b\), which is slightly biased but with much
    lower sampling variance. Even though \(\widehat{\theta}_b\) is biased, the probability
    of drawing a value close to the truth is higher than for \(\widehat{\theta}_a\).
    The MSE helps capture this balancing between bias and variance, and, indeed, in
    this case, \(MSE[\widehat{\theta}_b] < MSE[\widehat{\theta}_a]\).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此图显示了两个估计量的抽样分布：（1）\(\widehat{\theta}_a\)，它是无偏的（以真实值\(\theta\)为中心），但抽样方差很高；（2）\(\widehat{\theta}_b\)，它略有偏差但抽样方差低得多。尽管\(\widehat{\theta}_b\)有偏差，但抽取接近真实值的值的概率高于\(\widehat{\theta}_a\)。MSE有助于捕捉这种偏差和方差之间的平衡，实际上，在这种情况下，\(MSE[\widehat{\theta}_b]
    < MSE[\widehat{\theta}_a]\)。
- en: 2.11 Summary
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.11 总结
- en: In this chapter, we introduced **model-based inference**, in which we posit
    a probability model for the data-generating process. These models can be **parametric**
    in the sense that we specify the probability distribution of the data up to some
    parameters. They can also be **semiparametric** where we only specify certain
    features of the distribution such as a finite mean and variance. This chapter
    mostly focused on the latter, where we assumed the observed data were **independent
    and identically distributed** draws from a population distribution with finite
    mean and variance.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了**基于模型的推断**，其中我们为数据生成过程设定一个概率模型。这些模型可以是**参数化的**，即我们指定数据的概率分布直到某些参数。它们也可以是**半参数化的**，其中我们只指定分布的某些特征，如有限均值和方差。本章主要关注后者，其中我们假设观测数据是从具有有限均值和方差的总体分布中独立同分布抽取的。
- en: An **estimator** is a function of the data meant as a guess for some quantity
    of interest in the population. Because it is a function of random variables (the
    data), estimators are also random variables and have distributions, called **sampling
    distributions**, across repeated draws from the population. If this distribution
    is centered on the true value of the quantity of interest, we call the estimator
    **unbiased**. The variance of the sampling distribution, called the **sampling
    variance**, tells us how variable we should expect the estimator to be across
    draws from the population. The mean-squared error is an overall measure of the
    accuracy of an estimator that combines notions of bias and sampling variance.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**估计量**是数据的一个函数，其目的是对总体中某个感兴趣的数量进行猜测。因为它是一个随机变量（数据）的函数，所以估计量也是随机变量，并且具有在从总体中重复抽取时的分布，这种分布称为**抽样分布**。如果这个分布以感兴趣的数量真实值为中心，我们称这个估计量为**无偏**。抽样分布的方差，称为**抽样方差**，告诉我们应该期望估计量在从总体中抽取时的变化程度。均方误差是估计量准确性的总体度量，它结合了偏差和抽样方差的概念。'
- en: We showed in this chapter that the sample mean is unbiased for the population
    mean and that the sampling variance of the sample mean is the ratio of the population
    variance to the sample size. We also saw that **plug-in estimators** are a powerful
    way of constructing estimators as functions of sample means. That said, the focus
    of this chapter was finite-sample properties (that is, properties that are true
    no matter the sample size). In the next chapter, we will derive even more powerful
    results using large-sample approximations.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了样本均值对于总体均值是无偏的，并且样本均值的抽样方差是总体方差与样本大小的比率。我们还看到，**插值估计量**是将估计量作为样本均值函数构建的一种强大方法。尽管如此，本章的重点是有限样本性质（即，无论样本大小如何都为真的性质）。在下一章中，我们将使用大样本近似推导出更强大的结果。
- en: '* * *'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '1924 May 24, Boston Herald, Whiting’s Column: Tammany Has Learned That This
    Is No Time for Political Bosses, Quote Page 2, Column 1, Boston, Massachusetts.
    (GenealogyBank)[↩︎](#fnref1)***********'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1924年5月24日，波士顿先驱报，惠丁专栏：塔玛尼已经意识到现在不是政治老板的时间，引文页面2，第1栏，马萨诸塞州波士顿。（GenealogyBank)[↩︎](#fnref1)***********
