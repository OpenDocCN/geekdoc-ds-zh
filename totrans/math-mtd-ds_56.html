<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>7.4. Limit behavior 2: convergence to equilibrium#</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>7.4. Limit behavior 2: convergence to equilibrium#</h1>
<blockquote>原文：<a href="https://mmids-textbook.github.io/chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html">https://mmids-textbook.github.io/chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html</a></blockquote>

<p>We continue our study of the long-term behavior of a chain. Again, we restrict ourselves to finite-space discrete-time Markov chains that are also time-homogeneous.</p>
<section id="definitions">
<h2><span class="section-number">7.4.1. </span>Definitions<a class="headerlink" href="#definitions" title="Link to this heading">#</a></h2>
<p>Now that we have established the existence and uniqueness of a stationary distribution (at least in the irreducible case), it remains to justify its relevance. As we indicated before, the fixed-point nature of the stationary distribution definition suggests that it arises as a limit of repeatedly applying <span class="math notranslate nohighlight">\(P\)</span>. Indeed it can be shown that, starting from any distribution, the state distribution at time <span class="math notranslate nohighlight">\(t\)</span> converges to the stationary distribution as <span class="math notranslate nohighlight">\(t \to +\infty\)</span> – under an additional assumption.</p>
<p>The additional assumption involves issues of periodicity. The following example will suffice to illustrate.</p>
<p><strong>EXAMPLE:</strong> <strong>(A Periodic Chain)</strong> Consider a two-state Markov chain with transition matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P =\begin{pmatrix}
0 &amp; 1\\
1 &amp; 0
\end{pmatrix}.
\end{split}\]</div>
<p>Note that this chain is irreducible. Its unique stationary distribution is <span class="math notranslate nohighlight">\(\bpi = (1/2, 1/2)^T\)</span> since indeed</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\bpi P 
= (1/2, 1/2)^T \begin{pmatrix}
0 &amp; 1\\
1 &amp; 0
\end{pmatrix}
= (1/2, 1/2)^T
= \bpi.
\end{split}\]</div>
<p>We compute the distribution at time <span class="math notranslate nohighlight">\(t\)</span>, started from state <span class="math notranslate nohighlight">\(1\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[
\bmu = (1, 0)^T.
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
\bmu P
= (0, 1)^T,
\]</div>
<div class="math notranslate nohighlight">
\[
\bmu P^2 = (1,0)^T,
\]</div>
<div class="math notranslate nohighlight">
\[
\bmu P^3 = (0,1)^T,
\]</div>
<p>and so on.</p>
<p>In general, by induction,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\bmu P^k
= \begin{cases}
(1,0)^T &amp; \text{if $k$ is even}\\
(0,1)^T &amp; \text{if $k$ is odd}.
\end{cases}
\end{split}\]</div>
<p>Clearly the distribution is not converging. Note however that the time average does</p>
<div class="math notranslate nohighlight">
\[
\lim_{t \to +\infty}
\frac{1}{t}\sum_{k \leq t}
\bmu P^k
= (1/2, 1/2)^T
= \bpi.
\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We will need the following definition.</p>
<p><strong>DEFINITION</strong> <strong>(Aperiodic)</strong> <span class="math notranslate nohighlight">\(\idx{aperiodic}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain over a finite state space <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. We say that state <span class="math notranslate nohighlight">\(i \in \mathcal{S}\)</span> is aperiodic if</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i\,|\,X_0 = i] &gt; 0,
\]</div>
<p>for all sufficiently large <span class="math notranslate nohighlight">\(t\)</span>. A chain is aperiodic if all its states are. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(A Periodic Chain, continued)</strong> Going back to the two-state chain above, we note that neither state is aperiodic. For state <span class="math notranslate nohighlight">\(1\)</span>, we have shown that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = 1\,|\, X_0 = 1]
= 0
\]</div>
<p>for all <span class="math notranslate nohighlight">\(t\)</span> odd. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We will not need to explore this definition in great details here. Instead we give a simple <em>sufficient</em> condition that is typically good enough for data science applications.</p>
<p><strong>DEFINITION</strong> <strong>(Lazy)</strong> <span class="math notranslate nohighlight">\(\idx{lazy}\xdi\)</span> We say that a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is lazy if every state <span class="math notranslate nohighlight">\(i\)</span> satisfies</p>
<div class="math notranslate nohighlight">
\[
\P[X_1 = i\,|\,X_0 = i] &gt; 0.
\]</div>
<p>Put differently, all entries on the diagonal of the transition matrix are strictly positive. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>Graphically, the chain has self-loops<span class="math notranslate nohighlight">\(\idx{self-loop}\xdi\)</span> on each vertex. This terminology (which is not entirely standard) emphasizes the idea that the chain can “lazily” stay in its current state rather than always transitioning to a different one.</p>
<p>We check that a lazy chain is necessarily aperiodic. For any state <span class="math notranslate nohighlight">\(i \in \mathcal{S}\)</span> and any <span class="math notranslate nohighlight">\(t\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i\,|\,X_0 = i]
\geq \prod_{s = 1}^t \P[X_{s} = i\,|\,X_{s-1} = i] 
= (\P[X_1 = i\,|\,X_0 = i])^t 
&gt; 0,
\]</div>
<p>by assumption. In words, the probability of being at <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> given that we started at <span class="math notranslate nohighlight">\(i\)</span> is at least the probability that we never left.</p>
<p><strong>EXAMPLE:</strong> Any Markov chain can be modified to be lazy by adding self-loops to all vertices. Specifically, let <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j} \in \mathbb{R}^{n \times n}\)</span> be the transition matrix of a Markov chain on <span class="math notranslate nohighlight">\([n]\)</span>. Consider the modified transition matrix <span class="math notranslate nohighlight">\(Q = (q_{i,j})_{i,j}\)</span> defined as</p>
<div class="math notranslate nohighlight">
\[
Q 
= 
\frac{1}{2}(I_{n \times n} + P).
\]</div>
<p>We check that this is indeed a stochastic matrix. For each <span class="math notranslate nohighlight">\(i, j \in [n]\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
q_{i,j}
= \frac{1}{2} \mathbf{1}_{i = j} + \frac{1}{2} p_{i,j}
\geq \frac{1}{2} p_{i,j} \geq 0
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^n q_{i,\ell} 
= \sum_{\ell=1}^n \left[\frac{1}{2} \mathbf{1}_{i = \ell} + \frac{1}{2} p_{i,\ell}\right]
= \frac{1}{2} \sum_{\ell=1}^n  \mathbf{1}_{i = \ell} + \frac{1}{2} \sum_{\ell=1}^n  p_{i,\ell}
= \frac{1}{2} + \frac{1}{2}
= 1.
\]</div>
<p>Finally, we note that <span class="math notranslate nohighlight">\(Q\)</span> is lazy since</p>
<div class="math notranslate nohighlight">
\[
q_{i,i}
= \frac{1}{2} \mathbf{1}_{i = i} + \frac{1}{2} p_{i,i}
= \frac{1}{2} + \frac{1}{2} p_{i,i}
\geq \frac{1}{2} &gt; 0.
\]</div>
<p>The chain <span class="math notranslate nohighlight">\(Q\)</span> is often referred to as the “lazy version” of <span class="math notranslate nohighlight">\(P\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
</section>
<section id="convergence-theorems">
<h2><span class="section-number">7.4.2. </span>Convergence theorems<a class="headerlink" href="#convergence-theorems" title="Link to this heading">#</a></h2>
<p>We are ready to state two key theorems.</p>
<p>First, the <em>Convergence to Equilibrium Theorem</em> applies to irreducible and aperiodic chains. Such chains have a unique stationary distribution. The theorem says that, started from any initial distribution, the distribution at time <span class="math notranslate nohighlight">\(t\)</span> converges to the stationary distribution as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>.</p>
<p><strong>THEOREM</strong> <strong>(Convergence to Equilibrium)</strong> <span class="math notranslate nohighlight">\(\idx{convergence to equilibrium theorem}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> be a finite, irreducible and aperiodic Markov chain with unique stationary distribution <span class="math notranslate nohighlight">\(\bpi\)</span>. Then for any initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> and any state <span class="math notranslate nohighlight">\(i\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i] \to \pi_i,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p>Put differently, this theorem should look familiar. Using the formula <span class="math notranslate nohighlight">\((\bmu P^t)_i\)</span> for the probability that the state is <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, we can rephrase the theorem in matrix form as</p>
<div class="math notranslate nohighlight">
\[
\bmu P^t \to \bpi,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. This is highly reminiscent of the <em>Power Iteration Lemma</em>. Here repeated multiplication by <span class="math notranslate nohighlight">\(P\)</span> starting from an arbitrary distribution converges to <span class="math notranslate nohighlight">\(\bpi\)</span>, which recall is a left eigenvector of <span class="math notranslate nohighlight">\(P\)</span> with eigenvalue <span class="math notranslate nohighlight">\(1\)</span>. Unlike the <em>Power Iteration Lemma</em>, there is no need to normalize here. This is because we implicitly work with the <span class="math notranslate nohighlight">\(\ell_1\)</span>-norm and <span class="math notranslate nohighlight">\(P\)</span> is stochastic, thereby preserving the norm.</p>
<p>Second, the <em>Ergodic Theorem</em> applies to irreducible (but not necessarily aperiodic) chains. Again such have a unique stationary distribution. The theorem says that, started from any initial distribution, the frequency of visits to any state <span class="math notranslate nohighlight">\(i\)</span> converges to the stationary distribution. Below, we use the notation <span class="math notranslate nohighlight">\(\mathbf{1}[X_s = i]\)</span> which is <span class="math notranslate nohighlight">\(1\)</span> when <span class="math notranslate nohighlight">\(X_s = i\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<p><strong>THEOREM</strong> <strong>(Ergodic)</strong> <span class="math notranslate nohighlight">\(\idx{ergodic theorem}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> be a finite and irreducible Markov chain with unique stationary distribution <span class="math notranslate nohighlight">\(\bpi\)</span>. Then for any initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> and any state <span class="math notranslate nohighlight">\(i\)</span></p>
<div class="math notranslate nohighlight">
\[
\frac{1}{t} \sum_{s = 0}^t \mathbf{1}[X_s = i] \to \pi_i,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p>Above, <span class="math notranslate nohighlight">\(\sum_{s = 0}^t \mathbf{1}[X_s = i]\)</span> is the number of visits to <span class="math notranslate nohighlight">\(i\)</span> up to time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Note that neither of these two theorems immediately implies the other. They are both useful in their own way.</p>
<p><strong>NUMERICAL CORNER:</strong> The <em>Convergence to Equilibrium Theorem</em> implies that we can use power iteration to compute the unique stationary diistribution in the irreducible case. We revisit the <em>Robot Vaccum Example</em>. We initialize with the uniform distribution, then repeatedly multiply by <span class="math notranslate nohighlight">\(P\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">P_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">n_robot</span> <span class="o">=</span> <span class="n">P_robot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span><span class="o">/</span><span class="n">n_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.04444444 0.18333333 0.03888889 0.05       0.12222222 0.25555556
 0.10555556 0.15       0.05      ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.06       0.10222222 0.075      0.03944444 0.085      0.21722222
 0.12166667 0.195      0.10444444]
</pre></div>
</div>
</div>
</div>
<p>We repeat, say, <span class="math notranslate nohighlight">\(10\)</span> more times and compare to the truth <code class="docutils literal notranslate"><span class="pre">pi_robot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.0358112  0.10982018 0.06297235 0.02721311 0.08055026 0.27393441
 0.09944157 0.19521946 0.11503747]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">P_robot</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">pi_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pi_robot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03581295 0.11029771 0.06311453 0.02723642 0.0802953  0.27369992
 0.09922559 0.19502056 0.11529703]
</pre></div>
</div>
</div>
</div>
<p>We see that a small number of iterations sufficed to get an accurate answer. In general, the speed of convergence depends on the eigenvalues of <span class="math notranslate nohighlight">\(P\)</span> that are strictly smaller than <span class="math notranslate nohighlight">\(1\)</span> in absolute value.</p>
<p>We can also check the <em>Ergodic Theorem</em> through simulation. We generate a long sample path and compare the state visit frequencies to <code class="docutils literal notranslate"><span class="pre">pi_robot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_robot</span>
<span class="n">path_length</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">visit_freq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="n">path_length</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_robot</span><span class="p">):</span>
    <span class="n">visit_freq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">path</span> <span class="o">==</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">path_length</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">visit_freq</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03627927 0.10927781 0.0601788  0.02645947 0.08045839 0.27359453
 0.10119798 0.19693606 0.11561769]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="n">pi_robot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03581295 0.11029771 0.06311453 0.02723642 0.0802953  0.27369992
 0.09922559 0.19502056 0.11529703]
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>CHAT &amp; LEARN</strong> The mixing time is an important quantity in the study of Markov chains. Ask your favorite AI chatbot to define this concept and discuss its relevance to the convergence of Markov chains. Explore some bounds on the mixing time for specific classes of Markov chains. <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> Which of the following is a sufficient condition for a Markov chain to be aperiodic?</p>
<p>a) The chain is irreducible.</p>
<p>b) The chain has a unique stationary distribution.</p>
<p>c) The chain is lazy.</p>
<p>d) The chain has a finite state space.</p>
<p><strong>2</strong> In a Markov chain with state space <span class="math notranslate nohighlight">\(S\)</span> and transition matrix <span class="math notranslate nohighlight">\(P\)</span>, what does it mean if the chain is lazy?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{E}[X_t] = 0\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>b) <span class="math notranslate nohighlight">\(P_{ii} &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i \in S\)</span>.</p>
<p>c) <span class="math notranslate nohighlight">\(P_{ij} = 0\)</span> for all <span class="math notranslate nohighlight">\(i \ne j\)</span>.</p>
<p>d) <span class="math notranslate nohighlight">\(\mathrm{Var}(X_t) = 1\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p><strong>3</strong> The Convergence to Equilibrium Theorem applies to which type of Markov chains?</p>
<p>a) Irreducible and aperiodic chains</p>
<p>b) Irreducible and periodic chains</p>
<p>c) Reducible and aperiodic chains</p>
<p>d) Reducible and periodic chains</p>
<p><strong>4</strong> The Ergodic Theorem applies to which type of Markov chains?</p>
<p>a) Irreducible chains</p>
<p>b) Aperiodic chains</p>
<p>c) Reducible chains</p>
<p>d) Periodic chains</p>
<p><strong>5</strong> Which of the following describes a key difference between the Convergence to Equilibrium Theorem and the Ergodic Theorem?</p>
<p>a) The Convergence to Equilibrium Theorem applies to periodic chains, while the Ergodic Theorem applies to aperiodic chains.</p>
<p>b) The Convergence to Equilibrium Theorem concerns the state distribution, while the Ergodic Theorem concerns the frequency of state visits.</p>
<p>c) The Convergence to Equilibrium Theorem requires a diagonal transition matrix, while the Ergodic Theorem does not.</p>
<p>d) The Convergence to Equilibrium Theorem is applicable only to finite Markov chains, while the Ergodic Theorem is not.</p>
<p>Answer for 1: c. Justification: The text states, “We check that a lazy chain is necessarily aperiodic.”</p>
<p>Answer for 2: b. Justification: A weakly lazy Markov chain is defined as having all diagonal entries of the transition matrix strictly positive, i.e., <span class="math notranslate nohighlight">\(P_{ii} &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i \in S\)</span>.</p>
<p>Answer for 3: a. Justification: The text states, “First, the Convergence to Equilibrium Theorem applies to irreducible and aperiodic chains.”</p>
<p>Answer for 4: a. Justification: The text states, “Second, the Ergodic Theorem applies to irreducible (but not necessarily aperiodic) chains.”</p>
<p>Answer for 5: b. Justification: The Convergence to Equilibrium Theorem addresses the convergence of the state distribution to the stationary distribution, while the Ergodic Theorem focuses on the frequency of visits to any state converging to the stationary distribution.</p>
</section>
&#13;

<h2><span class="section-number">7.4.1. </span>Definitions<a class="headerlink" href="#definitions" title="Link to this heading">#</a></h2>
<p>Now that we have established the existence and uniqueness of a stationary distribution (at least in the irreducible case), it remains to justify its relevance. As we indicated before, the fixed-point nature of the stationary distribution definition suggests that it arises as a limit of repeatedly applying <span class="math notranslate nohighlight">\(P\)</span>. Indeed it can be shown that, starting from any distribution, the state distribution at time <span class="math notranslate nohighlight">\(t\)</span> converges to the stationary distribution as <span class="math notranslate nohighlight">\(t \to +\infty\)</span> – under an additional assumption.</p>
<p>The additional assumption involves issues of periodicity. The following example will suffice to illustrate.</p>
<p><strong>EXAMPLE:</strong> <strong>(A Periodic Chain)</strong> Consider a two-state Markov chain with transition matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P =\begin{pmatrix}
0 &amp; 1\\
1 &amp; 0
\end{pmatrix}.
\end{split}\]</div>
<p>Note that this chain is irreducible. Its unique stationary distribution is <span class="math notranslate nohighlight">\(\bpi = (1/2, 1/2)^T\)</span> since indeed</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\bpi P 
= (1/2, 1/2)^T \begin{pmatrix}
0 &amp; 1\\
1 &amp; 0
\end{pmatrix}
= (1/2, 1/2)^T
= \bpi.
\end{split}\]</div>
<p>We compute the distribution at time <span class="math notranslate nohighlight">\(t\)</span>, started from state <span class="math notranslate nohighlight">\(1\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[
\bmu = (1, 0)^T.
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
\bmu P
= (0, 1)^T,
\]</div>
<div class="math notranslate nohighlight">
\[
\bmu P^2 = (1,0)^T,
\]</div>
<div class="math notranslate nohighlight">
\[
\bmu P^3 = (0,1)^T,
\]</div>
<p>and so on.</p>
<p>In general, by induction,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\bmu P^k
= \begin{cases}
(1,0)^T &amp; \text{if $k$ is even}\\
(0,1)^T &amp; \text{if $k$ is odd}.
\end{cases}
\end{split}\]</div>
<p>Clearly the distribution is not converging. Note however that the time average does</p>
<div class="math notranslate nohighlight">
\[
\lim_{t \to +\infty}
\frac{1}{t}\sum_{k \leq t}
\bmu P^k
= (1/2, 1/2)^T
= \bpi.
\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We will need the following definition.</p>
<p><strong>DEFINITION</strong> <strong>(Aperiodic)</strong> <span class="math notranslate nohighlight">\(\idx{aperiodic}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> be a Markov chain over a finite state space <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. We say that state <span class="math notranslate nohighlight">\(i \in \mathcal{S}\)</span> is aperiodic if</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i\,|\,X_0 = i] &gt; 0,
\]</div>
<p>for all sufficiently large <span class="math notranslate nohighlight">\(t\)</span>. A chain is aperiodic if all its states are. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(A Periodic Chain, continued)</strong> Going back to the two-state chain above, we note that neither state is aperiodic. For state <span class="math notranslate nohighlight">\(1\)</span>, we have shown that</p>
<div class="math notranslate nohighlight">
\[
\P[X_t = 1\,|\, X_0 = 1]
= 0
\]</div>
<p>for all <span class="math notranslate nohighlight">\(t\)</span> odd. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We will not need to explore this definition in great details here. Instead we give a simple <em>sufficient</em> condition that is typically good enough for data science applications.</p>
<p><strong>DEFINITION</strong> <strong>(Lazy)</strong> <span class="math notranslate nohighlight">\(\idx{lazy}\xdi\)</span> We say that a Markov chain <span class="math notranslate nohighlight">\((X_t)_{t \geq 0}\)</span> is lazy if every state <span class="math notranslate nohighlight">\(i\)</span> satisfies</p>
<div class="math notranslate nohighlight">
\[
\P[X_1 = i\,|\,X_0 = i] &gt; 0.
\]</div>
<p>Put differently, all entries on the diagonal of the transition matrix are strictly positive. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>Graphically, the chain has self-loops<span class="math notranslate nohighlight">\(\idx{self-loop}\xdi\)</span> on each vertex. This terminology (which is not entirely standard) emphasizes the idea that the chain can “lazily” stay in its current state rather than always transitioning to a different one.</p>
<p>We check that a lazy chain is necessarily aperiodic. For any state <span class="math notranslate nohighlight">\(i \in \mathcal{S}\)</span> and any <span class="math notranslate nohighlight">\(t\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i\,|\,X_0 = i]
\geq \prod_{s = 1}^t \P[X_{s} = i\,|\,X_{s-1} = i] 
= (\P[X_1 = i\,|\,X_0 = i])^t 
&gt; 0,
\]</div>
<p>by assumption. In words, the probability of being at <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> given that we started at <span class="math notranslate nohighlight">\(i\)</span> is at least the probability that we never left.</p>
<p><strong>EXAMPLE:</strong> Any Markov chain can be modified to be lazy by adding self-loops to all vertices. Specifically, let <span class="math notranslate nohighlight">\(P = (p_{i,j})_{i,j} \in \mathbb{R}^{n \times n}\)</span> be the transition matrix of a Markov chain on <span class="math notranslate nohighlight">\([n]\)</span>. Consider the modified transition matrix <span class="math notranslate nohighlight">\(Q = (q_{i,j})_{i,j}\)</span> defined as</p>
<div class="math notranslate nohighlight">
\[
Q 
= 
\frac{1}{2}(I_{n \times n} + P).
\]</div>
<p>We check that this is indeed a stochastic matrix. For each <span class="math notranslate nohighlight">\(i, j \in [n]\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
q_{i,j}
= \frac{1}{2} \mathbf{1}_{i = j} + \frac{1}{2} p_{i,j}
\geq \frac{1}{2} p_{i,j} \geq 0
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^n q_{i,\ell} 
= \sum_{\ell=1}^n \left[\frac{1}{2} \mathbf{1}_{i = \ell} + \frac{1}{2} p_{i,\ell}\right]
= \frac{1}{2} \sum_{\ell=1}^n  \mathbf{1}_{i = \ell} + \frac{1}{2} \sum_{\ell=1}^n  p_{i,\ell}
= \frac{1}{2} + \frac{1}{2}
= 1.
\]</div>
<p>Finally, we note that <span class="math notranslate nohighlight">\(Q\)</span> is lazy since</p>
<div class="math notranslate nohighlight">
\[
q_{i,i}
= \frac{1}{2} \mathbf{1}_{i = i} + \frac{1}{2} p_{i,i}
= \frac{1}{2} + \frac{1}{2} p_{i,i}
\geq \frac{1}{2} &gt; 0.
\]</div>
<p>The chain <span class="math notranslate nohighlight">\(Q\)</span> is often referred to as the “lazy version” of <span class="math notranslate nohighlight">\(P\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
&#13;

<h2><span class="section-number">7.4.2. </span>Convergence theorems<a class="headerlink" href="#convergence-theorems" title="Link to this heading">#</a></h2>
<p>We are ready to state two key theorems.</p>
<p>First, the <em>Convergence to Equilibrium Theorem</em> applies to irreducible and aperiodic chains. Such chains have a unique stationary distribution. The theorem says that, started from any initial distribution, the distribution at time <span class="math notranslate nohighlight">\(t\)</span> converges to the stationary distribution as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>.</p>
<p><strong>THEOREM</strong> <strong>(Convergence to Equilibrium)</strong> <span class="math notranslate nohighlight">\(\idx{convergence to equilibrium theorem}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> be a finite, irreducible and aperiodic Markov chain with unique stationary distribution <span class="math notranslate nohighlight">\(\bpi\)</span>. Then for any initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> and any state <span class="math notranslate nohighlight">\(i\)</span></p>
<div class="math notranslate nohighlight">
\[
\P[X_t = i] \to \pi_i,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p>Put differently, this theorem should look familiar. Using the formula <span class="math notranslate nohighlight">\((\bmu P^t)_i\)</span> for the probability that the state is <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, we can rephrase the theorem in matrix form as</p>
<div class="math notranslate nohighlight">
\[
\bmu P^t \to \bpi,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. This is highly reminiscent of the <em>Power Iteration Lemma</em>. Here repeated multiplication by <span class="math notranslate nohighlight">\(P\)</span> starting from an arbitrary distribution converges to <span class="math notranslate nohighlight">\(\bpi\)</span>, which recall is a left eigenvector of <span class="math notranslate nohighlight">\(P\)</span> with eigenvalue <span class="math notranslate nohighlight">\(1\)</span>. Unlike the <em>Power Iteration Lemma</em>, there is no need to normalize here. This is because we implicitly work with the <span class="math notranslate nohighlight">\(\ell_1\)</span>-norm and <span class="math notranslate nohighlight">\(P\)</span> is stochastic, thereby preserving the norm.</p>
<p>Second, the <em>Ergodic Theorem</em> applies to irreducible (but not necessarily aperiodic) chains. Again such have a unique stationary distribution. The theorem says that, started from any initial distribution, the frequency of visits to any state <span class="math notranslate nohighlight">\(i\)</span> converges to the stationary distribution. Below, we use the notation <span class="math notranslate nohighlight">\(\mathbf{1}[X_s = i]\)</span> which is <span class="math notranslate nohighlight">\(1\)</span> when <span class="math notranslate nohighlight">\(X_s = i\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<p><strong>THEOREM</strong> <strong>(Ergodic)</strong> <span class="math notranslate nohighlight">\(\idx{ergodic theorem}\xdi\)</span> Let <span class="math notranslate nohighlight">\((X_t)_{t\geq 0}\)</span> be a finite and irreducible Markov chain with unique stationary distribution <span class="math notranslate nohighlight">\(\bpi\)</span>. Then for any initial distribution <span class="math notranslate nohighlight">\(\bmu\)</span> and any state <span class="math notranslate nohighlight">\(i\)</span></p>
<div class="math notranslate nohighlight">
\[
\frac{1}{t} \sum_{s = 0}^t \mathbf{1}[X_s = i] \to \pi_i,
\]</div>
<p>as <span class="math notranslate nohighlight">\(t \to +\infty\)</span>. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p>Above, <span class="math notranslate nohighlight">\(\sum_{s = 0}^t \mathbf{1}[X_s = i]\)</span> is the number of visits to <span class="math notranslate nohighlight">\(i\)</span> up to time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Note that neither of these two theorems immediately implies the other. They are both useful in their own way.</p>
<p><strong>NUMERICAL CORNER:</strong> The <em>Convergence to Equilibrium Theorem</em> implies that we can use power iteration to compute the unique stationary diistribution in the irreducible case. We revisit the <em>Robot Vaccum Example</em>. We initialize with the uniform distribution, then repeatedly multiply by <span class="math notranslate nohighlight">\(P\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">P_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">n_robot</span> <span class="o">=</span> <span class="n">P_robot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span><span class="o">/</span><span class="n">n_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.04444444 0.18333333 0.03888889 0.05       0.12222222 0.25555556
 0.10555556 0.15       0.05      ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.06       0.10222222 0.075      0.03944444 0.085      0.21722222
 0.12166667 0.195      0.10444444]
</pre></div>
</div>
</div>
</div>
<p>We repeat, say, <span class="math notranslate nohighlight">\(10\)</span> more times and compare to the truth <code class="docutils literal notranslate"><span class="pre">pi_robot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">@</span> <span class="n">P_robot</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.0358112  0.10982018 0.06297235 0.02721311 0.08055026 0.27393441
 0.09944157 0.19521946 0.11503747]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">P_robot</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">pi_robot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pi_robot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03581295 0.11029771 0.06311453 0.02723642 0.0802953  0.27369992
 0.09922559 0.19502056 0.11529703]
</pre></div>
</div>
</div>
</div>
<p>We see that a small number of iterations sufficed to get an accurate answer. In general, the speed of convergence depends on the eigenvalues of <span class="math notranslate nohighlight">\(P\)</span> that are strictly smaller than <span class="math notranslate nohighlight">\(1\)</span> in absolute value.</p>
<p>We can also check the <em>Ergodic Theorem</em> through simulation. We generate a long sample path and compare the state visit frequencies to <code class="docutils literal notranslate"><span class="pre">pi_robot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_robot</span>
<span class="n">path_length</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">visit_freq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_robot</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">SamplePath</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">P_robot</span><span class="p">,</span> <span class="n">path_length</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_robot</span><span class="p">):</span>
    <span class="n">visit_freq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">path</span> <span class="o">==</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">path_length</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">visit_freq</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03627927 0.10927781 0.0601788  0.02645947 0.08045839 0.27359453
 0.10119798 0.19693606 0.11561769]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span/><span class="nb">print</span><span class="p">(</span><span class="n">pi_robot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span/>[0.03581295 0.11029771 0.06311453 0.02723642 0.0802953  0.27369992
 0.09922559 0.19502056 0.11529703]
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>CHAT &amp; LEARN</strong> The mixing time is an important quantity in the study of Markov chains. Ask your favorite AI chatbot to define this concept and discuss its relevance to the convergence of Markov chains. Explore some bounds on the mixing time for specific classes of Markov chains. <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> Which of the following is a sufficient condition for a Markov chain to be aperiodic?</p>
<p>a) The chain is irreducible.</p>
<p>b) The chain has a unique stationary distribution.</p>
<p>c) The chain is lazy.</p>
<p>d) The chain has a finite state space.</p>
<p><strong>2</strong> In a Markov chain with state space <span class="math notranslate nohighlight">\(S\)</span> and transition matrix <span class="math notranslate nohighlight">\(P\)</span>, what does it mean if the chain is lazy?</p>
<p>a) <span class="math notranslate nohighlight">\(\mathbb{E}[X_t] = 0\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>b) <span class="math notranslate nohighlight">\(P_{ii} &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i \in S\)</span>.</p>
<p>c) <span class="math notranslate nohighlight">\(P_{ij} = 0\)</span> for all <span class="math notranslate nohighlight">\(i \ne j\)</span>.</p>
<p>d) <span class="math notranslate nohighlight">\(\mathrm{Var}(X_t) = 1\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p><strong>3</strong> The Convergence to Equilibrium Theorem applies to which type of Markov chains?</p>
<p>a) Irreducible and aperiodic chains</p>
<p>b) Irreducible and periodic chains</p>
<p>c) Reducible and aperiodic chains</p>
<p>d) Reducible and periodic chains</p>
<p><strong>4</strong> The Ergodic Theorem applies to which type of Markov chains?</p>
<p>a) Irreducible chains</p>
<p>b) Aperiodic chains</p>
<p>c) Reducible chains</p>
<p>d) Periodic chains</p>
<p><strong>5</strong> Which of the following describes a key difference between the Convergence to Equilibrium Theorem and the Ergodic Theorem?</p>
<p>a) The Convergence to Equilibrium Theorem applies to periodic chains, while the Ergodic Theorem applies to aperiodic chains.</p>
<p>b) The Convergence to Equilibrium Theorem concerns the state distribution, while the Ergodic Theorem concerns the frequency of state visits.</p>
<p>c) The Convergence to Equilibrium Theorem requires a diagonal transition matrix, while the Ergodic Theorem does not.</p>
<p>d) The Convergence to Equilibrium Theorem is applicable only to finite Markov chains, while the Ergodic Theorem is not.</p>
<p>Answer for 1: c. Justification: The text states, “We check that a lazy chain is necessarily aperiodic.”</p>
<p>Answer for 2: b. Justification: A weakly lazy Markov chain is defined as having all diagonal entries of the transition matrix strictly positive, i.e., <span class="math notranslate nohighlight">\(P_{ii} &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i \in S\)</span>.</p>
<p>Answer for 3: a. Justification: The text states, “First, the Convergence to Equilibrium Theorem applies to irreducible and aperiodic chains.”</p>
<p>Answer for 4: a. Justification: The text states, “Second, the Ergodic Theorem applies to irreducible (but not necessarily aperiodic) chains.”</p>
<p>Answer for 5: b. Justification: The Convergence to Equilibrium Theorem addresses the convergence of the state distribution to the stationary distribution, while the Ergodic Theorem focuses on the frequency of visits to any state converging to the stationary distribution.</p>
    
</body>
</html>