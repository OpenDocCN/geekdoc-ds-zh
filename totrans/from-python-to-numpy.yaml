- en: From Python to Numpy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Copyright (c) 2017 - Nicolas P. Rougier <[Nicolas.Rougier@inria.fr](mailto:Nicolas.Rougier%40inria.fr)>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![img/37ef03690ff06d35c7a6a4721a5bfdf6.png](img/37ef03690ff06d35c7a6a4721a5bfdf6.png)
    ![img/b9aad74680f5251444b0d4b4ffa1af9a.png](img/b9aad74680f5251444b0d4b4ffa1af9a.png)
    ![img/02dcd8f1f04a6181a76ede131dfccf71.png](img/02dcd8f1f04a6181a76ede131dfccf71.png)
    ![img/2cdafe9a0083e1ba44f35436fa336345.png](img/2cdafe9a0083e1ba44f35436fa336345.png)Latest
    version - May 2017DOI: [10.5281/zenodo.225783](http://doi.org/10.5281/zenodo.225783)![img/247a52e4201671bc71b669dffc84bc84.png](img/247a52e4201671bc71b669dffc84bc84.png)'
  prefs: []
  type: TYPE_IMG
- en: There are already a fair number of books about Numpy (see [Bibliography](#bibliography))
    and a legitimate question is to wonder if another book is really necessary. As
    you may have guessed by reading these lines, my personal answer is yes, mostly
    because I think there is room for a different approach concentrating on the migration
    from Python to Numpy through vectorization. There are a lot of techniques that
    you don't find in books and such techniques are mostly learned through experience.
    The goal of this book is to explain some of these techniques and to provide an
    opportunity for making this experience in the process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Website:** [http://www.labri.fr/perso/nrougier/from-python-to-numpy](http://www.labri.fr/perso/nrougier/from-python-to-numpy)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table of Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Preface](#preface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[About the author](#about-the-author)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[About this book](#about-this-book)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[License](#license)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#introduction)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple example](#simple-example)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Readability vs speed](#readability-vs-speed)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Anatomy of an array](#anatomy-of-an-array)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id3)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory layout](#memory-layout)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Views and copies](#views-and-copies)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#conclusion)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Code vectorization](#code-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id5)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Uniform vectorization](#uniform-vectorization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Temporal vectorization](#temporal-vectorization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Spatial vectorization](#spatial-vectorization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id17)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Problem vectorization](#problem-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id19)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Path finding](#path-finding)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fluid Dynamics](#fluid-dynamics)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blue noise sampling](#blue-noise-sampling)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id27)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Custom vectorization](#custom-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id29)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Typed list](#typed-list)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory aware array](#memory-aware-array)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id36)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beyond Numpy](#beyond-numpy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Python](#back-to-python)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy & co](#numpy-co)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Scipy & co](#scipy-co)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id52)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id53)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Quick References](#quick-references)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data type](#id56)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creation](#id57)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Indexing](#id58)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reshaping](#reshaping)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Broadcasting](#broadcasting)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bibliography](#bibliography)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tutorials](#tutorials)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Articles](#articles)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Books](#books)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disclaimer:** All external pictures should have associated credits. If there
    are missing credits, please tell me, I will correct it. Similarly, all excerpts
    should be sourced (wikipedia mostly). If not, this is an error and I will correct
    it as soon as you tell me.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Preface](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[About the author](#about-the-author)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[About this book](#about-this-book)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prerequisites](#prerequisites)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conventions](#conventions)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to contribute](#how-to-contribute)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Publishing](#publishing)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[License](#license)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[About the author](#contents)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Nicolas P. Rougier](http://www.labri.fr/perso/nrougier/) is a full-time research
    scientist at [Inria](http://www.inria.fr/en) which is the French national institute
    for research in computer science and control. This is a public scientific and
    technological establishment (EPST) under the double supervision of the Research
    & Education Ministry, and the Ministry of Economy Finance and Industry. Nicolas
    P. Rougier is working within the [Mnemosyne](http://www.inria.fr/en/teams/mnemosyne)
    project which lies at the frontier between integrative and computational neuroscience
    in association with the [Institute of Neurodegenerative Diseases](http://www.imn-bordeaux.org/en/),
    the Bordeaux laboratory for research in computer science ([LaBRI](https://www.labri.fr/)),
    the [University of Bordeaux](http://www.u-bordeaux.com/) and the national center
    for scientific research ([CNRS](http://www.cnrs.fr/index.php)).'
  prefs: []
  type: TYPE_NORMAL
- en: He has been using Python for more than 15 years and numpy for more than 10 years
    for modeling in neuroscience, machine learning and for advanced visualization
    (OpenGL). Nicolas P. Rougier is the author of several online resources and tutorials
    (Matplotlib, numpy, OpenGL) and he's teaching Python, numpy and scientific visualization
    at the University of Bordeaux and in various conferences and schools worldwide
    (SciPy, EuroScipy, etc). He's also the author of the popular article [Ten Simple
    Rules for Better Figures](http://dx.doi.org/10.1371/journal.pcbi.1003833) and
    a popular [matplotlib tutorial](http://www.labri.fr/perso/nrougier/teaching/matplotlib/matplotlib.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[About this book](#contents)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This book has been written in [restructured text](http://docutils.sourceforge.net/rst.html)
    format and generated using the `rst2html.py` command line available from the [docutils](http://docutils.sourceforge.net/)
    python package.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to rebuild the html output, from the top directory, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The sources are available from [https://github.com/rougier/from-python-to-numpy](https://github.com/rougier/from-python-to-numpy).
  prefs: []
  type: TYPE_NORMAL
- en: '[Prerequisites](#contents)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is not a Python beginner guide and you should have an intermediate level
    in Python and ideally a beginner level in numpy. If this is not the case, have
    a look at the [bibliography](#bibliography) for a curated list of resources.
  prefs: []
  type: TYPE_NORMAL
- en: '[Conventions](#contents)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will use usual naming conventions. If not stated explicitly, each script
    should import numpy, scipy and matplotlib as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll use up-to-date versions (at the date of writing, i.e. January, 2017)
    of the different packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Packages | Version |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Python | 3.6.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Numpy | 1.12.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Scipy | 0.18.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Matplotlib | 2.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '[How to contribute](#contents)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you want to contribute to this book, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: Review chapters (please contact me)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Report issues ([https://github.com/rougier/from-python-to-numpy/issues](https://github.com/rougier/from-python-to-numpy/issues))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suggest improvements ([https://github.com/rougier/from-python-to-numpy/pulls](https://github.com/rougier/from-python-to-numpy/pulls))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correct English ([https://github.com/rougier/from-python-to-numpy/issues](https://github.com/rougier/from-python-to-numpy/issues))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design a better and more responsive html template for the book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Star the project ([https://github.com/rougier/from-python-to-numpy](https://github.com/rougier/from-python-to-numpy))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Publishing](#contents)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you''re an editor interested in publishing this book, you can [contact me](mailto:Nicolas.Rougier%40inria.fr)
    if you agree to have this version and all subsequent versions open access (i.e.
    online at [this address](http://www.labri.fr/perso/nrougier/from-python-to-numpy)),
    you know how to deal with [restructured text](http://docutils.sourceforge.net/rst.html)
    (Word is not an option), you provide a real added-value as well as supporting
    services, and more importantly, you have a truly amazing latex book template (and
    be warned that I''m a bit picky about typography & design: [Edward Tufte](https://www.edwardtufte.com/tufte/)
    is my hero). Still here?'
  prefs: []
  type: TYPE_NORMAL
- en: '[License](#contents)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Book**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This work is licensed under a [Creative Commons Attribution-Non Commercial-Share
    Alike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/).
    You are free to:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Share** — copy and redistribute the material in any medium or format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adapt** — remix, transform, and build upon the material'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The licensor cannot revoke these freedoms as long as you follow the license
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code**'
  prefs: []
  type: TYPE_NORMAL
- en: The code is licensed under the [OSI-approved BSD 2-Clause License](LICENSE-code.txt).
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Simple example](#simple-example)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Readability vs speed](#readability-vs-speed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple example](#id1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can execute any code below from the [code](code) folder using the regular
    python shell or from inside an IPython session or Jupyter notebook. In such a
    case, you might want to use the magic command `%timeit` instead of the [custom
    one](code/tools.py) I wrote.
  prefs: []
  type: TYPE_NORMAL
- en: Numpy is all about vectorization. If you are familiar with Python, this is the
    main difficulty you'll face because you'll need to change your way of thinking
    and your new friends (among others) are named "vectors", "arrays", "views" or
    "ufuncs".
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a very simple example, random walk. One possible object oriented
    approach would be to define a `RandomWalker` class and write a walk method that
    would return the current position after each (random) step. It''s nice, it''s
    readable, but it is slow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object oriented approach**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Benchmarking gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Procedural approach**'
  prefs: []
  type: TYPE_NORMAL
- en: For such a simple problem, we can probably save the class definition and concentrate
    only on the walk method that computes successive positions after each random step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This new method saves some CPU cycles but not that much because this function
    is pretty much the same as in the object-oriented approach and the few cycles
    we saved probably come from the inner Python object-oriented machinery.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Vectorized approach**'
  prefs: []
  type: TYPE_NORMAL
- en: 'But we can do better using the [itertools](https://docs.python.org/3.6/library/itertools.html)
    Python module that offers *a set of functions creating iterators for efficient
    looping*. If we observe that a random walk is an accumulation of steps, we can
    rewrite the function by first generating all the steps and accumulate them without
    any loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, we''ve just *vectorized* our function. Instead of looping for picking
    sequential steps and add them to the current position, we first generated all
    the steps at once and used the [accumulate](https://docs.python.org/3.6/library/itertools.html#itertools.accumulate)
    function to compute all the positions. We got rid of the loop and this makes things
    faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We gained 85% of computation-time compared to the previous version, not so bad.
    But the advantage of this new version is that it makes numpy vectorization super
    simple. We just have to translate itertools call into numpy ones.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Not too difficult, but we gained a factor 500x using numpy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This book is about vectorization, be it at the code or problem level. We'll
    see this difference is important before looking at custom vectorization.
  prefs: []
  type: TYPE_NORMAL
- en: '[Readability vs speed](#id1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before heading to the next chapter, I would like to warn you about a potential
    problem you may encounter once you'll have become familiar with numpy. It is a
    very powerful library and you can make wonders with it but, most of the time,
    this comes at the price of readability. If you don't comment your code at the
    time of writing, you won't be able to tell what a function is doing after a few
    weeks (or possibly days). For example, can you tell what the two functions below
    are doing? Probably you can tell for the first one, but unlikely for the second
    (or your name is [Jaime Fernández del Río](http://stackoverflow.com/questions/7100242/python-numpy-first-occurrence-of-subarray)
    and you don't need to read this book).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you may have guessed, the second function is the vectorized-optimized-faster-numpy
    version of the first function. It is 10 times faster than the pure Python version,
    but it is hardly readable.
  prefs: []
  type: TYPE_NORMAL
- en: '[Anatomy of an array](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction](#id3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory layout](#memory-layout)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Views and copies](#views-and-copies)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Direct and indirect access](#direct-and-indirect-access)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Temporary copy](#temporary-copy)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#conclusion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained in the [Preface](#preface), you should have a basic experience
    with numpy to read this book. If this is not the case, you'd better start with
    a beginner tutorial before coming back here. Consequently I'll only give here
    a quick reminder on the basic anatomy of numpy arrays, especially regarding the
    memory layout, view, copy and the data type. They are critical notions to understand
    if you want your computation to benefit from numpy philosophy.
  prefs: []
  type: TYPE_NORMAL
- en: Let's consider a simple example where we want to clear all the values from an
    array which has the dtype `np.float32`. How does one write it to maximize speed?
    The below syntax is rather obvious (at least for those familiar with numpy) but
    the above question asks to find the fastest operation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you look more closely at both the dtype and the size of the array, you can
    observe that this array can be casted (i.e. viewed) into many other "compatible"
    data types. By compatible, I mean that `Z.size * Z.itemsize` can be divided by
    the new dtype itemsize.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly enough, the obvious way of clearing all the values is not the
    fastest. By casting the array into a larger data type such as `np.float64`, we
    gained a 25% speed factor. But, by viewing the array as a byte array (`np.int8`),
    we gained a 50% factor. The reason for such speedup are to be found in the internal
    numpy machinery and the compiler optimization. This simple example illustrates
    the philosophy of numpy as we'll see in the next section below.
  prefs: []
  type: TYPE_NORMAL
- en: '[Memory layout](#id2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The [numpy documentation](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)
    defines the ndarray class very clearly:'
  prefs: []
  type: TYPE_NORMAL
- en: '*An instance of class ndarray consists of a contiguous one-dimensional segment
    of computer memory (owned by the array, or by some other object), combined with
    an indexing scheme that maps N integers into the location of an item in the block.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Said differently, an array is mostly a contiguous block of memory whose parts
    can be accessed using an indexing scheme. Such indexing scheme is in turn defined
    by a [shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html#numpy.ndarray.shape)
    and a [data type](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)
    and this is precisely what is needed when you define a new array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we know that Z itemsize is 2 bytes (`int16`), the shape is (3,3) and the
    number of dimensions is 2 (`len(Z.shape)`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Furthermore and because Z is not a view, we can deduce the [strides](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.strides.html#numpy.ndarray.strides)
    of the array that define the number of bytes to step in each dimension when traversing
    the array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'With all these information, we know how to access a specific item (designed
    by an index tuple) and more precisely, how to compute the start and end offsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see if this is correct using the [tobytes](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tobytes.html)
    conversion method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This array can be actually considered from different perspectives (i.e. layouts):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Item layout**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Flattened item layout**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Memory layout (C order, big endian)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'If we now take a slice of `Z`, the result is a view of the base array `Z`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Such view is specified using a shape, a dtype **and** strides because strides
    cannot be deduced anymore from the dtype and shape only:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Item layout**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**Flattened item layout**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '**Memory layout (C order, big endian)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[Views and copies](#id2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Views and copies are important concepts for the optimization of your numerical
    computations. Even if we've already manipulated them in the previous section,
    the whole story is a bit more complex.
  prefs: []
  type: TYPE_NORMAL
- en: '[Direct and indirect access](#id2)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we have to distinguish between [indexing](https://docs.scipy.org/doc/numpy/user/basics.indexing.html#)
    and [fancy indexing](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#advanced-indexing).
    The first will always return a view while the second will return a copy. This
    difference is important because in the first case, modifying the view modifies
    the base array while this is not true in the second case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, if you need fancy indexing, it''s better to keep a copy of your fancy
    index (especially if it was complex to compute it) and to work with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are unsure if the result of your indexing is a view or a copy, you can
    check what is the `base` of your result. If it is `None`, then you result is a
    copy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that some numpy functions return a view when possible (e.g. [ravel](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html))
    while some others always return a copy (e.g. [flatten](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html#numpy.ndarray.flatten)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[Temporary copy](#id2)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Copies can be made explicitly like in the previous section, but the most general
    case is the implicit creation of intermediate copies. This is the case when you
    are doing some arithmetic with arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In the example above, three intermediate arrays have been created. One for
    holding the result of `2*X`, one for holding the result of `2*Y` and the last
    one for holding the result of `2*X+2*Y`. In this specific case, the arrays are
    small enough and this does not really make a difference. However, if your arrays
    are big, then you have to be careful with such expressions and wonder if you can
    do it differently. For example, if only the final result matters and you don''t
    need `X` nor `Y` afterwards, an alternate solution would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this alternate solution, no temporary array has been created. Problem
    is that there are many other cases where such copies needs to be created and this
    impact the performance like demonstrated on the example below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[Conclusion](#id2)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a conclusion, we'll make an exercise. Given two vectors `Z1` and `Z2`. We
    would like to know if `Z2` is a view of `Z1` and if yes, what is this view ?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: First, we need to check if `Z1` is the base of `Z2`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we know `Z2` is a view of `Z1`, meaning `Z2` can be expressed
    as `Z1[start:stop:step]`. The difficulty is to find `start`, `stop` and `step`.
    For the `step`, we can use the `strides` property of any array that gives the
    number of bytes to go from one element to the other in each dimension. In our
    case, and because both arrays are one-dimensional, we can directly compare the
    first stride only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Next difficulty is to find the `start` and the `stop` indices. To do this, we
    can take advantage of the `byte_bounds` method that returns a pointer to the end-points
    of an array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Converting these offsets into indices is straightforward using the `itemsize`
    and taking into account that the `offset_stop` is negative (end-bound of `Z2`
    is logically smaller than end-bound of `Z1` array). We thus need to add the items
    size of Z1 to get the right end index.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Last we test our results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'As an exercise, you can improve this first and very simple implementation by
    taking into account:'
  prefs: []
  type: TYPE_NORMAL
- en: Negative steps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-dimensional arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Solution](code/find_index.py) to the exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Code vectorization](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction](#id5)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Uniform vectorization](#uniform-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Game of Life](#the-game-of-life)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python implementation](#python-implementation)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy implementation](#numpy-implementation)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exercise](#exercise)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#sources)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#references)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Temporal vectorization](#temporal-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python implementation](#id6)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id7)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Faster numpy implementation](#faster-numpy-implementation)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Visualization](#visualization)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exercise](#id8)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id9)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id10)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Spatial vectorization](#spatial-vectorization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Boids](#boids)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python implementation](#id12)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id13)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exercise](#id14)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id15)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id16)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id17)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Code vectorization means that the problem you''re trying to solve is inherently
    vectorizable and only requires a few numpy tricks to make it faster. Of course
    it does not mean it is easy or straightforward, but at least it does not necessitate
    totally rethinking your problem (as it will be the case in the [Problem vectorization](#problem-vectorization)
    chapter). Still, it may require some experience to see where code can be vectorized.
    Let''s illustrate this through a simple example where we want to sum up two lists
    of integers. One simple way using pure Python is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This first naive solution can be vectorized very easily using numpy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Without any surprise, benchmarking the two approaches shows the second method
    is the fastest with one order of magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Not only is the second approach faster, but it also naturally adapts to the
    shape of `Z1` and `Z2`. This is the reason why we did not write `Z1 + Z2` because
    it would not work if `Z1` and `Z2` were both lists. In the first Python method,
    the inner `+` is interpreted differently depending on the nature of the two objects
    such that if we consider two nested lists, we get the following outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The first method concatenates the two lists together, the second method concatenates
    the internal lists together and the last one computes what is (numerically) expected.
    As an exercise, you can rewrite the Python version such that it accepts nested
    lists of any depth.
  prefs: []
  type: TYPE_NORMAL
- en: '[Uniform vectorization](#id4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Uniform vectorization is the simplest form of vectorization where all the elements
    share the same computation at every time step with no specific processing for
    any element. One stereotypical case is the Game of Life that has been invented
    by John Conway (see below) and is one of the earliest examples of cellular automata.
    Those cellular automata can be conveniently regarded as an array of cells that
    are connected together with the notion of neighbours and their vectorization is
    straightforward. Let me first define the game and we'll see how to vectorize it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Conus textile snail exhibits a cellular automaton pattern on its shell. Image
    by [Richard Ling](https://commons.wikimedia.org/wiki/File:Textile_cone.JPG), 2005.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/c091c3d73318960a6f67f0411911ec50.png](img/c091c3d73318960a6f67f0411911ec50.png)'
  prefs: []
  type: TYPE_IMG
- en: '[The Game of Life](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Excerpt from the Wikipedia entry on the [Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life)
  prefs: []
  type: TYPE_NORMAL
- en: The Game of Life is a cellular automaton devised by the British mathematician
    John Horton Conway in 1970\. It is the best-known example of a cellular automaton.
    The "game" is actually a zero-player game, meaning that its evolution is determined
    by its initial state, needing no input from human players. One interacts with
    the Game of Life by creating an initial configuration and observing how it evolves.
  prefs: []
  type: TYPE_NORMAL
- en: 'The universe of the Game of Life is an infinite two-dimensional orthogonal
    grid of square cells, each of which is in one of two possible states, live or
    dead. Every cell interacts with its eight neighbours, which are the cells that
    are directly horizontally, vertically, or diagonally adjacent. At each step in
    time, the following transitions occur:'
  prefs: []
  type: TYPE_NORMAL
- en: Any live cell with fewer than two live neighbours dies, as if by needs caused
    by underpopulation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any live cell with more than three live neighbours dies, as if by overcrowding.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any live cell with two or three live neighbours lives, unchanged, to the next
    generation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any dead cell with exactly three live neighbours becomes a live cell.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The initial pattern constitutes the 'seed' of the system. The first generation
    is created by applying the above rules simultaneously to every cell in the seed
    – births and deaths happen simultaneously, and the discrete moment at which this
    happens is sometimes called a tick. (In other words, each generation is a pure
    function of the one before.) The rules continue to be applied repeatedly to create
    further generations.
  prefs: []
  type: TYPE_NORMAL
- en: '[Python implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We could have used the more efficient python [array interface](http://docs.python.org/3/library/array.html)
    but it is more convenient to use the familiar list object.
  prefs: []
  type: TYPE_NORMAL
- en: In pure Python, we can code the Game of Life using a list of lists representing
    the board where cells are supposed to evolve. Such a board will be equipped with
    border of 0 that allows to accelerate things a bit by avoiding having specific
    tests for borders when counting the number of neighbours.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Taking the border into account, counting neighbours then is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'To iterate one step in time, we then simply count the number of neighbours
    for each internal cell and we update the whole board according to the four aforementioned
    rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The figure below shows four iterations on a 4x4 area where the initial state
    is a [glider](https://en.wikipedia.org/wiki/Glider_(Conway%27s_Life)), a structure
    discovered by Richard K. Guy in 1970.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.2**'
  prefs: []
  type: TYPE_NORMAL
- en: The glider pattern is known to replicate itself one step diagonally in 4 iterations.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/d3d45b9f3ee5417c34c6fd84b90f9af4.png](img/d3d45b9f3ee5417c34c6fd84b90f9af4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Numpy implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Starting from the Python version, the vectorization of the Game of Life requires
    two parts, one responsible for counting the neighbours and one responsible for
    enforcing the rules. Neighbour-counting is relatively easy if we remember we took
    care of adding a null border around the arena. By considering partial views of
    the arena we can actually access neighbours quite intuitively as illustrated below
    for the one-dimensional case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Going to the two dimensional case requires just a bit of arithmetic to make
    sure to consider all the eight neighbours.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: For the rule enforcement, we can write a first version using numpy's [argwhere](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html)
    method that will give us the indices where a given condition is True.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Even if this first version does not use nested loops, it is far from optimal
    because of the use of the four `argwhere` calls that may be quite slow. We can
    instead factorize the rules into cells that will survive (stay at 1) and cells
    that will give birth. For doing this, we can take advantage of Numpy boolean capability
    and write quite naturally:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We did no write `Z = 0` as this would simply assign the value 0 to `Z` that
    would then become a simple scalar.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: If you look at the `birth` and `survive` lines, you'll see that these two variables
    are arrays that can be used to set `Z` values to 1 after having cleared it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.3**'
  prefs: []
  type: TYPE_NORMAL
- en: The Game of Life. Gray levels indicate how much a cell has been active in the
    past.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/game-of-life.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: '[Exercise](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Reaction and diffusion of chemical species can produce a variety of patterns,
    reminiscent of those often seen in nature. The Gray-Scott equations model such
    a reaction. For more information on this chemical system see the article *Complex
    Patterns in a Simple System* (John E. Pearson, Science, Volume 261, 1993). Let''s
    consider two chemical species *U* and *V* with respective concentrations *u* and
    *v* and diffusion rates *Du* and *Dv*. *V* is converted into *P* with a rate of
    conversion *k*. *f* represents the rate of the process that feeds *U* and drains
    *U*, *V* and *P*. This can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Chemical reaction | Equations |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *U* + 2*V* → 3*V* | *u̇* = *Du*∇²*u* − *uv*² + *f*(1 − *u*) |'
  prefs: []
  type: TYPE_TB
- en: '| *V* → *P* | *v̇* = *Dv*∇²*v* + *uv*² − (*f* + *k*)*v* |'
  prefs: []
  type: TYPE_TB
- en: 'Based on the Game of Life example, try to implement such reaction-diffusion
    system. Here is a set of interesting parameters to test:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Du | Dv | f | k |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Bacteria 1 | 0.16 | 0.08 | 0.035 | 0.065 |'
  prefs: []
  type: TYPE_TB
- en: '| Bacteria 2 | 0.14 | 0.06 | 0.035 | 0.065 |'
  prefs: []
  type: TYPE_TB
- en: '| Coral | 0.16 | 0.08 | 0.060 | 0.062 |'
  prefs: []
  type: TYPE_TB
- en: '| Fingerprint | 0.19 | 0.05 | 0.060 | 0.062 |'
  prefs: []
  type: TYPE_TB
- en: '| Spirals | 0.10 | 0.10 | 0.018 | 0.050 |'
  prefs: []
  type: TYPE_TB
- en: '| Spirals Dense | 0.12 | 0.08 | 0.020 | 0.050 |'
  prefs: []
  type: TYPE_TB
- en: '| Spirals Fast | 0.10 | 0.16 | 0.020 | 0.050 |'
  prefs: []
  type: TYPE_TB
- en: '| Unstable | 0.16 | 0.08 | 0.020 | 0.055 |'
  prefs: []
  type: TYPE_TB
- en: '| Worms 1 | 0.16 | 0.08 | 0.050 | 0.065 |'
  prefs: []
  type: TYPE_TB
- en: '| Worms 2 | 0.16 | 0.08 | 0.054 | 0.063 |'
  prefs: []
  type: TYPE_TB
- en: '| Zebrafish | 0.16 | 0.08 | 0.035 | 0.060 |'
  prefs: []
  type: TYPE_TB
- en: The figure below shows some animations of the model for a specific set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.4**'
  prefs: []
  type: TYPE_NORMAL
- en: Reaction-diffusion Gray-Scott model. From left to right, *Bacteria 1*, *Coral*
    and *Spiral Dense*.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/gray-scott-1.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/gray-scott-2.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/gray-scott-3.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: '[Sources](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[game_of_life_python.py](code/game_of_life_python.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[game_of_life_numpy.py](code/game_of_life_numpy.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[gray_scott.py](code/gray_scott.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[John Conway new solitaire game "life"](https://web.archive.org/web/20090603015231/http://ddi.cs.uni-potsdam.de/HyFISCH/Produzieren/lis_projekt/proj_gamelife/ConwayScientificAmerican.htm),
    Martin Gardner, Scientific American 223, 1970.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gray Scott Model of Reaction Diffusion](http://groups.csail.mit.edu/mac/projects/amorphous/GrayScott/),
    Abelson, Adams, Coore, Hanson, Nagpal, Sussman, 1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reaction-Diffusion by the Gray-Scott Model](http://mrob.com/pub/comp/xmorphia/),
    Robert P. Munafo, 1996.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Temporal vectorization](#id4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Mandelbrot set is the set of complex numbers *c* for which the function
    *f*[*c*](*z*) = *z*² + *c* does not diverge when iterated from *z* = 0, i.e.,
    for which the sequence *f*[*c*](0), *f*[*c*](*f*[*c*](0)), etc., remains bounded
    in absolute value. It is very easy to compute, but it can take a very long time
    because you need to ensure a given number does not diverge. This is generally
    done by iterating the computation up to a maximum number of iterations, after
    which, if the number is still within some bounds, it is considered non-divergent.
    Of course, the more iterations you do, the more precision you get.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.5**'
  prefs: []
  type: TYPE_NORMAL
- en: Romanesco broccoli, showing self-similar form approximating a natural fractal.
    Image by [Jon Sullivan](https://commons.wikimedia.org/wiki/File:Fractal_Broccoli.jpg),
    2004.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/c00398a6e63dcdcf8495aa58e80c0f72.png](img/c00398a6e63dcdcf8495aa58e80c0f72.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Python implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A pure python implementation is written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The interesting (and slow) part of this code is the `mandelbrot` function that
    actually computes the sequence *f*[*c*](*f*[*c*](*f*[*c*]...))). The vectorization
    of such code is not totally straightforward because the internal `return` implies
    a differential processing of the element. Once it has diverged, we don't need
    to iterate any more and we can safely return the iteration count at divergence.
    The problem is to then do the same in numpy. But how?
  prefs: []
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The trick is to search at each iteration values that have not yet diverged and
    update relevant information for these values and only these values. Because we
    start from *Z* = 0, we know that each value will be updated at least once (when
    they're equal to 0, they have not yet diverged) and will stop being updated as
    soon as they've diverged. To do that, we'll use numpy fancy indexing with the
    `less(x1,x2)` function that return the truth value of `(x1 < x2)` element-wise.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[Faster numpy implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The gain is roughly a 5x factor, not as much as we could have expected. Part
    of the problem is that the `np.less` function implies *xn* × *yn* tests at every
    iteration while we know that some values have already diverged. Even if these
    tests are performed at the C level (through numpy), the cost is nonetheless significant.
    Another approach proposed by [Dan Goodman](https://thesamovar.wordpress.com/)
    is to work on a dynamic array at each iteration that stores only the points which
    have not yet diverged. It requires more lines but the result is faster and leads
    to a 10x factor speed improvement compared to the Python version.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The benchmark gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[Visualization](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to visualize our results, we could directly display the `N` array using
    the matplotlib `imshow` command, but this would result in a "banded" image that
    is a known consequence of the escape count algorithm that we've been using. Such
    banding can be eliminated by using a fractional escape count. This can be done
    by measuring how far the iterated point landed outside of the escape cutoff. See
    the reference below about the renormalization of the escape count. Here is a picture
    of the result where we use recount normalization, and added a power normalized
    color map (gamma=0.3) as well as light shading.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.6**'
  prefs: []
  type: TYPE_NORMAL
- en: The Mandelbrot as rendered by matplotlib using recount normalization, power
    normalized color map (gamma=0.3) and light shading.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/9ea19f540f154a1bc6fcf2fa7a4ba552.png](img/9ea19f540f154a1bc6fcf2fa7a4ba552.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Exercise](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You should look at the [ufunc.reduceat](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.reduceat.html)
    method that performs a (local) reduce with specified slices over a single axis.
  prefs: []
  type: TYPE_NORMAL
- en: We now want to measure the fractal dimension of the Mandelbrot set using the
    [Minkowski–Bouligand dimension](https://en.wikipedia.org/wiki/Minkowski–Bouligand_dimension).
    To do that, we need to do box-counting with a decreasing box size (see figure
    below). As you can imagine, we cannot use pure Python because it would be way
    too slow. The goal of the exercise is to write a function using numpy that takes
    a two-dimensional float array and returns the dimension. We'll consider values
    in the array to be normalized (i.e. all values are between 0 and 1).
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.7**'
  prefs: []
  type: TYPE_NORMAL
- en: The Minkowski–Bouligand dimension of the Great Britain coastlines is approximately
    1.24.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/3790c715b411fa4b5650d93efabbaf3d.png](img/3790c715b411fa4b5650d93efabbaf3d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Sources](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[mandelbrot.py](code/mandelbrot.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[mandelbrot_python.py](code/mandelbrot_python.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[mandelbrot_numpy_1.py](code/mandelbrot_numpy_1.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[mandelbrot_numpy_2.py](code/mandelbrot_numpy_2.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[fractal_dimension.py](code/fractal_dimension.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How To Quickly Compute the Mandelbrot Set in Python](https://www.ibm.com/developerworks/community/blogs/jfp/entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en),
    Jean Francois Puget, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[My Christmas Gift: Mandelbrot Set Computation In Python](https://www.ibm.com/developerworks/community/blogs/jfp/entry/My_Christmas_Gift?lang=en),
    Jean Francois Puget, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fast fractals with Python and Numpy](https://thesamovar.wordpress.com/2009/03/22/fast-fractals-with-python-and-numpy/),
    Dan Goodman, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Renormalizing the Mandelbrot Escape](http://linas.org/art-gallery/escape/escape.html),
    Linas Vepstas, 1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Spatial vectorization](#id4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spatial vectorization refers to a situation where elements share the same computation
    but are in interaction with only a subgroup of other elements. This was already
    the case for the game of life example, but in some situations there is an added
    difficulty because the subgroup is dynamic and needs to be updated at each iteration.
    This the case, for example, in particle systems where particles interact mostly
    with local neighbours. This is also the case for "boids" that simulate flocking
    behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.8**'
  prefs: []
  type: TYPE_NORMAL
- en: Flocking birds are an example of self-organization in biology. Image by [Christoffer
    A Rasmussen](https://commons.wikimedia.org/wiki/File:Fugle,_ørnsø_073.jpg), 2012.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/7b37fde927b910d7cbe8fb3dcbf545d4.png](img/7b37fde927b910d7cbe8fb3dcbf545d4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Boids](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Excerpt from the Wikipedia entry [Boids](https://en.wikipedia.org/wiki/Boids)
  prefs: []
  type: TYPE_NORMAL
- en: Boids is an artificial life program, developed by Craig Reynolds in 1986, which
    simulates the flocking behaviour of birds. The name "boid" corresponds to a shortened
    version of "bird-oid object", which refers to a bird-like object.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with most artificial life simulations, Boids is an example of emergent behavior;
    that is, the complexity of Boids arises from the interaction of individual agents
    (the boids, in this case) adhering to a set of simple rules. The rules applied
    in the simplest Boids world are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**separation**: steer to avoid crowding local flock-mates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**alignment**: steer towards the average heading of local flock-mates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cohesion**: steer to move toward the average position (center of mass) of
    local flock-mates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Figure 4.9**'
  prefs: []
  type: TYPE_NORMAL
- en: Boids are governed by a set of three local rules (separation, cohesion and alignment)
    that serve as computing velocity and acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/c8b3883aeb2fb8322a4b531ca31ccaed.png](img/c8b3883aeb2fb8322a4b531ca31ccaed.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Python implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since each boid is an autonomous entity with several properties such as position
    and velocity, it seems natural to start by writing a Boid class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `vec2` object is a very simple class that handles all common vector operations
    with 2 components. It will save us some writing in the main `Boid` class. Note
    that there are some vector packages in the Python Package Index, but that would
    be overkill for such a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Boid is a difficult case for regular Python because a boid has interaction
    with local neighbours. However, and because boids are moving, to find such local
    neighbours requires computing at each time step the distance to each and every
    other boid in order to sort those which are in a given interaction radius. The
    prototypical way of writing the three rules is thus something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Full sources are given in the references section below, it would be too long
    to describe it here and there is no real difficulty.
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete the picture, we can also create a `Flock` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Using this approach, we can have up to 50 boids until the computation time becomes
    too slow for a smooth animation. As you may have guessed, we can do much better
    using numpy, but let me first point out the main problem with this Python implementation.
    If you look at the code, you will certainly notice there is a lot of redundancy.
    More precisely, we do not exploit the fact that the Euclidean distance is reflexive,
    that is, |*x* − *y*| = |*y* − *x*|. In this naive Python implementation, each
    rule (function) computes *n*² distances while (*n*²)/(2) would be sufficient if
    properly cached. Furthermore, each rule re-computes every distance without caching
    the result for the other functions. In the end, we are computing 3*n*² distances
    instead of (*n*²)/(2).
  prefs: []
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you might expect, the numpy implementation takes a different approach and
    we''ll gather all our boids into a `position` array and a `velocity` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step is to compute the local neighborhood for all boids, and for
    this we need to compute all paired distances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: We could have used the scipy [cdist](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html)
    but we'll need the `dx` and `dy` arrays later. Once those have been computed,
    it is faster to use the [hypot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.hypot.html)
    method. Note that distance shape is `(n, n)` and each line relates to one boid,
    i.e. each line gives the distance to all other boids (including self).
  prefs: []
  type: TYPE_NORMAL
- en: From theses distances, we can now compute the local neighborhood for each of
    the three rules, taking advantage of the fact that we can mix them together. We
    can actually compute a mask for distances that are strictly positive (i.e. have
    no self-interaction) and multiply it with other distance masks.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If we suppose that boids cannot occupy the same position, how can you compute
    `mask_0` more efficiently?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Then, we compute the number of neighbours within the given radius and we ensure
    it is at least 1 to avoid division by zero.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re ready to write our three rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Alignment**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '**Cohesion**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '**Separation**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'All three resulting steerings (separation, alignment & cohesion) need to be
    limited in magnitude. We leave this as an exercise for the reader. Combination
    of these rules is straightforward as well as the resulting update of velocity
    and position:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: We finally visualize the result using a custom oriented scatter plot.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 4.10**'
  prefs: []
  type: TYPE_NORMAL
- en: Boids is an artificial life program, developed by Craig Reynolds in 1986, which
    simulates the flocking behaviour of birds.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/boids.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: '[Exercise](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are now ready to visualize our boids. The easiest way is to use the matplotlib
    animation function and a scatter plot. Unfortunately, scatters cannot be individually
    oriented and we need to make our own objects using a matplotlib `PathCollection`.
    A simple triangle path can be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: This path can be repeated several times inside an array and each triangle can
    be made independent.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: We now have a `(n,4,2)` array for vertices and a `(n,4)` array for codes representing
    `n` boids. We are interested in manipulating the vertices array to reflect the
    translation, scaling and rotation of each of the `n` boids.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Rotate is really tricky.
  prefs: []
  type: TYPE_NORMAL
- en: How would you write the `translate`, `scale` and `rotate` functions ?
  prefs: []
  type: TYPE_NORMAL
- en: '[Sources](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[boid_python.py](code/boid_python.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[boid_numpy.py](code/boid_numpy.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id4)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Flocking](https://processing.org/examples/flocking.html), Daniel Shiffman,
    2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Flocks, herds and schools: A distributed behavioral model](http://www.red3d.com/cwr/boids/),
    Craig Reynolds, SIGGRAPH, 1987'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id4)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ve seen through these examples three forms of code vectorization:'
  prefs: []
  type: TYPE_NORMAL
- en: Uniform vectorization where elements share the same computation unconditionally
    and for the same duration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Temporal vectorization where elements share the same computation but necessitate
    a different number of iterations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spatial vectorization where elements share the same computation but on dynamic
    spatial arguments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And there are probably many more forms of such direct code vectorization. As
    explained before, this kind of vectorization is one of the most simple even though
    we've seen it can be really tricky to implement and requires some experience,
    some help or both. For example, the solution to the boids exercise was provided
    by [Divakar](http://stackoverflow.com/users/3293881/divakar) on [stack overflow](http://stackoverflow.com/questions/40822983/multiple-individual-2d-rotation-at-once)
    after having explained my problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[Problem vectorization](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction](#id19)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Path finding](#path-finding)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a maze](#building-a-maze)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Breadth-first](#breadth-first)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bellman-Ford method](#bellman-ford-method)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id20)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id21)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fluid Dynamics](#fluid-dynamics)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lagrangian vs Eulerian method](#lagrangian-vs-eulerian-method)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id22)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id23)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id24)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blue noise sampling](#blue-noise-sampling)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DART method](#dart-method)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bridson method](#bridson-method)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id25)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id26)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id27)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id18)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Problem vectorization is much harder than code vectorization because it means
    that you fundamentally have to rethink your problem in order to make it vectorizable.
    Most of the time this means you have to use a different algorithm to solve your
    problem or even worse... to invent a new one. The difficulty is thus to think
    out-of-the-box.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this, let''s consider a simple problem where given two vectors
    `X` and `Y`, we want to compute the sum of `X[i]*Y[j]` for all pairs of indices
    `i`, `j`. One simple and obvious solution is to write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'However, this first and naïve implementation requires two loops and we already
    know it will be slow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'How to vectorize the problem then? If you remember your linear algebra course,
    you may have identified the expression `X[i] * Y[j]` to be very similar to a matrix
    product expression. So maybe we could benefit from some numpy speedup. One wrong
    solution would be to write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'This is wrong because the `X*Y` expression will actually compute a new vector
    `Z` such that `Z[i] = X[i] * Y[i]` and this is not what we want. Instead, we can
    exploit numpy broadcasting by first reshaping the two vectors and then multiply
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we have `Z[i,j] == X[i,0]*Y[0,j]` and if we take the sum over each elements
    of `Z`, we get the expected result. Let''s see how much speedup we gain in the
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: This is better, we gained a factor of ~150\. But we can do much better.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look again and more closely at the pure Python version, you can see
    that the inner loop is using `X[i]` that does not depend on the `j` index, meaning
    it can be removed from the inner loop. Code can be rewritten as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'But since the inner loop does not depend on the `i` index, we might as well
    compute it only once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Not so bad, we have removed the inner loop, meaning with transform a *O*(*n*²)
    complexity into *O*(*n*) complexity. Using the same approach, we can now write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, having realized we only need the product of the sum over `X` and `Y`
    respectively, we can benefit from the `np.sum` function and write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'It is shorter, clearer and much, much faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'We have indeed reformulated our problem, taking advantage of the fact that
    ∑[*ij*]*X*[*i*]*Y*[*j*] = ∑[*i*]*X*[*i*]∑[*j*]*Y*[*j*] and we''ve learned in the
    meantime that there are two kinds of vectorization: code vectorization and problem
    vectorization. The latter is the most difficult but the most important because
    this is where you can expect huge gains in speed. In this simple example, we gain
    a factor of 150 with code vectorization but we gained a factor of 70,000 with
    problem vectorization, just by writing our problem differently (even though you
    cannot expect such a huge speedup in all situations). However, code vectorization
    remains an important factor, and if we rewrite the last solution the Python way,
    the improvement is good but not as much as in the numpy version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'This new Python version is much faster than the previous Python version, but
    still, it is 50 times slower than the numpy version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[Path finding](#id18)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Path finding is all about finding the shortest path in a graph. This can be
    split in two distinct problems: to find a path between two nodes in a graph and
    to find the shortest path. We''ll illustrate this through path finding in a maze.
    The first task is thus to build a maze.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.1**'
  prefs: []
  type: TYPE_NORMAL
- en: A hedge maze at Longleat stately home in England. Image by [Prince Rurik](https://commons.wikimedia.org/wiki/File:Longleat_maze.jpg),
    2005.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/760876f935b5a4bdc2877549c1cabec9.png](img/760876f935b5a4bdc2877549c1cabec9.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Building a maze](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There exist [many maze generation algorithms](https://en.wikipedia.org/wiki/Maze_generation_algorithm)
    but I tend to prefer the one I've been using for several years but whose origin
    is unknown to me. I've added the code in the cited wikipedia entry. Feel free
    to complete it if you know the original author. This algorithm works by creating
    `n` (density) islands of length `p` (complexity). An island is created by choosing
    a random starting point with odd coordinates, then a random direction is chosen.
    If the cell two steps in a given direction is free, then a wall is added at both
    one step and two steps in this direction. The process is iterated for `n` steps
    for this island. `p` islands are created. `n` and `p` are expressed as `float`
    to adapt them to the size of the maze. With a low complexity, islands are very
    small and the maze is easy to solve. With low density, the maze has more "big
    empty rooms".
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Here is an animation showing the generation process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Progressive maze building with complexity and density control.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/maze-build.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: '[Breadth-first](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The breadth-first (as well as depth-first) search algorithm addresses the problem
    of finding a path between two nodes by examining all possibilities starting from
    the root node and stopping as soon as a solution has been found (destination node
    has been reached). This algorithm runs in linear time with complexity in *O*(|*V*| + |*E*|)
    (where *V* is the number of vertices, and *E* is the number of edges). Writing
    such an algorithm is not especially difficult, provided you have the right data
    structure. In our case, the array representation of the maze is not the most well-suited
    and we need to transform it into an actual graph as proposed by [Valentin Bryukhanov](http://bryukh.com).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If we had used the depth-first algorithm, there is no guarantee to find the
    shortest path, only to find a path (if it exists).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once this is done, writing the breadth-first algorithm is straightforward.
    We start from the starting node and we visit nodes at the current depth only (breadth-first,
    remember?) and we iterate the process until reaching the final node, if possible.
    The question is then: do we get the shortest path exploring the graph this way?
    In this specific case, "yes", because we don''t have an edge-weighted graph, i.e.
    all the edges have the same weight (or cost).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[Bellman-Ford method](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bellman–Ford algorithm is an algorithm that is able to find the optimal
    path in a graph using a diffusion process. The optimal path is found by ascending
    the resulting gradient. This algorithm runs in quadratic time *O*(|*V*||*E*|)
    (where *V* is the number of vertices, and *E* is the number of edges). However,
    in our simple case, we won't hit the worst case scenario. The algorithm is illustrated
    below (reading from left to right, top to bottom). Once this is done, we can ascend
    the gradient from the starting node. You can check on the figure that this leads
    to the shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.3**'
  prefs: []
  type: TYPE_NORMAL
- en: Value iteration algorithm on a simple maze. Once entrance has been reached,
    it is easy to find the shortest path by ascending the value gradient.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/23273028ed7c308c5053f969e41f7471.png](img/23273028ed7c308c5053f969e41f7471.png)
    ![img/0bd752138eda95a4a062032e9ef4100e.png](img/0bd752138eda95a4a062032e9ef4100e.png)
    ![img/e33abc8e918425a64e9453cf0a651e41.png](img/e33abc8e918425a64e9453cf0a651e41.png)
    ![img/89b5382abc5d8c757df5ae510473f636.png](img/89b5382abc5d8c757df5ae510473f636.png)
    ![img/28a4fc5dbe7ab7c7cd41be569274fec7.png](img/28a4fc5dbe7ab7c7cd41be569274fec7.png)
    ![img/c980df26414ea32c86e51335a027d6b9.png](img/c980df26414ea32c86e51335a027d6b9.png)
    ![img/37b7fa5200493002586ba83473dfa57f.png](img/37b7fa5200493002586ba83473dfa57f.png)
    ![img/2cd153d230f00b7cdb9e8c87ee555fad.png](img/2cd153d230f00b7cdb9e8c87ee555fad.png)
    ![img/0970a7d64f8fce9622ca4d1bf1fb440d.png](img/0970a7d64f8fce9622ca4d1bf1fb440d.png)
    ![img/a731b6cc95670022e66d5585c8d7e130.png](img/a731b6cc95670022e66d5585c8d7e130.png)'
  prefs: []
  type: TYPE_IMG
- en: We start by setting the exit node to the value 1, while every other node is
    set to 0, except the walls. Then we iterate a process such that each cell's new
    value is computed as the maximum value between the current cell value and the
    discounted (`gamma=0.9` in the case below) 4 neighbour values. The process starts
    as soon as the starting node value becomes strictly positive.
  prefs: []
  type: TYPE_NORMAL
- en: 'The numpy implementation is straightforward if we take advantage of the `generic_filter`
    (from `scipy.ndimage`) for the diffusion process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'But in this specific case, it is rather slow. We''d better cook-up our own
    solution, reusing part of the game of life code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is done, we can ascend the gradient to find the shortest path as
    illustrated on the figure below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.4**'
  prefs: []
  type: TYPE_NORMAL
- en: Path finding using the Bellman-Ford algorithm. Gradient colors indicate propagated
    values from the end-point of the maze (bottom-right). Path is found by ascending
    gradient from the goal.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/d808f0dc7c41b6768554a47834b568e9.png](img/d808f0dc7c41b6768554a47834b568e9.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Sources](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[maze_build.py](code/maze_build.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[maze_numpy.py](code/maze_numpy.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Labyrinth Algorithms](http://bryukh.com/labyrinth-algorithms/), Valentin Bryukhanov,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fluid Dynamics](#id18)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Figure 5.5**'
  prefs: []
  type: TYPE_NORMAL
- en: Hydrodynamic flow at two different zoom levels, Neckar river, Heidelberg, Germany.
    Image by [Steven Mathey](https://commons.wikimedia.org/wiki/File:Self_Similar_Turbulence.png),
    2012.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/89e537df1608439e1d4339ff3bad9a78.png](img/89e537df1608439e1d4339ff3bad9a78.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Lagrangian vs Eulerian method](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Excerpt from the Wikipedia entry on the [Lagrangian and Eulerian specification](https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field)
  prefs: []
  type: TYPE_NORMAL
- en: In classical field theory, the Lagrangian specification of the field is a way
    of looking at fluid motion where the observer follows an individual fluid parcel
    as it moves through space and time. Plotting the position of an individual parcel
    through time gives the pathline of the parcel. This can be visualized as sitting
    in a boat and drifting down a river.
  prefs: []
  type: TYPE_NORMAL
- en: The Eulerian specification of the flow field is a way of looking at fluid motion
    that focuses on specific locations in the space through which the fluid flows
    as time passes. This can be visualized by sitting on the bank of a river and watching
    the water pass the fixed location.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, in the Eulerian case, you divide a portion of space into cells
    and each cell contains a velocity vector and other information, such as density
    and temperature. In the Lagrangian case, we need particle-based physics with dynamic
    interactions and generally we need a high number of particles. Both methods have
    advantages and disadvantages and the choice between the two methods depends on
    the nature of your problem. Of course, you can also mix the two methods into a
    hybrid method.
  prefs: []
  type: TYPE_NORMAL
- en: However, the biggest problem for particle-based simulation is that particle
    interaction requires finding neighbouring particles and this has a cost as we've
    seen in the boids case. If we target Python and numpy only, it is probably better
    to choose the Eulerian method since vectorization will be almost trivial compared
    to the Lagrangian method.
  prefs: []
  type: TYPE_NORMAL
- en: '[Numpy implementation](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I won't explain all the theory behind computational fluid dynamics because first,
    I cannot (I'm not an expert at all in this domain) and there are many resources
    online that explain this nicely (have a look at references below, especially tutorial
    by L. Barba). Why choose a computational fluid as an example then? Because results
    are (almost) always beautiful and fascinating. I couldn't resist (look at the
    movie below).
  prefs: []
  type: TYPE_NORMAL
- en: We'll further simplify the problem by implementing a method from computer graphics
    where the goal is not correctness but convincing behavior. Jos Stam wrote a very
    nice article for SIGGRAPH 1999 describing a technique to have stable fluids over
    time (i.e. whose solution in the long term does not diverge). [Alberto Santini](https://github.com/albertosantini/python-fluid)
    wrote a Python replication a long time ago (using numarray!) such that I only
    had to adapt it to modern numpy and accelerate it a bit using modern numpy tricks.
  prefs: []
  type: TYPE_NORMAL
- en: I won't comment the code since it would be too long, but you can read the original
    paper as well as the explanation by [Philip Rideout](http://prideout.net/blog/?p=58)
    on his blog. Below are some movies I've made using this technique.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.6**'
  prefs: []
  type: TYPE_NORMAL
- en: Smoke simulation using the stable fluids algorithm by Jos Stam. Right most video
    comes from the [glumpy](http://glumpy.github.io) package and is using the GPU
    (framebuffer operations, i.e. no OpenCL nor CUDA) for faster computations.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/smoke-1.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/smoke-2.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: <https://www.labri.fr/perso/nrougier/from-python-to-numpy/data/smoke-gpu.mp4>
  prefs: []
  type: TYPE_NORMAL
- en: Your browser does not support the video tag.
  prefs: []
  type: TYPE_NORMAL
- en: '[Sources](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[smoke_1.py](code/smoke_1.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[smoke_2.py](code/smoke_2.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[smoke_solver.py](code/smoke_solver.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[smoke_interactive.py](code/smoke_interactive.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[12 Steps to Navier-Stokes](https://github.com/barbagroup/CFDPython), Lorena
    Barba, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stable Fluids](http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/ns.pdf),
    Jos Stam, 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple Fluid Simulation](http://prideout.net/blog/?p=58), Philip Rideout,
    2010'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fast Fluid Dynamics Simulation on the GPU](http://http.developer.nvidia.com/GPUGems/gpugems_ch38.html),
    Mark Harris, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Animating Sand as a Fluid](https://www.cs.ubc.ca/%7Erbridson/docs/zhu-siggraph05-sandfluid.pdf),
    Yongning Zhu & Robert Bridson, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Blue noise sampling](#id18)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Blue noise refers to sample sets that have random and yet uniform distributions
    with absence of any spectral bias. Such noise is very useful in a variety of graphics
    applications like rendering, dithering, stippling, etc. Many different methods
    have been proposed to achieve such noise, but the most simple is certainly the
    DART method.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.7**'
  prefs: []
  type: TYPE_NORMAL
- en: Detail of "The Starry Night", Vincent van Gogh, 1889\. The detail has been resampled
    using voronoi cells whose centers are a blue noise sample.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/b5243aadd074137f551ae1b47c8d5cc0.png](img/b5243aadd074137f551ae1b47c8d5cc0.png)'
  prefs: []
  type: TYPE_IMG
- en: '[DART method](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The DART method is one of the earliest and simplest methods. It works by sequentially
    drawing uniform random points and only accepting those that lie at a minimum distance
    from every previous accepted sample. This sequential method is therefore extremely
    slow because each new candidate needs to be tested against previous accepted candidates.
    The more points you accept, the slower the method is. Let's consider the unit
    surface and a minimum radius `r` to be enforced between each point.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing that the densest packing of circles in the plane is the hexagonal lattice
    of the bee's honeycomb, we know this density is *d* = (1)/(6)*π*√(3) (in fact
    [I learned it](https://en.wikipedia.org/wiki/Circle_packing) while writing this
    book). Considering circles with radius *r*, we can pack at most (*d*)/(*π**r*²) = (√(3))/(6*r*²) = (1)/(2*r*²√(3)).
    We know the theoretical upper limit for the number of discs we can pack onto the
    surface, but we'll likely not reach this upper limit because of random placements.
    Furthermore, because a lot of points will be rejected after a few have been accepted,
    we need to set a limit on the number of successive failed trials before we stop
    the whole process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: I left as an exercise the vectorization of the DART method. The idea is to pre-compute
    enough uniform random samples as well as paired distances and to test for their
    sequential inclusion.
  prefs: []
  type: TYPE_NORMAL
- en: '[Bridson method](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If the vectorization of the previous method poses no real difficulty, the speed
    improvement is not so good and the quality remains low and dependent on the `k`
    parameter. The higher, the better since it basically governs how hard to try to
    insert a new sample. But, when there is already a large number of accepted samples,
    only chance allows us to find a position to insert a new sample. We could increase
    the `k` value but this would make the method even slower without any guarantee
    in quality. It''s time to think out-of-the-box and luckily enough, Robert Bridson
    did that for us and proposed a simple yet efficient method:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 0**. Initialize an n-dimensional background grid for storing samples
    and accelerating spatial searches. We pick the cell size to be bounded by (*r*)/(√(*n*)),
    so that each grid cell will contain at most one sample, and thus the grid can
    be implemented as a simple n-dimensional array of integers: the default −1 indicates
    no sample, a non-negative integer gives the index of the sample located in a cell.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Step 1**. Select the initial sample, *x*[0], randomly chosen uniformly from
    the domain. Insert it into the background grid, and initialize the “active list”
    (an array of sample indices) with this index (zero).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Step 2**. While the active list is not empty, choose a random index from
    it (say *i*). Generate up to *k* points chosen uniformly from the spherical annulus
    between radius *r* and 2*r* around *x*[*i*]. For each point in turn, check if
    it is within distance *r* of existing samples (using the background grid to only
    test nearby samples). If a point is adequately far from existing samples, emit
    it as the next sample and add it to the active list. If after *k* attempts no
    such point is found, instead remove *i* from the active list.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Implementation poses no real problem and is left as an exercise for the reader.
    Note that not only is this method fast, but it also offers a better quality (more
    samples) than the DART method even with a high *k* parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 5.8**'
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of uniform, grid-jittered and Bridson sampling.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/3f0249fec14faeea13174847e8028b41.png](img/3f0249fec14faeea13174847e8028b41.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Sources](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[DART_sampling_python.py](code/DART_sampling_python.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DART_sampling_numpy.py](code/DART_sampling_numpy.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Bridson_sampling.py](code/Bridson_sampling.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[sampling.py](code/sampling.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[mosaic.py](code/mosaic.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[voronoi.py](code/voronoi.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[References](#id18)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Visualizing Algorithms](https://bost.ocks.org/mike/algorithms/) Mike Bostock,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stippling and Blue Noise](http://www.joesfer.com/?p=108) Jose Esteve, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Poisson Disk Sampling](http://devmag.org.za/2009/05/03/poisson-disk-sampling/)
    Herman Tulleken, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fast Poisson Disk Sampling in Arbitrary Dimensions](http://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph07-poissondisk.pdf),
    Robert Bridson, SIGGRAPH, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id18)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last example we've been studying is indeed a nice example where it is more
    important to vectorize the problem rather than to vectorize the code (and too
    early). In this specific case we were lucky enough to have the work done for us
    but it won't be always the case and in such a case, the temptation might be high
    to vectorize the first solution we've found. I hope you're now convinced it might
    be a good idea in general to look for alternative solutions once you've found
    one. You'll (almost) always improve speed by vectorizing your code, but in the
    process, you may miss huge improvements.
  prefs: []
  type: TYPE_NORMAL
- en: '[Custom vectorization](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction](#id29)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Typed list](#typed-list)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creation](#creation)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Access](#access)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exercise](#id31)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id32)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory aware array](#memory-aware-array)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Glumpy](#id33)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Array subclass](#array-subclass)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Computing extents](#computing-extents)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Keeping track of pending data](#keeping-track-of-pending-data)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sources](#id35)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id36)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction](#id28)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the strengths of numpy is that it can be used to build new objects or
    to [subclass the ndarray](https://docs.scipy.org/doc/numpy/user/basics.subclassing.html)
    object. This later process is a bit tedious but it is worth the effort because
    it allows you to improve the `ndarray` object to suit your problem. We'll examine
    in the following section two real-world cases (typed list and memory-aware array)
    that are extensively used in the [glumpy](http://glumpy.github.io) project (that
    I maintain) while the last one (double precision array) is a more academic case.
  prefs: []
  type: TYPE_NORMAL
- en: '[Typed list](#id28)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Typed list (also known as ragged array) is a list of items that all have the
    same data type (in the sense of numpy). They offer both the list and the ndarray
    API (with some restriction of course) but because their respective APIs may not
    be compatible in some cases, we have to make choices. For example, concerning
    the `+` operator, we'll choose to use the numpy API where the value is added to
    each individual item instead of expanding the list by appending a new item (`1`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: From the list API, we want our new object to offer the possibility of inserting,
    appending and removing items seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: '[Creation](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the object is dynamic by definition, it is important to offer a general-purpose
    creation method powerful enough to avoid having to do later manipulations. Such
    manipulations, for example insertion/deletion, cost a lot of operations and we
    want to avoid them. Here is a proposal (among others) for the creation of a `TypedList`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: This API allows creating an empty list or creating a list from some external
    data. Note that in the latter case, we need to specify how to partition the data
    into several items or they will split into 1-size items. It can be a regular partition
    (i.e. each item is 2 data long) or a custom one (i.e. data must be split in items
    of size 1, 2, 3 and 4 items).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the question is whether to subclass the `ndarray` class or to
    use an internal `ndarray` to store our data. In our specific case, it does not
    really make sense to subclass `ndarray` because we don't really want to offer
    the `ndarray` interface. Instead, we'll use an `ndarray` for storing the list
    data and this design choice will offer us more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'To store the limit of each item, we''ll use an `items` array that will take
    care of storing the position (start and end) for each item. For the creation of
    a list, there are two distinct cases: no data is given or some data is given.
    The first case is easy and requires only the creation of the `_data` and `_items`
    arrays. Note that their size is not `null` since it would be too costly to resize
    the array each time we insert a new item. Instead, it''s better to reserve some
    space.'
  prefs: []
  type: TYPE_NORMAL
- en: '**First case.** No data has been given, only dtype.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '**Second case.** Some data has been given as well as a list of item sizes (for
    other cases, see full code below)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[Access](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once this is done, every list method requires only a bit of computation and
    playing with the different key when getting, inserting or setting an item. Here
    is the code for the `__getitem__` method. No real difficulty but the possible
    negative step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[Exercise](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Modification of the list is a bit more complicated, because it requires managing
    memory properly. Since it poses no real difficulty, we left this as an exercise
    for the reader. For the lazy, you can have a look at the code below. Be careful
    with negative steps, key range and array expansion. When the underlying array
    needs to be expanded, it's better to expand it more than necessary in order to
    avoid future expansion.
  prefs: []
  type: TYPE_NORMAL
- en: '**setitem**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '**delitem**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '**insert**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[Sources](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[array_list.py](code/array_list.py) (solution to the exercise)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory aware array](#id28)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Glumpy](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Glumpy](http://glumpy.github.io) is an OpenGL-based interactive visualization
    library in Python whose goal is to make it easy to create fast, scalable, beautiful,
    interactive and dynamic visualizations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 6.1**'
  prefs: []
  type: TYPE_NORMAL
- en: Simulation of a spiral galaxy using the density wave theory.
  prefs: []
  type: TYPE_NORMAL
- en: '![img/4a1bec6566a39698532f9fb071ef6ffc.png](img/4a1bec6566a39698532f9fb071ef6ffc.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 6.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Tiger display using collections and 2 GL calls
  prefs: []
  type: TYPE_NORMAL
- en: '![img/97405080ef01bac0bf56599757b7489f.png](img/97405080ef01bac0bf56599757b7489f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Glumpy is based on a tight and seamless integration with numpy arrays. This
    means you can manipulate GPU data as you would with regular numpy arrays and glumpy
    will take care of the rest. But an example is worth a thousand words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '`V` is a `VertexBuffer` which is both a `GPUData` and a numpy array. When `V`
    is modified, glumpy takes care of computing the smallest contiguous block of dirty
    memory since it was last uploaded to GPU memory. When this buffer is to be used
    on the GPU, glumpy takes care of uploading the "dirty" area at the very last moment.
    This means that if you never use `V`, nothing will be ever uploaded to the GPU!
    In the case above, the last computed "dirty" area is made of 88 bytes starting
    at offset 0 as illustrated below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![img/51d636eb5c4a87df76ffe74319ca2360.png](img/51d636eb5c4a87df76ffe74319ca2360.png)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When a buffer is created, it is marked as totally dirty, but for the sake of
    illustration, just pretend this is not the case here.
  prefs: []
  type: TYPE_NORMAL
- en: Glumpy will thus end up uploading 88 bytes while only 16 bytes have been actually
    modified. You might wonder if this optimal. Actually, most of the time it is,
    because uploading some data to a buffer requires a lot of operations on the GL
    side and each call has a fixed cost.
  prefs: []
  type: TYPE_NORMAL
- en: '[Array subclass](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As explained in the [Subclassing ndarray](https://docs.scipy.org/doc/numpy/user/basics.subclassing.html)
    documentation, subclassing `ndarray` is complicated by the fact that new instances
    of `ndarray` classes can come about in three different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Explicit constructor call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: View casting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New from template
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However our case is simpler because we''re only interested in the view casting.
    We thus only need to define the `__new__` method that will be called at each instance
    creation. As such, the `GPUData` class will be equipped with two properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '`extents`: This represents the full extent of the view relatively to the base
    array. It is stored as a byte offset and a byte size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pending_data`: This represents the contiguous *dirty* area as (byte offset,
    byte size) relatively to the `extents` property.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[Computing extents](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each time a partial view of the array is requested, we need to compute the extents
    of this partial view while we have access to the base array.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[Keeping track of pending data](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One extra difficulty is that we don''t want all the views to keep track of
    the dirty area but only the base array. This is the reason why we don''t instantiate
    the `self._pending_data` in the second case of the `__array_finalize__` method.
    This will be handled when we need to update some data as during a `__setitem__`
    call for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[Sources](#id28)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[gpudata.py](code/gpudata.py)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id28)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained on the numpy website, numpy is the fundamental package for scientific
    computing with Python. However, as illustrated in this chapter, the usage of numpy
    strengths goes far beyond a mere *multi-dimensional container of generic data*.
    Using `ndarray` as a private property in one case (`TypedList`) or directly subclassing
    the `ndarray` class (`GPUData`) to keep track of memory in another case, we've
    seen how it is possible to extend numpy's capabilities to suit very specific needs.
    The limit is only your imagination and your experience.
  prefs: []
  type: TYPE_NORMAL
- en: '[Beyond Numpy](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Back to Python](#back-to-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy & co](#numpy-co)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[NumExpr](#numexpr)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cython](#cython)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numba](#numba)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Theano](#theano)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyCUDA](#pycuda)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyOpenCL](#pyopencl)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Scipy & co](#scipy-co)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[scikit-learn](#scikit-learn)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[scikit-image](#scikit-image)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SymPy](#sympy)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Astropy](#astropy)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cartopy](#cartopy)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Brian](#brian)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Glumpy](#id50)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Conclusion](#id52)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Python](#id37)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You''ve almost reached the end of the book and, hopefully, you''ve learned
    that numpy is a very versatile and powerful library. However in the meantime,
    remember that Python is also quite a powerful language. In fact, in some specific
    cases, it might be more powerful than numpy. Let''s consider, for example, an
    interesting exercise that has been proposed by Tucker Balch in his [Coursera''s
    Computational Investing](https://www.coursera.org/learn/computational-investing)
    course. The exercise is written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Write the most succinct code possible to compute all "legal" allocations to
    4 stocks such that the allocations are in 1.0 chunks, and the allocations sum
    to 10.0.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Yaser Martinez](http://yasermartinez.com/blog/index.html) collected the different
    answers from the community and the proposed solutions yield surprising results.
    But let''s start with the most obvious Python solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'This solution is the slowest solution because it requires 4 loops, and more
    importantly, it tests all the different combinations (11641) of 4 integers between
    0 and 10 to retain only combinations whose sum is 10\. We can of course get rid
    of the 4 loops using itertools, but the code remains slow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the best solution that has been proposed by Nick Popplas takes advantage
    of the fact we can have intelligent imbricated loops that will allow us to directly
    build each tuple without any test as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'The best numpy solution by Yaser Martinez uses a different strategy with a
    restricted set of tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'If we benchmark these methods, we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'The numpy solution is the fastest but the pure Python solution is comparable.
    But let me introduce a small modification to the Python solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'If we benchmark it, we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'You read that right, we have gained a factor of 100 just by replacing square
    brackets with parenthesis. How is that possible? The explanation can be found
    by looking at the type of the returned object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: The `solution_3_bis()` returns a generator that can be used to generate the
    full list or to iterate over all the different elements. In any case, the huge
    speedup comes from the non-instantiation of the full list and it is thus important
    to wonder if you need an actual instance of your result or if a simple generator
    might do the job.
  prefs: []
  type: TYPE_NORMAL
- en: '[Numpy & co](#id37)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Beyond numpy, there are several other Python packages that are worth a look
    because they address similar yet different class of problems using different technology
    (compilation, virtual machine, just in time compilation, GPU, compression, etc.).
    Depending on your specific problem and your hardware, one package may be better
    than the other. Let''s illustrate their usage using a very simple example where
    we want to compute an expression based on two float vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[NumExpr](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [numexpr](https://github.com/pyhttps://www.labri.fr/perso/nrougier/from-python-to-numpy/data/numexpr/wiki/Numexpr-Users-Guide)
    package supplies routines for the fast evaluation of array expressions element-wise
    by using a vector-based virtual machine. It's comparable to SciPy's weave package,
    but doesn't require a separate compile step of C or C++ code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[Cython](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Cython](http://cython.org) is an optimising static compiler for both the Python
    programming language and the extended Cython programming language (based on Pyrex).
    It makes writing C extensions for Python as easy as Python itself.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[Numba](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Numba](http://numba.pydata.org) gives you the power to speed up your applications
    with high performance functions written directly in Python. With a few annotations,
    array-oriented and math-heavy Python code can be just-in-time compiled to native
    machine instructions, similar in performance to C, C++ and Fortran, without having
    to switch languages or Python interpreters.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[Theano](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Theano](http://www.deeplearning.net/software/theano/) is a Python library
    that allows you to define, optimize, and evaluate mathematical expressions involving
    multi-dimensional arrays efficiently. Theano features tight integration with numpy,
    transparent use of a GPU, efficient symbolic differentiation, speed and stability
    optimizations, dynamic C code generation and extensive unit-testing and self-verification.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PyCUDA](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyCUDA](http://mathema.tician.de/software/pycuda) lets you access Nvidia''s
    CUDA parallel computation API from Python.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PyOpenCL](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyOpenCL](http://mathema.tician.de/software/pyopencl) lets you access GPUs
    and other massively parallel compute devices from Python.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[Scipy & co](#id37)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If there are several additional packages for numpy, there are a trillion additional
    packages for scipy. In fact, every domain of science probably has its own package
    and most of the examples we've been studying until now could have been solved
    in two or three calls to a method in the relevant package. But of course, that
    was not the goal and programming things yourself is generally a good exercise
    if you have some spare time. The biggest difficulty at this point is to find these
    relevant packages. Here is a very short list of packages that are well-maintained,
    well-tested and may simplify your scientific life (depending on your domain).
    There are of course many more and depending on your specific needs, chances are
    you do not have to program everything by yourself. For an extensive list, have
    a look at the [Awesome python list](https://awesome-python.com).
  prefs: []
  type: TYPE_NORMAL
- en: '[scikit-learn](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[scikit-learn](http://scikit-learn.org/stable/) is a free software machine
    learning library for the Python programming language. It features various classification,
    regression and clustering algorithms including support vector machines, random
    forests, gradient boosting, k-means and DBSCAN, and is designed to inter-operate
    with the Python numerical and scientific libraries numpy and SciPy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[scikit-image](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[scikit-image](http://scikit-image.org) is a Python package dedicated to image
    processing, and using natively numpy arrays as image objects. This chapter describes
    how to use scikit-image on various image processing tasks, and insists on the
    link with other scientific Python modules such as numpy and SciPy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[SymPy](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[SymPy](http://www.sympy.org/en/index.html) is a Python library for symbolic
    mathematics. It aims to become a full-featured computer algebra system (CAS) while
    keeping the code as simple as possible in order to be comprehensible and easily
    extensible. SymPy is written entirely in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Astropy](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [Astropy](http://www.astropy.org) project is a community effort to develop
    a single core package for astronomy in Python and foster interoperability between
    Python astronomy packages.
  prefs: []
  type: TYPE_NORMAL
- en: '[Cartopy](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Cartopy](http://scitools.org.uk/cartopy/) is a Python package designed to
    make drawing maps for data analysis and visualization as easy as possible. Cartopy
    makes use of the powerful PROJ.4, numpy and shapely libraries and has a simple
    and intuitive drawing interface to matplotlib for creating publication quality
    maps.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Brian](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Brian](http://www.briansimulator.org) is a free, open source simulator for
    spiking neural networks. It is written in the Python programming language and
    is available on almost all platforms. We believe that a simulator should not only
    save the time of processors, but also the time of scientists. Brian is therefore
    designed to be easy to learn and use, highly flexible and easily extensible.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Glumpy](#id37)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Glumpy](http://glumpy.github.io) is an OpenGL-based interactive visualization
    library in Python. Its goal is to make it easy to create fast, scalable, beautiful,
    interactive and dynamic visualizations. The main documentation for the site is
    organized into a couple of sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Conclusion](#id37)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numpy is a very versatile library but still, it does not mean you have to use
    it in every situation. In this chapter, we've seen some alternatives (including
    Python itself) that are worth a look. As always, the choice belongs to you. You
    have to consider what is the best solution for you in term of development time,
    computation time and effort in maintenance. On the one hand, if you design your
    own solution, you'll have to test it and to maintain it, but in exchange, you'll
    be free to design it the way you want. On the other hand, if you decide to rely
    on a third-party package, you'll save time in development and benefit from community-support
    even though you might have to adapt the package to your specific needs. The choice
    is up to you.
  prefs: []
  type: TYPE_NORMAL
- en: '[Conclusion](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You've reached the end of this book. I hope you've learned something while reading
    it, I sure learned a lot writing it. Trying to explain something is a generally
    a good exercise to test for your knowledge of this thing. Of course, we only scratched
    the surface of numpy and there are many things left to discover. Have a look at
    the bibliography for books written by true experts, at the documentation written
    by people making numpy and don't hesitate to ask your questions on the mailing
    lists because the numpy community is very friendly.
  prefs: []
  type: TYPE_NORMAL
- en: 'If there''s a single message to retain from this book it is "premature optimization
    is the root of all evil". We''ve seen that code vectorization can drastically
    improve your computation, with several orders of magnitude in some cases. Still,
    problem vectorization is generally much more powerful. If you write code vectorization
    too early in your design process, you won''t be able to think out-of-the-box and
    you''ll certainly miss some really powerful alternatives because you won''t be
    able to identify your problem properly as we''ve seen in the problem vectorization
    chapter. This requires some experience and you have to be patient: experience
    is not an overnight process.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, custom vectorization is an option worth considering once you've looked
    at the alternatives to numpy. When nothing works for you, numpy still offers you
    a clever framework to forge your own tools. And who knows, this can be the start
    of an exciting adventure for you and the community as it happened to me with the
    [glumpy](http://glumpy.github.io) and the [vispy](http://vispy.org) packages.
  prefs: []
  type: TYPE_NORMAL
- en: '[Quick References](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data type](#id56)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creation](#id57)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Indexing](#id58)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reshaping](#reshaping)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Broadcasting](#broadcasting)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data type](#id55)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Type | Name | Bytes | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `bool` | `b` | 1 | Boolean (True or False) stored as a byte |'
  prefs: []
  type: TYPE_TB
- en: '| `int` | `l` | 4-8 | Platform (long) integer (normally either int32 or int64)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `intp` | `p` | 4-8 | Integer used for indexing (normally either int32 or
    int64) |'
  prefs: []
  type: TYPE_TB
- en: '| `int8` | `i1` | 1 | Byte (-128 to 127) |'
  prefs: []
  type: TYPE_TB
- en: '| `int16` | `i2` | 2 | Integer (-32768 to 32767) |'
  prefs: []
  type: TYPE_TB
- en: '| `int32` | `i4` | 4 | Integer (-2147483648 to 2147483647) |'
  prefs: []
  type: TYPE_TB
- en: '| `int64` | `i8` | 8 | Integer (-9223372036854775808 to 9223372036854775807)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `uint8` | `u1` | 1 | Unsigned integer (0 to 255) |'
  prefs: []
  type: TYPE_TB
- en: '| `uint16` | `u2` | 2 | Unsigned integer (0 to 65535) |'
  prefs: []
  type: TYPE_TB
- en: '| `uint32` | `u4` | 4 | Unsigned integer (0 to 4294967295) |'
  prefs: []
  type: TYPE_TB
- en: '| `uint64` | `u8` | 8 | Unsigned integer (0 to 18446744073709551615) |'
  prefs: []
  type: TYPE_TB
- en: '| `float` | `f8` | 8 | Shorthand for float64 |'
  prefs: []
  type: TYPE_TB
- en: '| `float16` | `f2` | 2 | Half precision float: sign bit, 5 bits exponent, 10
    bits mantissa |'
  prefs: []
  type: TYPE_TB
- en: '| `float32` | `f` | 4 | Single precision float: sign bit, 8 bits exponent,
    23 bits mantissa |'
  prefs: []
  type: TYPE_TB
- en: '| `float64` | `d` | 8 | Double precision float: sign bit, 11 bits exponent,
    52 bits mantissa |'
  prefs: []
  type: TYPE_TB
- en: '| `complex` | `c16` | 16 | Shorthand for complex128. |'
  prefs: []
  type: TYPE_TB
- en: '| `complex64` | `c8` | 8 | Complex number, represented by two 32-bit floats
    |'
  prefs: []
  type: TYPE_TB
- en: '| `complex128` | `c16` | 16 | Complex number, represented by two 64-bit floats
    |'
  prefs: []
  type: TYPE_TB
- en: '`bool`, `int`, `float`, and `complex` are understood, but named `np.bool_`
    with an additional underscore in NumPy. Additionally the names such as `intc`,
    `long`, or `double` used in the C programming language are defined.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Creation](#id55)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[Indexing](#id55)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[Reshaping](#id55)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[Broadcasting](#id55)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: '[Bibliography](#table-of-contents)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a curated list of some numpy related resources (articles, books & tutorials)
    addressing different aspects of numpy. Some are very specific to numpy/Scipy while
    some others offer a broader view on numerical computing.
  prefs: []
  type: TYPE_NORMAL
- en: '**Contents**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Tutorials](#tutorials)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Articles](#articles)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Books](#books)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tutorials](#id59)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[100 Numpy exercises](http://www.labri.fr/perso/nrougier/teaching/numpy.100/index.html),
    Nicolas P. Rougier, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy tutorial](http://www.labri.fr/perso/nrougier/teaching/numpy/numpy.html),
    Nicolas P. Rougier, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python course](http://www.python-course.eu/numpy.php), Bernd Klein, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An introduction to Numpy and Scipy](https://engineering.ucsb.edu/~shell/che210d/numpy.pdf),
    M. Scott Shell, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Numpy tutorial](http://cs231n.github.io/python-numpy-tutorial/), Justin
    Johnson, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Quickstart tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html),
    Numpy developers, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Numpy medkits](http://mentat.za.net/numpy/numpy_advanced_slides/), Stéfan
    van der Walt, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Articles](#id59)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The NumPy array: a structure for efficient numerical computation](https://hal.inria.fr/inria-00564007/document)Stéfan
    van der Walt, Chris Colbert & Gael Varoquaux, Computing in Science and Engineering,
    13(2), 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the Python world, NumPy arrays are the standard representation for numerical
    data and enable efficient implementation of numerical computations in a high-level
    language. As this effort shows, NumPy performance can be improved through three
    techniques: vectorizing calculations, avoiding copying data in memory, and minimizing
    operation counts.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Vectorised algorithms for spiking neural network simulation](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.397.6097)Romain
    Brette & Dan F. M. Goodman, Neural Computation, 23(6), 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-level languages (Matlab, Python) are popular in neuroscience because they
    are flexible and accelerate development. However, for simulating spiking neural
    networks, the cost of interpretation is a bottleneck. We describe a set of algorithms
    to simulate large spiking neural networks efficiently with high-level languages
    using vector-based operations. These algorithms constitute the core of Brian,
    a spiking neural network simulator written in the Python language. Vectorized
    simulation makes it possible to combine the flexibility of high-level languages
    with the computational efficiency usually associated with compiled languages.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Python for Scientific Computing](http://dl.acm.org/citation.cfm?id=1251830)Travis
    E. Oliphant, Computing in Science & Engineering, 9(3), 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By itself, Python is an excellent "steering" language for scientific codes written
    in other languages. However, with additional basic tools, Python transforms into
    a high-level language suited for scientific and engineering code that's often
    fast enough to be immediately useful but also flexible enough to be sped up with
    additional extensions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Books](#id59)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[SciPy Lecture Notes](http://www.scipy-lectures.org),Gaël Varoquaux, Emmanuelle
    Gouillart, Olav Vahtras et al., 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One document to learn numerics, science, and data with Python. Tutorials on
    the scientific Python ecosystem: a quick introduction to central tools and techniques.
    The different chapters each correspond to a 1 to 2 hours course with increasing
    level of expertise, from beginner to expert.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do)Jake
    van der Plas, O''Reilly, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Python Data Science Handbook provides a reference to the breadth of computational
    and statistical methods that are central to data—intensive science, research,
    and discovery. People with a programming background who want to use Python effectively
    for data science tasks will learn how to face a variety of problems: for example,
    how can you read this data format into your script? How can you manipulate, transform,
    and clean this data? How can you use this data to gain insight, answer questions,
    or to build statistical or machine learning models?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Elegant SciPy: The Art of Scientific Python](http://shop.oreilly.com/product/0636920038481.do)Juan
    Nunez-Iglesias, Stéfan van der Walt, Harriet Dashnow, O''Reilly, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Welcome to Scientific Python and its community! With this practical book, you'll
    learn the fundamental parts of SciPy and related libraries, and get a taste of
    beautiful, easy-to-read code that you can use in practice. More and more scientists
    are programming, and the SciPy library is here to help. Finding useful functions
    and using them correctly, efficiently, and in easily readable code are two very
    different things. You'll learn by example with some of the best code available,
    selected to cover a wide range of SciPy and related libraries—including scikit-learn,
    scikit-image, toolz, and pandas.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Learning IPython for Interactive Computing and Data Visualization](https://www.packtpub.com/big-data-and-business-intelligence/learning-ipython-interactive-computing-and-data-visualization-sec)Cyrille
    Rossant, Packt Publishing, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This book is a beginner-friendly guide to the Python data analysis platform.
    After an introduction to the Python language, IPython, and the Jupyter Notebook,
    you will learn how to analyze and visualize data on real-world examples, how to
    create graphical user interfaces for image processing in the Notebook, and how
    to perform fast numerical computations for scientific simulations with NumPy,
    Numba, Cython, and ipyparallel. By the end of this book, you will be able to perform
    in-depth analyses of all sorts of data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[SciPy and NumPy](https://www.safaribooksonline.com/library/view/scipy-and-numpy/9781449361600/)Eli
    Bressert, O''Reilly Media, Inc., 2012'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are you new to SciPy and NumPy? Do you want to learn it quickly and easily through
    examples and concise introduction? Then this is the book for you. You’ll cut through
    the complexity of online documentation and discover how easily you can get up
    to speed with these Python libraries.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)Wes
    McKinney, O''Reilly Media, Inc., 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking for complete instructions on manipulating, processing, cleaning, and
    crunching structured data in Python? This hands-on book is packed with practical
    cases studies that show you how to effectively solve a broad set of data analysis
    problems, using several Python libraries.*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Guide to NumPy](http://csc.ucdavis.edu/~chaos/courses/nlp/Software/NumPyBook.pdf)Travis
    Oliphant, 2006'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This book only briefly outlines some of the infrastructure that surrounds the
    basic objects in NumPy to provide the additional functionality contained in the
    older Numeric package (i.e. LinearAlgebra, RandomArray, FFT). This infrastructure
    in NumPy includes basic linear algebra routines, Fourier transform capabilities,
    and random number generators. In addition, the f2py module is described in its
    own documentation, and so is only briefly mentioned in the second part of the
    book.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
