- en: The LAB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://little-book-of.github.io/linear-algebra/books/en-US/lab.html](https://little-book-of.github.io/linear-algebra/books/en-US/lab.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chapter 1\. Vectors, scalars, and geometry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Scalars, Vectors, and Coordinate Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s get our hands dirty! This lab is about playing with the *building blocks*
    of linear algebra: scalars and vectors. Think of a scalar as just a plain number,
    like `3` or `-1.5`. A vector is a small list of numbers, which you can picture
    as an arrow in space.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use Python (with NumPy) to explore them. Don’t worry if this is your first
    time with NumPy - we’ll go slowly.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*That’s it - we’re ready! NumPy is the main tool we’ll use for linear algebra.*  *####
    Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Scalars are just numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE2]*  *Vectors are lists of numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE4]*  *Coordinates tell us where we are. Think of `[2, 3]` as “go 2 steps
    in the x-direction, 3 steps in the y-direction.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can even *draw* it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/5a3607f4b32724c983fa329537dcf6fc.png)*  *This makes a little
    arrow from the origin `(0,0)` to `(2,3)`.***  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change the vector `v` to `[4, 1]`. Where does the arrow point now?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try making a 3D vector with 4 numbers, like `[1, 2, 3, 4]`. What happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace `np.array([2,3])` with `np.array([0,0])`. What does the arrow look like?****  ***###
    2\. Vector Notation, Components, and Arrows
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this lab, we’ll practice reading, writing, and visualizing vectors in different
    ways. A vector can look simple at first - just a list of numbers - but how we
    *write* it and how we *interpret* it really matters. This is where notation and
    components come into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'A vector has:'
  prefs: []
  type: TYPE_NORMAL
- en: A symbol (we might call it `v`, `w`, or even `→AB` in geometry).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Components (the individual numbers, like `2` and `3` in `[2, 3]`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An arrow picture (a geometric way to see the vector as a directed line segment).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s see all three in action with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Writing vectors in Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE8]*  *Here `v` has components `(2, 3)` and `w` has components `(1, -1,
    4)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing components Each number in the vector is a *component*. We can pick
    them out using indexing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE10]*  *Notice: in Python, indices start at `0`, so `v[0]` is the *first*
    component.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing vectors as arrows In 2D, it’s easy to draw a vector from the origin
    `(0,0)` to its endpoint `(x,y)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/ec80c79cd6f849d29241fce12f25f133.png)*  *This shows vector v
    as a red arrow from `(0,0)` to `(2,3)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Drawing multiple vectors We can plot several arrows at once to compare them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/f68beaac55212c7ba347fee7231081c3.png)*  *Now you’ll see three
    arrows starting at the same point, each pointing in a different direction.****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change `v` to `[5, 0]`. What does the arrow look like now?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try a vector like `[0, -3]`. Which axis does it line up with?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a new vector `q = np.array([2, 0, 0])`. What happens if you try to plot
    it with `plt.quiver` in 2D?****  ***### 3\. Vector Addition and Scalar Multiplication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this lab, we’ll explore the two most fundamental operations you can perform
    with vectors: adding them together and scaling them by a number (a scalar). These
    operations form the basis of everything else in linear algebra, from geometry
    to machine learning. Understanding how they work, both in code and visually, is
    key to building intuition.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Vector addition When you add two vectors, you simply add their components one
    by one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE15]*  *Here, `(2,3) + (1,-1) = (3,2)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing vector addition (tip-to-tail method) Graphically, vector addition
    means placing the tail of one vector at the head of the other. The resulting vector
    goes from the start of the first to the end of the second.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/24c9b4a14e7428e0011d7e6b7a2945d8.png)*  *The green arrow is
    the result of adding `v` and `u`.'
  prefs: []
  type: TYPE_NORMAL
- en: Scalar multiplication Multiplying a vector by a scalar stretches or shrinks
    it. If the scalar is negative, the vector flips direction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE18]*  *So `2 * (2,3) = (4,6)` and `-1 * (2,3) = (-2,-3)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing scalar multiplication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/ff749a52dbaf032f6ec065b9394b4c88.png)*  *Here, the blue arrow
    is twice as long as the red arrow, while the green arrow points in the opposite
    direction.'
  prefs: []
  type: TYPE_NORMAL
- en: Combining both operations We can scale vectors and then add them. This is called
    a linear combination (and it’s the foundation for the next section).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE21]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Replace `c = 2` with `c = 0.5`. What happens to the vector?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Try adding three vectors: `v + u + np.array([-1,2])`. Can you predict the result
    before printing?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize `3*v + 2*u` using arrows. How does it compare to just `v + u`?****  ***###
    4\. Linear Combinations and Span
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we know how to add vectors and scale them, we can combine these two
    moves to create linear combinations. A linear combination is just a recipe: multiply
    vectors by scalars, then add them together. The set of all possible results you
    can get from such recipes is called the span.'
  prefs: []
  type: TYPE_NORMAL
- en: This idea is powerful because span tells us what directions and regions of space
    we can reach using given vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Linear combinations in Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE24]*  *Here, we multiplied and added vectors using scalars. Each result
    is a new vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing linear combinations Let’s plot `v`, `u`, and their combinations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/917c473dd3d518353b37910186a72b84.png)*  *This shows how new
    arrows can be generated from scaling and adding the original ones.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploring the span The span of two 2D vectors is either:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A line (if one is a multiple of the other).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The whole 2D plane (if they are independent).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/f0bf1cab2386e70472f7667b98e35c71.png)*  *The gray dots show
    all reachable points with combinations of `v` and `u`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Special case: dependent vectors'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/9a3bff45697a7ebc4a8d4f898ac7022d.png)*  *Here, the span collapses
    to a line because `w` is just a scaled copy of `v`.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Replace `u = [1,3]` with `u = [-1,2]`. What does the span look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try three vectors in 2D (e.g., `v, u, w`). Do you get more than the whole plane?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with 3D vectors. Use `np.array([x,y,z])` and check whether different
    vectors span a plane or all of space.****  ***### 5\. Length (Norm) and Distance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this lab, we’ll measure how big a vector is (its length, also called its
    norm) and how far apart two vectors are (their distance). These ideas connect
    algebra to geometry: when we compute a norm, we’re measuring the size of an arrow;
    when we compute a distance, we’re measuring the gap between two points in space.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Vector length (norm) in 2D The length of a vector is computed using the Pythagorean
    theorem. For a vector `(x, y)`, the length is `sqrt(x² + y²)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE30]*  *This prints `5.0`, because `(3,4)` forms a right triangle with
    sides 3 and 4, and `sqrt(3²+4²)=5`.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual calculation vs NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE32]*  *Both give the same result.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing vector length
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/04cfb44175ad74ab63140dc3267c160a.png)*  *You’ll see the arrow
    `(3,4)` with its length labeled.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Distance between two vectors The distance between `v` and another vector `u`
    is the length of their difference: `‖v - u‖`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE35]*  *Since `u` is the origin, this is just the length of `v`.'
  prefs: []
  type: TYPE_NORMAL
- en: A more interesting distance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE37]*  *This measures how far `(3,4)` is from `(1,1)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing distance between points
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/373a87dc071b7c20ba645a697df4552d.png)*  *The dashed line shows
    the distance between the two points.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Higher-dimensional vectors Norms and distances work the same way in any dimension:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE40]*  *Even though we can’t draw 3D easily on paper, the formulas still
    apply.*******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the length of `np.array([5,12])`. What do you expect?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the distance between `(2,3)` and `(7,7)`. Can you sketch it by hand and
    check?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In 3D, try vectors `(1,1,1)` and `(2,2,2)`. Why is the distance exactly `sqrt(3)`?****  ***###
    6\. Dot Product
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dot product is one of the most important operations in linear algebra. It
    takes two vectors and gives you a single number. That number combines both the
    lengths of the vectors and how much they point in the same direction. In this
    lab, we’ll calculate dot products in several ways, see how they relate to geometry,
    and visualize their meaning.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Algebraic definition The dot product of two vectors is the sum of the products
    of their components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE43]*  *Here, `(2*4) + (3*-1) = 8 - 3 = 5`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Geometric definition The dot product also equals the product of the lengths
    of the vectors times the cosine of the angle between them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ v \cdot u = \|v\| \|u\| \cos \theta \]
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compute the angle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE45]*  *This gives the angle between `v` and `u`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visualizing the dot product Let’s draw the two vectors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/c7afb0b142eec45593b1a3363fccf940.png)*  *The dot product is
    positive if the angle is less than 90°, negative if greater than 90°, and zero
    if the vectors are perpendicular.'
  prefs: []
  type: TYPE_NORMAL
- en: Projections and dot product The dot product lets us compute how much of one
    vector lies in the direction of another.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE48]*  *This is the length of the shadow of `v` onto `u`.'
  prefs: []
  type: TYPE_NORMAL
- en: Special cases
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If vectors point in the same direction, the dot product is large and positive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If vectors are perpendicular, the dot product is zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If vectors point in opposite directions, the dot product is negative.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE50]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the dot product of `(3,4)` with `(4,3)`. Is the result larger or smaller
    than the product of their lengths?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try `(1,2,3) · (4,5,6)`. Does the geometric meaning still work in 3D?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two perpendicular vectors (e.g. `(2,0)` and `(0,5)`). Verify the dot
    product is zero.****  ***### 7\. Angles Between Vectors and Cosine
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this lab, we’ll go deeper into the connection between vectors and geometry
    by calculating angles. Angles tell us how much two vectors “point in the same
    direction.” The bridge between algebra and geometry here is the cosine formula,
    which comes directly from the dot product.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Formula for the angle The angle \(\theta\) between two vectors \(v\) and \(u\)
    is given by:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \cos \theta = \frac{v \cdot u}{\|v\| \, \|u\|} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'This means:'
  prefs: []
  type: TYPE_NORMAL
- en: If \(\cos \theta = 1\), the vectors point in exactly the same direction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\cos \theta = 0\), they are perpendicular.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\cos \theta = -1\), they point in opposite directions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing the angle in Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE53]*  *This gives both the cosine value and the actual angle.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/afb9916f799a2374f1fa1fcf79d592fe.png)*  *You can see the angle
    between `v` and `u` as the gap between the red and blue arrows.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking special cases
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE56]*  **   Angle between `(1,0)` and `(0,1)` is 90°.'
  prefs: []
  type: TYPE_NORMAL
- en: Angle between `(1,0)` and `(-1,0)` is 180°.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using cosine as a similarity measure In data science and machine learning,
    people often use cosine similarity instead of raw angles. It’s just the cosine
    value itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE58]*  *Values close to `1` mean vectors are aligned, values near `0` mean
    unrelated, and values near `-1` mean opposite.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create two random vectors with `np.random.randn(3)` and compute the angle between
    them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that swapping the vectors gives the same angle (symmetry).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find two vectors where cosine similarity is exactly `0`. Can you come up with
    an example in 2D?****  ***### 8\. Projections and Decompositions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this lab, we’ll learn how to split one vector into parts: one part that
    lies *along* another vector, and one part that is *perpendicular*. This process
    is called projection and decomposition. Projections let us measure “how much of
    a vector points in a given direction,” and decompositions give us a way to break
    vectors into useful components.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Projection formula The projection of vector \(v\) onto vector \(u\) is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \text{proj}_u(v) = \frac{v \cdot u}{u \cdot u} \, u \]
  prefs: []
  type: TYPE_NORMAL
- en: This gives the component of \(v\) that points in the direction of \(u\).
  prefs: []
  type: TYPE_NORMAL
- en: Computing projection in Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE61]*  *Here, \(v = (3,2)\) and \(u = (2,0)\). The projection of `v` onto
    `u` is a vector pointing along the x-axis.'
  prefs: []
  type: TYPE_NORMAL
- en: Decomposing into parallel and perpendicular parts
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can write:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ v = \text{proj}_u(v) + (v - \text{proj}_u(v)) \]
  prefs: []
  type: TYPE_NORMAL
- en: The first part is parallel to `u`, the second part is perpendicular.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE63]*  *4.  Visualizing projection and decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/16a53f9ebdb01200ad8263dbcf9a3eaa.png)*  *You’ll see `v` (red),
    `u` (blue), the projection (green), and the perpendicular remainder (magenta).'
  prefs: []
  type: TYPE_NORMAL
- en: Projection in higher dimensions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This formula works in any dimension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE66]*  *Even in 3D or higher, projections are about splitting into “along”
    and “across.”****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Try projecting `(2,3)` onto `(0,5)`. Where does it land?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a 3D vector like `(4,2,6)` and project it onto `(1,0,0)`. What does this
    give you?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the base vector `u` to something not aligned with the axes, like `(1,1)`.
    Does the projection still work?****  ***### 9\. Cauchy–Schwarz and Triangle Inequalities
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This lab introduces two fundamental inequalities in linear algebra. They may
    look abstract at first, but they provide guarantees that always hold true for
    vectors. We’ll explore them with small examples in Python to see why they matter.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Cauchy–Schwarz inequality
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The inequality states:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ |v \cdot u| \leq \|v\| \, \|u\| \]
  prefs: []
  type: TYPE_NORMAL
- en: It means the dot product is never “bigger” than the product of the vector lengths.
    Equality happens only if the two vectors are pointing in exactly the same (or
    opposite) direction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE69]*  *2.  Testing Cauchy–Schwarz with different vectors'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE71]*  **   Perpendicular vectors give `|v·u| = 0`, far less than the product
    of norms.'
  prefs: []
  type: TYPE_NORMAL
- en: Multiples give equality (`lhs = rhs`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Triangle inequality
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The triangle inequality states:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \|v + u\| \leq \|v\| + \|u\| \]
  prefs: []
  type: TYPE_NORMAL
- en: Geometrically, the length of one side of a triangle can never be longer than
    the sum of the other two sides.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE73]*  *4.  Visual demonstration with a triangle'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/f98fd435cf31640d8b4193da3f48f365.png)*  *This triangle shows
    why the inequality is called the “triangle” inequality.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing triangle inequality with random vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE76]*  *No matter what vectors you try, the inequality always holds.*****  ***####
    The Takeaway'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cauchy–Schwarz: The dot product is always bounded by the product of vector
    lengths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Triangle inequality: The length of one side of a triangle can’t exceed the
    sum of the other two.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These inequalities form the backbone of geometry, analysis, and many proofs
    in linear algebra.****  ***### 10\. Orthonormal Sets in ℝ²/ℝ³
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this lab, we’ll explore orthonormal sets - collections of vectors that are
    both orthogonal (perpendicular) and normalized (length = 1). These sets are the
    “nicest” possible bases for vector spaces. In 2D and 3D, they correspond to the
    coordinate axes we already know, but we can also construct and test new ones.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Orthogonal vectors Two vectors are orthogonal if their dot product is zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE79]*  *So the standard axes are orthogonal.'
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing vectors Normalization means dividing a vector by its length to make
    its norm equal to 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE81]*  *Now `v_normalized` points in the same direction as `v` but has
    unit length.'
  prefs: []
  type: TYPE_NORMAL
- en: Building an orthonormal set in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE83]*  *Both have length 1, and their dot product is 0\. That makes `{u1,
    u2}` an orthonormal set in 2D.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing 2D orthonormal vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/cb7ed899fdf67e3f9f3f6c9dcda6f752.png)*  *You’ll see the red
    and blue arrows at right angles, each of length 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Orthonormal set in 3D In 3D, the standard basis vectors are:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE86]*  *Lengths are all 1, and dot products are 0\. So `{i, j, k}` is an
    orthonormal set in ℝ³.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Testing if a set is orthonormal We can write a helper function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE88]*  *7.  Constructing a new orthonormal pair Not all orthonormal sets
    look like the axes.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE90]*  *This gives a rotated orthonormal basis in 2D.*******  ***#### Try
    It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Normalize `(2,2,1)` to make it a unit vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test whether the set `{[1,0,0], [0,2,0], [0,0,3]}` is orthonormal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Construct two vectors in 2D that are not perpendicular. Normalize them and check
    if the dot product is still zero.*******************************  ***## Chapter
    2\. Matrices and basic operations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 11\. Matrices as Tables and as Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Matrices can feel mysterious at first, but there are two simple ways to think
    about them:'
  prefs: []
  type: TYPE_NORMAL
- en: As tables of numbers - just a grid you can store and manipulate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As machines - something that takes a vector in and spits a new vector out.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this lab, we’ll explore both views and see how they connect.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: A matrix as a table of numbers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE93]*  *Here, `A` is a 2×3 matrix (2 rows, 3 columns).'
  prefs: []
  type: TYPE_NORMAL
- en: Rows = horizontal slices → `[1,2,3]` and `[4,5,6]`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columns = vertical slices → `[1,4]`, `[2,5]`, `[3,6]`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing rows and columns
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE95]*  *Rows are whole vectors too, and so are columns.'
  prefs: []
  type: TYPE_NORMAL
- en: A matrix as a machine
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A matrix can “act” on a vector. If `x = [x1, x2, x3]`, then `A·x` is computed
    by taking linear combinations of the columns of `A`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE97]*  *Interpretation: multiply `A` by `x` = combine columns of `A` with
    weights from `x`.'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A \cdot x = 1 \cdot \text{(col 1)} + 0 \cdot \text{(col 2)} + (-1) \cdot
    \text{(col 3)} \]
  prefs: []
  type: TYPE_NORMAL
- en: Verifying column combination view
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE99]*  *They match exactly. This shows the “machine” interpretation is
    just a shortcut for column combinations.'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric intuition (2D example)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE101]*  *Here, `B` scales the x-direction by 2 while leaving the y-direction
    alone. So `(1,2)` becomes `(2,2)`.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a 3×3 identity matrix with `np.eye(3)` and multiply it by different vectors.
    What happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a matrix `[[0,-1],[1,0]]`. Try multiplying it by `(1,0)` and `(0,1)`.
    What transformation is this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create your own 2×2 matrix that flips vectors across the x-axis. Test it on
    `(1,2)` and `(−3,4)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A matrix is both a grid of numbers and a machine that transforms vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix–vector multiplication is the same as combining columns with given weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking of matrices as machines helps build intuition for rotations, scalings,
    and other transformations later.****  ***### 12\. Matrix Shapes, Indexing, and
    Block Views
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrices come in many shapes, and learning to read their structure is essential.
    Shape tells us how many rows and columns a matrix has. Indexing lets us grab specific
    entries, rows, or columns. Block views let us zoom in on submatrices, which is
    extremely useful for both theory and computation.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix shapes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The shape of a matrix is `(rows, columns)`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE104]*  *Here, `A` is a 3×3 matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Indexing elements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In NumPy, rows and columns are 0-based. The first entry is `A[0,0]`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE106]*  *3.  Extracting rows and columns'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE108]*  *Notice: `A[i]` gives a row, `A[:,j]` gives a column.'
  prefs: []
  type: TYPE_NORMAL
- en: Slicing submatrices (block view)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can slice multiple rows and columns to form a smaller matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE110]*  *This block is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 2 & 3 \\ 5 & 6 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: Modifying parts of a matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE112]*  *6.  Non-square matrices'
  prefs: []
  type: TYPE_NORMAL
- en: Not all matrices are square. Shapes can be rectangular, too.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE114]*  *Here, `B` is 3×2 (3 rows, 2 columns).'
  prefs: []
  type: TYPE_NORMAL
- en: Block decomposition idea
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can think of large matrices as made of smaller blocks. This is common in
    linear algebra proofs and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE116]*  *This is the start of block matrix notation.*******  ***#### Try
    It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a 4×5 matrix with values 1–20 using `np.arange(1,21).reshape(4,5)`. Find
    its shape.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the middle row and last column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cut it into four 2×2 blocks. Can you reassemble them in a different order?****  ***###
    13\. Matrix Addition and Scalar Multiplication
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we understand matrix shapes and indexing, let’s practice two of the
    simplest but most important operations: adding matrices and scaling them with
    numbers (scalars). These operations extend the rules we already know for vectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Adding two matrices You can add two matrices if (and only if) they have the
    same shape. Addition happens entry by entry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE119]*  *Each element in `C` is the sum of corresponding elements in `A`
    and `B`.'
  prefs: []
  type: TYPE_NORMAL
- en: Scalar multiplication Multiplying a matrix by a scalar multiplies every entry
    by that number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE121]*  *Here, each element of `A` is tripled.'
  prefs: []
  type: TYPE_NORMAL
- en: Combining both operations We can mix addition and scaling, just like with vectors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE123]*  *This creates new matrices as linear combinations of others.'
  prefs: []
  type: TYPE_NORMAL
- en: Zero matrix A matrix of all zeros acts like “nothing happens” for addition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE125]*  *5.  Shape mismatch (what fails) If shapes don’t match, NumPy throws
    an error.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE127]*  *This shows why shape consistency matters.*****  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create two random 3×3 matrices with `np.random.randint(0,10,(3,3))` and add
    them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply a 4×4 matrix by `-1`. What happens to its entries?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute `3A + 2B` with the matrices from above. Compare with doing each step
    manually.****  ***### 14\. Matrix–Vector Product (Linear Combinations of Columns)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This lab introduces the matrix–vector product, one of the most important operations
    in linear algebra. Multiplying a matrix by a vector doesn’t just crunch numbers
    - it produces a new vector by combining the matrix’s columns in a weighted way.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: A simple matrix and vector
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '*Here, `A` has 2 columns, so we can multiply it by a 2D vector `x`.'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix–vector multiplication in NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE131]*  *Result: a 3D vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the result as linear combinations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Matrix `A` has two columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE133]*  *This matches `A·x`. In words: *multiply each column by the corresponding
    entry of `x` and then add them up*.'
  prefs: []
  type: TYPE_NORMAL
- en: Another example (geometry)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE135]*  *Here, `(1,3)` becomes `(2,3)`. The x-component was doubled, while
    y stayed the same.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualization of matrix action
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/6b4ad3db5bd6e132804e9f93324cad0f.png)*  *Red arrow = original
    vector, blue arrow = transformed vector.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Multiply
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix}1 & 0 \\ 0 & 1 \\ -1 & 2\end{bmatrix},\; x = [3,1] \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What’s the result?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Replace `B` with `[[0,-1],[1,0]]`. Multiply it by `(1,0)` and `(0,1)`. What
    geometric transformation does this represent?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a 4×4 identity matrix (`np.eye(4)`), try multiplying by any 4D vector. What
    do you observe?****  ***### 15\. Matrix–Matrix Product (Composition of Linear
    Steps)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Matrix–matrix multiplication is how we combine two linear transformations into
    one. Instead of applying one transformation, then another, we can multiply their
    matrices and get a single matrix that does both at once.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix–matrix multiplication in NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE139]*  *The result `C` is another 2×2 matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual computation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Each entry of `C` is computed as a row of A dotted with a column of B:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE141]*  *This should match `A·B`.'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric interpretation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s see how two transformations combine.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix `B` scales x by 2 and stretches y by 2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix `A` applies another linear transformation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, `C = A·B` does both in one step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE143]*  *The result is the same: applying `B` then `A` is equivalent to
    applying `C`.'
  prefs: []
  type: TYPE_NORMAL
- en: Non-square matrices
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Matrix multiplication also works for rectangular matrices, as long as the inner
    dimensions match.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE145]*  *Shape rule: `(2×3)·(3×2) = (2×2)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Associativity (but not commutativity)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Matrix multiplication is associative: `(A·B)·C = A·(B·C)`. But it’s not commutative:
    in general, `A·B ≠ B·A`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE147]*  *The two results are different.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Multiply
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix},\; B = \begin{bmatrix}0 &
    -1 \\ 1 & 0\end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What transformation does `A·B` represent?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a random 3×2 matrix and a 2×4 matrix. Multiply them. What shape is the
    result?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify with Python that `(A·B)·C = A·(B·C)` for some 3×3 random matrices.****  ***###
    16\. Identity, Inverse, and Transpose
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this lab, we’ll meet three special matrix operations and objects: the identity
    matrix, the inverse, and the transpose. These are the building blocks of matrix
    algebra, each with a simple meaning but deep importance.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Identity matrix The identity matrix is like the number `1` for matrices: multiplying
    by it changes nothing.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE150]*  *Both equal `A`.'
  prefs: []
  type: TYPE_NORMAL
- en: Transpose The transpose flips rows and columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE152]*  **   Original: 2×3'
  prefs: []
  type: TYPE_NORMAL
- en: 'Transpose: 3×2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometrically, transpose swaps the axes when vectors are viewed in row/column
    form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inverse The inverse matrix is like dividing by a number: multiplying a matrix
    by its inverse gives the identity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE154]*  *Both products are (approximately) the identity.'
  prefs: []
  type: TYPE_NORMAL
- en: Matrices that don’t have inverses Not every matrix is invertible. If a matrix
    is singular (determinant = 0), it has no inverse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE156]*  *Here, the second row is a multiple of the first, so `D` can’t
    be inverted.'
  prefs: []
  type: TYPE_NORMAL
- en: Transpose and inverse together For invertible matrices,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ (A^T)^{-1} = (A^{-1})^T \]
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check this numerically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE158]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a 4×4 identity matrix. Multiply it by any 4×1 vector. Does it change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a random 2×2 matrix with `np.random.randint`. Compute its inverse and check
    if multiplying gives identity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pick a rectangular 3×2 matrix. What happens when you try `np.linalg.inv`? Why?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute `(A.T).T` for some matrix `A`. What do you notice?****  ***### 17\.
    Symmetric, Diagonal, Triangular, and Permutation Matrices
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this lab, we’ll meet four important families of special matrices. They have
    patterns that make them easier to understand, compute with, and use in algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Symmetric matrices A matrix is symmetric if it equals its transpose: \(A =
    A^T\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE161]*  *Symmetric matrices appear in physics, optimization, and statistics
    (e.g., covariance matrices).'
  prefs: []
  type: TYPE_NORMAL
- en: Diagonal matrices A diagonal matrix has nonzero entries only on the main diagonal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE163]*  *Diagonal multiplication simply scales each coordinate separately.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Triangular matrices Upper triangular: all entries below the diagonal are zero.
    Lower triangular: all entries above the diagonal are zero.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE165]*  *These are important in solving linear systems (e.g., Gaussian
    elimination).'
  prefs: []
  type: TYPE_NORMAL
- en: Permutation matrices A permutation matrix rearranges the order of coordinates.
    Each row and each column has exactly one `1`, everything else is `0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE167]*  *Here, `P` cycles `(10,20,30)` into `(20,30,10)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking properties
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE169]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a random symmetric matrix by generating any matrix `M` and computing
    `(M + M.T)/2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a 4×4 diagonal matrix with diagonal entries `[2,4,6,8]` and multiply it
    by `[1,1,1,1]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a permutation matrix that swaps the first and last components of a 3D vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the identity matrix is diagonal, symmetric, upper triangular,
    and lower triangular all at once.****  ***### 18\. Trace and Basic Matrix Properties
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this lab, we’ll introduce the trace of a matrix and a few quick properties
    that often appear in proofs, algorithms, and applications. The trace is simple
    to compute but surprisingly powerful.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'What is the trace? The trace of a square matrix is the sum of its diagonal
    entries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \text{tr}(A) = \sum_i A_{ii} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE172]*  *Here, trace = \(2 + 4 + 6 = 12\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Trace is linear For matrices `A` and `B`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \text{tr}(A+B) = \text{tr}(A) + \text{tr}(B) \]
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{tr}(cA) = c \cdot \text{tr}(A) \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE174]*  *3.  Trace of a product One important property is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{tr}(AB) = \text{tr}(BA) \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE176]*  *Both are equal, even though `CD` and `DC` are different matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: Trace and eigenvalues The trace equals the sum of eigenvalues of a matrix (counting
    multiplicities).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE178]*  *The results should match (within rounding error).'
  prefs: []
  type: TYPE_NORMAL
- en: Quick invariants
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Trace doesn’t change under transpose: `tr(A) = tr(A.T)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trace doesn’t change under similarity transforms: `tr(P^-1 A P) = tr(A)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE180]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a 2×2 rotation matrix for 90°:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ R = \begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What is its trace? What does that tell you about its eigenvalues?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make a random 3×3 matrix and compare `tr(A)` with the sum of eigenvalues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test `tr(AB)` and `tr(BA)` with a rectangular matrix `A` (e.g. 2×3) and `B`
    (3×2). Do they still match?****  ***### 19\. Affine Transforms and Homogeneous
    Coordinates
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Affine transformations let us do more than just linear operations - they include
    translations (shifting points), which ordinary matrices can’t handle alone. To
    unify rotations, scalings, reflections, and translations, we use homogeneous coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Linear transformations vs affine transformations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A linear transformation can rotate, scale, or shear, but always keeps the origin
    fixed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An affine transformation allows translation as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, shifting every point by `(2,3)` is affine but not linear.
  prefs: []
  type: TYPE_NORMAL
- en: Homogeneous coordinates idea We add an extra coordinate (usually `1`) to vectors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A 2D point `(x,y)` becomes `(x,y,1)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 3D point `(x,y,z)` becomes `(x,y,z,1)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This trick lets us represent translations using matrix multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: 2D translation matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ T = \begin{bmatrix} 1 & 0 & t_x \\ 0 & 1 & t_y \\ 0 & 0 & 1 \end{bmatrix}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE183]*  *This shifts `(1,1)` to `(3,4)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Combining rotation and translation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A 90° rotation around the origin in 2D:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE185]*  *Now we can apply rotation and translation in one step.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualization of translation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/4f5db4b64133225a63bedd92cf26ad76.png)*  *You’ll see the red
    unit square moved to a blue unit square shifted by `(2,3)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Extending to 3D In 3D, homogeneous coordinates use 4×4 matrices. Translations,
    rotations, and scalings all fit the same framework.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE188]*  *This shifts `(1,2,3)` to `(6,0,6)`.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Build a scaling matrix in homogeneous coordinates that doubles both x and y,
    and apply it to `(1,1)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a 2D transform that rotates by 90° and then shifts by `(−2,1)`. Apply
    it to `(0,2)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In 3D, translate `(0,0,0)` by `(10,10,10)`. What homogeneous matrix did you
    use?****  ***### 20\. Computing with Matrices (Cost Counts and Simple Speedups)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Working with matrices is not just about theory - in practice, we care about
    how much computation it takes to perform operations, and how we can make them
    faster. This lab introduces basic cost analysis (counting operations) and demonstrates
    simple NumPy optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Counting operations (matrix–vector multiply)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If `A` is an \(m \times n\) matrix and `x` is an \(n\)-dimensional vector, computing
    `A·x` takes about \(m \times n\) multiplications and the same number of additions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE191]*  *Here the cost is \(3 \times 4 = 12\) multiplications + 12 additions.'
  prefs: []
  type: TYPE_NORMAL
- en: Counting operations (matrix–matrix multiply)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For an \(m \times n\) times \(n \times p\) multiplication, the cost is about
    \(m \times n \times p\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE193]*  *Here the cost is \(3 \times 4 \times 2 = 24\) multiplications
    + 24 additions.'
  prefs: []
  type: TYPE_NORMAL
- en: Timing with NumPy (vectorized vs loop)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NumPy is optimized in C and Fortran under the hood. Let’s compare matrix multiplication
    with and without vectorization.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE195]*  *The vectorized version should be thousands of times faster.'
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting tricks
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NumPy lets us avoid loops by broadcasting operations across entire rows or columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE197]*  *5.  Memory and data types'
  prefs: []
  type: TYPE_NORMAL
- en: For large computations, data type matters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE199]*  *Using `float32` instead of `float64` halves memory use and can
    speed up computation (at the cost of some precision).*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the cost of multiplying a 200×500 matrix with a 500×1000 matrix. How
    many multiplications are needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Time matrix multiplication for sizes 100, 500, 1000 in NumPy. How does the time
    scale?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with `float32` vs `float64` in NumPy. How do speed and memory change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Try broadcasting: multiply each column of a matrix by `[1,2,3,...]`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Matrix operations have predictable computational costs: `A·x` ~ \(m \times
    n\), `A·B` ~ \(m \times n \times p\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vectorized NumPy operations are vastly faster than Python loops.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Broadcasting and choosing the right data type are simple speedups every beginner
    should learn.*******************************  ***## Chapter 3\. Linear Systems
    and Elimination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 21\. From Equations to Matrices (Augmenting and Encoding)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Linear algebra often begins with solving systems of linear equations. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + 2y = 5 \\ 3x - y = 4 \end{cases} \]
  prefs: []
  type: TYPE_NORMAL
- en: Instead of juggling symbols, we can encode the entire system into a matrix.
    This is the key idea that lets computers handle thousands or millions of equations
    efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Write a system of equations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We’ll use this small example:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} 2x + y = 8 \\ -3x + 4y = -11 \end{cases} \]
  prefs: []
  type: TYPE_NORMAL
- en: Encode coefficients and constants
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Coefficient matrix \(A\): numbers multiplying variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Variable vector \(x\): unknowns `[x, y]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Constant vector \(b\): right-hand side.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE201]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE202]*  *So the system is \(A·x = b\).'
  prefs: []
  type: TYPE_NORMAL
- en: Augmented matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can bundle the system into one compact matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ [A|b] = \begin{bmatrix}2 & 1 & | & 8 \\ -3 & 4 & | & -11 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE203]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE204]*  *This format is useful for elimination algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Solving directly with NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE205]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE206]*  *Here NumPy solves the system using efficient algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking the solution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Always verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE207]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE208]*  *6.  Another example (3 variables)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + y + z = 6 \\ 2x - y + z = 3 \\ - x + 2y - z = 2 \end{cases}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE210]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Encode the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{cases} 2x - y = 1 \\ x + 3y = 7 \end{cases} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Write `A` and `b`, then solve.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For a 3×3 system, try creating a random coefficient matrix with `np.random.randint(-5,5,(3,3))`
    and a random `b`. Use `np.linalg.solve`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the constants `b` slightly and see how the solution changes. This introduces
    the idea of sensitivity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Systems of linear equations can be neatly written as \(A·x = b\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The augmented matrix \([A|b]\) is a compact way to set up elimination.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This matrix encoding transforms algebra problems into matrix problems - the
    gateway to all of linear algebra.****  ***### 22\. Row Operations (Legal Moves
    That Keep Solutions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When solving linear systems, we don’t want to change the solutions - just simplify
    the system into an easier form. This is where row operations come in. They are
    the “legal moves” we can do on an augmented matrix \([A|b]\) without changing
    the solution set.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE211]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Three legal row operations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Swap two rows \((R_i \leftrightarrow R_j)\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply a row by a nonzero scalar \((R_i \to c·R_i)\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace a row with itself plus a multiple of another row \((R_i \to R_i + c·R_j)\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These preserve the solution set.
  prefs: []
  type: TYPE_NORMAL
- en: Start with an augmented matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + 2y = 5 \\ 3x + 4y = 6 \end{cases} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE212]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE213]*  *3.  Row swap'
  prefs: []
  type: TYPE_NORMAL
- en: Swap row 0 and row 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE214]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE215]*  *4.  Multiply a row by a scalar'
  prefs: []
  type: TYPE_NORMAL
- en: Make the pivot in row 0 equal to 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE216]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE217]*  *5.  Add a multiple of another row'
  prefs: []
  type: TYPE_NORMAL
- en: Eliminate the first column of row 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE218]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE219]*  *Now the system is simpler: second row has only `y`.'
  prefs: []
  type: TYPE_NORMAL
- en: Solving from the new system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE220]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE221]*  *7.  Using NumPy step-by-step vs solver'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE222]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE223]*  *Both methods give the same solution.******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{cases} 2x + y = 7 \\ x - y = 1 \end{cases} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write its augmented matrix, then:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Swap rows.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale the first row.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Eliminate one variable.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a random 3×3 system with integers between -5 and 5\. Perform at least
    one of each row operation manually in code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with multiplying a row by `0`. What happens, and why is this not
    allowed as a legal operation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The three legal row operations are row swap, row scaling, and row replacement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These steps preserve the solution set while moving toward a simpler form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are the foundation of Gaussian elimination, the standard algorithm for
    solving linear systems.****  ***### 23\. Row-Echelon and Reduced Row-Echelon Forms
    (Target Shapes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When solving systems, our goal is to simplify the augmented matrix into a standard
    shape where the solutions are easy to read. These shapes are called row-echelon
    form (REF) and reduced row-echelon form (RREF).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE224]'
  prefs: []
  type: TYPE_PRE
- en: '*We’ll use NumPy for basic work and SymPy for exact RREF (since NumPy doesn’t
    have it built-in).*  *#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Row-Echelon Form (REF)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All nonzero rows are above any zero rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each leading entry (pivot) is to the right of the pivot in the row above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pivots are usually scaled to 1, but not strictly required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example system:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + 2y + z = 7 \\ 2x + 4y + z = 12 \\ 3x + 6y + 2z = 17 \end{cases}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE225]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE226]*  *Perform elimination manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE227]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE228]*  *Now the pivots move diagonally across the matrix - this is row-echelon
    form.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reduced Row-Echelon Form (RREF) In RREF, we go further:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Every pivot = 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every pivot is the only nonzero in its column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instead of coding manually, we’ll let SymPy handle it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE229]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE230]*  *SymPy shows the final canonical form.'
  prefs: []
  type: TYPE_NORMAL
- en: Reading solutions from RREF
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the RREF looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 0 & a & b \\ 0 & 1 & c & d \\ 0 & 0 & 0 & 0 \end{bmatrix}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: 'It means:'
  prefs: []
  type: TYPE_NORMAL
- en: The first two variables are leading (pivots).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third variable is free.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solutions can be written in terms of the free variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick example with free variables
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y + z = 3 \\ 2x + y - z = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE231]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE232]*  *Here, one column will not have a pivot → that variable is free.****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ 2x + 3y = 6, \quad 4x + 6y = 12 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Write the augmented matrix and compute its RREF. What does it tell you about
    solutions?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a random 3×4 matrix in NumPy. Use SymPy’s `Matrix.rref()` to compute
    its reduced form. Identify the pivot columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + 2y + 3z = 4, \quad 2x + 4y + 6z = 8 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Check if the equations are independent or multiples of each other by looking
    at the RREF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: REF organizes equations into a staircase shape.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RREF goes further, making each pivot the only nonzero in its column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These canonical forms make it easy to identify pivot variables, free variables,
    and the solution set structure.****  ***### 24\. Pivots, Free Variables, and Leading
    Ones (Reading Solutions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once a matrix is in row-echelon or reduced row-echelon form, the solutions to
    the system become visible. The key is identifying pivots, leading ones, and free
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE233]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: What are pivots?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A pivot is the first nonzero entry in a row (after elimination).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In RREF, pivots are scaled to `1` and are called leading ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pivot columns correspond to basic variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + y + z = 6 \\ 2x + 3y + z = 10 \end{cases} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE234]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE235]*  *3.  Interpreting the RREF'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose the RREF comes out as:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 0 & -2 & 4 \\ 0 & 1 & 1 & 2 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'This means:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pivot columns: 1 and 2 → variables \(x\) and \(y\) are basic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Free variable: \(z\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Equations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ x - 2z = 4, \quad y + z = 2 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Solution in terms of \(z\):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ x = 4 + 2z, \quad y = 2 - z, \quad z = z \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Coding the solution extraction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE236]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE237]*  *5.  Another example with infinitely many solutions'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + 2y + 3z = 4, \quad 2x + 4y + 6z = 8 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE238]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE239]*  *The second row becomes all zeros, showing redundancy. Pivot in
    column 1, free variables in columns 2 and 3.'
  prefs: []
  type: TYPE_NORMAL
- en: Solving underdetermined systems
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you have more variables than equations, expect free variables. Example:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y = 3 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE240]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE241]*  *Here, \(x = 3 - y\). Variable \(y\) is free.****  ***#### Try
    It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + y + z = 2, \quad y + z = 1 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute its RREF and identify pivot and free variables.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a random 3×4 system and compute its pivots. How many free variables do
    you get?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x - y = 0, \quad 2x - 2y = 0 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Verify that the system has infinitely many solutions and describe them in terms
    of a free variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pivots / leading ones mark the basic variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Free variables correspond to non-pivot columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solutions are written in terms of free variables, showing whether the system
    has a unique, infinite, or no solution.****  ***### 25\. Solving Consistent Systems
    (Unique vs. Infinite Solutions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we can spot pivots and free variables, we can classify systems of equations
    as having a unique solution or infinitely many solutions (assuming they’re consistent).
    In this lab, we’ll practice solving both types.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE242]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Unique solution example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y = 3, \quad 2x - y = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE243]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE244]*  *2.  Infinite solution example'
  prefs: []
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y + z = 2, \quad 2x + 2y + 2z = 4 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE245]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE246]*  *Only one pivot → two free variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Interpretation:'
  prefs: []
  type: TYPE_NORMAL
- en: \(x = 2 - y - z\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(y, z\) are free
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infinite solutions described by parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying consistency
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A system is consistent if the RREF does *not* have a row like:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ [0, 0, 0, c] \quad (c \neq 0) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Example consistent system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE247]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE248]*  *Example inconsistent system (no solution):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE249]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE250]*  *The second one ends with `[0,0,1]`, meaning contradiction (0 =
    1).'
  prefs: []
  type: TYPE_NORMAL
- en: Quick NumPy comparison
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For systems with unique solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE251]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE252]*  *For systems with infinite solutions, `np.linalg.solve` will fail,
    but SymPy handles parametric solutions.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Solve:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + y + z = 1, \quad 2x + 3y + z = 2 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is the solution unique or infinite?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check consistency of:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + 2y = 3, \quad 2x + 4y = 8 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Build a random 3×4 augmented matrix and compute its RREF. Identify:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does it have a unique solution, infinitely many, or none?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unique solution: pivot in every variable column.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Infinite solutions: free variables remain, system is still consistent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No solution: an inconsistent row appears.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding pivots and free variables gives a complete picture of the solution
    set.****  ***### 26\. Detecting Inconsistency (When No Solution Exists)
  prefs: []
  type: TYPE_NORMAL
- en: Not all systems of linear equations can be solved. Some are inconsistent, meaning
    the equations contradict each other. In this lab, we’ll learn how to recognize
    inconsistency using augmented matrices and RREF.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE253]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: An inconsistent system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + y = 2, \quad 2x + 2y = 5 \]
  prefs: []
  type: TYPE_NORMAL
- en: Notice the second equation looks like a multiple of the first, but the constant
    doesn’t match - contradiction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE254]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE255]*  *RREF gives:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 & 2 \\ 0 & 0 & 1 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: The last row means \(0 = 1\), so no solution exists.
  prefs: []
  type: TYPE_NORMAL
- en: A consistent system (for contrast)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + y = 2, \quad 2x + 2y = 4 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE256]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE257]*  *This reduces to one equation and a redundant row of zeros → infinitely
    many solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing inconsistency (2D case)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y = 2 \quad \text{and} \quad x + y = 3 \]
  prefs: []
  type: TYPE_NORMAL
- en: These are parallel lines that never meet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE258]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/5025c9114c6fb19aa93f8af5073b3f20.png)*  *The two lines are parallel
    → no solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting inconsistency automatically
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can scan the RREF for a row of the form \([0, 0, …, c]\) with \(c \neq 0\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE259]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE260]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Test the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + 2y = 4, \quad 2x + 4y = 10 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Write the augmented matrix and check if it’s inconsistent.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Build a random 2×3 augmented matrix with integer entries. Use `is_inconsistent`
    to check.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot two linear equations in 2D. Adjust constants to see when they intersect
    (consistent) vs when they are parallel (inconsistent).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A system is inconsistent if RREF contains a row like \([0,0,…,c]\) with \(c
    \neq 0\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometrically, this means the equations describe parallel lines (2D), parallel
    planes (3D), or higher-dimensional contradictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing inconsistency quickly saves time and avoids chasing impossible solutions.****  ***###
    27\. Gaussian Elimination by Hand (A Disciplined Procedure)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaussian elimination is the systematic way to solve linear systems using row
    operations. It transforms the augmented matrix into row-echelon form (REF) and
    then uses back substitution to find solutions. In this lab, we’ll walk step by
    step through the process.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE261]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Example system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + y + z = 6 \\ 2x + 3y + z = 14 \\ x + 2y + 3z = 14 \end{cases}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE262]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE263]*  *2.  Step 1: Get a pivot in the first column'
  prefs: []
  type: TYPE_NORMAL
- en: Make the pivot at (0,0) into 1 (it already is). Now eliminate below it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE264]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE265]*  *3.  Step 2: Pivot in the second column'
  prefs: []
  type: TYPE_NORMAL
- en: Make the pivot in row 1, col 1 equal to 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE266]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE267]*  *Now eliminate below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE268]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE269]*  *4.  Step 3: Pivot in the third column'
  prefs: []
  type: TYPE_NORMAL
- en: Make the bottom-right entry into 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE270]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE271]*  *At this point, the matrix is in row-echelon form (REF).'
  prefs: []
  type: TYPE_NORMAL
- en: Back substitution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now solve from the bottom up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE272]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE273]*  *6.  Verification'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE274]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE275]*  *The results match.*******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Solve:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ 2x + y = 5, \quad 4x - 6y = -2 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using Gaussian elimination manually in code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a random 3×4 augmented matrix and reduce it step by step, printing after
    each row operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare your manual elimination to SymPy’s RREF with `Matrix.rref()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Gaussian elimination is a disciplined sequence of row operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reduces the matrix to row-echelon form, from which back substitution is straightforward.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This method is the backbone of solving systems by hand and underlies many numerical
    algorithms.****  ***### 28\. Back Substitution and Solution Sets (Finishing Cleanly)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once Gaussian elimination reduces a system to row-echelon form (REF), the final
    step is back substitution. This means solving variables starting from the last
    equation and working upward. In this lab, we’ll practice both unique and infinite
    solution cases.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE276]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Unique solution example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y + z = 6, \quad 2y + 5z = -4, \quad z = 3 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Row-echelon form looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 & 1 & 6 \\ 0 & 2 & 5 & -4 \\ 0 & 0 & 1 & 3 \end{bmatrix}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Solve bottom-up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE277]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE278]*  *2.  Infinite solution example'
  prefs: []
  type: TYPE_NORMAL
- en: 'System:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x + y + z = 2, \quad 2x + 2y + 2z = 4 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'After elimination:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 & 1 & 2 \\ 0 & 0 & 0 & 0 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'This means:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Equation: \(x + y + z = 2\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Free variables: choose \(y\) and \(z\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let \(y = s, z = t\). Then:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x = 2 - s - t \]
  prefs: []
  type: TYPE_NORMAL
- en: 'So the solution set is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE279]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE280]*  *3.  Consistency check with RREF'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use SymPy to confirm solution sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE281]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE282]*  *The second row disappears, showing infinite solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: Encoding solution sets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: General solutions are often written in parametric vector form.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the infinite solution above:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ (x,y,z) = (2,0,0) + s(-1,1,0) + t(-1,0,1) \]
  prefs: []
  type: TYPE_NORMAL
- en: This shows the solution space is a plane in \(\mathbb{R}^3\).***  ***#### Try
    It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: 'Solve:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + 2y = 5, \quad y = 1 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do back substitution by hand and check with NumPy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Take the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ x + y + z = 1, \quad 2x + 2y + 2z = 2 \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Write its solution set in parametric form.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Use `Matrix.rref()` on a 3×4 random augmented matrix. Identify pivot and free
    variables, then describe the solution set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Back substitution is the cleanup step after Gaussian elimination.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reveals whether the system has a unique solution or infinitely many.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solutions can be expressed explicitly (unique case) or parametrically (infinite
    case).****  ***### 29\. Rank and Its First Meaning (Pivots as Information)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rank of a matrix tells us how much independent information it contains.
    Rank is one of the most important concepts in linear algebra because it connects
    to pivots, independence, dimension, and the number of solutions to a system.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE283]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Rank definition The rank is the number of pivots (leading ones) in the row-echelon
    form of a matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE284]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE285]*  **   The second row is a multiple of the first, so the rank is
    less than 3.'
  prefs: []
  type: TYPE_NORMAL
- en: Only two independent rows → rank = 2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank and solutions to \(A·x = b\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Consider:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} x + y + z = 3 \\ 2x + 2y + 2z = 6 \\ x - y = 0 \end{cases}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE286]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE287]*  **   If rank(A) = rank([A|b]) = number of variables → unique solution.'
  prefs: []
  type: TYPE_NORMAL
- en: If rank(A) = rank([A|b]) < number of variables → infinite solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If rank(A) < rank([A|b]) → no solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy comparison
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE288]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE289]*  *4.  Rank as “dimension of information”'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rank equals:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of independent rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of independent columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dimension of the column space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE290]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE291]*  *All columns are multiples → only one independent direction → rank
    = 1.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute the rank of:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 2 & 3 \\ 2 & 4 & 6 \\ 3 & 6 & 9 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What do you expect?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a random 4×4 matrix with `np.random.randint`. Compute its rank with both
    SymPy and NumPy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Test solution consistency using rank: build a system where rank(A) ≠ rank([A|b])
    and show it has no solution.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Rank = number of pivots = dimension of independent information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank reveals whether a system has no solution, one solution, or infinitely many.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank connects algebra (pivots) with geometry (dimension of subspaces).****  ***###
    30\. LU Factorization (Elimination Captured as L and U)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaussian elimination can be recorded in a neat factorization:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = LU \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(L\) is a lower triangular matrix (recording the multipliers we used)
    and \(U\) is an upper triangular matrix (the result of elimination). This is called
    LU factorization. It’s a powerful tool for solving systems efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE292]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Example matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE293]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE294]*  *2.  LU decomposition with SciPy'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE295]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE296]*  *Here, \(P\) handles row swaps (partial pivoting), \(L\) is lower
    triangular, and \(U\) is upper triangular.'
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the factorization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE297]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE298]*  *4.  Solving a system with LU'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to solve \(Ax = b\). Instead of working directly with \(A\),
    we solve in two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Solve \(Ly = Pb\) (forward substitution).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Solve \(Ux = y\) (back substitution).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE299]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE300]*  *5.  Efficiency advantage'
  prefs: []
  type: TYPE_NORMAL
- en: If we have to solve many systems with the same \(A\) but different \(b\), we
    only compute \(LU\) once, then reuse it. This saves a lot of computation.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy’s built-in rank-revealing factorization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While NumPy doesn’t have `lu` directly, it works seamlessly with SciPy. For
    large matrices, LU decomposition is the backbone of solvers like `np.linalg.solve`.****  ***####
    Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Compute LU decomposition for
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & 2 & 0 \\ 3 & 4 & 4 \\ 5 & 6 & 3 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Verify \(P·L·U = A\).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Solve \(Ax = b\) with
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ b = [3,7,8] \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using LU factorization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compare solving with LU factorization vs directly using `np.linalg.solve(A,b)`.
    Are the answers the same?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'LU factorization captures Gaussian elimination in matrix form: \(A = P·L·U\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows fast repeated solving of systems with different right-hand sides.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LU decomposition is a core technique in numerical linear algebra and the basis
    of many solvers.*******************************  ***## Chapter 4\. Vector Spaces
    and Subspaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 31\. Axioms of Vector Spaces (What “Space” Really Means)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vector spaces generalize what we’ve been doing with vectors and matrices. Instead
    of just \(\mathbb{R}^n\), a vector space is any collection of objects (vectors)
    where addition and scalar multiplication follow specific axioms (rules). In this
    lab, we’ll explore these axioms concretely with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE301]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vector space example: \(\mathbb{R}^2\)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s check two rules (axioms): closure under addition and scalar multiplication.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE302]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE303]*  *Both results are still in \(\mathbb{R}^2\).'
  prefs: []
  type: TYPE_NORMAL
- en: Zero vector and additive inverses
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Every vector space must contain a zero vector, and every vector must have an
    additive inverse.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE304]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE305]*  *3.  Distributive and associative properties'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check:'
  prefs: []
  type: TYPE_NORMAL
- en: \(a(u+v) = au + av\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \((a+b)u = au + bu\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE306]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE307]*  *Both equalities hold → distributive laws confirmed.'
  prefs: []
  type: TYPE_NORMAL
- en: A set that fails to be a vector space
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider only positive numbers with normal addition and scalar multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE308]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE309]*  *Negative results leave the set → not a vector space.'
  prefs: []
  type: TYPE_NORMAL
- en: Python helper to check axioms
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can quickly check if a set of vectors is closed under addition and scalar
    multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE310]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE311]*  *This small set is closed → it forms a vector space (a subspace
    of \(\mathbb{R}^2\)).*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that \(\mathbb{R}^3\) satisfies the vector space axioms using random
    vectors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test whether the set of all 2×2 matrices forms a vector space under normal addition
    and scalar multiplication.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find an example of a set that fails closure (e.g., integers under division).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A vector space is any set where addition and scalar multiplication satisfy 10
    standard axioms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These rules ensure consistent algebraic behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many objects beyond arrows in \(\mathbb{R}^n\) (like polynomials or matrices)
    are vector spaces too.****  ***### 32\. Subspaces, Column Space, and Null Space
    (Where Solutions Live)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A subspace is a smaller vector space sitting inside a bigger one. For matrices,
    two subspaces show up all the time:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Column space: all combinations of the matrix’s columns (possible outputs of
    \(Ax\)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Null space: all vectors \(x\) such that \(Ax = 0\) (inputs that vanish).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This lab explores both in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE312]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Column space basics
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & 2 \\ 2 & 4 \\ 3 & 6 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE313]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE314]*  **   The second column is a multiple of the first → column space
    has dimension 1.'
  prefs: []
  type: TYPE_NORMAL
- en: All outputs of \(Ax\) lie on a line in \(\mathbb{R}^3\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Null space basics
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE315]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE316]*  *The null space contains all \(x\) where \(Ax=0\). Here, the null
    space is 1-dimensional (vectors like \([-2,1]\)).'
  prefs: []
  type: TYPE_NORMAL
- en: A full-rank example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE317]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE318]*  **   Column space = all of \(\mathbb{R}^3\).'
  prefs: []
  type: TYPE_NORMAL
- en: Null space = only the zero vector.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometry link
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For \(A\) (rank 1, 2 columns):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Column space: line in \(\mathbb{R}^3\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Null space: line in \(\mathbb{R}^2\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Together they explain the system \(Ax = b\):'
  prefs: []
  type: TYPE_NORMAL
- en: If \(b\) is outside the column space, no solution exists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(b\) is inside, solutions differ by a vector in the null space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quick NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NumPy doesn’t directly give null space, but we can compute it with SVD.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE319]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE320]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Find the column space and null space of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 \\ 0 & 1 \\ 0 & 0 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How many dimensions does each have?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Generate a random 3×3 matrix. Compute its rank, column space, and null space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Solve \(Ax = b\) with
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & 2 \\ 2 & 4 \\ 3 & 6 \end{bmatrix}, \quad b = \begin{bmatrix}
    1 \\ 2 \\ 3 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and describe why it has infinitely many solutions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The column space = all possible outputs of a matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The null space = all inputs that map to zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These subspaces give the complete picture of what a matrix does.****  ***###
    33\. Span and Generating Sets (Coverage of a Space)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The span of a set of vectors is all the linear combinations you can make from
    them. If a set of vectors can “cover” a whole space, we call it a generating set.
    This lab shows how to compute and visualize spans.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE321]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Span in \(\mathbb{R}^2\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Two vectors that aren’t multiples span the whole plane.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE322]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE323]*  *Rank = 2 → the span of \(\{u,v\}\) is all of \(\mathbb{R}^2\).'
  prefs: []
  type: TYPE_NORMAL
- en: Dependent vectors (smaller span)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE324]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE325]*  *Rank = 1 → these vectors only span a line.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing a span
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s see what the span of two vectors looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE326]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/3be8bde45f66675a1034af9296fd97e5.png)*  *You’ll see a filled
    grid - the entire plane, because the two vectors are independent.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating set of a space
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For \(\mathbb{R}^3\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE327]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE328]*  *Rank = 3 → this set spans the whole space.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing if a vector is in the span
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Example: Is \([3,5]\) in the span of \([1,2]\) and \([2,1]\)?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE329]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE330]*  *If a solution exists, the target is in the span.*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Test if \([4,6]\) is in the span of \([1,2]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize the span of \([1,0,0]\) and \([0,1,0]\) in \(\mathbb{R}^3\). What
    does it look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a random 3×3 matrix. Use `rank()` to check if its columns span \(\mathbb{R}^3\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Span = all linear combinations of a set of vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Independent vectors span bigger spaces; dependent ones collapse to smaller spaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating sets are the foundation of bases and coordinate systems.****  ***###
    34\. Linear Independence and Dependence (No Redundancy vs. Redundancy)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of vectors is linearly independent if none of them can be written as a
    combination of the others. If at least one can, the set is dependent. This distinction
    tells us whether a set of vectors has redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE331]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Independent vectors example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE332]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE333]*  *Rank = 3, number of vectors = 3 → all independent.'
  prefs: []
  type: TYPE_NORMAL
- en: Dependent vectors example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE334]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE335]*  *Rank = 1, number of vectors = 3 → they’re dependent (multiples
    of each other).'
  prefs: []
  type: TYPE_NORMAL
- en: Checking dependence automatically
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A quick test: if rank < number of vectors → dependent.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE336]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE337]*  *4.  Solving for dependence relation'
  prefs: []
  type: TYPE_NORMAL
- en: If vectors are dependent, we can find coefficients \(c_1, c_2, …\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ c_1 v_1 + c_2 v_2 + … + c_k v_k = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: with some \(c_i \neq 0\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE338]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE339]*  *This shows the exact linear relation.'
  prefs: []
  type: TYPE_NORMAL
- en: Random example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE340]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE341]*  *Depending on the rank, the columns may be independent (rank =
    3) or dependent (rank < 3).*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Test if \([1,1,0], [0,1,1], [1,2,1]\) are independent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate 4 random vectors in \(\mathbb{R}^3\). Can they ever be independent?
    Why or why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the dependence relation for \([2,4], [3,6]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Independent set: no redundancy, each vector adds a new direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependent set: at least one vector is unnecessary (it lies in the span of others).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Independence is the key to defining basis and dimension.****  ***### 35\. Basis
    and Coordinates (Naming Every Vector Uniquely)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A basis is a set of independent vectors that span a space. It’s like choosing
    a coordinate system: every vector in the space can be expressed uniquely as a
    combination of basis vectors. In this lab, we’ll see how to find bases and compute
    coordinates relative to them.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE342]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Standard basis in \(\mathbb{R}^3\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE343]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE344]*  *These three independent vectors form the standard basis of \(\mathbb{R}^3\).
    Any vector like \([2,5,-1]\) can be expressed as'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 2e_1 + 5e_2 - 1e_3 \]
  prefs: []
  type: TYPE_NORMAL
- en: Finding a basis from dependent vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE345]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE346]*  *SymPy extracts independent columns automatically. This gives a
    basis for the column space.'
  prefs: []
  type: TYPE_NORMAL
- en: Coordinates relative to a basis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Suppose basis = \(\{ [1,0], [1,1] \}\). Express vector \([3,5]\) in this basis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE347]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE348]*  *So \([3,5] = 3·[1,0] + 2·[1,1]\).'
  prefs: []
  type: TYPE_NORMAL
- en: Basis change
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we switch to a different basis, coordinates change but the vector stays the
    same.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE349]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE350]*  *5.  Random example'
  prefs: []
  type: TYPE_NORMAL
- en: Generate 3 random vectors in \(\mathbb{R}^3\). Check if they form a basis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE351]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE352]*  *If rank = 3 → basis for \(\mathbb{R}^3\). Otherwise, only span
    a subspace.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Check if \([1,2], [3,4]\) form a basis of \(\mathbb{R}^2\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Express vector \([7,5]\) in that basis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create 4 random vectors in \(\mathbb{R}^3\). Find a basis for their span.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A basis = minimal set of vectors that span a space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every vector has a unique coordinate representation in a given basis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing bases changes the coordinates, not the vector itself.****  ***### 36\.
    Dimension (How Many Directions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dimension of a vector space is the number of independent directions it has.
    Formally, it’s the number of vectors in any basis of the space. Dimension tells
    us the “size” of a space in terms of degrees of freedom.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE353]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Dimension of \(\mathbb{R}^n\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dimension of \(\mathbb{R}^n\) is \(n\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE354]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE355]*  *Each standard unit vector adds one independent direction → dimension
    = 4.'
  prefs: []
  type: TYPE_NORMAL
- en: Dimension via rank
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The rank of a matrix equals the dimension of its column space.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE356]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE357]*  *Here, rank = 2 → the column space is a 2D plane inside \(\mathbb{R}^3\).'
  prefs: []
  type: TYPE_NORMAL
- en: Null space dimension
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The null space dimension is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{dim(Null(A))} = \#\text{variables} - \text{rank(A)} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE358]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE359]*  *This is the number of free variables in a solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Dimension in practice
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A line through the origin in \(\mathbb{R}^3\) has dimension 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A plane through the origin has dimension 2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The whole \(\mathbb{R}^3\) has dimension 3.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE360]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE361]*  *Result = 1 → they only generate a line.'
  prefs: []
  type: TYPE_NORMAL
- en: Random example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE362]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE363]*  *Rank may be 4 (full space) or smaller (collapsed).*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Find the dimension of the column space of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 0 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute the dimension of the null space of a 3×3 singular matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a 5×3 random matrix and compute its column space dimension.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Dimension = number of independent directions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Found by counting basis vectors (or rank).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensions describe lines (1D), planes (2D), and higher subspaces inside larger
    spaces.****  ***### 37\. Rank–Nullity Theorem (Dimensions That Add Up)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rank–nullity theorem ties together the dimension of the column space and
    the null space of a matrix. It says:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{rank}(A) + \text{nullity}(A) = \text{number of columns of } A \]
  prefs: []
  type: TYPE_NORMAL
- en: This is a powerful consistency check in linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE364]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple 3×3 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE365]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE366]*  *You should see that rank + nullity = 3, the number of columns.'
  prefs: []
  type: TYPE_NORMAL
- en: Full-rank case
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE367]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE368]*  **   Rank = 3 (all independent).'
  prefs: []
  type: TYPE_NORMAL
- en: Nullity = 0 (only zero solution to \(Bx=0\)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank + Nullity = 3 columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wide matrix (more columns than rows)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE369]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE370]*  *Here, nullity > 0 because there are more variables than independent
    equations.'
  prefs: []
  type: TYPE_NORMAL
- en: Verifying with random matrices
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE371]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE372]*  *Always consistent: rank + nullity = number of columns.'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric interpretation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For an \(m \times n\) matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: Rank(A) = dimension of outputs (column space).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nullity(A) = dimension of hidden directions that collapse to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, they use up all the “input dimensions” (n).****  ***#### Try It Yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute rank and nullity of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Check the theorem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a 2×4 random integer matrix. Confirm that rank + nullity = 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain why a tall full-rank \(5 \times 3\) matrix must have nullity = 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Rank + Nullity = number of columns (always true).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank measures independent outputs; nullity measures hidden freedom.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This theorem connects solutions of \(Ax=0\) with the structure of \(A\).****  ***###
    38\. Coordinates Relative to a Basis (Changing the “Ruler”)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we choose a basis, every vector can be described with coordinates relative
    to that basis. This is like changing the “ruler” we use to measure vectors. In
    this lab, we’ll practice computing coordinates in different bases.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE373]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Standard basis coordinates
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Vector \(v = [4,5]\) in \(\mathbb{R}^2\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE374]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE375]*  *Result is just \([4,5]\). Easy - the standard basis matches the
    components directly.'
  prefs: []
  type: TYPE_NORMAL
- en: Non-standard basis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Suppose basis = \(\{ [1,1], [1,-1] \}\). Express \(v = [4,5]\) in this basis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE376]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE377]*  *Now \(v\) has different coordinates.'
  prefs: []
  type: TYPE_NORMAL
- en: Changing coordinates back
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To reconstruct the vector from coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE378]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE379]*  *It matches the original \([4,5]\).'
  prefs: []
  type: TYPE_NORMAL
- en: Random basis in \(\mathbb{R}^3\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE380]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE381]*  *Any independent set of 3 vectors in \(\mathbb{R}^3\) works as
    a basis.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualization in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s compare coordinates in two bases.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE382]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/94e45721d91cdb2553ab97d801176784.png)*  *Even though the basis
    vectors look different, they span the same space, and \(v\) can be expressed in
    terms of them.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Express \([7,3]\) in the basis \(\{[2,0], [0,3]\}\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pick three independent random vectors in \(\mathbb{R}^3\). Write down the coordinates
    of \([1,2,3]\) in that basis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that reconstructing always gives the original vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A basis provides a coordinate system for vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coordinates depend on the basis, but the underlying vector doesn’t change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the basis is like changing the “ruler” you measure vectors with.****  ***###
    39\. Change-of-Basis Matrices (Moving Between Coordinate Systems)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we switch from one basis to another, we need a change-of-basis matrix.
    This matrix acts like a translator: it converts coordinates in one system to coordinates
    in another.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE383]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Two bases in \(\mathbb{R}^2\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s define:'
  prefs: []
  type: TYPE_NORMAL
- en: Basis \(B = \{ [1,0], [0,1] \}\) (standard basis).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basis \(C = \{ [1,1], [1,-1] \}\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE384]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Change-of-basis matrix'
  prefs: []
  type: TYPE_NORMAL
- en: The matrix that converts C-coordinates → standard coordinates is just \(C\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE385]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE386]*  *To go the other way (standard → C), we compute the inverse of
    \(C\).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE387]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE388]*  *3.  Converting coordinates'
  prefs: []
  type: TYPE_NORMAL
- en: Vector \(v = [4,5]\).
  prefs: []
  type: TYPE_NORMAL
- en: 'In standard basis:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE389]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE390]*  **   In basis \(C\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE391]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE392]*  **   Convert back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE393]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE394]*  *The reconstruction matches the original vector.'
  prefs: []
  type: TYPE_NORMAL
- en: General formula
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If \(P\) is the change-of-basis matrix from basis \(B\) to basis \(C\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ [v]_C = P^{-1}[v]_B \]
  prefs: []
  type: TYPE_NORMAL
- en: \[ [v]_B = P[v]_C \]
  prefs: []
  type: TYPE_NORMAL
- en: Here, \(P\) is the matrix of new basis vectors written in terms of the old basis.
  prefs: []
  type: TYPE_NORMAL
- en: Random 3D example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE395]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE396]*******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Convert \([7,3]\) from the standard basis to the basis \(\{[2,0], [0,3]\}\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pick a random invertible 3×3 matrix as a basis. Write a vector in that basis,
    then convert it back to the standard basis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prove that converting back and forth always returns the same vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A change-of-basis matrix converts coordinates between bases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going from new basis → old basis uses the basis matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Going from old basis → new basis requires its inverse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The vector itself never changes - only the description of it does.****  ***###
    40\. Affine Subspaces (Lines and Planes Not Through the Origin)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, subspaces always passed through the origin. But many familiar objects
    - like lines offset from the origin or planes floating in space - are affine subspaces.
    They look like subspaces, just shifted away from zero.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE397]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Line through the origin (a subspace)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '\[ L = \{ t \cdot [1,2] : t \in \mathbb{R} \} \]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE398]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/820aa9812ef15d19d89f6dd35fb5c244.png)*  *2.  Line not through
    the origin (affine subspace)'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ L'' = \{ [3,1] + t \cdot [1,2] : t \in \mathbb{R} \} \]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE399]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/a389be3ce91bf8359bc03aa4241d3597.png)*  *3.  Visualizing together'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE400]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/4ebc677422d3e91ca65dce027558c6c4.png)*  *One line passes through
    the origin, the other is parallel but shifted.'
  prefs: []
  type: TYPE_NORMAL
- en: Plane example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A plane in \(\mathbb{R}^3\):'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ P = \{ [1,2,3] + s[1,0,0] + t[0,1,0] : s,t \in \mathbb{R} \} \]'
  prefs: []
  type: TYPE_NORMAL
- en: This is an affine plane parallel to the \(xy\)-plane, but shifted.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE401]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/0d8f2fc986385977d5126403c4947c3c.png)*  *5.  Algebraic difference'
  prefs: []
  type: TYPE_NORMAL
- en: A subspace must satisfy closure under addition and scalar multiplication, and
    must include 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An affine subspace is just a subspace plus a fixed shift vector.****  ***####
    Try It Yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Define a line in \(\mathbb{R}^2\):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ (x,y) = (2,3) + t(1,-1) \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Plot it and compare with the subspace spanned by \((1,-1)\).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Construct an affine plane in \(\mathbb{R}^3\) shifted by vector \((5,5,5)\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Show algebraically that subtracting the shift point turns an affine subspace
    back into a regular subspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Subspaces go through the origin.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Affine subspaces are shifted copies of subspaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They’re essential in geometry, computer graphics, and optimization (e.g., feasible
    regions in linear programming).*******************************  ***## Chapter
    5\. Linear Transformation and Structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 41\. Linear Transformations (Preserving Lines and Sums)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A linear transformation is a function between vector spaces that preserves
    two key properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additivity: \(T(u+v) = T(u) + T(v)\)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Homogeneity: \(T(cu) = cT(u)\)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In practice, every linear transformation can be represented by a matrix. This
    lab will help you understand and experiment with linear transformations in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE402]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear transformation (scaling)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s scale vectors by 2 in the x-direction and by 0.5 in the y-direction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE403]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE404]*  *2.  Visualizing multiple vectors'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE405]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/b858df9d6265391c08ceee623c4fdf19.png)*  *Blue arrows are the
    original vectors; red arrows are the transformed ones. Notice how the transformation
    stretches and compresses consistently.'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation as a linear transformation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rotating vectors by \(\theta = 90^\circ\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE406]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE407]*  *The result is \([0,1]\), a perfect rotation.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking linearity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE408]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE409]*  *Both checks return `True`, proving \(T\) is linear.'
  prefs: []
  type: TYPE_NORMAL
- en: Non-linear example (for contrast)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A transformation like \(T(x,y) = (x^2, y)\) is not linear.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE410]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE411]*  *This fails the additivity test, so it’s not linear.*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Define a shear matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ S = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Apply it to vectors and plot before/after.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Verify linearity for rotation by 45°.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test whether \(T(x,y) = (x+y, y)\) is linear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A linear transformation preserves vector addition and scalar multiplication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every linear transformation can be represented by a matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualizing with arrows helps build geometric intuition: stretching, rotating,
    and shearing are all linear.****  ***### 42\. Matrix Representation of a Linear
    Map (Choosing a Basis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every linear transformation can be written as a matrix, but the exact matrix
    depends on the basis you choose. This lab shows how to build and interpret matrix
    representations.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE412]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: From transformation to matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose \(T: \mathbb{R}^2 \to \mathbb{R}^2\) is defined by:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ T(x,y) = (2x + y, \; x - y) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'To find its matrix in the standard basis, apply \(T\) to each basis vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE413]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE414]*  *Stacking results as columns gives the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE415]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE416]*  *2.  Using the matrix for computations'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE417]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE418]*  *Both methods match.'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix in a different basis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now suppose we use basis
  prefs: []
  type: TYPE_NORMAL
- en: \[ B = \{ [1,1], [1,-1] \} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'To represent \(T\) in this basis:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the change-of-basis matrix \(P\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute \(A_B = P^{-1}AP\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE419]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE420]*  *4.  Interpretation'
  prefs: []
  type: TYPE_NORMAL
- en: In standard basis, \(A\) tells us how \(T\) acts on unit vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In basis \(B\), \(A_B\) shows how \(T\) looks when described using different
    coordinates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random linear map in \(\mathbb{R}^3\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE421]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE422]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Define \(T(x,y) = (x+2y, 3x+y)\). Find its matrix in the standard basis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a new basis \(\{[2,0],[0,3]\}\). Compute the representation \(A_B\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that applying \(T\) directly to a vector matches computing via \(A_B\)
    and change-of-basis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A linear transformation becomes a matrix representation once a basis is chosen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columns of the matrix = images of basis vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the basis changes the matrix, but the transformation itself stays the
    same.****  ***### 43\. Kernel and Image (Inputs That Vanish; Outputs We Can Reach)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two fundamental subspaces describe any linear transformation \(T(x) = Ax\):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kernel (null space): all vectors \(x\) such that \(Ax = 0\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Image (column space): all possible outputs \(Ax\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kernel tells us what inputs collapse to zero, while the image tells us what
    outputs are achievable.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE423]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Kernel of a matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 4 & 6 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE424]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE425]*  *The null space basis shows dependencies among columns. Here, the
    kernel is 2-dimensional because columns are dependent.'
  prefs: []
  type: TYPE_NORMAL
- en: Image (column space)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE426]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE427]*  *The image is spanned by \([1,2]^T\). So all outputs of \(A\) are
    multiples of this vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kernel vectors → directions that map to zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image vectors → directions we can actually reach in the output space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(x \in \ker(A)\), then \(Ax = 0\). If \(b\) is not in the image, the system
    \(Ax = b\) has no solution.
  prefs: []
  type: TYPE_NORMAL
- en: Example with full rank
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE428]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE429]*  **   Kernel = only zero vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Image = all of \(\mathbb{R}^3\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy version (image via column space)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE430]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE431]*  *NumPy doesn’t compute null spaces directly, but we can use SVD
    for that if needed.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute kernel and image for
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What do they look like?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Take a random 3×4 matrix and find its kernel and image dimensions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Solve \(Ax = b\) for a matrix \(A\). Try two different \(b\): one inside the
    image, one outside. Observe the difference.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Kernel = inputs that vanish under \(A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image = outputs that can be reached by \(A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Together, they fully describe what a linear map does: what it “kills” and what
    it “produces.”****  ***### 44\. Invertibility and Isomorphisms (Perfectly Reversible
    Maps)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A matrix (or linear map) is invertible if it has an inverse \(A^{-1}\) such
    that
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^{-1}A = I \quad \text{and} \quad AA^{-1} = I \]
  prefs: []
  type: TYPE_NORMAL
- en: An invertible map is also called an isomorphism, because it preserves all information
    - every input has exactly one output, and every output comes from exactly one
    input.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE432]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Checking invertibility
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE433]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE434]*  *If determinant ≠ 0 → invertible.'
  prefs: []
  type: TYPE_NORMAL
- en: Computing the inverse
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE435]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE436]*  *3.  Solving systems with inverses'
  prefs: []
  type: TYPE_NORMAL
- en: 'For \(Ax = b\), if \(A\) is invertible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE437]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE438]*  *This is equivalent to `A.solve(b)` in SymPy or `np.linalg.solve`
    in NumPy.'
  prefs: []
  type: TYPE_NORMAL
- en: Non-invertible (singular) example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE439]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE440]*  *Determinant = 0 → no inverse. The matrix collapses space onto
    a line, losing information.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE441]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE442]*  *6.  Geometric intuition'
  prefs: []
  type: TYPE_NORMAL
- en: Invertible transformation = reversible (like rotating, scaling by nonzero).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-invertible transformation = squashing space into a lower dimension (like
    flattening a plane onto a line).*****  ***#### Try It Yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test whether
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: is invertible and find its inverse.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Compute the determinant of a 3×3 random integer matrix. If it’s nonzero, find
    its inverse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a singular 3×3 matrix (make one row a multiple of another). Confirm it
    has no inverse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Invertible matrix ↔︎ isomorphism: perfectly reversible, no information lost.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant ≠ 0 → invertible; determinant = 0 → singular.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inverses are useful conceptually, but in computation we usually solve systems
    directly instead of calculating \(A^{-1}\).****  ***### 45\. Composition, Powers,
    and Iteration (Doing It Again and Again)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear transformations can be chained together. Applying one after another is
    called composition, and in matrix form this becomes multiplication. Repeated application
    of the same transformation leads to powers of a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE443]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Composition of transformations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose we have two linear maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '\(T_1\): rotate by 90°'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(T_2\): scale x by 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE444]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE445]*  *Applying the composite matrix is equivalent to applying both maps
    in sequence.'
  prefs: []
  type: TYPE_NORMAL
- en: Verifying with a vector
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE446]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE447]*  *Both results are the same → composition = matrix multiplication.'
  prefs: []
  type: TYPE_NORMAL
- en: Powers of a matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeatedly applying a transformation corresponds to matrix powers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: scaling by 2.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE448]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE449]*  *Each step doubles the scaling effect.'
  prefs: []
  type: TYPE_NORMAL
- en: Iteration dynamics
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s iterate a transformation many times and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE450]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE451]*  *Each step shrinks the vector → iteration can reveal stability.'
  prefs: []
  type: TYPE_NORMAL
- en: Random example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE452]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE453]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create two transformations: reflection across x-axis and scaling by 3\. Compose
    them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a shear matrix and compute \(A^5\). What happens to a vector after repeated
    application?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with a rotation matrix raised to higher powers. What cycle do you
    see?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Composition of linear maps = matrix multiplication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Powers of a matrix represent repeated application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iteration reveals long-term dynamics: shrinking, growing, or oscillating behavior.****  ***###
    46\. Similarity and Conjugation (Same Action, Different Basis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two matrices \(A\) and \(B\) are called similar if there exists an invertible
    matrix \(P\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ B = P^{-1} A P \]
  prefs: []
  type: TYPE_NORMAL
- en: This means \(A\) and \(B\) represent the same linear transformation, but in
    different bases. This lab explores similarity and why it matters.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE454]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Example with a change of basis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE455]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE456]*  *Here, \(A\) and \(B\) are similar: they describe the same transformation
    in different coordinates.'
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvalues stay the same
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similarity preserves eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE457]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE458]*  *Both matrices have the same eigenvalues, even though their entries
    differ.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarity and diagonalization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a matrix is diagonalizable, there exists \(P\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ D = P^{-1} A P \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(D\) is diagonal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE459]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE460]*  *Diagonalization is a special case of similarity, where the new
    matrix is as simple as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE461]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE462]*  *Here, eigenvectors form the change-of-basis matrix \(P\).'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric interpretation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similar matrices = same transformation, different “ruler” (basis).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagonalization = finding a ruler that makes the transformation look like pure
    stretching along axes.****  ***#### Try It Yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and find a matrix \(P\) that gives a similar \(B\).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Show that two similar matrices have the same determinant and trace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a random 3×3 matrix, check if it is diagonalizable using SymPy’s `.diagonalize()`
    method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Similarity = same linear map, different basis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar matrices share eigenvalues, determinant, and trace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagonalization is the simplest similarity form, making repeated computations
    (like powers) much easier.****  ***### 47\. Projections and Reflections (Idempotent
    and Involutive Maps)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two very common geometric linear maps are projections and reflections. They
    show up in graphics, physics, and optimization.
  prefs: []
  type: TYPE_NORMAL
- en: A projection squashes vectors onto a subspace (like dropping a shadow).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A reflection flips vectors across a line or plane (like a mirror).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE463]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Projection onto a line
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If we want to project onto the line spanned by \(u\), the projection matrix
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ P = \frac{uu^T}{u^T u} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE464]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE465]*  *Apply projection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE466]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE467]*  *2.  Visualization of projection'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE468]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/96d5f7fe73dc68f2b7bc52a6d4043832.png)*  *The projection is the
    closest point on the line to the original vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Reflection across a line
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The reflection matrix across the line spanned by \(u\) is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ R = 2P - I \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE469]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE470]*  *4.  Checking algebraic properties'
  prefs: []
  type: TYPE_NORMAL
- en: 'Projection: \(P^2 = P\) (idempotent).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reflection: \(R^2 = I\) (involutive).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE471]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE472]*  *5.  Projection in higher dimensions'
  prefs: []
  type: TYPE_NORMAL
- en: Project onto the plane spanned by two vectors in \(\mathbb{R}^3\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE473]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE474]******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Project \([4,5]\) onto the x-axis and verify the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reflect \([1,2]\) across the line \(y=x\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a random 3D vector and project it onto the plane spanned by \([1,1,0]\)
    and \([0,1,1]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Projection: idempotent (\(P^2 = P\)), finds the closest vector in a subspace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reflection: involutive (\(R^2 = I\)), flips across a line/plane but preserves
    lengths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both are simple but powerful examples of linear transformations with clear geometry.****  ***###
    48\. Rotations and Shear (Geometric Intuition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two transformations often used in geometry, graphics, and physics are rotations
    and shears. Both are linear maps, but they behave differently:'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation preserves lengths and angles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shear preserves area (in 2D) but distorts shapes, turning squares into parallelograms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE475]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The rotation matrix by angle \(\theta\) is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ R(\theta) = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta
    \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE476]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE477]*  *2.  Visualizing rotation'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE478]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/549924f5e5024e5a8c4b9b284dbdcc79.png)*  *The vector rotates
    counterclockwise by 45°.'
  prefs: []
  type: TYPE_NORMAL
- en: Shear in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A shear along the x-axis by factor \(k\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ S = \begin{bmatrix} 1 & k \\ 0 & 1 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE479]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE480]*  *4.  Visualizing shear'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE481]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/21caaab0832fcb4f9abc360249d10585.png)*  *The shear moves the
    vector sideways, distorting its angle.'
  prefs: []
  type: TYPE_NORMAL
- en: Properties check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rotation preserves length:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE482]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE483]*  **   Shear preserves area (determinant = 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE484]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE485]******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Rotate \([1,0]\) by 90° and check it becomes \([0,1]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply shear with \(k=2\) to a square (points \((0,0),(1,0),(1,1),(0,1)\)) and
    plot before/after.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Combine rotation and shear: apply shear first, then rotation. What happens?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Rotation: length- and angle-preserving, determinant = 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shear: shape-distorting but area-preserving, determinant = 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both are linear maps that provide geometric intuition and real-world modeling
    tools.****  ***### 49\. Rank and Operator Viewpoint (Rank Beyond Elimination)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rank of a matrix tells us how much “information” a linear map carries. Algebraically,
    it is the dimension of the image (column space). Geometrically, it measures how
    many independent directions survive the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the operator viewpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: A matrix \(A\) is not just a table of numbers - it is a linear operator that
    maps vectors to other vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rank is the dimension of the output space that \(A\) actually reaches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE486]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Rank via elimination (SymPy)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE487]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE488]*  *Here, the second row is a multiple of the first → less independence
    → rank < 3.'
  prefs: []
  type: TYPE_NORMAL
- en: Rank via NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE489]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE490]*  *3.  Operator viewpoint'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply \(A\) to random vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE491]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE492]*  *Even though we started in 3D, all outputs lie in a plane in \(\mathbb{R}^3\).
    That’s why rank = 2.'
  prefs: []
  type: TYPE_NORMAL
- en: Full rank vs reduced rank
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Full rank: the transformation preserves dimension (no collapse).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reduced rank: the transformation collapses onto a lower-dimensional subspace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example full-rank:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE493]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE494]*  *5.  Connection to nullity'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rank-nullity theorem:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{rank}(A) + \text{nullity}(A) = \text{number of columns of } A \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Check with SymPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE495]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE496]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Take
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and compute its rank. Why is it 1?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For a random 4×4 matrix, use `np.linalg.matrix_rank` to check if it’s invertible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify rank-nullity theorem for a 3×5 random integer matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Rank = dimension of the image (how many independent outputs a transformation
    has).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Operator viewpoint: rank shows how much of the input space survives after transformation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rank-nullity links the image and kernel - together they fully describe a linear
    operator.****  ***### 50\. Block Matrices and Block Maps (Divide and Conquer Structure)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes matrices can be arranged in blocks (submatrices). Treating a big matrix
    as smaller pieces helps simplify calculations, especially in systems with structure
    (networks, coupled equations, or partitioned variables).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE497]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Constructing block matrices
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can build a block matrix from smaller pieces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE498]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE499]*  *2.  Block multiplication'
  prefs: []
  type: TYPE_NORMAL
- en: 'If a matrix is partitioned into blocks, multiplication follows block rules:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} A & B \\ C & D \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}
    = \begin{bmatrix} Ax + By \\ Cx + Dy \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE500]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE501]*  *Here the vector is split into blocks \([x,y]\).'
  prefs: []
  type: TYPE_NORMAL
- en: Block diagonal matrices
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Block diagonal = independent subproblems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE502]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE503]*  *Applying this matrix acts separately on each block - like running
    two smaller transformations in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: Inverse of block diagonal
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The inverse of a block diagonal is just the block diagonal of inverses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE504]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE505]*  *5.  Practical example - coupled equations'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have two independent systems:'
  prefs: []
  type: TYPE_NORMAL
- en: 'System 1: \(Ax = b\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'System 2: \(Cy = d\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can represent both together:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} A & 0 \\ 0 & C \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}
    = \begin{bmatrix} b \\ d \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: This shows how block matrices organize multiple systems in one big equation.****  ***####
    Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Build a block diagonal matrix with three 2×2 blocks. Apply it to a vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify block multiplication rule by manually computing \(Ax + By\) and \(Cx
    + Dy\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write two small systems of equations and combine them into one block system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Block matrices let us break down big systems into smaller parts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Block diagonal matrices = independent subsystems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking in blocks simplifies algebra, programming, and numerical computation.*******************************  ***##
    Chapter 6\. Determinants and volume
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 51\. Areas, Volumes, and Signed Scale Factors (Geometric Entry Point)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The determinant of a matrix has a deep geometric meaning: it tells us how a
    linear transformation scales area (in 2D), volume (in 3D), or higher-dimensional
    content. It can also flip orientation (sign).'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE506]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Determinant in 2D (area scaling)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s take a matrix that stretches and shears:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE507]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE508]*  *The determinant = 1 → areas are preserved, even though the shape
    is distorted.'
  prefs: []
  type: TYPE_NORMAL
- en: Unit square under transformation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Transform the square with corners \((0,0),(1,0),(1,1),(0,1)\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE509]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE510]*  *The area of the transformed shape equals \(|\det(A)|\).'
  prefs: []
  type: TYPE_NORMAL
- en: Determinant in 3D (volume scaling)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE511]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE512]*  *\(\det(B)=3\) means that volumes are scaled by 3.'
  prefs: []
  type: TYPE_NORMAL
- en: Negative determinant = orientation flip
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE513]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE514]*  *The determinant = -1 → area preserved but orientation flipped
    (like a mirror reflection).'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE515]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE516]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Take
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 3 & 0 \\ 0 & 2 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and compute the determinant. Verify it scales areas by 6.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Build a 3×3 shear matrix and check how it affects volume.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test a reflection matrix and confirm that the determinant is negative.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinant measures how a linear map scales area, volume, or hypervolume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Positive determinant = preserves orientation; negative = flips it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Magnitude of determinant = scaling factor of geometric content.****  ***###
    52\. Determinant via Linear Rules (Multilinearity, Sign, Normalization)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The determinant isn’t just a formula; it’s defined by three elegant rules that
    make it unique. These rules capture its geometric meaning as a volume-scaling
    factor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multilinearity: Linear in each row (or column).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sign Change: Swapping two rows flips the sign.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Normalization: The determinant of the identity matrix is 1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE517]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Multilinearity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If one row is scaled, the determinant scales the same way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE518]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE519]*  *You’ll see `det(B) = 2 * det(A)`.'
  prefs: []
  type: TYPE_NORMAL
- en: Sign change by row swap
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE520]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE521]*  *Swapping rows flips the sign of the determinant.'
  prefs: []
  type: TYPE_NORMAL
- en: Normalization rule
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE522]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE523]*  *The determinant of the identity is always 1 - this fixes the scaling
    baseline.'
  prefs: []
  type: TYPE_NORMAL
- en: Combining rules (example in 3×3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE524]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE525]*  *Here, rows are linearly dependent, so the determinant is 0 - consistent
    with multilinearity (since one row can be written as a combo of others).'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE526]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE527]*  *Both SymPy and NumPy confirm the same result.*****  ***#### Try
    It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Scale a row of a 3×3 matrix by 3\. Confirm the determinant scales by 3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Swap two rows twice in a row - does the determinant return to its original value?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute determinant of a triangular matrix. What pattern do you see?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinant is defined by multilinearity, sign change, and normalization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These rules uniquely pin down the determinant’s behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every formula (cofactor expansion, row-reduction method, etc.) comes from these
    core principles.****  ***### 53\. Determinant and Row Operations (How Each Move
    Changes det)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Row operations are at the heart of Gaussian elimination, and the determinant
    has simple, predictable reactions to them. Understanding these reactions gives
    both computational shortcuts and geometric intuition.
  prefs: []
  type: TYPE_NORMAL
- en: The Three Key Rules
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Row swap: Swapping two rows flips the sign of the determinant.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Row scaling: Multiplying a row by a scalar \(c\) multiplies the determinant
    by \(c\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Row replacement: Adding a multiple of one row to another leaves the determinant
    unchanged.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE528]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Row swap
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE529]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE530]*  *The result flips sign.'
  prefs: []
  type: TYPE_NORMAL
- en: Row scaling
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE531]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE532]*  *Determinant is multiplied by 2.'
  prefs: []
  type: TYPE_NORMAL
- en: Row replacement (no change)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE533]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE534]*  *Determinant stays the same.'
  prefs: []
  type: TYPE_NORMAL
- en: Triangular form shortcut
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since elimination only uses row replacement (which doesn’t change the determinant)
    and row swaps/scales (which we can track), the determinant of a triangular matrix
    is just the product of its diagonal entries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE535]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE536]*  *5.  NumPy confirmation'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE537]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE538]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Take
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 2 & 3 \\ 4 & 6 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and scale the second row by \(\tfrac{1}{2}\). Compare determinants before and
    after.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Gaussian elimination on a 3×3 matrix, and track how each row operation changes
    the determinant.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute determinant by reducing to triangular form and compare with SymPy’s
    `.det()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinant reacts predictably to row operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Row replacement is “safe” (no change), scaling multiplies by the factor, and
    swapping flips the sign.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This makes elimination not just a solving tool, but also a method to compute
    determinants efficiently.****  ***### 54\. Triangular Matrices and Product of
    Diagonals (Fast Wins)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For triangular matrices (upper or lower), the determinant is simply the product
    of the diagonal entries. This rule is one of the biggest shortcuts in linear algebra
    - no expansion or elimination needed.
  prefs: []
  type: TYPE_NORMAL
- en: Why It Works
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Triangular matrices already look like the end result of Gaussian elimination.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since row replacement operations don’t change the determinant, what’s left is
    just the product of the diagonal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE539]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Upper triangular example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE540]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE541]*  *Both values match exactly.'
  prefs: []
  type: TYPE_NORMAL
- en: Lower triangular example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE542]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE543]*  *3.  Diagonal matrix (special case)'
  prefs: []
  type: TYPE_NORMAL
- en: For diagonal matrices, determinant = product of diagonal entries directly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE544]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE545]*  *4.  NumPy version'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE546]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE547]*  *5.  Quick elimination to triangular form'
  prefs: []
  type: TYPE_NORMAL
- en: Even for non-triangular matrices, elimination reduces them to triangular form,
    where this rule applies.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE548]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE549]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the determinant of a 4×4 diagonal matrix quickly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that triangular matrices with a zero on the diagonal always have determinant
    0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use SymPy to check that elimination to triangular form preserves determinant
    (except for swaps/scales).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For triangular (and diagonal) matrices:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \det(A) = \prod_{i} a_{ii} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This shortcut makes determinant computation trivial.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaussian elimination leverages this fact: once reduced to triangular form,
    the determinant is just the product of pivots (with sign adjustments for swaps).****  ***###
    55\. det(AB) = det(A)det(B) (Multiplicative Magic)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the most elegant properties of determinants is multiplicativity:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \det(AB) = \det(A)\,\det(B) \]
  prefs: []
  type: TYPE_NORMAL
- en: This rule is powerful because it connects algebra (matrix multiplication) with
    geometry (volume scaling).
  prefs: []
  type: TYPE_NORMAL
- en: Geometric Intuition
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If \(A\) scales volumes by factor \(\det(A)\), and \(B\) scales them by \(\det(B)\),
    then applying \(B\) followed by \(A\) scales volumes by \(\det(A)\det(B)\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This property works in all dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE550]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 2×2 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE551]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE552]*  *The two results match.'
  prefs: []
  type: TYPE_NORMAL
- en: 3×3 random matrix check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE553]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE554]*  *3.  Special cases'
  prefs: []
  type: TYPE_NORMAL
- en: If \(\det(A)=0\), then \(\det(AB)=0\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\det(A)=\pm1\), it acts like a “volume-preserving” transformation (rotation/reflection).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE555]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE556]*  *Both are 0.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE557]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE558]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Construct two triangular matrices and verify multiplicativity (diagonal products
    multiply too).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the property with an orthogonal matrix \(Q\) (\(\det(Q)=\pm 1\)). What
    happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try with one matrix singular - confirm the product is always singular.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinant is multiplicative, not additive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\det(AB) = \det(A)\det(B)\) is a cornerstone identity in linear algebra.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This property connects geometry (volume scaling) with algebra (matrix multiplication).****  ***###
    56\. Invertibility and Zero Determinant (Flat vs. Full Volume)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The determinant gives a quick test for invertibility:'
  prefs: []
  type: TYPE_NORMAL
- en: If \(\det(A) \neq 0\), the matrix is invertible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\det(A) = 0\), the matrix is singular (non-invertible).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geometrically:'
  prefs: []
  type: TYPE_NORMAL
- en: Nonzero determinant → transformation keeps full dimension (no collapse).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero determinant → transformation flattens space into a lower dimension (volume
    = 0).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE559]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Invertible example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE560]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE561]*  *The determinant is nonzero → invertible.'
  prefs: []
  type: TYPE_NORMAL
- en: Singular example (zero determinant)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE562]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE563]*  *Since the second row is a multiple of the first, determinant =
    0 → no inverse.'
  prefs: []
  type: TYPE_NORMAL
- en: Solving systems with determinant check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If \(\det(A)=0\), the system \(Ax=b\) may have no solutions or infinitely many.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE564]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE565]*  *SymPy indicates inconsistency or multiple solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: Higher-dimensional example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE566]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE567]*  *Diagonal entries all nonzero → invertible.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE568]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE569]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Build a 3×3 matrix with determinant 0 by making one row a multiple of another.
    Confirm singularity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a random 4×4 matrix and check whether it’s invertible using `.det()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test if two different 2×2 matrices are invertible, then multiply them together
    - is the product invertible too?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: \(\det(A) \neq 0 \implies\) invertible (full volume).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\det(A) = 0 \implies\) singular (space collapsed).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant gives both algebraic and geometric insight into when a matrix is
    reversible.****  ***### 57\. Cofactor Expansion (Laplace’s Method)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cofactor expansion is a systematic way to compute determinants using minors.
    It’s not efficient for large matrices, but it reveals the recursive structure
    of determinants.
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For an \(n \times n\) matrix \(A\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ \det(A) = \sum_{j=1}^{n} (-1)^{i+j} a_{ij} \det(M_{ij}) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: \(i\) = chosen row (or column),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(M_{ij}\) = minor matrix after removing row \(i\), column \(j\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE570]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 2×2 case (base rule)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE571]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE572]*  *Formula: \(\det(A) = ad - bc\).'
  prefs: []
  type: TYPE_NORMAL
- en: 3×3 example using cofactor expansion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE573]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE574]*  *Let’s compute manually along the first row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE575]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE576]*  *Both match (here = 0 because rows are dependent).'
  prefs: []
  type: TYPE_NORMAL
- en: Expansion along different rows/columns
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The result is the same no matter which row/column you expand along.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE577]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE578]*  *4.  Larger example (4×4)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE579]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE580]*  *SymPy handles it directly, but conceptually it’s still the same
    recursive expansion.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy vs SymPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE581]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE582]******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute a 3×3 determinant manually using cofactor expansion and confirm with
    `.det()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand along a different row and check that the result is unchanged.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a 4×4 diagonal matrix and expand it - what simplification do you notice?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Cofactor expansion defines determinant recursively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Works on any row or column, with consistent results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important for proofs and theory, though not practical for computation on large
    matrices.****  ***### 58\. Permutations and Sign (The Combinatorial Core)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The determinant can also be defined using permutations of indices. This looks
    abstract, but it’s the most fundamental definition:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \det(A) = \sum_{\sigma \in S_n} \text{sgn}(\sigma) \prod_{i=1}^n a_{i,\sigma(i)}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: \(S_n\) = set of all permutations of \(\{1,\dots,n\}\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\text{sgn}(\sigma)\) = +1 if the permutation is even, -1 if odd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each term = one product of entries, one from each row and column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This formula explains why determinants mix signs, why row swaps flip the determinant,
    and why dependence kills it.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE583]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Determinant by permutation expansion (3×3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE584]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE585]*  *Both results ≈ 0, since rows are dependent.'
  prefs: []
  type: TYPE_NORMAL
- en: Count permutations
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For \(n=3\), there are \(3! = 6\) terms:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \det(A) = a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} -
    a_{13}a_{22}a_{31} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} \]
  prefs: []
  type: TYPE_NORMAL
- en: You can see the alternating signs explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Verification with SymPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE586]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE587]*  *Matches the permutation expansion.'
  prefs: []
  type: TYPE_NORMAL
- en: Growth of terms
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2×2 → 2 terms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3×3 → 6 terms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4×4 → 24 terms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(n\) → \(n!\) terms (factorial growth!)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is why cofactor or LU is preferred computationally.**  **#### Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Write out the 2×2 permutation formula explicitly and check it equals \(ad -
    bc\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand a 3×3 determinant by hand using the six terms.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the code to count how many multiplications are required for a 5×5 matrix
    using the permutation definition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinant = signed sum over all permutations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signs come from permutation parity (even/odd swaps).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This definition is the combinatorial foundation that unifies all determinant
    properties.***  ***### 59\. Cramer’s Rule (Solving with Determinants, and When
    Not to Use It)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cramer’s Rule gives an explicit formula for solving a system of linear equations
    \(Ax = b\) using determinants. It is elegant but inefficient for large systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'For \(A \in \mathbb{R}^{n \times n}\) with \(\det(A) \neq 0\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x_i = \frac{\det(A_i)}{\det(A)} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(A_i\) is \(A\) with its \(i\)-th column replaced by \(b\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE588]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple 2×2 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Solve:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{cases} 2x + y = 5 \\ x - y = 1 \end{cases} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE589]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE590]*  *Both give the same solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 3×3 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE591]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE592]*  *3.  NumPy version (inefficient but illustrative)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE593]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE594]*  *4.  Why not use it in practice?'
  prefs: []
  type: TYPE_NORMAL
- en: Requires computing \(n+1\) determinants.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant computation via cofactor expansion is factorial-time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaussian elimination or LU is far more efficient.***  ***#### Try It Yourself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solve a 3×3 system using Cramer’s Rule and confirm with `A.solve(b)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try Cramer’s Rule when \(\det(A)=0\). What happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare runtime of Cramer’s Rule vs LU for a random 5×5 matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Cramer’s Rule gives explicit formulas for solutions using determinants.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beautiful for theory, useful for small cases, but not computationally practical.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It highlights the deep connection between determinants and solving linear systems.****  ***###
    60\. Computing Determinants in Practice (Use LU, Mind Stability)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While definitions like cofactor expansion and permutations are beautiful, they
    are too slow for large matrices. In practice, determinants are computed using
    row reduction or LU decomposition, with careful attention to numerical stability.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE595]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Cofactor expansion is too slow
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE596]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE597]*  *This works for 3×3, but complexity grows factorially.'
  prefs: []
  type: TYPE_NORMAL
- en: Determinant via triangular form (LU decomposition)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LU decomposition factorizes \(A = LU\), where \(L\) is lower triangular and
    \(U\) is upper triangular. Determinant = product of diagonals of \(U\), up to
    sign corrections for row swaps.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE598]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE599]*  *3.  NumPy efficient method'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE600]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE601]*  *NumPy uses optimized routines (LAPACK under the hood).'
  prefs: []
  type: TYPE_NORMAL
- en: Large random matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE602]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE603]*  *Computes quickly even for larger matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: Stability issues
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Determinants of large or ill-conditioned matrices can suffer from floating-point
    errors. For example, if rows are nearly dependent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE604]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE605]*  *The result may not be exactly 0 due to floating-point approximations.*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the determinant of a random 10×10 matrix with `np.linalg.det`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare results between SymPy (exact rational arithmetic) and NumPy (floating-point).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test determinant of a nearly singular matrix - notice numerical instability.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Determinants in practice are computed with LU decomposition or equivalent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always be mindful of numerical stability - small errors matter when determinant
    ≈ 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For exact answers (small cases), use symbolic tools like SymPy; for speed, use
    NumPy.*******************************  ***## Chapter 7\. Eigenvalues, Eigenvectors,
    and Dynamics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 61\. Eigenvalues and Eigenvectors (Directions That Stay Put)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An eigenvector of a matrix \(A\) is a special vector that doesn’t change direction
    when multiplied by \(A\). Instead, it only gets stretched or shrunk by a scalar
    called the eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A v = \lambda v \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(v\) is an eigenvector and \(\lambda\) is the eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Geometrically: eigenvectors are “preferred directions” of a linear transformation.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE606]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: A simple 2×2 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE607]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE608]*  *This outputs eigenvalues and their associated eigenvectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Verify the eigen equation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pick one eigenpair \((\lambda, v)\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE609]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE610]*  *Both sides match → confirming the eigenpair.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE611]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE612]*  *Columns of `eigvecs` are eigenvectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric interpretation (plot)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE613]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/09c3ff333d37228c7b215f249ee63f17.png)*  *Both eigenvectors define
    directions where the transformation acts by scaling only.'
  prefs: []
  type: TYPE_NORMAL
- en: Random 3×3 matrix example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE614]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE615]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute eigenvalues and eigenvectors of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 3 & 0 \\ 0 & 2 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and verify that they match the diagonal entries.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Use NumPy to find eigenvectors of a rotation matrix by 90°. What do you notice?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a singular matrix, check if 0 is an eigenvalue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Eigenvalues = scale factors; eigenvectors = directions that stay put.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The eigen equation \(Av=\lambda v\) captures the essence of a matrix’s action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They form the foundation for deeper topics like diagonalization, stability,
    and dynamics.****  ***### 62\. Characteristic Polynomial (Where Eigenvalues Come
    From)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvalues don’t appear out of thin air - they come from the characteristic
    polynomial of a matrix. For a square matrix \(A\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ p(\lambda) = \det(A - \lambda I) \]
  prefs: []
  type: TYPE_NORMAL
- en: The roots of this polynomial are the eigenvalues of \(A\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE616]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: 2×2 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE617]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE618]*  *Polynomial: \(\lambda^2 - 4\lambda + 3\). Roots: \(\lambda = 3,
    1\).'
  prefs: []
  type: TYPE_NORMAL
- en: Verify with eigen computation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE619]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE620]*  *Matches the roots of the polynomial.'
  prefs: []
  type: TYPE_NORMAL
- en: 3×3 example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE621]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE622]*  *4.  NumPy version'
  prefs: []
  type: TYPE_NORMAL
- en: 'NumPy doesn’t give the polynomial directly, but eigenvalues can be checked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE623]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE624]*  *5.  Relation to trace and determinant'
  prefs: []
  type: TYPE_NORMAL
- en: For a 2×2 matrix
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}, \]
  prefs: []
  type: TYPE_NORMAL
- en: the characteristic polynomial is
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lambda^2 - (a+d)\lambda + (ad - bc). \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Coefficient of \(\lambda\): \(-\text{trace}(A)\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Constant term: \(\det(A)\).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE625]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE626]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the characteristic polynomial of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 4 & 0 \\ 0 & 5 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and confirm eigenvalues are 4 and 5.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Check the relationship between polynomial coefficients, trace, and determinant
    for a 3×3 case.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify with NumPy that the roots of the polynomial equal the eigenvalues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The characteristic polynomial encodes eigenvalues as its roots.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Coefficients are tied to invariants: trace and determinant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This polynomial viewpoint is the bridge from algebraic formulas to geometric
    eigen-behavior.****  ***### 63\. Algebraic vs. Geometric Multiplicity (How Many
    and How Independent)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Eigenvalues can repeat, and when they do, two notions of multiplicity arise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Algebraic multiplicity: how many times the eigenvalue appears as a root of
    the characteristic polynomial.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geometric multiplicity: the dimension of the eigenspace (number of independent
    eigenvectors).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Always:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ 1 \leq \text{geometric multiplicity} \leq \text{algebraic multiplicity} \]
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE627]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix with repeated eigenvalue
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE628]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE629]*  **   Eigenvalue 2 has algebraic multiplicity = 2.'
  prefs: []
  type: TYPE_NORMAL
- en: But only 1 independent eigenvector → geometric multiplicity = 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagonal matrix with repetition
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE630]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE631]*  *Here, eigenvalue 3 has algebraic multiplicity = 3, and geometric
    multiplicity = 3.'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE632]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE633]*  *NumPy won’t show multiplicities directly, but you can see repeated
    eigenvalues.'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing two cases
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Defective matrix: Algebraic > geometric (like the upper triangular \(A\)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Diagonalizable matrix: Algebraic = geometric (like \(B\)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This distinction determines whether a matrix can be diagonalized.***  ***####
    Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Compute algebraic and geometric multiplicities of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '(hint: only one eigenvector).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Take a diagonal matrix with repeated entries - what happens to multiplicities?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test a random 3×3 singular matrix. Does 0 have algebraic multiplicity > 1?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Algebraic multiplicity = count of root in characteristic polynomial.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometric multiplicity = dimension of eigenspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If they match for all eigenvalues → matrix is diagonalizable.****  ***### 64\.
    Diagonalization (When a Matrix Becomes Simple)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A matrix \(A\) is diagonalizable if it can be written as
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = P D P^{-1} \]
  prefs: []
  type: TYPE_NORMAL
- en: \(D\) is diagonal (containing eigenvalues).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Columns of \(P\) are the eigenvectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means \(A\) acts like simple scaling in a “better” coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE634]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: A diagonalizable 2×2 matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE635]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE636]*  *2.  A non-diagonalizable matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE637]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE638]*  *This fails because eigenvalue 2 has algebraic multiplicity 2 but
    geometric multiplicity 1.'
  prefs: []
  type: TYPE_NORMAL
- en: Diagonalization with NumPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'NumPy doesn’t diagonalize explicitly, but we can build \(P\) and \(D\) ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE639]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE640]*  *4.  Powers of a diagonalizable matrix'
  prefs: []
  type: TYPE_NORMAL
- en: 'One reason diagonalization is powerful:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^k = P D^k P^{-1} \]
  prefs: []
  type: TYPE_NORMAL
- en: Since \(D^k\) is trivial (just raise each diagonal entry to power \(k\)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE641]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE642]*  *Both match.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Check whether
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 5 & 0 \\ 0 & 5 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: is diagonalizable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Try diagonalizing a rotation matrix by 90°. Do you get complex eigenvalues?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify the formula \(A^k = P D^k P^{-1}\) for a 3×3 diagonalizable matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Diagonalization rewrites a matrix in its simplest form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Works if there are enough independent eigenvectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It makes powers of \(A\) easy, and is the gateway to analyzing dynamics.****  ***###
    65\. Powers of a Matrix (Long-Term Behavior via Eigenvalues)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the most useful applications of eigenvalues and diagonalization is computing
    powers of a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^k = P D^k P^{-1} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(D\) is diagonal with eigenvalues of \(A\). Each eigenvalue \(\lambda\)
    raised to \(k\) dictates how its eigenvector direction grows, decays, or oscillates
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE643]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple diagonal matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If \(D = \text{diag}(2,3)\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE644]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE645]*  *Eigenvalues are 2 and 3\. Raising to the 5th power just raises
    each eigenvalue to the 5th: \(2^5, 3^5\).'
  prefs: []
  type: TYPE_NORMAL
- en: Non-diagonal matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE646]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE647]*  *Much easier than multiplying \(A\) ten times!'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE648]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE649]*  *4.  Long-term behavior'
  prefs: []
  type: TYPE_NORMAL
- en: 'Eigenvalues tell us what happens as \(k \to \infty\):'
  prefs: []
  type: TYPE_NORMAL
- en: If \(|\lambda| < 1\) → decay to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(|\lambda| > 1\) → grows unbounded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(|\lambda| = 1\) → oscillates or stabilizes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE650]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE651]*  *Here, the component along eigenvalue 0.5 decays, while eigenvalue
    1.2 grows.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute \(A^{50}\) for a diagonal matrix with eigenvalues 0.9 and 1.1\. Which
    component dominates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a stochastic (Markov) matrix and compute powers. Do the rows stabilize?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Experiment with complex eigenvalues (like a rotation) and check if the powers
    oscillate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Matrix powers are simple when using eigenvalues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long-term dynamics are controlled by eigenvalue magnitudes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This insight is critical in Markov chains, stability analysis, and dynamical
    systems.****  ***### 66\. Real vs. Complex Spectra (Rotations and Oscillations)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all eigenvalues are real. Some matrices, especially those involving rotations,
    have complex eigenvalues. Complex eigenvalues often describe oscillations or rotations
    in systems.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE652]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation matrix in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A 90° rotation matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ R = \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE653]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE654]*  *Result: eigenvalues are \(i\) and \(-i\) (purely imaginary).'
  prefs: []
  type: TYPE_NORMAL
- en: Verify eigen-equation with complex numbers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE655]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE656]*  *3.  NumPy version'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE657]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE658]*  *NumPy shows complex eigenvalues with `j` (Python’s imaginary unit).'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation by arbitrary angle
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'General 2D rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ R(\theta) = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta
    \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Eigenvalues:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \lambda = e^{\pm i\theta} = \cos\theta \pm i\sin\theta \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE659]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE660]*  *5.  Oscillation insight'
  prefs: []
  type: TYPE_NORMAL
- en: Complex eigenvalues with \(|\lambda|=1\) → pure oscillation (no growth).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(|\lambda|<1\) → decaying spiral.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(|\lambda|>1\) → growing spiral.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE661]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE662]*  *These eigenvalues lie inside the unit circle → spiral decay.*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute eigenvalues of a 180° rotation. What happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the rotation matrix to include scaling (e.g., multiply by 1.1). Do the
    eigenvalues lie outside the unit circle?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the trajectory of repeatedly applying a rotation matrix to a vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Complex eigenvalues naturally appear in rotations and oscillatory systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their magnitude controls growth or decay; their angle controls oscillation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a key link between linear algebra and dynamics in physics and engineering.****  ***###
    67\. Defective Matrices and a Peek at Jordan Form (When Diagonalization Fails)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not every matrix has enough independent eigenvectors to be diagonalized. Such
    matrices are called defective. To handle them, mathematicians use the Jordan normal
    form, which extends diagonalization with extra structure.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE663]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: A defective example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 2 & 1 \\ 0 & 2 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE664]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE665]*  **   Eigenvalue 2 has algebraic multiplicity = 2.'
  prefs: []
  type: TYPE_NORMAL
- en: Only 1 eigenvector exists → geometric multiplicity = 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus \(A\) is defective, not diagonalizable.
  prefs: []
  type: TYPE_NORMAL
- en: Attempt diagonalization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE666]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE667]*  *You’ll see an error - confirming \(A\) is not diagonalizable.'
  prefs: []
  type: TYPE_NORMAL
- en: Jordan form in SymPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE668]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE669]*  *The Jordan form shows a Jordan block:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ J = \begin{bmatrix} 2 & 1 \\ 0 & 2 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: This block structure represents the failure of diagonalization.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy perspective
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'NumPy doesn’t compute Jordan form, but you can see repeated eigenvalues and
    lack of eigenvectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE670]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE671]*  *The eigenvectors matrix has fewer independent columns than expected.'
  prefs: []
  type: TYPE_NORMAL
- en: Generalized eigenvectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Jordan form introduces generalized eigenvectors, which satisfy:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ (A - \lambda I)^k v = 0 \quad \text{for some } k>1 \]
  prefs: []
  type: TYPE_NORMAL
- en: They “fill the gap” when ordinary eigenvectors are insufficient.****  ***####
    Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Test diagonalizability of
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} 3 & 1 \\ 0 & 3 \end{bmatrix} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and compare with its Jordan form.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Try a 3×3 defective matrix with one Jordan block of size 3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify that Jordan blocks still capture the correct eigenvalues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Defective matrices lack enough eigenvectors for diagonalization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jordan form replaces diagonalization with blocks, keeping eigenvalues on the
    diagonal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Jordan blocks is essential for advanced linear algebra and differential
    equations.****  ***### 68\. Stability and Spectral Radius (Grow, Decay, or Oscillate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The spectral radius of a matrix \(A\) is defined as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \rho(A) = \max_i |\lambda_i| \]
  prefs: []
  type: TYPE_NORMAL
- en: 'where \(\lambda_i\) are the eigenvalues. It tells us the long-term behavior
    of repeated applications of \(A\):'
  prefs: []
  type: TYPE_NORMAL
- en: If \(\rho(A) < 1\) → powers of \(A\) tend to 0 (stable/decay).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\rho(A) = 1\) → powers neither blow up nor vanish (neutral, may oscillate).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(\rho(A) > 1\) → powers diverge (unstable/growth).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE672]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Stable matrix (\(\rho < 1\))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE673]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE674]*  *All entries shrink toward zero.'
  prefs: []
  type: TYPE_NORMAL
- en: Unstable matrix (\(\rho > 1\))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE675]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE676]*  *The component along eigenvalue 1.2 grows quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: Neutral/oscillatory case (\(\rho = 1\))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '90° rotation matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE677]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE678]*  *Eigenvalues are ±i, with modulus 1 → pure oscillation.'
  prefs: []
  type: TYPE_NORMAL
- en: Spectral radius with SymPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE679]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE680]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Build a diagonal matrix with entries 0.8, 1.0, and 1.1\. Predict which direction
    dominates as powers grow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply a random matrix repeatedly to a vector. Does it shrink, grow, or oscillate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check if a Markov chain transition matrix always has spectral radius 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The spectral radius is the key number that predicts growth, decay, or oscillation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long-term stability in dynamical systems is governed entirely by eigenvalue
    magnitudes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This connects linear algebra directly to control theory, Markov chains, and
    differential equations.****  ***### 69\. Markov Chains and Steady States (Probabilities
    as Linear Algebra)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Markov chain is a process that moves between states according to probabilities.
    The transitions are encoded in a stochastic matrix \(P\):'
  prefs: []
  type: TYPE_NORMAL
- en: Each entry \(p_{ij} \geq 0\)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each row sums to 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we start with a probability vector \(v_0\), then after \(k\) steps:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ v_k = v_0 P^k \]
  prefs: []
  type: TYPE_NORMAL
- en: A steady state is a probability vector \(v\) such that \(vP = v\). It corresponds
    to eigenvalue \(\lambda = 1\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE681]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple two-state chain
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE682]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE683]*  *The distribution stabilizes as \(k\) increases.'
  prefs: []
  type: TYPE_NORMAL
- en: Steady state via eigenvector
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Find eigenvector for eigenvalue 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE684]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE685]*  *3.  SymPy exact check'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE686]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE687]*  *4.  A 3-state example'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE688]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE689]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a transition matrix where one state is absorbing (e.g., row = [0,0,1]).
    What happens to the steady state?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simulate a random walk on 3 states. Does the steady state distribute evenly?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare long-run simulation with eigenvector computation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Markov chains evolve by repeated multiplication with a stochastic matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steady states are eigenvectors with eigenvalue 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This framework powers real applications like PageRank, weather models, and queuing
    systems.****  ***### 70\. Linear Differential Systems (Solutions via Eigen-Decomposition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Linear differential equations often reduce to systems of the form:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{d}{dt}x(t) = A x(t) \]
  prefs: []
  type: TYPE_NORMAL
- en: 'where \(A\) is a matrix and \(x(t)\) is a vector of functions. The solution
    is given by the matrix exponential:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x(t) = e^{At} x(0) \]
  prefs: []
  type: TYPE_NORMAL
- en: If \(A\) is diagonalizable, this becomes simple using eigenvalues and eigenvectors.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE690]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simple system with diagonal matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} -1 & 0 \\ 0 & 2 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE691]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE692]*  *Solution:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x(t) = \begin{bmatrix} e^{-t} & 0 \\ 0 & e^{2t} \end{bmatrix} x(0) \]
  prefs: []
  type: TYPE_NORMAL
- en: One component decays, the other grows.
  prefs: []
  type: TYPE_NORMAL
- en: Non-diagonal example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE693]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE694]*  *Here the solution involves exponentials and possibly sines/cosines
    (oscillatory behavior).'
  prefs: []
  type: TYPE_NORMAL
- en: Numeric computation with SciPy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE695]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE696]*  *This computes \(e^{At}\) numerically.'
  prefs: []
  type: TYPE_NORMAL
- en: Simulation of a trajectory
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE697]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE698]*  *One coordinate decays, the other explodes with time.****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Solve the system \(\dot{x} = \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix}x\).
    What kind of motion do you see?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use SciPy to simulate a system with eigenvalues less than 0\. Does it always
    decay?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try an unstable system with eigenvalues > 0 and watch how trajectories diverge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Linear systems \(\dot{x} = Ax\) are solved via the matrix exponential.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Eigenvalues determine stability: negative real parts = stable, positive = unstable,
    imaginary = oscillations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This ties linear algebra directly to differential equations and dynamical systems.*******************************  ***##
    Chapter 8\. Orthogonality, least squars, and QR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 71\. Inner Products Beyond Dot Product (Custom Notions of Angle)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dot product is the standard inner product in \(\mathbb{R}^n\), but linear
    algebra allows us to define more general inner products that measure length and
    angle in different ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'An inner product on a vector space is a function \(\langle u, v \rangle\) that
    satisfies:'
  prefs: []
  type: TYPE_NORMAL
- en: Linearity in the first argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Symmetry: \(\langle u, v \rangle = \langle v, u \rangle\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Positive definiteness: \(\langle v, v \rangle \geq 0\) and equals 0 only if
    \(v=0\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE699]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Standard dot product
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE700]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE701]*  *This is the familiar formula: \(1·4 + 2·5 + 3·6 = 32\).'
  prefs: []
  type: TYPE_NORMAL
- en: Weighted inner product
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can define:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \langle u, v \rangle_W = u^T W v \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(W\) is a positive definite matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE702]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE703]*  *Here, some coordinates “count more” than others.'
  prefs: []
  type: TYPE_NORMAL
- en: Check symmetry and positivity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE704]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE705]*  *4.  Angle with weighted inner product'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \cos\theta = \frac{\langle u,v \rangle_W}{\|u\|_W \, \|v\|_W} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE706]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE707]*  *5.  Custom example: correlation inner product'
  prefs: []
  type: TYPE_NORMAL
- en: 'For statistics, an inner product can be defined as covariance or correlation.
    Example with mean-centered vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE708]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE709]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Define a custom inner product with \(W = \text{diag}(1,10,100)\). How does it
    change angles between vectors?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify positivity: compute \(\langle v, v \rangle_W\) for a random vector \(v\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare dot product vs weighted inner product on the same pair of vectors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Inner products generalize the dot product to new “geometries.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By changing the weight matrix \(W\), you change how lengths and angles are measured.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This flexibility is essential in statistics, optimization, and machine learning.****  ***###
    72\. Orthogonality and Orthonormal Bases (Perpendicular Power)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two vectors are orthogonal if their inner product is zero:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \langle u, v \rangle = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'If, in addition, each vector has length 1, the set is orthonormal. Orthonormal
    bases are extremely useful because they simplify computations: projections, decompositions,
    and coordinate changes all become clean.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE710]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Check orthogonality
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE711]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE712]*  *Since the dot product is 0, they’re orthogonal.'
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \hat{u} = \frac{u}{\|u\|} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE713]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE714]*  *Now both have length 1.'
  prefs: []
  type: TYPE_NORMAL
- en: Form an orthonormal basis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE715]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE716]*  *The result is the identity matrix → perfectly orthonormal.'
  prefs: []
  type: TYPE_NORMAL
- en: Apply to coordinates
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If \(x = [2,3]\), coordinates in the orthonormal basis are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE717]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE718]*  *It reconstructs exactly.'
  prefs: []
  type: TYPE_NORMAL
- en: Random example with QR
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Any set of linearly independent vectors can be orthonormalized (Gram–Schmidt,
    or QR decomposition):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE719]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE720]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create two 3D vectors and check if they’re orthogonal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalize them to form an orthonormal set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `np.linalg.qr` on a 4×3 random matrix and verify that the columns of \(Q\)
    are orthonormal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Orthogonality means perpendicularity; orthonormality adds unit length.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orthonormal bases simplify coordinate systems, making inner products and projections
    easy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QR decomposition is the practical tool to generate orthonormal bases in higher
    dimensions.****  ***### 73\. Gram–Schmidt Process (Constructing Orthonormal Bases)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Gram–Schmidt process takes a set of linearly independent vectors and turns
    them into an orthonormal basis. This is crucial for working with subspaces, projections,
    and numerical stability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given vectors \(v_1, v_2, \dots, v_n\):'
  prefs: []
  type: TYPE_NORMAL
- en: Set \(u_1 = v_1\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Subtract projections to make each new vector orthogonal to the earlier ones:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ u_k = v_k - \sum_{j=1}^{k-1} \frac{\langle v_k, u_j \rangle}{\langle u_j,
    u_j \rangle} u_j \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Normalize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ e_k = \frac{u_k}{\|u_k\|} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The set \(\{e_1, e_2, \dots, e_n\}\) is orthonormal.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE721]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Define vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE722]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Implement Gram–Schmidt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE723]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE724]*  *3.  Compare with NumPy QR'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE725]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE726]*  *Both methods give orthonormal bases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Application: projection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To project a vector \(x\) onto the span of \(V\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE727]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE728]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Run Gram–Schmidt on two vectors in 2D. Compare with just normalizing and checking
    orthogonality.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace one vector with a linear combination of others. What happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use QR decomposition on a 4×3 random matrix and compare with Gram–Schmidt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Gram–Schmidt converts arbitrary independent vectors into an orthonormal basis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orthonormal bases simplify projections, decompositions, and computations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, QR decomposition is often used as a numerically stable implementation.****  ***###
    74\. Orthogonal Projections onto Subspaces (Closest Point Principle)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given a subspace spanned by vectors, the orthogonal projection of a vector \(x\)
    onto the subspace is the point in the subspace that is closest to \(x\). This
    is a cornerstone idea in least squares, data fitting, and signal processing.
  prefs: []
  type: TYPE_NORMAL
- en: Formula Recap
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If \(Q\) is a matrix with orthonormal columns spanning the subspace, the projection
    of \(x\) is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \text{proj}(x) = Q Q^T x \]
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE729]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Projection onto a line (1D subspace)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Suppose the subspace is spanned by \(u = [1,2]\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE730]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE731]*  *This gives the closest point to \(x\) along the line spanned by
    \(u\).'
  prefs: []
  type: TYPE_NORMAL
- en: Projection onto a plane (2D subspace in 3D)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE732]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE733]*  *Result drops the z-component → projection onto the plane.'
  prefs: []
  type: TYPE_NORMAL
- en: General projection using QR
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE734]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE735]*  *4.  Visualization (2D case)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE736]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/b692f40e9b624b568a3feb20a645f0dc.png)****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Project a vector onto the line spanned by \([2,1]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Project \([1,2,3]\) onto the plane spanned by \([1,0,1]\) and \([0,1,1]\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare projection via formula \(Q Q^T x\) with manually solving least squares.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Orthogonal projection finds the closest point in a subspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Formula \(Q Q^T x\) works perfectly when \(Q\) has orthonormal columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Projections are the foundation of least squares, PCA, and many geometric algorithms.****  ***###
    75\. Least-Squares Problems (Fit When Exact Solve Is Impossible)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sometimes a system of equations \(Ax = b\) has no exact solution - usually
    because it’s overdetermined (more equations than unknowns). In this case, we look
    for an approximate solution \(x^*\) that minimizes the error:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x^* = \arg\min_x \|Ax - b\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: This is the least-squares solution, which geometrically is the projection of
    \(b\) onto the column space of \(A\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE737]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Overdetermined system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '3 equations, 2 unknowns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE738]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Solve least squares with NumPy'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE739]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE740]*  *3.  Compare with normal equations'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^T A x = A^T b \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE741]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE742]*  *4.  Geometric picture'
  prefs: []
  type: TYPE_NORMAL
- en: 'The least-squares solution projects \(b\) onto the column space of \(A\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE743]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE744]*  *The error vector is orthogonal to the column space.'
  prefs: []
  type: TYPE_NORMAL
- en: Verify orthogonality condition
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ A^T (b - Ax^*) = 0 \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE745]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE746]*  *The result should be (close to) zero.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create a taller \(A\) (say 5×2) with random numbers and solve least squares
    for a random \(b\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the residual from `np.linalg.lstsq` with geometric intuition (projection).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify \(b\) so that the system has an exact solution. Check if least squares
    gives it exactly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Least-squares finds the best-fit solution when no exact solution exists.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It works by projecting \(b\) onto the column space of \(A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This principle underlies regression, curve fitting, and countless applications
    in data science.****  ***### 76\. Normal Equations and Geometry of Residuals (Why
    It Works)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The least-squares solution can be found by solving the normal equations:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^T A x = A^T b \]
  prefs: []
  type: TYPE_NORMAL
- en: This comes from the condition that the residual vector
  prefs: []
  type: TYPE_NORMAL
- en: \[ r = b - Ax \]
  prefs: []
  type: TYPE_NORMAL
- en: is orthogonal to the column space of \(A\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE747]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build an overdetermined system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE748]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Solve least squares via normal equations'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE749]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE750]*  *3.  Compute residual and check orthogonality'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE751]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE752]*  *This verifies the residual is perpendicular to the column space
    of \(A\).'
  prefs: []
  type: TYPE_NORMAL
- en: Compare with NumPy’s least squares solver
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE753]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE754]*  *The solutions should match (within numerical precision).'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric picture
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \(b\) is a point in \(\mathbb{R}^3\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(Ax\) is restricted to lie in the 2D column space of \(A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The least-squares solution picks the \(Ax\) closest to \(b\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The error vector \(r = b - Ax^*\) is orthogonal to the subspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE755]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE756]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change \(b\) to \([1,1,1]\). Solve again and check the residual.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a random tall \(A\) (say 6×2) and verify that the residual is always orthogonal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute \(\|r\|\) and see how it changes when you change \(b\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Least squares works by making the residual orthogonal to the column space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal equations are the algebraic way to encode this condition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This orthogonality principle is the geometric heart of least-squares fitting.****  ***###
    77\. QR Factorization (Stable Least Squares via Orthogonality)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While normal equations solve least squares, they can be numerically unstable
    if \(A^T A\) is ill-conditioned. A more stable method uses QR factorization:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = Q R \]
  prefs: []
  type: TYPE_NORMAL
- en: '\(Q\): matrix with orthonormal columns'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(R\): upper triangular matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then the least-squares problem reduces to solving:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ Rx = Q^T b \]
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE757]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Overdetermined system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE758]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  QR factorization'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE759]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE760]*  *3.  Solve least squares using QR'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE761]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE762]*  *4.  Compare with NumPy’s `lstsq`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE763]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE764]*  *The answers should match closely.'
  prefs: []
  type: TYPE_NORMAL
- en: Residual check
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE765]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE766]*  *Residual is orthogonal to the column space, confirming correctness.*****  ***####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Solve least squares for a 5×2 random matrix using both normal equations and
    QR. Compare results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check stability by making columns of \(A\) nearly dependent - see if QR behaves
    better than normal equations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute projection of \(b\) using \(Q Q^T b\) and confirm it equals \(A x^*\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: QR factorization provides a numerically stable way to solve least squares.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It avoids the instability of normal equations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, modern solvers (like NumPy’s `lstsq`) rely on QR or SVD under the
    hood.****  ***### 78\. Orthogonal Matrices (Length-Preserving Transforms)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An orthogonal matrix \(Q\) is a square matrix whose columns (and rows) are
    orthonormal vectors. Formally:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ Q^T Q = Q Q^T = I \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Key properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Preserves lengths: \(\|Qx\| = \|x\|\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Preserves dot products: \(\langle Qx, Qy \rangle = \langle x, y \rangle\)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant is either \(+1\) (rotation) or \(-1\) (reflection)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE767]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Construct a simple orthogonal matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '90° rotation in 2D:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE768]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE769]*  *Result = identity → confirms orthogonality.'
  prefs: []
  type: TYPE_NORMAL
- en: Check length preservation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE770]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE771]*  *Both lengths match.'
  prefs: []
  type: TYPE_NORMAL
- en: Check dot product preservation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE772]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE773]*  *Dot product is preserved.'
  prefs: []
  type: TYPE_NORMAL
- en: Reflection matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Reflection about the x-axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE774]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE775]*  *Determinant = -1 → reflection.'
  prefs: []
  type: TYPE_NORMAL
- en: Random orthogonal matrix via QR
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE776]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE777]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Build a 2D rotation matrix for 45°. Verify it’s orthogonal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether scaling matrices (e.g., \(\text{diag}(2,1)\)) are orthogonal.
    Why or why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a random orthogonal matrix with `np.linalg.qr` and test its determinant.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Orthogonal matrices are rigid motions: they rotate or reflect without distorting
    lengths or angles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They play a key role in numerical stability, geometry, and physics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every orthonormal basis corresponds to an orthogonal matrix.****  ***### 79\.
    Fourier Viewpoint (Expanding in Orthogonal Waves)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Fourier viewpoint treats functions or signals as combinations of orthogonal
    waves (sines and cosines). This is just linear algebra: sine and cosine functions
    form an orthogonal basis, and any signal can be expressed as a linear combination
    of them.'
  prefs: []
  type: TYPE_NORMAL
- en: Formula Recap
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For a discrete signal \(x\), the Discrete Fourier Transform (DFT) is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ X_k = \sum_{n=0}^{N-1} x_n e^{-2\pi i kn / N}, \quad k=0,\dots,N-1 \]
  prefs: []
  type: TYPE_NORMAL
- en: The inverse DFT reconstructs the signal. Orthogonality of complex exponentials
    makes this work.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE778]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build a simple signal
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE779]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/59c7e2adf8a52cda633e1c3496675a81.png)*  *2.  Compute Fourier
    transform (DFT)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE780]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/14b51bb53b253c76a4c74d57e671594f.png)*  *Peaks appear at 3Hz
    and 5Hz → the frequencies of the original signal.'
  prefs: []
  type: TYPE_NORMAL
- en: Reconstruct signal using inverse FFT
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE781]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE782]*  *Error is near zero → perfect reconstruction.'
  prefs: []
  type: TYPE_NORMAL
- en: Orthogonality check of sinusoids
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE783]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE784]*  *The result is ≈ 0 → confirms orthogonality.****  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change the frequencies to 7Hz and 9Hz. Do the Fourier peaks move accordingly?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mix in some noise and check how the spectrum looks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try cosine signals instead of sine. Do you still see orthogonality?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fourier analysis = linear algebra with orthogonal sinusoidal basis functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any signal can be decomposed into orthogonal waves.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This orthogonal viewpoint powers audio, image compression, and signal processing.****  ***###
    80\. Polynomial and Multifeature Least Squares (Fitting More Flexibly)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Least squares isn’t limited to straight lines. By adding polynomial or multiple
    features, we can fit curves and capture more complex relationships. This is the
    foundation of regression models in data science.
  prefs: []
  type: TYPE_NORMAL
- en: Formula Recap
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Given data \((x_i, y_i)\), we build a design matrix \(A\):'
  prefs: []
  type: TYPE_NORMAL
- en: 'For polynomial fit of degree \(d\):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ A = \begin{bmatrix} 1 & x_1 & x_1^2 & \dots & x_1^d \\ 1 & x_2 & x_2^2 &
    \dots & x_2^d \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & x_n & x_n^2
    & \dots & x_n^d \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Then solve least squares:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \hat{c} = \arg\min_c \|Ac - y\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE785]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Generate noisy quadratic data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE786]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/d62c3c2981487234fb5812edfd85d7cf.png)*  *2.  Build polynomial
    design matrix (degree 2)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE787]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE788]*  *3.  Plot fitted polynomial'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE789]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e1e010ef63b6e1c56ff13d0f27df2c89.png)*  *4.  Higher-degree fit
    (overfitting demonstration)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE790]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/38287a6c0a2feb9d3f00259e90085109.png)*  *5.  Multifeature regression
    example'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we predict \(y\) from features \([x, x^2, \sin(x)]\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE791]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE792]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Fit degree 3, 4, 5 polynomials to the same data. Watch how the curve changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add features like \(\cos(x)\) or \(\exp(x)\) - does the fit improve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare training error (fit to noisy data) vs error on new test points.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Least squares can fit polynomials and arbitrary feature combinations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The design matrix encodes how input variables transform into features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the basis of regression, curve fitting, and many machine learning models.*******************************  ***##
    Chapter 9\. SVD, PCA, and Conditioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 81\. Singular Values and SVD (Universal Factorization)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Singular Value Decomposition (SVD) is one of the most powerful results
    in linear algebra. It says any \(m \times n\) matrix \(A\) can be factored as:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A = U \Sigma V^T \]
  prefs: []
  type: TYPE_NORMAL
- en: '\(U\): orthogonal \(m \times m\) matrix (left singular vectors)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(\Sigma\): diagonal \(m \times n\) matrix with nonnegative numbers (singular
    values)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(V\): orthogonal \(n \times n\) matrix (right singular vectors)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singular values are always nonnegative and sorted \(\sigma_1 \geq \sigma_2 \geq
    \dots\).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE793]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Compute SVD of a matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE794]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE795]*  **   `U`: orthogonal basis in input space.'
  prefs: []
  type: TYPE_NORMAL
- en: '`S`: singular values (as a 1D array).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`V^T`: orthogonal basis in output space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reconstruct \(A\) from decomposition
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE796]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE797]*  *The error should be near zero.'
  prefs: []
  type: TYPE_NORMAL
- en: Rank from SVD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Number of nonzero singular values = rank of \(A\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE798]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE799]*  *4.  Geometry: effect of \(A\)'
  prefs: []
  type: TYPE_NORMAL
- en: 'SVD says:'
  prefs: []
  type: TYPE_NORMAL
- en: \(V\) rotates input space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \(\Sigma\) scales along orthogonal directions (by singular values).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \(U\) rotates to output space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This explains why SVD works for any matrix (not just square ones).
  prefs: []
  type: TYPE_NORMAL
- en: Low-rank approximation preview
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keep only the top singular value(s) → best approximation of \(A\).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE800]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE801]****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compute SVD for a random 5×3 matrix. Check if \(U\) and \(V\) are orthogonal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare singular values of a diagonal matrix vs a rotation matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero out small singular values and see how much of \(A\) is preserved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SVD factorizes any matrix into rotations and scalings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singular values reveal rank and strength of directions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It’s the universal tool of numerical linear algebra: the backbone of PCA, compression,
    and stability analysis.****  ***### 82\. Geometry of SVD (Rotations + Stretching)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Singular Value Decomposition (SVD) has a beautiful geometric interpretation:
    every matrix is just a combination of two rotations (or reflections) and a stretching.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For \(A = U \Sigma V^T\):'
  prefs: []
  type: TYPE_NORMAL
- en: '\(V^T\): rotates (or reflects) the input space.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '\(\Sigma\): stretches space along orthogonal axes by singular values \(\sigma_i\).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '\(U\): rotates (or reflects) the result into the output space.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This turns any linear transformation into a rotation → stretching → rotation
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE802]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Make a 2D matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE803]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Apply SVD'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE804]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE805]*  *3.  Visualize effect on the unit circle'
  prefs: []
  type: TYPE_NORMAL
- en: The unit circle is often used to visualize linear transformations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE806]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/f55d1900ae2b3fbf2e73df58ab41bb26.png)*  *The circle becomes
    an ellipse. Its axes align with the singular vectors, and its radii are the singular
    values.'
  prefs: []
  type: TYPE_NORMAL
- en: Compare with decomposition steps
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE807]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/c2bdac9342e6dbe5abc212d68cecfa8d.png)*  *Both transformed shapes
    match → confirms SVD’s geometric picture.****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change \(A\) to a pure shear, like `[[1,2],[0,1]]`. How does the ellipse look?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try a diagonal matrix, like `[[3,0],[0,1]]`. Do the singular vectors match the
    coordinate axes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scale the input circle to a square and see if geometry still works.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SVD = rotate → stretch → rotate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The unit circle becomes an ellipse: axes = singular vectors, radii = singular
    values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This geometric lens makes SVD intuitive and explains why it’s so widely used
    in data, graphics, and signal processing.****  ***### 83\. Relation to Eigen-Decompositions
    (ATA and AAT)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singular values and eigenvalues are closely connected. While eigen-decomposition
    applies only to square matrices, SVD works for any rectangular matrix. The bridge
    between them is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^T A v = \sigma^2 v \quad \text{and} \quad A A^T u = \sigma^2 u \]
  prefs: []
  type: TYPE_NORMAL
- en: '\(v\): right singular vector (from eigenvectors of \(A^T A\))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(u\): left singular vector (from eigenvectors of \(A A^T\))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(\sigma\): singular values (square roots of eigenvalues of \(A^T A\) or \(A
    A^T\))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE808]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Define a rectangular matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE809]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Compute SVD directly'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE810]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE811]*  *3.  Compare with eigenvalues of \(A^T A\)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE812]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE813]*  *Notice: singular values from SVD = square roots of eigenvalues
    of \(A^T A\).'
  prefs: []
  type: TYPE_NORMAL
- en: Compare with eigenvalues of \(A A^T\)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE814]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE815]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE816]*  *They match too → confirming the relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: Verify singular vectors
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right singular vectors (\(V\)) = eigenvectors of \(A^T A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Left singular vectors (\(U\)) = eigenvectors of \(A A^T\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE817]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE818]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Try a square symmetric matrix and compare SVD with eigen-decomposition. Do they
    match?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a tall vs wide rectangular matrix, check whether \(U\) and \(V\) differ.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute eigenvalues manually with `np.linalg.eig` for a random \(A\) and confirm
    singular values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Singular values = square roots of eigenvalues of \(A^T A\) (or \(A A^T\)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Right singular vectors = eigenvectors of \(A^T A\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Left singular vectors = eigenvectors of \(A A^T\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVD generalizes eigen-decomposition to all matrices, rectangular or square.****  ***###
    84\. Low-Rank Approximation (Best Small Models)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the most useful applications of SVD is low-rank approximation: compressing
    a large matrix into a smaller one while keeping most of the important information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Eckart–Young theorem says: If \(A = U \Sigma V^T\), then the best rank-\(k\)
    approximation (in least-squares sense) is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A_k = U_k \Sigma_k V_k^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where we keep only the top \(k\) singular values (and corresponding vectors).
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE819]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Create a matrix with hidden low-rank structure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE820]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Full SVD'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE821]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE822]*  *Only the first ~5 should be large; the rest close to zero.'
  prefs: []
  type: TYPE_NORMAL
- en: Build rank-1 approximation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE823]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE824]*  *4.  Rank-5 approximation (should be almost exact)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE825]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE826]*  *5.  Visual comparison (image compression demo)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see it on an image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE827]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/f75e66b7e9f78366778792898f4c6aa2.png)*  *Even with just 2 singular
    values, the digit shape is recognizable.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Vary \(k\) in the image example (1, 2, 5, 10). How much detail do you keep?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the approximation error \(\|A - A_k\|\) as \(k\) increases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply low-rank approximation to random noisy data. Does it denoise?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SVD gives the best possible low-rank approximation in terms of error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By truncating singular values, you compress data while keeping its essential
    structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the backbone of image compression, recommender systems, and dimensionality
    reduction.****  ***### 85\. Principal Component Analysis (Variance and Directions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principal Component Analysis (PCA) is one of the most important applications
    of SVD. It finds the directions (principal components) where data varies the most,
    and projects the data onto them to reduce dimensionality while preserving as much
    information as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically:'
  prefs: []
  type: TYPE_NORMAL
- en: Center the data (subtract the mean).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute covariance matrix \(C = \frac{1}{n} X^T X\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eigenvectors of \(C\) = principal directions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eigenvalues = variance explained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Equivalently: PCA = SVD of centered data matrix.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE828]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Generate synthetic 2D data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE829]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/4ee496ffc33356435a312affe651f883.png)*  *2.  Center the data'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE830]'
  prefs: []
  type: TYPE_PRE
- en: '*3.  Compute SVD'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE831]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE832]*  *Rows of `Vt` are the principal components.'
  prefs: []
  type: TYPE_NORMAL
- en: Project data onto first component
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE833]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e185574662ce2d32b63dcf3ba06f5eb9.png)*  *This collapses data
    into 1D, keeping the most variance.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualize principal axes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE834]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/22fd7647497edd7133983d6fd85f5096.png)*  *The red arrows show
    where the data spreads most.'
  prefs: []
  type: TYPE_NORMAL
- en: PCA on real data (digits)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE835]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE836]******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Reduce digits dataset to 2D using the top 2 components and plot. Do digit clusters
    separate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare explained variance ratio for top 10 components.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add noise to data and check if PCA filters it out when projecting to fewer dimensions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PCA finds directions of maximum variance using SVD.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By projecting onto top components, you compress data with minimal information
    loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PCA is the backbone of dimensionality reduction, visualization, and preprocessing
    in machine learning.****  ***### 86\. Pseudoinverse (Moore–Penrose) and Solving
    Ill-Posed Systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Moore–Penrose pseudoinverse \(A^+\) generalizes the inverse of a matrix.
    It allows solving systems \(Ax = b\) even when:'
  prefs: []
  type: TYPE_NORMAL
- en: \(A\) is not square, or
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(A\) is singular (non-invertible).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The solution given by the pseudoinverse is the least-squares solution with
    minimum norm:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x = A^+ b \]
  prefs: []
  type: TYPE_NORMAL
- en: 'If \(A = U \Sigma V^T\), then:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A^+ = V \Sigma^+ U^T \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\Sigma^+\) is obtained by taking reciprocals of nonzero singular values.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE837]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Solve an overdetermined system (more equations than unknowns)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE838]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE839]*  *2.  Compute with pseudoinverse'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE840]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE841]*  *Both match → pseudoinverse gives least-squares solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Solve an underdetermined system (fewer equations than unknowns)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE842]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE843]*  *Here, infinitely many solutions exist. The pseudoinverse picks
    the one with smallest norm.'
  prefs: []
  type: TYPE_NORMAL
- en: Compare with singular matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE844]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE845]*  *Even when \(A\) is singular, pseudoinverse provides a solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual pseudoinverse via SVD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE846]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE847]*  *They match.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Create an overdetermined system with noise and see how pseudoinverse smooths
    the solution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare pseudoinverse with direct inverse (`np.linalg.inv`) on a square nonsingular
    matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero out small singular values manually and see how solution changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The pseudoinverse solves any linear system, square or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides the least-squares solution in overdetermined cases and the minimum-norm
    solution in underdetermined cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built on SVD, it is a cornerstone of regression, optimization, and numerical
    methods.****  ***### 87\. Conditioning and Sensitivity (How Errors Amplify)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conditioning tells us how sensitive a system is to small changes. For a linear
    system \(Ax = b\):'
  prefs: []
  type: TYPE_NORMAL
- en: If \(A\) is well-conditioned, small changes in \(b\) or \(A\) → small changes
    in \(x\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If \(A\) is ill-conditioned, tiny changes can cause huge swings in \(x\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The condition number is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \kappa(A) = \|A\| \cdot \|A^{-1}\| \]
  prefs: []
  type: TYPE_NORMAL
- en: 'For SVD:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \kappa(A) = \frac{\sigma_{\max}}{\sigma_{\min}} \]
  prefs: []
  type: TYPE_NORMAL
- en: where \(\sigma_{\max}\) and \(\sigma_{\min}\) are the largest and smallest singular
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Large \(\kappa(A)\) → unstable system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Small \(\kappa(A)\) → stable system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE848]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Well-conditioned system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE849]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE850]*  *Condition number = ratio of singular values → moderate size.'
  prefs: []
  type: TYPE_NORMAL
- en: Ill-conditioned system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE851]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE852]*  *Condition number is very large → instability.'
  prefs: []
  type: TYPE_NORMAL
- en: Perturb the right-hand side
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE853]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE854]*  *The solution changes drastically → shows sensitivity.'
  prefs: []
  type: TYPE_NORMAL
- en: Relation to singular values
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE855]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE856]*  *5.  Scaling experiment'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE857]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE858]*  *As scale shrinks, condition number explodes.*****  ***#### Try
    It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Generate random matrices and compute their condition numbers. Which are stable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare condition numbers of Hilbert matrices (notoriously ill-conditioned).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explore how rounding errors grow with high condition numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Condition number = measure of problem sensitivity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \(\kappa(A) = \sigma_{\max}/\sigma_{\min}\).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ill-conditioned problems amplify errors and are numerically unstable → why scaling,
    regularization, and good formulations matter.****  ***### 88\. Matrix Norms and
    Singular Values (Measuring Size Properly)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix norms measure the size or strength of a matrix. They extend the idea
    of vector length to matrices. Norms are crucial for analyzing stability, error
    growth, and performance of algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some important norms:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Frobenius norm:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \|A\|_F = \sqrt{\sum_{i,j} |a_{ij}|^2} \]
  prefs: []
  type: TYPE_NORMAL
- en: Equivalent to treating the matrix as a big vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spectral norm (operator 2-norm):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \|A\|_2 = \sigma_{\max} \]
  prefs: []
  type: TYPE_NORMAL
- en: The largest singular value - tells how much \(A\) can stretch a vector.
  prefs: []
  type: TYPE_NORMAL
- en: '1-norm: maximum absolute column sum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '∞-norm: maximum absolute row sum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE859]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build a test matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE860]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Compute different norms'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE861]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE862]*  *3.  Compare spectral norm with largest singular value'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE863]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE864]*  *They match → spectral norm = largest singular value.'
  prefs: []
  type: TYPE_NORMAL
- en: Frobenius norm from singular values
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ \|A\|_F = \sqrt{\sigma_1^2 + \sigma_2^2 + \dots} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE865]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE866]*  *5.  Stretching effect demonstration'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pick a random vector and see how much it grows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE867]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE868]*  *The stretch ≤ spectral norm, always.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compare norms for diagonal matrices - do they match the largest diagonal entry?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate random matrices and see how norms differ.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute Frobenius vs spectral norm for a rank-1 matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Frobenius norm = overall energy of the matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spectral norm = maximum stretching power (largest singular value).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other norms (1-norm, ∞-norm) capture row/column dominance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singular values unify all these views of “matrix size.”****  ***### 89\. Regularization
    (Ridge/Tikhonov to Tame Instability)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When solving \(Ax = b\), if \(A\) is ill-conditioned (large condition number),
    small errors in data can cause huge errors in the solution. Regularization stabilizes
    the problem by adding a penalty term that discourages extreme solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common form: ridge regression (a.k.a. Tikhonov regularization):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x_\lambda = \arg\min_x \|Ax - b\|^2 + \lambda \|x\|^2 \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Closed form:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x_\lambda = (A^T A + \lambda I)^{-1} A^T b \]
  prefs: []
  type: TYPE_NORMAL
- en: 'Here \(\lambda > 0\) controls the amount of regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Small \(\lambda\): solution close to least-squares.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Large \(\lambda\): smaller coefficients, more stability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE869]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build an ill-conditioned system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE870]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Solve without regularization'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE871]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE872]*  *The result may be unstable.'
  prefs: []
  type: TYPE_NORMAL
- en: Apply ridge regularization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE873]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE874]*  *4.  Compare effect of different λ'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE875]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e4f94a0ed50b1e1fec7cb740f6adf8a4.png)*  *As \(\lambda\) increases,
    the solution becomes smaller and more stable.'
  prefs: []
  type: TYPE_NORMAL
- en: Connection to SVD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If \(A = U \Sigma V^T\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ x_\lambda = \sum_i \frac{\sigma_i}{\sigma_i^2 + \lambda} (u_i^T b) v_i \]
  prefs: []
  type: TYPE_NORMAL
- en: Small singular values (causing instability) get damped by \(\frac{\sigma_i}{\sigma_i^2
    + \lambda}\).****  ***#### Try It Yourself
  prefs: []
  type: TYPE_NORMAL
- en: Experiment with larger and smaller \(\lambda\). What happens to the solution?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add random noise to \(b\). Compare least-squares vs ridge stability.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot how each coefficient changes with λ.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Regularization controls instability in ill-conditioned problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ridge regression balances fit vs. stability using λ.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In SVD terms, regularization damps small singular values that cause wild solutions.****  ***###
    90\. Rank-Revealing QR and Practical Diagnostics (What Rank Really Is)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, we often need to determine the numerical rank of a matrix - not
    just the theoretical rank, but how many directions carry meaningful information
    beyond round-off errors or noise. A useful tool for this is the Rank-Revealing
    QR (RRQR) factorization.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a matrix \(A\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ A P = Q R \]
  prefs: []
  type: TYPE_NORMAL
- en: '\(Q\): orthogonal matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(R\): upper triangular matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(P\): column permutation matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By reordering columns smartly, the diagonal of \(R\) reveals which directions
    are significant.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE876]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build a nearly rank-deficient matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE877]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE878]*  *This matrix is almost rank 2 but with small perturbations.'
  prefs: []
  type: TYPE_NORMAL
- en: QR with column pivoting
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE879]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE880]*  *The diagonal entries of \(R\) decrease rapidly → numerical rank
    is determined where they become tiny.'
  prefs: []
  type: TYPE_NORMAL
- en: Compare with SVD
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE881]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE882]*  *The singular values tell the same story: one is very small → effective
    rank ≈ 2.'
  prefs: []
  type: TYPE_NORMAL
- en: Thresholding for rank
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE883]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE884]*  *5.  Diagnostics on a noisy matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE885]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/50d94d023826abc1ba71dafaccff1e42.png)*  *The drop in singular
    values shows effective rank.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change the perturbation in \(A\) from 0.001 to 0.000001\. Does the numerical
    rank change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test QR with pivoting on random rectangular matrices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare rank estimates from QR vs SVD for large noisy matrices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Rank-revealing QR is a practical tool to detect effective rank in real-world
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVD gives the most precise picture (singular values), but QR with pivoting is
    faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding numerical rank is crucial for diagnostics, stability, and model
    complexity control.*******************************  ***## Chapter 10\. Applications
    and computation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 91\. 2D/3D Geometry Pipelines (Cameras, Rotations, and Transforms)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linear algebra powers the geometry pipelines in computer graphics and robotics.
  prefs: []
  type: TYPE_NORMAL
- en: '2D transforms: rotation, scaling, translation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3D transforms: same ideas, but with an extra dimension.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Homogeneous coordinates let us unify all transforms (even translations) into
    matrix multiplications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE886]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Rotation in 2D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: \[ R(\theta) = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta
    \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE887]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE888]*  *2.  Translation using homogeneous coordinates'
  prefs: []
  type: TYPE_NORMAL
- en: 'In 2D:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ T(dx, dy) = \begin{bmatrix} 1 & 0 & dx \\ 0 & 1 & dy \\ 0 & 0 & 1 \end{bmatrix}
    \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE889]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE890]*  *3.  Combine rotation + translation'
  prefs: []
  type: TYPE_NORMAL
- en: Transformations compose by multiplying matrices.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE891]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE892]*  *4.  3D rotation (around z-axis)'
  prefs: []
  type: TYPE_NORMAL
- en: \[ R_z(\theta) = \begin{bmatrix} \cos\theta & -\sin\theta & 0 \\ \sin\theta
    & \cos\theta & 0 \\ 0 & 0 & 1 \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE893]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE894]*  *5.  Camera projection (3D → 2D)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Simple pinhole model:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \begin{bmatrix} x' \\ y' \end{bmatrix} = \begin{bmatrix} f \cdot x / z \\
    f \cdot y / z \end{bmatrix} \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE895]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE896]*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Rotate a square in 2D, then translate it. Plot before/after.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rotate a 3D point cloud around x, y, and z axes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Project a cube into 2D using the pinhole camera model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Geometry pipelines = sequences of linear transforms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Homogeneous coordinates unify rotation, scaling, and translation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Camera projection links 3D world to 2D images - a cornerstone of graphics and
    vision.****  ***### 92\. Computer Graphics and Robotics (Homogeneous Tricks in
    Action)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer graphics and robotics both rely on homogeneous coordinates to unify
    rotations, translations, scalings, and projections into a single framework. With
    \(4 \times 4\) matrices in 3D, entire transformation pipelines can be built as
    matrix products.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE897]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Homogeneous representation of a point
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In 3D:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ (x, y, z) \mapsto (x, y, z, 1) \]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE898]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Define translation, rotation, and scaling matrices'
  prefs: []
  type: TYPE_NORMAL
- en: 'Translation by \((dx,dy,dz)\):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE899]'
  prefs: []
  type: TYPE_PRE
- en: '**   Scaling by factors \((sx, sy, sz)\):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE900]'
  prefs: []
  type: TYPE_PRE
- en: '**   Rotation about z-axis (\(\theta = 90^\circ\)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE901]'
  prefs: []
  type: TYPE_PRE
- en: '*3.  Combine transforms into a pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE902]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE903]*  *4.  Robotics: forward kinematics of a 2-link arm'
  prefs: []
  type: TYPE_NORMAL
- en: Each joint is a rotation + translation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE904]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE905]*  *5.  Graphics: simple 3D camera projection'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE906]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE907]'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a17e925e049c8e0d299dc3cf53f9c1d.png)*******  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change order of transforms (`Rz @ S @ T`). How does the result differ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a third joint to the robotic arm and compute new end-effector position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Project the cube with different focal lengths \(f\).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Homogeneous coordinates unify all transformations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robotics uses this framework for forward kinematics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graphics uses it for camera and projection pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both fields rely on the same linear algebra tricks - just applied differently.****  ***###
    93\. Graphs, Adjacency, and Laplacians (Networks via Matrices)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Graphs can be studied with linear algebra by encoding them into matrices. Two
    of the most important:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adjacency matrix \(A\):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ A_{ij} = \begin{cases} 1 & \text{if edge between i and j exists} \\ 0 & \text{otherwise}
    \end{cases} \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Graph Laplacian \(L\):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ L = D - A \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: where \(D\) is the degree matrix ($D_{ii} = $ number of neighbors of node \(i\)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These matrices let us analyze connectivity, diffusion, and clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE908]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build a simple graph
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE909]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/64454ac990588fc1fce85afd3a8f321c.png)*  *2.  Adjacency matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE910]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE911]*  *3.  Degree and Laplacian matrices'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE912]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE913]*  *4.  Eigenvalues of Laplacian (connectivity check)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE914]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE915]*  **   The number of zero eigenvalues = number of connected components.'
  prefs: []
  type: TYPE_NORMAL
- en: Spectral embedding (clustering)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use Laplacian eigenvectors to embed nodes in low dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE916]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/7bf23ee5ccfd5962a5e494691da16e28.png)*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Remove one edge from the graph and see how Laplacian eigenvalues change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a disconnected node - does an extra zero eigenvalue appear?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try a random graph and compare adjacency vs Laplacian spectra.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Adjacency matrices describe direct graph structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laplacians capture connectivity and diffusion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvalues of \(L\) reveal graph properties like connectedness and clustering
    - bridging networks with linear algebra.****  ***### 94\. Data Preprocessing as
    Linear Ops (Centering, Whitening, Scaling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many machine learning and data analysis workflows begin with preprocessing,
    and linear algebra provides the tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Centering: subtract the mean → move data to origin.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scaling: divide by standard deviation → normalize feature ranges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whitening: decorrelate features → make covariance matrix the identity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each step can be written as a matrix operation.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE917]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Generate correlated data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE918]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/83f61c756302ce9f515ff46e0f531b64.png)*  *2.  Centering (subtract
    mean)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE919]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE920]*  *3.  Scaling (normalize features)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE921]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE922]*  *4.  Whitening via eigen-decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: 'Covariance of centered data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE923]'
  prefs: []
  type: TYPE_PRE
- en: '*Check covariance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE924]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE925]*  *5.  Compare scatter plots'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE926]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e4d5724724602e6457dd4b8a6a6d0e8e.png)*  **   Original: elongated
    ellipse.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaled: axis-aligned ellipse.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whitened: circular cloud (uncorrelated, unit variance).******  ***#### Try
    It Yourself'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a third feature and apply centering, scaling, whitening.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare whitening with PCA - they use the same eigen-decomposition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test what happens if you skip centering before whitening.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Centering → mean zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling → unit variance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whitening → features uncorrelated, variance = 1\. Linear algebra provides the
    exact matrix operations to make preprocessing systematic and reliable.****  ***###
    95\. Linear Regression and Classification (From Model to Matrix)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear regression and classification problems can be written neatly in matrix
    form. This unifies data, models, and solutions under the framework of least squares
    and linear decision boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression Model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For data \((x_i, y_i)\):'
  prefs: []
  type: TYPE_NORMAL
- en: \[ y \approx X \beta \]
  prefs: []
  type: TYPE_NORMAL
- en: '\(X\): design matrix (rows = samples, columns = features).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '\(\beta\): coefficients to solve for.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solution (least squares):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ \hat{\beta} = (X^T X)^{-1} X^T y \]
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE927]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression example
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE928]'
  prefs: []
  type: TYPE_PRE
- en: '*Construct design matrix with bias term:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE929]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE930]*  *2.  Visualize regression line'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE931]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/6560e0e35a5165b504ed382e39863911.png)*  *3.  Logistic classification
    with linear decision boundary'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE932]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/746ac3324b672f64a27d021da35ddb4b.png)*  *4.  Logistic regression
    via gradient descent'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE933]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE934]*  *5.  Plot decision boundary'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE935]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/1495dc2e5e9463526c81e6ca48ecb775.png)******  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Add polynomial features to regression and refit. Does the line bend into a curve?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change learning rate in logistic regression - what happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate data that is not linearly separable. Can a linear model still classify
    well?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Regression and classification fit naturally into linear algebra with matrix
    formulations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Least squares solves regression directly; logistic regression requires optimization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear models are simple, interpretable, and still form the foundation of modern
    machine learning.****  ***### 96\. PCA in Practice (Dimensionality Reduction Workflow)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Principal Component Analysis (PCA) is widely used to reduce dimensions, compress
    data, and visualize high-dimensional datasets. Here, we’ll walk through a full
    PCA workflow: centering, computing components, projecting, and visualizing.'
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE936]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Load dataset (digits)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE937]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE938]*  *Each sample is an 8×8 grayscale image flattened into 64 features.'
  prefs: []
  type: TYPE_NORMAL
- en: Center the data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE939]'
  prefs: []
  type: TYPE_PRE
- en: '*3.  Compute PCA via SVD'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE940]'
  prefs: []
  type: TYPE_PRE
- en: '*4.  Plot explained variance ratio'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE941]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/c9dfb11d79fcd239fa71a8fca008b253.png)*  *This shows how many
    components are needed to capture most variance.'
  prefs: []
  type: TYPE_NORMAL
- en: Project onto top 2 components for visualization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE942]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/bba1df82965a0bded492822a0b9ee15c.png)*  *6.  Reconstruct images
    from reduced dimensions'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE943]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/95baf6363b8fe5096cf9552d4c46bb36.png)*  *Even with only 20/64
    components, the digits remain recognizable.******  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change \(k\) to 5, 10, 30 - how do reconstructions change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use top 2 PCA components to classify digits with k-NN. How does accuracy compare
    to full 64 features?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try PCA on your own dataset (images, tabular data).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PCA reduces dimensions while keeping maximum variance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In practice: center → decompose → select top components → project/reconstruct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PCA enables visualization, compression, and denoising in real-world workflows.****  ***###
    97\. Recommender Systems and Low-Rank Models (Fill the Missing Entries)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommender systems often deal with incomplete matrices - rows are users, columns
    are items, entries are ratings. Most entries are missing, but the matrix is usually
    close to low-rank (because user preferences depend on only a few hidden factors).
    SVD and low-rank approximations are powerful tools to fill in these missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE944]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Simulate a user–item rating matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE945]'
  prefs: []
  type: TYPE_PRE
- en: '*2.  Hide some ratings (simulate missing data)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE946]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE947]*  *3.  Simple mean imputation (baseline)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE948]'
  prefs: []
  type: TYPE_PRE
- en: '*4.  Apply SVD for low-rank approximation'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE949]'
  prefs: []
  type: TYPE_PRE
- en: '*5.  Compare filled matrix with ground truth'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE950]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE951]*  *6.  Visualize original vs reconstructed'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE952]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/65f1b5f72f46628f26c27205b43af635.png)******  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Vary \(k\) (2, 3, 5). Does error go down?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mask more entries (50%, 80%) - how does SVD reconstruction perform?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use iterative imputation: alternate filling missing entries with low-rank approximations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recommender systems rely on low-rank structure of user–item matrices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVD provides a natural way to approximate and fill missing ratings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This low-rank modeling idea underpins modern collaborative filtering systems
    like Netflix and Spotify recommenders.****  ***### 98\. PageRank and Random Walks
    (Ranking with Eigenvectors)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The PageRank algorithm, made famous by Google, uses linear algebra and random
    walks on graphs to rank nodes (webpages, people, items). The idea: importance
    flows through links - being linked by important nodes makes you important.'
  prefs: []
  type: TYPE_NORMAL
- en: The PageRank Idea
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Start a random walk on a graph: at each step, move to a random neighbor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a “teleportation” step with probability \(1 - \alpha\) to avoid dead ends.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The steady-state distribution of this walk is the PageRank vector, found as
    the principal eigenvector of the transition matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE953]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Build a small directed graph
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE954]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/440b6f5f30f2c7ae2cd5fdb8916a4abf.png)*  *2.  Build adjacency
    and transition matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE955]'
  prefs: []
  type: TYPE_PRE
- en: '*3.  Add teleportation (Google matrix)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE956]'
  prefs: []
  type: TYPE_PRE
- en: '*4.  Power iteration to compute PageRank'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE957]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE958]*  *5.  Compare with NetworkX built-in'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE959]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE960]*  *6.  Visualize node importance'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE961]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/ac7f2dd680a381cbf94a5abf3494be32.png)******  ***#### Try It
    Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Change \(\alpha\) (e.g., 0.6 vs 0.95). Does ranking change?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a “dangling node” with no outlinks. How does teleportation handle it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try PageRank on a larger graph (like a random graph with 50 nodes).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PageRank is a random-walk steady state problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reduces to finding the dominant eigenvector of the Google matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This method generalizes beyond webpages - to influence ranking, recommendation,
    and network analysis.****  ***### 99\. Numerical Linear Algebra Essentials (Floating
    Point, BLAS/LAPACK)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When working with linear algebra on computers, numbers are not exact. They live
    in floating-point arithmetic, and computations rely on highly optimized libraries
    like BLAS and LAPACK. Understanding these essentials is crucial to doing linear
    algebra at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Floating Point Basics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Numbers are stored in base-2 scientific notation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \[ x = \pm (1.b_1b_2b_3\ldots) \times 2^e \]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Limited precision means rounding errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two key constants:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Machine epsilon ($\(): smallest difference detectable (\)^{-16}$ for double).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overflow/underflow: too large or too small to represent.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Set Up Your Lab
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE962]'
  prefs: []
  type: TYPE_PRE
- en: '*#### Step-by-Step Code Walkthrough'
  prefs: []
  type: TYPE_NORMAL
- en: Machine epsilon
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE963]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE964]*  *2.  Round-off error demo'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE965]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE966]*  *3.  Stability of matrix inversion'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE967]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE968]*  *Notice: using `np.linalg.inv` can be less stable - better to solve
    directly.'
  prefs: []
  type: TYPE_NORMAL
- en: Conditioning of a matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE969]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE970]*  **   Large condition number → small input changes cause big output
    changes.'
  prefs: []
  type: TYPE_NORMAL
- en: BLAS/LAPACK under the hood
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE971]'
  prefs: []
  type: TYPE_PRE
- en: '*This `@` operator is not a naive loop - it calls a highly optimized C/Fortran
    routine.*****  ***#### Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Compare solving `Ax = b` with `np.linalg.solve` vs `np.linalg.inv(A) @ b` for
    larger, ill-conditioned systems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `np.linalg.svd` on a nearly singular matrix. How stable are the singular
    values?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check performance: time `A @ B` for sizes 100, 500, 1000.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Numerical linear algebra = math + floating-point reality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always prefer stable algorithms (`solve`, `qr`, `svd`) over naive inversion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries like BLAS/LAPACK make large computations fast, but understanding precision
    and conditioning prevents nasty surprises.****  ***### 100\. Capstone Problem
    Sets and Next Steps (A Roadmap to Mastery)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This final section ties everything together. Instead of introducing a new topic,
    it provides capstone labs that combine multiple ideas from the book. Working through
    them will give you confidence that you can apply linear algebra to real problems.
  prefs: []
  type: TYPE_NORMAL
- en: Problem Set 1 - Image Compression with SVD
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Take an image, treat it as a matrix, and approximate it with low-rank SVD.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE972]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/c0af6e97c0f8e3944a13019cad97b6ec.png)*  *Try different \(k\)
    values (5, 20, 100). How does quality vs. compression trade off?*  *#### Problem
    Set 2 - Predictive Modeling with PCA + Regression'
  prefs: []
  type: TYPE_NORMAL
- en: Combine PCA for dimensionality reduction with linear regression for prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE973]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE974]*  *Does reducing dimensions improve or hurt accuracy?*  *#### Problem
    Set 3 - Graph Analysis with PageRank'
  prefs: []
  type: TYPE_NORMAL
- en: Apply PageRank to a custom-built network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE975]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/81b77d4fb0ee96e5b3ce5fc6ce9a7ac3.png)*  *Which nodes dominate?
    How does structure affect ranking?*  *#### Problem Set 4 - Solving Differential
    Equations with Eigen Decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: Use eigenvalues/eigenvectors to solve a linear dynamical system.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE976]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE977]*  *Predict long-term behavior: will the system decay, oscillate,
    or grow?*  *#### Problem Set 5 - Least Squares for Overdetermined Systems'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE978]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE979]*  *Compare estimated vs. true coefficients. How close are they?*  *####
    Try It Yourself'
  prefs: []
  type: TYPE_NORMAL
- en: Combine SVD and recommender systems - build a movie recommender with synthetic
    data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement Gram–Schmidt by hand and test it against `np.linalg.qr`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a mini “linear algebra toolkit” with your favorite helper functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Takeaway
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You’ve practiced vectors, matrices, systems, eigenvalues, SVD, PCA, PageRank,
    and more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real problems often combine multiple concepts - the labs show how everything
    fits together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next steps: dive deeper into numerical linear algebra, explore machine learning
    applications, or study advanced matrix factorizations (Jordan form, tensor decompositions).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes the hands-on journey. By now, you don’t just know the theory
    - you can use linear algebra as a working tool in Python for data, science, and
    engineering.***********************************************************
  prefs: []
  type: TYPE_NORMAL
