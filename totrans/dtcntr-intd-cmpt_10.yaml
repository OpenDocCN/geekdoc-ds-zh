- en: 4.2¬†Processing Tablesüîó
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://dcic-world.org/2025-08-27/processing-tables.html](https://dcic-world.org/2025-08-27/processing-tables.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| ¬†¬†¬†¬†[4.2.1¬†Cleaning Data Tables](#%28part._cleaning-tables%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.1.1¬†Loading Data Tables](#%28part._loading-tables%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†¬†¬†[4.2.1.1.1¬†Loading Tables from Google Sheets in CPO](#%28part._loading-tables-from-google-sheets%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†¬†¬†[4.2.1.1.2¬†Loading Tables from CSV files in VSCode](#%28part._loading-tables-from-csv%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†¬†¬†[4.2.1.1.3¬†Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.1.2¬†Dealing with Missing Entries](#%28part._missing-data%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.1.3¬†Normalizing Data](#%28part._.Normalizing_.Data%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.1.4¬†Normalization, Systematically](#%28part._.Normalization__.Systematically%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.1.5¬†Using Programs to Detect Data Errors](#%28part._.Using_.Programs_to_.Detect_.Data_.Errors%29)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[4.2.2¬†Task Plans](#%28part._task-plans%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[4.2.3¬†Preparing Data Tables](#%28part._preparing-tables%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.3.1¬†Creating bins](#%28part._creating._bins%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†¬†¬†[4.2.3.2¬†Splitting Columns](#%28part._splitting-columns%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[4.2.4¬†Managing and Naming Data Tables](#%28part._naming-tables%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[4.2.5¬†Visualizations and Plots](#%28part._visualizing-tables%29) |'
  prefs: []
  type: TYPE_TB
- en: '| ¬†¬†¬†¬†[4.2.6¬†Summary: Managing a Data Analysis](#%28part._.Summary__.Managing_a_.Data_.Analysis%29)
    |'
  prefs: []
  type: TYPE_TB
- en: In data analysis, we often work with large datasets, some of which were collected
    by someone else. Datasets don‚Äôt necessarily come in a form that we can work with.
    We might need the raw data pulled apart or condensed to coarser granularity. Some
    data might be missing or entered incorrectly. On top of that, we have to plan
    for long-term maintenance of our datasets or analysis programs. Finally, we typically
    want to use visualizations to either communicate our data or to check for issues
    with our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a concrete example, assume that you are doing data analysis and support
    for a company that manages ticket sales for events. People purchase tickets through
    an online form. The form software creates a spreadsheet with all the entered data,
    which is what you have to work with. Here‚Äôs a screenshot of a [sample spreadsheet](https://docs.google.com/spreadsheets/d/1Ks4ll5_8wyYK1zyXMm_21KORhagSMZ59dcr7i3qY6T4):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/859438ff94b2fbba57b086c8702afb34.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Take a look at the table. What do you notice that might affect using the data
    in an analysis? Or for the operations for managing an event?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Some issues jump out quickly: the `three` in the `"Num Tickets"` column, differences
    in capitalization in the `"Discount Code"` column, and the use of each of `"none"`
    and blank spaces in the the `"Discount Code"` column (you may have spotted additional
    issues). Before we do any analysis with this dataset, we need to clean it up so
    that our analysis will be reliable. In addition, sometimes our dataset is clean,
    but it needs to be adjusted or prepared to fit the questions we want to ask. This
    chapter looks at both steps, and the programming techniques that are helpful for
    them.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1¬†Cleaning Data Tables[üîó](#(part._cleaning-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 4.2.1.1¬†Loading Data Tables[üîó](#(part._loading-tables) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using VSCode, you can load tables directly from CSV files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.1¬†Loading Tables from Google Sheets in CPO[üîó](#(part._loading-tables-from-google-sheets)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. We‚Äôll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.2¬†Loading Tables from CSV files in VSCode[üîó](#(part._loading-tables-from-csv)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load from a CSV file via URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Load from a CSV file on your computer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.3¬†Dealing with Columns with Multiple Types of Data[üîó](#(part._cols-multiple-types-data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we aren‚Äôt throwing out useful information that
    was simply entered incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  prefs: []
  type: TYPE_NORMAL
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.2.1.2¬†Dealing with Missing Entries[üîó](#(part._missing-data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell ‚Äì there‚Äôs no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  prefs: []
  type: TYPE_NORMAL
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether you‚Äôre reading from Google Sheets or CSV files).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isn‚Äôt a string. What‚Äôs going on?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Look also at the last two rows (for Zander and Shweta) ‚Äì they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells weren‚Äôt actually
    empty in the Google Sheet, but instead contained several spaces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernie‚Äôs row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Sam‚Äôs row)?'
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Here‚Äôs how
    we modify the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Aren‚Äôt zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Zip codes are a terrific example of data that are written with digits, but aren‚Äôt
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we don‚Äôt write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    We‚Äôll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  prefs: []
  type: TYPE_NORMAL
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  prefs: []
  type: TYPE_NORMAL
- en: The lack of meaningful default values is one reason why Pyret doesn‚Äôt leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.3¬†Normalizing Data[üîó](#(part._.Normalizing_.Data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next, let‚Äôs look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You can‚Äôt answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  prefs: []
  type: TYPE_IMG
- en: How do we get to this table? How do we figure this out if we aren‚Äôt sure?
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyret‚Äôs `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  prefs: []
  type: TYPE_NORMAL
- en: Get `"none"` to appear in every cell that currently lacks a value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert all the codes that aren‚Äôt `"none"` to upper case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fortunately, these tasks align with functions we‚Äôve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can capture these together in a function that takes in and produces a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE8]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process can‚Äôt
    produce different capitalizations of `"none"`, we should include that as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Here‚Äôs the modified code,
    on which all the examples pass.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE11]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that we‚Äôve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What‚Äôs with that first row, with the discount code `" "`? Where might that have
    come from?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Maybe you didn‚Äôt notice this before (or wouldn‚Äôt have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.4¬†Normalization, Systematically[üîó](#(part._.Normalization__.Systematically)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: via a drop-down menu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: in a text-entry box
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A drop-down menu automatically normalizes the data, so that‚Äôs not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So let‚Äôs assume this is from a text-entry
    box.
  prefs: []
  type: TYPE_NORMAL
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, you‚Äôd have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. ‚Äì these are questions of policy, not of programming).
  prefs: []
  type: TYPE_NORMAL
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once you‚Äôve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now we‚Äôre getting ahead of ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 4.2.1.5¬†Using Programs to Detect Data Errors[üîó](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Let‚Äôs consider the `"email"` column: that‚Äôs
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Let‚Äôs consider two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Valid email addresses should contain an `@` sign
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program can‚Äôt be written to perform the fixing.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2¬†Task Plans[üîó](#(part._task-plans) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before we move on, it‚Äôs worth stepping back to reflect on our process for producing
    the discount-summary table. We started from a concrete example, checked the documentation
    for a built-in function that might help, then manipulated our data to work with
    that function. These are part of a more general process that applies to data and
    problems beyond tables. We‚Äôll refer to this process as task planning. Specifically,
    a task plan is a sequence of steps (tasks) that decompose a computational problem
    into smaller steps (sub-tasks). A useful task plan contains sub-tasks that you
    know how to implement, either by using a built-in function or writing your own.
    There is no single notation or format for task plans. For some problems, a bulleted-list
    of steps will suffice. For others, a diagram showing how data transform through
    a problem is more helpful. This is a personal choice tailored to a specific problem.
    The goal is simply to decompose a problem into something of a programming to-do
    list, to help you manage the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy: Creating a Task Plan'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Develop a concrete example showing the desired output on a given input (you
    pick the input: a good one is large enough to show different features of your
    inputs, but small enough to work with manually during planning. For table problems,
    roughly 4-6 rows usually works well in practice).'
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mentally identify functions that you already know (or that you find in the documentation)
    that might be useful for transforming the input data to the output data.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Develop a sequence of steps‚Äî<wbr>whether as pictures, textual descriptions of
    computations, or a combination of the two‚Äî<wbr>that could be used to solve the
    problem. If you are using pictures, draw out the intermediate data values from
    your concrete example and make notes on what operations might be useful to get
    from one intermediate value to the next. The functions you identified in the previous
    step should show up here.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat the previous step, breaking down the subtasks until you believe you could
    write expressions or functions to perform each step or data transformation.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: Here‚Äôs a diagram-based task plan for the `discount-summary` program that we
    just developed. We‚Äôve drawn this on paper to highlight that task plans are not
    written within a programming environment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09978b14040aceae2e35d06715cb920e.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have a plan, you turn it into a program by writing expressions and
    functions for the intermediate steps, passing the output of one step as the input
    of the next. Sometimes, we look at a problem and immediately know how to write
    the code for it (if it is a kind of problem that you‚Äôve solved many times before).
    When you don‚Äôt immediately see the solution, use this process and break down the
    problem by working with concrete examples of data.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You‚Äôve been asked to develop a program that identifies the student with the
    largest improvement from the midterm to the final exam in a course. Your input
    table will have columns for each exam as well as for student names. Write a task
    plan for this problem.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Some task plans involve more than just a sequence of table values. Sometimes,
    we do multiple transformations to the same table to extract different pieces of
    data, then compute over those data. In that case, we draw our plan with branches
    that show the different computations that come together in the final result. Continuing
    with the gradebook, for example, you might be asked to write a program to compute
    the difference between the largest and lowest scores on the midterm. That task
    plan might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
  prefs: []
  type: TYPE_IMG
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You‚Äôve been given a table of weather data that has columns for the date, amount
    of precipitation, and highest temperature for the day. You‚Äôve been asked to compute
    whether there were more snowy days in January than in February, where a day is
    snowy if the highest temperature is below freezing and the precipitation was more
    than zero.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The takeaway of this strategy is easy to state:'
  prefs: []
  type: TYPE_NORMAL
- en: If you aren‚Äôt sure how to approach a problem, don‚Äôt start by trying to write
    code. Plan until you understand the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Newer programmers often ignore this advice, assuming that the fastest way to
    produce working code for a programming problem is to start writing code (especially
    if you see classmates who are able to jump directly to writing code). Experienced
    programmers know that trying to write all the code before you‚Äôve understood the
    problem will take much longer than stepping back and understanding the problem
    first. As you develop your programming skills, the specific format of your task
    plans will evolve (and indeed, we will see some cases of this later in the book
    as well). But the core idea is the same: use concrete examples to help identify
    the intermediate computations that will need, then convert those intermediate
    computations to code after or as you figure them out.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3¬†Preparing Data Tables[üîó](#(part._preparing-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sometimes, the data we have is clean (in that we‚Äôve normalized the data and
    dealt with errors), but it still isn‚Äôt in a format that we can use for the analysis
    that we want to run. For example, what if we want to look at the distribution
    of small, medium, and large ticket orders? In our current table, we have the number
    of tickets in an order, but not an explicit label on the scale of that order.
    If we wanted to produce some sort of chart showing our order scales, we will need
    to make those labels explicit.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3.1¬†Creating bins[üîó](#(part._creating._bins) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs an example of creating bins for the scale of the ticket orders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 4.2.3.2¬†Splitting Columns[üîó](#(part._splitting-columns) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a person‚Äôs name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Responsible Computing: Representing Names'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. It‚Äôs okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for ‚Äúfalsehoods programmers believe about ...‚Äù, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
- en: 4.2.4¬†Managing and Naming Data Tables[üîó](#(part._naming-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At this point, we have worked with several versions of the events table:'
  prefs: []
  type: TYPE_NORMAL
- en: The original dataset that we tried to load
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new sheet of the dataset with manual corrections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The version with the discount codes normalized
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another version that normalized the delivery mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The version extended with the order-scale column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which of these versions should get explicit names within our code file?
  prefs: []
  type: TYPE_NORMAL
- en: Usually, we keep both the original raw source datasheet, as well as the copy
    with our manual corrections. Why? In case we ever have to look at the original
    data again, either to identify kinds of errors that people were making or to apply
    different fixes.
  prefs: []
  type: TYPE_NORMAL
- en: For similar reasons, we want to keep the cleaned (normalized) data separate
    from the version that we initially loaded. Fortunately, Pyret helps with this
    since it creates new tables, rather than modify the prior ones. If we have to
    normalize multiple columns, however, do we really need a new name for every intermediate
    table?
  prefs: []
  type: TYPE_NORMAL
- en: 'As a general rule, we usually maintain separate names for the initially-loaded
    table, the cleaned table, and for significant variations for analysis purposes.
    In our code, this might mean having names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: where `yes-to-email` is a function we have not written, but that might have
    normalized the `"yes"` value in the `"delivery"` column. Note that we applied
    each of the normalizations in sequence, naming only the final table with all normalizations
    applied. In professional practice, if you were working with a very large dataset,
    you might just write the cleaned dataset out to a file, so that you loaded only
    the clean version during analysis. We will look at writing to file later. Having
    only a few table names will reduce your own confusion when working with your files.
    If you work on multiple data-analyses, developing a consistent strategy for how
    you name your tables will likely help you better manage your code as you switch
    between projects.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.5¬†Visualizations and Plots[üîó](#(part._visualizing-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that our data are cleaned and prepared, we are ready to analyze it. What
    might we want to know? Perhaps we want to know which discount code has been used
    most often. Maybe we want to know whether the time when a purchase was made correlates
    with how many tickets people buy. There‚Äôs a host of different kinds of visualizations
    and plots that people use to summarize data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Which plot type to use depends on both the question and the data at hand. The
    nature of variables in a dataset helps determine relevant plots or statistical
    operations. An attribute or variable in a dataset (i.e., a single column of a
    table) can be classified as one of several different kinds, including:'
  prefs: []
  type: TYPE_NORMAL
- en: 'quantitative: a variable whose values are numeric and can be ordered with a
    consistent interval between values. They are meaningful to use in computations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'categorical: a variable with a fixed set of values. The values may have an
    order, but there are no meaningful computational operations between the values
    other than ordering. Such variables usually correspond to characteristics of your
    samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which kind of variable are last names? Grades in courses? Zipcodes?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Common plots and the kinds of variables they require include:'
  prefs: []
  type: TYPE_NORMAL
- en: Scatterplots show relationships between two quantitative variables, with one
    variable on each axis of a 2D chart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequency Bar charts show the frequency of each categorical value within a column
    of a dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms segment quantitative data into equal-size intervals, showing the
    distribution of values across each interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pie charts show the proportion of cells in a column across the categorical values
    in a dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Map each of the following questions to a chart type, based on the kinds of
    variables involved in the question:'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which discount code has been used most often?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Is there a relationship between the number of tickets purchased in one order
    and the time of purchase?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: How many orders have been made for each delivery option?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, we might use a frequency-bar-chart to answer the third question.
    Based on the `Table` documentation, we would generate this using the following
    code (with similar style for the other kinds of plots):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Which yields the following chart (assuming we had not actually normalized the
    contents of the `"delivery"` column):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Whoa ‚Äì where did that extra `"email"` column come from? If you look closely,
    you‚Äôll spot the error: in the row for `"Alvina"`, there‚Äôs a typo (`"emall"` with
    an `l` instead of an `i`) in the discount column (drop-down menus, anyone?).'
  prefs: []
  type: TYPE_NORMAL
- en: The lesson here is that plots and visualizations are valuable not only in the
    analysis phase, but also early on, when we are trying to sanity check that our
    data are clean and ready to use. Good data scientists never trust a dataset without
    first making sure that the values make sense. In larger datasets, manually inspecting
    all of the data is often infeasible. But creating some plots or other summaries
    of the data is also useful for identifying errors.
  prefs: []
  type: TYPE_NORMAL
- en: '4.2.6¬†Summary: Managing a Data Analysis[üîó](#(part._.Summary__.Managing_a_.Data_.Analysis)
    "Link to here")'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This chapter has given you a high-level overview of how to use coding for managing
    and processing data. When doing any data analysis, a good data practitioner undergoes
    several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think about the data in each column: what are plausible values in the column,
    and what kinds of errors might be in that column based on what you know about
    the data collection methods?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the data for errors, using a combination of manual inspection of the table,
    plots, and `filter-with` expressions that check for unexpected values. Normalize
    or correct the data, either at the source (if you control that) or via small programs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store the normalized/cleaned data table, either as a name in your program, or
    by saving it back out to a new file. Leave the raw data intact (in case you need
    to refer to the original later).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prepare the data based on the questions you want to ask about it: compute new
    columns, bin existing columns, or combine data from across tables. You can either
    finish all preparations and name the final table, or you can make separate preparations
    for each question, naming the per-question tables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At last, perform your analysis, using the statistical methods, visualizations,
    and interpretations that make sense for the question and kinds of variables involved.
    When you report out on the data, always store notes about the file that holds
    your analysis code, and which parts of the file were used to generate each graph
    or interpretation in your report.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There‚Äôs a lot more to managing data and performing analysis than this book can
    cover. There are entire books, degrees, and careers in each of the management
    of data and its analysis. One area we have not discussed, for example, is machine
    learning, in which programs (that others have written) are used to make predictions
    from datasets (in contrast, this chapter has focused on projects in which you
    will use summary statistics and visualizations to perform analysis). These skills
    covered in this chapter are all prerequisites for using machine learning effectively
    and responsibly. But we still have much more to explore and understand about data
    themselves, which we turn to in the coming chapters. Onward!
  prefs: []
  type: TYPE_NORMAL
- en: 'Responsible Computing: Bias in Statistical Prediction'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In a book that is discussing data and social responsibility, we would be remiss
    in not at least mentioning some of the many issues that arise when using data
    to make predictions (via techniques like machine learning). Some issues arise
    from problems with the data themselves (e.g., whether samples are representative,
    or whether correlations between variables lead to discrimination as in algorithmic
    hiring). Others arise with how data collected for one purpose is misused to make
    predictions for another. Still more arise with the interpretation of results.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: These are all rich topics. There are myriad articles which you could read at
    this point to begin to understand the pitfalls (and benefits) of algorithmic decision
    making. This book will focus instead on issues that arise from the programs we
    are teaching you to write, leaving other courses, or the interests of instructors,
    to augment the material as appropriate for readers‚Äô contexts.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 4.2.1¬†Cleaning Data Tables[üîó](#(part._cleaning-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 4.2.1.1¬†Loading Data Tables[üîó](#(part._loading-tables) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using VSCode, you can load tables directly from CSV files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.1¬†Loading Tables from Google Sheets in CPO[üîó](#(part._loading-tables-from-google-sheets)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. We‚Äôll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.2¬†Loading Tables from CSV files in VSCode[üîó](#(part._loading-tables-from-csv)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load from a CSV file via URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Load from a CSV file on your computer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.3¬†Dealing with Columns with Multiple Types of Data[üîó](#(part._cols-multiple-types-data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we aren‚Äôt throwing out useful information that
    was simply entered incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  prefs: []
  type: TYPE_NORMAL
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.2.1.2¬†Dealing with Missing Entries[üîó](#(part._missing-data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell ‚Äì there‚Äôs no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  prefs: []
  type: TYPE_NORMAL
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether you‚Äôre reading from Google Sheets or CSV files).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isn‚Äôt a string. What‚Äôs going on?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Look also at the last two rows (for Zander and Shweta) ‚Äì they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells weren‚Äôt actually
    empty in the Google Sheet, but instead contained several spaces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernie‚Äôs row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Sam‚Äôs row)?'
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Here‚Äôs how
    we modify the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Aren‚Äôt zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Zip codes are a terrific example of data that are written with digits, but aren‚Äôt
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we don‚Äôt write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    We‚Äôll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  prefs: []
  type: TYPE_NORMAL
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  prefs: []
  type: TYPE_NORMAL
- en: The lack of meaningful default values is one reason why Pyret doesn‚Äôt leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.3¬†Normalizing Data[üîó](#(part._.Normalizing_.Data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next, let‚Äôs look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You can‚Äôt answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  prefs: []
  type: TYPE_IMG
- en: How do we get to this table? How do we figure this out if we aren‚Äôt sure?
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyret‚Äôs `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  prefs: []
  type: TYPE_NORMAL
- en: Get `"none"` to appear in every cell that currently lacks a value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert all the codes that aren‚Äôt `"none"` to upper case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fortunately, these tasks align with functions we‚Äôve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can capture these together in a function that takes in and produces a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE26]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process can‚Äôt
    produce different capitalizations of `"none"`, we should include that as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Here‚Äôs the modified code,
    on which all the examples pass.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE29]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that we‚Äôve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What‚Äôs with that first row, with the discount code `" "`? Where might that have
    come from?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Maybe you didn‚Äôt notice this before (or wouldn‚Äôt have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.4¬†Normalization, Systematically[üîó](#(part._.Normalization__.Systematically)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: via a drop-down menu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: in a text-entry box
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A drop-down menu automatically normalizes the data, so that‚Äôs not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So let‚Äôs assume this is from a text-entry
    box.
  prefs: []
  type: TYPE_NORMAL
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, you‚Äôd have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. ‚Äì these are questions of policy, not of programming).
  prefs: []
  type: TYPE_NORMAL
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once you‚Äôve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now we‚Äôre getting ahead of ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 4.2.1.5¬†Using Programs to Detect Data Errors[üîó](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Let‚Äôs consider the `"email"` column: that‚Äôs
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Let‚Äôs consider two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Valid email addresses should contain an `@` sign
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program can‚Äôt be written to perform the fixing.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1¬†Loading Data Tables[üîó](#(part._loading-tables) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using VSCode, you can load tables directly from CSV files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.1¬†Loading Tables from Google Sheets in CPO[üîó](#(part._loading-tables-from-google-sheets)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. We‚Äôll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.2¬†Loading Tables from CSV files in VSCode[üîó](#(part._loading-tables-from-csv)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load from a CSV file via URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Load from a CSV file on your computer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.3¬†Dealing with Columns with Multiple Types of Data[üîó](#(part._cols-multiple-types-data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we aren‚Äôt throwing out useful information that
    was simply entered incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  prefs: []
  type: TYPE_NORMAL
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.2.1.1.1¬†Loading Tables from Google Sheets in CPO[üîó](#(part._loading-tables-from-google-sheets)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. We‚Äôll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.2¬†Loading Tables from CSV files in VSCode[üîó](#(part._loading-tables-from-csv)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load from a CSV file via URL:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Load from a CSV file on your computer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.1.3¬†Dealing with Columns with Multiple Types of Data[üîó](#(part._cols-multiple-types-data)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we aren‚Äôt throwing out useful information that
    was simply entered incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  prefs: []
  type: TYPE_NORMAL
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4.2.1.2¬†Dealing with Missing Entries[üîó](#(part._missing-data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell ‚Äì there‚Äôs no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  prefs: []
  type: TYPE_NORMAL
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether you‚Äôre reading from Google Sheets or CSV files).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isn‚Äôt a string. What‚Äôs going on?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Look also at the last two rows (for Zander and Shweta) ‚Äì they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells weren‚Äôt actually
    empty in the Google Sheet, but instead contained several spaces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernie‚Äôs row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Sam‚Äôs row)?'
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
- en: '`event-data` will be the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Here‚Äôs how
    we modify the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Aren‚Äôt zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Zip codes are a terrific example of data that are written with digits, but aren‚Äôt
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we don‚Äôt write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    We‚Äôll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  prefs: []
  type: TYPE_NORMAL
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  prefs: []
  type: TYPE_NORMAL
- en: The lack of meaningful default values is one reason why Pyret doesn‚Äôt leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.3¬†Normalizing Data[üîó](#(part._.Normalizing_.Data) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next, let‚Äôs look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You can‚Äôt answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  prefs: []
  type: TYPE_IMG
- en: How do we get to this table? How do we figure this out if we aren‚Äôt sure?
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyret‚Äôs `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  prefs: []
  type: TYPE_NORMAL
- en: Get `"none"` to appear in every cell that currently lacks a value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert all the codes that aren‚Äôt `"none"` to upper case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fortunately, these tasks align with functions we‚Äôve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can capture these together in a function that takes in and produces a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE43]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process can‚Äôt
    produce different capitalizations of `"none"`, we should include that as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Here‚Äôs the modified code,
    on which all the examples pass.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]uppercase all strings other than none,'
  prefs: []
  type: TYPE_NORMAL
- en: convert blank cells to contain none[PRE46]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now that we‚Äôve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  prefs: []
  type: TYPE_IMG
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What‚Äôs with that first row, with the discount code `" "`? Where might that have
    come from?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Maybe you didn‚Äôt notice this before (or wouldn‚Äôt have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1.4¬†Normalization, Systematically[üîó](#(part._.Normalization__.Systematically)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: via a drop-down menu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: in a text-entry box
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A drop-down menu automatically normalizes the data, so that‚Äôs not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So let‚Äôs assume this is from a text-entry
    box.
  prefs: []
  type: TYPE_NORMAL
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  prefs: []
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, you‚Äôd have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. ‚Äì these are questions of policy, not of programming).
  prefs: []
  type: TYPE_NORMAL
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once you‚Äôve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now we‚Äôre getting ahead of ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 4.2.1.5¬†Using Programs to Detect Data Errors[üîó](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Let‚Äôs consider the `"email"` column: that‚Äôs
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Let‚Äôs consider two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Valid email addresses should contain an `@` sign
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program can‚Äôt be written to perform the fixing.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2¬†Task Plans[üîó](#(part._task-plans) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before we move on, it‚Äôs worth stepping back to reflect on our process for producing
    the discount-summary table. We started from a concrete example, checked the documentation
    for a built-in function that might help, then manipulated our data to work with
    that function. These are part of a more general process that applies to data and
    problems beyond tables. We‚Äôll refer to this process as task planning. Specifically,
    a task plan is a sequence of steps (tasks) that decompose a computational problem
    into smaller steps (sub-tasks). A useful task plan contains sub-tasks that you
    know how to implement, either by using a built-in function or writing your own.
    There is no single notation or format for task plans. For some problems, a bulleted-list
    of steps will suffice. For others, a diagram showing how data transform through
    a problem is more helpful. This is a personal choice tailored to a specific problem.
    The goal is simply to decompose a problem into something of a programming to-do
    list, to help you manage the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy: Creating a Task Plan'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Develop a concrete example showing the desired output on a given input (you
    pick the input: a good one is large enough to show different features of your
    inputs, but small enough to work with manually during planning. For table problems,
    roughly 4-6 rows usually works well in practice).'
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mentally identify functions that you already know (or that you find in the documentation)
    that might be useful for transforming the input data to the output data.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Develop a sequence of steps‚Äî<wbr>whether as pictures, textual descriptions of
    computations, or a combination of the two‚Äî<wbr>that could be used to solve the
    problem. If you are using pictures, draw out the intermediate data values from
    your concrete example and make notes on what operations might be useful to get
    from one intermediate value to the next. The functions you identified in the previous
    step should show up here.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat the previous step, breaking down the subtasks until you believe you could
    write expressions or functions to perform each step or data transformation.
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
- en: Here‚Äôs a diagram-based task plan for the `discount-summary` program that we
    just developed. We‚Äôve drawn this on paper to highlight that task plans are not
    written within a programming environment.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/09978b14040aceae2e35d06715cb920e.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have a plan, you turn it into a program by writing expressions and
    functions for the intermediate steps, passing the output of one step as the input
    of the next. Sometimes, we look at a problem and immediately know how to write
    the code for it (if it is a kind of problem that you‚Äôve solved many times before).
    When you don‚Äôt immediately see the solution, use this process and break down the
    problem by working with concrete examples of data.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You‚Äôve been asked to develop a program that identifies the student with the
    largest improvement from the midterm to the final exam in a course. Your input
    table will have columns for each exam as well as for student names. Write a task
    plan for this problem.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Some task plans involve more than just a sequence of table values. Sometimes,
    we do multiple transformations to the same table to extract different pieces of
    data, then compute over those data. In that case, we draw our plan with branches
    that show the different computations that come together in the final result. Continuing
    with the gradebook, for example, you might be asked to write a program to compute
    the difference between the largest and lowest scores on the midterm. That task
    plan might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
  prefs: []
  type: TYPE_IMG
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You‚Äôve been given a table of weather data that has columns for the date, amount
    of precipitation, and highest temperature for the day. You‚Äôve been asked to compute
    whether there were more snowy days in January than in February, where a day is
    snowy if the highest temperature is below freezing and the precipitation was more
    than zero.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The takeaway of this strategy is easy to state:'
  prefs: []
  type: TYPE_NORMAL
- en: If you aren‚Äôt sure how to approach a problem, don‚Äôt start by trying to write
    code. Plan until you understand the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Newer programmers often ignore this advice, assuming that the fastest way to
    produce working code for a programming problem is to start writing code (especially
    if you see classmates who are able to jump directly to writing code). Experienced
    programmers know that trying to write all the code before you‚Äôve understood the
    problem will take much longer than stepping back and understanding the problem
    first. As you develop your programming skills, the specific format of your task
    plans will evolve (and indeed, we will see some cases of this later in the book
    as well). But the core idea is the same: use concrete examples to help identify
    the intermediate computations that will need, then convert those intermediate
    computations to code after or as you figure them out.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3¬†Preparing Data Tables[üîó](#(part._preparing-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sometimes, the data we have is clean (in that we‚Äôve normalized the data and
    dealt with errors), but it still isn‚Äôt in a format that we can use for the analysis
    that we want to run. For example, what if we want to look at the distribution
    of small, medium, and large ticket orders? In our current table, we have the number
    of tickets in an order, but not an explicit label on the scale of that order.
    If we wanted to produce some sort of chart showing our order scales, we will need
    to make those labels explicit.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3.1¬†Creating bins[üîó](#(part._creating._bins) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs an example of creating bins for the scale of the ticket orders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 4.2.3.2¬†Splitting Columns[üîó](#(part._splitting-columns) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a person‚Äôs name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Responsible Computing: Representing Names'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. It‚Äôs okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for ‚Äúfalsehoods programmers believe about ...‚Äù, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
- en: 4.2.3.1¬†Creating bins[üîó](#(part._creating._bins) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs an example of creating bins for the scale of the ticket orders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 4.2.3.2¬†Splitting Columns[üîó](#(part._splitting-columns) "Link to here")
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a person‚Äôs name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Responsible Computing: Representing Names'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. It‚Äôs okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for ‚Äúfalsehoods programmers believe about ...‚Äù, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
- en: 4.2.4¬†Managing and Naming Data Tables[üîó](#(part._naming-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At this point, we have worked with several versions of the events table:'
  prefs: []
  type: TYPE_NORMAL
- en: The original dataset that we tried to load
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new sheet of the dataset with manual corrections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The version with the discount codes normalized
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another version that normalized the delivery mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The version extended with the order-scale column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which of these versions should get explicit names within our code file?
  prefs: []
  type: TYPE_NORMAL
- en: Usually, we keep both the original raw source datasheet, as well as the copy
    with our manual corrections. Why? In case we ever have to look at the original
    data again, either to identify kinds of errors that people were making or to apply
    different fixes.
  prefs: []
  type: TYPE_NORMAL
- en: For similar reasons, we want to keep the cleaned (normalized) data separate
    from the version that we initially loaded. Fortunately, Pyret helps with this
    since it creates new tables, rather than modify the prior ones. If we have to
    normalize multiple columns, however, do we really need a new name for every intermediate
    table?
  prefs: []
  type: TYPE_NORMAL
- en: 'As a general rule, we usually maintain separate names for the initially-loaded
    table, the cleaned table, and for significant variations for analysis purposes.
    In our code, this might mean having names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: where `yes-to-email` is a function we have not written, but that might have
    normalized the `"yes"` value in the `"delivery"` column. Note that we applied
    each of the normalizations in sequence, naming only the final table with all normalizations
    applied. In professional practice, if you were working with a very large dataset,
    you might just write the cleaned dataset out to a file, so that you loaded only
    the clean version during analysis. We will look at writing to file later. Having
    only a few table names will reduce your own confusion when working with your files.
    If you work on multiple data-analyses, developing a consistent strategy for how
    you name your tables will likely help you better manage your code as you switch
    between projects.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.5¬†Visualizations and Plots[üîó](#(part._visualizing-tables) "Link to here")
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that our data are cleaned and prepared, we are ready to analyze it. What
    might we want to know? Perhaps we want to know which discount code has been used
    most often. Maybe we want to know whether the time when a purchase was made correlates
    with how many tickets people buy. There‚Äôs a host of different kinds of visualizations
    and plots that people use to summarize data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Which plot type to use depends on both the question and the data at hand. The
    nature of variables in a dataset helps determine relevant plots or statistical
    operations. An attribute or variable in a dataset (i.e., a single column of a
    table) can be classified as one of several different kinds, including:'
  prefs: []
  type: TYPE_NORMAL
- en: 'quantitative: a variable whose values are numeric and can be ordered with a
    consistent interval between values. They are meaningful to use in computations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'categorical: a variable with a fixed set of values. The values may have an
    order, but there are no meaningful computational operations between the values
    other than ordering. Such variables usually correspond to characteristics of your
    samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which kind of variable are last names? Grades in courses? Zipcodes?
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Common plots and the kinds of variables they require include:'
  prefs: []
  type: TYPE_NORMAL
- en: Scatterplots show relationships between two quantitative variables, with one
    variable on each axis of a 2D chart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequency Bar charts show the frequency of each categorical value within a column
    of a dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms segment quantitative data into equal-size intervals, showing the
    distribution of values across each interval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pie charts show the proportion of cells in a column across the categorical values
    in a dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do Now!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Map each of the following questions to a chart type, based on the kinds of
    variables involved in the question:'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which discount code has been used most often?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Is there a relationship between the number of tickets purchased in one order
    and the time of purchase?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: How many orders have been made for each delivery option?
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, we might use a frequency-bar-chart to answer the third question.
    Based on the `Table` documentation, we would generate this using the following
    code (with similar style for the other kinds of plots):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Which yields the following chart (assuming we had not actually normalized the
    contents of the `"delivery"` column):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Whoa ‚Äì where did that extra `"email"` column come from? If you look closely,
    you‚Äôll spot the error: in the row for `"Alvina"`, there‚Äôs a typo (`"emall"` with
    an `l` instead of an `i`) in the discount column (drop-down menus, anyone?).'
  prefs: []
  type: TYPE_NORMAL
- en: The lesson here is that plots and visualizations are valuable not only in the
    analysis phase, but also early on, when we are trying to sanity check that our
    data are clean and ready to use. Good data scientists never trust a dataset without
    first making sure that the values make sense. In larger datasets, manually inspecting
    all of the data is often infeasible. But creating some plots or other summaries
    of the data is also useful for identifying errors.
  prefs: []
  type: TYPE_NORMAL
- en: '4.2.6¬†Summary: Managing a Data Analysis[üîó](#(part._.Summary__.Managing_a_.Data_.Analysis)
    "Link to here")'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This chapter has given you a high-level overview of how to use coding for managing
    and processing data. When doing any data analysis, a good data practitioner undergoes
    several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think about the data in each column: what are plausible values in the column,
    and what kinds of errors might be in that column based on what you know about
    the data collection methods?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check the data for errors, using a combination of manual inspection of the table,
    plots, and `filter-with` expressions that check for unexpected values. Normalize
    or correct the data, either at the source (if you control that) or via small programs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store the normalized/cleaned data table, either as a name in your program, or
    by saving it back out to a new file. Leave the raw data intact (in case you need
    to refer to the original later).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prepare the data based on the questions you want to ask about it: compute new
    columns, bin existing columns, or combine data from across tables. You can either
    finish all preparations and name the final table, or you can make separate preparations
    for each question, naming the per-question tables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At last, perform your analysis, using the statistical methods, visualizations,
    and interpretations that make sense for the question and kinds of variables involved.
    When you report out on the data, always store notes about the file that holds
    your analysis code, and which parts of the file were used to generate each graph
    or interpretation in your report.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There‚Äôs a lot more to managing data and performing analysis than this book can
    cover. There are entire books, degrees, and careers in each of the management
    of data and its analysis. One area we have not discussed, for example, is machine
    learning, in which programs (that others have written) are used to make predictions
    from datasets (in contrast, this chapter has focused on projects in which you
    will use summary statistics and visualizations to perform analysis). These skills
    covered in this chapter are all prerequisites for using machine learning effectively
    and responsibly. But we still have much more to explore and understand about data
    themselves, which we turn to in the coming chapters. Onward!
  prefs: []
  type: TYPE_NORMAL
- en: 'Responsible Computing: Bias in Statistical Prediction'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In a book that is discussing data and social responsibility, we would be remiss
    in not at least mentioning some of the many issues that arise when using data
    to make predictions (via techniques like machine learning). Some issues arise
    from problems with the data themselves (e.g., whether samples are representative,
    or whether correlations between variables lead to discrimination as in algorithmic
    hiring). Others arise with how data collected for one purpose is misused to make
    predictions for another. Still more arise with the interpretation of results.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: These are all rich topics. There are myriad articles which you could read at
    this point to begin to understand the pitfalls (and benefits) of algorithmic decision
    making. This book will focus instead on issues that arise from the programs we
    are teaching you to write, leaving other courses, or the interests of instructors,
    to augment the material as appropriate for readers‚Äô contexts.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
