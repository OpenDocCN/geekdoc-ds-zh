- en: 4.2Â Processing TablesğŸ”—
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4.2Â å¤„ç†è¡¨æ ¼ğŸ”—
- en: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/processing-tables.html](https://dcic-world.org/2025-08-27/processing-tables.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/processing-tables.html](https://dcic-world.org/2025-08-27/processing-tables.html)
- en: '| Â Â Â Â [4.2.1Â Cleaning Data Tables](#%28part._cleaning-tables%29) |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.1Â æ¸…ç†æ•°æ®è¡¨](#%28part._cleaning-tables%29) |'
- en: '| Â Â Â Â Â Â [4.2.1.1Â Loading Data Tables](#%28part._loading-tables%29) |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.1.1Â åŠ è½½æ•°æ®è¡¨](#%28part._loading-tables%29) |'
- en: '| Â Â Â Â Â Â Â Â [4.2.1.1.1Â Loading Tables from Google Sheets in CPO](#%28part._loading-tables-from-google-sheets%29)
    |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â Â Â [4.2.1.1.1 åœ¨ CPO ä¸­ä» Google Sheets åŠ è½½è¡¨æ ¼](#%28part._loading-tables-from-google-sheets%29)
    |'
- en: '| Â Â Â Â Â Â Â Â [4.2.1.1.2Â Loading Tables from CSV files in VSCode](#%28part._loading-tables-from-csv%29)
    |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â Â [4.2.1.1.2 åœ¨ VSCode ä¸­ä» CSV æ–‡ä»¶åŠ è½½è¡¨æ ¼](#%28part._loading-tables-from-csv%29)
    |'
- en: '| Â Â Â Â Â Â Â Â [4.2.1.1.3Â Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29)
    |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â Â Â [4.2.1.1.3Â å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—](#%28part._cols-multiple-types-data%29) |'
- en: '| Â Â Â Â Â Â [4.2.1.2Â Dealing with Missing Entries](#%28part._missing-data%29) |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.1.2Â å¤„ç†ç¼ºå¤±æ¡ç›®](#%28part._missing-data%29) |'
- en: '| Â Â Â Â Â Â [4.2.1.3Â Normalizing Data](#%28part._.Normalizing_.Data%29) |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.1.3Â è§„èŒƒåŒ–æ•°æ®](#%28part._.Normalizing_.Data%29) |'
- en: '| Â Â Â Â Â Â [4.2.1.4Â Normalization, Systematically](#%28part._.Normalization__.Systematically%29)
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.1.4Â ç³»ç»Ÿåœ°è§„èŒƒåŒ–](#%28part._.Normalization__.Systematically%29) |'
- en: '| Â Â Â Â Â Â [4.2.1.5Â Using Programs to Detect Data Errors](#%28part._.Using_.Programs_to_.Detect_.Data_.Errors%29)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.1.5Â ä½¿ç”¨ç¨‹åºæ£€æµ‹æ•°æ®é”™è¯¯](#%28part._.Using_.Programs_to_.Detect_.Data_.Errors%29)
    |'
- en: '| Â Â Â Â [4.2.2Â Task Plans](#%28part._task-plans%29) |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.2Â ä»»åŠ¡è®¡åˆ’](#%28part._task-plans%29) |'
- en: '| Â Â Â Â [4.2.3Â Preparing Data Tables](#%28part._preparing-tables%29) |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.3Â å‡†å¤‡æ•°æ®è¡¨](#%28part._preparing-tables%29) |'
- en: '| Â Â Â Â Â Â [4.2.3.1Â Creating bins](#%28part._creating._bins%29) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â Â Â [4.2.3.1Â åˆ›å»ºåŒºé—´](#%28part._creating._bins%29)'
- en: '| Â Â Â Â Â Â [4.2.3.2Â Splitting Columns](#%28part._splitting-columns%29) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â [4.2.3.2Â æ‹†åˆ†åˆ—](#%28part._splitting-columns%29) |'
- en: '| Â Â Â Â [4.2.4Â Managing and Naming Data Tables](#%28part._naming-tables%29) |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.4Â ç®¡ç†å’Œå‘½åæ•°æ®è¡¨](#%28part._naming-tables%29) |'
- en: '| Â Â Â Â [4.2.5Â Visualizations and Plots](#%28part._visualizing-tables%29) |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.5Â å¯è§†åŒ–å’Œå›¾è¡¨](#%28part._visualizing-tables%29) |'
- en: '| Â Â Â Â [4.2.6Â Summary: Managing a Data Analysis](#%28part._.Summary__.Managing_a_.Data_.Analysis%29)
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â Â Â Â [4.2.6Â æ€»ç»“ï¼šç®¡ç†æ•°æ®åˆ†æ](#%28part._.Summary__.Managing_a_.Data_.Analysis%29)
    |'
- en: In data analysis, we often work with large datasets, some of which were collected
    by someone else. Datasets donâ€™t necessarily come in a form that we can work with.
    We might need the raw data pulled apart or condensed to coarser granularity. Some
    data might be missing or entered incorrectly. On top of that, we have to plan
    for long-term maintenance of our datasets or analysis programs. Finally, we typically
    want to use visualizations to either communicate our data or to check for issues
    with our data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®åˆ†æä¸­ï¼Œæˆ‘ä»¬ç»å¸¸å¤„ç†å¤§å‹æ•°æ®é›†ï¼Œå…¶ä¸­ä¸€äº›æ•°æ®æ˜¯ç”±å…¶ä»–äººæ”¶é›†çš„ã€‚æ•°æ®é›†ä¸ä¸€å®šä»¥æˆ‘ä»¬å¯ä»¥å¤„ç†çš„å½¢å¼å‡ºç°ã€‚æˆ‘ä»¬å¯èƒ½éœ€è¦å°†åŸå§‹æ•°æ®æ‹†åˆ†æˆ–å‹ç¼©åˆ°æ›´ç²—çš„ç²’åº¦ã€‚ä¸€äº›æ•°æ®å¯èƒ½ç¼ºå¤±æˆ–è¾“å…¥é”™è¯¯ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸ºæ•°æ®é›†æˆ–åˆ†æç¨‹åºçš„é•¿æœŸç»´æŠ¤åšå‡ºè§„åˆ’ã€‚æœ€åï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›ä½¿ç”¨å¯è§†åŒ–æ¥ä¼ è¾¾æˆ‘ä»¬çš„æ•°æ®æˆ–æ£€æŸ¥æ•°æ®ä¸­å­˜åœ¨çš„é—®é¢˜ã€‚
- en: 'As a concrete example, assume that you are doing data analysis and support
    for a company that manages ticket sales for events. People purchase tickets through
    an online form. The form software creates a spreadsheet with all the entered data,
    which is what you have to work with. Hereâ€™s a screenshot of a [sample spreadsheet](https://docs.google.com/spreadsheets/d/1Ks4ll5_8wyYK1zyXMm_21KORhagSMZ59dcr7i3qY6T4):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä½œä¸ºå…·ä½“ä¾‹å­ï¼Œå‡è®¾ä½ æ­£åœ¨ä¸ºä¸€ä¸ªç®¡ç†æ´»åŠ¨ç¥¨åŠ¡çš„å…¬å¸è¿›è¡Œæ•°æ®åˆ†æå’Œæ”¯æŒå·¥ä½œã€‚äººä»¬é€šè¿‡åœ¨çº¿è¡¨å•è´­ä¹°é—¨ç¥¨ã€‚è¡¨å•è½¯ä»¶åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«æ‰€æœ‰è¾“å…¥æ•°æ®çš„ç”µå­è¡¨æ ¼ï¼Œè¿™å°±æ˜¯ä½ éœ€è¦å¤„ç†çš„å†…å®¹ã€‚ä»¥ä¸‹æ˜¯ç”µå­è¡¨æ ¼çš„æˆªå›¾
    [æ ·æœ¬ç”µå­è¡¨æ ¼](https://docs.google.com/spreadsheets/d/1Ks4ll5_8wyYK1zyXMm_21KORhagSMZ59dcr7i3qY6T4):'
- en: '![](../Images/859438ff94b2fbba57b086c8702afb34.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/859438ff94b2fbba57b086c8702afb34.png)'
- en: Do Now!
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Take a look at the table. What do you notice that might affect using the data
    in an analysis? Or for the operations for managing an event?
  id: totrans-23
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: çœ‹çœ‹è¿™ä¸ªè¡¨æ ¼ã€‚ä½ æ³¨æ„åˆ°ä»€ä¹ˆå¯èƒ½ä¼šå½±å“åœ¨åˆ†æä¸­ä½¿ç”¨æ•°æ®ï¼Ÿæˆ–è€…å¯¹äºç®¡ç†æ´»åŠ¨çš„æ“ä½œï¼Ÿ
- en: 'Some issues jump out quickly: the `three` in the `"Num Tickets"` column, differences
    in capitalization in the `"Discount Code"` column, and the use of each of `"none"`
    and blank spaces in the the `"Discount Code"` column (you may have spotted additional
    issues). Before we do any analysis with this dataset, we need to clean it up so
    that our analysis will be reliable. In addition, sometimes our dataset is clean,
    but it needs to be adjusted or prepared to fit the questions we want to ask. This
    chapter looks at both steps, and the programming techniques that are helpful for
    them.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›é—®é¢˜å¾ˆå¿«å°±ä¼šæ˜¾ç°å‡ºæ¥ï¼š`"Num Tickets"` åˆ—ä¸­çš„ `three`ï¼Œ`"Discount Code"` åˆ—ä¸­å¤§å°å†™çš„ä¸€è‡´æ€§å·®å¼‚ï¼Œä»¥åŠ `"Discount
    Code"` åˆ—ä¸­ `"none"` å’Œç©ºç™½ç©ºé—´çš„ä½¿ç”¨ï¼ˆä½ å¯èƒ½å·²ç»å‘ç°äº†å…¶ä»–é—®é¢˜ï¼‰ã€‚åœ¨æˆ‘ä»¬ä½¿ç”¨æ­¤æ•°æ®é›†è¿›è¡Œä»»ä½•åˆ†æä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œæ¸…ç†ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„åˆ†ææ˜¯å¯é çš„ã€‚æ­¤å¤–ï¼Œæœ‰æ—¶æˆ‘ä»¬çš„æ•°æ®é›†æ˜¯å¹²å‡€çš„ï¼Œä½†éœ€è¦è°ƒæ•´æˆ–å‡†å¤‡ä»¥é€‚åº”æˆ‘ä»¬æƒ³è¦æå‡ºçš„é—®é¢˜ã€‚æœ¬ç« å°†æ¢è®¨è¿™ä¸¤ä¸ªæ­¥éª¤ï¼Œä»¥åŠæœ‰åŠ©äºè¿™äº›æ­¥éª¤çš„ç¼–ç¨‹æŠ€æœ¯ã€‚
- en: 4.2.1Â Cleaning Data Tables[ğŸ”—](#(part._cleaning-tables) "Link to here")
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 æ¸…ç†æ•°æ®è¡¨æ ¼[ğŸ”—](#(part._cleaning-tables) "é“¾æ¥è‡³æ­¤")
- en: 4.2.1.1Â Loading Data Tables[ğŸ”—](#(part._loading-tables) "Link to here")
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1 åŠ è½½æ•°æ®è¡¨æ ¼[ğŸ”—](#(part._loading-tables) "é“¾æ¥è‡³æ­¤")
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¤–éƒ¨æ•°æ®æºä¸€èµ·å·¥ä½œçš„ç¬¬ä¸€æ­¥æ˜¯å°†å®ƒåŠ è½½åˆ°ä½ çš„ç¼–ç¨‹å’Œåˆ†æç¯å¢ƒä¸­ã€‚ä½ ä½¿ç”¨å“ªç§æºå–å†³äºä½ ä¸º Pyret ä½¿ç”¨çš„ç¼–ç¨‹ç¯å¢ƒï¼š
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨ CPOï¼Œå¯ä»¥ä» Google Sheets åŠ è½½è¡¨æ ¼ï¼ˆå¦‚æœä½ æƒ³è¦åŠ è½½ CSVï¼Œé¦–å…ˆéœ€è¦å°†å…¶å¯¼å…¥åˆ° Google Sheetsï¼‰
- en: If you are using VSCode, you can load tables directly from CSV files
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨ VSCodeï¼Œå¯ä»¥ç›´æ¥ä» CSV æ–‡ä»¶åŠ è½½è¡¨æ ¼
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„ Pyret æ“ä½œï¼ˆ`load-table`ï¼‰ï¼Œä½†æ–¹å¼ç•¥æœ‰ä¸åŒã€‚
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Google Sheets å’Œ CSV æ–‡ä»¶åœ¨å•å…ƒæ ¼ä¸­çš„æ•°æ®å¤„ç†æ–¹å¼ä¸åŒï¼Œå› æ­¤æˆ‘ä»¬åœ¨åŠ è½½åç®¡ç† Pyret åˆ—çš„ç±»å‹æ—¶ä¹Ÿå­˜åœ¨å·®å¼‚ã€‚åƒ `"Num Tickets"`
    è¿™æ ·çš„åˆ—ä¼¼ä¹åŒæ—¶åŒ…å«æ•°å­—å’Œå­—ç¬¦ä¸²ï¼Œè¿™çªå‡ºäº†è¿™äº›å·®å¼‚ã€‚æˆ‘ä»¬å°†åœ¨æ¯ä¸ªæºæ–‡ä»¶çš„å•ç‹¬éƒ¨åˆ†è®¨è®ºè¿™äº›ç»†å¾®å·®åˆ«ã€‚
- en: 4.2.1.1.1Â Loading Tables from Google Sheets in CPO[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "Link to here")
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.1 ä» Google Sheets åŠ è½½è¡¨æ ¼åˆ° CPO[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "é“¾æ¥è‡³æ­¤")
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ssid` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ Google Sheet çš„æ ‡è¯†ç¬¦ï¼ˆæ ‡è¯†ç¬¦æ˜¯ Google Sheet URL ä¸­çš„é•¿åºåˆ—å­—æ¯å’Œæ•°å­—ï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åè·Ÿçš„åç§°åºåˆ—ç”¨äº Pyret ç‰ˆæœ¬çš„è¡¨æ ¼åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°**ä¸å¿…**ä¸åŸå§‹å·¥ä½œè¡¨ä¸­çš„åç§°åŒ¹é…ã€‚'
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret è¦åŠ è½½å“ªä¸ªå·¥ä½œè¡¨ã€‚`load-spreadsheet` æ“ä½œæ¥å— Google Sheet æ ‡è¯†ç¬¦ï¼ˆæ­¤å¤„ä¸º `ssid`ï¼‰ï¼Œä»¥åŠ
    Google Sheet å†…éƒ¨å‘½åçš„å·¥ä½œè¡¨ï¼ˆæˆ–æ ‡ç­¾ï¼‰åç§°ï¼ˆæ­¤å¤„ä¸º `"Orig Data"`ï¼‰ã€‚æœ€åçš„å¸ƒå°”å€¼è¡¨ç¤ºè¡¨æ ¼ä¸­æ˜¯å¦æœ‰æ ‡é¢˜è¡Œï¼ˆ`true` è¡¨ç¤ºæœ‰æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. Weâ€™ll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» Google Sheets è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret ä¼šæ ¹æ®æ•°æ®çš„ç¬¬ä¸€è¡Œä¸­çš„å€¼å°†æ¯ä¸ªåˆ—è§†ä¸ºå…·æœ‰ç±»å‹ã€‚å› æ­¤ï¼ŒPyret æŠ¥å‘Šäº†ä¸€ä¸ªé”™è¯¯ï¼Œå³ `"Num
    Tickets"` åˆ—ä¸­çš„ `three` ä¸æ˜¯ä¸€ä¸ªæ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨ [å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—](#%28part._cols-multiple-types-data%29)
    ä¸­è®¨è®ºå¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µã€‚
- en: 4.2.1.1.2Â Loading Tables from CSV files in VSCode[ğŸ”—](#(part._loading-tables-from-csv)
    "Link to here")
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.2 åœ¨ VSCode ä¸­ä» CSV æ–‡ä»¶åŠ è½½è¡¨æ ¼[ğŸ”—](#(part._loading-tables-from-csv) "é“¾æ¥è‡³æ­¤")
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ® CSV æ–‡ä»¶æ˜¯åœ¨ä½ çš„ç”µè„‘ä¸Šè¿˜æ˜¯é€šè¿‡ URL å¯ç”¨æ¥é…ç½® `load-table` æ“ä½œã€‚
- en: 'Load from a CSV file via URL:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ URL ä» CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE1]'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ CSV æ•°æ®å­˜åœ¨çš„ç½‘é¡µåœ°å€ï¼ˆURLï¼‰çš„æ ‡è¯†ç¬¦ã€‚'
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret ä»å“ªé‡ŒåŠ è½½æ•°æ®ã€‚`csv-table-url` æ“ä½œæ¥å—ç½‘é¡µåœ°å€ï¼ˆæ­¤å¤„ä¸º `url`ï¼‰ï¼Œä»¥åŠé€‰é¡¹ï¼ˆä¾‹å¦‚ï¼ŒæŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦æœŸæœ›å­˜åœ¨æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åè·Ÿçš„åç§°åºåˆ—ç”¨äº Pyret è¡¨æ ¼ç‰ˆæœ¬ä¸­çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°ä¸éœ€è¦ä¸ CSV æ–‡ä»¶ç¬¬ä¸€è¡Œï¼ˆé€šå¸¸æ˜¯æ ‡é¢˜è¡Œï¼‰ä¸­ä½¿ç”¨çš„åç§°åŒ¹é…ã€‚'
- en: 'Load from a CSV file on your computer:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ‚¨ç”µè„‘ä¸Šçš„ CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» CSV è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret å°†æ¯ä¸ªå•å…ƒæ ¼è§†ä¸ºåŒ…å«å­—ç¬¦ä¸²ï¼Œå³ä½¿å•å…ƒæ ¼æ•°æ®çœ‹èµ·æ¥æ˜¯æ•°å­—ã€‚å› æ­¤ï¼ŒPyret ä¸ä¼šåœ¨ `"Num Tickets"`
    åˆ—ä¸­çš„ `three` å’Œæ•°å­—ç»„åˆå‘¨å›´æŠ¥å‘Šé”™è¯¯ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾å®ƒä»¬éƒ½æ˜¯æ•°å­—çš„å­—ç¬¦ä¸²ï¼Œå¹¶å°è¯•ä½¿ç”¨åˆ—æ•°æ®ï¼Œä¸ä¸€è‡´æ€§å°†å†æ¬¡å‡ºç°ã€‚å¦‚æœæˆ‘ä»¬åœ¨æˆ‘ä»¬åŠ è½½æ•°æ®ä¹‹å‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ç»§ç»­ä¹‹å‰ä¿®å¤å®ƒã€‚
- en: 4.2.1.1.3Â Dealing with Columns with Multiple Types of Data[ğŸ”—](#(part._cols-multiple-types-data)
    "Link to here")
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.3 å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—[ğŸ”—](#(part._cols-multiple-types-data) "é“¾æ¥è‡³æ­¤")
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we arenâ€™t throwing out useful information that
    was simply entered incorrectly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æ„è‰¯å¥½çš„æ•°æ®ä¸åº”åœ¨å•ä¸ªåˆ—ä¸­æ··åˆæ•°æ®ç±»å‹ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿç¼–å†™å°ç¨‹åºæ¥çº æ­£è¿™äº›ä¸ä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç¨‹åºå¯ä»¥å¸®åŠ©æˆ‘ä»¬åˆ é™¤ä¸é¢„æœŸåˆ—ç±»å‹ä¸ä¸€è‡´çš„æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•åº”è¯¥åœ¨ä»”ç»†ç ”ç©¶æ•°æ®ä¹‹åä½¿ç”¨ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šä¸¢å¼ƒç”±äºè¾“å…¥é”™è¯¯è€Œä¸¢å¤±çš„æœ‰ç”¨ä¿¡æ¯ã€‚
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ­¤ç±»é—®é¢˜éœ€è¦è°¨æ…ï¼Œæˆ‘ä»¬å»ºè®®åœ¨å°†æ•°æ®åŠ è½½åˆ° Pyretï¼ˆæˆ–ä»»ä½•å…¶ä»–ç¼–ç¨‹æˆ–åˆ†æå·¥å…·ï¼‰ä¹‹å‰ï¼Œåœ¨æºæ–‡ä»¶ä¸­ä¿®å¤æ­¤ç±»é”™è¯¯ã€‚
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç®¡ç†æ­¤ç±»ä¿®è®¢æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ•°æ®ç®¡ç†é—®é¢˜ã€‚ä½ å¯èƒ½å·²ç»ä»å¦ä¸€ä¸ªå·¥å…·æ¥æ”¶äº†æ•°æ®ï¼Œæˆ–è€…ä»åŒ…å«é”™è¯¯çš„å¦ä¸€ä¸ªå·¥ä½œè¡¨ä¸­å¯¼å…¥å®ƒã€‚å…¶ä»–äººå¯èƒ½ä¹Ÿä¼šæä¾›ä½ éœ€è¦è·Ÿè¸ªçš„æ•°æ®æ›´æ–°ã€‚å¦‚æœä½ ä»å…¶ä»–äººé‚£é‡Œè·å¾—äº†æ•°æ®ï¼Œé€šå¸¸æœ‰é“ç†å¤åˆ¶æºæ•°æ®å¹¶å¯¹å‰¯æœ¬è¿›è¡Œæ¸…ç†ï¼Œè¿™æ ·ä½ ä»ç„¶å¯ä»¥åœ¨éœ€è¦æ—¶è®¿é—®åŸå§‹æ•°æ®ã€‚
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è¯¾çš„æºæ•°æ®æ–‡ä»¶è¿˜åŒ…å«ç”¨äºæœ¬ç« å…¶ä½™éƒ¨åˆ†çš„æ¸…æ´ç‰ˆæœ¬ã€‚
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ Google è¡¨æ ¼ï¼Œè¯·å¯»æ‰¾åä¸º `"Data"` çš„å•ç‹¬å·¥ä½œè¡¨/æ ‡ç­¾é¡µï¼Œå…¶ä¸­ `three` å·²è¢«æ›¿æ¢ä¸ºä¸€ä¸ªæ•°å­—ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ `"Data"`
    è€Œä¸æ˜¯ `"Orig Data"` åœ¨ä¸Šé¢çš„ `load-spreadsheet` å‘½ä»¤ä¸­ï¼Œäº‹ä»¶è¡¨å°†åŠ è½½åˆ° Pyret ä¸­ã€‚
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ VSCode ä¸­çš„ CSV æ–‡ä»¶ï¼Œè¯·å°†æ–‡ä»¶è·¯å¾„ä¿®æ”¹ä¸ºä»¥ `"events-f25.csv"` ç»“å°¾ï¼Œè€Œä¸æ˜¯ `"events-orig-f25.csv"`ã€‚
- en: 4.2.1.2Â Dealing with Missing Entries[ğŸ”—](#(part._missing-data) "Link to here")
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.2 å¤„ç†ç¼ºå¤±æ¡ç›®[ğŸ”—](#(part._missing-data) "é“¾æ¥è‡³æ­¤")
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell â€“ thereâ€™s no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åœ¨ Pyret ä¸­æ‰‹åŠ¨åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»ä¸ºæ¯ä¸ªå•å…ƒæ ¼æä¾›ä¸€ä¸ªå€¼â€”â€”æ²¡æœ‰â€œè·³è¿‡â€å•å…ƒæ ¼çš„æ–¹æ³•ã€‚å½“æˆ‘ä»¬åœ¨ä¸€ä¸ªç”µå­è¡¨æ ¼ç¨‹åºï¼ˆå¦‚ Excelã€Google
    Sheets æˆ–ç±»ä¼¼ç¨‹åºï¼‰ä¸­åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œå¯ä»¥å®Œå…¨ç•™ç©ºå•å…ƒæ ¼ã€‚å½“æˆ‘ä»¬æŠŠåŒ…å«ç©ºå•å…ƒæ ¼çš„è¡¨æ ¼åŠ è½½åˆ° Pyret ä¸­æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether youâ€™re reading from Google Sheets or CSV files).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹æ•°æ®æ–‡ä»¶åœ¨ `discount` åˆ—ä¸­æœ‰ç©ºæ ¼ã€‚åœ¨æˆ‘ä»¬å°†å…¶åŠ è½½åˆ° Pyret åï¼Œæˆ‘ä»¬å‘ç°åœ¨è¯¥åˆ—ä¸­æœ‰äº›æœ‰è¶£çš„ç°è±¡ï¼ˆå°½ç®¡å…·ä½“å†…å®¹ä¼šæ ¹æ®æ‚¨æ˜¯ä» Google
    Sheets è¿˜æ˜¯ CSV æ–‡ä»¶è¯»å–è€Œæœ‰æ‰€ä¸åŒï¼‰ã€‚
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ Google Sheets å’Œ CPOï¼ŒæŒ‰ç…§ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE3]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`event-data` will be the following table:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isnâ€™t a string. Whatâ€™s going on?
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œé‚£äº›åŒ…å«æŠ˜æ‰£ä»£ç çš„å•å…ƒæ ¼ç°åœ¨æœ‰ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆå¥‡æ€ªçš„ç¬¦å·ï¼Œå¦‚ `some("student")`ï¼Œè€Œä¸€äº›åŸæœ¬ä¸ºç©ºçš„å•å…ƒæ ¼åŒ…å« `none`ï¼Œä½† `none`
    ä¸æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Pyret æ”¯æŒä¸€ç§ç‰¹æ®Šçš„æ•°æ®ç±»å‹ï¼Œç§°ä¸º optionã€‚æ­£å¦‚å…¶åæ‰€ç¤ºï¼Œoption ç”¨äºå¯èƒ½å­˜åœ¨æˆ–ä¸å­˜åœ¨çš„æ•°æ®ã€‚`none` æ˜¯è¡¨ç¤ºâ€œæ•°æ®ç¼ºå¤±â€çš„å€¼ã€‚å¦‚æœæ•°æ®å­˜åœ¨ï¼Œå®ƒå°†å‡ºç°åœ¨
    `some` çš„åŒ…è£…ä¸­ã€‚
- en: Look also at the last two rows (for Zander and Shweta) â€“ they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells werenâ€™t actually
    empty in the Google Sheet, but instead contained several spaces.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿˜è¦æ³¨æ„æœ€åä¸¤è¡Œï¼ˆZander å’Œ Shweta çš„è¡Œï¼‰â€”â€”å½“åœ¨ Google Sheets ä¸­æŸ¥çœ‹æ—¶ï¼Œå®ƒä»¬çœ‹èµ·æ¥ä¹Ÿæ˜¯ç©ºçš„ï¼Œä½† Pyret å°†å®ƒä»¬åŠ è½½ä¸ºåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼Œ`some("
    ")`ï¼‰ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™æ„å‘³ç€é‚£äº›å•å…ƒæ ¼åœ¨ Google Sheets ä¸­å®é™…ä¸Šå¹¶ä¸æ˜¯ç©ºçš„ï¼Œè€Œæ˜¯åŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚
- en: Do Now!
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨èµ·æ¥ï¼
- en: ''
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernieâ€™s row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Samâ€™s row)?'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: çœ‹çœ‹ Ernie è¡Œçš„ `discount` å€¼ï¼šå®ƒè¯»ä½œ `some("none")`ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™ä¸ `none`ï¼ˆå¦‚ Sam çš„è¡Œä¸­æ‰€ç¤ºï¼‰æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ CSV æ–‡ä»¶å’Œ VSCodeï¼ŒæŒ‰ç…§ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE4]'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`event-data` will be the following table:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæ²¡æœ‰æ•°æ®çš„å•å…ƒæ ¼è¦ä¹ˆæ˜¯ç©ºå­—ç¬¦ä¸² (`""`)ï¼Œè¦ä¹ˆæ˜¯åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸² (`" "`)ã€‚æ˜¯ä»€ä¹ˆå¯¼è‡´äº†è¿™ç§å·®å¼‚ï¼Ÿåœ¨åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²å•å…ƒæ ¼ä¸­ï¼ŒåŸå§‹ CSV
    ä¸­çš„å•å…ƒæ ¼çœ‹èµ·æ¥æ˜¯ç©ºçš„ï¼Œä½†å®é™…ä¸ŠåŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚åœ¨è¯»å– CSV æ—¶ï¼ŒPyret ä¿ç•™äº†å•å…ƒæ ¼çš„å®é™…å†…å®¹ã€‚åªæœ‰å½“ CSV å•å…ƒæ ¼å®é™…ä¸Šæ²¡æœ‰ä»»ä½•æ•°æ®æ—¶ï¼Œæ‰ä¼šä½¿ç”¨ç©ºå­—ç¬¦ä¸²ã€‚
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Hereâ€™s how
    we modify the code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ‚¨ä½¿ç”¨ Google Sheets è¿˜æ˜¯ CSV æ–‡ä»¶ï¼Œå¤„ç†ç¼ºå¤±æ•°æ®ï¼ˆä»¥åŠä¸€èˆ¬è½¬æ¢ï¼‰çš„æ­£ç¡®æ–¹æ³•æ˜¯æŒ‡ç¤ºå¦‚ä½•å¤„ç†æ¯ä¸€åˆ—ã€‚è¿™ä¿è¯äº†åœ¨è¯»å–æ•°æ®åï¼Œæ•°æ®å°†å¦‚æ‚¨é¢„æœŸçš„é‚£æ ·ã€‚æˆ‘ä»¬é€šè¿‡
    `load-table` çš„é™„åŠ åŠŸèƒ½ï¼Œç§°ä¸º sanitizers æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹ä»£ç çš„æ–¹å¼ï¼š
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸€è¡Œ `sanitize` æŒ‡ä»¤éƒ½å‘Šè¯‰ Pyret åœ¨ç›¸åº”åˆ—ç¼ºå°‘æ•°æ®æ—¶åº”è¯¥åšä»€ä¹ˆã€‚`string-sanitizer` æŒ‡ä»¤è¡¨ç¤ºå°†ç¼ºå¤±æ•°æ®åŠ è½½ä¸ºä¸€ä¸ªç©ºå­—ç¬¦ä¸²
    (`""`)ã€‚Sanitizers è¿˜å¯ä»¥å¤„ç†ç®€å•çš„æ•°æ®è½¬æ¢ã€‚å¦‚æœå°† `string-sanitizer` åº”ç”¨åˆ°ä¸€ä¸ªåŒ…å«æ•°å­—ï¼ˆå¦‚ `3`ï¼‰çš„åˆ—ä¸Šï¼Œæ¸…ç†å™¨ä¼šå°†è¯¥æ•°å­—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚
    `"3"`ï¼‰ã€‚åŒæ ·ï¼Œå°† `num-sanitizer` åº”ç”¨åˆ°ä¸€ä¸ªåˆ—ä¸Šä¼šå°†æ•°å­—å­—ç¬¦ä¸²ï¼ˆå¦‚ `"3"`ï¼‰è½¬æ¢ä¸ºå®é™…çš„æ•°å­—ï¼ˆ`3`ï¼‰ã€‚
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¸…ç†å™¨ï¼Œ`event-data` è¡¨çš„è¯»å–æ–¹å¼å¦‚ä¸‹ï¼š
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
- en: Do Now!
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Arenâ€™t zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  id: totrans-80
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ æ³¨æ„åˆ°æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ `num-sanitizer` è€Œæ˜¯ä½¿ç”¨ `string-sanitizer` æ¸…ç† `zip` åˆ—äº†å—ï¼Ÿé‚®ç¼–ä¸æ˜¯æ•°å­—å—ï¼Ÿå°è¯•ä½¿ç”¨
    `string-sanitizer` å’Œ `num-sanitizer` åˆ†åˆ«å¯¹ `code` è¿›è¡Œä¸Šè¿°ä»£ç çš„æµ‹è¯•ï¼Œçœ‹çœ‹ä½ æ˜¯å¦èƒ½å‘ç°å·®å¼‚ã€‚
- en: Zip codes are a terrific example of data that are written with digits, but arenâ€™t
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we donâ€™t write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    Weâ€™ll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: é‚®ç¼–æ˜¯æ•°æ®ä»¥æ•°å­—å½¢å¼ç¼–å†™ä½†å¹¶ä¸æ‰“ç®—ç”¨äºæ•°å€¼è®¡ç®—çš„ç»ä½³ä¾‹å­ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿå¦‚æœæ•°æ®æ‰“ç®—ç”¨äºæ•°å€¼è®¡ç®—ï¼Œé‚£ä¹ˆæ ‡å‡†ç®—æœ¯è¿ç®—åº”è¯¥åœ¨è¿™äº›æ•°æ®ä¸Šæ˜¯æœ‰æ„ä¹‰çš„ã€‚ä¾‹å¦‚ï¼Œå°†é‚®ç¼–ä¹˜ä»¥
    3 æœ‰ä»€ä¹ˆæ„ä¹‰å‘¢ï¼Ÿæ²¡æœ‰ã€‚åŒæ ·ï¼Œæˆ‘ä»¬ä¸ä¼šç”¨å‰å¯¼é›¶å†™æ•°å­—ï¼Œä½†é‚®ç¼–å¯ä»¥æœ‰æ„ä¹‰åœ°ä»¥ 0 å¼€å¤´ã€‚å°†é‚®ç¼–è§†ä¸ºå­—ç¬¦ä¸²å°†å®ƒä»¬è§†ä¸ºæ ‡è¯†ç¬¦è€Œä¸æ˜¯æ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„åé¢éƒ¨åˆ†å›åˆ°è¿™ä¸ªè¯é¢˜ï¼ˆ[å¯è§†åŒ–å’Œå›¾è¡¨](#%28part._visualizing-tables%29)ï¼‰ã€‚
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºé»˜è®¤å€¼çš„è¯´æ˜ï¼šä¸ `string-sanitizer` ä¸åŒï¼Œ`num-sanitizer` ä¸ä¼šå°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºé»˜è®¤å€¼ï¼ˆå¦‚ 0ï¼‰ã€‚å¯¹äºæ•°å­—çš„æ‰€æœ‰ä½¿ç”¨æ–¹å¼ï¼Œæ²¡æœ‰å•ä¸€çš„é»˜è®¤å€¼æ˜¯æœ‰æ„ä¹‰çš„ï¼šè™½ç„¶
    `0` å¯èƒ½æ˜¯ç¼ºå¤±ç¥¨æ•°çš„åˆç†é»˜è®¤å€¼ï¼Œä½†å®ƒå¯¹ç¼ºå¤±çš„å¹´é¾„æ¥è¯´å¹¶æ²¡æœ‰æ„ä¹‰ã€‚å¦‚æœå°†å…¶ç”¨ä½œç¼ºå¤±è€ƒè¯•æˆç»©çš„é»˜è®¤å€¼ï¼ˆåæ¥ç”¨äºè®¡ç®—è¯¾ç¨‹æˆç»©ï¼‰ï¼Œå¯èƒ½ä¼šäº§ç”Ÿæ˜æ˜¾çš„é”™è¯¯ã€‚å› æ­¤ï¼Œå¦‚æœå•å…ƒæ ¼ä¸­çš„æ•°æ®ï¼ˆæˆ–å…¶ç¼ºå¤±ï¼‰æ— æ³•å¯é åœ°è§£é‡Šä¸ºæ•°å­—ï¼Œ`num-sanitizer`
    ä¼šæŠ¥å‘Šé”™è¯¯ã€‚Pyret å…è®¸ä½ ç¼–å†™è‡ªå·±çš„è‡ªå®šä¹‰æ¸…ç†å™¨ï¼ˆä¾‹å¦‚ï¼Œå°†ç¼ºå¤±æ•°å­—é»˜è®¤ä¸º 0 çš„æ¸…ç†å™¨ï¼‰ã€‚å¦‚æœä½ æƒ³è¿™æ ·åšï¼Œè¯·å‚é˜… Pyret æ–‡æ¡£ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚
- en: The lack of meaningful default values is one reason why Pyret doesnâ€™t leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå°‘æœ‰æ„ä¹‰çš„é»˜è®¤å€¼æ˜¯ Pyret ä¸åˆ©ç”¨åˆ—ä¸Šçš„ç±»å‹æ³¨è§£è‡ªåŠ¨æ¸…ç†å¯¼å…¥æ•°æ®çš„ä¸€ä¸ªåŸå› ã€‚è‡ªåŠ¨åŒ–ä¼šä»ç¨‹åºå‘˜æ‰‹ä¸­å¤ºèµ°æ§åˆ¶æƒï¼›æ¸…ç†å™¨ä¸ºç¨‹åºå‘˜æä¾›äº†å¯¹é»˜è®¤å€¼çš„æ§åˆ¶ï¼Œä»¥åŠé€‰æ‹©æ˜¯å¦ä½¿ç”¨ï¼ˆæˆ–ä¸ä½¿ç”¨ï¼‰æ¸…ç†å™¨çš„é€‰é¡¹ã€‚
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸è§„åšæ³•ï¼šå½“ä½ åŠ è½½ä¸€ä¸ªè¡¨æ—¶ï¼Œä½¿ç”¨æ¸…ç†å™¨æ¥é˜²æ­¢åŸå§‹è¡¨æ ¼ä¸­æŸäº›å•å…ƒæ ¼ç¼ºå°‘æ•°æ®æ—¶å‡ºç°é”™è¯¯ã€‚
- en: 4.2.1.3Â Normalizing Data[ğŸ”—](#(part._.Normalizing_.Data) "Link to here")
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.3 æ•°æ®æ ‡å‡†åŒ–[ğŸ”—](#(part._.Normalizing_.Data) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Next, letâ€™s look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ `"æŠ˜æ‰£ä»£ç "` è¿™ä¸€åˆ—ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èƒ½å¤Ÿå‡†ç¡®å›ç­”â€œæ¯ä¸ªæŠ˜æ‰£ä»£ç ä¸‹æœ‰å¤šå°‘è®¢å•â€ã€‚æˆ‘ä»¬å¸Œæœ›ç­”æ¡ˆä»¥è¡¨æ ¼å½¢å¼æ€»ç»“ï¼Œå…¶ä¸­ä¸€åˆ—å‘½åæŠ˜æ‰£ä»£ç ï¼Œå¦ä¸€åˆ—ç»™å‡ºä½¿ç”¨è¯¥ä»£ç çš„è¡Œæ•°ã€‚
- en: Do Now!
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  id: totrans-89
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸¾ä¾‹è¯´æ˜ï¼æˆ‘ä»¬å¸Œæœ›ä»è¿™ä¸ªè®¡ç®—ä¸­å¾—åˆ°çš„è¡¨æ ¼ç‰‡æ®µæ˜¯ä»€ä¹ˆï¼Ÿ
- en: 'You canâ€™t answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸å†³å®šå¦‚ä½•æ ‡å‡†åŒ–åç§°å’Œå¤„ç†ç¼ºå¤±å€¼ï¼Œå°±æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è§„èŒƒåŒ–ä¸€è¯æŒ‡çš„æ˜¯ç¡®ä¿æ•°æ®é›†åˆï¼ˆå¦‚åˆ—ï¼‰å…·æœ‰ç»“æ„å’Œæ ¼å¼ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå°†æ—¨åœ¨ç”Ÿæˆä»¥ä¸‹è¡¨æ ¼ï¼Œä½†æ‚¨å¯èƒ½åšå‡ºäº†ä¸æˆ‘ä»¬è¿™é‡Œä¸åŒçš„é€‰æ‹©ï¼š
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/67e61db173feac2c615c0772e8bad093.png)'
- en: How do we get to this table? How do we figure this out if we arenâ€™t sure?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å¾—åˆ°è¿™ä¸ªè¡¨æ ¼ï¼Ÿå¦‚æœæˆ‘ä»¬ä¸ç¡®å®šï¼Œæˆ‘ä»¬å¦‚ä½•æ‰¾å‡ºç­”æ¡ˆï¼Ÿ
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyretâ€™s `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼ŒæŸ¥é˜…æ–‡æ¡£ä¸­å¯èƒ½æœ‰åŠ©äºæ­¤ä»»åŠ¡çš„ä»»ä½•åº“å‡½æ•°ã€‚åœ¨ [Pyret çš„ `dcic2024` ä¸Šä¸‹æ–‡æ–‡æ¡£](https://hackmd.io/@cs111/table)
    ä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¬èµ·æ¥å¾ˆæœ‰ç”¨ï¼Œåªè¦ `"æŠ˜æ‰£ä»£ç "` åˆ—ä¸­çš„æ¯ä¸ªåˆ—éƒ½æœ‰å€¼ï¼Œå¹¶ä¸”è¯¥åˆ—ä¸­åªæœ‰æˆ‘ä»¬æœŸæœ›è¾“å‡ºè¡¨ä¸­çš„é‚£äº›å€¼ã€‚æˆ‘ä»¬éœ€è¦åšä»€ä¹ˆæ‰èƒ½å®ç°è¿™ä¸€ç‚¹ï¼Ÿ
- en: Get `"none"` to appear in every cell that currently lacks a value
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®© `"none"` å‡ºç°åœ¨å½“å‰ç¼ºå°‘å€¼çš„æ¯ä¸ªå•å…ƒæ ¼ä¸­
- en: Convert all the codes that arenâ€™t `"none"` to upper case
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ä¸æ˜¯ `"none"` çš„ä»£ç è½¬æ¢ä¸ºå¤§å†™
- en: 'Fortunately, these tasks align with functions weâ€™ve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œè¿™äº›ä»»åŠ¡ä¸æˆ‘ä»¬å·²ç»å­¦ä¼šä½¿ç”¨çš„å‡½æ•°ç›¸ä¸€è‡´ï¼šæ¯ä¸ªéƒ½æ˜¯ä¸€ä¸ªåˆ—è½¬æ¢çš„ä¾‹å­ï¼Œå…¶ä¸­ç¬¬äºŒä¸ªæ¶‰åŠåˆ° `String` åº“ä¸­çš„å¤§å†™è½¬æ¢å‡½æ•°ã€‚
- en: 'We can capture these together in a function that takes in and produces a string:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªå‡½æ•°ä¸­æ•è·è¿™äº›ï¼Œè¯¥å‡½æ•°æ¥æ”¶å¹¶ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼š
- en: '[PRE7]uppercase all strings other than none,'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]å°†é™¤äº† `"none"` ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE8]
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å« `"none"`[PRE8]
- en: Do Now!
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  id: totrans-104
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯„ä¼° `cell-to-discount-code` ä¸­åŒ…å«çš„ç¤ºä¾‹ã€‚è¿™æ˜¯ä¸€ç»„å¥½çš„ç¤ºä¾‹ï¼Œè¿˜æ˜¯é—æ¼äº†ä»»ä½•å…³é”®ç¤ºä¾‹ï¼Ÿ
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process canâ€™t
    produce different capitalizations of `"none"`, we should include that as well:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰çš„ç¤ºä¾‹è€ƒè™‘äº† `"birthday"` çš„ä¸åŒå¤§å°å†™ï¼Œä½†æ²¡æœ‰è€ƒè™‘ `"none"`ã€‚é™¤éæ‚¨ç¡®ä¿¡æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸ä¼šäº§ç”Ÿ `"none"` çš„ä¸åŒå¤§å°å†™ï¼Œå¦åˆ™æˆ‘ä»¬åº”è¯¥åŒ…æ‹¬è¿™ä¸€ç‚¹ï¼š
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å“å‘€ï¼å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªç¤ºä¾‹æ·»åŠ åˆ°æˆ‘ä»¬çš„ `where` å—ä¸­å¹¶è¿è¡Œä»£ç ï¼ŒPyret ä¼šæŠ¥å‘Šè¿™ä¸ªç¤ºä¾‹å¤±è´¥äº†ã€‚
- en: Do Now!
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  id: totrans-110
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆ `"NoNe"` è¿™ç§æƒ…å†µå¤±è´¥äº†ï¼Ÿ
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Hereâ€™s the modified code,
    on which all the examples pass.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬åœ¨ `if` è¡¨è¾¾å¼ä¸­æ£€æŸ¥ `"none"` å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬éœ€è¦å°†è¾“å…¥è§„èŒƒåŒ–ä»¥åŒ¹é…æˆ‘ä»¬çš„ `if` è¡¨è¾¾å¼æœŸæœ›çš„å†…å®¹ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹åçš„ä»£ç ï¼Œæ‰€æœ‰ç¤ºä¾‹éƒ½é€šè¿‡äº†ã€‚
- en: '[PRE10]uppercase all strings other than none,'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10]å°†é™¤äº† `"none"` ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE11]
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å« `"none"`[PRE11]
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ­¤åŠŸèƒ½ä¸ `transform-column` ç»“åˆï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªå…·æœ‰æ ‡å‡†åŒ–æ ¼å¼çš„æŠ˜æ‰£ä»£ç è¡¨æ ¼ï¼ˆæé†’ï¼šæ‚¨éœ€è¦åœ¨å·¥ä½œåœ¨ `dcic2024` ä¸Šä¸‹æ–‡ä¸­æ‰èƒ½ä½¿æ­¤åŠŸèƒ½ç”Ÿæ•ˆï¼‰ï¼š
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Exercise
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  id: totrans-118
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°è¯•è‡ªå·±ï¼šå°† `"é…é€"` åˆ—è§„èŒƒåŒ–ï¼Œä½¿æ‰€æœ‰ `"yes"` å€¼éƒ½è½¬æ¢ä¸º `"email"`ã€‚
- en: 'Now that weâ€™ve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†äº†ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨`"count"`å‡½æ•°æ¥æå–æˆ‘ä»¬çš„æ±‡æ€»è¡¨æ ¼ï¼š
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This produces the following table:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿä»¥ä¸‹è¡¨æ ¼ï¼š
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
- en: Do Now!
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Whatâ€™s with that first row, with the discount code `" "`? Where might that have
    come from?
  id: totrans-125
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é‚£ç¬¬ä¸€è¡Œï¼Œå¸¦æœ‰æŠ˜æ‰£ä»£ç `" "`çš„è¡Œæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿå®ƒå¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿ
- en: Maybe you didnâ€™t notice this before (or wouldnâ€™t have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸ä½ ä¹‹å‰æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸€ç‚¹ï¼ˆæˆ–è€…åœ¨æ›´å¤§çš„è¡¨æ ¼ä¸­ä¸ä¼šæ³¨æ„åˆ°ï¼‰ï¼Œä½†æºæ•°æ®ä¸­è‚¯å®šæœ‰ä¸€ä¸ªå•å…ƒæ ¼åŒ…å«ä¸€ä¸²ç©ºæ ¼ï¼Œè€Œä¸æ˜¯ç¼ºå¤±çš„å†…å®¹ã€‚æˆ‘ä»¬å¦‚ä½•å¤„ç†è§„èŒƒåŒ–ä»¥é¿å…ç±»ä¼¼è¿™ç§æƒ…å†µçš„ç¼ºå¤±æ¡ˆä¾‹ï¼Ÿ
- en: 4.2.1.4Â Normalization, Systematically[ğŸ”—](#(part._.Normalization__.Systematically)
    "Link to here")
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.4Â è§„èŒƒåŒ–ï¼Œç³»ç»ŸåŒ–[ğŸ”—](#(part._.Normalization__.Systematically) "é“¾æ¥åˆ°æ­¤å¤„")
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰ä¾‹æ‰€ç¤ºï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§ç³»ç»Ÿæ€§åœ°æ€è€ƒæ½œåœ¨è§„èŒƒåŒ–çš„æ–¹æ³•ã€‚æˆ‘ä»¬å…³äºç¼–å†™ç¤ºä¾‹çš„åˆå§‹è®¨è®ºç»™å‡ºäº†ä¸€ç§å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„æ–¹æ³•ã€‚é‚£é‡Œçš„ä¸€æ¡æŒ‡å¯¼åŸåˆ™æ˜¯è€ƒè™‘è¾“å…¥åŸŸï¼Œä»¥åŠè¾“å…¥å¯èƒ½çš„å˜åŒ–æ–¹å¼ã€‚å¦‚æœæˆ‘ä»¬å°†è¿™ä¸€ç‚¹åº”ç”¨äºåŠ è½½çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘åŸå§‹æ•°æ®æ˜¯å¦‚ä½•æ”¶é›†çš„ã€‚
- en: Do Now!
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  id: totrans-131
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ å¯¹ç½‘ç«™çš„äº†è§£ï¼Œäº‹ä»¶ä»£ç å†…å®¹å¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿå®ƒä»¬æ˜¯å¦‚ä½•è¢«è¾“å…¥çš„ï¼Ÿè¿™äº›ä¿¡æ¯èƒ½å‘Šè¯‰ä½ å…³äºæ•°æ®ä¸­ä¸åŒå¯èƒ½çš„é”™è¯¯ä»€ä¹ˆï¼Ÿ
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯¹äºæ¥è‡ªåŸºäºç½‘é¡µçš„è¡¨å•ï¼ˆå¦‚æˆ‘ä»¬æœ€åˆæ‰€æ­ç¤ºçš„ï¼‰çš„æ•°æ®ï¼Œæ•°æ®å¾ˆå¯èƒ½æ˜¯ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€è¢«è¾“å…¥çš„ï¼š
- en: via a drop-down menu
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸‹æ‹‰èœå•
- en: in a text-entry box
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ–‡æœ¬è¾“å…¥æ¡†ä¸­
- en: A drop-down menu automatically normalizes the data, so thatâ€™s not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So letâ€™s assume this is from a text-entry
    box.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹æ‹‰èœå•ä¼šè‡ªåŠ¨è§„èŒƒåŒ–æ•°æ®ï¼Œå› æ­¤è¿™ä¸æ˜¯ä¸€ä¸ªå¯èƒ½çš„æ•°æ®æ¥æºï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“ä½ åœ¨è¡¨å•ä¸Šæƒ³è¦ç”¨æˆ·ä»å›ºå®šé€‰é¡¹é›†åˆä¸­é€‰æ‹©æ—¶ï¼Œä½ åº”è¯¥ä½¿ç”¨ä¸‹æ‹‰èœå•ï¼‰ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å‡è®¾è¿™æ˜¯æ¥è‡ªæ–‡æœ¬è¾“å…¥æ¡†çš„ã€‚
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬è¾“å…¥æ¡†æ„å‘³ç€ä»»ä½•å…¸å‹çš„äººç±»æ‰“å­—é”™è¯¯éƒ½å¯èƒ½ä¼šå‡ºç°åœ¨ä½ çš„æ•°æ®ä¸­ï¼šäº¤æ¢çš„å­—æ¯ï¼Œç¼ºå¤±çš„å­—æ¯ï¼Œå‰å¯¼ç©ºæ ¼ï¼Œå¤§å°å†™ç­‰ã€‚ä½ ä¹Ÿå¯èƒ½å¾—åˆ°ä¸€äº›æ•°æ®ï¼Œå…¶ä¸­æœ‰äººåªæ˜¯è¾“å…¥äº†é”™è¯¯çš„å†…å®¹ï¼ˆæˆ–è€…éšæœºè¾“å…¥ï¼Œçœ‹çœ‹ä½ çš„è¡¨å•ä¼šåšä»€ä¹ˆï¼‰ã€‚
- en: Do Now!
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  id: totrans-139
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è®¤ä¸ºç¨‹åºå¯ä»¥è‡ªåŠ¨çº æ­£äº¤æ¢çš„å­—æ¯ã€ç¼ºå¤±é”™è¯¯å’Œéšæœºæ–‡æœ¬ä¸­çš„å“ªäº›ï¼Ÿ
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, youâ€™d have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. â€“ these are questions of policy, not of programming).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤æ¢å’Œç¼ºå¤±çš„å­—æ¯æ˜¯æ‹¼å†™æ£€æŸ¥ç¨‹åºå¯èƒ½èƒ½å¤Ÿä¿®å¤çš„ç±»å‹ï¼ˆç‰¹åˆ«æ˜¯å¦‚æœç¨‹åºçŸ¥é“æ‰€æœ‰æœ‰æ•ˆçš„æŠ˜æ‰£ä»£ç ï¼‰ã€‚æ ¹æ®å®šä¹‰ï¼Œéšæœºåƒåœ¾æ˜¯éšæœºçš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å°†ä¸å¾—ä¸ä¸æ´»åŠ¨å…¬å¸äº¤è°ˆï¼Œä»¥å†³å®šä»–ä»¬å¸Œæœ›å¦‚ä½•å¤„ç†è¿™äº›æƒ…å†µï¼ˆå°†å®ƒä»¬è½¬æ¢ä¸º`"none"`ï¼Œè”ç³»å®¢æˆ·ç­‰â€”â€”è¿™äº›é—®é¢˜æ˜¯æ”¿ç­–é—®é¢˜ï¼Œè€Œä¸æ˜¯ç¼–ç¨‹é—®é¢˜ï¼‰ã€‚
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®é™…ä¸Šï¼Œè¿™ä¸ªæ•™è®­å°±æ˜¯å°½å¯èƒ½ä½¿ç”¨ä¸‹æ‹‰èœå•æˆ–å…¶ä»–æ–¹æ³•åœ¨æºå¤´é˜²æ­¢é”™è¯¯æ•°æ®çš„å‘ç”Ÿã€‚
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once youâ€™ve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ä½ å¯¹ç¼–ç¨‹ç»éªŒçš„ç§¯ç´¯ï¼Œä½ ä¹Ÿä¼šå­¦ä¼šé¢„åˆ¤æŸäº›ç±»å‹çš„é”™è¯¯ã€‚ä¾‹å¦‚ï¼Œä¸€æ—¦ä½ å¤„ç†è¿‡è¶³å¤Ÿå¤šçš„åŒ…å«ç©ºå•å…ƒæ ¼çš„è¡¨æ ¼ï¼Œè¿™äº›é—®é¢˜å°±ä¼šå˜å¾—ä¹ ä»¥ä¸ºå¸¸ã€‚éœ€è¦é¢„åˆ¤æ•°æ®é”™è¯¯æ˜¯ä¼˜ç§€æ•°æ®ç§‘å­¦å®¶å¿…é¡»äº†è§£ä»–ä»¬æ‰€åœ¨é¢†åŸŸçš„åŸå› ä¹‹ä¸€ã€‚
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now weâ€™re getting ahead of ourselves.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥å­¦åˆ°çš„æ˜¯æˆ‘ä»¬å¦‚ä½•è®¨è®ºé¢„æœŸçš„æƒ…å†µã€‚æˆ‘ä»¬è€ƒè™‘äº†æ•°æ®æ¥æºï¼Œä»¥åŠåœ¨è¯¥æƒ…å†µä¸‹å¯èƒ½å‡ºç°çš„é”™è¯¯ã€‚åœ¨è„‘æµ·ä¸­æœ‰ä¸€ä¸ªæ¸…æ™°çš„é”™è¯¯æ¨¡å‹å°†æœ‰åŠ©äºä½ å¼€å‘æ›´å¥å£®çš„ç¨‹åºã€‚äº‹å®ä¸Šï¼Œè¿™ç§å¯¹æŠ—æ€§æ€ç»´æ˜¯å®‰å…¨é¢†åŸŸå·¥ä½œçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä½†ç°åœ¨æˆ‘ä»¬è·‘é¢˜äº†ã€‚
- en: Exercise
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  id: totrans-146
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ç”µå­è¡¨æ ¼ä¸­ï¼Œæœ‰æ—¶çœ‹ä¼¼ç©ºç™½çš„å•å…ƒæ ¼å®é™…ä¸ŠåŒ…å«ç”±ç©ºæ ¼ç»„æˆçš„å­—ç¬¦ä¸²ï¼šå½“æˆ‘ä»¬æŸ¥çœ‹ç”µå­è¡¨æ ¼æ—¶ï¼Œ`""`å’Œ`" "`çœ‹èµ·æ¥ç›¸åŒï¼Œä½†å®ƒä»¬åœ¨è®¡ç®—ä¸Šå®é™…ä¸Šæ˜¯ä¸åŒçš„å€¼ã€‚
- en: ''
  id: totrans-147
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  id: totrans-148
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ ä¼šå¦‚ä½•ä¿®æ”¹`cell-to-discount-code`å‡½æ•°ï¼Œä»¥ä¾¿åªåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ä¹Ÿè¢«è½¬æ¢ä¸º`"none"`ï¼Ÿï¼ˆæç¤ºï¼šåœ¨å­—ç¬¦ä¸²åº“ä¸­æŸ¥æ‰¾`string-replace`ã€‚ï¼‰
- en: 4.2.1.5Â Using Programs to Detect Data Errors[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.5 ä½¿ç”¨ç¨‹åºæ¥æ£€æµ‹æ•°æ®é”™è¯¯[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors) "é“¾æ¥è‡³æ­¤")
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Letâ€™s consider the `"email"` column: thatâ€™s
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Letâ€™s consider two rules:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé€šè¿‡ç¼–å†™å‡½æ•°æ¥æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åŒ…å«æ„å¤–çš„å€¼æ¥æŸ¥æ‰¾é”™è¯¯ã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹`"email"`åˆ—ï¼šè¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥ç¼–å†™ç¨‹åºæ¥æ ‡è®°ä»»ä½•åŒ…å«æ— æ•ˆç”µå­é‚®ä»¶åœ°å€çš„è¡Œçš„ä½ç½®ã€‚ä»€ä¹ˆæ„æˆäº†ä¸€ä¸ªæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ï¼Ÿè®©æˆ‘ä»¬è€ƒè™‘ä¸¤ä¸ªè§„åˆ™ï¼š
- en: Valid email addresses should contain an `@` sign
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”åŒ…å«ä¸€ä¸ª`@`ç¬¦å·
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”ä»¥`".com"`ã€`".edu"`æˆ–`".org"`ä¹‹ä¸€ç»“å°¾
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¡®å®æ˜¯ä¸€ä¸ªè¿‡æ—¶ã€æœ‰é™ä¸”ä»¥ç¾å›½ä¸ºä¸­å¿ƒçš„ç”µå­é‚®ä»¶åœ°å€å®šä¹‰ï¼Œä½†æ‰©å±•æ ¼å¼å¹¶ä¸ä»æ ¹æœ¬ä¸Šæ”¹å˜æœ¬èŠ‚çš„ç›®çš„ã€‚
- en: Exercise
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  id: totrans-156
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªåä¸º`is-email`çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºè¯¥å­—ç¬¦ä¸²æ˜¯å¦æ»¡è¶³ä¸Šè¿°ä¸¤ä¸ªè§„åˆ™ä»¥æˆä¸ºæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ã€‚ä¸ºäº†å¢åŠ ä¸€äº›æŒ‘æˆ˜æ€§ï¼Œè¿˜å¯ä»¥åŒ…æ‹¬ä¸€ä¸ªè§„åˆ™ï¼Œå³åœ¨`@`å’ŒåŸºäºç‚¹çš„ç»“å°¾ä¹‹é—´å¿…é¡»æœ‰ä¸€äº›å­—ç¬¦ã€‚
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program canâ€™t be written to perform the fixing.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰äº†è¿™æ ·çš„å‡½æ•°ï¼Œ`filter-with`ä¾‹ç¨‹å°±å¯ä»¥ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼ï¼Œæ ‡è¯†æ‰€æœ‰éœ€è¦æ›´æ­£ç”µå­é‚®ä»¶åœ°å€çš„è¡Œã€‚è¿™é‡Œçš„è¦ç‚¹æ˜¯ï¼Œç¨‹åºé€šå¸¸æœ‰åŠ©äºæ‰¾åˆ°éœ€è¦æ›´æ­£çš„æ•°æ®ï¼Œå³ä½¿æ— æ³•ç¼–å†™ç¨‹åºæ¥æ‰§è¡Œä¿®å¤ã€‚
- en: 4.2.2Â Task Plans[ğŸ”—](#(part._task-plans) "Link to here")
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 ä»»åŠ¡è®¡åˆ’[ğŸ”—](#(part._task-plans) "é“¾æ¥è‡³æ­¤")
- en: Before we move on, itâ€™s worth stepping back to reflect on our process for producing
    the discount-summary table. We started from a concrete example, checked the documentation
    for a built-in function that might help, then manipulated our data to work with
    that function. These are part of a more general process that applies to data and
    problems beyond tables. Weâ€™ll refer to this process as task planning. Specifically,
    a task plan is a sequence of steps (tasks) that decompose a computational problem
    into smaller steps (sub-tasks). A useful task plan contains sub-tasks that you
    know how to implement, either by using a built-in function or writing your own.
    There is no single notation or format for task plans. For some problems, a bulleted-list
    of steps will suffice. For others, a diagram showing how data transform through
    a problem is more helpful. This is a personal choice tailored to a specific problem.
    The goal is simply to decompose a problem into something of a programming to-do
    list, to help you manage the process.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œå€¼å¾—å›é¡¾ä¸€ä¸‹æˆ‘ä»¬ç”ŸæˆæŠ˜æ‰£æ‘˜è¦è¡¨çš„è¿‡ç¨‹ã€‚æˆ‘ä»¬ä»å…·ä½“ä¾‹å­å¼€å§‹ï¼Œæ£€æŸ¥æ–‡æ¡£ä¸­å¯èƒ½æœ‰åŠ©äºçš„å†…ç½®å‡½æ•°ï¼Œç„¶åæ“çºµæˆ‘ä»¬çš„æ•°æ®ä»¥ä½¿ç”¨è¯¥å‡½æ•°ã€‚è¿™äº›éƒ½æ˜¯é€‚ç”¨äºè¡¨æ ¼ä¹‹å¤–çš„æ•°æ®å’Œé—®é¢˜çš„æ›´ä¸€èˆ¬è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬å°†æŠŠè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºä»»åŠ¡è§„åˆ’ã€‚å…·ä½“æ¥è¯´ï¼Œä»»åŠ¡è®¡åˆ’æ˜¯ä¸€ç³»åˆ—æ­¥éª¤ï¼ˆä»»åŠ¡ï¼‰ï¼Œå°†è®¡ç®—é—®é¢˜åˆ†è§£æˆæ›´å°çš„æ­¥éª¤ï¼ˆå­ä»»åŠ¡ï¼‰ã€‚ä¸€ä¸ªæœ‰ç”¨çš„ä»»åŠ¡è®¡åˆ’åŒ…å«ä½ çŸ¥é“å¦‚ä½•å®ç°çš„å­ä»»åŠ¡ï¼Œæ— è®ºæ˜¯é€šè¿‡ä½¿ç”¨å†…ç½®å‡½æ•°è¿˜æ˜¯ç¼–å†™è‡ªå·±çš„å‡½æ•°ã€‚ä»»åŠ¡è®¡åˆ’æ²¡æœ‰å•ä¸€çš„ç¬¦å·æˆ–æ ¼å¼ã€‚å¯¹äºæŸäº›é—®é¢˜ï¼Œæ­¥éª¤çš„åˆ—è¡¨è¶³ä»¥æ»¡è¶³ã€‚å¯¹äºå…¶ä»–é—®é¢˜ï¼Œä¸€ä¸ªæ˜¾ç¤ºæ•°æ®å¦‚ä½•é€šè¿‡é—®é¢˜è¿›è¡Œè½¬æ¢çš„å›¾è¡¨å¯èƒ½æ›´æœ‰å¸®åŠ©ã€‚è¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„ä¸ªäººé€‰æ‹©ã€‚ç›®æ ‡æ˜¯ç®€å•åœ°å°†é—®é¢˜åˆ†è§£æˆæŸç§ç¼–ç¨‹å¾…åŠäº‹é¡¹åˆ—è¡¨ï¼Œä»¥å¸®åŠ©ä½ ç®¡ç†è¿™ä¸ªè¿‡ç¨‹ã€‚
- en: 'Strategy: Creating a Task Plan'
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç­–ç•¥ï¼šåˆ›å»ºä»»åŠ¡è®¡åˆ’
- en: ''
  id: totrans-161
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Develop a concrete example showing the desired output on a given input (you
    pick the input: a good one is large enough to show different features of your
    inputs, but small enough to work with manually during planning. For table problems,
    roughly 4-6 rows usually works well in practice).'
  id: totrans-162
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œå±•ç¤ºåœ¨ç»™å®šè¾“å…¥ï¼ˆä½ é€‰æ‹©è¾“å…¥ï¼šä¸€ä¸ªå¥½çš„ä¾‹å­æ˜¯è¶³å¤Ÿå¤§ä»¥å±•ç¤ºè¾“å…¥çš„ä¸åŒç‰¹å¾ï¼Œä½†è¶³å¤Ÿå°ä»¥ä¾¿åœ¨è§„åˆ’æœŸé—´æ‰‹åŠ¨å¤„ç†ã€‚å¯¹äºè¡¨æ ¼é—®é¢˜ï¼Œå®è·µä¸­é€šå¸¸4-6è¡Œæ•ˆæœå¾ˆå¥½ï¼‰ä¸Šçš„æœŸæœ›è¾“å‡ºã€‚
- en: ''
  id: totrans-163
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-164
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mentally identify functions that you already know (or that you find in the documentation)
    that might be useful for transforming the input data to the output data.
  id: totrans-165
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¿ƒç†ä¸Šè¯†åˆ«ä½ å·²ç»çŸ¥é“ï¼ˆæˆ–ä½ åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°çš„ï¼‰å¯èƒ½å¯¹å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºè¾“å‡ºæ•°æ®æœ‰ç”¨çš„å‡½æ•°ã€‚
- en: ''
  id: totrans-166
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-167
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Develop a sequence of stepsâ€”<wbr>whether as pictures, textual descriptions of
    computations, or a combination of the twoâ€”<wbr>that could be used to solve the
    problem. If you are using pictures, draw out the intermediate data values from
    your concrete example and make notes on what operations might be useful to get
    from one intermediate value to the next. The functions you identified in the previous
    step should show up here.
  id: totrans-168
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘ä¸€ç³»åˆ—æ­¥éª¤â€”â€”æ— è®ºæ˜¯ä½œä¸ºå›¾ç‰‡ã€è®¡ç®—æ–‡æœ¬æè¿°ï¼Œè¿˜æ˜¯ä¸¤è€…çš„ç»„åˆâ€”â€”è¿™äº›æ­¥éª¤å¯ä»¥ç”¨æ¥è§£å†³é—®é¢˜ã€‚å¦‚æœä½ ä½¿ç”¨å›¾ç‰‡ï¼Œä»å…·ä½“ä¾‹å­ä¸­ç»˜åˆ¶å‡ºä¸­é—´æ•°æ®å€¼ï¼Œå¹¶æ³¨æ˜å¯èƒ½æœ‰åŠ©äºä»ä¸€ä¸ªä¸­é—´å€¼åˆ°ä¸‹ä¸€ä¸ªä¸­é—´å€¼è¿›è¡Œæ“ä½œçš„è¿ç®—ã€‚ä½ åœ¨ä¸Šä¸€æ­¥ä¸­ç¡®å®šçš„å‡½æ•°åº”è¯¥å‡ºç°åœ¨è¿™é‡Œã€‚
- en: ''
  id: totrans-169
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-170
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat the previous step, breaking down the subtasks until you believe you could
    write expressions or functions to perform each step or data transformation.
  id: totrans-171
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤ä¸Šä¸€æ­¥ï¼Œåˆ†è§£å­ä»»åŠ¡ï¼Œç›´åˆ°ä½ ç›¸ä¿¡ä½ å¯ä»¥ç¼–å†™è¡¨è¾¾å¼æˆ–å‡½æ•°æ¥æ‰§è¡Œæ¯ä¸ªæ­¥éª¤æˆ–æ•°æ®è½¬æ¢ã€‚
- en: Hereâ€™s a diagram-based task plan for the `discount-summary` program that we
    just developed. Weâ€™ve drawn this on paper to highlight that task plans are not
    written within a programming environment.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªåŸºäºå›¾è¡¨çš„ä»»åŠ¡è®¡åˆ’ï¼Œç”¨äºæˆ‘ä»¬åˆšåˆšå¼€å‘çš„`discount-summary`ç¨‹åºã€‚æˆ‘ä»¬åœ¨çº¸ä¸Šç»˜åˆ¶äº†è¿™ä¸ªå›¾è¡¨ï¼Œä»¥çªå‡ºä»»åŠ¡è®¡åˆ’ä¸æ˜¯åœ¨ç¼–ç¨‹ç¯å¢ƒä¸­ç¼–å†™çš„ã€‚
- en: '![](../Images/09978b14040aceae2e35d06715cb920e.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/09978b14040aceae2e35d06715cb920e.png)'
- en: Once you have a plan, you turn it into a program by writing expressions and
    functions for the intermediate steps, passing the output of one step as the input
    of the next. Sometimes, we look at a problem and immediately know how to write
    the code for it (if it is a kind of problem that youâ€™ve solved many times before).
    When you donâ€™t immediately see the solution, use this process and break down the
    problem by working with concrete examples of data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ æœ‰äº†è®¡åˆ’ï¼Œä½ å°±é€šè¿‡ç¼–å†™ä¸­é—´æ­¥éª¤çš„è¡¨è¾¾å¼å’Œå‡½æ•°ï¼Œå°†è¾“å‡ºä¼ é€’ç»™ä¸‹ä¸€ä¸ªæ­¥éª¤ï¼Œå°†å…¶è½¬æ¢æˆä¸€ä¸ªç¨‹åºã€‚æœ‰æ—¶ï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸ªé—®é¢˜ï¼Œå°±ä¼šç«‹å³çŸ¥é“å¦‚ä½•ç¼–å†™å®ƒçš„ä»£ç ï¼ˆå¦‚æœä½ æ˜¯é‚£ç§ä½ ä»¥å‰è§£å†³è¿‡å¾ˆå¤šæ¬¡çš„é—®é¢˜ï¼‰ã€‚å½“ä½ æ²¡æœ‰ç«‹å³çœ‹åˆ°è§£å†³æ–¹æ¡ˆæ—¶ï¼Œä½¿ç”¨è¿™ä¸ªè¿‡ç¨‹ï¼Œé€šè¿‡å¤„ç†å…·ä½“çš„æ•°æ®ä¾‹å­æ¥åˆ†è§£é—®é¢˜ã€‚
- en: Exercise
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-176
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Youâ€™ve been asked to develop a program that identifies the student with the
    largest improvement from the midterm to the final exam in a course. Your input
    table will have columns for each exam as well as for student names. Write a task
    plan for this problem.
  id: totrans-177
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è¢«è¦æ±‚å¼€å‘ä¸€ä¸ªç¨‹åºï¼Œç”¨äºè¯†åˆ«ä¸€é—¨è¯¾ç¨‹ä¸­ä»æœŸä¸­è€ƒè¯•åˆ°æœŸæœ«è€ƒè¯•æˆç»©æå‡æœ€å¤§çš„å­¦ç”Ÿã€‚ä½ çš„è¾“å…¥è¡¨å°†åŒ…å«æ¯ä¸ªè€ƒè¯•çš„åˆ—ä»¥åŠå­¦ç”Ÿå§“ååˆ—ã€‚ä¸ºè¿™ä¸ªé—®é¢˜ç¼–å†™ä¸€ä¸ªä»»åŠ¡è®¡åˆ’ã€‚
- en: 'Some task plans involve more than just a sequence of table values. Sometimes,
    we do multiple transformations to the same table to extract different pieces of
    data, then compute over those data. In that case, we draw our plan with branches
    that show the different computations that come together in the final result. Continuing
    with the gradebook, for example, you might be asked to write a program to compute
    the difference between the largest and lowest scores on the midterm. That task
    plan might look like:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›ä»»åŠ¡è®¡åˆ’ä¸ä»…ä»…æ¶‰åŠä¸€ç³»åˆ—çš„è¡¨å€¼åºåˆ—ã€‚æœ‰æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹åŒä¸€å¼ è¡¨è¿›è¡Œå¤šæ¬¡è½¬æ¢ä»¥æå–ä¸åŒçš„æ•°æ®ç‰‡æ®µï¼Œç„¶åå¯¹è¿™äº›æ•°æ®è¿›è¡Œè®¡ç®—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç”¨åˆ†æ”¯æ¥ç»˜åˆ¶æˆ‘ä»¬çš„è®¡åˆ’ï¼Œä»¥å±•ç¤ºæœ€ç»ˆç»“æœä¸­æ±‡é›†çš„ä¸åŒè®¡ç®—ã€‚ä»¥æˆç»©å†Œä¸ºä¾‹ï¼Œä½ å¯èƒ½è¢«è¦æ±‚ç¼–å†™ä¸€ä¸ªç¨‹åºæ¥è®¡ç®—æœŸä¸­è€ƒè¯•ä¸­æœ€é«˜åˆ†å’Œæœ€ä½åˆ†ä¹‹é—´çš„å·®å¼‚ã€‚è¿™ä¸ªä»»åŠ¡è®¡åˆ’å¯èƒ½çœ‹èµ·æ¥åƒï¼š
- en: '![](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
- en: Exercise
  id: totrans-180
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Youâ€™ve been given a table of weather data that has columns for the date, amount
    of precipitation, and highest temperature for the day. Youâ€™ve been asked to compute
    whether there were more snowy days in January than in February, where a day is
    snowy if the highest temperature is below freezing and the precipitation was more
    than zero.
  id: totrans-182
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è¢«æä¾›äº†ä¸€ä¸ªåŒ…å«æ—¥æœŸã€é™æ°´é‡å’Œå½“å¤©æœ€é«˜æ¸©åº¦çš„å¤©æ°”æ•°æ®è¡¨ã€‚ä½ è¢«è¦æ±‚è®¡ç®—ä¸€æœˆä»½çš„é›ªå¤©æ˜¯å¦æ¯”äºŒæœˆä»½å¤šï¼Œå…¶ä¸­é›ªå¤©æ˜¯æŒ‡æœ€é«˜æ¸©åº¦ä½äºå†°ç‚¹ä¸”é™æ°´é‡è¶…è¿‡é›¶ã€‚
- en: 'The takeaway of this strategy is easy to state:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç­–ç•¥çš„è¦ç‚¹å¾ˆå®¹æ˜“è¯´æ˜ï¼š
- en: If you arenâ€™t sure how to approach a problem, donâ€™t start by trying to write
    code. Plan until you understand the problem.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸ç¡®å®šå¦‚ä½•å¤„ç†ä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦ä¸€å¼€å§‹å°±å°è¯•ç¼–å†™ä»£ç ã€‚å…ˆè®¡åˆ’ï¼Œç›´åˆ°ä½ ç†è§£äº†é—®é¢˜ã€‚
- en: 'Newer programmers often ignore this advice, assuming that the fastest way to
    produce working code for a programming problem is to start writing code (especially
    if you see classmates who are able to jump directly to writing code). Experienced
    programmers know that trying to write all the code before youâ€™ve understood the
    problem will take much longer than stepping back and understanding the problem
    first. As you develop your programming skills, the specific format of your task
    plans will evolve (and indeed, we will see some cases of this later in the book
    as well). But the core idea is the same: use concrete examples to help identify
    the intermediate computations that will need, then convert those intermediate
    computations to code after or as you figure them out.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æ–°æ‰‹ç¨‹åºå‘˜ç»å¸¸å¿½è§†è¿™ä¸ªå»ºè®®ï¼Œè®¤ä¸ºç¼–å†™ä»£ç æ˜¯è§£å†³ç¼–ç¨‹é—®é¢˜çš„æœ€å¿«æ–¹å¼ï¼ˆå°¤å…¶æ˜¯å¦‚æœä½ çœ‹åˆ°åŒå­¦èƒ½å¤Ÿç›´æ¥å¼€å§‹ç¼–å†™ä»£ç ï¼‰ã€‚æœ‰ç»éªŒçš„ç¨‹åºå‘˜çŸ¥é“ï¼Œåœ¨ç†è§£é—®é¢˜ä¹‹å‰å°è¯•ç¼–å†™æ‰€æœ‰ä»£ç ä¼šæ¯”å…ˆé€€åä¸€æ­¥ç†è§£é—®é¢˜èŠ±è´¹æ›´é•¿çš„æ—¶é—´ã€‚éšç€ä½ ç¼–ç¨‹æŠ€èƒ½çš„å‘å±•ï¼Œä½ çš„ä»»åŠ¡è®¡åˆ’çš„å…·ä½“æ ¼å¼ä¹Ÿä¼šæ¼”å˜ï¼ˆå®é™…ä¸Šï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ä¹¦çš„åé¢çœ‹åˆ°ä¸€äº›è¿™æ ·çš„ä¾‹å­ï¼‰ã€‚ä½†æ ¸å¿ƒæ€æƒ³æ˜¯ç›¸åŒçš„ï¼šä½¿ç”¨å…·ä½“çš„ä¾‹å­æ¥å¸®åŠ©ç¡®å®šéœ€è¦çš„ä¸­é—´è®¡ç®—ï¼Œç„¶ååœ¨å¼„æ¸…æ¥šè¿™äº›ä¸­é—´è®¡ç®—ä¹‹åæˆ–åŒæ—¶å°†å®ƒä»¬è½¬æ¢ä¸ºä»£ç ã€‚
- en: 4.2.3Â Preparing Data Tables[ğŸ”—](#(part._preparing-tables) "Link to here")
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 å‡†å¤‡æ•°æ®è¡¨[ğŸ”—](#(part._preparing-tables) "é“¾æ¥è‡³æ­¤")
- en: Sometimes, the data we have is clean (in that weâ€™ve normalized the data and
    dealt with errors), but it still isnâ€™t in a format that we can use for the analysis
    that we want to run. For example, what if we want to look at the distribution
    of small, medium, and large ticket orders? In our current table, we have the number
    of tickets in an order, but not an explicit label on the scale of that order.
    If we wanted to produce some sort of chart showing our order scales, we will need
    to make those labels explicit.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ï¼Œæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®æ˜¯å¹²å‡€çš„ï¼ˆå³æˆ‘ä»¬å·²ç»æ ‡å‡†åŒ–äº†æ•°æ®å¹¶å¤„ç†äº†é”™è¯¯ï¼‰ï¼Œä½†å®ƒä»ç„¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦è¿è¡Œçš„åˆ†æçš„æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŸ¥çœ‹å°å‹ã€ä¸­å‹å’Œå¤§å‹è®¢å•çš„åˆ†å¸ƒæƒ…å†µæ€ä¹ˆåŠï¼Ÿåœ¨æˆ‘ä»¬çš„å½“å‰è¡¨ä¸­ï¼Œæˆ‘ä»¬æœ‰è®¢å•ä¸­çš„ç¥¨æ•°ï¼Œä½†æ²¡æœ‰è¯¥è®¢å•è§„æ¨¡çš„æ˜ç¡®æ ‡ç­¾ã€‚å¦‚æœæˆ‘ä»¬æƒ³ç”ŸæˆæŸç§ç±»å‹çš„å›¾è¡¨æ¥æ˜¾ç¤ºæˆ‘ä»¬çš„è®¢å•è§„æ¨¡ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®è¿™äº›æ ‡ç­¾ã€‚
- en: 4.2.3.1Â Creating bins[ğŸ”—](#(part._creating._bins) "Link to here")
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.1 åˆ›å»ºæ•°æ®åŒºé—´[ğŸ”—](#(part._creating._bins) "é“¾æ¥è‡³æ­¤")
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸€ç»„å€¼ï¼ˆå¦‚ `tickcounts` å€¼ï¼‰å‡å°‘åˆ°æ›´å°çš„ç±»åˆ«é›†åˆï¼ˆå¦‚è®¢å•çš„å°/ä¸­/å¤§ï¼Œæˆ–æ—¶é—´æˆ³çš„ä¸Šåˆ/ä¸‹åˆç­‰ï¼‰çš„è¡Œä¸ºç§°ä¸ºåˆ†ç»„ã€‚åˆ†ç»„æ˜¯ç±»åˆ«ã€‚ä¸ºäº†å°†è¡Œæ”¾å…¥åˆ†ç»„ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—åŸå§‹æ•°æ®å€¼çš„åˆ†ç»„ï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°åˆ†ç»„æ ‡ç­¾çš„åˆ—ã€‚
- en: 'Hereâ€™s an example of creating bins for the scale of the ticket orders:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªåˆ›å»ºç”¨äºç¥¨åŠ¡è®¢å•è§„æ¨¡çš„åˆ†ç»„çš„ä¾‹å­ï¼š
- en: '[PRE14]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 4.2.3.2Â Splitting Columns[ğŸ”—](#(part._splitting-columns) "Link to here")
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.2 åˆ—åˆ†å‰²[ğŸ”—](#(part._splitting-columns) "é“¾æ¥è‡³æ­¤")
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶è¡¨ç›®å‰ä½¿ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²æ¥è¡¨ç¤ºä¸€ä¸ªäººçš„åå­—ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŒ‰å§“æ°æ’åºæ•°æ®ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²å°±æ²¡ä»€ä¹ˆç”¨äº†ã€‚å°†ä¸€åˆ—åˆ†å‰²æˆå‡ åˆ—å¯ä»¥åœ¨å‡†å¤‡æ•°æ®é›†è¿›è¡Œåˆ†ææˆ–ä½¿ç”¨æ—¶æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ­¥éª¤ã€‚ç¼–ç¨‹è¯­è¨€é€šå¸¸æä¾›å„ç§æ“ä½œæ¥åˆ†å‰²å­—ç¬¦ä¸²ï¼šPyret
    æœ‰ `string-split` å’Œ `string-split-all` è¿™æ ·çš„æ“ä½œï¼Œå¯ä»¥å°†ä¸€ä¸ªå­—ç¬¦ä¸²åˆ†å‰²æˆå‡ ä¸ªéƒ¨åˆ†ï¼Œå›´ç»•ä¸€ä¸ªç»™å®šçš„å­—ç¬¦ï¼ˆå¦‚ç©ºæ ¼ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å†™
    `string-split("Josie Zhao", " ")` æ¥æå– `"Josie"` å’Œ `"Zhao"` ä½œä¸ºå•ç‹¬çš„å­—ç¬¦ä¸²ã€‚
- en: Exercise
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  id: totrans-196
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä¸€ä¸ªå‡½æ•°ç¼–å†™ä»»åŠ¡è®¡åˆ’ï¼ˆä¸æ˜¯ä»£ç ï¼Œåªæ˜¯è®¡åˆ’ï¼‰ï¼Œè¯¥å‡½æ•°å°†äº‹ä»¶è¡¨ä¸­çš„å½“å‰ `name` åˆ—æ›¿æ¢ä¸ºä¸¤ä¸ªåä¸º `last-name` å’Œ `first-name`
    çš„åˆ—ã€‚
- en: Do Now!
  id: totrans-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  id: totrans-199
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†ä½ æƒ³è¦æµ‹è¯•åç§°åˆ†å‰²å‡½æ•°çš„å…·ä½“åç§°å­—ç¬¦ä¸²é›†åˆå†™ä¸‹æ¥ã€‚
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a personâ€™s name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ è‡³å°‘çœ‹äº†ä¸€ä¸‹è¡¨æ ¼ï¼Œå¹¶æ³¨æ„åˆ°æˆ‘ä»¬æœ‰ä¸€ä¸ªåå« `"Zander"` çš„äººï¼Œä»–çš„æ•´ä¸ªåå­—æ˜¯ä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ç”±åå­—å’Œå§“æ°ä¸¤éƒ¨åˆ†ç»„æˆã€‚æˆ‘ä»¬è¯¥å¦‚ä½•å¤„ç†ä¸­é—´åå‘¢ï¼Ÿæˆ–è€…é‚£äº›åå­—ä¸­åŒ…å«çˆ¶æ¯åŒæ–¹å§“æ°çš„æ–‡åŒ–å‘¢ï¼Ÿæˆ–è€…é‚£äº›å°†å§“æ°æ”¾åœ¨åå­—å‰é¢çš„æ–‡åŒ–ï¼Ÿæˆ–è€…é‚£äº›åå­—ä¸ä»¥æ‹‰ä¸å­—æ¯ä¹¦å†™çš„æ–‡åŒ–å‘¢ï¼Ÿè¿™æ— ç–‘å˜å¾—æ›´åŠ å¤æ‚äº†ã€‚
- en: 'Responsible Computing: Representing Names'
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»è®¡ç®—ï¼šè¡¨ç¤ºåå­—
- en: ''
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. Itâ€™s okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  id: totrans-203
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†åå­—è¡¨ç¤ºä¸ºæ•°æ®æ˜¯é«˜åº¦ä¾èµ–äºä¸Šä¸‹æ–‡å’Œæ–‡åŒ–çš„ã€‚ä»”ç»†æ€è€ƒä½ çš„æ•°æ®é›†éœ€è¦åŒ…å«å“ªäº›ä¸ªä½“ï¼Œå¹¶æ®æ­¤è®¾è®¡ä½ çš„è¡¨æ ¼ç»“æ„ã€‚æ’é™¤ä½ è¯•å›¾ä»£è¡¨çš„äººå£ä¹‹å¤–çš„åå­—çš„è¡¨æ ¼ç»“æ„æ˜¯å¯ä»¥æ¥å—çš„ã€‚å¤´ç–¼çš„åœ°æ–¹åœ¨äºåæ¥æ„è¯†åˆ°ä½ çš„æ•°æ®é›†æˆ–ç¨‹åºæ’é™¤äº†éœ€è¦æ”¯æŒçš„æ•°æ®ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ£€æŸ¥ä½ çš„è¡¨æ ¼ç»“æ„æ‰€åšå‡ºçš„å…³äºæ•°æ®çš„å‡è®¾ï¼Œå¹¶åœ¨è€ƒè™‘äº†éœ€è¦ä»£è¡¨å“ªäº›è§‚å¯Ÿç»“æœæˆ–ä¸ªä½“ä¹‹åé€‰æ‹©è¡¨æ ¼ç»“æ„ã€‚
- en: ''
  id: totrans-204
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for â€œfalsehoods programmers believe about ...â€, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  id: totrans-205
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦æ·±å…¥äº†è§£åœ¨ç¨‹åºä¸­è¡¨ç¤ºç°å®ä¸–ç•Œåç§°å’Œæ—¥æœŸçš„å¤æ‚æ€§ï¼Œè¯·æœç´¢â€œç¨‹åºå‘˜ç›¸ä¿¡çš„â€¦â€¦é”™è¯¯â€ï¼Œè¿™å°†å‡ºç°è¯¸å¦‚[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºåç§°çš„é”™è¯¯](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)å’Œ[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºæ—¶é—´çš„é”™è¯¯](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time)ä¹‹ç±»çš„æ–‡ç« ã€‚
- en: Exercise
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  id: totrans-208
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè¿‡æ»¤è¡¨æ ¼ï¼ŒåªåŒ…å«é‚£äº›åå­—ä¸æ˜¯ç”±ä¸¤ä¸ªç”±ç©ºæ ¼åˆ†éš”çš„å­—ç¬¦ä¸²ç»„æˆçš„è¡Œã€‚
- en: Exercise
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  id: totrans-211
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè¯¥ç¨‹åºæ¥å—ä¸€ä¸ªå…·æœ‰`"first-name last-name"`æ ¼å¼çš„`name`åˆ—çš„è¡¨æ ¼ï¼Œå¹¶å°†`name`åˆ—æ›¿æ¢ä¸ºä¸¤ä¸ªåä¸º`last-name`å’Œ`first-name`çš„åˆ—ã€‚è¦ä»å•ä¸ªåç§°å­—ç¬¦ä¸²ä¸­æå–é¦–åå’Œå§“æ°ï¼Œè¯·ä½¿ç”¨ï¼š
- en: ''
  id: totrans-212
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-213
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 4.2.4Â Managing and Naming Data Tables[ğŸ”—](#(part._naming-tables) "Link to here")
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.4Â ç®¡ç†å¹¶å‘½åæ•°æ®è¡¨[ğŸ”—](#(part._naming-tables) "é“¾æ¥è‡³æ­¤")
- en: 'At this point, we have worked with several versions of the events table:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å·²ç»å¤„ç†äº†äº‹ä»¶è¡¨çš„ä¸åŒç‰ˆæœ¬ï¼š
- en: The original dataset that we tried to load
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°è¯•åŠ è½½çš„åŸå§‹æ•°æ®é›†
- en: The new sheet of the dataset with manual corrections
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰æ‰‹åŠ¨æ›´æ­£çš„æ–°æ•°æ®è¡¨
- en: The version with the discount codes normalized
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰æŠ˜æ‰£ä»£ç è§„èŒƒåŒ–çš„ç‰ˆæœ¬
- en: Another version that normalized the delivery mode
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªè§„èŒƒäº†é…é€æ–¹å¼çš„ç‰ˆæœ¬
- en: The version extended with the order-scale column
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰©å±•äº†è®¢å•è§„æ¨¡åˆ—çš„ç‰ˆæœ¬
- en: Which of these versions should get explicit names within our code file?
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰ˆæœ¬ä¸­çš„å“ªä¸€ä¸ªåº”è¯¥åœ¨ä»£ç æ–‡ä»¶ä¸­å…·æœ‰æ˜¾å¼çš„åç§°ï¼Ÿ
- en: Usually, we keep both the original raw source datasheet, as well as the copy
    with our manual corrections. Why? In case we ever have to look at the original
    data again, either to identify kinds of errors that people were making or to apply
    different fixes.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬ä¿ç•™åŸå§‹çš„åŸå§‹æ•°æ®è¡¨å‰¯æœ¬ä»¥åŠæˆ‘ä»¬æ‰‹åŠ¨æ›´æ­£çš„å‰¯æœ¬ã€‚ä¸ºä»€ä¹ˆï¼Ÿä»¥é˜²æˆ‘ä»¬ä»¥åéœ€è¦å†æ¬¡æŸ¥çœ‹åŸå§‹æ•°æ®ï¼Œæ— è®ºæ˜¯ä¸ºäº†è¯†åˆ«äººä»¬æ‰€çŠ¯çš„é”™è¯¯ç±»å‹è¿˜æ˜¯ä¸ºäº†åº”ç”¨ä¸åŒçš„ä¿®å¤ã€‚
- en: For similar reasons, we want to keep the cleaned (normalized) data separate
    from the version that we initially loaded. Fortunately, Pyret helps with this
    since it creates new tables, rather than modify the prior ones. If we have to
    normalize multiple columns, however, do we really need a new name for every intermediate
    table?
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºç±»ä¼¼çš„åŸå› ï¼Œæˆ‘ä»¬å¸Œæœ›å°†æ¸…æ´—ï¼ˆè§„èŒƒåŒ–ï¼‰çš„æ•°æ®ä¸æœ€åˆåŠ è½½çš„ç‰ˆæœ¬åˆ†å¼€ã€‚å¹¸è¿çš„æ˜¯ï¼ŒPyretæœ‰åŠ©äºè¿™ä¸€ç‚¹ï¼Œå› ä¸ºå®ƒåˆ›å»ºæ–°çš„è¡¨æ ¼ï¼Œè€Œä¸æ˜¯ä¿®æ”¹å…ˆå‰çš„è¡¨æ ¼ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å¿…é¡»è§„èŒƒåŒ–å¤šä¸ªåˆ—ï¼Œæˆ‘ä»¬çœŸçš„éœ€è¦ä¸ºæ¯ä¸ªä¸­é—´è¡¨æ ¼éƒ½åˆ›å»ºä¸€ä¸ªæ–°çš„åç§°å—ï¼Ÿ
- en: 'As a general rule, we usually maintain separate names for the initially-loaded
    table, the cleaned table, and for significant variations for analysis purposes.
    In our code, this might mean having names:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€èˆ¬è§„åˆ™ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ºæœ€åˆåŠ è½½çš„è¡¨ã€æ¸…æ´—çš„è¡¨ä»¥åŠç”¨äºåˆ†æç›®çš„çš„æ˜¾è‘—å˜ä½“ç»´æŠ¤ä¸åŒçš„åç§°ã€‚åœ¨æˆ‘ä»¬çš„ä»£ç ä¸­ï¼Œè¿™å¯èƒ½æ„å‘³ç€å…·æœ‰ä»¥ä¸‹åç§°ï¼š
- en: '[PRE16]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: where `yes-to-email` is a function we have not written, but that might have
    normalized the `"yes"` value in the `"delivery"` column. Note that we applied
    each of the normalizations in sequence, naming only the final table with all normalizations
    applied. In professional practice, if you were working with a very large dataset,
    you might just write the cleaned dataset out to a file, so that you loaded only
    the clean version during analysis. We will look at writing to file later. Having
    only a few table names will reduce your own confusion when working with your files.
    If you work on multiple data-analyses, developing a consistent strategy for how
    you name your tables will likely help you better manage your code as you switch
    between projects.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­`yes-to-email`æ˜¯æˆ‘ä»¬å°šæœªç¼–å†™çš„å‡½æ•°ï¼Œä½†å®ƒå¯èƒ½å·²ç»å°†`"delivery"`åˆ—ä¸­çš„`"yes"`å€¼è¿›è¡Œäº†è§„èŒƒåŒ–ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æŒ‰é¡ºåºåº”ç”¨äº†æ¯ç§è§„èŒƒåŒ–ï¼Œåªå‘½ååº”ç”¨äº†æ‰€æœ‰è§„èŒƒåŒ–çš„æœ€ç»ˆè¡¨æ ¼ã€‚åœ¨ä¸“ä¸šå®è·µä¸­ï¼Œå¦‚æœä½ æ­£åœ¨å¤„ç†ä¸€ä¸ªéå¸¸å¤§çš„æ•°æ®é›†ï¼Œä½ å¯èƒ½åªéœ€å°†æ¸…æ´—åçš„æ•°æ®é›†å†™å…¥æ–‡ä»¶ï¼Œè¿™æ ·åœ¨åˆ†ææ—¶åªéœ€åŠ è½½æ¸…æ´—åçš„ç‰ˆæœ¬ã€‚æˆ‘ä»¬å°†åœ¨ç¨åæŸ¥çœ‹å†™å…¥æ–‡ä»¶ã€‚åªæœ‰å°‘æ•°å‡ ä¸ªè¡¨åå°†å‡å°‘ä½ åœ¨å¤„ç†æ–‡ä»¶æ—¶çš„å›°æƒ‘ã€‚å¦‚æœä½ ä»äº‹å¤šä¸ªæ•°æ®åˆ†æå·¥ä½œï¼Œåˆ¶å®šä¸€ä¸ªä¸€è‡´çš„å‘½åè¡¨ç­–ç•¥å¯èƒ½ä¼šå¸®åŠ©ä½ æ›´å¥½åœ°åœ¨é¡¹ç›®ä¹‹é—´åˆ‡æ¢æ—¶ç®¡ç†ä»£ç ã€‚
- en: 4.2.5Â Visualizations and Plots[ğŸ”—](#(part._visualizing-tables) "Link to here")
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.5Â å¯è§†åŒ–å’Œç»˜å›¾[ğŸ”—](#(part._visualizing-tables) "é“¾æ¥è‡³æ­¤")
- en: Now that our data are cleaned and prepared, we are ready to analyze it. What
    might we want to know? Perhaps we want to know which discount code has been used
    most often. Maybe we want to know whether the time when a purchase was made correlates
    with how many tickets people buy. Thereâ€™s a host of different kinds of visualizations
    and plots that people use to summarize data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†å¹¶å‡†å¤‡å¥½äº†æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹åˆ†æäº†ã€‚æˆ‘ä»¬å¯èƒ½æƒ³çŸ¥é“ä»€ä¹ˆï¼Ÿä¹Ÿè®¸æˆ‘ä»¬æƒ³çŸ¥é“å“ªä¸ªæŠ˜æ‰£ä»£ç è¢«ä½¿ç”¨å¾—æœ€é¢‘ç¹ã€‚ä¹Ÿè®¸æˆ‘ä»¬æƒ³çŸ¥é“è´­ä¹°æ—¶é—´ä¸äººä»¬è´­ä¹°çš„ç¥¨æ•°ä¹‹é—´æ˜¯å¦æœ‰ç›¸å…³æ€§ã€‚äººä»¬ä½¿ç”¨å„ç§ä¸åŒçš„å¯è§†åŒ–å›¾è¡¨å’Œå›¾å½¢æ¥æ€»ç»“æ•°æ®ã€‚
- en: 'Which plot type to use depends on both the question and the data at hand. The
    nature of variables in a dataset helps determine relevant plots or statistical
    operations. An attribute or variable in a dataset (i.e., a single column of a
    table) can be classified as one of several different kinds, including:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å“ªç§å›¾è¡¨ç±»å‹å–å†³äºé—®é¢˜å’Œæ‰‹å¤´çš„æ•°æ®ã€‚æ•°æ®é›†ä¸­å˜é‡çš„æ€§è´¨æœ‰åŠ©äºç¡®å®šç›¸å…³çš„å›¾è¡¨æˆ–ç»Ÿè®¡æ“ä½œã€‚æ•°æ®é›†ä¸­çš„å±æ€§æˆ–å˜é‡ï¼ˆå³è¡¨æ ¼çš„å•åˆ—ï¼‰å¯ä»¥å½’ç±»ä¸ºå‡ ç§ä¸åŒç±»å‹ä¹‹ä¸€ï¼ŒåŒ…æ‹¬ï¼š
- en: 'quantitative: a variable whose values are numeric and can be ordered with a
    consistent interval between values. They are meaningful to use in computations.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®šé‡å˜é‡ï¼šå€¼æ˜¯æ•°å­—ä¸”å¯ä»¥æŒ‰ä¸€è‡´é—´éš”æ’åºçš„å˜é‡ã€‚å®ƒä»¬åœ¨è®¡ç®—ä¸­æ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: 'categorical: a variable with a fixed set of values. The values may have an
    order, but there are no meaningful computational operations between the values
    other than ordering. Such variables usually correspond to characteristics of your
    samples.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»å˜é‡ï¼šå…·æœ‰ä¸€ç»„å›ºå®šå€¼çš„å˜é‡ã€‚è¿™äº›å€¼å¯èƒ½æœ‰é¡ºåºï¼Œä½†é™¤äº†æ’åºä¹‹å¤–ï¼Œå€¼ä¹‹é—´æ²¡æœ‰æœ‰æ„ä¹‰çš„è®¡ç®—æ“ä½œã€‚è¿™ç±»å˜é‡é€šå¸¸å¯¹åº”äºæ ·æœ¬çš„ç‰¹å¾ã€‚
- en: Do Now!
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-233
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which kind of variable are last names? Grades in courses? Zipcodes?
  id: totrans-234
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å§“æ°ã€è¯¾ç¨‹æˆç»©ã€é‚®ç¼–å±äºå“ªç§å˜é‡ç±»å‹ï¼Ÿ
- en: 'Common plots and the kinds of variables they require include:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸è§çš„å›¾è¡¨åŠå…¶æ‰€éœ€çš„å˜é‡ç±»å‹åŒ…æ‹¬ï¼š
- en: Scatterplots show relationships between two quantitative variables, with one
    variable on each axis of a 2D chart.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•£ç‚¹å›¾æ˜¾ç¤ºä¸¤ä¸ªå®šé‡å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œæ¯ä¸ªå˜é‡ä½äº2Då›¾è¡¨çš„ä¸€ä¸ªè½´ä¸Šã€‚
- en: Frequency Bar charts show the frequency of each categorical value within a column
    of a dataset.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢‘ç‡æ¡å½¢å›¾æ˜¾ç¤ºæ•°æ®é›†ä¸­æŸä¸€åˆ—ä¸­æ¯ä¸ªåˆ†ç±»å€¼çš„é¢‘ç‡ã€‚
- en: Histograms segment quantitative data into equal-size intervals, showing the
    distribution of values across each interval.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ–¹å›¾å°†å®šé‡æ•°æ®åˆ†å‰²æˆç­‰å¤§å°çš„åŒºé—´ï¼Œæ˜¾ç¤ºæ¯ä¸ªåŒºé—´å†…å€¼çš„åˆ†å¸ƒã€‚
- en: Pie charts show the proportion of cells in a column across the categorical values
    in a dataset.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥¼å›¾æ˜¾ç¤ºæ•°æ®é›†ä¸­æŸä¸€åˆ—çš„å•å…ƒæ ¼åœ¨åˆ†ç±»å€¼ä¸­çš„æ¯”ä¾‹ã€‚
- en: Do Now!
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Map each of the following questions to a chart type, based on the kinds of
    variables involved in the question:'
  id: totrans-242
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†ä»¥ä¸‹é—®é¢˜æ˜ å°„åˆ°å›¾è¡¨ç±»å‹ï¼ŒåŸºäºé—®é¢˜ä¸­æ¶‰åŠçš„å˜é‡ç±»å‹ï¼š
- en: ''
  id: totrans-243
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which discount code has been used most often?
  id: totrans-244
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: å“ªä¸ªæŠ˜æ‰£ä»£ç è¢«ä½¿ç”¨å¾—æœ€é¢‘ç¹ï¼Ÿ
- en: ''
  id: totrans-245
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-246
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Is there a relationship between the number of tickets purchased in one order
    and the time of purchase?
  id: totrans-247
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: è´­ä¹°è®¢å•ä¸­çš„ç¥¨æ•°ä¸è´­ä¹°æ—¶é—´ä¹‹é—´æ˜¯å¦å­˜åœ¨å…³ç³»ï¼Ÿ
- en: ''
  id: totrans-248
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-249
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: How many orders have been made for each delivery option?
  id: totrans-250
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªé…é€é€‰é¡¹è¢«ä¸‹äº†å¤šå°‘è®¢å•ï¼Ÿ
- en: 'For example, we might use a frequency-bar-chart to answer the third question.
    Based on the `Table` documentation, we would generate this using the following
    code (with similar style for the other kinds of plots):'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨é¢‘ç‡æ¡å½¢å›¾æ¥å›ç­”ç¬¬ä¸‰ä¸ªé—®é¢˜ã€‚æ ¹æ® `Table` æ–‡æ¡£ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼ˆå…¶ä»–ç±»å‹çš„å›¾è¡¨é£æ ¼ç±»ä¼¼ï¼‰ï¼š
- en: '[PRE17]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Which yields the following chart (assuming we had not actually normalized the
    contents of the `"delivery"` column):'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿä»¥ä¸‹å›¾è¡¨ï¼ˆå‡è®¾æˆ‘ä»¬å®é™…ä¸Šæ²¡æœ‰å¯¹ `"delivery"` åˆ—çš„å†…å®¹è¿›è¡Œå½’ä¸€åŒ–ï¼‰ï¼š
- en: '![](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
- en: 'Whoa â€“ where did that extra `"email"` column come from? If you look closely,
    youâ€™ll spot the error: in the row for `"Alvina"`, thereâ€™s a typo (`"emall"` with
    an `l` instead of an `i`) in the discount column (drop-down menus, anyone?).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡â€”â€”é‚£ä¸ªé¢å¤–çš„ `"email"` åˆ—æ˜¯ä»å“ªé‡Œæ¥çš„ï¼Ÿå¦‚æœä½ ä»”ç»†çœ‹ï¼Œä½ ä¼šæ³¨æ„åˆ°é”™è¯¯ï¼šåœ¨ `"Alvina"` è¿™ä¸€è¡Œä¸­ï¼ŒæŠ˜æ‰£åˆ—ï¼ˆä¸‹æ‹‰èœå•ï¼Œæœ‰äººå—ï¼Ÿï¼‰æœ‰ä¸€ä¸ªæ‹¼å†™é”™è¯¯ï¼ˆ`"emall"`
    ä¸­çš„ `l` åº”è¯¥æ˜¯ `i`ï¼‰ã€‚
- en: The lesson here is that plots and visualizations are valuable not only in the
    analysis phase, but also early on, when we are trying to sanity check that our
    data are clean and ready to use. Good data scientists never trust a dataset without
    first making sure that the values make sense. In larger datasets, manually inspecting
    all of the data is often infeasible. But creating some plots or other summaries
    of the data is also useful for identifying errors.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„æ•™è®­æ˜¯ï¼Œå›¾è¡¨å’Œå¯è§†åŒ–ä¸ä»…åœ¨åˆ†æé˜¶æ®µæœ‰ä»·å€¼ï¼Œè€Œä¸”åœ¨æ—©æœŸï¼Œå½“æˆ‘ä»¬è¯•å›¾éªŒè¯æˆ‘ä»¬çš„æ•°æ®æ˜¯å¦å¹²å‡€ä¸”å¯ç”¨æ—¶ä¹Ÿéå¸¸æœ‰ç”¨ã€‚ä¼˜ç§€çš„æ•°æ®ç§‘å­¦å®¶åœ¨ç¡®ä¿å€¼æœ‰æ„ä¹‰ä¹‹å‰ï¼Œæ°¸è¿œä¸ä¼šä¿¡ä»»ä¸€ä¸ªæ•°æ®é›†ã€‚åœ¨å¤§å‹æ•°æ®é›†ä¸­ï¼Œæ‰‹åŠ¨æ£€æŸ¥æ‰€æœ‰æ•°æ®é€šå¸¸æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä½†åˆ›å»ºä¸€äº›å›¾è¡¨æˆ–å…¶ä»–æ•°æ®æ‘˜è¦ä¹Ÿæœ‰åŠ©äºè¯†åˆ«é”™è¯¯ã€‚
- en: '4.2.6Â Summary: Managing a Data Analysis[ğŸ”—](#(part._.Summary__.Managing_a_.Data_.Analysis)
    "Link to here")'
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.6 æ‘˜è¦ï¼šç®¡ç†æ•°æ®åˆ†æ[ğŸ”—](#(part._.Summary__.Managing_a_.Data_.Analysis) "é“¾æ¥è‡³æ­¤")
- en: 'This chapter has given you a high-level overview of how to use coding for managing
    and processing data. When doing any data analysis, a good data practitioner undergoes
    several steps:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªå¦‚ä½•ä½¿ç”¨ç¼–ç æ¥ç®¡ç†å’Œå¤„ç†æ•°æ®çš„é«˜çº§æ¦‚è¿°ã€‚åœ¨è¿›è¡Œä»»ä½•æ•°æ®åˆ†ææ—¶ï¼Œä¼˜ç§€çš„æ•°æ®ä»ä¸šè€…éƒ½ä¼šç»å†å‡ ä¸ªæ­¥éª¤ï¼š
- en: 'Think about the data in each column: what are plausible values in the column,
    and what kinds of errors might be in that column based on what you know about
    the data collection methods?'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°æ¯ä¸ªåˆ—ä¸­çš„æ•°æ®ï¼šè¯¥åˆ—ä¸­å¯èƒ½å­˜åœ¨çš„åˆç†å€¼æ˜¯ä»€ä¹ˆï¼Œä»¥åŠæ ¹æ®ä½ å¯¹æ•°æ®æ”¶é›†æ–¹æ³•çš„äº†è§£ï¼Œè¯¥åˆ—å¯èƒ½å­˜åœ¨å“ªäº›ç±»å‹çš„é”™è¯¯ï¼Ÿ
- en: Check the data for errors, using a combination of manual inspection of the table,
    plots, and `filter-with` expressions that check for unexpected values. Normalize
    or correct the data, either at the source (if you control that) or via small programs.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨é”™è¯¯ï¼Œç»“åˆæ‰‹åŠ¨æ£€æŸ¥è¡¨æ ¼ã€å›¾è¡¨å’Œ`filter-with`è¡¨è¾¾å¼æ¥æŸ¥æ‰¾æ„å¤–å€¼ã€‚åœ¨æ•°æ®æºï¼ˆå¦‚æœä½ èƒ½æ§åˆ¶çš„è¯ï¼‰æˆ–é€šè¿‡å°å‹ç¨‹åºå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–æˆ–æ ¡æ­£ã€‚
- en: Store the normalized/cleaned data table, either as a name in your program, or
    by saving it back out to a new file. Leave the raw data intact (in case you need
    to refer to the original later).
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å½’ä¸€åŒ–/æ¸…æ´—åçš„æ•°æ®è¡¨å­˜å‚¨ä¸ºç¨‹åºä¸­çš„åç§°ï¼Œæˆ–è€…å°†å…¶ä¿å­˜å›æ–°æ–‡ä»¶ã€‚ä¿ç•™åŸå§‹æ•°æ®ï¼ˆä»¥é˜²ä½ éœ€è¦ç¨åå‚è€ƒåŸå§‹æ•°æ®ï¼‰ã€‚
- en: 'Prepare the data based on the questions you want to ask about it: compute new
    columns, bin existing columns, or combine data from across tables. You can either
    finish all preparations and name the final table, or you can make separate preparations
    for each question, naming the per-question tables.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ æƒ³å¯¹å…¶æå‡ºçš„é—®é¢˜å‡†å¤‡æ•°æ®ï¼šè®¡ç®—æ–°åˆ—ã€å¯¹ç°æœ‰åˆ—è¿›è¡Œåˆ†ç®±ï¼Œæˆ–ç»“åˆæ¥è‡ªä¸åŒè¡¨æ ¼çš„æ•°æ®ã€‚ä½ å¯ä»¥å®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œå¹¶å‘½åæœ€ç»ˆè¡¨æ ¼ï¼Œæˆ–è€…ä¸ºæ¯ä¸ªé—®é¢˜è¿›è¡Œå•ç‹¬çš„å‡†å¤‡å·¥ä½œï¼Œå¹¶ä¸ºæ¯ä¸ªé—®é¢˜å‘½åè¡¨æ ¼ã€‚
- en: At last, perform your analysis, using the statistical methods, visualizations,
    and interpretations that make sense for the question and kinds of variables involved.
    When you report out on the data, always store notes about the file that holds
    your analysis code, and which parts of the file were used to generate each graph
    or interpretation in your report.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œä½¿ç”¨é€‚åˆé—®é¢˜å’Œæ¶‰åŠå˜é‡çš„ç»Ÿè®¡æ–¹æ³•ã€å¯è§†åŒ–ä»¥åŠè§£é‡Šæ¥è¿›è¡Œåˆ†æã€‚åœ¨æŠ¥å‘Šæ•°æ®æ—¶ï¼Œå§‹ç»ˆå­˜å‚¨æœ‰å…³åŒ…å«åˆ†æä»£ç çš„æ–‡ä»¶ä»¥åŠæ–‡ä»¶ä¸­å“ªäº›éƒ¨åˆ†ç”¨äºç”ŸæˆæŠ¥å‘Šä¸­æ¯ä¸ªå›¾è¡¨æˆ–è§£é‡Šçš„ç¬”è®°ã€‚
- en: Thereâ€™s a lot more to managing data and performing analysis than this book can
    cover. There are entire books, degrees, and careers in each of the management
    of data and its analysis. One area we have not discussed, for example, is machine
    learning, in which programs (that others have written) are used to make predictions
    from datasets (in contrast, this chapter has focused on projects in which you
    will use summary statistics and visualizations to perform analysis). These skills
    covered in this chapter are all prerequisites for using machine learning effectively
    and responsibly. But we still have much more to explore and understand about data
    themselves, which we turn to in the coming chapters. Onward!
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡ç†æ•°æ®å’Œæ‰§è¡Œåˆ†æçš„å†…å®¹è¿œä¸æ­¢è¿™æœ¬ä¹¦æ‰€èƒ½æ¶µç›–çš„ã€‚åœ¨æ•°æ®ç®¡ç†å’Œå…¶åˆ†ææ–¹é¢ï¼Œæœ‰å®Œæ•´çš„ä¹¦ç±ã€å­¦ä½å’ŒèŒä¸šã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°šæœªè®¨è®ºçš„ä¸€ä¸ªé¢†åŸŸæ˜¯æœºå™¨å­¦ä¹ ï¼Œå…¶ä¸­ä½¿ç”¨ï¼ˆå…¶ä»–äººç¼–å†™çš„ï¼‰ç¨‹åºä»æ•°æ®é›†ä¸­è¿›è¡Œé¢„æµ‹ï¼ˆç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ¬ç« é‡ç‚¹ä»‹ç»äº†ä½ å°†ä½¿ç”¨æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–æ¥æ‰§è¡Œåˆ†æçš„é¡¹ç›®ï¼‰ã€‚æœ¬ç« ä¸­æ¶µç›–çš„æ‰€æœ‰æŠ€èƒ½éƒ½æ˜¯æœ‰æ•ˆå’Œè´Ÿè´£ä»»åœ°ä½¿ç”¨æœºå™¨å­¦ä¹ çš„å…ˆå†³æ¡ä»¶ã€‚ä½†æˆ‘ä»¬è¿˜æœ‰æ›´å¤šéœ€è¦æ¢ç´¢å’Œç†è§£çš„æ•°æ®æœ¬èº«ï¼Œè¿™å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­å±•å¼€ã€‚ç»§ç»­å‰è¿›ï¼
- en: 'Responsible Computing: Bias in Statistical Prediction'
  id: totrans-265
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è´£ä»»è®¡ç®—ï¼šç»Ÿè®¡é¢„æµ‹ä¸­çš„åå·®
- en: ''
  id: totrans-266
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In a book that is discussing data and social responsibility, we would be remiss
    in not at least mentioning some of the many issues that arise when using data
    to make predictions (via techniques like machine learning). Some issues arise
    from problems with the data themselves (e.g., whether samples are representative,
    or whether correlations between variables lead to discrimination as in algorithmic
    hiring). Others arise with how data collected for one purpose is misused to make
    predictions for another. Still more arise with the interpretation of results.
  id: totrans-267
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸€æœ¬è®¨è®ºæ•°æ®å’Œè´£ä»»æ„Ÿçš„ä¹¦ä¸­ï¼Œå¦‚æœæˆ‘ä»¬ä¸è‡³å°‘æåŠä½¿ç”¨æ•°æ®åšå‡ºé¢„æµ‹ï¼ˆé€šè¿‡æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯ï¼‰æ—¶å‡ºç°çš„è®¸å¤šé—®é¢˜ï¼Œæˆ‘ä»¬å°†æ„Ÿåˆ°ç–å¿½ã€‚ä¸€äº›é—®é¢˜æºäºæ•°æ®æœ¬èº«çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œæ ·æœ¬æ˜¯å¦å…·æœ‰ä»£è¡¨æ€§ï¼Œæˆ–å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯å¦ä¼šå¯¼è‡´åƒç®—æ³•æ‹›è˜é‚£æ ·çš„æ­§è§†ï¼‰ã€‚å…¶ä»–é—®é¢˜å‡ºç°åœ¨ä¸ºä¸€ç§ç›®çš„æ”¶é›†çš„æ•°æ®è¢«è¯¯ç”¨äºå¦ä¸€ç§ç›®çš„çš„é¢„æµ‹ä¸­ã€‚è¿˜æœ‰æ›´å¤šçš„é—®é¢˜å‡ºç°åœ¨å¯¹ç»“æœçš„è§£é‡Šä¸­ã€‚
- en: ''
  id: totrans-268
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: These are all rich topics. There are myriad articles which you could read at
    this point to begin to understand the pitfalls (and benefits) of algorithmic decision
    making. This book will focus instead on issues that arise from the programs we
    are teaching you to write, leaving other courses, or the interests of instructors,
    to augment the material as appropriate for readersâ€™ contexts.
  id: totrans-269
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™äº›éƒ½æ˜¯ä¸°å¯Œçš„ä¸»é¢˜ã€‚åœ¨è¿™ä¸ªé˜¶æ®µï¼Œä½ å¯ä»¥é˜…è¯»å¤§é‡æ–‡ç« æ¥å¼€å§‹äº†è§£ç®—æ³•å†³ç­–çš„é™·é˜±ï¼ˆä»¥åŠå¥½å¤„ï¼‰ã€‚æœ¬ä¹¦å°†ä¸“æ³¨äºæˆ‘ä»¬ä»ç¨‹åºä¸­æ•™æˆä½ ç¼–å†™çš„é—®é¢˜ï¼Œè®©å…¶ä»–è¯¾ç¨‹æˆ–æ•™å¸ˆçš„å…´è¶£æ ¹æ®è¯»è€…çš„èƒŒæ™¯é€‚å½“è¡¥å……ææ–™ã€‚
- en: 4.2.1Â Cleaning Data Tables[ğŸ”—](#(part._cleaning-tables) "Link to here")
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 æ¸…æ´—æ•°æ®è¡¨[ğŸ”—](#(part._cleaning-tables) "é“¾æ¥è‡³æ­¤")
- en: 4.2.1.1Â Loading Data Tables[ğŸ”—](#(part._loading-tables) "Link to here")
  id: totrans-271
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1 åŠ è½½æ•°æ®è¡¨[ğŸ”—](#(part._loading-tables) "é“¾æ¥è‡³æ­¤")
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¤–éƒ¨æ•°æ®æºä¸€èµ·å·¥ä½œçš„ç¬¬ä¸€æ­¥æ˜¯å°†å®ƒåŠ è½½åˆ°ä½ çš„ç¼–ç¨‹å’Œåˆ†æç¯å¢ƒä¸­ã€‚ä½ ä½¿ç”¨å“ªç§æ¥æºå–å†³äºä½ ä¸ºPyretä½¿ç”¨çš„ç¼–ç¨‹ç¯å¢ƒï¼š
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨CPOï¼Œä½ å¯ä»¥ä»Google SheetsåŠ è½½æ•°æ®è¡¨ï¼ˆå¦‚æœä½ è¦åŠ è½½CSVæ–‡ä»¶ï¼Œé¦–å…ˆéœ€è¦å°†å…¶å¯¼å…¥Google Sheetsï¼‰
- en: If you are using VSCode, you can load tables directly from CSV files
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨VSCodeï¼Œä½ å¯ä»¥ç›´æ¥ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®è¡¨
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„Pyretæ“ä½œï¼ˆ`load-table`ï¼‰ï¼Œä½†æ–¹å¼ç•¥æœ‰ä¸åŒã€‚
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Google Sheetså’ŒCSVæ–‡ä»¶å¯¹å•å…ƒæ ¼ä¸­çš„æ•°æ®ç±»å‹å¤„ç†ä¸åŒï¼Œå› æ­¤æˆ‘ä»¬åœ¨åŠ è½½åå¯¹Pyretåˆ—çš„æ•°æ®ç±»å‹ç®¡ç†ä¹Ÿæœ‰æ‰€ä¸åŒã€‚åƒ`"Num Tickets"`è¿™æ ·çš„åˆ—ä¼¼ä¹åŒæ—¶åŒ…å«æ•°å­—å’Œå­—ç¬¦ä¸²ï¼Œçªå‡ºäº†è¿™äº›å·®å¼‚ã€‚æˆ‘ä»¬å°†åœ¨æ¯ä¸ªæºæ–‡ä»¶çš„ä¸åŒéƒ¨åˆ†ä¸­è®¨è®ºè¿™äº›ç»†å¾®å·®åˆ«ã€‚
- en: 4.2.1.1.1Â Loading Tables from Google Sheets in CPO[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "Link to here")
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.1 åœ¨CPOä¸­ä»Google SheetsåŠ è½½æ•°æ®è¡¨[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "é“¾æ¥è‡³æ­¤")
- en: '[PRE18]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ssid`æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„Google Sheetsçš„æ ‡è¯†ç¬¦ï¼ˆæ ‡è¯†ç¬¦æ˜¯Google Sheets URLä¸­çš„é•¿åºåˆ—å­—æ¯å’Œæ•°å­—ï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table`åé¢çš„åç§°åºåˆ—ç”¨äºPyretç‰ˆæœ¬è¡¨ä¸­çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°ä¸éœ€è¦ä¸åŸå§‹è¡¨ä¸­çš„åç§°åŒ¹é…ã€‚'
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source`å‘Šè¯‰Pyretè¦åŠ è½½å“ªä¸ªå·¥ä½œè¡¨ã€‚`load-spreadsheet`æ“ä½œæ¥å—Google Sheetsæ ‡è¯†ç¬¦ï¼ˆåœ¨æ­¤å¤„ä¸º`ssid`ï¼‰ï¼Œä»¥åŠGoogle
    Sheetså†…éƒ¨å‘½åçš„å·¥ä½œè¡¨ï¼ˆæˆ–æ ‡ç­¾ï¼‰åç§°ï¼ˆåœ¨æ­¤å¤„ä¸º`"Orig Data"`ï¼‰ã€‚æœ€åçš„å¸ƒå°”å€¼è¡¨ç¤ºè¡¨ä¸­æ˜¯å¦æœ‰æ ‡é¢˜è¡Œï¼ˆ`true`è¡¨ç¤ºæœ‰æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. Weâ€™ll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» Google Sheets è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret ä¼šæ ¹æ®æ•°æ®ç¬¬ä¸€è¡Œçš„å€¼å°†æ¯ä¸ªåˆ—è§†ä¸ºå…·æœ‰æŸç§ç±»å‹ã€‚å› æ­¤ï¼ŒPyret æŠ¥å‘Šäº†ä¸€ä¸ªé”™è¯¯ï¼Œå³ `"Num
    Tickets"` åˆ—ä¸­çš„ `three` ä¸æ˜¯ä¸€ä¸ªæ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨ [å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—](#%28part._cols-multiple-types-data%29)
    ä¸­è®¨è®ºå¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µã€‚
- en: 4.2.1.1.2Â Loading Tables from CSV files in VSCode[ğŸ”—](#(part._loading-tables-from-csv)
    "Link to here")
  id: totrans-283
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.2 ä» CSV æ–‡ä»¶ä¸­åŠ è½½è¡¨æ ¼åœ¨ VSCode ä¸­[ğŸ”—](#(part._loading-tables-from-csv) "é“¾æ¥è‡³æ­¤")
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ® CSV æ–‡ä»¶æ˜¯åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šè¿˜æ˜¯é€šè¿‡ URL å¯ç”¨æ¥é…ç½® `load-table` æ“ä½œã€‚
- en: 'Load from a CSV file via URL:'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ URL ä» CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE19]'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ CSV æ•°æ®å­˜åœ¨çš„ç½‘é¡µåœ°å€ï¼ˆURLï¼‰çš„æ ‡è¯†ç¬¦ã€‚'
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret ä»å“ªé‡ŒåŠ è½½æ•°æ®ã€‚`csv-table-url` æ“ä½œæ¥å—ç½‘é¡µåœ°å€ï¼ˆæ­¤å¤„ä¸º `url`ï¼‰ï¼Œä»¥åŠé€‰é¡¹ï¼ˆä¾‹å¦‚ï¼ŒæŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦æœŸæœ›å­˜åœ¨æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åè·Ÿçš„åç§°åºåˆ—ç”¨äºè¡¨æ ¼çš„ Pyret ç‰ˆæœ¬çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°**ä¸å¿…**ä¸ CSV æ–‡ä»¶ç¬¬ä¸€è¡Œï¼ˆé€šå¸¸ä¸ºæ ‡é¢˜è¡Œï¼‰ä¸­ä½¿ç”¨çš„åç§°ç›¸åŒ¹é…ã€‚'
- en: 'Load from a CSV file on your computer:'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ‚¨çš„è®¡ç®—æœºä¸Šçš„ CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE20]'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» CSV è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret å°†æ¯ä¸ªå•å…ƒæ ¼è§†ä¸ºåŒ…å«å­—ç¬¦ä¸²ï¼Œå³ä½¿å•å…ƒæ ¼æ•°æ®çœ‹èµ·æ¥æ˜¯æ•°å­—ã€‚å› æ­¤ï¼ŒPyret ä¸ä¼šåœ¨ `"Num Tickets"`
    åˆ—ä¸­çš„ `three` å’Œæ•°å­—ç»„åˆå‘¨å›´æŠ¥å‘Šé”™è¯¯ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾è¿™äº›æ•°æ®éƒ½æ˜¯æ•°å­—å­—ç¬¦ä¸²å¹¶å°è¯•ä½¿ç”¨è¿™äº›åˆ—æ•°æ®ï¼Œä¸ä¸€è‡´æ€§å°†ä¼šå†æ¬¡å‡ºç°ã€‚å¦‚æœæˆ‘ä»¬åœ¨æˆ‘ä»¬åŠ è½½æ•°æ®ä¹‹å‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ç»§ç»­ä¹‹å‰ä¿®å¤å®ƒã€‚
- en: 4.2.1.1.3Â Dealing with Columns with Multiple Types of Data[ğŸ”—](#(part._cols-multiple-types-data)
    "Link to here")
  id: totrans-293
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.3 å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—[ğŸ”—](#(part._cols-multiple-types-data) "é“¾æ¥è‡³æ­¤")
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we arenâ€™t throwing out useful information that
    was simply entered incorrectly.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æ„è‰¯å¥½çš„æ•°æ®ä¸åº”åœ¨å•ä¸ªåˆ—ä¸­æ··åˆæ•°æ®ç±»å‹ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿç¼–å†™å°ç¨‹åºæ¥çº æ­£è¿™äº›ä¸ä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œç¨‹åºå¯ä»¥å¸®åŠ©æˆ‘ä»¬åˆ é™¤ä¸é¢„æœŸåˆ—ç±»å‹ä¸ä¸€è‡´çš„æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•åº”åœ¨ä»”ç»†ç ”ç©¶æ•°æ®åä½¿ç”¨ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šä¸¢å¼ƒç”±äºè¾“å…¥é”™è¯¯è€Œä¸¢å¤±çš„æœ‰ç”¨ä¿¡æ¯ã€‚
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ­¤ç±»é—®é¢˜éœ€è¦è°¨æ…ï¼Œæˆ‘ä»¬å»ºè®®åœ¨å°†æ•°æ®åŠ è½½åˆ° Pyretï¼ˆæˆ–ä»»ä½•å…¶ä»–ç¼–ç¨‹æˆ–åˆ†æå·¥å…·ï¼‰ä¹‹å‰ï¼Œå…ˆåœ¨æºæ–‡ä»¶ä¸­ä¿®å¤æ­¤ç±»é”™è¯¯ã€‚
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç®¡ç†æ­¤ç±»ä¿®è®¢æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ•°æ®ç®¡ç†é—®é¢˜ã€‚æ‚¨å¯èƒ½å·²ä»å¦ä¸€ä¸ªå·¥å…·æ¥æ”¶æ•°æ®ï¼Œæˆ–ä»åŒ…å«é”™è¯¯çš„å¦ä¸€ä¸ªå·¥ä½œè¡¨å¯¼å…¥æ•°æ®ã€‚å…¶ä»–äººå¯èƒ½è¿˜æä¾›äº†æ‚¨éœ€è¦è·Ÿè¸ªçš„æ•°æ®æ›´æ–°ã€‚å¦‚æœæ‚¨ä»å…¶ä»–äººé‚£é‡Œè·å–äº†æ•°æ®ï¼Œé€šå¸¸æœ‰é“ç†å¤åˆ¶æºæ•°æ®å¹¶æ¸…ç†å‰¯æœ¬ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶ä»èƒ½è®¿é—®åŸå§‹æ•°æ®ã€‚
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è¯¾çš„æºæ•°æ®æ–‡ä»¶è¿˜åŒ…å«ç”¨äºæœ¬ç« å…¶ä½™éƒ¨åˆ†çš„æ¸…æ´ç‰ˆæœ¬ã€‚
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Google Sheetï¼Œè¯·æŸ¥æ‰¾åä¸º `"Data"` çš„å•ç‹¬å·¥ä½œè¡¨/æ ‡ç­¾é¡µï¼Œå…¶ä¸­ `three` å·²è¢«æ›¿æ¢ä¸ºä¸€ä¸ªæ•°å­—ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ `"Data"`
    è€Œä¸æ˜¯ `"Orig Data"` åœ¨ä¸Šé¢çš„ `load-spreadsheet` å‘½ä»¤ä¸­ï¼Œäº‹ä»¶è¡¨å°†åŠ è½½åˆ° Pyretã€‚
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ VSCode ä¸­çš„ CSV æ–‡ä»¶ï¼Œè¯·å°†æ–‡ä»¶è·¯å¾„ä¿®æ”¹ä¸ºä»¥ `"events-f25.csv"` ç»“å°¾ï¼Œè€Œä¸æ˜¯ `"events-orig-f25.csv"`ã€‚
- en: 4.2.1.2Â Dealing with Missing Entries[ğŸ”—](#(part._missing-data) "Link to here")
  id: totrans-300
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.2 å¤„ç†ç¼ºå¤±æ¡ç›®[ğŸ”—](#(part._missing-data) "é“¾æ¥è‡³æ­¤")
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell â€“ thereâ€™s no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åœ¨ Pyret ä¸­æ‰‹åŠ¨åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»ä¸ºæ¯ä¸ªå•å…ƒæ ¼æä¾›ä¸€ä¸ªå€¼â€”â€”æ²¡æœ‰â€œè·³è¿‡â€å•å…ƒæ ¼çš„æ–¹æ³•ã€‚å½“æˆ‘ä»¬åœ¨ä¸€ä¸ªç”µå­è¡¨æ ¼ç¨‹åºï¼ˆå¦‚ Excelã€Google
    Sheets æˆ–ç±»ä¼¼ç¨‹åºï¼‰ä¸­åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œå¯ä»¥å®Œå…¨ç•™ç©ºå•å…ƒæ ¼ã€‚å½“æˆ‘ä»¬æŠŠå¸¦æœ‰ç©ºå•å…ƒæ ¼çš„è¡¨æ ¼åŠ è½½åˆ° Pyret ä¸­æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether youâ€™re reading from Google Sheets or CSV files).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹æ•°æ®æ–‡ä»¶åœ¨ `discount` åˆ—ä¸­æœ‰ç©ºæ ¼ã€‚åœ¨æˆ‘ä»¬å°†å…¶åŠ è½½åˆ° Pyret åï¼Œæˆ‘ä»¬å‘ç°è¯¥åˆ—ä¸­æœ‰äº›æœ‰è¶£çš„ç°è±¡ï¼ˆå°½ç®¡å…·ä½“æ˜¯ä»€ä¹ˆå–å†³äºä½ æ˜¯ä» Google
    Sheets è¿˜æ˜¯ CSV æ–‡ä»¶ä¸­è¯»å–çš„ï¼‰ã€‚
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨ Google Sheets å’Œ CPOï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE21]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`event-data` will be the following table:'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/79459f101e303b7d4194f62bd697807a.png)'
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isnâ€™t a string. Whatâ€™s going on?
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œé‚£äº›åŒ…å«æŠ˜æ‰£ä»£ç çš„å•å…ƒæ ¼ç°åœ¨æœ‰çœ‹èµ·æ¥å¥‡æ€ªçš„ç¬¦å·ï¼Œå¦‚ `some("student")`ï¼Œè€Œä¸€äº›åŸæœ¬ä¸ºç©ºçš„å•å…ƒæ ¼åŒ…å« `none`ï¼Œä½† `none`
    ä¸æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Pyret æ”¯æŒä¸€ç§ç‰¹æ®Šç±»å‹çš„æ•°æ®ï¼Œç§°ä¸º optionã€‚æ­£å¦‚å…¶åæ‰€ç¤ºï¼Œoption ç”¨äºå¯èƒ½å­˜åœ¨æˆ–ä¸å­˜åœ¨çš„æ•°æ®ã€‚`none` æ˜¯è¡¨ç¤ºâ€œæ•°æ®ç¼ºå¤±â€çš„å€¼ã€‚å¦‚æœæ•°æ®å­˜åœ¨ï¼Œå®ƒå°†åŒ…è£¹åœ¨
    `some` ä¸­ã€‚
- en: Look also at the last two rows (for Zander and Shweta) â€“ they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells werenâ€™t actually
    empty in the Google Sheet, but instead contained several spaces.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿˜è¦æ³¨æ„æœ€åä¸¤è¡Œï¼ˆZander å’Œ Shwetaï¼‰ï¼Œåœ¨ Google Sheets ä¸­çœ‹èµ·æ¥ä¹Ÿæ˜¯ç©ºçš„ï¼Œä½† Pyret å°†å®ƒä»¬åŠ è½½ä¸ºåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼Œ`some("
    ")`ï¼‰ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™æ„å‘³ç€é‚£äº›å•å…ƒæ ¼åœ¨ Google Sheets ä¸­å®é™…ä¸Šä¸æ˜¯ç©ºçš„ï¼Œè€Œæ˜¯åŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚
- en: Do Now!
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernieâ€™s row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Samâ€™s row)?'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: çœ‹çœ‹ Ernie è¡Œçš„ `discount` å€¼ï¼šå®ƒè¯»å–ä¸º `some("none")`ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™ä¸ `none`ï¼ˆå¦‚ Sam çš„è¡Œä¸­æ‰€ç¤ºï¼‰æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨ CSV æ–‡ä»¶å’Œ VSCodeï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE22]'
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`event-data` will be the following table:'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œé‚£äº›æ²¡æœ‰æ•°æ®çš„å•å…ƒæ ¼è¦ä¹ˆæ˜¯ç©ºå­—ç¬¦ä¸² (`""`)ï¼Œè¦ä¹ˆæ˜¯åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸² (`" "`)ã€‚æ˜¯ä»€ä¹ˆå¯¼è‡´äº†è¿™ç§å·®å¼‚ï¼Ÿåœ¨åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²çš„å•å…ƒæ ¼ä¸­ï¼ŒåŸå§‹
    CSV ä¸­çš„å•å…ƒæ ¼çœ‹èµ·æ¥æ˜¯ç©ºçš„ï¼Œä½†å®é™…ä¸ŠåŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚åœ¨è¯»å– CSV æ—¶ï¼ŒPyret ä¿ç•™å•å…ƒæ ¼ä¸­çš„å®é™…å†…å®¹ã€‚åªæœ‰å½“ CSV å•å…ƒæ ¼å®é™…ä¸Šæ²¡æœ‰ä»»ä½•æ•°æ®æ—¶ï¼Œæ‰ä¼šä½¿ç”¨ç©ºå­—ç¬¦ä¸²ã€‚
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Hereâ€™s how
    we modify the code:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è®ºä½ ä½¿ç”¨çš„æ˜¯ Google Sheets è¿˜æ˜¯ CSV æ–‡ä»¶ï¼Œå¤„ç†ç¼ºå¤±æ•°æ®ï¼ˆä»¥åŠä¸€èˆ¬è½¬æ¢ï¼‰çš„æ­£ç¡®æ–¹æ³•æ˜¯æŒ‡æ˜å¦‚ä½•å¤„ç†æ¯ä¸€åˆ—ã€‚è¿™ä¿è¯äº†ä½ åœ¨è¯»å–æ•°æ®åï¼Œæ•°æ®å°†å¦‚ä½ æ‰€æœŸæœ›çš„é‚£æ ·ã€‚æˆ‘ä»¬é€šè¿‡
    `load-table` çš„é™„åŠ åŠŸèƒ½â€œæ¸…ç†å™¨â€æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ä»£ç ä¿®æ”¹æ–¹å¼ï¼š
- en: '[PRE23]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ª `sanitize` è¡Œéƒ½å‘Šè¯‰ Pyret åœ¨ç›¸åº”åˆ—ä¸­ç¼ºå¤±æ•°æ®æ—¶åº”è¯¥åšä»€ä¹ˆã€‚`string-sanitizer` è¡¨ç¤ºå°†ç¼ºå¤±æ•°æ®åŠ è½½ä¸ºç©ºå­—ç¬¦ä¸² (`""`)ã€‚æ¸…ç†å™¨è¿˜å¯ä»¥å¤„ç†ç®€å•çš„æ•°æ®è½¬æ¢ã€‚å¦‚æœ
    `string-sanitizer` åº”ç”¨äºåŒ…å«æ•°å­—ï¼ˆå¦‚ `3`ï¼‰çš„åˆ—ï¼Œæ¸…ç†å™¨ä¼šå°†è¯¥æ•°å­—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚ `"3"`ï¼‰ã€‚åŒæ ·ï¼Œå°† `num-sanitizer`
    åº”ç”¨åˆ°åˆ—ä¸­ä¼šå°†æ•°å­—å­—ç¬¦ä¸²ï¼ˆå¦‚ `"3"`) è½¬æ¢ä¸ºå®é™…æ•°å­— (`3`)ã€‚
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¸…ç†å™¨ï¼Œ`event-data` è¡¨çš„è¯»å–æ–¹å¼å¦‚ä¸‹ï¼š
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
- en: Do Now!
  id: totrans-323
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-324
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Arenâ€™t zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  id: totrans-325
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ æ³¨æ„åˆ°æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ `num-sanitizer` è€Œæ˜¯ä½¿ç”¨ `string-sanitizer` æ¸…ç† `zip` åˆ—äº†å—ï¼Ÿé‚®ç¼–ä¸æ˜¯æ•°å­—å—ï¼Ÿå°è¯•ä½¿ç”¨
    `string-sanitizer` å’Œ `num-sanitizer` åˆ†åˆ«å¯¹ `code` è¿›è¡Œä¸Šè¿°ä»£ç çš„æµ‹è¯•ï¼Œçœ‹çœ‹ä½ æ˜¯å¦èƒ½å‘ç°å·®å¼‚ã€‚
- en: Zip codes are a terrific example of data that are written with digits, but arenâ€™t
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we donâ€™t write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    Weâ€™ll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: é‚®ç¼–æ˜¯æ•°æ®ä»¥æ•°å­—å½¢å¼ç¼–å†™ä½†å¹¶ä¸æ‰“ç®—ç”¨äºæ•°å€¼çš„ç»ä½³ä¾‹å­ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿå¦‚æœæ•°æ®æ‰“ç®—ç”¨äºæ•°å€¼ï¼Œé‚£ä¹ˆæ ‡å‡†ç®—æœ¯è¿ç®—åº”è¯¥åœ¨è¿™äº›æ•°æ®ä¸Šæ˜¯æœ‰æ„ä¹‰çš„ã€‚ä¾‹å¦‚ï¼Œå°†é‚®ç¼–ä¹˜ä»¥
    3 æœ‰ä»€ä¹ˆæ„ä¹‰å‘¢ï¼Ÿæ²¡æœ‰æ„ä¹‰ã€‚åŒæ ·ï¼Œæˆ‘ä»¬ä¸ä¼šç”¨å‰å¯¼é›¶å†™æ•°å­—ï¼Œä½†é‚®ç¼–å¯ä»¥æœ‰æ„ä¹‰åœ°ä»¥ 0 å¼€å¤´ã€‚å°†é‚®ç¼–è§†ä¸ºå­—ç¬¦ä¸²å°†å®ƒä»¬è§†ä¸ºæ ‡è¯†ç¬¦è€Œä¸æ˜¯æ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„åé¢å›åˆ°è¿™ä¸ªè¯é¢˜ï¼ˆ[å¯è§†åŒ–ä¸å›¾è¡¨](#%28part._visualizing-tables%29)ï¼‰ã€‚
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºé»˜è®¤å€¼çš„è¯´æ˜ï¼šä¸ `string-sanitizer` ä¸åŒï¼Œ`num-sanitizer` ä¸ä¼šå°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºé»˜è®¤å€¼ï¼ˆå¦‚ 0ï¼‰ã€‚æ²¡æœ‰å•ä¸€çš„é»˜è®¤å€¼å¯¹æ‰€æœ‰ä½¿ç”¨æ•°å­—çš„æ–¹å¼éƒ½æ˜¯æœ‰æ„ä¹‰çš„ï¼šè™½ç„¶
    `0` å¯èƒ½æ˜¯ç¼ºå¤±ç¥¨æ•°çš„åˆç†é»˜è®¤å€¼ï¼Œä½†å®ƒå¯¹ç¼ºå¤±å¹´é¾„æ¥è¯´å¹¶æ²¡æœ‰æ„ä¹‰ã€‚å¦‚æœç”¨ä½œç¼ºå¤±è€ƒè¯•æˆç»©çš„é»˜è®¤å€¼ï¼ˆåæ¥ç”¨äºè®¡ç®—è¯¾ç¨‹æˆç»©ï¼‰ï¼Œå¯èƒ½ä¼šäº§ç”Ÿå®Œå…¨é”™è¯¯çš„ç»“æœã€‚å› æ­¤ï¼Œå¦‚æœå•å…ƒæ ¼ä¸­çš„æ•°æ®ï¼ˆæˆ–å…¶ç¼ºå¤±ï¼‰æ— æ³•å¯é åœ°è§£é‡Šä¸ºæ•°å­—ï¼Œ`num-sanitizer`
    ä¼šæŠ¥å‘Šé”™è¯¯ã€‚Pyret å…è®¸ä½ ç¼–å†™è‡ªå·±çš„è‡ªå®šä¹‰æ¸…ç†å™¨ï¼ˆä¾‹å¦‚ï¼Œå°†ç¼ºå¤±æ•°å­—é»˜è®¤ä¸º 0 çš„æ¸…ç†å™¨ï¼‰ã€‚å¦‚æœä½ æƒ³è¿™æ ·åšï¼Œè¯·å‚é˜… Pyret æ–‡æ¡£ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚
- en: The lack of meaningful default values is one reason why Pyret doesnâ€™t leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå°‘æœ‰æ„ä¹‰çš„é»˜è®¤å€¼æ˜¯ Pyret ä¸åˆ©ç”¨åˆ—ä¸Šçš„ç±»å‹æ³¨è§£è‡ªåŠ¨æ¸…ç†å¯¼å…¥æ•°æ®çš„ä¸€ä¸ªåŸå› ã€‚è‡ªåŠ¨åŒ–ä¼šä»ç¨‹åºå‘˜æ‰‹ä¸­å¤ºèµ°æ§åˆ¶æƒï¼›æ¸…ç†å™¨ä¸ºç¨‹åºå‘˜æä¾›äº†æ§åˆ¶é»˜è®¤å€¼ä»¥åŠé€‰æ‹©æ˜¯å¦ä½¿ç”¨ï¼ˆæˆ–ä¸ä½¿ç”¨ï¼‰æ¸…ç†å™¨çš„é€‰é¡¹ã€‚
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: ç»éªŒæ³•åˆ™ï¼šå½“ä½ åŠ è½½ä¸€ä¸ªè¡¨æ ¼æ—¶ï¼Œä½¿ç”¨æ¸…ç†å™¨æ¥é˜²æ­¢åŸå§‹è¡¨æ ¼ä¸­æŸäº›å•å…ƒæ ¼ç¼ºå¤±æ•°æ®æ—¶çš„é”™è¯¯ã€‚
- en: 4.2.1.3Â Normalizing Data[ğŸ”—](#(part._.Normalizing_.Data) "Link to here")
  id: totrans-330
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.3 æ ‡å‡†åŒ–æ•°æ®[ğŸ”—](#(part._.Normalizing_.Data) "é“¾æ¥è‡³æ­¤")
- en: Next, letâ€™s look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ `"Discount Code"` åˆ—ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èƒ½å¤Ÿå‡†ç¡®å›ç­”â€œæœ‰å¤šå°‘è®¢å•æ˜¯åœ¨æ¯ä¸ªæŠ˜æ‰£ä»£ç ä¸‹è¿›è¡Œçš„â€ã€‚æˆ‘ä»¬å¸Œæœ›ç­”æ¡ˆä»¥è¡¨æ ¼å½¢å¼æ€»ç»“ï¼Œå…¶ä¸­ä¸€åˆ—å‘½åæŠ˜æ‰£ä»£ç ï¼Œå¦ä¸€åˆ—ç»™å‡ºä½¿ç”¨è¯¥ä»£ç çš„è¡Œæ•°ã€‚
- en: Do Now!
  id: totrans-332
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-333
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  id: totrans-334
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¾‹å­å…ˆè¡Œï¼æˆ‘ä»¬å¸Œæœ›ä»è¿™ä¸ªè¡¨æ ¼ç‰‡æ®µçš„è®¡ç®—ä¸­å¾—åˆ°ä»€ä¹ˆæ ·çš„è¡¨æ ¼ï¼Ÿ
- en: 'You canâ€™t answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åšå‡ºä¸€äº›å…³äºå¦‚ä½•æ ‡å‡†åŒ–åç§°ä»¥åŠå¦‚ä½•å¤„ç†ç¼ºå¤±å€¼çš„å†³å®šï¼Œä½ å°±æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è§„èŒƒåŒ–è¿™ä¸ªæœ¯è¯­æŒ‡çš„æ˜¯ç¡®ä¿æ•°æ®é›†åˆï¼ˆå¦‚åˆ—ï¼‰å…·æœ‰ç»“æ„å’Œæ ¼å¼ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå°†è‡´åŠ›äºäº§ç”Ÿä»¥ä¸‹è¡¨æ ¼ï¼Œä½†ä½ å¯èƒ½åšå‡ºäº†ä¸æˆ‘ä»¬è¿™é‡Œä¸åŒçš„é€‰æ‹©ï¼š
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
- en: How do we get to this table? How do we figure this out if we arenâ€™t sure?
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å¾—åˆ°è¿™ä¸ªè¡¨æ ¼ï¼Ÿå¦‚æœæˆ‘ä»¬ä¸ç¡®å®šï¼Œæˆ‘ä»¬å¦‚ä½•æ‰¾å‡ºè¿™ä¸ªç­”æ¡ˆï¼Ÿ
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyretâ€™s `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆåœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾å¯èƒ½æœ‰åŠ©äºè¿™ä¸ªä»»åŠ¡çš„ä»»ä½•åº“å‡½æ•°ã€‚åœ¨ Pyret çš„ `dcic2024` ä¸Šä¸‹æ–‡[æ–‡æ¡£](https://hackmd.io/@cs111/table)ä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š
- en: '[PRE24]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¬èµ·æ¥å¾ˆæœ‰ç”¨ï¼Œåªè¦ `"Discount code"` åˆ—ä¸­çš„æ¯ä¸€åˆ—éƒ½æœ‰å€¼ï¼Œå¹¶ä¸”è¯¥åˆ—ä¸­å”¯ä¸€çš„å€¼æ˜¯æˆ‘ä»¬æƒ³è¦çš„è¾“å‡ºè¡¨ä¸­çš„é‚£äº›å€¼ã€‚æˆ‘ä»¬éœ€è¦åšä»€ä¹ˆæ‰èƒ½å®ç°è¿™ä¸€ç‚¹ï¼Ÿ
- en: Get `"none"` to appear in every cell that currently lacks a value
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®© `"none"` å‡ºç°åœ¨å½“å‰ç¼ºå°‘å€¼çš„æ¯ä¸ªå•å…ƒæ ¼ä¸­
- en: Convert all the codes that arenâ€™t `"none"` to upper case
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ä¸æ˜¯ `"none"` çš„ä»£ç è½¬æ¢ä¸ºå¤§å†™
- en: 'Fortunately, these tasks align with functions weâ€™ve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œè¿™äº›ä»»åŠ¡ä¸æˆ‘ä»¬å·²ç»å­¦ä¼šä½¿ç”¨çš„å‡½æ•°ç›¸å»åˆï¼šæ¯ä¸ªéƒ½æ˜¯ä¸€ä¸ªåˆ—è½¬æ¢çš„ä¾‹å­ï¼Œå…¶ä¸­ç¬¬äºŒä¸ªæ¶‰åŠåˆ° `String` åº“ä¸­çš„å¤§å†™è½¬æ¢å‡½æ•°ã€‚
- en: 'We can capture these together in a function that takes in and produces a string:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ä¸€èµ·æ•è·è¿™äº›ï¼Œè¯¥å‡½æ•°æ¥æ”¶å¹¶ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼š
- en: '[PRE25]uppercase all strings other than none,'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE25]å°†é™¤äº† `none` ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE26]
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å« `none`[PRE26]
- en: Do Now!
  id: totrans-347
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-348
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  id: totrans-349
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯„ä¼° `cell-to-discount-code` åŒ…å«çš„ä¾‹å­ã€‚è¿™æ˜¯ä¸€ç»„å¥½çš„ä¾‹å­ï¼Œè¿˜æ˜¯é—æ¼äº†ä»»ä½•å…³é”®ä¾‹å­ï¼Ÿ
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process canâ€™t
    produce different capitalizations of `"none"`, we should include that as well:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰ä¾‹å­è€ƒè™‘äº† `"birthday"` çš„ä¸åŒå¤§å°å†™ï¼Œä½†æ²¡æœ‰è€ƒè™‘ `"none"`ã€‚é™¤éä½ ç¡®ä¿¡æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸ä¼šäº§ç”Ÿ `"none"` çš„ä¸åŒå¤§å°å†™ï¼Œå¦åˆ™æˆ‘ä»¬ä¹Ÿåº”è¯¥åŒ…æ‹¬è¿™ä¸€ç‚¹ï¼š
- en: '[PRE27]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: å“å‘€ï¼å¦‚æœæˆ‘ä»¬æŠŠè¿™ä¸ªä¾‹å­æ·»åŠ åˆ°æˆ‘ä»¬çš„ `where` å—ä¸­å¹¶è¿è¡Œä»£ç ï¼ŒPyret ä¼šæŠ¥å‘Šè¿™ä¸ªä¾‹å­å¤±è´¥ã€‚
- en: Do Now!
  id: totrans-353
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-354
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  id: totrans-355
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆ `"NoNe"` çš„æƒ…å†µå¤±è´¥äº†ï¼Ÿ
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Hereâ€™s the modified code,
    on which all the examples pass.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬åœ¨ `if` è¡¨è¾¾å¼ä¸­æ£€æŸ¥å­—ç¬¦ä¸² `"none"`ï¼Œæˆ‘ä»¬éœ€è¦å°†è¾“å…¥è§„èŒƒåŒ–ä»¥åŒ¹é…æˆ‘ä»¬çš„ `if` è¡¨è¾¾å¼æ‰€æœŸæœ›çš„å†…å®¹ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹åçš„ä»£ç ï¼Œæ‰€æœ‰ä¾‹å­éƒ½é€šè¿‡äº†ã€‚
- en: '[PRE28]uppercase all strings other than none,'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE28]å°†é™¤äº† `none` ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE29]
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å« `none`[PRE29]
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ä¸ªå‡½æ•°ä¸ `transform-column` ç»“åˆä¼šäº§ç”Ÿä¸€ä¸ªå…·æœ‰æ ‡å‡†åŒ–æ ¼å¼çš„æŠ˜æ‰£ä»£ç è¡¨æ ¼ï¼ˆæé†’ï¼šä½ éœ€è¦åœ¨è¿™ä¸ª `dcic2024` ä¸Šä¸‹æ–‡ä¸­å·¥ä½œæ‰èƒ½ä½¿è¿™ç”Ÿæ•ˆï¼‰ï¼š
- en: '[PRE30]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Exercise
  id: totrans-361
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-362
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  id: totrans-363
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯•è¯•çœ‹ï¼šå°† `"delivery"` åˆ—è§„èŒƒåŒ–ï¼Œä»¥ä¾¿æ‰€æœ‰ `"yes"` å€¼éƒ½è½¬æ¢ä¸º `"email"`ã€‚
- en: 'Now that weâ€™ve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†äº†ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨`"count"`å‡½æ•°æ¥æå–æˆ‘ä»¬çš„æ±‡æ€»è¡¨ï¼š
- en: '[PRE31]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This produces the following table:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿä»¥ä¸‹è¡¨æ ¼ï¼š
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
- en: Do Now!
  id: totrans-368
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-369
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Whatâ€™s with that first row, with the discount code `" "`? Where might that have
    come from?
  id: totrans-370
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é‚£ç¬¬ä¸€è¡Œï¼ŒæŠ˜æ‰£ä»£ç `" "`æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿå®ƒå¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿ
- en: Maybe you didnâ€™t notice this before (or wouldnâ€™t have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸æ‚¨ä¹‹å‰æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸€ç‚¹ï¼ˆæˆ–è€…åœ¨æ›´å¤§çš„è¡¨æ ¼ä¸­ä¸ä¼šæ³¨æ„åˆ°ï¼‰ï¼Œä½†æºæ•°æ®ä¸­è‚¯å®šæœ‰ä¸€ä¸ªå•å…ƒæ ¼åŒ…å«ä¸€ä¸²ç©ºæ ¼ï¼Œè€Œä¸æ˜¯ç¼ºå¤±çš„å†…å®¹ã€‚æˆ‘ä»¬å¦‚ä½•å¤„ç†è§„èŒƒåŒ–ä»¥é¿å…ç±»ä¼¼è¿™ç§æƒ…å†µçš„ç¼ºå¤±ï¼Ÿ
- en: 4.2.1.4Â Normalization, Systematically[ğŸ”—](#(part._.Normalization__.Systematically)
    "Link to here")
  id: totrans-372
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.4Â è§„èŒƒåŒ–ï¼Œç³»ç»ŸåŒ–[ğŸ”—](#(part._.Normalization__.Systematically) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰ä¾‹æ‰€ç¤ºï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§ç³»ç»Ÿæ€§åœ°æ€è€ƒæ½œåœ¨è§„èŒƒåŒ–çš„æ–¹æ³•ã€‚æˆ‘ä»¬å…³äºç¼–å†™ç¤ºä¾‹çš„åˆå§‹è®¨è®ºç»™å‡ºäº†ä¸€ç§å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„æ–¹æ³•ã€‚é‚£é‡Œçš„ä¸€ä¸ªæŒ‡å¯¼åŸåˆ™æ˜¯è€ƒè™‘è¾“å…¥åŸŸï¼Œä»¥åŠè¾“å…¥å¯èƒ½çš„å˜åŒ–æ–¹å¼ã€‚å¦‚æœæˆ‘ä»¬å°†è¿™ä¸€ç‚¹åº”ç”¨äºåŠ è½½çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘åŸå§‹æ•°æ®æ˜¯å¦‚ä½•æ”¶é›†çš„ã€‚
- en: Do Now!
  id: totrans-374
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-375
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  id: totrans-376
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‚¨å¯¹ç½‘ç«™çš„äº†è§£ï¼Œäº‹ä»¶ä»£ç å†…å®¹å¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿå®ƒä»¬æ˜¯å¦‚ä½•è¾“å…¥çš„ï¼Ÿè¿™äº›ä¿¡æ¯å‘Šè¯‰æ‚¨å…³äºæ•°æ®ä¸­ä¸åŒå¯èƒ½çš„é”™è¯¯ä»€ä¹ˆï¼Ÿ
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯¹äºæ¥è‡ªåŸºäºç½‘é¡µçš„è¡¨å•ï¼ˆå¦‚æˆ‘ä»¬æœ€åˆæ‰€æ­ç¤ºçš„ï¼‰çš„æ•°æ®ï¼Œæ•°æ®å¾ˆå¯èƒ½æ˜¯ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€è¾“å…¥çš„ï¼š
- en: via a drop-down menu
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸‹æ‹‰èœå•
- en: in a text-entry box
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ–‡æœ¬è¾“å…¥æ¡†ä¸­
- en: A drop-down menu automatically normalizes the data, so thatâ€™s not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So letâ€™s assume this is from a text-entry
    box.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¸‹æ‹‰èœå•ä¼šè‡ªåŠ¨è§„èŒƒåŒ–æ•°æ®ï¼Œæ‰€ä»¥è¿™ä¸æ˜¯ä¸€ä¸ªåˆç†çš„æ¥æºï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“æ‚¨å¸Œæœ›ç”¨æˆ·ä»ä¸€ç»„å›ºå®šçš„é€‰é¡¹ä¸­é€‰æ‹©æ—¶ï¼Œåº”è¯¥åœ¨è¡¨å•ä¸Šä½¿ç”¨ä¸‹æ‹‰èœå•ï¼‰ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å‡è®¾è¿™æ˜¯ä»ä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†æ¥çš„ã€‚
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬è¾“å…¥æ¡†æ„å‘³ç€ä»»ä½•å…¸å‹çš„äººç±»æ‰“å­—é”™è¯¯éƒ½å¯èƒ½å‡ºç°åœ¨æ‚¨çš„æ•°æ®ä¸­ï¼šäº¤æ¢çš„å­—æ¯ï¼Œç¼ºå¤±çš„å­—æ¯ï¼Œå‰å¯¼ç©ºæ ¼ï¼Œå¤§å°å†™ç­‰ã€‚æ‚¨ä¹Ÿå¯èƒ½å¾—åˆ°ä¸€äº›æ•°æ®ï¼Œå…¶ä¸­æœ‰äººåªæ˜¯è¾“å…¥äº†é”™è¯¯çš„å†…å®¹ï¼ˆæˆ–è€…éšæœºè¾“å…¥ï¼Œçœ‹çœ‹æ‚¨çš„è¡¨å•ä¼šåšä»€ä¹ˆï¼‰ã€‚
- en: Do Now!
  id: totrans-382
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-383
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  id: totrans-384
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‚¨è®¤ä¸ºç¨‹åºå¯ä»¥è‡ªåŠ¨çº æ­£å“ªäº›äº¤æ¢çš„å­—æ¯ã€ç¼ºå¤±é”™è¯¯å’Œéšæœºæ–‡æœ¬ï¼Ÿ
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, youâ€™d have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. â€“ these are questions of policy, not of programming).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤æ¢å’Œç¼ºå¤±çš„å­—æ¯æ˜¯æ‹¼å†™æ£€æŸ¥å™¨å¯èƒ½èƒ½å¤Ÿçº æ­£çš„ç±»å‹ï¼ˆç‰¹åˆ«æ˜¯å¦‚æœç¨‹åºçŸ¥é“æ‰€æœ‰çš„æœ‰æ•ˆæŠ˜æ‰£ä»£ç ï¼‰ã€‚éšæœºåƒåœ¾ï¼ŒæŒ‰ç…§å®šä¹‰ï¼Œæ˜¯éšæœºçš„ã€‚åœ¨é‚£é‡Œï¼Œæ‚¨éœ€è¦ä¸æ´»åŠ¨å…¬å¸äº¤è°ˆï¼Œä»¥å†³å®šä»–ä»¬å¸Œæœ›å¦‚ä½•å¤„ç†è¿™äº›æƒ…å†µï¼ˆå°†å®ƒä»¬è½¬æ¢ä¸º`"none"`ï¼Œè”ç³»å®¢æˆ·ç­‰ã€‚è¿™äº›é—®é¢˜æ˜¯æ”¿ç­–é—®é¢˜ï¼Œè€Œä¸æ˜¯ç¼–ç¨‹é—®é¢˜ï¼‰ã€‚
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®é™…ä¸Šï¼Œè¿™ä¸ªæ•™è®­å°±æ˜¯å°½å¯èƒ½ä½¿ç”¨ä¸‹æ‹‰èœå•æˆ–å…¶ä»–æ–¹å¼æ¥é˜²æ­¢åœ¨æºæ•°æ®ä¸­è¾“å…¥é”™è¯¯ã€‚
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once youâ€™ve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æ‚¨åœ¨ç¼–ç¨‹æ–¹é¢çš„ç»éªŒè¶Šæ¥è¶Šä¸°å¯Œï¼Œæ‚¨ä¹Ÿå°†å­¦ä¼šé¢„è§æŸäº›ç±»å‹çš„é”™è¯¯ã€‚ä¾‹å¦‚ï¼Œä¸€æ—¦æ‚¨å¤„ç†è¿‡è¶³å¤Ÿå¤šçš„åŒ…å«è¿™äº›é—®é¢˜çš„è¡¨æ ¼ï¼Œå•å…ƒæ ¼çœ‹èµ·æ¥ç©ºçš„æƒ…å†µå°±ä¼šå˜å¾—å¾ˆè‡ªç„¶ã€‚éœ€è¦é¢„è§æ•°æ®é”™è¯¯æ˜¯ä¼˜ç§€çš„æ•°æ®ç§‘å­¦å®¶å¿…é¡»äº†è§£ä»–ä»¬æ‰€åœ¨é¢†åŸŸçš„åŸå› ä¹‹ä¸€ã€‚
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now weâ€™re getting ahead of ourselves.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥å­¦åˆ°çš„æ˜¯æˆ‘ä»¬å¦‚ä½•è®¨è®ºé¢„æœŸå†…å®¹ã€‚æˆ‘ä»¬æ€è€ƒäº†æ•°æ®æ¥æºï¼Œä»¥åŠåœ¨é‚£ä¸ªæƒ…å†µä¸‹å¯èƒ½å‡ºç°çš„é”™è¯¯ã€‚æœ‰ä¸€ä¸ªæ¸…æ™°çš„é”™è¯¯æ¨¡å‹åœ¨å¿ƒä¸­å°†æœ‰åŠ©äºä½ å¼€å‘æ›´å¥å£®çš„ç¨‹åºã€‚å®é™…ä¸Šï¼Œè¿™ç§å¯¹æŠ—æ€§æ€ç»´æ˜¯å®‰å…¨é¢†åŸŸå·¥ä½œçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä½†ç°åœ¨æˆ‘ä»¬å¯èƒ½æœ‰äº›è¶…å‰äº†ã€‚
- en: Exercise
  id: totrans-389
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-390
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  id: totrans-391
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ç”µå­è¡¨æ ¼ä¸­ï¼Œçœ‹ä¼¼ç©ºç™½çš„å•å…ƒæ ¼æœ‰æ—¶å®é™…ä¸ŠåŒ…å«å†…å®¹ï¼Œå½¢å¼ä¸ºåªç”±ç©ºæ ¼ç»„æˆçš„å­—ç¬¦ä¸²ï¼šå½“æˆ‘ä»¬æŸ¥çœ‹ç”µå­è¡¨æ ¼æ—¶ï¼Œ`""`å’Œ`" "`çœ‹èµ·æ¥ç›¸åŒï¼Œä½†å®ƒä»¬åœ¨è®¡ç®—ä¸Šå®é™…ä¸Šæ˜¯ä¸åŒçš„å€¼ã€‚
- en: ''
  id: totrans-392
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  id: totrans-393
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ ä¼šå¦‚ä½•ä¿®æ”¹`cell-to-discount-code`å‡½æ•°ï¼Œä»¥ä¾¿åªåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ä¹Ÿè¢«è½¬æ¢ä¸º`"none"`ï¼Ÿï¼ˆæç¤ºï¼šåœ¨å­—ç¬¦ä¸²åº“ä¸­æŸ¥æ‰¾`string-replace`ã€‚ï¼‰
- en: 4.2.1.5Â Using Programs to Detect Data Errors[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  id: totrans-394
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.5Â ä½¿ç”¨ç¨‹åºæ£€æµ‹æ•°æ®é”™è¯¯[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors) "é“¾æ¥è‡³æ­¤")
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Letâ€™s consider the `"email"` column: thatâ€™s
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Letâ€™s consider two rules:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé€šè¿‡ç¼–å†™å‡½æ•°æ¥æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åŒ…å«æ„å¤–çš„å€¼æ¥æŸ¥æ‰¾é”™è¯¯ã€‚è®©æˆ‘ä»¬è€ƒè™‘`"email"`åˆ—ï¼šè¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿç¼–å†™ç¨‹åºæ¥æ ‡è®°ä»»ä½•åŒ…å«æ— æ•ˆç”µå­é‚®ä»¶åœ°å€çš„è¡Œçš„ä½ç½®ã€‚ä»€ä¹ˆæ„æˆäº†ä¸€ä¸ªæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ï¼Ÿè®©æˆ‘ä»¬è€ƒè™‘ä¸¤ä¸ªè§„åˆ™ï¼š
- en: Valid email addresses should contain an `@` sign
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”åŒ…å«ä¸€ä¸ª`@`ç¬¦å·
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”ä»¥`".com"`ã€`".edu"`æˆ–`".org"`ä¹‹ä¸€ç»“å°¾
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¡®å®æ˜¯ä¸€ä¸ªè¿‡æ—¶ã€æœ‰é™ä¸”ä»¥ç¾å›½ä¸ºä¸­å¿ƒçš„ç”µå­é‚®ä»¶åœ°å€å®šä¹‰ï¼Œä½†æ‰©å±•æ ¼å¼å¹¶ä¸ä¼šä»æ ¹æœ¬ä¸Šæ”¹å˜æœ¬èŠ‚çš„ä¸»æ—¨ã€‚
- en: Exercise
  id: totrans-399
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-400
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  id: totrans-401
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªåä¸º`is-email`çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºè¯¥å­—ç¬¦ä¸²æ˜¯å¦æ»¡è¶³ä¸Šè¿°ä¸¤ä¸ªè§„åˆ™ä»¥æˆä¸ºæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ã€‚ä¸ºäº†å¢åŠ ä¸€äº›æŒ‘æˆ˜ï¼Œè¿˜å¯ä»¥åŒ…æ‹¬ä¸€ä¸ªè§„åˆ™ï¼Œå³åœ¨`@`å’ŒåŸºäºç‚¹çš„ç»“å°¾ä¹‹é—´å¿…é¡»æœ‰ä¸€äº›å­—ç¬¦ã€‚
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program canâ€™t be written to perform the fixing.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¿™æ ·çš„å‡½æ•°ï¼Œä¸€ä¸ª`filter-with`ä¾‹ç¨‹å¯ä»¥ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼ï¼Œæ ‡è¯†æ‰€æœ‰éœ€è¦çº æ­£ç”µå­é‚®ä»¶åœ°å€çš„è¡Œã€‚è¿™é‡Œçš„è¦ç‚¹æ˜¯ç¨‹åºå¯¹äºæŸ¥æ‰¾éœ€è¦çº æ­£çš„æ•°æ®éå¸¸æœ‰å¸®åŠ©ï¼Œå³ä½¿ä¸èƒ½ç¼–å†™ç¨‹åºæ¥æ‰§è¡Œä¿®å¤ã€‚
- en: 4.2.1.1Â Loading Data Tables[ğŸ”—](#(part._loading-tables) "Link to here")
  id: totrans-403
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1Â åŠ è½½æ•°æ®è¡¨[ğŸ”—](#(part._loading-tables) "é“¾æ¥è‡³æ­¤")
- en: 'The first step to working with an outside data source is to load it into your
    programming and analysis environment. Which source you use depends on the programming
    environment that you are using for Pyret:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¤–éƒ¨æ•°æ®æºä¸€èµ·å·¥ä½œçš„ç¬¬ä¸€æ­¥æ˜¯å°†å®ƒåŠ è½½åˆ°ä½ çš„ç¼–ç¨‹å’Œåˆ†æç¯å¢ƒä¸­ã€‚ä½ ä½¿ç”¨å“ªç§æºå–å†³äºä½ ä¸ºPyretä½¿ç”¨çš„ç¼–ç¨‹ç¯å¢ƒï¼š
- en: If you are using CPO, you can load tables from Google Sheets (if you want to
    load a CSV, you first need to import it into Google Sheets)
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨CPOï¼Œä½ å¯ä»¥ä»Google Sheetsä¸­åŠ è½½è¡¨æ ¼ï¼ˆå¦‚æœä½ è¦åŠ è½½CSVï¼Œé¦–å…ˆéœ€è¦å°†å…¶å¯¼å…¥Google Sheetsï¼‰
- en: If you are using VSCode, you can load tables directly from CSV files
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä½¿ç”¨VSCodeï¼Œä½ å¯ä»¥ç›´æ¥ä»CSVæ–‡ä»¶ä¸­åŠ è½½è¡¨æ ¼
- en: Both use the same Pyret operation (`load-table`), but in slightly different
    ways.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬éƒ½ä½¿ç”¨ç›¸åŒçš„Pyretæ“ä½œï¼ˆ`load-table`ï¼‰ï¼Œä½†æ–¹å¼ç•¥æœ‰ä¸åŒã€‚
- en: Google Sheets and CSV files treat the types of data in cells differently, so
    there are also differences in how we manage the types of Pyret columns after loading.
    Columns like `"Num Tickets"` that appear to contain both numbers and strings highlight
    the differences. We discuss these nuances in separate sections for each kind of
    source file.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: Google Sheets å’Œ CSV æ–‡ä»¶å¯¹å•å…ƒæ ¼ä¸­çš„æ•°æ®ç±»å‹å¤„ç†ä¸åŒï¼Œå› æ­¤æˆ‘ä»¬åœ¨åŠ è½½åç®¡ç† Pyret åˆ—çš„ç±»å‹æ—¶ä¹Ÿå­˜åœ¨å·®å¼‚ã€‚åƒ `"Num Tickets"`
    è¿™æ ·çš„åˆ—ï¼Œçœ‹èµ·æ¥åŒæ—¶åŒ…å«æ•°å­—å’Œå­—ç¬¦ä¸²ï¼Œçªå‡ºäº†è¿™äº›å·®å¼‚ã€‚æˆ‘ä»¬å°†åœ¨æ¯ä¸ªæºæ–‡ä»¶ç±»å‹çš„å•ç‹¬éƒ¨åˆ†ä¸­è®¨è®ºè¿™äº›ç»†å¾®å·®åˆ«ã€‚
- en: 4.2.1.1.1Â Loading Tables from Google Sheets in CPO[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "Link to here")
  id: totrans-409
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.1 åœ¨ CPO ä¸­ä» Google Sheets åŠ è½½è¡¨æ ¼[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "é“¾æ¥åˆ°æ­¤å¤„")
- en: '[PRE32]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ssid` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ Google Sheet çš„æ ‡è¯†ç¬¦ï¼ˆæ ‡è¯†ç¬¦æ˜¯ Google Sheet URL ä¸­çš„ä¸€é•¿ä¸²å­—æ¯å’Œæ•°å­—ï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åé¢çš„åç§°åºåˆ—ç”¨äº Pyret ç‰ˆæœ¬çš„è¡¨æ ¼çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°ä¸éœ€è¦ä¸åŸå§‹è¡¨æ ¼ä¸­ä½¿ç”¨çš„åç§°åŒ¹é…ã€‚'
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret è¦åŠ è½½å“ªä¸ªå·¥ä½œè¡¨ã€‚`load-spreadsheet` æ“ä½œæ¥å— Google Sheet æ ‡è¯†ç¬¦ï¼ˆåœ¨æ­¤å¤„ä¸º `ssid`ï¼‰ï¼Œä»¥åŠ
    Google Sheet ä¸­å‘½åçš„å·¥ä½œè¡¨ï¼ˆæˆ–æ ‡ç­¾ï¼‰çš„åç§°ï¼ˆåœ¨æ­¤å¤„ä¸º `"Orig Data"`ï¼‰ã€‚æœ€åçš„å¸ƒå°”å€¼è¡¨ç¤ºè¡¨æ ¼ä¸­æ˜¯å¦æœ‰æ ‡é¢˜è¡Œï¼ˆ`true` è¡¨ç¤ºæœ‰æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. Weâ€™ll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» Google Sheets è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret æ ¹æ®æ•°æ®ç¬¬ä¸€è¡Œçš„å€¼å°†æ¯ä¸ªåˆ—è§†ä¸ºå…·æœ‰ç±»å‹ã€‚å› æ­¤ï¼ŒPyret æŠ¥å‘Šäº†ä¸€ä¸ªé”™è¯¯ï¼Œå³ `"Num Tickets"`
    åˆ—ä¸­çš„ `three` ä¸æ˜¯ä¸€ä¸ªæ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨ [å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—](#(part._cols-multiple-types-data)) ä¸­è®¨è®ºå¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µã€‚
- en: 4.2.1.1.2Â Loading Tables from CSV files in VSCode[ğŸ”—](#(part._loading-tables-from-csv)
    "Link to here")
  id: totrans-415
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.2 åœ¨ VSCode ä¸­ä» CSV æ–‡ä»¶åŠ è½½è¡¨æ ¼[ğŸ”—](#(part._loading-tables-from-csv) "é“¾æ¥åˆ°æ­¤å¤„")
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ® CSV æ–‡ä»¶æ˜¯åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šè¿˜æ˜¯é€šè¿‡ URL å¯ç”¨æ¥é…ç½® `load-table` æ“ä½œã€‚
- en: 'Load from a CSV file via URL:'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ URL ä» CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE33]'
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ CSV æ•°æ®å­˜åœ¨çš„ç½‘é¡µåœ°å€ï¼ˆURLï¼‰çš„æ ‡è¯†ç¬¦ã€‚'
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret ä»å“ªé‡ŒåŠ è½½æ•°æ®ã€‚`csv-table-url` æ“ä½œæ¥å—ç½‘é¡µåœ°å€ï¼ˆåœ¨æ­¤å¤„ä¸º `url`ï¼‰ï¼Œä»¥åŠé€‰é¡¹ï¼ˆä¾‹å¦‚ï¼ŒæŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦æœŸæœ›æœ‰æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åé¢çš„åç§°åºåˆ—ç”¨äº Pyret ç‰ˆæœ¬çš„è¡¨æ ¼çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°ä¸éœ€è¦ä¸ CSV æ–‡ä»¶ç¬¬ä¸€è¡Œï¼ˆé€šå¸¸æ˜¯æ ‡é¢˜è¡Œï¼‰ä¸­ä½¿ç”¨çš„åç§°åŒ¹é…ã€‚'
- en: 'Load from a CSV file on your computer:'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æ‚¨è®¡ç®—æœºä¸Šçš„ CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE34]'
  id: totrans-423
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» CSV æ–‡ä»¶è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret å°†æ¯ä¸ªå•å…ƒæ ¼è§†ä¸ºåŒ…å«å­—ç¬¦ä¸²ï¼Œå³ä½¿å•å…ƒæ ¼æ•°æ®çœ‹èµ·æ¥æ˜¯æ•°å­—ã€‚å› æ­¤ï¼ŒPyret ä¸ä¼šåœ¨ `"Num Tickets"`
    åˆ—çš„ `three` å’Œæ•°å­—çš„ç»„åˆå‘¨å›´æŠ¥å‘Šé”™è¯¯ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å°è¯•ä½¿ç”¨å‡è®¾å®ƒä»¬éƒ½æ˜¯æ•°å­—å­—ç¬¦ä¸²çš„åˆ—æ•°æ®ï¼Œè¿™ç§ä¸ä¸€è‡´æ€§å°±ä¼šå†æ¬¡å‡ºç°ã€‚å¦‚æœæˆ‘ä»¬åœ¨æˆ‘ä»¬åŠ è½½æ•°æ®ä¹‹å‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ç»§ç»­ä¹‹å‰ä¿®å¤å®ƒã€‚
- en: 4.2.1.1.3Â Dealing with Columns with Multiple Types of Data[ğŸ”—](#(part._cols-multiple-types-data)
    "Link to here")
  id: totrans-425
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.3 å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—[ğŸ”—](#(part._cols-multiple-types-data) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we arenâ€™t throwing out useful information that
    was simply entered incorrectly.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¼å¼è‰¯å¥½çš„æ•°æ®ä¸åº”åœ¨å•ä¸ªåˆ—ä¸­æ··åˆæ•°æ®ç±»å‹ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿç¼–å†™å°ç¨‹åºæ¥çº æ­£è¿™äº›ä¸ä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç¨‹åºå¯ä»¥å¸®åŠ©æˆ‘ä»¬åˆ é™¤ä¸é¢„æœŸåˆ—ç±»å‹ä¸ä¸€è‡´çš„æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•åº”è¯¥åœ¨ä»”ç»†ç ”ç©¶æ•°æ®ä¹‹åä½¿ç”¨ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šä¸¢å¼ƒç”±äºè¾“å…¥é”™è¯¯è€Œä¸¢å¤±çš„æœ‰ç”¨ä¿¡æ¯ã€‚
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ­¤ç±»é—®é¢˜éœ€è¦è°¨æ…ï¼Œæˆ‘ä»¬å»ºè®®åœ¨å°†æ•°æ®åŠ è½½åˆ° Pyretï¼ˆæˆ–ä»»ä½•å…¶ä»–ç¼–ç¨‹æˆ–åˆ†æå·¥å…·ï¼‰ä¹‹å‰ï¼Œåœ¨æºæ–‡ä»¶ä¸­ä¿®å¤æ­¤ç±»é”™è¯¯ã€‚
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç®¡ç†æ­¤ç±»ä¿®è®¢æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ•°æ®ç®¡ç†é—®é¢˜ã€‚ä½ å¯èƒ½å·²ç»ä»å¦ä¸€ä¸ªå·¥å…·æ¥æ”¶äº†æ•°æ®ï¼Œæˆ–è€…ä»åŒ…å«é”™è¯¯çš„å¦ä¸€ä¸ªå·¥ä½œè¡¨ä¸­å¯¼å…¥å®ƒã€‚å…¶ä»–äººå¯èƒ½ä¹Ÿä¼šæä¾›ä½ éœ€è¦è·Ÿè¸ªçš„æ•°æ®æ›´æ–°ã€‚å¦‚æœä½ ä»å…¶ä»–äººé‚£é‡Œè·å¾—äº†æ•°æ®ï¼Œé€šå¸¸æœ‰é“ç†å¤åˆ¶æºæ•°æ®å¹¶æ¸…ç†å‰¯æœ¬ï¼Œè¿™æ ·ä½ ä»ç„¶å¯ä»¥åœ¨éœ€è¦æ—¶è®¿é—®åŸå§‹æ•°æ®ã€‚
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è¯¾çš„æºæ•°æ®æ–‡ä»¶è¿˜åŒ…å«ç”¨äºæœ¬ç« å…¶ä½™éƒ¨åˆ†çš„æ¸…æ´ç‰ˆæœ¬ã€‚
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ Google Sheetï¼Œè¯·å¯»æ‰¾åä¸º `"Data"` çš„å•ç‹¬å·¥ä½œè¡¨/æ ‡ç­¾é¡µï¼Œå…¶ä¸­ `three` å·²è¢«æ›¿æ¢ä¸ºä¸€ä¸ªæ•°å­—ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ `"Data"`
    è€Œä¸æ˜¯ `"Orig Data"` åœ¨ä¸Šé¢çš„ `load-spreadsheet` å‘½ä»¤ä¸­ï¼Œäº‹ä»¶è¡¨å°†åŠ è½½åˆ° Pyret ä¸­ã€‚
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ VSCode ä¸­çš„ CSV æ–‡ä»¶ï¼Œè¯·ä¿®æ”¹æ–‡ä»¶è·¯å¾„ä»¥ç»“æŸäº `"events-f25.csv"` è€Œä¸æ˜¯ `"events-orig-f25.csv"`ã€‚
- en: 4.2.1.1.1Â Loading Tables from Google Sheets in CPO[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "Link to here")
  id: totrans-432
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.1 ä» CPO ä¸­åŠ è½½ Google Sheets ä¸­çš„è¡¨æ ¼[ğŸ”—](#(part._loading-tables-from-google-sheets)
    "é“¾æ¥è‡³æ­¤")
- en: '[PRE35]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`ssid` is the identifier of the Google Sheet we want to load (the identifier
    is the long sequence of letters and numbers in the Google Sheet URL).'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ssid` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ Google Sheet çš„æ ‡è¯†ç¬¦ï¼ˆæ ‡è¯†ç¬¦æ˜¯ Google Sheet URL ä¸­çš„é•¿åºåˆ—å­—æ¯å’Œæ•°å­—ï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the original Sheet.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åè·Ÿçš„åç§°åºåˆ—ç”¨äº Pyret è¡¨æ ¼ç‰ˆæœ¬ä¸­çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°ä¸éœ€è¦ä¸åŸå§‹å·¥ä½œè¡¨ä¸­ä½¿ç”¨çš„åç§°åŒ¹é…ã€‚'
- en: '`source` tells Pyret which sheet to load. The `load-spreadsheet` operation
    takes the Google Sheet identifier (here, `ssid`), as well as the name of the individual
    worksheet (or tab) as named within the Google Sheet (here, `"Orig Data"`). The
    final boolean indicates whether there is a header row in the table (`true` means
    there is a header row).'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret è¦åŠ è½½å“ªä¸ªå·¥ä½œè¡¨ã€‚`load-spreadsheet` æ“ä½œæ¥å— Google Sheet æ ‡è¯†ç¬¦ï¼ˆåœ¨è¿™é‡Œï¼Œ`ssid`ï¼‰ï¼Œä»¥åŠ
    Google Sheet ä¸­å‘½åçš„å·¥ä½œè¡¨ï¼ˆæˆ–æ ‡ç­¾é¡µï¼‰çš„åç§°ï¼ˆåœ¨è¿™é‡Œï¼Œ`"Orig Data"`ï¼‰ã€‚æœ€åçš„å¸ƒå°”å€¼è¡¨ç¤ºè¡¨ä¸­æ˜¯å¦æœ‰æ ‡é¢˜è¡Œï¼ˆ`true` è¡¨ç¤ºæœ‰æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: When reading a table from Google Sheets, Pyret treats each column as having
    a type, based on the value in the first row of data. Pyret thus reports an error
    that `three` (in the `"Num Tickets"` column) is not a number. Weâ€™ll discuss how
    to handle this in [Dealing with Columns with Multiple Types of Data](#%28part._cols-multiple-types-data%29).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» Google Sheets è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret ä¼šæ ¹æ®æ•°æ®ç¬¬ä¸€è¡Œçš„å€¼å°†æ¯ä¸ªåˆ—è§†ä¸ºå…·æœ‰ç±»å‹ã€‚å› æ­¤ï¼ŒPyret æŠ¥å‘Šäº†ä¸€ä¸ªé”™è¯¯ï¼Œå³ `"Num Tickets"`
    åˆ—ä¸­çš„ `three` ä¸æ˜¯ä¸€ä¸ªæ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨ [å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—](#%28part._cols-multiple-types-data%29)
    ä¸­è®¨è®ºå¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µã€‚
- en: 4.2.1.1.2Â Loading Tables from CSV files in VSCode[ğŸ”—](#(part._loading-tables-from-csv)
    "Link to here")
  id: totrans-438
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.2 ä» VSCode ä¸­çš„ CSV æ–‡ä»¶åŠ è½½è¡¨æ ¼[ğŸ”—](#(part._loading-tables-from-csv) "é“¾æ¥è‡³æ­¤")
- en: We configure the `load-table` operation differently depending on whether the
    CSV file is on your computer or available through a URL.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ® CSV æ–‡ä»¶æ˜¯åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šè¿˜æ˜¯é€šè¿‡ URL å¯ç”¨æ¥é…ç½®ä¸åŒçš„ `load-table` æ“ä½œã€‚
- en: 'Load from a CSV file via URL:'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ URL ä» CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE36]'
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`url` is the identifier of the web address (URL) where the CSV data we want
    to load exists.'
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url` æ˜¯æˆ‘ä»¬æƒ³è¦åŠ è½½çš„ CSV æ•°æ®å­˜åœ¨çš„ç½‘é¡µåœ°å€ï¼ˆURLï¼‰çš„æ ‡è¯†ç¬¦ã€‚'
- en: '`source` tells Pyret where to load the data from. The `csv-table-url` operation
    takes the web address (here, `url`), as well as options (which indicate, for example,
    whether we expect there to be a header row).'
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source` å‘Šè¯‰ Pyret ä»å“ªé‡ŒåŠ è½½æ•°æ®ã€‚`csv-table-url` æ“ä½œæ¥å—ç½‘é¡µåœ°å€ï¼ˆæ­¤å¤„ä¸º `url`ï¼‰ï¼Œä»¥åŠé€‰é¡¹ï¼ˆä¾‹å¦‚ï¼ŒæŒ‡ç¤ºæˆ‘ä»¬æ˜¯å¦æœŸæœ›å­˜åœ¨æ ‡é¢˜è¡Œï¼‰ã€‚'
- en: The sequence of names following `load-table` is used for the column headers
    in the Pyret version of the table. These do NOT have to match the names used in
    the first row of the CSV file (which is usually a header row).
  id: totrans-444
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load-table` åé¢çš„åç§°åºåˆ—ç”¨äº Pyret è¡¨æ ¼ç‰ˆæœ¬ä¸­çš„åˆ—æ ‡é¢˜ã€‚è¿™äº›åç§°**ä¸**éœ€è¦ä¸ CSV æ–‡ä»¶ç¬¬ä¸€è¡Œä¸­ä½¿ç”¨çš„åç§°ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæ ‡é¢˜è¡Œï¼‰ç›¸åŒ¹é…ã€‚'
- en: 'Load from a CSV file on your computer:'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»ä½ çš„ç”µè„‘ä¸Šçš„ CSV æ–‡ä»¶åŠ è½½ï¼š
- en: '[PRE37]'
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE37]'
- en: When reading a table from CSV, Pyret treats every cell as containing a string,
    even if the cell data appears to be numeric. Thus, Pyret does not report an error
    around the combination of `three` and numbers in the `"Num Tickets"` column. The
    inconsistency would resurface, however, if we try to use the column data assuming
    that they are all strings of numerals. If we notice this problem before loading
    our data, we should fix it before we proceed.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä» CSV è¯»å–è¡¨æ ¼æ—¶ï¼ŒPyret å°†æ¯ä¸ªå•å…ƒæ ¼è§†ä¸ºåŒ…å«å­—ç¬¦ä¸²ï¼Œå³ä½¿å•å…ƒæ ¼æ•°æ®çœ‹èµ·æ¥æ˜¯æ•°å­—ã€‚å› æ­¤ï¼ŒPyret ä¸ä¼šåœ¨ `"Num Tickets"`
    åˆ—çš„ `three` å’Œæ•°å­—ç»„åˆå‘¨å›´æŠ¥å‘Šé”™è¯¯ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾è¿™äº›æ•°æ®éƒ½æ˜¯æ•°å­—å­—ç¬¦ä¸²å¹¶å°è¯•ä½¿ç”¨åˆ—æ•°æ®ï¼Œè¿™ç§ä¸ä¸€è‡´æ€§å°±ä¼šå†æ¬¡å‡ºç°ã€‚å¦‚æœæˆ‘ä»¬åœ¨æˆ‘ä»¬åŠ è½½æ•°æ®ä¹‹å‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ç»§ç»­ä¹‹å‰ä¿®å¤å®ƒã€‚
- en: 4.2.1.1.3Â Dealing with Columns with Multiple Types of Data[ğŸ”—](#(part._cols-multiple-types-data)
    "Link to here")
  id: totrans-448
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.1.3 å¤„ç†å…·æœ‰å¤šç§æ•°æ®ç±»å‹çš„åˆ—[ğŸ”—](#(part._cols-multiple-types-data) "é“¾æ¥è‡³æ­¤")
- en: Well-formed data should not mix types of data within a single column. In some
    situations, we might be able to write small programs to correct these inconsistencies.
    For example, a program could help us remove data that are inconsistent with the
    expected column type. However, such an approach should only be used after careful
    study of the data to make sure we arenâ€™t throwing out useful information that
    was simply entered incorrectly.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æ„è‰¯å¥½çš„æ•°æ®ä¸åº”åœ¨å•ä¸ªåˆ—ä¸­æ··åˆæ•°æ®ç±»å‹ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿç¼–å†™å°ç¨‹åºæ¥çº æ­£è¿™äº›ä¸ä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œç¨‹åºå¯ä»¥å¸®åŠ©æˆ‘ä»¬åˆ é™¤ä¸é¢„æœŸåˆ—ç±»å‹ä¸ä¸€è‡´çš„æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•åªèƒ½åœ¨ä»”ç»†ç ”ç©¶æ•°æ®åä½¿ç”¨ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šä¸¢å¼ƒç”±äºè¾“å…¥é”™è¯¯è€Œä¸¢å¤±çš„æœ‰ç”¨ä¿¡æ¯ã€‚
- en: Due to the need for care in dealing with such issues, we instead recommend fixing
    this sort of error in the source file before loading the data into Pyret (or any
    other programming or analysis tool).
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ­¤ç±»é—®é¢˜éœ€è¦è°¨æ…ï¼Œæˆ‘ä»¬å»ºè®®åœ¨å°†æ•°æ®åŠ è½½åˆ° Pyretï¼ˆæˆ–ä»»ä½•å…¶ä»–ç¼–ç¨‹æˆ–åˆ†æå·¥å…·ï¼‰ä¹‹å‰ï¼Œåœ¨æºæ–‡ä»¶ä¸­ä¿®å¤æ­¤ç±»é”™è¯¯ã€‚
- en: How to manage revisions like this is itself an interesting data-management problem.
    You might have received the data from another tool, or imported it from another
    sheet that contained the error. Someone else might provide updates to the data
    that you need to track as well. If you got the data from someone else, it often
    makes sense for you to make a copy of the source data and clean up the copy so
    you still have access to the original if needed.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç®¡ç†è¿™ç±»ä¿®è®¢æœ¬èº«å°±æ˜¯ä¸€ç§æœ‰è¶£çš„æ•°æ®ç®¡ç†é—®é¢˜ã€‚ä½ å¯èƒ½ä»å¦ä¸€ä¸ªå·¥å…·æ¥æ”¶åˆ°äº†æ•°æ®ï¼Œæˆ–è€…ä»åŒ…å«é”™è¯¯çš„å¦ä¸€ä¸ªå·¥ä½œè¡¨ä¸­å¯¼å…¥å®ƒã€‚å…¶ä»–äººå¯èƒ½ä¹Ÿä¼šæä¾›ä½ éœ€è¦è·Ÿè¸ªçš„æ•°æ®æ›´æ–°ã€‚å¦‚æœä½ ä»åˆ«äººé‚£é‡Œè·å¾—äº†æ•°æ®ï¼Œé‚£ä¹ˆåˆ¶ä½œæºæ•°æ®çš„å‰¯æœ¬å¹¶æ¸…ç†å‰¯æœ¬ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶ä»ç„¶å¯ä»¥è®¿é—®åŸå§‹æ•°æ®ï¼Œé€šå¸¸æ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: The source data files for this lesson also contain clean versions to use in
    the rest of this chapter.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è¯¾çš„æºæ•°æ®æ–‡ä»¶è¿˜åŒ…å«ç”¨äºæœ¬ç« å…¶ä½™éƒ¨åˆ†çš„æ¸…æ´ç‰ˆæœ¬ã€‚
- en: If you are using the Google Sheet, look for the separate worksheet/tab named
    `"Data"` in which the `three` has been replaced with a number. If we use `"Data"`
    instead of `"Orig Data"` in the above `load-spreadsheet` command, the event table
    loads into Pyret.
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ Google è¡¨æ ¼ï¼Œè¯·æŸ¥æ‰¾åä¸º `"Data"` çš„å•ç‹¬å·¥ä½œè¡¨/æ ‡ç­¾é¡µï¼Œå…¶ä¸­ `three` å·²è¢«æ›¿æ¢ä¸ºæ•°å­—ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ `"Data"`
    è€Œä¸æ˜¯ `"Orig Data"` åœ¨ä¸Šé¢çš„ `load-spreadsheet` å‘½ä»¤ä¸­ï¼Œäº‹ä»¶è¡¨å°±ä¼šåŠ è½½åˆ° Pyret ä¸­ã€‚
- en: If you are using the CSV files in VSCode, modify the file path to end with `"events-f25.csv"`
    instead of `"events-orig-f25.csv"`.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ VSCode ä¸­çš„ CSV æ–‡ä»¶ï¼Œè¯·å°†æ–‡ä»¶è·¯å¾„ä¿®æ”¹ä¸ºä»¥ `"events-f25.csv"` ç»“å°¾ï¼Œè€Œä¸æ˜¯ `"events-orig-f25.csv"`ã€‚
- en: 4.2.1.2Â Dealing with Missing Entries[ğŸ”—](#(part._missing-data) "Link to here")
  id: totrans-455
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.2 å¤„ç†ç¼ºå¤±æ¡ç›®[ğŸ”—](#(part._missing-data) "é“¾æ¥è‡³æ­¤")
- en: When we create tables manually in Pyret, we have to provide a value for each
    cell â€“ thereâ€™s no way to "skip" a cell. When we create tables in a spreadsheet
    program (such as Excel, Google Sheets, or something similar), it is possible to
    leave cells completely empty. What happens when we load a table with empty cells
    into Pyret?
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åœ¨ Pyret ä¸­æ‰‹åŠ¨åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»ä¸ºæ¯ä¸ªå•å…ƒæ ¼æä¾›ä¸€ä¸ªå€¼â€”â€”æ²¡æœ‰â€œè·³è¿‡â€å•å…ƒæ ¼çš„æ–¹æ³•ã€‚å½“æˆ‘ä»¬åœ¨ä¸€ä¸ªç”µå­è¡¨æ ¼ç¨‹åºï¼ˆå¦‚ Excelã€Google
    Sheets æˆ–ç±»ä¼¼ç¨‹åºï¼‰ä¸­åˆ›å»ºè¡¨æ ¼æ—¶ï¼Œå¯ä»¥å®Œå…¨ç•™ç©ºå•å…ƒæ ¼ã€‚å½“æˆ‘ä»¬æŠŠåŒ…å«ç©ºå•å…ƒæ ¼çš„è¡¨æ ¼åŠ è½½åˆ° Pyret ä¸­ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
- en: The original data file has blanks in the `discount` column. After we load it
    into Pyret, we see something interesting in that column (though what it is will
    differ depending on whether youâ€™re reading from Google Sheets or CSV files).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹æ•°æ®æ–‡ä»¶åœ¨ `discount` åˆ—ä¸­æœ‰ç©ºæ ¼ã€‚åœ¨æˆ‘ä»¬å°†å…¶åŠ è½½åˆ° Pyret åï¼Œæˆ‘ä»¬ä¼šåœ¨è¯¥åˆ—ä¸­çœ‹åˆ°ä¸€äº›æœ‰è¶£çš„ç°è±¡ï¼ˆå°½ç®¡å…·ä½“å†…å®¹å–å†³äºæ‚¨æ˜¯ä» Google
    Sheets è¿˜æ˜¯ CSV æ–‡ä»¶ä¸­è¯»å–ï¼‰ã€‚
- en: 'If you are using Google Sheets and CPO, load the table as follows:'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ Google Sheets å’Œ CPOï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE38]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`event-data` will be the following table:'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/79459f101e303b7d4194f62bd697807a.png)'
- en: Note that those cells that had discount codes in them now have an odd-looking
    notation like `some("student")`, while some of the cells that were empty contain
    `none`, but `none` isnâ€™t a string. Whatâ€™s going on?
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œé‚£äº›åŒ…å«æŠ˜æ‰£ä»£ç çš„å•å…ƒæ ¼ç°åœ¨æœ‰ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆå¥‡æ€ªçš„ç¬¦å· `some("student")`ï¼Œè€Œä¸€äº›åŸæœ¬ä¸ºç©ºçš„å•å…ƒæ ¼åŒ…å« `none`ï¼Œä½† `none`
    ä¸æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ
- en: Pyret supports a special type of data called option. As the name suggests, option
    is for data that may or may not be present. `none` is the value that stands for
    "the data are missing". If a datum are present, it appears wrapped in `some`.
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Pyret æ”¯æŒä¸€ç§ç‰¹æ®Šçš„æ•°æ®ç±»å‹ï¼Œç§°ä¸ºé€‰é¡¹ã€‚æ­£å¦‚å…¶åæ‰€ç¤ºï¼Œé€‰é¡¹ç”¨äºå¯èƒ½å­˜åœ¨æˆ–ä¸å­˜åœ¨çš„æ•°æ®ã€‚`none` æ˜¯è¡¨ç¤ºâ€œæ•°æ®ç¼ºå¤±â€çš„å€¼ã€‚å¦‚æœæ•°æ®å­˜åœ¨ï¼Œå®ƒå°†åŒ…è£¹åœ¨
    `some` ä¸­ã€‚
- en: Look also at the last two rows (for Zander and Shweta) â€“ they also appear empty
    when seen in Google Sheets, but Pyret has loaded them as strings of spaces (e.g.,
    `some(" ")`). What does that mean? It means that those cells werenâ€™t actually
    empty in the Google Sheet, but instead contained several spaces.
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¹Ÿçœ‹çœ‹æœ€åä¸¤è¡Œï¼ˆZander å’Œ Shweta çš„è¡Œï¼‰â€”â€”åœ¨ Google Sheets ä¸­çœ‹èµ·æ¥ä¹Ÿæ˜¯ç©ºçš„ï¼Œä½† Pyret å°†å®ƒä»¬åŠ è½½ä¸ºç©ºæ ¼å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼Œ`some("
    ")`ï¼‰ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™æ„å‘³ç€é‚£äº›å•å…ƒæ ¼åœ¨ Google Sheets ä¸­å®é™…ä¸Šå¹¶ä¸æ˜¯ç©ºçš„ï¼Œè€Œæ˜¯åŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚
- en: Do Now!
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿›è¡Œç»ƒä¹ ï¼
- en: ''
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Look at the `discount` value for Ernieâ€™s row: it reads `some("none")`. What
    does this mean? How is this different from `none` (as in Samâ€™s row)?'
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: çœ‹çœ‹ Ernie è¡Œçš„ `discount` å€¼ï¼šå®ƒè¯»ä½œ `some("none")`ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™ä¸ Sam è¡Œä¸­çš„ `none`ï¼ˆå¦‚ä¸Šæ‰€è¿°ï¼‰æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ
- en: 'If you are using CSV files and VSCode, load the table as follows:'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨ä½¿ç”¨ CSV æ–‡ä»¶å’Œ VSCodeï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½è¡¨æ ¼ï¼š
- en: '[PRE39]'
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`event-data` will be the following table:'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`event-data` å°†æ˜¯ä»¥ä¸‹è¡¨æ ¼ï¼š'
- en: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/f2819291a355f419b87d02cbf54b33aa.png)'
- en: Note that cells that had no data have either empty strings (`""`) or strings
    with spaces (`" "`). What caused the difference? In the cells where the string
    has spaces, the cell in the original CSV appeared to be empty, but it actually
    contained some spaces. When reading in the CSV, Pyret retains the actual content
    in the cell. The empty string is only used if the CSV cell actually had no data
    at all.
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæ²¡æœ‰æ•°æ®çš„å•å…ƒæ ¼è¦ä¹ˆæ˜¯ç©ºå­—ç¬¦ä¸² (`""`)ï¼Œè¦ä¹ˆæ˜¯åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸² (`" "`)ã€‚æ˜¯ä»€ä¹ˆå¯¼è‡´äº†è¿™ç§å·®å¼‚ï¼Ÿåœ¨åŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ä¸­ï¼ŒåŸå§‹ CSV ä¸­çš„å•å…ƒæ ¼çœ‹èµ·æ¥æ˜¯ç©ºçš„ï¼Œä½†å®é™…ä¸ŠåŒ…å«äº†ä¸€äº›ç©ºæ ¼ã€‚åœ¨è¯»å–
    CSV æ—¶ï¼ŒPyret ä¿ç•™å•å…ƒæ ¼çš„å®é™…å†…å®¹ã€‚ç©ºå­—ç¬¦ä¸²ä»…åœ¨ CSV å•å…ƒæ ¼å®é™…ä¸Šæ²¡æœ‰ä»»ä½•æ•°æ®æ—¶ä½¿ç”¨ã€‚
- en: 'Whether you are using Google Sheets or CSV files, the right way to address
    missing data (and conversion in general) is to indicate how to handle each column.
    This guarantees that the data will be as you expect after you read them in. We
    do this with an additional aspect of `load-table` called sanitizers. Hereâ€™s how
    we modify the code:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ‚¨ä½¿ç”¨ Google Sheets è¿˜æ˜¯ CSV æ–‡ä»¶ï¼Œå¤„ç†ç¼ºå¤±æ•°æ®ï¼ˆä»¥åŠä¸€èˆ¬è½¬æ¢ï¼‰çš„æ­£ç¡®æ–¹æ³•æ˜¯æŒ‡ç¤ºå¦‚ä½•å¤„ç†æ¯ä¸€åˆ—ã€‚è¿™ä¿è¯äº†æ‚¨è¯»å–æ•°æ®åï¼Œæ•°æ®å°†å¦‚æ‚¨é¢„æœŸçš„é‚£æ ·ã€‚æˆ‘ä»¬é€šè¿‡
    `load-table` çš„é™„åŠ åŠŸèƒ½â€”â€”æ¸…ç†å™¨æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ä»£ç ä¿®æ”¹æ–¹å¼ï¼š
- en: '[PRE40]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Each of the `sanitize` lines tells Pyret what to do in the case of missing data
    in the respective column. `string-sanitizer` says to load missing data as an empty
    string (`""`). Sanitizers also handle simple data conversions. If the `string-sanitizer`
    were applied to a column with a number (like `3`), the sanitizer would convert
    that number to a string (like `"3"`). Similarly, applying `num-sanitizer` to a
    column would convert number-strings (like `"3"`) to an actual number (`3`).
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ª`sanitize`è¡Œå‘Šè¯‰ Pyret åœ¨ç›¸åº”åˆ—ç¼ºå¤±æ•°æ®æ—¶åº”è¯¥åšä»€ä¹ˆã€‚`string-sanitizer`è¡¨ç¤ºå°†ç¼ºå¤±æ•°æ®åŠ è½½ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆ`""`ï¼‰ã€‚æ¸…ç†å™¨è¿˜å¤„ç†ç®€å•çš„æ•°æ®è½¬æ¢ã€‚å¦‚æœ`string-sanitizer`åº”ç”¨äºåŒ…å«æ•°å­—ï¼ˆå¦‚`3`ï¼‰çš„åˆ—ï¼Œæ¸…ç†å™¨ä¼šå°†è¯¥æ•°å­—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚`"3"`ï¼‰ã€‚ç±»ä¼¼åœ°ï¼Œå°†`num-sanitizer`åº”ç”¨äºåˆ—ä¼šå°†æ•°å­—å­—ç¬¦ä¸²ï¼ˆå¦‚`"3"`ï¼‰è½¬æ¢ä¸ºå®é™…æ•°å­—ï¼ˆ`3`ï¼‰ã€‚
- en: 'Using sanitizers, the `event-data` table reads in as follows:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¸…ç†å™¨ï¼Œ`event-data`è¡¨æ ¼çš„è¯»å–æ–¹å¼å¦‚ä¸‹ï¼š
- en: '![](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
  id: totrans-477
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/042711398d7fbca215e22fa61f3a6c84.png)'
- en: Do Now!
  id: totrans-478
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-479
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you notice that we sanitized the `zip` column with `string-sanitizer` instead
    of `num-sanitizer`? Arenâ€™t zip codes numbers? Try the above code with each of
    `string-sanitizer` and `num-sanitizer` for `code` and see if you can spot the
    difference.
  id: totrans-480
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ æ³¨æ„åˆ°æˆ‘ä»¬æ²¡æœ‰ç”¨`num-sanitizer`è€Œæ˜¯ç”¨`string-sanitizer`æ¥æ¸…ç†`zip`åˆ—äº†å—ï¼Ÿé‚®ç¼–ä¸æ˜¯æ•°å­—å—ï¼Ÿå°è¯•ç”¨`string-sanitizer`å’Œ`num-sanitizer`åˆ†åˆ«å¯¹`code`è¿›è¡Œä¸Šè¿°ä»£ç çš„æµ‹è¯•ï¼Œçœ‹çœ‹ä½ æ˜¯å¦èƒ½å‘ç°å·®å¼‚ã€‚
- en: Zip codes are a terrific example of data that are written with digits, but arenâ€™t
    meant to be used numerically. What does that mean? If data are meant to be used
    numerically, then standard arithmetic operations should make sense on them. What
    sense would it make to multiply a zip code by 3, for example? None. Similarly,
    we donâ€™t write numbers with leading zeros, but zip codes can meaningfully start
    with 0\. Treating zip codes as strings treats them as identifiers more than numbers.
    Weâ€™ll return to this point later in this chapter ([Visualizations and Plots](#%28part._visualizing-tables%29)).
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: é‚®ç¼–æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œæ•°æ®æ˜¯ç”¨æ•°å­—å†™çš„ï¼Œä½†å¹¶ä¸æ‰“ç®—ç”¨æ¥è¿›è¡Œæ•°å€¼è¿ç®—ã€‚è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿå¦‚æœæ•°æ®æ‰“ç®—ç”¨æ¥è¿›è¡Œæ•°å€¼è¿ç®—ï¼Œé‚£ä¹ˆæ ‡å‡†ç®—æœ¯è¿ç®—åº”è¯¥åœ¨è¿™äº›æ•°æ®ä¸Šæ˜¯æœ‰æ„ä¹‰çš„ã€‚ä¾‹å¦‚ï¼Œå°†é‚®ç¼–ä¹˜ä»¥3æœ‰ä»€ä¹ˆæ„ä¹‰å‘¢ï¼Ÿæ²¡æœ‰æ„ä¹‰ã€‚åŒæ ·ï¼Œæˆ‘ä»¬ä¸ä¼šç”¨å‰å¯¼é›¶æ¥å†™æ•°å­—ï¼Œä½†é‚®ç¼–å¯ä»¥æœ‰æ„ä¹‰åœ°ä»¥0å¼€å¤´ã€‚å°†é‚®ç¼–è§†ä¸ºå­—ç¬¦ä¸²å°†å®ƒä»¬è§†ä¸ºæ ‡è¯†ç¬¦è€Œä¸æ˜¯æ•°å­—ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„åé¢å›åˆ°è¿™ä¸ªè§‚ç‚¹ï¼ˆ[å¯è§†åŒ–ä¸å›¾è¡¨](#%28part._visualizing-tables%29)ï¼‰ã€‚
- en: 'A note on default values: Unlike `string-sanitizer`, `num-sanitizer` does NOT
    convert blank cells to a default value (such as 0). There is no single default
    value that would make sense for all the ways in which numbers are used: while
    `0` would be a plausible default for missing numbers of tickets, it would not
    be a meaningful default for a missing age. It could create outright errors if
    used as the default for a missing exam grade (which was later used to compute
    a course grade). As a result, `num-sanitizer` reports an error if the data (or
    lack thereof) in a cell cannot be reliably interpreted as a number. Pyret allows
    you to write your own custom sanitizers (e.g., one that would default missing
    numbers to 0). If you want to do this, see the Pyret documentation for details.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºé»˜è®¤å€¼çš„ä¸€ä¸ªè¯´æ˜ï¼šä¸`string-sanitizer`ä¸åŒï¼Œ`num-sanitizer`ä¸ä¼šå°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºé»˜è®¤å€¼ï¼ˆä¾‹å¦‚0ï¼‰ã€‚æ²¡æœ‰å•ä¸€çš„é»˜è®¤å€¼å¯¹æ‰€æœ‰ä½¿ç”¨æ•°å­—çš„æ–¹å¼éƒ½æ˜¯æœ‰æ„ä¹‰çš„ï¼šè™½ç„¶`0`å¯èƒ½æ˜¯ç¼ºå¤±ç¥¨æ•°çš„åˆç†é»˜è®¤å€¼ï¼Œä½†å®ƒå¯¹ç¼ºå¤±å¹´é¾„æ¥è¯´å¹¶æ²¡æœ‰æ„ä¹‰ã€‚å¦‚æœç”¨ä½œç¼ºå¤±è€ƒè¯•æˆç»©çš„é»˜è®¤å€¼ï¼ˆåæ¥ç”¨äºè®¡ç®—è¯¾ç¨‹æˆç»©ï¼‰ï¼Œå¯èƒ½ä¼šäº§ç”Ÿæ˜æ˜¾çš„é”™è¯¯ã€‚å› æ­¤ï¼Œå¦‚æœå•å…ƒæ ¼ä¸­çš„æ•°æ®ï¼ˆæˆ–å…¶ç¼ºå¤±ï¼‰æ— æ³•å¯é åœ°è§£é‡Šä¸ºæ•°å­—ï¼Œ`num-sanitizer`ä¼šæŠ¥å‘Šé”™è¯¯ã€‚Pyret
    å…è®¸ä½ ç¼–å†™è‡ªå·±çš„è‡ªå®šä¹‰æ¸…ç†å™¨ï¼ˆä¾‹å¦‚ï¼Œå°†ç¼ºå¤±æ•°å­—é»˜è®¤ä¸º0çš„æ¸…ç†å™¨ï¼‰ã€‚å¦‚æœä½ æƒ³è¿™æ ·åšï¼Œè¯·å‚é˜… Pyret æ–‡æ¡£ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚
- en: The lack of meaningful default values is one reason why Pyret doesnâ€™t leverage
    type annotations on columns to automatically sanitize imported data. Automation
    takes control away from the programmer; sanitizers provide the programmer with
    control over default values, as well as the option to use (or not) sanitizers
    at all.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºä¹æœ‰æ„ä¹‰çš„é»˜è®¤å€¼æ˜¯ Pyret ä¸åˆ©ç”¨åˆ—ä¸Šçš„ç±»å‹æ³¨è§£è‡ªåŠ¨æ¸…ç†å¯¼å…¥æ•°æ®çš„ä¸€ä¸ªåŸå› ã€‚è‡ªåŠ¨åŒ–å°†æ§åˆ¶æƒä»ç¨‹åºå‘˜æ‰‹ä¸­å¤ºèµ°ï¼›æ¸…ç†å™¨ä¸ºç¨‹åºå‘˜æä¾›äº†å¯¹é»˜è®¤å€¼çš„æ§åˆ¶æƒï¼Œä»¥åŠé€‰æ‹©ä½¿ç”¨ï¼ˆæˆ–ä¸ä½¿ç”¨ï¼‰æ¸…ç†å™¨çš„é€‰é¡¹ã€‚
- en: 'Rule of thumb: when you load a table, use a sanitizer to guard against errors
    in case the original sheet is missing data in some cells.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: ç»éªŒæ³•åˆ™ï¼šå½“ä½ åŠ è½½ä¸€ä¸ªè¡¨æ ¼æ—¶ï¼Œä½¿ç”¨æ¸…ç†å™¨æ¥é˜²æ­¢åŸå§‹è¡¨æ ¼ä¸­æŸäº›å•å…ƒæ ¼ç¼ºå¤±æ•°æ®æ—¶çš„é”™è¯¯ã€‚
- en: 4.2.1.3Â Normalizing Data[ğŸ”—](#(part._.Normalizing_.Data) "Link to here")
  id: totrans-485
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.3 æ•°æ®æ ‡å‡†åŒ–[ğŸ”—](#(part._.Normalizing_.Data) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Next, letâ€™s look at the `"Discount Code"` column. Our goal is to be able to
    accurately answer the question "How many orders were placing under each discount
    code". We would like to have the answer summarized in a table, where one column
    names the discount code and another gives a count of the rows that used that code.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹`"Discount Code"`åˆ—ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èƒ½å¤Ÿå‡†ç¡®å›ç­”â€œæœ‰å¤šå°‘è®¢å•æ˜¯åœ¨æ¯ä¸ªæŠ˜æ‰£ä»£ç ä¸‹è¿›è¡Œçš„â€ã€‚æˆ‘ä»¬å¸Œæœ›ç­”æ¡ˆä»¥è¡¨æ ¼å½¢å¼æ€»ç»“ï¼Œå…¶ä¸­ä¸€åˆ—å‘½åæŠ˜æ‰£ä»£ç ï¼Œå¦ä¸€åˆ—ç»™å‡ºä½¿ç”¨è¯¥ä»£ç çš„è¡Œæ•°ã€‚
- en: Do Now!
  id: totrans-487
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-488
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Examples first! What table do we want from this computation on the fragment
    of table that we gave you?
  id: totrans-489
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹å…ˆè¡Œï¼æˆ‘ä»¬å¸Œæœ›ä»è¿™ä¸ªè®¡ç®—ä¸­è·å–å“ªä¸ªè¡¨æ ¼ï¼Œé’ˆå¯¹æˆ‘ä»¬ç»™å‡ºçš„è¡¨æ ¼ç‰‡æ®µï¼Ÿ
- en: 'You canâ€™t answer this question without making some decisions about how to standardize
    the names and how to handle missing values. The term normalization refers to making
    sure that a collection of data (such as a column) shares structure and formatting.
    Our solution will aim to produce the following table, but you could have made
    different choices from what we have here:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸å†³å®šå¦‚ä½•æ ‡å‡†åŒ–åç§°ä»¥åŠå¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Œä½ å°±æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚æœ¯è¯­æ ‡å‡†åŒ–æŒ‡çš„æ˜¯ç¡®ä¿æ•°æ®é›†åˆï¼ˆå¦‚åˆ—ï¼‰å…·æœ‰ç»“æ„å’Œæ ¼å¼ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå°†æ—¨åœ¨ç”Ÿæˆä»¥ä¸‹è¡¨æ ¼ï¼Œä½†ä½ å¯èƒ½åšå‡ºäº†ä¸æˆ‘ä»¬è¿™é‡Œä¸åŒçš„é€‰æ‹©ï¼š
- en: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
  id: totrans-491
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67e61db173feac2c615c0772e8bad093.png)'
- en: How do we get to this table? How do we figure this out if we arenâ€™t sure?
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å¾—åˆ°è¿™ä¸ªè¡¨æ ¼ï¼Ÿå¦‚æœæˆ‘ä»¬ä¸ç¡®å®šï¼Œæˆ‘ä»¬å¦‚ä½•æ‰¾å‡ºè¿™ä¸ªï¼Ÿ
- en: 'Start by looking in the documentation for any library functions that might
    help with this task. In the [documentation for Pyretâ€™s `dcic2024` context](https://hackmd.io/@cs111/table),
    we find:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œåœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾å¯èƒ½æœ‰åŠ©äºæ­¤ä»»åŠ¡çš„ä»»ä½•åº“å‡½æ•°ã€‚åœ¨[Pyretçš„`dcic2024`ä¸Šä¸‹æ–‡æ–‡æ¡£](https://hackmd.io/@cs111/table)ä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š
- en: '[PRE41]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This sounds useful, as long as every column has a value in the `"Discount code"`
    column, and that the only values in the column are those in our desired output
    table. What do we need to do to achieve this?
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¬èµ·æ¥å¾ˆæœ‰ç”¨ï¼Œåªè¦æ¯ä¸ªåˆ—åœ¨`"Discount code"`åˆ—ä¸­éƒ½æœ‰å€¼ï¼Œå¹¶ä¸”è¯¥åˆ—ä¸­åªæœ‰æˆ‘ä»¬æœŸæœ›è¾“å‡ºè¡¨ä¸­çš„å€¼ã€‚æˆ‘ä»¬éœ€è¦åšä»€ä¹ˆæ‰èƒ½å®ç°è¿™ä¸€ç‚¹ï¼Ÿ
- en: Get `"none"` to appear in every cell that currently lacks a value
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¯ä¸ªå½“å‰æ²¡æœ‰å€¼çš„å•å…ƒæ ¼æ˜¾ç¤ºä¸º`"none"`
- en: Convert all the codes that arenâ€™t `"none"` to upper case
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰ä¸æ˜¯`"none"`çš„ä»£ç è½¬æ¢ä¸ºå¤§å†™
- en: 'Fortunately, these tasks align with functions weâ€™ve already seen how to use:
    each one is an example of a column transformation, where the second one involves
    the upper-case conversion functions from the `String` library.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œè¿™äº›ä»»åŠ¡ä¸æˆ‘ä»¬å·²ç»å­¦ä¹ å¦‚ä½•ä½¿ç”¨çš„å‡½æ•°ç›¸ä¸€è‡´ï¼šæ¯ä¸ªéƒ½æ˜¯ä¸€ä¸ªåˆ—è½¬æ¢çš„ä¾‹å­ï¼Œå…¶ä¸­ç¬¬äºŒä¸ªæ¶‰åŠåˆ°`String`åº“ä¸­çš„å¤§å†™è½¬æ¢å‡½æ•°ã€‚
- en: 'We can capture these together in a function that takes in and produces a string:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªå‡½æ•°ä¸­æ•è·è¿™äº›ï¼Œè¯¥å‡½æ•°æ¥å—å¹¶ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼š
- en: '[PRE42]uppercase all strings other than none,'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE42]å°†é™¤äº†`none`ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE43]
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å«`none`[PRE43]
- en: Do Now!
  id: totrans-502
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-503
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Assess the examples included with `cell-to-discount-code`. Is this a good set
    of examples, or are any key ones missing?
  id: totrans-504
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯„ä¼°åŒ…å«åœ¨`cell-to-discount-code`ä¸­çš„ç¤ºä¾‹ã€‚è¿™æ˜¯ä¸€ç»„å¥½çš„ç¤ºä¾‹ï¼Œè¿˜æ˜¯æœ‰ä»»ä½•å…³é”®ç¤ºä¾‹ç¼ºå¤±ï¼Ÿ
- en: 'The current examples consider different capitalizations for `"birthday"`, but
    not for `"none"`. Unless you are confident that the data-gathering process canâ€™t
    produce different capitalizations of `"none"`, we should include that as well:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰ç¤ºä¾‹è€ƒè™‘äº†`"birthday"`çš„ä¸åŒå¤§å°å†™ï¼Œä½†æ²¡æœ‰è€ƒè™‘`"none"`ã€‚é™¤éä½ ç¡®ä¿¡æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸ä¼šäº§ç”Ÿ`"none"`çš„ä¸åŒå¤§å°å†™ï¼Œå¦åˆ™æˆ‘ä»¬åº”è¯¥å°†å…¶ä¹ŸåŒ…æ‹¬åœ¨å†…ï¼š
- en: '[PRE44]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Oops! If we add this example to our `where` block and run the code, Pyret reports
    that this example fails.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: å“å‘€ï¼å¦‚æœæˆ‘ä»¬å°†æ­¤ç¤ºä¾‹æ·»åŠ åˆ°æˆ‘ä»¬çš„`where`å—ä¸­å¹¶è¿è¡Œä»£ç ï¼ŒPyretä¼šæŠ¥å‘Šæ­¤ç¤ºä¾‹å¤±è´¥ã€‚
- en: Do Now!
  id: totrans-508
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-509
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why did the `"NoNe"` case fail?
  id: totrans-510
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆ`"NoNe"`æƒ…å†µå¤±è´¥äº†ï¼Ÿ
- en: Since we check for the string `"none"` in the `if` expression, we need to normalize
    the input to match what our `if` expression expects. Hereâ€™s the modified code,
    on which all the examples pass.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬åœ¨`if`è¡¨è¾¾å¼ä¸­æ£€æŸ¥å­—ç¬¦ä¸²`"none"`ï¼Œæˆ‘ä»¬éœ€è¦å°†è¾“å…¥æ ‡å‡†åŒ–ä»¥åŒ¹é…æˆ‘ä»¬çš„`if`è¡¨è¾¾å¼æ‰€æœŸæœ›çš„æ ¼å¼ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹åçš„ä»£ç ï¼Œæ‰€æœ‰ç¤ºä¾‹éƒ½é€šè¿‡äº†æµ‹è¯•ã€‚
- en: '[PRE45]uppercase all strings other than none,'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE45]å°†é™¤äº†`none`ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™ï¼Œ'
- en: convert blank cells to contain none[PRE46]
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†ç©ºç™½å•å…ƒæ ¼è½¬æ¢ä¸ºåŒ…å«`none`[PRE46]
- en: 'Using this function with `transform-column` yields a table with a standardized
    formatting for discount codes (reminder that you need to be working in the `dcic2024`
    context for this to work):'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ­¤å‡½æ•°ä¸`transform-column`ä¸€èµ·ä½¿ç”¨ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªå…·æœ‰æ ‡å‡†åŒ–æ ¼å¼çš„æŠ˜æ‰£ä»£ç è¡¨æ ¼ï¼ˆæé†’ï¼šæ‚¨éœ€è¦åœ¨å·¥ä½œåœ¨`dcic2024`ä¸Šä¸‹æ–‡ä¸­æ‰èƒ½ä½¿æ­¤åŠŸèƒ½ç”Ÿæ•ˆï¼‰ï¼š
- en: '[PRE47]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Exercise
  id: totrans-516
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-517
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Try it yourself: normalize the `"delivery"` column so that all `"yes"` values
    are converted to `"email"`.'
  id: totrans-518
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°è¯•ä¸€ä¸‹ï¼šå°†`"delivery"`åˆ—æ ‡å‡†åŒ–ï¼Œä»¥ä¾¿æ‰€æœ‰`"yes"`å€¼éƒ½è½¬æ¢ä¸º`"email"`ã€‚
- en: 'Now that weâ€™ve cleaned up the codes, we can proceed to using the `"count"`
    function to extract our summary table:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…ç†äº†ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨`"count"`å‡½æ•°æ¥æå–æˆ‘ä»¬çš„æ‘˜è¦è¡¨ï¼š
- en: '[PRE48]'
  id: totrans-520
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This produces the following table:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿä»¥ä¸‹è¡¨æ ¼ï¼š
- en: '![](../Images/2e1e61875a93a7de92cde5c995392660.png)'
  id: totrans-522
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/2e1e61875a93a7de92cde5c995392660.png)'
- en: Do Now!
  id: totrans-523
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-524
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Whatâ€™s with that first row, with the discount code `" "`? Where might that have
    come from?
  id: totrans-525
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é‚£ç¬¬ä¸€è¡Œï¼Œå¸¦æœ‰æŠ˜æ‰£ä»£ç `" "`çš„è¡Œæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿå®ƒå¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿ
- en: Maybe you didnâ€™t notice this before (or wouldnâ€™t have noticed it within a larger
    table), but there must have been a cell of the source data with a string of blanks,
    rather than missing content. How do we approach normalization to avoid missing
    cases like this?
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½ä½ ä¹‹å‰æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸€ç‚¹ï¼ˆæˆ–è€…åœ¨æ›´å¤§çš„è¡¨æ ¼ä¸­ä¸ä¼šæ³¨æ„åˆ°ï¼‰ï¼Œä½†æºæ•°æ®ä¸­è‚¯å®šæœ‰ä¸€ä¸ªå•å…ƒæ ¼åŒ…å«ä¸€ä¸²ç©ºæ ¼ï¼Œè€Œä¸æ˜¯ç¼ºå¤±çš„å†…å®¹ã€‚æˆ‘ä»¬å¦‚ä½•å¤„ç†è¿™ç§ç¼ºå¤±æƒ…å†µä»¥é¿å…ç±»ä¼¼çš„é—®é¢˜ï¼Ÿ
- en: 4.2.1.4Â Normalization, Systematically[ğŸ”—](#(part._.Normalization__.Systematically)
    "Link to here")
  id: totrans-527
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.4Â å½’ä¸€åŒ–ï¼Œç³»ç»ŸåŒ–[ğŸ”—](#(part._.Normalization__.Systematically) "é“¾æ¥åˆ°æ­¤å¤„")
- en: As the previous example showed, we need a way to think through potential normalizations
    systematically. Our initial discussion of writing examples gives an idea of how
    to do this. One of the guidelines there says to think about the domain of the
    inputs, and ways that inputs might vary. If we apply that in the context of loaded
    datasets, we should think about how the original data were collected.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰ä¾‹æ‰€ç¤ºï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§ç³»ç»Ÿæ€§åœ°æ€è€ƒæ½œåœ¨å½’ä¸€åŒ–çš„æ–¹æ³•ã€‚æˆ‘ä»¬å…³äºç¼–å†™ç¤ºä¾‹çš„åˆæ­¥è®¨è®ºç»™å‡ºäº†ä¸€ç§å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„æƒ³æ³•ã€‚é‚£é‡Œçš„ä¸€ä¸ªæŒ‡å¯¼åŸåˆ™æ˜¯è€ƒè™‘è¾“å…¥åŸŸä»¥åŠè¾“å…¥å¯èƒ½çš„å˜åŒ–æ–¹å¼ã€‚å¦‚æœæˆ‘ä»¬å°†è¿™ä¸€ç‚¹åº”ç”¨äºåŠ è½½çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘åŸå§‹æ•°æ®æ˜¯å¦‚ä½•æ”¶é›†çš„ã€‚
- en: Do Now!
  id: totrans-529
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-530
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Based on what you know about websites, where might the event code contents come
    from? How might they have been entered? What do these tell you about different
    plausible mistakes in the data?
  id: totrans-531
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ å¯¹ç½‘ç«™çš„äº†è§£ï¼Œäº‹ä»¶ä»£ç å†…å®¹å¯èƒ½æ¥è‡ªå“ªé‡Œï¼Ÿå®ƒä»¬æ˜¯å¦‚ä½•è¢«è¾“å…¥çš„ï¼Ÿè¿™äº›ä¿¡æ¯èƒ½å‘Šè¯‰ä½ å…³äºæ•°æ®ä¸­ä¸åŒå¯èƒ½çš„é”™è¯¯æ˜¯ä»€ä¹ˆï¼Ÿ
- en: 'In this case, for data that came from a web-based form (as we revealed at the
    beginning), the data was likely entered in one of two ways:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯¹äºæ¥è‡ªåŸºäºç½‘ç»œçš„è¡¨å•ï¼ˆå¦‚æˆ‘ä»¬æœ€åˆæ‰€æ­ç¤ºçš„ï¼‰çš„æ•°æ®ï¼Œæ•°æ®å¾ˆå¯èƒ½æ˜¯ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä¹‹ä¸€è¾“å…¥çš„ï¼š
- en: via a drop-down menu
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸‹æ‹‰èœå•
- en: in a text-entry box
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ–‡æœ¬è¾“å…¥æ¡†ä¸­
- en: A drop-down menu automatically normalizes the data, so thatâ€™s not a plausible
    source (this is why you should use drop-downs on forms when you want users to
    select from a fixed collection of options). So letâ€™s assume this is from a text-entry
    box.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹æ‹‰èœå•ä¼šè‡ªåŠ¨å½’ä¸€åŒ–æ•°æ®ï¼Œæ‰€ä»¥è¿™ä¸æ˜¯ä¸€ä¸ªå¯èƒ½çš„æ•°æ®æ¥æºï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“ä½ åœ¨è¡¨å•ä¸Šæƒ³è¦ç”¨æˆ·ä»ä¸€ç»„å›ºå®šçš„é€‰é¡¹ä¸­é€‰æ‹©æ—¶ï¼Œä½ åº”è¯¥ä½¿ç”¨ä¸‹æ‹‰èœå•ï¼‰ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å‡è®¾è¿™æ˜¯æ¥è‡ªæ–‡æœ¬è¾“å…¥æ¡†çš„ã€‚
- en: 'A text-entry box means that any sort of typical human typing error could show
    up in your data: swapped letters, missing letters, leading spaces, capitalization,
    etc. You could also get data where someone just typed the wrong thing (or something
    random, just to see what your form would do).'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æœ¬è¾“å…¥æ¡†æ„å‘³ç€ä»»ä½•å…¸å‹çš„äººç±»æ‰“å­—é”™è¯¯éƒ½å¯èƒ½å‡ºç°åœ¨ä½ çš„æ•°æ®ä¸­ï¼šäº¤æ¢çš„å­—æ¯ï¼Œç¼ºå¤±çš„å­—æ¯ï¼Œå‰å¯¼ç©ºæ ¼ï¼Œå¤§å°å†™ç­‰ã€‚ä½ ä¹Ÿå¯èƒ½å¾—åˆ°ä¸€äº›æ•°æ®ï¼Œå…¶ä¸­æœ‰äººåªæ˜¯è¾“å…¥äº†é”™è¯¯çš„å†…å®¹ï¼ˆæˆ–è€…éšæœºè¾“å…¥ï¼Œçœ‹çœ‹ä½ çš„è¡¨å•ä¼šåšä»€ä¹ˆï¼‰ã€‚
- en: Do Now!
  id: totrans-537
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨å°±åšï¼
- en: ''
  id: totrans-538
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which of swapped letters, missing errors, and random text do you think a program
    can correct for automatically?
  id: totrans-539
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è®¤ä¸ºç¨‹åºå¯ä»¥è‡ªåŠ¨çº æ­£å“ªäº›äº¤æ¢çš„å­—æ¯ã€ç¼ºå¤±é”™è¯¯å’Œéšæœºæ–‡æœ¬ï¼Ÿ
- en: Swapped and missing letters are the sorts of things a spell-checker might be
    able to fix (especially if the program knew all of the valid discount codes).
    Random junk, by definition, is random. There, youâ€™d have to talk to the events
    company to decide how they wanted those handled (convert them to `"none"`, reach
    out to the customer, etc. â€“ these are questions of policy, not of programming).
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤æ¢å’Œç¼ºå¤±çš„å­—æ¯æ˜¯æ‹¼å†™æ£€æŸ¥ç¨‹åºå¯èƒ½èƒ½å¤Ÿä¿®å¤çš„ç±»å‹ï¼ˆç‰¹åˆ«æ˜¯å¦‚æœç¨‹åºçŸ¥é“æ‰€æœ‰æœ‰æ•ˆçš„æŠ˜æ‰£ä»£ç ï¼‰ã€‚éšæœºåƒåœ¾ï¼ŒæŒ‰ç…§å®šä¹‰ï¼Œæ˜¯éšæœºçš„ã€‚åœ¨é‚£é‡Œï¼Œä½ å°†ä¸å¾—ä¸ä¸äº‹ä»¶å…¬å¸äº¤è°ˆï¼Œä»¥å†³å®šä»–ä»¬å¸Œæœ›å¦‚ä½•å¤„ç†è¿™äº›é—®é¢˜ï¼ˆå°†å®ƒä»¬è½¬æ¢ä¸º`"none"`ï¼Œè”ç³»å®¢æˆ·ç­‰â€”â€”è¿™äº›é—®é¢˜æ˜¯æ”¿ç­–é—®é¢˜ï¼Œè€Œä¸æ˜¯ç¼–ç¨‹é—®é¢˜ï¼‰ã€‚
- en: But really, the moral of this is to just use drop-downs or other means to prevent
    incorrect data at the source whenever possible.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®é™…ä¸Šï¼Œè¿™ä¸ªæ•™è®­å°±æ˜¯å°½å¯èƒ½ä½¿ç”¨ä¸‹æ‹‰èœå•æˆ–å…¶ä»–æ–¹æ³•æ¥é˜²æ­¢åœ¨æºå¤´å‡ºç°é”™è¯¯æ•°æ®ã€‚
- en: As you get more experience with programming, you will also learn to anticipate
    certain kinds of errors. Issues such as cells that appear empty will become second
    nature once youâ€™ve processed enough tables that have them, for example. Needing
    to anticipate data errors is one reason why good data scientists have to understand
    the domain that they are working in.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ä½ å¯¹ç¼–ç¨‹ç»éªŒçš„ç§¯ç´¯ï¼Œä½ ä¹Ÿä¼šå­¦ä¼šé¢„è§æŸäº›ç±»å‹çš„é”™è¯¯ã€‚ä¾‹å¦‚ï¼Œä¸€æ—¦ä½ å¤„ç†è¿‡è¶³å¤Ÿå¤šçš„åŒ…å«ç©ºå•å…ƒæ ¼çš„è¡¨æ ¼ï¼Œè¿™äº›é—®é¢˜å°±ä¼šå˜å¾—ä¹ ä»¥ä¸ºå¸¸ã€‚éœ€è¦é¢„è§æ•°æ®é”™è¯¯æ˜¯ä¸ºä»€ä¹ˆä¼˜ç§€çš„æ•°æ®ç§‘å­¦å®¶å¿…é¡»äº†è§£ä»–ä»¬æ­£åœ¨å·¥ä½œçš„é¢†åŸŸçš„åŸå› ä¹‹ä¸€ã€‚
- en: The takeaway from this is how we talked through what to expect. We thought about
    where the data came from, and what errors would be plausible in that situation.
    Having a clear error model in mind will help you develop more robust programs.
    In fact, such adversarial thinking is a core skill of working in security, but
    now weâ€™re getting ahead of ourselves.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥å­¦åˆ°çš„æ˜¯æˆ‘ä»¬å¦‚ä½•è®¨è®ºé¢„æœŸç»“æœã€‚æˆ‘ä»¬æ€è€ƒäº†æ•°æ®æ¥æºï¼Œä»¥åŠåœ¨é‚£ä¸ªæƒ…å†µä¸‹å¯èƒ½å‡ºç°çš„é”™è¯¯ã€‚æœ‰ä¸€ä¸ªæ¸…æ™°çš„é”™è¯¯æ¨¡å‹åœ¨å¿ƒä¸­å°†æœ‰åŠ©äºä½ å¼€å‘å‡ºæ›´å¥å£®çš„ç¨‹åºã€‚å®é™…ä¸Šï¼Œè¿™ç§å¯¹æŠ—æ€§æ€ç»´æ˜¯å®‰å…¨é¢†åŸŸå·¥ä½œçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œä½†ç°åœ¨æˆ‘ä»¬å¯èƒ½æœ‰äº›è¿‡äºè¶…å‰äº†ã€‚
- en: Exercise
  id: totrans-544
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-545
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In spreadsheets, cells that appear empty sometimes have actual content, in
    the form of strings made up of spaces: both `""` and `" "` appear the same when
    we look at a spreadsheet, but they are actually different values computationally.'
  id: totrans-546
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ç”µå­è¡¨æ ¼ä¸­ï¼Œçœ‹ä¼¼ç©ºç™½çš„å•å…ƒæ ¼æœ‰æ—¶å®é™…ä¸ŠåŒ…å«ç”±ç©ºæ ¼ç»„æˆçš„å­—ç¬¦ä¸²å†…å®¹ï¼šå½“æˆ‘ä»¬æŸ¥çœ‹ç”µå­è¡¨æ ¼æ—¶ï¼Œ`""`å’Œ`" "`çœ‹èµ·æ¥ç›¸åŒï¼Œä½†å®ƒä»¬åœ¨è®¡ç®—ä¸Šå®é™…ä¸Šæ˜¯ä¸åŒçš„å€¼ã€‚
- en: ''
  id: totrans-547
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How would you modify `cell-to-discount-code` so that strings containing only
    spaces were also converted to `"none"`? (Hint: look for `string-replace` in the
    strings library.)'
  id: totrans-548
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ ä¼šå¦‚ä½•ä¿®æ”¹`cell-to-discount-code`ï¼Œä»¥ä¾¿åªåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²ä¹Ÿè¢«è½¬æ¢ä¸º`"none"`ï¼Ÿï¼ˆæç¤ºï¼šåœ¨å­—ç¬¦ä¸²åº“ä¸­æŸ¥æ‰¾`string-replace`ã€‚ï¼‰
- en: 4.2.1.5Â Using Programs to Detect Data Errors[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors)
    "Link to here")
  id: totrans-549
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.1.5Â ä½¿ç”¨ç¨‹åºæ£€æµ‹æ•°æ®é”™è¯¯[ğŸ”—](#(part._.Using_.Programs_to_.Detect_.Data_.Errors) "é“¾æ¥è‡³æ­¤")
- en: 'Sometimes, we also look for errors by writing functions to check whether a
    table contains unexpected values. Letâ€™s consider the `"email"` column: thatâ€™s
    a place where we should be able to write a program to flag any rows with invalid
    email addresses. What makes for a valid email address? Letâ€™s consider two rules:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé€šè¿‡ç¼–å†™å‡½æ•°æ¥æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åŒ…å«æ„å¤–çš„å€¼æ¥å¯»æ‰¾é”™è¯¯ã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹`"email"`åˆ—ï¼šè¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿç¼–å†™ç¨‹åºæ¥æ ‡è®°ä»»ä½•åŒ…å«æ— æ•ˆç”µå­é‚®ä»¶åœ°å€çš„è¡Œçš„ä½ç½®ã€‚ä»€ä¹ˆæ„æˆäº†ä¸€ä¸ªæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ï¼Ÿè®©æˆ‘ä»¬è€ƒè™‘ä¸¤ä¸ªè§„åˆ™ï¼š
- en: Valid email addresses should contain an `@` sign
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”åŒ…å«ä¸€ä¸ª`@`ç¬¦å·
- en: Valid email addresses should end in one of `".com"`, `".edu"` or `".org"`
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€åº”ä»¥`".com"`, `".edu"`æˆ–`".org"`ä¹‹ä¸€ç»“å°¾
- en: This is admittedly an outdated, limited, and US-centric definition of email
    addresses, but expanding the formats does not fundamentally change the point of
    this section.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå®šä¹‰ç¡®å®æ˜¯ä¸€ä¸ªè¿‡æ—¶ã€æœ‰é™ä¸”ä»¥ç¾å›½ä¸ºä¸­å¿ƒçš„ç”µå­é‚®ä»¶åœ°å€å®šä¹‰ï¼Œä½†æ‰©å±•æ ¼å¼å¹¶æ²¡æœ‰ä»æ ¹æœ¬ä¸Šæ”¹å˜æœ¬èŠ‚çš„ç›®çš„ã€‚
- en: Exercise
  id: totrans-554
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-555
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a function `is-email` that takes a string and returns a boolean indicating
    whether the string satisfies the above two rules for being valid email addresses.
    For a bit more of a challenge, also include a rule that there must be some character
    between the `@` and the `.`-based ending.
  id: totrans-556
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªåä¸º`is-email`çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºè¯¥å­—ç¬¦ä¸²æ˜¯å¦æ»¡è¶³ä¸Šè¿°ä¸¤ä¸ªè§„åˆ™ä»¥æˆä¸ºæœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ã€‚ä¸ºäº†å¢åŠ ä¸€äº›æŒ‘æˆ˜ï¼Œè¿˜å¯ä»¥åŒ…æ‹¬ä¸€ä¸ªè§„åˆ™ï¼Œå³åœ¨`@`å’ŒåŸºäºç‚¹çš„ç»“å°¾ä¹‹é—´å¿…é¡»æœ‰ä¸€äº›å­—ç¬¦ã€‚
- en: Assuming we had such a function, a routine `filter-with` could then produce
    a table identifying all rows that need to have their email addresses corrected.
    The point here is that programs are often helpful for finding data that need correcting,
    even if a program canâ€™t be written to perform the fixing.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¿™æ ·çš„å‡½æ•°ï¼Œä¸€ä¸ªåä¸º`filter-with`çš„å¸¸è§„ç¨‹åºå¯ä»¥ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼ï¼Œæ ‡è¯†å‡ºæ‰€æœ‰éœ€è¦æ›´æ­£ç”µå­é‚®ä»¶åœ°å€çš„è¡Œã€‚è¿™é‡Œçš„è¦ç‚¹æ˜¯ï¼Œç¨‹åºåœ¨æŸ¥æ‰¾éœ€è¦æ›´æ­£çš„æ•°æ®æ–¹é¢é€šå¸¸å¾ˆæœ‰å¸®åŠ©ï¼Œå³ä½¿æ— æ³•ç¼–å†™ç¨‹åºæ¥æ‰§è¡Œä¿®å¤æ“ä½œã€‚
- en: 4.2.2Â Task Plans[ğŸ”—](#(part._task-plans) "Link to here")
  id: totrans-558
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2Â ä»»åŠ¡è®¡åˆ’[ğŸ”—](#(part._task-plans) "é“¾æ¥è‡³æ­¤")
- en: Before we move on, itâ€™s worth stepping back to reflect on our process for producing
    the discount-summary table. We started from a concrete example, checked the documentation
    for a built-in function that might help, then manipulated our data to work with
    that function. These are part of a more general process that applies to data and
    problems beyond tables. Weâ€™ll refer to this process as task planning. Specifically,
    a task plan is a sequence of steps (tasks) that decompose a computational problem
    into smaller steps (sub-tasks). A useful task plan contains sub-tasks that you
    know how to implement, either by using a built-in function or writing your own.
    There is no single notation or format for task plans. For some problems, a bulleted-list
    of steps will suffice. For others, a diagram showing how data transform through
    a problem is more helpful. This is a personal choice tailored to a specific problem.
    The goal is simply to decompose a problem into something of a programming to-do
    list, to help you manage the process.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œå€¼å¾—å›é¡¾ä¸€ä¸‹æˆ‘ä»¬ç”ŸæˆæŠ˜æ‰£æ‘˜è¦è¡¨çš„è¿‡ç¨‹ã€‚æˆ‘ä»¬ä»å…·ä½“ç¤ºä¾‹å¼€å§‹ï¼Œæ£€æŸ¥æ–‡æ¡£ä¸­å¯èƒ½æœ‰åŠ©äºçš„å†…ç½®å‡½æ•°ï¼Œç„¶åæ“çºµæˆ‘ä»¬çš„æ•°æ®ä»¥ä½¿ç”¨è¯¥å‡½æ•°ã€‚è¿™äº›éƒ½æ˜¯é€‚ç”¨äºè¡¨æ ¼ä¹‹å¤–çš„æ•°æ®å’Œé—®é¢˜çš„æ›´ä¸€èˆ¬è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬å°†æŠŠè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºä»»åŠ¡è§„åˆ’ã€‚å…·ä½“æ¥è¯´ï¼Œä»»åŠ¡è®¡åˆ’æ˜¯ä¸€ç³»åˆ—æ­¥éª¤ï¼ˆä»»åŠ¡ï¼‰ï¼Œå°†è®¡ç®—é—®é¢˜åˆ†è§£æˆæ›´å°çš„æ­¥éª¤ï¼ˆå­ä»»åŠ¡ï¼‰ã€‚ä¸€ä¸ªæœ‰ç”¨çš„ä»»åŠ¡è®¡åˆ’åŒ…å«ä½ çŸ¥é“å¦‚ä½•å®ç°çš„å­ä»»åŠ¡ï¼Œæ— è®ºæ˜¯ä½¿ç”¨å†…ç½®å‡½æ•°è¿˜æ˜¯ç¼–å†™è‡ªå·±çš„å‡½æ•°ã€‚ä»»åŠ¡è®¡åˆ’æ²¡æœ‰å•ä¸€çš„ç¬¦å·æˆ–æ ¼å¼ã€‚å¯¹äºæŸäº›é—®é¢˜ï¼Œæ­¥éª¤çš„åˆ—è¡¨å°±è¶³å¤Ÿäº†ã€‚å¯¹äºå…¶ä»–é—®é¢˜ï¼Œæ˜¾ç¤ºæ•°æ®å¦‚ä½•é€šè¿‡é—®é¢˜è¿›è¡Œè½¬æ¢çš„å›¾è¡¨å¯èƒ½æ›´æœ‰å¸®åŠ©ã€‚è¿™æ˜¯ä¸€ä¸ªæ ¹æ®å…·ä½“é—®é¢˜è¿›è¡Œä¸ªäººé€‰æ‹©çš„å†³å®šã€‚ç›®æ ‡æ˜¯ç®€å•åœ°åˆ†è§£é—®é¢˜ï¼Œä½¿å…¶æˆä¸ºæŸç§ç¼–ç¨‹å¾…åŠäº‹é¡¹åˆ—è¡¨ï¼Œä»¥å¸®åŠ©ä½ ç®¡ç†è¿™ä¸ªè¿‡ç¨‹ã€‚
- en: 'Strategy: Creating a Task Plan'
  id: totrans-560
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç­–ç•¥ï¼šåˆ›å»ºä»»åŠ¡è®¡åˆ’
- en: ''
  id: totrans-561
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Develop a concrete example showing the desired output on a given input (you
    pick the input: a good one is large enough to show different features of your
    inputs, but small enough to work with manually during planning. For table problems,
    roughly 4-6 rows usually works well in practice).'
  id: totrans-562
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘ä¸€ä¸ªå…·ä½“çš„ç¤ºä¾‹ï¼Œå±•ç¤ºåœ¨ç»™å®šè¾“å…¥ä¸Šçš„æœŸæœ›è¾“å‡ºï¼ˆä½ é€‰æ‹©è¾“å…¥ï¼šä¸€ä¸ªå¥½çš„é€‰æ‹©æ˜¯è¶³å¤Ÿå¤§ä»¥å±•ç¤ºè¾“å…¥çš„ä¸åŒç‰¹å¾ï¼Œä½†è¶³å¤Ÿå°ï¼Œåœ¨è§„åˆ’æœŸé—´å¯ä»¥æ‰‹åŠ¨å¤„ç†ã€‚å¯¹äºè¡¨æ ¼é—®é¢˜ï¼Œå®è·µä¸­é€šå¸¸4-6è¡Œå°±è¶³å¤Ÿå¥½äº†ï¼‰ã€‚
- en: ''
  id: totrans-563
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-564
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Mentally identify functions that you already know (or that you find in the documentation)
    that might be useful for transforming the input data to the output data.
  id: totrans-565
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å¿ƒç†ä¸Šè¯†åˆ«å‡ºä½ å·²ç»çŸ¥é“ï¼ˆæˆ–ä½ åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°çš„ï¼‰å¯èƒ½å¯¹å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºè¾“å‡ºæ•°æ®æœ‰ç”¨çš„åŠŸèƒ½ã€‚
- en: ''
  id: totrans-566
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-567
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Develop a sequence of stepsâ€”<wbr>whether as pictures, textual descriptions of
    computations, or a combination of the twoâ€”<wbr>that could be used to solve the
    problem. If you are using pictures, draw out the intermediate data values from
    your concrete example and make notes on what operations might be useful to get
    from one intermediate value to the next. The functions you identified in the previous
    step should show up here.
  id: totrans-568
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å‘ä¸€ç³»åˆ—æ­¥éª¤â€”â€”æ— è®ºæ˜¯ä½œä¸ºå›¾ç‰‡ã€è®¡ç®—çš„æ–‡å­—æè¿°ï¼Œè¿˜æ˜¯ä¸¤è€…çš„ç»“åˆâ€”â€”è¿™äº›æ­¥éª¤å¯ä»¥ç”¨æ¥è§£å†³é—®é¢˜ã€‚å¦‚æœä½ ä½¿ç”¨å›¾ç‰‡ï¼Œä»å…·ä½“ç¤ºä¾‹ä¸­ç»˜åˆ¶å‡ºä¸­é—´æ•°æ®å€¼ï¼Œå¹¶è®°ä¸‹å¯èƒ½æœ‰åŠ©äºä»ä¸€ä¸ªä¸­é—´å€¼åˆ°ä¸‹ä¸€ä¸ªä¸­é—´å€¼è¿›è¡Œæ“ä½œçš„æ“ä½œã€‚ä½ ä¹‹å‰è¯†åˆ«å‡ºçš„å‡½æ•°åº”è¯¥ä¼šå‡ºç°åœ¨è¿™é‡Œã€‚
- en: ''
  id: totrans-569
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-570
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat the previous step, breaking down the subtasks until you believe you could
    write expressions or functions to perform each step or data transformation.
  id: totrans-571
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤å‰é¢çš„æ­¥éª¤ï¼Œåˆ†è§£å­ä»»åŠ¡ï¼Œç›´åˆ°ä½ ç›¸ä¿¡ä½ å¯ä»¥ç¼–å†™è¡¨è¾¾å¼æˆ–å‡½æ•°æ¥æ‰§è¡Œæ¯ä¸ªæ­¥éª¤æˆ–æ•°æ®è½¬æ¢ã€‚
- en: Hereâ€™s a diagram-based task plan for the `discount-summary` program that we
    just developed. Weâ€™ve drawn this on paper to highlight that task plans are not
    written within a programming environment.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªåŸºäºå›¾è¡¨çš„ä»»åŠ¡è®¡åˆ’ï¼Œç”¨äºæˆ‘ä»¬åˆšåˆšå¼€å‘çš„`discount-summary`ç¨‹åºã€‚æˆ‘ä»¬åœ¨çº¸ä¸Šç»˜åˆ¶äº†è¿™ä¸ªå›¾è¡¨ï¼Œä»¥çªå‡ºä»»åŠ¡è®¡åˆ’ä¸æ˜¯åœ¨ç¼–ç¨‹ç¯å¢ƒä¸­ç¼–å†™çš„ã€‚
- en: '![](../Images/09978b14040aceae2e35d06715cb920e.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](../Images/09978b14040aceae2e35d06715cb920e.png)'
- en: Once you have a plan, you turn it into a program by writing expressions and
    functions for the intermediate steps, passing the output of one step as the input
    of the next. Sometimes, we look at a problem and immediately know how to write
    the code for it (if it is a kind of problem that youâ€™ve solved many times before).
    When you donâ€™t immediately see the solution, use this process and break down the
    problem by working with concrete examples of data.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ æœ‰äº†è®¡åˆ’ï¼Œä½ å°±å¯ä»¥é€šè¿‡ç¼–å†™è¡¨ç¤ºä¸­é—´æ­¥éª¤çš„è¡¨è¾¾å¼å’Œå‡½æ•°æ¥å°†å…¶è½¬åŒ–ä¸ºç¨‹åºï¼Œå°†ä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ã€‚æœ‰æ—¶ï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸ªé—®é¢˜ï¼Œé©¬ä¸Šå°±çŸ¥é“å¦‚ä½•ç¼–å†™ä»£ç ï¼ˆå¦‚æœä½ ä¹‹å‰å·²ç»è§£å†³è¿‡å¾ˆå¤šæ¬¡è¿™ç§é—®é¢˜ï¼‰ã€‚å½“ä½ æ²¡æœ‰ç«‹å³çœ‹åˆ°è§£å†³æ–¹æ¡ˆæ—¶ï¼Œä½¿ç”¨è¿™ä¸ªè¿‡ç¨‹ï¼Œé€šè¿‡å¤„ç†å…·ä½“çš„æ•°æ®ç¤ºä¾‹æ¥åˆ†è§£é—®é¢˜ã€‚
- en: Exercise
  id: totrans-575
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-576
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Youâ€™ve been asked to develop a program that identifies the student with the
    largest improvement from the midterm to the final exam in a course. Your input
    table will have columns for each exam as well as for student names. Write a task
    plan for this problem.
  id: totrans-577
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è¢«è¦æ±‚å¼€å‘ä¸€ä¸ªç¨‹åºï¼Œç”¨äºè¯†åˆ«è¯¾ç¨‹ä¸­ä»æœŸä¸­è€ƒè¯•åˆ°æœŸæœ«è€ƒè¯•è¿›æ­¥æœ€å¤§çš„å­¦ç”Ÿã€‚ä½ çš„è¾“å…¥è¡¨å°†åŒ…å«æ¯ä¸ªè€ƒè¯•çš„åˆ—ä»¥åŠå­¦ç”Ÿå§“åã€‚ä¸ºè¿™ä¸ªé—®é¢˜ç¼–å†™ä¸€ä¸ªä»»åŠ¡è®¡åˆ’ã€‚
- en: 'Some task plans involve more than just a sequence of table values. Sometimes,
    we do multiple transformations to the same table to extract different pieces of
    data, then compute over those data. In that case, we draw our plan with branches
    that show the different computations that come together in the final result. Continuing
    with the gradebook, for example, you might be asked to write a program to compute
    the difference between the largest and lowest scores on the midterm. That task
    plan might look like:'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›ä»»åŠ¡è®¡åˆ’ä¸ä»…æ¶‰åŠä¸€ç³»åˆ—è¡¨å€¼ã€‚æœ‰æ—¶ï¼Œæˆ‘ä»¬å¯¹åŒä¸€å¼ è¡¨è¿›è¡Œå¤šæ¬¡è½¬æ¢ä»¥æå–ä¸åŒçš„æ•°æ®ç‰‡æ®µï¼Œç„¶åå¯¹è¿™äº›æ•°æ®è¿›è¡Œè®¡ç®—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç”¨åˆ†æ”¯ç»˜åˆ¶æˆ‘ä»¬çš„è®¡åˆ’ï¼Œä»¥æ˜¾ç¤ºæœ€ç»ˆç»“æœä¸­ç»“åˆçš„ä¸åŒè®¡ç®—ã€‚ä»¥æˆç»©ç°¿ä¸ºä¾‹ï¼Œä½ å¯èƒ½ä¼šè¢«è¦æ±‚ç¼–å†™ä¸€ä¸ªç¨‹åºæ¥è®¡ç®—æœŸä¸­è€ƒè¯•çš„æœ€é«˜åˆ†å’Œæœ€ä½åˆ†ä¹‹é—´çš„å·®å¼‚ã€‚è¿™ä¸ªä»»åŠ¡è®¡åˆ’å¯èƒ½çœ‹èµ·æ¥åƒï¼š
- en: '![](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
  id: totrans-579
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/817f5ff4b256c9d34e213feb73e72b30.png)'
- en: Exercise
  id: totrans-580
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-581
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Youâ€™ve been given a table of weather data that has columns for the date, amount
    of precipitation, and highest temperature for the day. Youâ€™ve been asked to compute
    whether there were more snowy days in January than in February, where a day is
    snowy if the highest temperature is below freezing and the precipitation was more
    than zero.
  id: totrans-582
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ è¢«æä¾›äº†ä¸€ä¸ªåŒ…å«æ—¥æœŸã€é™æ°´é‡å’Œå½“å¤©æœ€é«˜æ¸©åº¦çš„å¤©æ°”æ•°æ®è¡¨ã€‚ä½ è¢«è¦æ±‚è®¡ç®—ä¸€æœˆä»½çš„é›ªå¤©æ˜¯å¦æ¯”äºŒæœˆä»½å¤šï¼Œå…¶ä¸­é›ªå¤©æ˜¯æŒ‡æœ€é«˜æ¸©åº¦ä½äºå†°ç‚¹ä¸”é™æ°´é‡å¤§äºé›¶ã€‚
- en: 'The takeaway of this strategy is easy to state:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç­–ç•¥çš„è¦ç‚¹å¾ˆå®¹æ˜“è¯´æ˜ï¼š
- en: If you arenâ€™t sure how to approach a problem, donâ€™t start by trying to write
    code. Plan until you understand the problem.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸ç¡®å®šå¦‚ä½•å¤„ç†ä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦ä¸€å¼€å§‹å°±å°è¯•ç¼–å†™ä»£ç ã€‚è®¡åˆ’ç›´åˆ°ä½ ç†è§£äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: 'Newer programmers often ignore this advice, assuming that the fastest way to
    produce working code for a programming problem is to start writing code (especially
    if you see classmates who are able to jump directly to writing code). Experienced
    programmers know that trying to write all the code before youâ€™ve understood the
    problem will take much longer than stepping back and understanding the problem
    first. As you develop your programming skills, the specific format of your task
    plans will evolve (and indeed, we will see some cases of this later in the book
    as well). But the core idea is the same: use concrete examples to help identify
    the intermediate computations that will need, then convert those intermediate
    computations to code after or as you figure them out.'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: æ–°ç¨‹åºå‘˜ç»å¸¸å¿½ç•¥è¿™ä¸ªå»ºè®®ï¼Œè®¤ä¸ºç¼–å†™ä»£ç æ˜¯äº§ç”Ÿç¼–ç¨‹é—®é¢˜å·¥ä½œä»£ç çš„æœ€å¿«æ–¹å¼ï¼ˆå°¤å…¶æ˜¯å¦‚æœä½ çœ‹åˆ°åŒå­¦èƒ½å¤Ÿç›´æ¥ç¼–å†™ä»£ç ï¼‰ã€‚ç»éªŒä¸°å¯Œçš„ç¨‹åºå‘˜çŸ¥é“ï¼Œåœ¨ç†è§£é—®é¢˜ä¹‹å‰å°è¯•ç¼–å†™æ‰€æœ‰ä»£ç ä¼šæ¯”å…ˆé€€åä¸€æ­¥ç†è§£é—®é¢˜èŠ±è´¹æ›´é•¿çš„æ—¶é—´ã€‚éšç€ä½ ç¼–ç¨‹æŠ€èƒ½çš„å‘å±•ï¼Œä½ çš„ä»»åŠ¡è®¡åˆ’çš„å…·ä½“æ ¼å¼ä¹Ÿä¼šæ¼”å˜ï¼ˆå®é™…ä¸Šï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ä¹¦çš„åé¢éƒ¨åˆ†çœ‹åˆ°ä¸€äº›è¿™æ ·çš„ä¾‹å­ï¼‰ã€‚ä½†æ ¸å¿ƒæ€æƒ³æ˜¯ç›¸åŒçš„ï¼šä½¿ç”¨å…·ä½“ç¤ºä¾‹æ¥å¸®åŠ©è¯†åˆ«éœ€è¦çš„ä¸­é—´è®¡ç®—ï¼Œç„¶ååœ¨ç†è§£å®ƒä»¬ä¹‹åæˆ–åŒæ—¶å°†é‚£äº›ä¸­é—´è®¡ç®—è½¬æ¢ä¸ºä»£ç ã€‚
- en: 4.2.3Â Preparing Data Tables[ğŸ”—](#(part._preparing-tables) "Link to here")
  id: totrans-586
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 å‡†å¤‡æ•°æ®è¡¨[ğŸ”—](#(part._preparing-tables) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Sometimes, the data we have is clean (in that weâ€™ve normalized the data and
    dealt with errors), but it still isnâ€™t in a format that we can use for the analysis
    that we want to run. For example, what if we want to look at the distribution
    of small, medium, and large ticket orders? In our current table, we have the number
    of tickets in an order, but not an explicit label on the scale of that order.
    If we wanted to produce some sort of chart showing our order scales, we will need
    to make those labels explicit.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®æ˜¯å¹²å‡€çš„ï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å·²ç»æ ‡å‡†åŒ–äº†æ•°æ®å¹¶å¤„ç†äº†é”™è¯¯ï¼‰ï¼Œä½†å®ƒä»ç„¶ä¸æ˜¯æˆ‘ä»¬å¯ä»¥ç”¨äºæˆ‘ä»¬æƒ³è¦è¿è¡Œçš„åˆ†æçš„æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŸ¥çœ‹å°å‹ã€ä¸­å‹å’Œå¤§å®—è®¢å•çš„åˆ†å¸ƒæƒ…å†µå‘¢ï¼Ÿåœ¨æˆ‘ä»¬çš„å½“å‰è¡¨ä¸­ï¼Œæˆ‘ä»¬æœ‰è®¢å•ä¸­çš„ç¥¨æ•°ï¼Œä½†æ²¡æœ‰è¯¥è®¢å•è§„æ¨¡çš„æ˜ç¡®æ ‡ç­¾ã€‚å¦‚æœæˆ‘ä»¬æƒ³åˆ¶ä½œæŸç§æ˜¾ç¤ºè®¢å•è§„æ¨¡çš„å›¾è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®è¿™äº›æ ‡ç­¾ã€‚
- en: 4.2.3.1Â Creating bins[ğŸ”—](#(part._creating._bins) "Link to here")
  id: totrans-588
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.1 åˆ›å»ºåŒºé—´[ğŸ”—](#(part._creating._bins) "é“¾æ¥åˆ°æ­¤å¤„")
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸€ç»„å€¼ï¼ˆå¦‚`tickcounts`å€¼ï¼‰å‡å°‘åˆ°æ›´å°çš„ç±»åˆ«é›†åˆï¼ˆå¦‚è®¢å•çš„å°/ä¸­/å¤§ï¼Œæˆ–æ—¶é—´æˆ³çš„ä¸Šåˆ/ä¸‹åˆç­‰ï¼‰çš„è¡Œä¸ºç§°ä¸ºåˆ†ç®±ã€‚åˆ†ç®±æ˜¯ç±»åˆ«ã€‚ä¸ºäº†å°†è¡Œæ”¾å…¥åˆ†ç®±ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—åŸå§‹æ•°æ®å€¼çš„åˆ†ç®±ï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°åˆ†ç®±æ ‡ç­¾çš„åˆ—ã€‚
- en: 'Hereâ€™s an example of creating bins for the scale of the ticket orders:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªåˆ›å»ºç¥¨è®¢å•è§„æ¨¡çš„åˆ†ç®±ç¤ºä¾‹ï¼š
- en: '[PRE49]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 4.2.3.2Â Splitting Columns[ğŸ”—](#(part._splitting-columns) "Link to here")
  id: totrans-592
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.2 åˆ—æ‹†åˆ†[ğŸ”—](#(part._splitting-columns) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶è¡¨ç›®å‰ä½¿ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²æ¥è¡¨ç¤ºä¸€ä¸ªäººçš„åå­—ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŒ‰å§“æ°æ’åºæ•°æ®ï¼Œè¿™ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²å°±ä¸å†æœ‰ç”¨ã€‚å°†ä¸€åˆ—æ‹†åˆ†æˆå‡ ä¸ªåˆ—å¯ä»¥åœ¨å‡†å¤‡æ•°æ®é›†ç”¨äºåˆ†ææˆ–ä½¿ç”¨æ—¶æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ­¥éª¤ã€‚ç¼–ç¨‹è¯­è¨€é€šå¸¸æä¾›å„ç§æ“ä½œæ¥æ‹†åˆ†å­—ç¬¦ä¸²ï¼šPyret
    æœ‰åä¸º `string-split` å’Œ `string-split-all` çš„æ“ä½œï¼Œå¯ä»¥å°†ä¸€ä¸ªå­—ç¬¦ä¸²æ‹†åˆ†æˆå‡ ä¸ªéƒ¨åˆ†ï¼Œå›´ç»•ä¸€ä¸ªç»™å®šçš„å­—ç¬¦ï¼ˆå¦‚ç©ºæ ¼ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ç¼–å†™
    `string-split("Josie Zhao", " ")` æ¥æå– `"Josie"` å’Œ `"Zhao"` ä½œä¸ºå•ç‹¬çš„å­—ç¬¦ä¸²ã€‚
- en: Exercise
  id: totrans-594
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-595
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  id: totrans-596
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä¸€ä¸ªå‡½æ•°ç¼–å†™ä¸€ä¸ªä»»åŠ¡è®¡åˆ’ï¼ˆä¸æ˜¯ä»£ç ï¼Œåªæ˜¯è®¡åˆ’ï¼‰ï¼Œè¯¥å‡½æ•°å°†æ›¿æ¢äº‹ä»¶è¡¨ä¸­çš„å½“å‰`name`åˆ—ï¼Œç”¨ä¸¤ä¸ªåä¸º`last-name`å’Œ`first-name`çš„åˆ—æ¥ä»£æ›¿ã€‚
- en: Do Now!
  id: totrans-597
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-598
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  id: totrans-599
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®°å½•ä¸‹ä½ æƒ³è¦æµ‹è¯•å§“åæ‹†åˆ†å‡½æ•°çš„ä¸€ç»„ç‰¹å®šçš„å§“åå­—ç¬¦ä¸²ã€‚
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a personâ€™s name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ è‡³å°‘æŸ¥çœ‹äº†ä¸€ä¸‹è¡¨æ ¼ï¼Œå¹¶æ³¨æ„åˆ°æˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º `"Zander"` çš„ä¸ªäººï¼Œä»–çš„æ•´ä¸ªåå­—æ˜¯ä¸€ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯æ—¢æœ‰åå­—ä¹Ÿæœ‰å§“æ°ã€‚æˆ‘ä»¬å¦‚ä½•å¤„ç†ä¸­é—´åï¼Ÿæˆ–è€…æ¥è‡ªé‚£äº›ä¸€ä¸ªäººçš„åå­—åŒ…å«å…¶çˆ¶æ¯å§“æ°çš„æ–‡åŒ–ä¸­çš„åå­—ï¼Ÿæˆ–è€…é‚£äº›å°†å§“æ°æ”¾åœ¨åå­—å‰é¢çš„æ–‡åŒ–ï¼Ÿæˆ–è€…é‚£äº›åå­—ä¸ä»¥æ‹‰ä¸å­—æ¯ä¹¦å†™çš„æ–‡åŒ–ï¼Ÿè¿™è‚¯å®šå˜å¾—æ›´åŠ å¤æ‚äº†ã€‚
- en: 'Responsible Computing: Representing Names'
  id: totrans-601
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»è®¡ç®—ï¼šè¡¨ç¤ºå§“å
- en: ''
  id: totrans-602
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. Itâ€™s okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  id: totrans-603
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†å§“åè¡¨ç¤ºä¸ºæ•°æ®æ˜¯é«˜åº¦ä¾èµ–äºä¸Šä¸‹æ–‡å’Œæ–‡åŒ–çš„ã€‚ä»”ç»†æ€è€ƒä½ çš„æ•°æ®é›†éœ€è¦åŒ…å«å“ªäº›ä¸ªäººï¼Œå¹¶ç›¸åº”åœ°è®¾è®¡ä½ çš„è¡¨æ ¼ç»“æ„ã€‚æ’é™¤ä½ è¯•å›¾è¡¨ç¤ºçš„ç¾¤ä½“ä¹‹å¤–çš„åå­—çš„è¡¨æ ¼ç»“æ„æ˜¯å¯ä»¥æ¥å—çš„ã€‚å¤´ç–¼çš„æ˜¯åæ¥æ„è¯†åˆ°ä½ çš„æ•°æ®é›†æˆ–ç¨‹åºæ’é™¤äº†éœ€è¦æ”¯æŒçš„æ•°æ®ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ£€æŸ¥ä½ çš„è¡¨æ ¼ç»“æ„å¯¹å…¶æ•°æ®æ‰€åšçš„å‡è®¾ï¼Œå¹¶åœ¨è€ƒè™‘å®ƒéœ€è¦è¡¨ç¤ºå“ªäº›è§‚å¯Ÿæˆ–ä¸ªäººåé€‰æ‹©è¡¨æ ¼ç»“æ„ã€‚
- en: ''
  id: totrans-604
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for â€œfalsehoods programmers believe about ...â€, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  id: totrans-605
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦æ·±å…¥äº†è§£åœ¨ç¨‹åºä¸­è¡¨ç¤ºç°å®ä¸–ç•Œå§“åå’Œæ—¥æœŸçš„å¤æ‚æ€§ï¼Œè¯·æœç´¢â€œç¨‹åºå‘˜ç›¸ä¿¡çš„â€¦â€¦é”™è¯¯â€ï¼Œè¿™å°†å‡ºç°å¦‚[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºå§“åçš„é”™è¯¯](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)å’Œ[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºæ—¶é—´](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time)ä¹‹ç±»çš„æ–‡ç« ã€‚
- en: Exercise
  id: totrans-606
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-607
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  id: totrans-608
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œä»¥è¿‡æ»¤è¡¨æ ¼ï¼ŒåªåŒ…æ‹¬é‚£äº›åå­—ä¸æ˜¯ç”±ä¸¤ä¸ªç©ºæ ¼åˆ†éš”çš„å­—ç¬¦ä¸²ç»„æˆçš„è¡Œã€‚
- en: Exercise
  id: totrans-609
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-610
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  id: totrans-611
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè¯¥ç¨‹åºæ¥å—ä¸€ä¸ªå…·æœ‰`name`åˆ—çš„è¡¨æ ¼ï¼Œè¯¥åˆ—ä»¥`"first-name last-name"`æ ¼å¼è¡¨ç¤ºï¼Œå¹¶ç”¨ä¸¤ä¸ªåä¸º`last-name`å’Œ`first-name`çš„åˆ—æ›¿æ¢`name`åˆ—ã€‚è¦ä»å•ä¸ªåç§°å­—ç¬¦ä¸²ä¸­æå–é¦–åå’Œå§“æ°ï¼Œè¯·ä½¿ç”¨ï¼š
- en: ''
  id: totrans-612
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-613
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 4.2.3.1Â Creating bins[ğŸ”—](#(part._creating._bins) "Link to here")
  id: totrans-614
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.1 åˆ›å»ºåˆ†ç»„[ğŸ”—](#(part._creating._bins) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: The act of reducing one set of values (such as the `tickcounts` values) into
    a smaller set of categories (such as small/medium/large for orders, or morning/afternoon/etc.
    for timestamps) is known as binning. The bins are the categories. To put rows
    into bins, we create a function to compute the bin for a raw data value, then
    create a column for the new bin labels.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸€ç»„å€¼ï¼ˆå¦‚`tickcounts`å€¼ï¼‰å‡å°‘åˆ°æ›´å°çš„ç±»åˆ«é›†åˆï¼ˆå¦‚è®¢å•çš„å°/ä¸­/å¤§ï¼Œæˆ–æ—¶é—´æˆ³çš„ä¸Šåˆ/ä¸‹åˆç­‰ï¼‰çš„è¡Œä¸ºè¢«ç§°ä¸ºåˆ†ç»„ã€‚åˆ†ç»„å°±æ˜¯ç±»åˆ«ã€‚ä¸ºäº†å°†è¡Œæ”¾å…¥åˆ†ç»„ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—åŸå§‹æ•°æ®å€¼çš„åˆ†ç»„ï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°åˆ†ç»„æ ‡ç­¾çš„åˆ—ã€‚
- en: 'Hereâ€™s an example of creating bins for the scale of the ticket orders:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªåˆ›å»ºç”¨äºç¥¨åŠ¡è®¢å•è§„æ¨¡çš„åˆ†ç»„çš„ç¤ºä¾‹ï¼š
- en: '[PRE51]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 4.2.3.2Â Splitting Columns[ğŸ”—](#(part._splitting-columns) "Link to here")
  id: totrans-618
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 4.2.3.2 åˆ†å‰²åˆ—[ğŸ”—](#(part._splitting-columns) "é“¾æ¥åˆ°è¿™é‡Œ")
- en: 'The events table currently uses a single string to represent the name of a
    person. This single string is not useful if we want to sort data by last names,
    however. Splitting one column into several columns can be a useful step in preparing
    a dataset for analysis or use. Programming languages usually provide a variety
    of operations for splitting apart strings: Pyret has operations called `string-split`
    and `string-split-all` that split one string into several around a given character
    (like a space). You could, for example, write `string-split("Josie Zhao", " ")`
    to extract `"Josie"` and `"Zhao"` as separate strings.'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶è¡¨ç›®å‰ä½¿ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²æ¥è¡¨ç¤ºä¸€ä¸ªäººçš„åå­—ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŒ‰å§“æ°æ’åºæ•°æ®ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²å°±æ²¡ä»€ä¹ˆç”¨äº†ã€‚å°†ä¸€åˆ—åˆ†å‰²æˆå‡ åˆ—å¯ä»¥æ˜¯å‡†å¤‡æ•°æ®é›†ä»¥ä¾›åˆ†ææˆ–ä½¿ç”¨çš„ä¸€ä¸ªæœ‰ç”¨æ­¥éª¤ã€‚ç¼–ç¨‹è¯­è¨€é€šå¸¸æä¾›å„ç§æ“ä½œæ¥åˆ†å‰²å­—ç¬¦ä¸²ï¼šPyretæœ‰åä¸º`string-split`å’Œ`string-split-all`çš„æ“ä½œï¼Œå¯ä»¥å°†ä¸€ä¸ªå­—ç¬¦ä¸²åˆ†å‰²æˆå‡ ä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†å›´ç»•ä¸€ä¸ªç»™å®šçš„å­—ç¬¦ï¼ˆå¦‚ç©ºæ ¼ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å†™`string-split("Josie
    Zhao", " ")`æ¥æå–`"Josie"`å’Œ`"Zhao"`ä½œä¸ºå•ç‹¬çš„å­—ç¬¦ä¸²ã€‚
- en: Exercise
  id: totrans-620
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-621
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a task plan (not the code, just the plan) for a function that would replace
    the current `name` column in the events table with two columns called `last-name`
    and `first-name`.
  id: totrans-622
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸ºä¸€ä¸ªå‡½æ•°ç¼–å†™ä»»åŠ¡è®¡åˆ’ï¼ˆä¸æ˜¯ä»£ç ï¼Œåªæ˜¯è®¡åˆ’ï¼‰ï¼Œè¯¥å‡½æ•°å°†äº‹ä»¶è¡¨ä¸­çš„å½“å‰`name`åˆ—æ›¿æ¢ä¸ºåä¸º`last-name`å’Œ`first-name`çš„ä¸¤ä¸ªåˆ—ã€‚
- en: Do Now!
  id: totrans-623
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-624
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write down a collection of specific name strings on which you would want to
    test a name-splitting function.
  id: totrans-625
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è®°å½•ä¸‹ä½ æƒ³è¦æµ‹è¯•åç§°åˆ†å‰²å‡½æ•°çš„ä¸€ç»„ç‰¹å®šåç§°å­—ç¬¦ä¸²ã€‚
- en: Hopefully, you at least looked at the table and noticed that we have one individual,
    `"Zander"` whose entire name is a single string, rather than having both a first
    name and a last name. How would we handle middle names? Or names from cultures
    where a personâ€™s name has the last names of both of their parents as part of their
    name? Or cultures that put the family name before the given name? Or cultures
    where names are not written as in the Latin alphabet. This is definitely getting
    more complicated.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ è‡³å°‘çœ‹äº†ä¸€ä¸‹è¡¨æ ¼ï¼Œå¹¶æ³¨æ„åˆ°æˆ‘ä»¬æœ‰ä¸€ä¸ªåå«â€œZanderâ€çš„ä¸ªäººï¼Œä»–çš„æ•´ä¸ªåå­—æ˜¯ä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ç”±åå­—å’Œå§“æ°ä¸¤éƒ¨åˆ†ç»„æˆã€‚æˆ‘ä»¬å¦‚ä½•å¤„ç†ä¸­é—´åï¼Ÿæˆ–è€…æ¥è‡ªé‚£äº›ä¸€ä¸ªäººçš„åå­—åŒ…å«å…¶çˆ¶æ¯å§“æ°çš„æ–‡åŒ–ï¼Ÿæˆ–è€…é‚£äº›å°†å§“æ°æ”¾åœ¨åå­—å‰é¢çš„æ–‡åŒ–ï¼Ÿæˆ–è€…é‚£äº›åå­—ä¸ä»¥æ‹‰ä¸å­—æ¯ä¹¦å†™çš„æ–‡åŒ–ï¼Ÿè¿™æ— ç–‘å˜å¾—æ›´åŠ å¤æ‚ã€‚
- en: 'Responsible Computing: Representing Names'
  id: totrans-627
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»è®¡ç®—ï¼šè¡¨ç¤ºå§“å
- en: ''
  id: totrans-628
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Representing names as data is heavily context- and culture-dependent. Think
    carefully about the individuals your dataset needs to include and design your
    table structure accordingly. Itâ€™s okay to have a table structure that excludes
    names outside of the population you are trying to represent. The headache comes
    from realizing later that your dataset or program excludes data that need to be
    supported. In short, examine your table structure for assumptions it makes about
    your data and choose table structure after thinking about which observations or
    individuals it needs to represent.
  id: totrans-629
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°†åç§°ä½œä¸ºæ•°æ®è¡¨ç¤ºæ˜¯é«˜åº¦ä¸Šä¸‹æ–‡å’Œ culturally-dependentçš„ã€‚ä»”ç»†è€ƒè™‘ä½ çš„æ•°æ®é›†éœ€è¦åŒ…å«å“ªäº›ä¸ªäººï¼Œå¹¶æ®æ­¤è®¾è®¡ä½ çš„è¡¨æ ¼ç»“æ„ã€‚æ’é™¤ä½ è¯•å›¾ä»£è¡¨çš„ç¾¤ä½“ä¹‹å¤–çš„åå­—çš„è¡¨æ ¼ç»“æ„æ˜¯å¯ä»¥æ¥å—çš„ã€‚å¤´ç–¼çš„æ˜¯åæ¥æ„è¯†åˆ°ä½ çš„æ•°æ®é›†æˆ–ç¨‹åºæ’é™¤äº†éœ€è¦æ”¯æŒçš„æ•°æ®ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ£€æŸ¥ä½ çš„è¡¨æ ¼ç»“æ„æ‰€åšå‡ºçš„å…³äºæ•°æ®çš„å‡è®¾ï¼Œå¹¶åœ¨è€ƒè™‘å®ƒéœ€è¦ä»£è¡¨å“ªäº›è§‚å¯Ÿæˆ–ä¸ªäººä¹‹åé€‰æ‹©è¡¨æ ¼ç»“æ„ã€‚
- en: ''
  id: totrans-630
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a deeper look at the complexity of representing real-world names and dates
    in programs, search for â€œfalsehoods programmers believe about ...â€, which turns
    up articles such as [Falsehoods Programmers Believe About Names](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)
    and [Falsehoods Programmers Believe About Time](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time).
  id: totrans-631
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¦æ·±å…¥äº†è§£åœ¨ç¨‹åºä¸­è¡¨ç¤ºç°å®ä¸–ç•Œåç§°å’Œæ—¥æœŸçš„å¤æ‚æ€§ï¼Œè¯·æœç´¢â€œç¨‹åºå‘˜ç›¸ä¿¡çš„â€¦â€¦é”™è¯¯â€ï¼Œè¿™å°†å‡ºç°å¦‚[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºåç§°çš„é”™è¯¯](https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/)å’Œ[ç¨‹åºå‘˜ç›¸ä¿¡çš„å…³äºæ—¶é—´çš„é”™è¯¯](https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time/)ä¹‹ç±»çš„æ–‡ç« ã€‚
- en: Exercise
  id: totrans-632
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-633
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write a program that filters a table to only include rows in which the name
    is not comprised of two strings separated by a space.
  id: totrans-634
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè¯¥ç¨‹åºè¿‡æ»¤è¡¨æ ¼ï¼ŒåªåŒ…æ‹¬åç§°ä¸æ˜¯ç”±ä¸¤ä¸ªç”±ç©ºæ ¼åˆ†éš”çš„å­—ç¬¦ä¸²ç»„æˆçš„è¡Œã€‚
- en: Exercise
  id: totrans-635
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-636
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Write a program that takes a table with a `name` column in `"first-name last-name"`
    format and replaces the `name` column with two columns called `last-name` and
    `first-name`. To extract the first- and last-names from a single name string,
    use:'
  id: totrans-637
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè¯¥ç¨‹åºæ¥å—ä¸€ä¸ªå…·æœ‰ `"first-name last-name"` æ ¼å¼çš„ `name` åˆ—çš„è¡¨æ ¼ï¼Œå¹¶å°† `name` åˆ—æ›¿æ¢ä¸ºä¸¤ä¸ªåä¸º
    `last-name` å’Œ `first-name` çš„åˆ—ã€‚è¦ä»å•ä¸ªåç§°å­—ç¬¦ä¸²ä¸­æå–é¦–å­—æ¯å’Œå§“æ°ï¼Œè¯·ä½¿ç”¨ï¼š
- en: ''
  id: totrans-638
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-639
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 4.2.4Â Managing and Naming Data Tables[ğŸ”—](#(part._naming-tables) "Link to here")
  id: totrans-640
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.4Â ç®¡ç†å’Œå‘½åæ•°æ®è¡¨[ğŸ”—](#(part._naming-tables) "é“¾æ¥è‡³æ­¤")
- en: 'At this point, we have worked with several versions of the events table:'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å¤„ç†äº†äº‹ä»¶è¡¨çš„å‡ ä¸ªç‰ˆæœ¬ï¼š
- en: The original dataset that we tried to load
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°è¯•åŠ è½½çš„åŸå§‹æ•°æ®é›†
- en: The new sheet of the dataset with manual corrections
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰æ‰‹åŠ¨æ›´æ­£çš„æ–°æ•°æ®è¡¨
- en: The version with the discount codes normalized
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰æ ‡å‡†åŒ–æŠ˜æ‰£ä»£ç çš„ç‰ˆæœ¬
- en: Another version that normalized the delivery mode
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæ ‡å‡†åŒ–äº†é…é€æ–¹å¼çš„ç‰ˆæœ¬
- en: The version extended with the order-scale column
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰©å±•äº†è®¢å•è§„æ¨¡åˆ—çš„ç‰ˆæœ¬
- en: Which of these versions should get explicit names within our code file?
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç‰ˆæœ¬ä¸­å“ªä¸€ä¸ªåº”è¯¥åœ¨ä»£ç æ–‡ä»¶ä¸­å…·æœ‰æ˜¾å¼çš„åç§°ï¼Ÿ
- en: Usually, we keep both the original raw source datasheet, as well as the copy
    with our manual corrections. Why? In case we ever have to look at the original
    data again, either to identify kinds of errors that people were making or to apply
    different fixes.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬ä¼šä¿ç•™åŸå§‹çš„åŸå§‹æ•°æ®è¡¨ä»¥åŠå¸¦æœ‰æˆ‘ä»¬æ‰‹åŠ¨æ›´æ­£çš„å‰¯æœ¬ã€‚ä¸ºä»€ä¹ˆï¼Ÿä»¥é˜²æˆ‘ä»¬ä»¥åéœ€è¦å†æ¬¡æŸ¥çœ‹åŸå§‹æ•°æ®ï¼Œæ— è®ºæ˜¯ä¸ºäº†è¯†åˆ«äººä»¬æ‰€çŠ¯çš„é”™è¯¯ç§ç±»ï¼Œè¿˜æ˜¯ä¸ºäº†åº”ç”¨ä¸åŒçš„ä¿®å¤æªæ–½ã€‚
- en: For similar reasons, we want to keep the cleaned (normalized) data separate
    from the version that we initially loaded. Fortunately, Pyret helps with this
    since it creates new tables, rather than modify the prior ones. If we have to
    normalize multiple columns, however, do we really need a new name for every intermediate
    table?
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºç±»ä¼¼çš„åŸå› ï¼Œæˆ‘ä»¬å¸Œæœ›å°†æ¸…æ´—ï¼ˆæ ‡å‡†åŒ–ï¼‰åçš„æ•°æ®ä¸æœ€åˆåŠ è½½çš„ç‰ˆæœ¬åˆ†å¼€ã€‚å¹¸è¿çš„æ˜¯ï¼ŒPyretæœ‰åŠ©äºè¿™ä¸€ç‚¹ï¼Œå› ä¸ºå®ƒåˆ›å»ºæ–°çš„è¡¨æ ¼ï¼Œè€Œä¸æ˜¯ä¿®æ”¹å…ˆå‰çš„è¡¨æ ¼ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å¿…é¡»æ ‡å‡†åŒ–å¤šä¸ªåˆ—ï¼Œæˆ‘ä»¬çœŸçš„éœ€è¦ä¸ºæ¯ä¸ªä¸­é—´è¡¨æ ¼å–ä¸€ä¸ªæ–°çš„åå­—å—ï¼Ÿ
- en: 'As a general rule, we usually maintain separate names for the initially-loaded
    table, the cleaned table, and for significant variations for analysis purposes.
    In our code, this might mean having names:'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€èˆ¬è§„åˆ™ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ºæœ€åˆåŠ è½½çš„è¡¨ã€æ¸…æ´—è¡¨ä»¥åŠç”¨äºåˆ†æç›®çš„çš„æ˜¾è‘—å˜åŒ–ç‰ˆæœ¬ä¿æŒä¸åŒçš„åç§°ã€‚åœ¨æˆ‘ä»¬çš„ä»£ç ä¸­ï¼Œè¿™å¯èƒ½æ„å‘³ç€å…·æœ‰ä»¥ä¸‹åç§°ï¼š
- en: '[PRE53]'
  id: totrans-651
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: where `yes-to-email` is a function we have not written, but that might have
    normalized the `"yes"` value in the `"delivery"` column. Note that we applied
    each of the normalizations in sequence, naming only the final table with all normalizations
    applied. In professional practice, if you were working with a very large dataset,
    you might just write the cleaned dataset out to a file, so that you loaded only
    the clean version during analysis. We will look at writing to file later. Having
    only a few table names will reduce your own confusion when working with your files.
    If you work on multiple data-analyses, developing a consistent strategy for how
    you name your tables will likely help you better manage your code as you switch
    between projects.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­`yes-to-email`æ˜¯æˆ‘ä»¬å°šæœªç¼–å†™çš„å‡½æ•°ï¼Œä½†å¯èƒ½å·²å°†`"delivery"`åˆ—ä¸­çš„`"yes"`å€¼è¿›è¡Œäº†æ ‡å‡†åŒ–ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æŒ‰é¡ºåºåº”ç”¨äº†æ¯ç§æ ‡å‡†åŒ–ï¼Œåªå‘½åäº†åº”ç”¨äº†æ‰€æœ‰æ ‡å‡†åŒ–çš„æœ€ç»ˆè¡¨æ ¼ã€‚åœ¨ä¸“ä¸šå®è·µä¸­ï¼Œå¦‚æœæ‚¨æ­£åœ¨å¤„ç†ä¸€ä¸ªéå¸¸å¤§çš„æ•°æ®é›†ï¼Œæ‚¨å¯èƒ½åªéœ€å°†æ¸…æ´—åçš„æ•°æ®é›†å†™å…¥æ–‡ä»¶ï¼Œè¿™æ ·åœ¨åˆ†ææ—¶åªéœ€åŠ è½½æ¸…æ´—åçš„ç‰ˆæœ¬ã€‚æˆ‘ä»¬å°†ç¨åæŸ¥çœ‹å†™å…¥æ–‡ä»¶ã€‚åªæœ‰å°‘æ•°å‡ ä¸ªè¡¨åå°†å‡å°‘æ‚¨åœ¨å¤„ç†æ–‡ä»¶æ—¶çš„å›°æƒ‘ã€‚å¦‚æœæ‚¨åœ¨å¤šä¸ªæ•°æ®åˆ†æå·¥ä½œä¸­å·¥ä½œï¼Œåˆ¶å®šä¸€ä¸ªä¸€è‡´çš„å‘½åè¡¨ç­–ç•¥å¯èƒ½ä¼šå¸®åŠ©æ‚¨åœ¨é¡¹ç›®ä¹‹é—´åˆ‡æ¢æ—¶æ›´å¥½åœ°ç®¡ç†ä»£ç ã€‚
- en: 4.2.5Â Visualizations and Plots[ğŸ”—](#(part._visualizing-tables) "Link to here")
  id: totrans-653
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.5 å¯è§†åŒ–å’Œå›¾è¡¨[ğŸ”—](#(part._visualizing-tables) "é“¾æ¥è‡³æ­¤")
- en: Now that our data are cleaned and prepared, we are ready to analyze it. What
    might we want to know? Perhaps we want to know which discount code has been used
    most often. Maybe we want to know whether the time when a purchase was made correlates
    with how many tickets people buy. Thereâ€™s a host of different kinds of visualizations
    and plots that people use to summarize data.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…æ´—å¹¶å‡†å¤‡å¥½äº†æ•°æ®ï¼Œæˆ‘ä»¬å‡†å¤‡åˆ†æå®ƒã€‚æˆ‘ä»¬å¯èƒ½æƒ³çŸ¥é“ä»€ä¹ˆï¼Ÿä¹Ÿè®¸æˆ‘ä»¬æƒ³çŸ¥é“å“ªä¸ªæŠ˜æ‰£ä»£ç ä½¿ç”¨å¾—æœ€é¢‘ç¹ã€‚ä¹Ÿè®¸æˆ‘ä»¬æƒ³çŸ¥é“è´­ä¹°æ—¶é—´ä¸äººä»¬è´­ä¹°çš„ç¥¨æ•°ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§ã€‚äººä»¬ä½¿ç”¨å„ç§ä¸åŒçš„å¯è§†åŒ–å›¾è¡¨æ¥æ€»ç»“æ•°æ®ã€‚
- en: 'Which plot type to use depends on both the question and the data at hand. The
    nature of variables in a dataset helps determine relevant plots or statistical
    operations. An attribute or variable in a dataset (i.e., a single column of a
    table) can be classified as one of several different kinds, including:'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å“ªç§å›¾è¡¨ç±»å‹å–å†³äºé—®é¢˜å’Œæ‰‹å¤´çš„æ•°æ®ã€‚æ•°æ®é›†ä¸­å˜é‡çš„æ€§è´¨æœ‰åŠ©äºç¡®å®šç›¸å…³çš„å›¾è¡¨æˆ–ç»Ÿè®¡æ“ä½œã€‚æ•°æ®é›†ä¸­çš„å±æ€§æˆ–å˜é‡ï¼ˆå³è¡¨æ ¼çš„å•åˆ—ï¼‰å¯ä»¥å½’ç±»ä¸ºå‡ ç§ä¸åŒç±»å‹ä¹‹ä¸€ï¼ŒåŒ…æ‹¬ï¼š
- en: 'quantitative: a variable whose values are numeric and can be ordered with a
    consistent interval between values. They are meaningful to use in computations.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®šé‡ï¼šä¸€ä¸ªæ•°å€¼å˜é‡ï¼Œå…¶å€¼æ˜¯æ•°å­—ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ•°å€¼ä¹‹é—´ä¿æŒä¸€è‡´é—´éš”è¿›è¡Œæ’åºã€‚å®ƒä»¬åœ¨è®¡ç®—ä¸­æ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: 'categorical: a variable with a fixed set of values. The values may have an
    order, but there are no meaningful computational operations between the values
    other than ordering. Such variables usually correspond to characteristics of your
    samples.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»ï¼šå…·æœ‰å›ºå®šå€¼é›†çš„å˜é‡ã€‚å€¼å¯èƒ½æœ‰é¡ºåºï¼Œä½†é™¤äº†æ’åºä¹‹å¤–ï¼Œå€¼ä¹‹é—´æ²¡æœ‰æœ‰æ„ä¹‰çš„è®¡ç®—æ“ä½œã€‚æ­¤ç±»å˜é‡é€šå¸¸å¯¹åº”äºæ ·æœ¬çš„ç‰¹å¾ã€‚
- en: Do Now!
  id: totrans-658
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨åšä»€ä¹ˆï¼Ÿ
- en: ''
  id: totrans-659
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which kind of variable are last names? Grades in courses? Zipcodes?
  id: totrans-660
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å§“æ°ã€è¯¾ç¨‹æˆç»©ã€é‚®ç¼–å±äºå“ªç§å˜é‡ç±»å‹ï¼Ÿ
- en: 'Common plots and the kinds of variables they require include:'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸è§çš„å›¾è¡¨å’Œå®ƒä»¬æ‰€éœ€çš„å˜é‡ç±»å‹åŒ…æ‹¬ï¼š
- en: Scatterplots show relationships between two quantitative variables, with one
    variable on each axis of a 2D chart.
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•£ç‚¹å›¾æ˜¾ç¤ºä¸¤ä¸ªå®šé‡å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œæ¯ä¸ªå˜é‡ä½äº2Då›¾è¡¨çš„ä¸€ä¸ªè½´ä¸Šã€‚
- en: Frequency Bar charts show the frequency of each categorical value within a column
    of a dataset.
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢‘ç‡æ¡å½¢å›¾æ˜¾ç¤ºäº†æ•°æ®é›†ä¸­åˆ—ä¸­æ¯ä¸ªåˆ†ç±»å€¼çš„é¢‘ç‡ã€‚
- en: Histograms segment quantitative data into equal-size intervals, showing the
    distribution of values across each interval.
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›´æ–¹å›¾å°†å®šé‡æ•°æ®åˆ†å‰²æˆç­‰å¤§å°çš„åŒºé—´ï¼Œæ˜¾ç¤ºæ¯ä¸ªåŒºé—´å†…å€¼çš„åˆ†å¸ƒã€‚
- en: Pie charts show the proportion of cells in a column across the categorical values
    in a dataset.
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¥¼å›¾æ˜¾ç¤ºäº†æ•°æ®é›†ä¸­åˆ—ä¸­å•å…ƒæ ¼åœ¨åˆ†ç±»å€¼ä¸­çš„æ¯”ä¾‹ã€‚
- en: Do Now!
  id: totrans-666
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨åšä»€ä¹ˆï¼Ÿ
- en: ''
  id: totrans-667
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Map each of the following questions to a chart type, based on the kinds of
    variables involved in the question:'
  id: totrans-668
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ ¹æ®é—®é¢˜ä¸­æ¶‰åŠçš„å˜é‡ç±»å‹ï¼Œå°†ä»¥ä¸‹æ¯ä¸ªé—®é¢˜æ˜ å°„åˆ°å›¾è¡¨ç±»å‹ï¼š
- en: ''
  id: totrans-669
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which discount code has been used most often?
  id: totrans-670
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: å“ªä¸ªæŠ˜æ‰£ä»£ç ä½¿ç”¨å¾—æœ€é¢‘ç¹ï¼Ÿ
- en: ''
  id: totrans-671
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-672
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Is there a relationship between the number of tickets purchased in one order
    and the time of purchase?
  id: totrans-673
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: è´­ä¹°å•ä¸­è´­ä¹°çš„ç¥¨æ•°ä¸è´­ä¹°æ—¶é—´ä¹‹é—´æ˜¯å¦å­˜åœ¨å…³ç³»ï¼Ÿ
- en: ''
  id: totrans-674
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-675
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: How many orders have been made for each delivery option?
  id: totrans-676
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªé…é€é€‰é¡¹å·²åˆ¶ä½œäº†å¤šå°‘è®¢å•ï¼Ÿ
- en: 'For example, we might use a frequency-bar-chart to answer the third question.
    Based on the `Table` documentation, we would generate this using the following
    code (with similar style for the other kinds of plots):'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨é¢‘ç‡æ¡å½¢å›¾æ¥å›ç­”ç¬¬ä¸‰ä¸ªé—®é¢˜ã€‚æ ¹æ® `Table` æ–‡æ¡£ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä»¥ä¸‹ä»£ç ç”Ÿæˆï¼ˆå…¶ä»–ç±»å‹çš„å›¾è¡¨ä¹Ÿæœ‰ç±»ä¼¼çš„é£æ ¼ï¼‰ï¼š
- en: '[PRE54]'
  id: totrans-678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Which yields the following chart (assuming we had not actually normalized the
    contents of the `"delivery"` column):'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿä»¥ä¸‹å›¾è¡¨ï¼ˆå‡è®¾æˆ‘ä»¬å®é™…ä¸Šå¹¶æ²¡æœ‰å¯¹ `"delivery"` åˆ—çš„å†…å®¹è¿›è¡Œæ ‡å‡†åŒ–ï¼‰ï¼š
- en: '![](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
  id: totrans-680
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d07ce823375dcb0f889ad5def3791e2.png)'
- en: 'Whoa â€“ where did that extra `"email"` column come from? If you look closely,
    youâ€™ll spot the error: in the row for `"Alvina"`, thereâ€™s a typo (`"emall"` with
    an `l` instead of an `i`) in the discount column (drop-down menus, anyone?).'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡â€”â€”é‚£ä¸ªé¢å¤–çš„ `"email"` åˆ—æ˜¯ä»å“ªé‡Œæ¥çš„ï¼Ÿå¦‚æœä½ ä»”ç»†çœ‹ï¼Œä¼šå‘ç°é”™è¯¯ï¼šåœ¨ `"Alvina"` è¿™ä¸€è¡Œï¼ŒæŠ˜æ‰£åˆ—ï¼ˆä¸‹æ‹‰èœå•ï¼Œå¯¹å—ï¼Ÿï¼‰ä¸­æœ‰ä¸€ä¸ªæ‹¼å†™é”™è¯¯ï¼ˆ`"emall"`
    ä¸­çš„ `l` åº”è¯¥æ˜¯ `i`ï¼‰ã€‚
- en: The lesson here is that plots and visualizations are valuable not only in the
    analysis phase, but also early on, when we are trying to sanity check that our
    data are clean and ready to use. Good data scientists never trust a dataset without
    first making sure that the values make sense. In larger datasets, manually inspecting
    all of the data is often infeasible. But creating some plots or other summaries
    of the data is also useful for identifying errors.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„æ•™è®­æ˜¯ï¼Œå›¾è¡¨å’Œå¯è§†åŒ–ä¸ä»…å¯¹åˆ†æé˜¶æ®µæœ‰ä»·å€¼ï¼Œè€Œä¸”åœ¨æ—©æœŸï¼Œå½“æˆ‘ä»¬è¯•å›¾éªŒè¯æˆ‘ä»¬çš„æ•°æ®æ˜¯å¦å¹²å‡€ä¸”å¯ç”¨æ—¶ä¹Ÿéå¸¸æœ‰ç”¨ã€‚ä¼˜ç§€çš„æ•°æ®ç§‘å­¦å®¶åœ¨ç¡®ä¿å€¼æœ‰æ„ä¹‰ä¹‹å‰ï¼Œæ°¸è¿œä¸ä¼šä¿¡ä»»ä¸€ä¸ªæ•°æ®é›†ã€‚åœ¨å¤§å‹æ•°æ®é›†ä¸­ï¼Œæ‰‹åŠ¨æ£€æŸ¥æ‰€æœ‰æ•°æ®é€šå¸¸æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä½†æ˜¯ï¼Œåˆ›å»ºä¸€äº›å›¾è¡¨æˆ–å…¶ä»–æ•°æ®æ‘˜è¦ä¹Ÿæœ‰åŠ©äºè¯†åˆ«é”™è¯¯ã€‚
- en: '4.2.6Â Summary: Managing a Data Analysis[ğŸ”—](#(part._.Summary__.Managing_a_.Data_.Analysis)
    "Link to here")'
  id: totrans-683
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.6 æ‘˜è¦ï¼šç®¡ç†æ•°æ®åˆ†æ[ğŸ”—](#(part._.Summary__.Managing_a_.Data_.Analysis) "é“¾æ¥åˆ°æ­¤å¤„")
- en: 'This chapter has given you a high-level overview of how to use coding for managing
    and processing data. When doing any data analysis, a good data practitioner undergoes
    several steps:'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªå…³äºå¦‚ä½•ä½¿ç”¨ç¼–ç æ¥ç®¡ç†å’Œå¤„ç†æ•°æ®çš„æ¦‚è¿°ã€‚åœ¨è¿›è¡Œä»»ä½•æ•°æ®åˆ†ææ—¶ï¼Œä¼˜ç§€çš„æ•°æ®ä»ä¸šè€…éƒ½ä¼šç»å†å‡ ä¸ªæ­¥éª¤ï¼š
- en: 'Think about the data in each column: what are plausible values in the column,
    and what kinds of errors might be in that column based on what you know about
    the data collection methods?'
  id: totrans-685
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°æ¯ä¸€åˆ—çš„æ•°æ®ï¼šè¿™ä¸€åˆ—ä¸­å¯èƒ½æœ‰å“ªäº›åˆç†çš„å€¼ï¼Œä»¥åŠæ ¹æ®ä½ æ‰€äº†è§£çš„æ•°æ®æ”¶é›†æ–¹æ³•ï¼Œè¿™ä¸€åˆ—å¯èƒ½å­˜åœ¨å“ªäº›ç±»å‹çš„é”™è¯¯ï¼Ÿ
- en: Check the data for errors, using a combination of manual inspection of the table,
    plots, and `filter-with` expressions that check for unexpected values. Normalize
    or correct the data, either at the source (if you control that) or via small programs.
  id: totrans-686
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ‰‹åŠ¨æ£€æŸ¥è¡¨æ ¼ã€å›¾è¡¨å’Œ `filter-with` è¡¨è¾¾å¼æ¥æ£€æŸ¥é”™è¯¯ï¼Œæ£€æŸ¥æ•°æ®ã€‚åœ¨æºå¤´ï¼ˆå¦‚æœä½ æ§åˆ¶é‚£é‡Œï¼‰æˆ–é€šè¿‡å°å‹ç¨‹åºå¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–æˆ–æ›´æ­£ã€‚
- en: Store the normalized/cleaned data table, either as a name in your program, or
    by saving it back out to a new file. Leave the raw data intact (in case you need
    to refer to the original later).
  id: totrans-687
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ ‡å‡†åŒ–/æ¸…æ´—åçš„æ•°æ®è¡¨å­˜å‚¨ä¸ºç¨‹åºä¸­çš„åç§°ï¼Œæˆ–è€…å°†å…¶ä¿å­˜ä¸ºæ–°çš„æ–‡ä»¶ã€‚ä¿ç•™åŸå§‹æ•°æ®ï¼ˆä»¥é˜²ä½ éœ€è¦ç¨åå‚è€ƒåŸå§‹æ•°æ®ï¼‰ã€‚
- en: 'Prepare the data based on the questions you want to ask about it: compute new
    columns, bin existing columns, or combine data from across tables. You can either
    finish all preparations and name the final table, or you can make separate preparations
    for each question, naming the per-question tables.'
  id: totrans-688
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ æƒ³å¯¹å…¶æå‡ºçš„é—®é¢˜å‡†å¤‡æ•°æ®ï¼šè®¡ç®—æ–°åˆ—ã€å¯¹ç°æœ‰åˆ—è¿›è¡Œåˆ†ç®±ï¼Œæˆ–ä»å¤šä¸ªè¡¨ä¸­åˆå¹¶æ•°æ®ã€‚ä½ å¯ä»¥å®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œå¹¶å‘½åæœ€ç»ˆè¡¨ï¼Œæˆ–è€…ä½ å¯ä»¥ä¸ºæ¯ä¸ªé—®é¢˜è¿›è¡Œå•ç‹¬çš„å‡†å¤‡ï¼Œå¹¶ä¸ºæ¯ä¸ªé—®é¢˜å‘½åè¡¨ã€‚
- en: At last, perform your analysis, using the statistical methods, visualizations,
    and interpretations that make sense for the question and kinds of variables involved.
    When you report out on the data, always store notes about the file that holds
    your analysis code, and which parts of the file were used to generate each graph
    or interpretation in your report.
  id: totrans-689
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œä½¿ç”¨é€‚åˆé—®é¢˜çš„ç»Ÿè®¡æ–¹æ³•ã€å¯è§†åŒ–å’Œè§£é‡Šæ¥è¿›è¡Œåˆ†æã€‚å½“ä½ æŠ¥å‘Šæ•°æ®æ—¶ï¼Œæ€»æ˜¯å­˜å‚¨æœ‰å…³åŒ…å«åˆ†æä»£ç çš„æ–‡ä»¶ä»¥åŠæ–‡ä»¶ä¸­å“ªäº›éƒ¨åˆ†ç”¨äºç”ŸæˆæŠ¥å‘Šä¸­æ¯ä¸ªå›¾è¡¨æˆ–è§£é‡Šçš„ç¬”è®°ã€‚
- en: Thereâ€™s a lot more to managing data and performing analysis than this book can
    cover. There are entire books, degrees, and careers in each of the management
    of data and its analysis. One area we have not discussed, for example, is machine
    learning, in which programs (that others have written) are used to make predictions
    from datasets (in contrast, this chapter has focused on projects in which you
    will use summary statistics and visualizations to perform analysis). These skills
    covered in this chapter are all prerequisites for using machine learning effectively
    and responsibly. But we still have much more to explore and understand about data
    themselves, which we turn to in the coming chapters. Onward!
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡ç†æ•°æ®å’Œè¿›è¡Œåˆ†æçš„å†…å®¹è¿œä¸æ­¢è¿™æœ¬ä¹¦æ‰€èƒ½æ¶µç›–çš„ã€‚åœ¨æ•°æ®ç®¡ç†å’Œå…¶åˆ†ææ–¹é¢ï¼Œæœ‰å®Œæ•´çš„ä¹¦ç±ã€å­¦ä½å’ŒèŒä¸šã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°šæœªè®¨è®ºçš„ä¸€ä¸ªé¢†åŸŸæ˜¯æœºå™¨å­¦ä¹ ï¼Œåœ¨è¿™ä¸ªé¢†åŸŸä¸­ï¼Œç¨‹åºï¼ˆç”±ä»–äººç¼–å†™ï¼‰è¢«ç”¨æ¥ä»æ•°æ®é›†ä¸­åšå‡ºé¢„æµ‹ï¼ˆç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ¬ç« é‡ç‚¹ä»‹ç»äº†ä½ å°†ä½¿ç”¨æ±‡æ€»ç»Ÿè®¡å’Œå¯è§†åŒ–æ¥è¿›è¡Œåˆ†æçš„é¡¹ç›®ï¼‰ã€‚æœ¬ç« æ¶µç›–çš„æ‰€æœ‰æŠ€èƒ½éƒ½æ˜¯æœ‰æ•ˆå’Œè´Ÿè´£ä»»åœ°ä½¿ç”¨æœºå™¨å­¦ä¹ çš„å…ˆå†³æ¡ä»¶ã€‚ä½†æˆ‘ä»¬è¿˜æœ‰æ›´å¤šéœ€è¦æ¢ç´¢å’Œç†è§£çš„æ•°æ®æœ¬èº«ï¼Œè¿™å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­å±•å¼€ã€‚ç»§ç»­å‰è¿›ï¼
- en: 'Responsible Computing: Bias in Statistical Prediction'
  id: totrans-691
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è´Ÿè´£ä»»è®¡ç®—ï¼šç»Ÿè®¡é¢„æµ‹ä¸­çš„åå·®
- en: ''
  id: totrans-692
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In a book that is discussing data and social responsibility, we would be remiss
    in not at least mentioning some of the many issues that arise when using data
    to make predictions (via techniques like machine learning). Some issues arise
    from problems with the data themselves (e.g., whether samples are representative,
    or whether correlations between variables lead to discrimination as in algorithmic
    hiring). Others arise with how data collected for one purpose is misused to make
    predictions for another. Still more arise with the interpretation of results.
  id: totrans-693
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸€æœ¬è®¨è®ºæ•°æ®å’Œç¤¾äº¤è´£ä»»çš„ä¹¦é‡Œï¼Œå¦‚æœæˆ‘ä»¬ä¸è‡³å°‘æåŠä¸€äº›åœ¨ä½¿ç”¨æ•°æ®åšå‡ºé¢„æµ‹ï¼ˆé€šè¿‡æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯ï¼‰æ—¶å‡ºç°çš„é—®é¢˜ï¼Œé‚£å°†æ˜¯æˆ‘ä»¬çš„å¤±èŒã€‚ä¸€äº›é—®é¢˜æºäºæ•°æ®æœ¬èº«çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œæ ·æœ¬æ˜¯å¦å…·æœ‰ä»£è¡¨æ€§ï¼Œæˆ–è€…å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯å¦ä¼šå¯¼è‡´åƒç®—æ³•æ‹›è˜é‚£æ ·çš„æ­§è§†ï¼‰ã€‚å…¶ä»–é—®é¢˜å‡ºç°åœ¨ä¸ºäº†ä¸€ä¸ªç›®çš„æ”¶é›†çš„æ•°æ®è¢«é”™è¯¯åœ°ç”¨äºå¦ä¸€ä¸ªç›®çš„çš„é¢„æµ‹ã€‚è¿˜æœ‰æ›´å¤šçš„é—®é¢˜å‡ºç°åœ¨å¯¹ç»“æœçš„è§£é‡Šä¸Šã€‚
- en: ''
  id: totrans-694
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: These are all rich topics. There are myriad articles which you could read at
    this point to begin to understand the pitfalls (and benefits) of algorithmic decision
    making. This book will focus instead on issues that arise from the programs we
    are teaching you to write, leaving other courses, or the interests of instructors,
    to augment the material as appropriate for readersâ€™ contexts.
  id: totrans-695
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'è¿™äº›éƒ½æ˜¯ä¸°å¯Œçš„ä¸»é¢˜ã€‚åœ¨è¿™ä¸ªæ—¶å€™ï¼Œä½ å¯ä»¥é˜…è¯»æ— æ•°ç¯‡æ–‡ç« æ¥å¼€å§‹ç†è§£ç®—æ³•å†³ç­–çš„é™·é˜±ï¼ˆä»¥åŠå¥½å¤„ï¼‰ã€‚æœ¬ä¹¦å°†ä¸“æ³¨äºç”±æˆ‘ä»¬æ•™æˆä½ ç¼–å†™çš„ç¨‹åºå¼•å‘çš„é—®é¢˜ï¼Œè€Œå°†å…¶ä»–è¯¾ç¨‹æˆ–æ•™å¸ˆçš„å…´è¶£ç•™ç»™é€‚å½“è¡¥å……è¯»è€…èƒŒæ™¯çš„ææ–™ã€‚ '
