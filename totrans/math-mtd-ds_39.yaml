- en: 5.4\. Spectral properties of the Laplacian matrix#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.4\. 拉普拉斯矩阵的谱性质#
- en: 原文：[https://mmids-textbook.github.io/chap05_specgraph/04_laplacian/roch-mmids-specgraph-laplacian.html](https://mmids-textbook.github.io/chap05_specgraph/04_laplacian/roch-mmids-specgraph-laplacian.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap05_specgraph/04_laplacian/roch-mmids-specgraph-laplacian.html](https://mmids-textbook.github.io/chap05_specgraph/04_laplacian/roch-mmids-specgraph-laplacian.html)
- en: In this section, we look at the spectral properties of the Laplacian of a graph.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们研究图的拉普拉斯的谱性质。
- en: '5.4.1\. Eigenvalues of the Laplacian matrix: first observations[#](#eigenvalues-of-the-laplacian-matrix-first-observations
    "Link to this heading")'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.1\. 拉普拉斯矩阵的特征值：初步观察[#](#eigenvalues-of-the-laplacian-matrix-first-observations
    "链接到这个标题")
- en: 'Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices. Two observations:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(G = (V, E)\) 是一个有 \(n = |V|\) 个顶点的图。有两个观察：
- en: 1- Since the Laplacian matrix \(L\) of \(G\) is symmetric, by the *Spectral
    Theorem*, it has a spectral decomposition
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 由于 \(G\) 的拉普拉斯矩阵 \(L\) 是对称的，根据 *谱定理*，它有一个谱分解
- en: \[ L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T \]
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T \]
- en: where the \(\mathbf{y}_i\)’s form an orthonormal basis of \(\mathbb{R}^n\).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{y}_i\) 形成了 \(\mathbb{R}^n\) 的正交基。
- en: 2- Further, because \(L\) is positive semidefinite, the eigenvalues are nonnegative.
    By convention, we assume
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 此外，因为 \(L\) 是半正定矩阵，所以特征值都是非负的。按照惯例，我们假设
- en: \[ 0 \leq \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n. \]
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 \leq \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n. \]
- en: Note that this is the opposite order to we used in the previous section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这与我们在上一节中使用的是相反的顺序。
- en: 'Another observation:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察：
- en: '**LEMMA** Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices and Laplacian
    matrix \(L\). The constant unit vector'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 设 \(G = (V, E)\) 是一个有 \(n = |V|\) 个顶点和拉普拉斯矩阵 \(L\) 的图。常量单位向量'
- en: \[ \mathbf{y}_1 = \frac{1}{\sqrt{n}} (1, \ldots, 1) \]
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{y}_1 = \frac{1}{\sqrt{n}} (1, \ldots, 1) \]
- en: is an eigenvector of \(L\) with eigenvalue \(0\). \(\flat\)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 是 \(L\) 的一个特征值为 \(0\) 的特征向量。 \(\flat\)
- en: '*Proof:* Let \(B\) be an oriented incidence matrix of \(G\) recall that \(L
    = B B^T\). By construction \(B^T \mathbf{y}_1 = \mathbf{0}\) since each column
    of \(B\) has exactly one \(1\) and one \(-1\). So \(L \mathbf{y}_1 = B B^T \mathbf{y}_1
    = \mathbf{0}\) as claimed. \(\square\)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明* 设 \(B\) 是 \(G\) 的有向关联矩阵，回忆一下 \(L = B B^T\)。由于 \(B^T \mathbf{y}_1 = \mathbf{0}\)（因为
    \(B\) 的每一列恰好有一个 \(1\) 和一个 \(-1\)），所以 \(L \mathbf{y}_1 = B B^T \mathbf{y}_1 = \mathbf{0}\)，正如所声称的那样。
    \(\square\)'
- en: In general, the constant vector may not be the only eigenvector with eigenvalue
    one.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，常量向量可能不是唯一具有特征值一的特征向量。
- en: '**NUMERICAL CORNER:** One use of the spectral decomposition of the Laplacian
    matrix is in graph drawing\(\idx{graph drawing}\xdi\). We illustrate this next.
    Given a graph \(G = (V, E)\), it is not clear a priori how to draw it in the plane
    since the only information available are adjacencies of vertices. One approach
    is just to position the vertices at random. The function [`networkx.draw`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw.html)
    or [`networkx.draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html#networkx.drawing.nx_pylab.draw_networkx)
    can take as input different [graph layout](https://networkx.org/documentation/stable/reference/drawing.html#module-networkx.drawing.layout)
    functions that return an \(x\) and \(y\)-coordinate for each vertex.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落:** 拉普拉斯矩阵的谱分解的一个用途是在图绘制中（\(\idx{graph drawing}\xdi\)）。我们将在下面说明这一点。给定一个图
    \(G = (V, E)\)，在平面上如何绘制它并不清楚，因为唯一可用的信息是顶点的邻接关系。一种方法是将顶点随机定位。函数 `networkx.draw`（https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw.html）或
    `networkx.draw_networkx`（https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html#networkx.drawing.nx_pylab.draw_networkx）可以接受不同的
    [图布局](https://networkx.org/documentation/stable/reference/drawing.html#module-networkx.drawing.layout)
    函数作为输入，这些函数为每个顶点返回一个 \(x\) 和 \(y\) 坐标。'
- en: We will test this on a grid graph. We use [`networkx.grid_2d_graph`](https://networkx.org/documentation/stable/reference/generated/networkx.generators.lattice.grid_2d_graph.html)
    to construct such a graph.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在网格图上测试这一点。我们使用 `networkx.grid_2d_graph`（https://networkx.org/documentation/stable/reference/generated/networkx.generators.lattice.grid_2d_graph.html）来构建这样的图。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: One layout approach is to choose random locations for the nodes. Specifically,
    for every node, a position is generated by choosing each coordinate uniformly
    at random on the interval \([0,1]\).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一种布局方法是选择节点的随机位置。具体来说，对于每个节点，通过在区间 \([0,1]\) 上均匀随机选择每个坐标来生成一个位置。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![../../_images/e71c11388af95019112c93563223107aea5d4aa3b91dbab26b654c57b7ad303b.png](../Images/f62f7cee4755a1c33c92335ca3d78f91.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e71c11388af95019112c93563223107aea5d4aa3b91dbab26b654c57b7ad303b.png](../Images/f62f7cee4755a1c33c92335ca3d78f91.png)'
- en: Clearly, this is hard to read.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这很难阅读。
- en: Another approach is to map the vertices to two eigenvectors, similarly to what
    we did for dimensionality reduction. The eigenvector associated to \(\mu_1\) is
    constant and therefore not useful for drawing. We try the next two. We use the
    Laplacian matrix. This is done using [`networkx.spectral_layout`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spectral_layout.html#networkx.drawing.layout.spectral_layout).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将顶点映射到两个特征向量，这与我们进行降维时所做的类似。与 \(\mu_1\) 相关的特征向量是常数，因此对绘图没有用。我们尝试下一个两个。我们使用拉普拉斯矩阵。这是通过使用
    `networkx.spectral_layout` 实现的。[networkx.spectral_layout](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spectral_layout.html#networkx.drawing.layout.spectral_layout)。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![../../_images/d9f18189eb6a51676466d9a2ffe9aa688e95d0f15f8697b68ee0c7c9ae2ada45.png](../Images/0ecdf40ac77cc8a246dd3cb1077c885d.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/d9f18189eb6a51676466d9a2ffe9aa688e95d0f15f8697b68ee0c7c9ae2ada45.png](../Images/0ecdf40ac77cc8a246dd3cb1077c885d.png)'
- en: Interestingly, the outcome is provides a much more natural drawing of the graph,
    revealing its underlying structure as a grid. We will come back later to try to
    explain this, after we have developed further understanding of the spectral properties
    of the Laplacian matrix.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，结果提供了一个更自然的图绘制，揭示了其作为网格的潜在结构。我们将在以后回来尝试解释这一点，在我们对拉普拉斯矩阵的谱性质有了更深入的理解之后。
- en: \(\unlhd\)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.4.2\. Laplacian matrix and connectivity[#](#laplacian-matrix-and-connectivity
    "Link to this heading")
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.2. 拉普拉斯矩阵与连通性[#](#laplacian-matrix-and-connectivity "链接到这个标题")
- en: As we indicated before, the Laplacian matrix contains information about the
    connectedness of \(G\). We elaborate on a first concrete connection here. But
    first we will need a useful form of the Laplaican quadratic form \(\mathbf{x}^T
    L \mathbf{x}\) which enters in the variational charaterization of the eigenvalues.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前指出的，拉普拉斯矩阵包含关于 \(G\) 的连通性信息。我们在这里详细阐述第一个具体的联系。但首先，我们需要一个有用的拉普拉斯二次型 \(\mathbf{x}^T
    L \mathbf{x}\) 的形式，它进入特征值的变分表征。
- en: '**LEMMA** **(Laplacian Quadratic Form)** \(\idx{Laplacian quadratic form lemma}\xdi\)
    Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices and Laplacian matrix \(L\).
    We have the following formula for the Laplacian quadratic form'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(拉普拉斯二次型)** \(\idx{Laplacian quadratic form lemma}\xdi\) 设 \(G = (V,
    E)\) 是一个有 \(n = |V|\) 个顶点和拉普拉斯矩阵 \(L\) 的图。我们有以下关于拉普拉斯二次型的公式'
- en: \[ \mathbf{x}^T L \mathbf{x} = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2 \]
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2 \]
- en: for any \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\). \(\flat\)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何 \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\)。 \(\flat\)
- en: Here is an intuitive way of interpreting this lemma. If one thinks of \(\mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n\) as a real-valued function over the vertices
    (i.e., it associates a real value \(x_i\) to vertex \(i\) for each \(i\)), then
    the Laplacian quadratic form measures how “smooth” the function is over the graph
    in the following sense. A small value of \(\mathbf{x}^T L \mathbf{x}\) indicates
    that adjacent vertices tend to get assigned close values.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个直观的方式来解释这个引理。如果将 \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\) 视为顶点上的实值函数（即，它将每个顶点
    \(i\) 联系到一个实值 \(x_i\)），那么拉普拉斯二次型衡量函数在图上的“平滑”程度如下。 \(\mathbf{x}^T L \mathbf{x}\)
    的值较小表示相邻顶点倾向于被分配到接近的值。
- en: '*Proof:* Let \(B\) be an oriented incidence matrix of \(G\). We have that \(L
    = B B^T\). Thus, for any \(\mathbf{x}\), we have \((B^T \mathbf{x})_k = x_v -
    x_u\) if the edge \(e_k = \{u, v\}\) is oriented as \((u,v)\) under \(B\). That
    implies'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 设 \(B\) 是 \(G\) 的有向关联矩阵。我们有 \(L = B B^T\)。因此，对于任何 \(\mathbf{x}\)，如果边
    \(e_k = \{u, v\}\) 在 \(B\) 下有向为 \((u,v)\)，则 \((B^T \mathbf{x})_k = x_v - x_u\)。这表明'
- en: \[ \mathbf{x}^T L \mathbf{x} = \mathbf{x}^T B B^T \mathbf{x} = \|B^T \mathbf{x}\|^2
    = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2. \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \mathbf{x}^T B B^T \mathbf{x} = \|B^T \mathbf{x}\|^2
    = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2. \]
- en: Since the latter is always nonnegative, it also implies that \(L\) is positive
    semidefinite. \(\square\)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于后者始终是非负的，这也意味着 \(L\) 是正半定的。 \(\square\)
- en: We are now ready to derive connectivity consequences. Recall that, for any graph
    \(G\), the Laplacian eigenvalue \(\mu_1 = 0\).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好推导出连通性的后果。回想一下，对于任何图 \(G\)，拉普拉斯特征值 \(\mu_1 = 0\)。
- en: '**LEMMA** **(Laplacian and Connectivity)** \(\idx{Laplacian and connectivity
    lemma}\xdi\) If \(G\) is connected, then the Laplacian eigenvalue \(\mu_2 > 0\).
    \(\flat\)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **（拉普拉斯矩阵与连通性）** \(\idx{拉普拉斯矩阵与连通性引理}\xdi\) 如果 \(G\) 是连通的，那么拉普拉斯特征值
    \(\mu_2 > 0\)。\(\flat\)'
- en: '*Proof:* Let \(G = (V, E)\) with \(n = |V|\) and let \(L = \sum_{i=1}^n \mu_i
    \mathbf{y}_i \mathbf{y}_i^T\) be a spectral decomposition of its Laplacian \(L\)
    with \(0 = \mu_1 \leq \cdots \leq \mu_n\). Suppose by way of contradiction that
    \(\mu_2 = 0\). Any eigenvector \(\mathbf{y} = (y_{1}, \ldots, y_{n})\) with \(0\)
    eigenvalue satisfies \(L \mathbf{y} = \mathbf{0}\) by definition. By the *Laplacian
    Quadratic Form Lemma* then'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明* 设 \(G = (V, E)\) 且 \(n = |V|\)，设 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i
    \mathbf{y}_i^T\) 是其拉普拉斯矩阵 \(L\) 的一个谱分解，其中 \(0 = \mu_1 \leq \cdots \leq \mu_n\)。假设通过反证法
    \(\mu_2 = 0\)。任何具有 \(0\) 特征值的特征向量 \(\mathbf{y} = (y_{1}, \ldots, y_{n})\) 根据定义满足
    \(L \mathbf{y} = \mathbf{0}\)。根据 *拉普拉斯二次型引理*，那么'
- en: \[ 0 = \mathbf{y}^T L \mathbf{y} = \sum_{e = \{i, j\} \in E} (y_{i} - y_{j})^2.
    \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 = \mathbf{y}^T L \mathbf{y} = \sum_{e = \{i, j\} \in E} (y_{i} - y_{j})^2.
    \]
- en: 1- In order for this to hold, it must be that any two adjacent vertices \(i\)
    and \(j\) have \(y_{i} = y_{j}\). That is, \(\{i,j\} \in E\) implies \(y_i = y_j\).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 为了使这一点成立，必须满足任何两个相邻顶点 \(i\) 和 \(j\) 都有 \(y_{i} = y_{j}\)。也就是说，\(\{i,j\} \in
    E\) 意味着 \(y_i = y_j\)。
- en: 2- Furthermore, because \(G\) is connected, between any two of its vertices
    \(u\) and \(v\) - adjacent or not - there is a path \(u = w_0 \sim \cdots \sim
    w_k = v\) along which the \(y_{w}\)’s must be the same. Thus \(\mathbf{y}\) is
    a constant vector.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 此外，因为 \(G\) 是连通的，所以它的任意两个顶点 \(u\) 和 \(v\)（无论是否相邻）之间都存在一条路径 \(u = w_0 \sim
    \cdots \sim w_k = v\)，在这条路径上 \(y_{w}\) 的值必须相同。因此 \(\mathbf{y}\) 是一个常向量。
- en: But that is a contradiction since the eigenvectors \(\mathbf{y}_1, \ldots, \mathbf{y}_n\)
    are in fact linearly independent, so that \(\mathbf{y}_1\) and \(\mathbf{y}_2\)
    cannot both be a constant vector. \(\square\)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但这与特征向量 \(\mathbf{y}_1, \ldots, \mathbf{y}_n\) 实际上是线性无关的事实相矛盾，因此 \(\mathbf{y}_1\)
    和 \(\mathbf{y}_2\) 不能同时是常向量。\(\square\)
- en: The quantity \(\mu_2\) is sometimes referred to as the [algebraic connectivity](https://mathworld.wolfram.com/AlgebraicConnectivity.html)\(\idx{algebraic
    connectivity}\xdi\) of the graph. The corresponding eigenvector, \(\mathbf{y}_2\),
    is known as the [Fiedler vector](https://mathworld.wolfram.com/FiedlerVector.html)\(\idx{Fiedler
    vector}\xdi\).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 量 \(\mu_2\) 有时被称为图的 [代数连通性](https://mathworld.wolfram.com/AlgebraicConnectivity.html)\(\idx{代数连通性}\xdi\)。相应的特征向量
    \(\mathbf{y}_2\) 被称为 [菲德勒向量](https://mathworld.wolfram.com/FiedlerVector.html)\(\idx{菲德勒向量}\xdi\)。
- en: We state the following (more general) converse result without proof.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以下列（更一般的）逆命题陈述，但不提供证明。
- en: '**LEMMA** If \(\mu_{k+1}\) is the smallest nonzero Laplacian eigenvalue of
    \(G\), then \(G\) has \(k\) connected components. \(\flat\)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 如果 \(\mu_{k+1}\) 是 \(G\) 的最小的非零拉普拉斯特征值，那么 \(G\) 有 \(k\) 个连通分量。\(\flat\)'
- en: We will be interested in more quantitative results of this type. Before proceeding,
    we start with a simple observation. By our proof of the *Spectral Theorem*, the
    largest eigenvalue \(\mu_n\) of the Laplacian matrix \(L\) is the solution to
    the optimization problem
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对此类更定量的结果感兴趣。在继续之前，我们首先进行一个简单的观察。根据我们对 *谱定理* 的证明，拉普拉斯矩阵 \(L\) 的最大特征值 \(\mu_n\)
    是以下优化问题的解
- en: \[ \mu_n = \max\{\langle \mathbf{x}, L \mathbf{x}\rangle:\|\mathbf{x}\| = 1\}.
    \]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_n = \max\{\langle \mathbf{x}, L \mathbf{x}\rangle:\|\mathbf{x}\| = 1\}.
    \]
- en: Such extremal characterization is useful in order to bound the eigenvalue \(\mu_n\),
    since any choice of \(\mathbf{x}\) with \(\|\mathbf{x}\| =1\) gives a lower bound
    through the quantity \(\langle \mathbf{x}, L \mathbf{x}\rangle\). That perspective
    will be key to our application to graph partitioning.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这种极值描述对于界定特征值 \(\mu_n\) 是有用的，因为任何选择 \(\|\mathbf{x}\| =1\) 的 \(\mathbf{x}\) 都可以通过数量
    \(\langle \mathbf{x}, L \mathbf{x}\rangle\) 给出一个下界。这种观点将是我们应用于图划分的关键。
- en: For now, we give a simple consequence.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们给出一个简单的推论。
- en: '**LEMMA** **(Laplacian and Maximum Degree)** \(\idx{Laplacian and maximum degree
    lemma}\xdi\) Let \(G = (V, E)\) be a graph with maximum degree \(\bar{\delta}\).
    Let \(\mu_n\) be the largest eigenvalue of its Laplacian matrix \(L\). Then'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **（拉普拉斯矩阵与最大度）** \(\idx{拉普拉斯矩阵与最大度引理}\xdi\) 设 \(G = (V, E)\) 是一个最大度为
    \(\bar{\delta}\) 的图。设 \(\mu_n\) 是其拉普拉斯矩阵 \(L\) 的最大特征值。那么'
- en: \[ \bar{\delta}+1 \leq \mu_n \leq 2 \bar{\delta}. \]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{\delta}+1 \leq \mu_n \leq 2 \bar{\delta}. \]
- en: \(\flat\)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof idea:* As explained before the statement of the lemma, for the lower
    bound it suffices to find a good test unit vector \(\mathbf{x}\) to plug into
    \(\langle \mathbf{x}, L \mathbf{x}\rangle\). A clever choice does the trick.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 如同在引理陈述之前所解释的，对于下界，只需要找到一个好的测试单位向量 \(\mathbf{x}\) 插入到 \(\langle \mathbf{x},
    L \mathbf{x}\rangle\) 中。一个巧妙的选择就能解决问题。'
- en: '*Proof:* We start with the lower bound. Let \(u \in V\) be a vertex with degree
    \(\bar{\delta}\). Let \(\mathbf{z}\) be the vector with entries'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 我们从下界开始。设 \(u \in V\) 是一个度数为 \(\bar{\delta}\) 的顶点。设 \(\mathbf{z}\) 是一个具有以下条目的向量'
- en: \[\begin{split} z_i = \begin{cases} \bar{\delta} & \text{if $i = u$}\\ -1 &
    \text{if $\{i,u\} \in E$}\\ 0 & \text{o.w.} \end{cases} \end{split}\]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} z_i = \begin{cases} \bar{\delta} & \text{if $i = u$}\\ -1 &
    \text{if $\{i,u\} \in E$}\\ 0 & \text{o.w.} \end{cases} \end{split}\]
- en: and let \(\mathbf{x}\) be the unit vector \(\mathbf{z}/\|\mathbf{z}\|\). By
    definition of the degree of \(u\), \(\|\mathbf{z}\|^2 = \bar{\delta}^2 + \bar{\delta}(-1)^2
    = \bar{\delta}(\bar{\delta}+1)\). Using the *Laplacian Quadratic Form Lemma*,
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 并令 \(\mathbf{x}\) 为单位向量 \(\mathbf{z}/\|\mathbf{z}\|\)。根据 \(u\) 的度数定义，\(\|\mathbf{z}\|^2
    = \bar{\delta}^2 + \bar{\delta}(-1)^2 = \bar{\delta}(\bar{\delta}+1)\)。使用 *拉普拉斯二次型引理*，
- en: '\[ \langle \mathbf{z}, L \mathbf{z}\rangle = \sum_{e = \{i, j\} \in E} (z_i
    - z_j)^2 \geq \sum_{i: \{i, u\} \in E} (z_i - z_u)^2 = \sum_{i: \{i, u\} \in E}
    (-1 - \bar{\delta})^2 = \bar{\delta} (\bar{\delta}+1)^2 \]'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \langle \mathbf{z}, L \mathbf{z}\rangle = \sum_{e = \{i, j\} \in E} (z_i
    - z_j)^2 \geq \sum_{i: \{i, u\} \in E} (z_i - z_u)^2 = \sum_{i: \{i, u\} \in E}
    (-1 - \bar{\delta})^2 = \bar{\delta} (\bar{\delta}+1)^2 \]'
- en: where we restricted the sum to those edges incident with \(u\) and used the
    fact that all terms in the sum are nonnegative. Finally
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们限制求和只包括与 \(u\) 相邻的边，并利用所有求和项都是非负的事实。最后
- en: \[ \langle \mathbf{x}, L \mathbf{x}\rangle = \left\langle \frac{\mathbf{z}}{\|\mathbf{z}\|},
    L \frac{\mathbf{z}}{\|\mathbf{z}\|}\right\rangle = \frac{1}{\|\mathbf{z}\|^2}
    \langle \mathbf{z}, L \mathbf{z}\rangle = \frac{\bar{\delta} (\bar{\delta}+1)^2}{\bar{\delta}(\bar{\delta}+1)}
    = \bar{\delta}+1 \]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{x}, L \mathbf{x}\rangle = \left\langle \frac{\mathbf{z}}{\|\mathbf{z}\|},
    L \frac{\mathbf{z}}{\|\mathbf{z}\|}\right\rangle = \frac{1}{\|\mathbf{z}\|^2}
    \langle \mathbf{z}, L \mathbf{z}\rangle = \frac{\bar{\delta} (\bar{\delta}+1)^2}{\bar{\delta}(\bar{\delta}+1)}
    = \bar{\delta}+1 \]
- en: so that
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此
- en: \[ \mu_n = \max\{\langle \mathbf{x}', L \mathbf{x}'\rangle:\|\mathbf{x}'\| =
    1\} \geq \langle \mathbf{x}, L \mathbf{x}\rangle = \bar{\delta}+1 \]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_n = \max\{\langle \mathbf{x}', L \mathbf{x}'\rangle:\|\mathbf{x}'\| =
    1\} \geq \langle \mathbf{x}, L \mathbf{x}\rangle = \bar{\delta}+1 \]
- en: as claimed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称。
- en: We proceed with the lower bound. For any unit vector \(\mathbf{x}\),
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续进行下界分析。对于任何单位向量 \(\mathbf{x}\)，
- en: \[\begin{align*} \langle \mathbf{x}, L \mathbf{x}\rangle &= \sum_{i,j} L_{ij}
    x_i x_j\\ &\leq \sum_{i,j} |L_{ij}| |x_i| |x_j|\\ &= \sum_{i,j} (D_{ij} + A_{ij})
    |x_i| |x_j|\\ &= \sum_{i} \delta(i) \,x_i^2 + \sum_{i,j} A_{ij} |x_i| |x_j|. \end{align*}\]
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \langle \mathbf{x}, L \mathbf{x}\rangle &= \sum_{i,j} L_{ij}
    x_i x_j\\ &\leq \sum_{i,j} |L_{ij}| |x_i| |x_j|\\ &= \sum_{i,j} (D_{ij} + A_{ij})
    |x_i| |x_j|\\ &= \sum_{i} \delta(i) \,x_i^2 + \sum_{i,j} A_{ij} |x_i| |x_j|. \end{align*}\]
- en: By the *Cauchy-Schwarz inequality*, this is
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 根据柯西-施瓦茨不等式，这可以表示为
- en: \[\begin{align*} &\leq \bar{\delta} + \left(\sum_{i,j} A_{ij} x_i^2\right)^{1/2}
    \left(\sum_{i,j} A_{ij} x_j^2\right)^{1/2}\\ &\leq \bar{\delta} + \left( \bar{\delta}
    \sum_{i} x_i^2\right)^{1/2} \left(\bar{\delta} \sum_{j} x_j^2\right)^{1/2}\\ &\leq
    2\bar{\delta}. \end{align*}\]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\leq \bar{\delta} + \left(\sum_{i,j} A_{ij} x_i^2\right)^{1/2}
    \left(\sum_{i,j} A_{ij} x_j^2\right)^{1/2}\\ &\leq \bar{\delta} + \left( \bar{\delta}
    \sum_{i} x_i^2\right)^{1/2} \left(\bar{\delta} \sum_{j} x_j^2\right)^{1/2}\\ &\leq
    2\bar{\delta}. \end{align*}\]
- en: \(\square\)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: '**NUMERICAL CORNER:** We construct a graph with two connected components and
    check the results above. We work directly with the adjacency matrix.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值分析角:** 我们构建一个具有两个连通分量的图，并检查上述结果。我们直接使用邻接矩阵。'
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note the block structure.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意块结构。
- en: The degrees can be obtained by summing the rows of the adjacency matrix.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过求邻接矩阵的行和可以得到度数。
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Observe that (up to numerical error) there are two \(0\) eigenvalues and that
    the largest eigenvalue is greater or equal than the maximum degree plus one.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 观察（考虑到数值误差），存在两个 \(0\) 特征值，并且最大的特征值大于或等于最大度数加一。
- en: 'To compute the Laplacian matrix, one can also use the function [`networkx.laplacian_matrix`](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.laplacianmatrix.laplacian_matrix.html).
    For example, the Laplacian of the Petersen graph is the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算拉普拉斯矩阵，也可以使用函数 `networkx.laplacian_matrix`（https://networkx.org/documentation/stable/reference/generated/networkx.linalg.laplacianmatrix.laplacian_matrix.html）。例如，Petersen
    图的拉普拉斯矩阵如下：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: \(\unlhd\)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.4.3\. Variational characterization of second Laplacian eigenvalue[#](#variational-characterization-of-second-laplacian-eigenvalue
    "Link to this heading")
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.3\. 第二个拉普拉斯特征值的变分特征[\#](#variational-characterization-of-second-laplacian-eigenvalue
    "链接到这个标题")
- en: The definition \(A \mathbf{x} = \lambda \mathbf{x}\) is perhaps not the best
    way to understand why the eigenvectors of the Laplacian matrix are useful. Instead
    the following application of the *Courant-Fischer theorem*\(\idx{Courant-Fischer
    Theorem}\xdi\) provides much insight, as we will see in the rest of this chapter.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 \(A \mathbf{x} = \lambda \mathbf{x}\) 可能不是理解拉普拉斯矩阵的特征向量为什么有用的最佳方式。相反，以下对
    *Courant-Fischer 定理* 的应用\(\idx{Courant-Fischer Theorem}\xdi\)提供了很多见解，正如我们将在本章的其余部分看到的那样。
- en: '**THEOREM** **(Variational Characterization of \(\mu_2\))** \(\idx{variational
    characterization of the algebraic connectivity}\xdi\) Let \(G = (V, E)\) be a
    graph with \(n = |V|\) vertices. Assume the Laplacian \(L\) of \(G\) has spectral
    decomposition \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T\) with \(0
    = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) and \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\).
    Then'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(第二个 \(\mu_2\) 的变分特征)** \(\idx{变分特征}\xdi\) 设 \(G = (V, E)\) 是一个有 \(n
    = |V|\) 个顶点的图。假设 \(G\) 的拉普拉斯 \(L\) 有谱分解 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i
    \mathbf{y}_i^T\)，其中 \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) 且 \(\mathbf{y}_1
    = \frac{1}{\sqrt{n}}(1,\ldots,1)\)。那么'
- en: '\[\begin{align*} \mu_2 = \min\left\{ \sum_{\{i, j\} \in E}(x_i - x_j)^2 \,:
    \,\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{j
    = 1}^n x_j^2=1 \right\}. \end{align*}\]'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\begin{align*} \mu_2 = \min\left\{ \sum_{\{i, j\} \in E}(x_i - x_j)^2 \,:
    \,\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{j
    = 1}^n x_j^2=1 \right\}. \end{align*}\]'
- en: Taking \(\mathbf{x} = \mathbf{y}_2\) achieves this minimum. \(\sharp\)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\mathbf{x} = \mathbf{y}_2\) 达到这个最小值。\(\sharp\)
- en: '*Proof:* By the *Courant-Fischer Theorem*,'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 根据 *Courant-Fischer 定理*，'
- en: \[ \mu_2 = \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u}),
    \]
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u}),
    \]
- en: where \(\mathcal{V}_{n-1} = \mathrm{span}(\mathbf{y}_2, \ldots, \mathbf{y}_n)
    = \mathrm{span}(\mathbf{y}_1)^\perp\). Observe that, because we reverse the order
    of the eigenvalues compared to the convention used in the *Courant-Fischer theorem*,
    we must adapt the definition of \(\mathcal{V}_{n-1}\) slightly. Moreover we know
    that \(\mathcal{R}_L(\mathbf{y}_2) = \mu_2\). We make a simple transformation
    of the problem.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathcal{V}_{n-1} = \mathrm{span}(\mathbf{y}_2, \ldots, \mathbf{y}_n) =
    \mathrm{span}(\mathbf{y}_1)^\perp\). 注意，因为我们与 *Courant-Fischer 定理* 中使用的惯例相比反转了特征值的顺序，我们必须稍微调整
    \(\mathcal{V}_{n-1}\) 的定义。此外，我们知道 \(\mathcal{R}_L(\mathbf{y}_2) = \mu_2\)。我们对问题进行简单的变换。
- en: We claim that
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称
- en: \[ \mu_2 = \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \qquad (*) \]
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \qquad (*) \]
- en: Indeed, if \(\mathbf{u} \in \mathrm{span}(\mathbf{y}_1)^\perp\) has unit norm,
    i.e., \(\|\mathbf{u}\| = 1\), then
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果 \(\mathbf{u} \in \mathrm{span}(\mathbf{y}_1)^\perp\) 且具有单位范数，即 \(\|\mathbf{u}\|
    = 1\)，那么
- en: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \langle \mathbf{u}, L \mathbf{u}\rangle. \]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \langle \mathbf{u}, L \mathbf{u}\rangle. \]
- en: In other words, we shown that
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们已经证明了
- en: \[ \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u})
    \leq \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u})
    \leq \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \]
- en: To prove the other direction, for any \(\mathbf{u} \neq \mathbf{0}\), we can
    normalize it by defining \(\mathbf{x} = \mathbf{u}/\|\mathbf{u}\|\) and we note
    that
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明另一个方向，对于任何 \(\mathbf{u} \neq \mathbf{0}\)，我们可以通过定义 \(\mathbf{x} = \mathbf{u}/\|\mathbf{u}\|\)
    来归一化它，并且我们注意到
- en: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \left\langle \frac{\mathbf{u}}{\|\mathbf{u}\|}, L \frac{\mathbf{u}}{\|\mathbf{u}\|}\right\rangle
    = \langle \mathbf{x}, L \mathbf{x}\rangle. \]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \left\langle \frac{\mathbf{u}}{\|\mathbf{u}\|}, L \frac{\mathbf{u}}{\|\mathbf{u}\|}\right\rangle
    = \langle \mathbf{x}, L \mathbf{x}\rangle. \]
- en: Moreover \(\langle \mathbf{u}, \mathbf{y}_1\rangle = 0\) if only if \(\langle
    \mathbf{x}, \mathbf{y}_1\rangle = 0\). That establishes \((*)\), since any objective
    value achieved in the original formulation can be achieved in the new one.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果且仅当 \(\langle \mathbf{x}, \mathbf{y}_1\rangle = 0\) 时，\(\langle \mathbf{u},
    \mathbf{y}_1\rangle = 0\)。这确立了 \((*)\)，因为原始公式中实现的任何目标值都可以在新公式中实现。
- en: Using that \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\), the condition
    \(\langle \mathbf{x}, \mathbf{y}_1 \rangle = 0\), i.e., \(\sum_{i=1}^n (x_i/\sqrt{n})
    = 0\), is equivalent to \(\sum_{i=1}^n x_i = 0\). Similary, the condition \(\|\mathbf{x}\|=1\)
    is equivalent, after squaring each side, to \(\sum_{j=1}^n x_j^2 = 1\).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\)，条件 \(\langle \mathbf{x},
    \mathbf{y}_1 \rangle = 0\)，即 \(\sum_{i=1}^n (x_i/\sqrt{n}) = 0\)，等价于 \(\sum_{i=1}^n
    x_i = 0\)。同样，条件 \(\|\mathbf{x}\|=1\) 在平方每一边后等价于 \(\sum_{j=1}^n x_j^2 = 1\)。
- en: Finally, the claim follows from the *Laplacian Quadratic Form Lemma*. \(\square\)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，根据 *拉普拉斯二次形式引理*，我们可以得出结论。 \(\square\)
- en: One application of this extremal characterization is the graph drawing heuristic
    we described previously. Consider the entries of the second Laplacian eigenvector
    \(\mathbf{y}_2\). Its entries are centered around \(0\) by the condition \(\langle
    \mathbf{y}_1, \mathbf{y}_2\rangle = 0\). Because it minimizes the following quantity
    over all centered unit vectors,
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这种极值特征的一个应用是我们之前描述的图绘制启发式方法。考虑第二个拉普拉斯特征向量 \(\mathbf{y}_2\) 的元素。由于条件 \(\langle
    \mathbf{y}_1, \mathbf{y}_2\rangle = 0\)，其元素围绕 \(0\) 对齐。因为它在所有中心单位向量上最小化以下量，
- en: \[ \sum_{\{i, j\} \in E} (x_i - x_j)^2 \]
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\{i, j\} \in E} (x_i - x_j)^2 \]
- en: the eigenvector \(\mathbf{y}_2\) tends to assign similar coordinates to adjacent
    vertices. A similar reasoning applies to the third Laplacian eigenvector, which
    in addition is orthogonal to the second one. So coordinates based on the second
    and third Laplacian eigenvectors should be expected to position adjacent vertices
    close-by and hence minimizing the need for long-range edges in the visualization.
    In particular, it reveals some of the underlying Euclidean geometry of the graph,
    as the next example shows.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量 \(\mathbf{y}_2\) 倾向于为相邻顶点分配相似的坐标。类似的推理适用于第三个拉普拉斯特征向量，它还与第二个特征向量正交。因此，基于第二个和第三个拉普拉斯特征向量的坐标应该期望将相邻顶点放置在附近，从而最小化可视化中长距离边的需要。特别是，它揭示了图的一些潜在的欧几里得几何，如下一个示例所示。
- en: '**NUMERICAL CORNER:** This is perhaps easiest to see on a path graph. Recall
    that NetworkX numbers vertices \(0,\ldots,n-1\).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**NUMERICAL CORNER:** 这在路径图上可能最容易看出。回想一下，NetworkX 将顶点编号为 \(0,\ldots,n-1\)。'
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We plot the second Laplacian eigenvector (i.e., the eigenvector of the Laplacian
    matrix corresponding to the second smallest eigenvalue). We use [`numpy.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)
    to find the index of the second smallest eigenvalue. Because indices start at
    `0`, we want entry `1` of the output.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制第二个拉普拉斯特征向量（即对应于第二个最小特征值的拉普拉斯矩阵的特征向量）。我们使用 [numpy.argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)
    来找到第二个最小特征值的索引。因为索引从 `0` 开始，我们想要输出中的 `1` 个条目。
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![../../_images/c346aff858ca3853432ca68560966ff40a69ed45112737ae2d576de9ef3cebb7.png](../Images/aa1979a98f2c16cedc4afdcc1b494809.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/c346aff858ca3853432ca68560966ff40a69ed45112737ae2d576de9ef3cebb7.png](../Images/aa1979a98f2c16cedc4afdcc1b494809.png)'
- en: \(\unlhd\)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**EXAMPLE:** **(Two-Component Graph)** Let \(G=(V,E)\) be a graph with two
    connected components \(\emptyset \neq V_1, V_2 \subseteq V\). By the properties
    of connected components, we have \(V_1 \cap V_2 = \emptyset\) and \(V_1 \cup V_2
    = V\). Assume the Laplacian \(L\) of \(G\) has spectral decomposition \(L = \sum_{i=1}^n
    \mu_i \mathbf{y}_i \mathbf{y}_i^T\) with \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq
    \mu_n\) and \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\). We claimed earlier
    that for such a graph \(\mu_2 = 0\). We prove this here using the *Variational
    Characterization of \(\mu_2\)*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**EXAMPLE:** **(两分量图)** 设 \(G=(V,E)\) 是一个具有两个连通分量 \(\emptyset \neq V_1, V_2
    \subseteq V\) 的图。根据连通分量的性质，我们有 \(V_1 \cap V_2 = \emptyset\) 和 \(V_1 \cup V_2 =
    V\)。假设 \(G\) 的拉普拉斯矩阵 \(L\) 的谱分解为 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T\)，其中
    \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) 且 \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\)。我们之前声称对于这样的图
    \(\mu_2 = 0\)。我们在这里使用 *\(\mu_2\) 的变分特征* 来证明这一点。'
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2=1
    \right\}. \]
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2=1
    \right\}. \]
- en: Based on this characterization, it suffices to find a vector \(\mathbf{x}\)
    satisfying \(\sum_{u=1}^n x_u = 0\) and \(\sum_{u = 1}^n x_u^2=1\) such that \(\sum_{\{u,
    v\} \in E} (x_u - x_v)^2 = 0\). Indeed, since \(\mu_2 \geq 0\) and any such \(\mathbf{x}\)
    gives an upper bound on \(\mu_2\), we then necessarily have that \(\mu_2 = 0\).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此特征，只需找到一个向量 \(\mathbf{x}\) 满足 \(\sum_{u=1}^n x_u = 0\) 和 \(\sum_{u = 1}^n
    x_u^2=1\)，使得 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2 = 0\)。实际上，由于 \(\mu_2 \geq 0\)
    并且任何这样的 \(\mathbf{x}\) 都给出了 \(\mu_2\) 的上界，因此我们必然有 \(\mu_2 = 0\)。
- en: For \(\sum_{\{u, v\} \in E} (x_u - x_v)^2\) to be \(0\), one might be tempted
    to take a constant vector \(\mathbf{x}\). But then we could not satisfy \(\sum_{u=1}^n
    x_u = 0\) and \(\sum_{u = 1}^n x_u^2=1\) simultaneously. Instead, we modify this
    guess slightly. Because the graph has two connected components, there is no edge
    between \(V_1\) and \(V_2\). Hence we can assign a different value to each component
    and still get \(\sum_{\{u, v\} \in E} (x_u - x_v)^2 = 0\). So we look for a vector
    \(\mathbf{x} = (x_1, \ldots, x_n)\) of the form
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2\) 为 \(0\)，人们可能会倾向于取一个常数向量 \(\mathbf{x}\)。但这样我们就不能同时满足
    \(\sum_{u=1}^n x_u = 0\) 和 \(\sum_{u = 1}^n x_u^2=1\)。相反，我们稍微修改了这个猜测。因为图有两个连通分量，\(V_1\)
    和 \(V_2\) 之间没有边。因此，我们可以为每个分量分配不同的值，同时仍然得到 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2
    = 0\)。因此，我们寻找一个形式为 \(\mathbf{x} = (x_1, \ldots, x_n)\) 的向量
- en: \[\begin{split} x_u = \begin{cases} \alpha, & \text{if $u \in V_1$,}\\ \beta,
    & \text{if $u \in V_2$.} \end{cases} \end{split}\]
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} x_u = \begin{cases} \alpha, & \text{if $u \in V_1$,}\\ \beta,
    & \text{if $u \in V_2$.} \end{cases} \end{split}\]
- en: To satisfy the constraints on \(\mathbf{x}\), we require
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足 \(\mathbf{x}\) 的约束，我们需要
- en: \[ \sum_{u=1}^n x_u = \sum_{u \in V_1} \alpha + \sum_{u \in V_2} \beta = |V_1|
    \alpha + |V_2| \beta = 0, \]
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{u=1}^n x_u = \sum_{u \in V_1} \alpha + \sum_{u \in V_2} \beta = |V_1|
    \alpha + |V_2| \beta = 0, \]
- en: and
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \sum_{u=1}^n x_u^2 = \sum_{u \in V_1} \alpha^2 + \sum_{u \in V_2} \beta^2
    = |V_1| \alpha^2 + |V_2| \beta^2 = 1. \]
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{u=1}^n x_u^2 = \sum_{u \in V_1} \alpha^2 + \sum_{u \in V_2} \beta^2
    = |V_1| \alpha^2 + |V_2| \beta^2 = 1. \]
- en: Replacing the first equation in the second one, we get
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 用第二个方程中的第一个方程替换，我们得到
- en: \[ |V_1| \left(\frac{-|V_2|\beta}{|V_1|}\right)^2 + |V_2| \beta^2 = \frac{|V_2|^2
    \beta^2}{|V_1|} + |V_2| \beta^2 = 1, \]
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |V_1| \left(\frac{-|V_2|\beta}{|V_1|}\right)^2 + |V_2| \beta^2 = \frac{|V_2|^2
    \beta^2}{|V_1|} + |V_2| \beta^2 = 1, \]
- en: or
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: \[ \beta^2 = \frac{|V_1|}{|V_2|(|V_2| + |V_1|)} = \frac{|V_1|}{n |V_2|}. \]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \beta^2 = \frac{|V_1|}{|V_2|(|V_2| + |V_1|)} = \frac{|V_1|}{n |V_2|}. \]
- en: Take
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 取
- en: \[ \beta = - \sqrt{\frac{|V_1|}{n |V_2|}}, \qquad \alpha = \frac{-|V_2|\beta}{|V_1|}
    = \sqrt{\frac{|V_2|}{n |V_1|}}. \]
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \beta = - \sqrt{\frac{|V_1|}{n |V_2|}}, \qquad \alpha = \frac{-|V_2|\beta}{|V_1|}
    = \sqrt{\frac{|V_2|}{n |V_1|}}. \]
- en: The vector \(\mathbf{x}\) we constructed is in fact an eigenvector of \(L\).
    Indeed, let \(B\) be an oriented incidence matrix of \(G\). Then, for \(e_k =
    \{u,v\}\), \((B^T \mathbf{x})_k\) is either \(x_u - x_v\) or \(x_v - x_u\). In
    both cases, that is \(0\). So \(L \mathbf{x} = B B^T \mathbf{x} = \mathbf{0}\),
    that is, \(\mathbf{x}\) is an eigenvector of \(L\) with eigenvalue \(0\).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构造的向量 \(\mathbf{x}\) 实际上是 \(L\) 的特征向量。实际上，设 \(B\) 是 \(G\) 的有向关联矩阵。那么，对于 \(e_k
    = \{u,v\}\)，\((B^T \mathbf{x})_k\) 要么是 \(x_u - x_v\)，要么是 \(x_v - x_u\)。在两种情况下，都是
    \(0\)。所以 \(L \mathbf{x} = B B^T \mathbf{x} = \mathbf{0}\)，即 \(\mathbf{x}\) 是特征值为
    \(0\) 的特征向量。
- en: We have shown that \(\mu_2 = 0\) when \(G\) has two connected components. A
    slight modification of this argument shows that \(\mu_2 = 0\) whenever \(G\) is
    not connected. \(\lhd\)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经证明，当 \(G\) 有两个连通分量时，\(\mu_2 = 0\)。对这个论证的轻微修改表明，当 \(G\) 不连通时，\(\mu_2 = 0\)。\(\lhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(有克劳德、双子星和ChatGPT的帮助)*'
- en: '**1** Which of the following is NOT a property of the Laplacian matrix \(L\)
    of a graph \(G\)?'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 以下哪项不是图 \(G\) 的拉普拉斯矩阵 \(L\) 的性质？'
- en: a) \(L\) is symmetric.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(L\) 是对称的。
- en: b) \(L\) is positive semidefinite.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(L\) 是正半定。
- en: c) The constant unit vector \(\frac{1}{\sqrt{n}}(1,\ldots,1)\) is an eigenvector
    of \(L\) with eigenvalue 0.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: c) 常数单位向量 \(\frac{1}{\sqrt{n}}(1,\ldots,1)\) 是 \(L\) 的特征值为0的特征向量。
- en: d) \(L\) is positive definite.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(L\) 是正定。
- en: '**2** Which vector is known as the Fiedler vector?'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 哪个向量被称为Fiedler向量？'
- en: a) The eigenvector corresponding to the largest eigenvalue of the Laplacian
    matrix.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: a) 与拉普拉斯矩阵的最大特征值对应的特征向量。
- en: b) The eigenvector corresponding to the smallest eigenvalue of the Laplacian
    matrix.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: b) 与拉普拉斯矩阵的最小特征值对应的特征向量。
- en: c) The eigenvector corresponding to the second smallest eigenvalue of the Laplacian
    matrix.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: c) 与拉普拉斯矩阵的第二小特征值对应的特征向量。
- en: d) The eigenvector corresponding to the average of all eigenvalues of the Laplacian
    matrix.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: d) 与拉普拉斯矩阵所有特征值的平均值对应的特征向量。
- en: '**3** For a connected graph \(G\), which of the following statements about
    the second smallest eigenvalue \(\mu_2\) of its Laplacian matrix is true?'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 对于一个连通图 \(G\)，关于其拉普拉斯矩阵的第二个最小特征值 \(\mu_2\) 的以下哪个陈述是正确的？'
- en: a) \(\mu_2 = 0\)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\mu_2 = 0\)
- en: b) \(\mu_2 < 0\)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\mu_2 < 0\)
- en: c) \(\mu_2 > 0\)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mu_2 > 0\)
- en: d) The value of \(\mu_2\) cannot be determined without additional information.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: d) 没有附加信息，无法确定 \(\mu_2\) 的值。
- en: '**4** The Laplacian quadratic form \(\mathbf{x}^T L \mathbf{x}\) for a graph
    \(G\) with Laplacian matrix \(L\) can be written as:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 对于具有拉普拉斯矩阵 \(L\) 的图 \(G\)，拉普拉斯二次型 \(\mathbf{x}^T L \mathbf{x}\) 可以写成：'
- en: \[ \mathbf{x}^T L \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2. \]
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2. \]
- en: What does this quadratic form measure?
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这个二次型测量的是什么？
- en: a) The average distance between vertices in the graph.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: a) 图中顶点之间的平均距离。
- en: b) The number of connected components in the graph.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: b) 图中的连通分量数。
- en: c) The “smoothness” of the function \(x\) over the graph.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: c) 函数 \(x\) 在图上的“平滑度”。
- en: d) The degree of each vertex in the graph.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: d) 图中每个顶点的度数。
- en: '**5** The Laplacian matrix \(L\) of a graph \(G\) can be decomposed as \(L
    = B B^T\), where \(B\) is an oriented incidence matrix. What does this decomposition
    imply about \(L\)?'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 图 \(G\) 的拉普拉斯矩阵 \(L\) 可以分解为 \(L = B B^T\)，其中 \(B\) 是一个有向关联矩阵。这种分解对 \(L\)
    有什么含义？'
- en: a) \(L\) is positive definite
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(L\) 是正定的
- en: b) \(L\) is symmetric and positive semidefinite
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(L\) 是对称的且正半定的
- en: c) \(L\) is antisymmetric
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(L\) 是反对称的
- en: d) \(L\) is a diagonal matrix
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(L\) 是一个对角矩阵
- en: 'Answer for 1: d. Justification: The text states that “because \(L\) is positive
    semidefinite, the eigenvalues are nonnegative,” but it does not claim that \(L\)
    is positive definite.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 1 的答案：d. 理由：文本中提到“因为 \(L\) 是正半定的，所以特征值是非负的”，但没有断言 \(L\) 是正定的。
- en: 'Answer for 2: c. Justification: The text refers to the eigenvector corresponding
    to \(\mu_2\) (the second smallest eigenvalue) as the Fiedler vector.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 2 的答案：c. 理由：文本提到与 \(\mu_2\)（第二个最小特征值）对应的特征向量是 Fiedler 向量。
- en: 'Answer for 3: c. Justification: The text proves that “If \(G\) is connected,
    then the Laplacian eigenvalue \(\mu_2 > 0\).”'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 3 的答案：c. 理由：文本证明了“如果 \(G\) 是连通的，那么拉普拉斯特征值 \(\mu_2 > 0\)。”
- en: 'Answer for 4: c. Justification: The text states that “the Laplacian quadratic
    form measures how ‘smooth’ the function \(\mathbf{x}\) is over the graph in the
    following sense. A small value of \(\mathbf{x}^T L \mathbf{x}\) indicates that
    adjacent vertices tend to get assigned close values.”'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 4 的答案：c. 理由：文本中提到“拉普拉斯二次型测量函数 \(\mathbf{x}\) 在图上的‘平滑度’。 \(\mathbf{x}^T L \mathbf{x}\)
    的值较小表示相邻顶点倾向于被分配到接近的值。”
- en: 'Answer for 5: b. Justification: The text states, “Let \(B\) be an oriented
    incidence matrix of \(G\). By construction, \(L = B B^T\). This implies that \(L\)
    is symmetric and positive semidefinite.”'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 5 的答案：b. 理由：文本中提到，“设 \(B\) 为 \(G\) 的有向关联矩阵。根据构造，\(L = B B^T\)。这表明 \(L\) 是对称的且正半定的。”
- en: '5.4.1\. Eigenvalues of the Laplacian matrix: first observations[#](#eigenvalues-of-the-laplacian-matrix-first-observations
    "Link to this heading")'
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.1\. 拉普拉斯矩阵的特征值：初步观察[#](#eigenvalues-of-the-laplacian-matrix-first-observations
    "链接到这个标题")
- en: 'Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices. Two observations:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(G = (V, E)\) 是一个有 \(n = |V|\) 个顶点的图。两个观察：
- en: 1- Since the Laplacian matrix \(L\) of \(G\) is symmetric, by the *Spectral
    Theorem*, it has a spectral decomposition
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 由于 \(G\) 的拉普拉斯矩阵 \(L\) 是对称的，根据**谱定理**，它有一个谱分解
- en: \[ L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T \]
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T \]
- en: where the \(\mathbf{y}_i\)’s form an orthonormal basis of \(\mathbb{R}^n\).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{y}_i\) 形成了一个 \(\mathbb{R}^n\) 的正交基。
- en: 2- Further, because \(L\) is positive semidefinite, the eigenvalues are nonnegative.
    By convention, we assume
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 此外，由于 \(L\) 是正半定的，特征值是非负的。按照惯例，我们假设
- en: \[ 0 \leq \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n. \]
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 \leq \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n. \]
- en: Note that this is the opposite order to we used in the previous section.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这与我们之前章节中使用的顺序相反。
- en: 'Another observation:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察：
- en: '**LEMMA** Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices and Laplacian
    matrix \(L\). The constant unit vector'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 设 \(G = (V, E)\) 是一个有 \(n = |V|\) 个顶点和拉普拉斯矩阵 \(L\) 的图。常量单位向量'
- en: \[ \mathbf{y}_1 = \frac{1}{\sqrt{n}} (1, \ldots, 1) \]
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{y}_1 = \frac{1}{\sqrt{n}} (1, \ldots, 1) \]
- en: is an eigenvector of \(L\) with eigenvalue \(0\). \(\flat\)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 是 \(L\) 的一个特征向量，其特征值为 \(0\)。 \(\flat\)
- en: '*Proof:* Let \(B\) be an oriented incidence matrix of \(G\) recall that \(L
    = B B^T\). By construction \(B^T \mathbf{y}_1 = \mathbf{0}\) since each column
    of \(B\) has exactly one \(1\) and one \(-1\). So \(L \mathbf{y}_1 = B B^T \mathbf{y}_1
    = \mathbf{0}\) as claimed. \(\square\)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 设 \(B\) 为 \(G\) 的有向关联矩阵，回忆一下 \(L = B B^T\)。由于 \(B\) 的每一列恰好有一个 \(1\) 和一个
    \(-1\)，所以 \(B^T \mathbf{y}_1 = \mathbf{0}\)。因此 \(L \mathbf{y}_1 = B B^T \mathbf{y}_1
    = \mathbf{0}\)，正如所声称的那样。 \(\square\)'
- en: In general, the constant vector may not be the only eigenvector with eigenvalue
    one.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，常数向量可能不是唯一具有特征值一的特征向量。
- en: '**NUMERICAL CORNER:** One use of the spectral decomposition of the Laplacian
    matrix is in graph drawing\(\idx{graph drawing}\xdi\). We illustrate this next.
    Given a graph \(G = (V, E)\), it is not clear a priori how to draw it in the plane
    since the only information available are adjacencies of vertices. One approach
    is just to position the vertices at random. The function [`networkx.draw`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw.html)
    or [`networkx.draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html#networkx.drawing.nx_pylab.draw_networkx)
    can take as input different [graph layout](https://networkx.org/documentation/stable/reference/drawing.html#module-networkx.drawing.layout)
    functions that return an \(x\) and \(y\)-coordinate for each vertex.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 拉普拉斯矩阵的谱分解的一个用途是在图绘制中（\(\idx{graph drawing}\xdi\)）。我们接下来将展示这一点。给定一个图
    \(G = (V, E)\)，在平面上如何绘制它并不清楚，因为可用的唯一信息是顶点的邻接关系。一种方法是将顶点随机放置。函数 `networkx.draw`
    或 `networkx.draw_networkx` 可以接受不同的 [图布局](https://networkx.org/documentation/stable/reference/drawing.html#module-networkx.drawing.layout)
    函数作为输入，这些函数为每个顶点返回一个 \(x\) 和 \(y\) 坐标。'
- en: We will test this on a grid graph. We use [`networkx.grid_2d_graph`](https://networkx.org/documentation/stable/reference/generated/networkx.generators.lattice.grid_2d_graph.html)
    to construct such a graph.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在网格图上测试这一点。我们使用 `networkx.grid_2d_graph` 来构建这样的图。
- en: '[PRE19]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: One layout approach is to choose random locations for the nodes. Specifically,
    for every node, a position is generated by choosing each coordinate uniformly
    at random on the interval \([0,1]\).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 一种布局方法是选择节点的随机位置。具体来说，对于每个节点，通过在区间 \([0,1]\) 上随机选择每个坐标来生成一个位置。
- en: '[PRE20]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![../../_images/e71c11388af95019112c93563223107aea5d4aa3b91dbab26b654c57b7ad303b.png](../Images/f62f7cee4755a1c33c92335ca3d78f91.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e71c11388af95019112c93563223107aea5d4aa3b91dbab26b654c57b7ad303b.png](../Images/f62f7cee4755a1c33c92335ca3d78f91.png)'
- en: Clearly, this is hard to read.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这是难以阅读的。
- en: Another approach is to map the vertices to two eigenvectors, similarly to what
    we did for dimensionality reduction. The eigenvector associated to \(\mu_1\) is
    constant and therefore not useful for drawing. We try the next two. We use the
    Laplacian matrix. This is done using [`networkx.spectral_layout`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spectral_layout.html#networkx.drawing.layout.spectral_layout).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是映射顶点到两个特征向量，类似于我们为降维所做的那样。与 \(\mu_1\) 相关的特征向量是常数，因此对绘制没有用。我们尝试下一个两个。我们使用拉普拉斯矩阵。这是通过使用
    `networkx.spectral_layout` 实现的。
- en: '[PRE21]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![../../_images/d9f18189eb6a51676466d9a2ffe9aa688e95d0f15f8697b68ee0c7c9ae2ada45.png](../Images/0ecdf40ac77cc8a246dd3cb1077c885d.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/d9f18189eb6a51676466d9a2ffe9aa688e95d0f15f8697b68ee0c7c9ae2ada45.png](../Images/0ecdf40ac77cc8a246dd3cb1077c885d.png)'
- en: Interestingly, the outcome is provides a much more natural drawing of the graph,
    revealing its underlying structure as a grid. We will come back later to try to
    explain this, after we have developed further understanding of the spectral properties
    of the Laplacian matrix.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，结果提供了一个更自然的图绘制，揭示了其作为网格的潜在结构。我们将在以后回来尝试解释这一点，在我们对拉普拉斯矩阵的谱性质有了更深入的理解之后。
- en: \(\unlhd\)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.4.2\. Laplacian matrix and connectivity[#](#laplacian-matrix-and-connectivity
    "Link to this heading")
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.2\. 拉普拉斯矩阵与连通性[#](#laplacian-matrix-and-connectivity "链接到这个标题")
- en: As we indicated before, the Laplacian matrix contains information about the
    connectedness of \(G\). We elaborate on a first concrete connection here. But
    first we will need a useful form of the Laplaican quadratic form \(\mathbf{x}^T
    L \mathbf{x}\) which enters in the variational charaterization of the eigenvalues.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前指出的，拉普拉斯矩阵包含关于 \(G\) 的连通性的信息。我们在这里详细阐述第一个具体的联系。但首先我们需要拉普拉斯二次型 \(\mathbf{x}^T
    L \mathbf{x}\) 的一个有用形式，它进入特征值的变分表征。
- en: '**LEMMA** **(Laplacian Quadratic Form)** \(\idx{Laplacian quadratic form lemma}\xdi\)
    Let \(G = (V, E)\) be a graph with \(n = |V|\) vertices and Laplacian matrix \(L\).
    We have the following formula for the Laplacian quadratic form'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(拉普拉斯二次型)** \(\idx{拉普拉斯二次型引理}\xdi\) 设 \(G = (V, E)\) 是一个具有 \(n = |V|\)
    个顶点和拉普拉斯矩阵 \(L\) 的图。我们有以下关于拉普拉斯二次型的公式'
- en: \[ \mathbf{x}^T L \mathbf{x} = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2 \]
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2 \]
- en: for any \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\). \(\flat\)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何 \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\)。 \(\flat\)
- en: Here is an intuitive way of interpreting this lemma. If one thinks of \(\mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n\) as a real-valued function over the vertices
    (i.e., it associates a real value \(x_i\) to vertex \(i\) for each \(i\)), then
    the Laplacian quadratic form measures how “smooth” the function is over the graph
    in the following sense. A small value of \(\mathbf{x}^T L \mathbf{x}\) indicates
    that adjacent vertices tend to get assigned close values.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一种直观的方式来解释这个引理。如果将 \(\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n\) 视为顶点上的实值函数（即，它将每个
    \(i\) 的实值 \(x_i\) 与顶点 \(i\) 关联），那么拉普拉斯二次型测量函数在图上的“平滑”程度如下。 \(\mathbf{x}^T L \mathbf{x}\)
    的值较小表示相邻顶点倾向于被分配接近的值。
- en: '*Proof:* Let \(B\) be an oriented incidence matrix of \(G\). We have that \(L
    = B B^T\). Thus, for any \(\mathbf{x}\), we have \((B^T \mathbf{x})_k = x_v -
    x_u\) if the edge \(e_k = \{u, v\}\) is oriented as \((u,v)\) under \(B\). That
    implies'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 设 \(B\) 是 \(G\) 的一个有向关联矩阵。我们有 \(L = B B^T\)。因此，对于任何 \(\mathbf{x}\)，如果边
    \(e_k = \{u, v\}\) 在 \(B\) 下有向为 \((u,v)\)，则 \((B^T \mathbf{x})_k = x_v - x_u\)。这表明'
- en: \[ \mathbf{x}^T L \mathbf{x} = \mathbf{x}^T B B^T \mathbf{x} = \|B^T \mathbf{x}\|^2
    = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2. \]
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \mathbf{x}^T B B^T \mathbf{x} = \|B^T \mathbf{x}\|^2
    = \sum_{e = \{i,j\} \in E} (x_i - x_j)^2. \]
- en: Since the latter is always nonnegative, it also implies that \(L\) is positive
    semidefinite. \(\square\)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于后者始终非负，这也表明 \(L\) 是正半定的。 \(\square\)
- en: We are now ready to derive connectivity consequences. Recall that, for any graph
    \(G\), the Laplacian eigenvalue \(\mu_1 = 0\).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备推导出连通性的后果。回想一下，对于任何图 \(G\)，拉普拉斯特征值 \(\mu_1 = 0\)。
- en: '**LEMMA** **(Laplacian and Connectivity)** \(\idx{Laplacian and connectivity
    lemma}\xdi\) If \(G\) is connected, then the Laplacian eigenvalue \(\mu_2 > 0\).
    \(\flat\)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(拉普拉斯与连通性)** \(\idx{拉普拉斯与连通性引理}\xdi\) 如果 \(G\) 是连通的，那么拉普拉斯特征值 \(\mu_2
    > 0\)。 \(\flat\)'
- en: '*Proof:* Let \(G = (V, E)\) with \(n = |V|\) and let \(L = \sum_{i=1}^n \mu_i
    \mathbf{y}_i \mathbf{y}_i^T\) be a spectral decomposition of its Laplacian \(L\)
    with \(0 = \mu_1 \leq \cdots \leq \mu_n\). Suppose by way of contradiction that
    \(\mu_2 = 0\). Any eigenvector \(\mathbf{y} = (y_{1}, \ldots, y_{n})\) with \(0\)
    eigenvalue satisfies \(L \mathbf{y} = \mathbf{0}\) by definition. By the *Laplacian
    Quadratic Form Lemma* then'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 设 \(G = (V, E)\) 且 \(n = |V|\)，设 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i
    \mathbf{y}_i^T\) 是其拉普拉斯 \(L\) 的谱分解，其中 \(0 = \mu_1 \leq \cdots \leq \mu_n\)。假设通过反证法
    \(\mu_2 = 0\)。任何具有 \(0\) 特征值的特征向量 \(\mathbf{y} = (y_{1}, \ldots, y_{n})\) 根据定义满足
    \(L \mathbf{y} = \mathbf{0}\)。根据 *拉普拉斯二次型引理*，则'
- en: \[ 0 = \mathbf{y}^T L \mathbf{y} = \sum_{e = \{i, j\} \in E} (y_{i} - y_{j})^2.
    \]
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 0 = \mathbf{y}^T L \mathbf{y} = \sum_{e = \{i, j\} \in E} (y_{i} - y_{j})^2.
    \]
- en: 1- In order for this to hold, it must be that any two adjacent vertices \(i\)
    and \(j\) have \(y_{i} = y_{j}\). That is, \(\{i,j\} \in E\) implies \(y_i = y_j\).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 1- 为了使这一点成立，任何两个相邻顶点 \(i\) 和 \(j\) 必须有 \(y_{i} = y_{j}\)。也就是说，\(\{i,j\} \in
    E\) 意味着 \(y_i = y_j\)。
- en: 2- Furthermore, because \(G\) is connected, between any two of its vertices
    \(u\) and \(v\) - adjacent or not - there is a path \(u = w_0 \sim \cdots \sim
    w_k = v\) along which the \(y_{w}\)’s must be the same. Thus \(\mathbf{y}\) is
    a constant vector.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 2- 此外，因为 \(G\) 是连通的，所以它的任意两个顶点 \(u\) 和 \(v\)（相邻或不相邻）之间都存在一条路径 \(u = w_0 \sim
    \cdots \sim w_k = v\)，沿着这条路径 \(y_{w}\) 必须相同。因此 \(\mathbf{y}\) 是一个常数向量。
- en: But that is a contradiction since the eigenvectors \(\mathbf{y}_1, \ldots, \mathbf{y}_n\)
    are in fact linearly independent, so that \(\mathbf{y}_1\) and \(\mathbf{y}_2\)
    cannot both be a constant vector. \(\square\)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 但这是矛盾的，因为特征向量 \(\mathbf{y}_1, \ldots, \mathbf{y}_n\) 实际上是线性无关的，因此 \(\mathbf{y}_1\)
    和 \(\mathbf{y}_2\) 不能同时是常数向量。\(\square\)
- en: The quantity \(\mu_2\) is sometimes referred to as the [algebraic connectivity](https://mathworld.wolfram.com/AlgebraicConnectivity.html)\(\idx{algebraic
    connectivity}\xdi\) of the graph. The corresponding eigenvector, \(\mathbf{y}_2\),
    is known as the [Fiedler vector](https://mathworld.wolfram.com/FiedlerVector.html)\(\idx{Fiedler
    vector}\xdi\).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 量 \(\mu_2\) 有时被称为图的 [代数连通性](https://mathworld.wolfram.com/AlgebraicConnectivity.html)\(\idx{代数连通性}\xdi\)。相应的特征向量，\(\mathbf{y}_2\)，被称为
    [Fiedler 向量](https://mathworld.wolfram.com/FiedlerVector.html)\(\idx{Fiedler 向量}\xdi\)。
- en: We state the following (more general) converse result without proof.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以下述（更一般的）逆命题陈述，而不加证明。
- en: '**LEMMA** If \(\mu_{k+1}\) is the smallest nonzero Laplacian eigenvalue of
    \(G\), then \(G\) has \(k\) connected components. \(\flat\)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 如果 \(\mu_{k+1}\) 是 \(G\) 的最小的非零拉普拉斯特征值，那么 \(G\) 有 \(k\) 个连通分量。\(\flat\)'
- en: We will be interested in more quantitative results of this type. Before proceeding,
    we start with a simple observation. By our proof of the *Spectral Theorem*, the
    largest eigenvalue \(\mu_n\) of the Laplacian matrix \(L\) is the solution to
    the optimization problem
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对此类更定量的结果感兴趣。在继续之前，我们从一个简单的观察开始。根据我们证明的 *谱定理*，拉普拉斯矩阵 \(L\) 的最大特征值 \(\mu_n\)
    是优化问题的解
- en: \[ \mu_n = \max\{\langle \mathbf{x}, L \mathbf{x}\rangle:\|\mathbf{x}\| = 1\}.
    \]
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_n = \max\{\langle \mathbf{x}, L \mathbf{x}\rangle:\|\mathbf{x}\| = 1\}.
    \]
- en: Such extremal characterization is useful in order to bound the eigenvalue \(\mu_n\),
    since any choice of \(\mathbf{x}\) with \(\|\mathbf{x}\| =1\) gives a lower bound
    through the quantity \(\langle \mathbf{x}, L \mathbf{x}\rangle\). That perspective
    will be key to our application to graph partitioning.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这种极值特征化对于界定特征值 \(\mu_n\) 是有用的，因为任何选择 \(\mathbf{x}\) 且 \(\|\mathbf{x}\| =1\)
    都可以通过量 \(\langle \mathbf{x}, L \mathbf{x}\rangle\) 给出一个下界。这种观点将是我们应用于图划分的关键。
- en: For now, we give a simple consequence.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们给出一个简单的结论。
- en: '**LEMMA** **(Laplacian and Maximum Degree)** \(\idx{Laplacian and maximum degree
    lemma}\xdi\) Let \(G = (V, E)\) be a graph with maximum degree \(\bar{\delta}\).
    Let \(\mu_n\) be the largest eigenvalue of its Laplacian matrix \(L\). Then'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(拉普拉斯矩阵与最大度)** \(\idx{拉普拉斯矩阵与最大度引理}\xdi\) 设 \(G = (V, E)\) 是一个最大度为
    \(\bar{\delta}\) 的图。设 \(\mu_n\) 是其拉普拉斯矩阵 \(L\) 的最大特征值。那么'
- en: \[ \bar{\delta}+1 \leq \mu_n \leq 2 \bar{\delta}. \]
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{\delta}+1 \leq \mu_n \leq 2 \bar{\delta}. \]
- en: \(\flat\)
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof idea:* As explained before the statement of the lemma, for the lower
    bound it suffices to find a good test unit vector \(\mathbf{x}\) to plug into
    \(\langle \mathbf{x}, L \mathbf{x}\rangle\). A clever choice does the trick.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 如引理陈述之前所解释的，对于下界，找到一个好的测试单位向量 \(\mathbf{x}\) 插入到 \(\langle \mathbf{x},
    L \mathbf{x}\rangle\) 中就足够了。一个巧妙的选择就能解决问题。'
- en: '*Proof:* We start with the lower bound. Let \(u \in V\) be a vertex with degree
    \(\bar{\delta}\). Let \(\mathbf{z}\) be the vector with entries'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 我们从下界开始。设 \(u \in V\) 是一个度数为 \(\bar{\delta}\) 的顶点。设 \(\mathbf{z}\) 是一个具有条目的向量'
- en: \[\begin{split} z_i = \begin{cases} \bar{\delta} & \text{if $i = u$}\\ -1 &
    \text{if $\{i,u\} \in E$}\\ 0 & \text{o.w.} \end{cases} \end{split}\]
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} z_i = \begin{cases} \bar{\delta} & \text{if } i = u\\ -1 & \text{if
    } \{i,u\} \in E\\ 0 & \text{o.w.} \end{cases} \end{split}\]
- en: and let \(\mathbf{x}\) be the unit vector \(\mathbf{z}/\|\mathbf{z}\|\). By
    definition of the degree of \(u\), \(\|\mathbf{z}\|^2 = \bar{\delta}^2 + \bar{\delta}(-1)^2
    = \bar{\delta}(\bar{\delta}+1)\). Using the *Laplacian Quadratic Form Lemma*,
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 并且设 \(\mathbf{x}\) 为单位向量 \(\mathbf{z}/\|\mathbf{z}\|\)。根据 \(u\) 的度数的定义，\(\|\mathbf{z}\|^2
    = \bar{\delta}^2 + \bar{\delta}(-1)^2 = \bar{\delta}(\bar{\delta}+1)\)。使用 *拉普拉斯二次型引理*，
- en: '\[ \langle \mathbf{z}, L \mathbf{z}\rangle = \sum_{e = \{i, j\} \in E} (z_i
    - z_j)^2 \geq \sum_{i: \{i, u\} \in E} (z_i - z_u)^2 = \sum_{i: \{i, u\} \in E}
    (-1 - \bar{\delta})^2 = \bar{\delta} (\bar{\delta}+1)^2 \]'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \langle \mathbf{z}, L \mathbf{z}\rangle = \sum_{e = \{i, j\} \in E} (z_i
    - z_j)^2 \geq \sum_{i: \{i, u\} \in E} (z_i - z_u)^2 = \sum_{i: \{i, u\} \in E}
    (-1 - \bar{\delta})^2 = \bar{\delta} (\bar{\delta}+1)^2 \]'
- en: where we restricted the sum to those edges incident with \(u\) and used the
    fact that all terms in the sum are nonnegative. Finally
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们限制和仅限于与 \(u\) 相邻的边，并利用和中的所有项都是非负的事实。最后
- en: \[ \langle \mathbf{x}, L \mathbf{x}\rangle = \left\langle \frac{\mathbf{z}}{\|\mathbf{z}\|},
    L \frac{\mathbf{z}}{\|\mathbf{z}\|}\right\rangle = \frac{1}{\|\mathbf{z}\|^2}
    \langle \mathbf{z}, L \mathbf{z}\rangle = \frac{\bar{\delta} (\bar{\delta}+1)^2}{\bar{\delta}(\bar{\delta}+1)}
    = \bar{\delta}+1 \]
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{x}, L \mathbf{x}\rangle = \left\langle \frac{\mathbf{z}}{\|\mathbf{z}\|},
    L \frac{\mathbf{z}}{\|\mathbf{z}\|}\right\rangle = \frac{1}{\|\mathbf{z}\|^2}
    \langle \mathbf{z}, L \mathbf{z}\rangle = \frac{\bar{\delta} (\bar{\delta}+1)^2}{\bar{\delta}(\bar{\delta}+1)}
    = \bar{\delta}+1 \]
- en: so that
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 因此
- en: \[ \mu_n = \max\{\langle \mathbf{x}', L \mathbf{x}'\rangle:\|\mathbf{x}'\| =
    1\} \geq \langle \mathbf{x}, L \mathbf{x}\rangle = \bar{\delta}+1 \]
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_n = \max\{\langle \mathbf{x}', L \mathbf{x}'\rangle:\|\mathbf{x}'\| =
    1\} \geq \langle \mathbf{x}, L \mathbf{x}\rangle = \bar{\delta}+1 \]
- en: as claimed.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如所证明。
- en: We proceed with the lower bound. For any unit vector \(\mathbf{x}\),
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续进行下界。对于任何单位向量 \(\mathbf{x}\)，
- en: \[\begin{align*} \langle \mathbf{x}, L \mathbf{x}\rangle &= \sum_{i,j} L_{ij}
    x_i x_j\\ &\leq \sum_{i,j} |L_{ij}| |x_i| |x_j|\\ &= \sum_{i,j} (D_{ij} + A_{ij})
    |x_i| |x_j|\\ &= \sum_{i} \delta(i) \,x_i^2 + \sum_{i,j} A_{ij} |x_i| |x_j|. \end{align*}\]
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \langle \mathbf{x}, L \mathbf{x}\rangle &= \sum_{i,j} L_{ij}
    x_i x_j\\ &\leq \sum_{i,j} |L_{ij}| |x_i| |x_j|\\ &= \sum_{i,j} (D_{ij} + A_{ij})
    |x_i| |x_j|\\ &= \sum_{i} \delta(i) \,x_i^2 + \sum_{i,j} A_{ij} |x_i| |x_j|. \end{align*}\]
- en: By the *Cauchy-Schwarz inequality*, this is
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 根据**柯西-施瓦茨不等式**，这可以表示为
- en: \[\begin{align*} &\leq \bar{\delta} + \left(\sum_{i,j} A_{ij} x_i^2\right)^{1/2}
    \left(\sum_{i,j} A_{ij} x_j^2\right)^{1/2}\\ &\leq \bar{\delta} + \left( \bar{\delta}
    \sum_{i} x_i^2\right)^{1/2} \left(\bar{\delta} \sum_{j} x_j^2\right)^{1/2}\\ &\leq
    2\bar{\delta}. \end{align*}\]
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\leq \bar{\delta} + \left(\sum_{i,j} A_{ij} x_i^2\right)^{1/2}
    \left(\sum_{i,j} A_{ij} x_j^2\right)^{1/2}\\ &\leq \bar{\delta} + \left( \bar{\delta}
    \sum_{i} x_i^2\right)^{1/2} \left(\bar{\delta} \sum_{j} x_j^2\right)^{1/2}\\ &\leq
    2\bar{\delta}. \end{align*}\]
- en: \(\square\)
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: \(\square\)
- en: '**NUMERICAL CORNER:** We construct a graph with two connected components and
    check the results above. We work directly with the adjacency matrix.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 我们构建一个有两个连通分量的图并检查上述结果。我们直接使用邻接矩阵。'
- en: '[PRE22]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note the block structure.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到块结构。
- en: The degrees can be obtained by summing the rows of the adjacency matrix.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过求邻接矩阵的行和来获得度数。
- en: '[PRE24]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Observe that (up to numerical error) there are two \(0\) eigenvalues and that
    the largest eigenvalue is greater or equal than the maximum degree plus one.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到（考虑到数值误差）有两个 \(0\) 特征值，并且最大的特征值大于或等于最大度数加一。
- en: 'To compute the Laplacian matrix, one can also use the function [`networkx.laplacian_matrix`](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.laplacianmatrix.laplacian_matrix.html).
    For example, the Laplacian of the Petersen graph is the following:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算拉普拉斯矩阵，也可以使用函数[`networkx.laplacian_matrix`](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.laplacianmatrix.laplacian_matrix.html)。例如，Petersen
    图的拉普拉斯矩阵如下：
- en: '[PRE32]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: \(\unlhd\)
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.4.3\. Variational characterization of second Laplacian eigenvalue[#](#variational-characterization-of-second-laplacian-eigenvalue
    "Link to this heading")
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4.3\. 第二个拉普拉斯特征值的变分特征化[#](#variational-characterization-of-second-laplacian-eigenvalue
    "链接到这个标题")
- en: The definition \(A \mathbf{x} = \lambda \mathbf{x}\) is perhaps not the best
    way to understand why the eigenvectors of the Laplacian matrix are useful. Instead
    the following application of the *Courant-Fischer theorem*\(\idx{Courant-Fischer
    Theorem}\xdi\) provides much insight, as we will see in the rest of this chapter.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 \(A \mathbf{x} = \lambda \mathbf{x}\) 可能不是理解拉普拉斯矩阵特征向量有用性的最佳方式。相反，以下对**Courant-Fischer
    定理**\(\idx{Courant-Fischer Theorem}\xdi\)的应用提供了许多见解，正如我们将在本章的其余部分看到的那样。
- en: '**THEOREM** **(Variational Characterization of \(\mu_2\))** \(\idx{variational
    characterization of the algebraic connectivity}\xdi\) Let \(G = (V, E)\) be a
    graph with \(n = |V|\) vertices. Assume the Laplacian \(L\) of \(G\) has spectral
    decomposition \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T\) with \(0
    = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) and \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\).
    Then'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** **(变分特征化 \(\mu_2\))** \(\idx{variational characterization of the algebraic
    connectivity}\xdi\) 设 \(G = (V, E)\) 是一个有 \(n = |V|\) 个顶点的图。假设 \(G\) 的拉普拉斯矩阵 \(L\)
    的谱分解为 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T\)，其中 \(0 = \mu_1 \leq
    \mu_2 \leq \cdots \leq \mu_n\) 且 \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\)。那么'
- en: '\[\begin{align*} \mu_2 = \min\left\{ \sum_{\{i, j\} \in E}(x_i - x_j)^2 \,:
    \,\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{j
    = 1}^n x_j^2=1 \right\}. \end{align*}\]'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\begin{align*} \mu_2 = \min\left\{ \sum_{\{i, j\} \in E}(x_i - x_j)^2 \,:
    \,\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{j
    = 1}^n x_j^2=1 \right\}. \end{align*}\]'
- en: Taking \(\mathbf{x} = \mathbf{y}_2\) achieves this minimum. \(\sharp\)
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 取 \(\mathbf{x} = \mathbf{y}_2\) 可以达到这个最小值。\(\sharp\)
- en: '*Proof:* By the *Courant-Fischer Theorem*,'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 通过 *Courant-Fischer 定理*，'
- en: \[ \mu_2 = \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u}),
    \]
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u}),
    \]
- en: where \(\mathcal{V}_{n-1} = \mathrm{span}(\mathbf{y}_2, \ldots, \mathbf{y}_n)
    = \mathrm{span}(\mathbf{y}_1)^\perp\). Observe that, because we reverse the order
    of the eigenvalues compared to the convention used in the *Courant-Fischer theorem*,
    we must adapt the definition of \(\mathcal{V}_{n-1}\) slightly. Moreover we know
    that \(\mathcal{R}_L(\mathbf{y}_2) = \mu_2\). We make a simple transformation
    of the problem.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathcal{V}_{n-1} = \mathrm{span}(\mathbf{y}_2, \ldots, \mathbf{y}_n) =
    \mathrm{span}(\mathbf{y}_1)^\perp\)。观察一下，因为我们与 *Courant-Fischer 定理* 中使用的惯例相比反转了特征值的顺序，我们必须稍微调整
    \(\mathcal{V}_{n-1}\) 的定义。此外，我们知道 \(\mathcal{R}_L(\mathbf{y}_2) = \mu_2\)。我们对问题进行简单的转换。
- en: We claim that
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称
- en: \[ \mu_2 = \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \qquad (*) \]
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \qquad (*) \]
- en: Indeed, if \(\mathbf{u} \in \mathrm{span}(\mathbf{y}_1)^\perp\) has unit norm,
    i.e., \(\|\mathbf{u}\| = 1\), then
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果 \(\mathbf{u} \in \mathrm{span}(\mathbf{y}_1)^\perp\) 且具有单位范数，即 \(\|\mathbf{u}\|
    = 1\)，那么
- en: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \langle \mathbf{u}, L \mathbf{u}\rangle. \]
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \langle \mathbf{u}, L \mathbf{u}\rangle. \]
- en: In other words, we shown that
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们证明了
- en: \[ \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u})
    \leq \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \]
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\mathbf{0} \neq \mathbf{u} \in \mathcal{V}_{n-1}} \mathcal{R}_L(\mathbf{u})
    \leq \min\left\{\langle \mathbf{x}, L \mathbf{x}\rangle\,:\ \|\mathbf{x}\|=1,
    \langle \mathbf{x}, \mathbf{y}_1\rangle = 0 \right\}. \]
- en: To prove the other direction, for any \(\mathbf{u} \neq \mathbf{0}\), we can
    normalize it by defining \(\mathbf{x} = \mathbf{u}/\|\mathbf{u}\|\) and we note
    that
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明另一个方向，对于任何 \(\mathbf{u} \neq \mathbf{0}\)，我们可以通过定义 \(\mathbf{x} = \mathbf{u}/\|\mathbf{u}\|\)
    来归一化它，并且我们注意到
- en: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \left\langle \frac{\mathbf{u}}{\|\mathbf{u}\|}, L \frac{\mathbf{u}}{\|\mathbf{u}\|}\right\rangle
    = \langle \mathbf{x}, L \mathbf{x}\rangle. \]
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{R}_L(\mathbf{u}) = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\langle
    \mathbf{u},\mathbf{u}\rangle} = \frac{\langle \mathbf{u}, L \mathbf{u}\rangle}{\|\mathbf{u}\|^2}
    = \left\langle \frac{\mathbf{u}}{\|\mathbf{u}\|}, L \frac{\mathbf{u}}{\|\mathbf{u}\|}\right\rangle
    = \langle \mathbf{x}, L \mathbf{x}\rangle. \]
- en: Moreover \(\langle \mathbf{u}, \mathbf{y}_1\rangle = 0\) if only if \(\langle
    \mathbf{x}, \mathbf{y}_1\rangle = 0\). That establishes \((*)\), since any objective
    value achieved in the original formulation can be achieved in the new one.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果且仅当 \(\langle \mathbf{x}, \mathbf{y}_1\rangle = 0\)，则 \(\langle \mathbf{u},
    \mathbf{y}_1\rangle = 0\)。这确立了 \((*)\)，因为原始公式中实现的任何目标值都可以在新公式中实现。
- en: Using that \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\), the condition
    \(\langle \mathbf{x}, \mathbf{y}_1 \rangle = 0\), i.e., \(\sum_{i=1}^n (x_i/\sqrt{n})
    = 0\), is equivalent to \(\sum_{i=1}^n x_i = 0\). Similary, the condition \(\|\mathbf{x}\|=1\)
    is equivalent, after squaring each side, to \(\sum_{j=1}^n x_j^2 = 1\).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\)，条件 \(\langle \mathbf{x},
    \mathbf{y}_1 \rangle = 0\)，即 \(\sum_{i=1}^n (x_i/\sqrt{n}) = 0\)，等价于 \(\sum_{i=1}^n
    x_i = 0\)。类似地，条件 \(\|\mathbf{x}\|=1\) 在平方每一边后等价于 \(\sum_{j=1}^n x_j^2 = 1\)。
- en: Finally, the claim follows from the *Laplacian Quadratic Form Lemma*. \(\square\)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个结论源于 *拉普拉斯二次型引理*。 \(\square\)
- en: One application of this extremal characterization is the graph drawing heuristic
    we described previously. Consider the entries of the second Laplacian eigenvector
    \(\mathbf{y}_2\). Its entries are centered around \(0\) by the condition \(\langle
    \mathbf{y}_1, \mathbf{y}_2\rangle = 0\). Because it minimizes the following quantity
    over all centered unit vectors,
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这种极值特征的一个应用是我们之前描述的图绘制启发式方法。考虑第二个拉普拉斯特征向量 \(\mathbf{y}_2\) 的元素。由于 \(\langle
    \mathbf{y}_1, \mathbf{y}_2\rangle = 0\) 的条件，这些元素围绕 \(0\) 中心化。因为它在所有中心化单位向量上最小化以下量，
- en: \[ \sum_{\{i, j\} \in E} (x_i - x_j)^2 \]
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{\{i, j\} \in E} (x_i - x_j)^2 \]
- en: the eigenvector \(\mathbf{y}_2\) tends to assign similar coordinates to adjacent
    vertices. A similar reasoning applies to the third Laplacian eigenvector, which
    in addition is orthogonal to the second one. So coordinates based on the second
    and third Laplacian eigenvectors should be expected to position adjacent vertices
    close-by and hence minimizing the need for long-range edges in the visualization.
    In particular, it reveals some of the underlying Euclidean geometry of the graph,
    as the next example shows.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量 \(\mathbf{y}_2\) 趋于将相似的坐标分配给相邻的顶点。类似的推理适用于第三个拉普拉斯特征向量，它还与第二个特征向量正交。因此，基于第二个和第三个拉普拉斯特征向量的坐标应该期望将相邻顶点放置在附近，从而最小化可视化中长距离边的需求。特别是，它揭示了图的一些潜在的欧几里得几何，如下一个示例所示。
- en: '**NUMERICAL CORNER:** This is perhaps easiest to see on a path graph. Recall
    that NetworkX numbers vertices \(0,\ldots,n-1\).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 这在路径图中可能最容易看出。回想一下，NetworkX 对顶点进行编号 \(0,\ldots,n-1\)。'
- en: '[PRE36]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We plot the second Laplacian eigenvector (i.e., the eigenvector of the Laplacian
    matrix corresponding to the second smallest eigenvalue). We use [`numpy.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)
    to find the index of the second smallest eigenvalue. Because indices start at
    `0`, we want entry `1` of the output.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制第二个拉普拉斯特征向量（即对应于第二个最小特征值的拉普拉斯矩阵的特征向量）。我们使用 `numpy.argsort`（https://numpy.org/doc/stable/reference/generated/numpy.argsort.html）来找到第二个最小特征值的索引。因为索引从
    `0` 开始，我们想要输出中的 `1` 个条目。
- en: '[PRE37]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![../../_images/c346aff858ca3853432ca68560966ff40a69ed45112737ae2d576de9ef3cebb7.png](../Images/aa1979a98f2c16cedc4afdcc1b494809.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/c346aff858ca3853432ca68560966ff40a69ed45112737ae2d576de9ef3cebb7.png](../Images/aa1979a98f2c16cedc4afdcc1b494809.png)'
- en: \(\unlhd\)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**EXAMPLE:** **(Two-Component Graph)** Let \(G=(V,E)\) be a graph with two
    connected components \(\emptyset \neq V_1, V_2 \subseteq V\). By the properties
    of connected components, we have \(V_1 \cap V_2 = \emptyset\) and \(V_1 \cup V_2
    = V\). Assume the Laplacian \(L\) of \(G\) has spectral decomposition \(L = \sum_{i=1}^n
    \mu_i \mathbf{y}_i \mathbf{y}_i^T\) with \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq
    \mu_n\) and \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\). We claimed earlier
    that for such a graph \(\mu_2 = 0\). We prove this here using the *Variational
    Characterization of \(\mu_2\)*'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**: **（双连通分量图**）设 \(G=(V,E)\) 是一个有两个连通分量 \(\emptyset \neq V_1, V_2 \subseteq
    V\) 的图。根据连通分量的性质，我们有 \(V_1 \cap V_2 = \emptyset\) 和 \(V_1 \cup V_2 = V\)。假设 \(G\)
    的拉普拉斯 \(L\) 有谱分解 \(L = \sum_{i=1}^n \mu_i \mathbf{y}_i \mathbf{y}_i^T\)，其中 \(0
    = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) 且 \(\mathbf{y}_1 = \frac{1}{\sqrt{n}}(1,\ldots,1)\)。我们之前声称对于这样的图
    \(\mu_2 = 0\)。我们在这里使用 \(*\mu_2 的变分描述*\) 来证明这一点。'
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2=1
    \right\}. \]
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2=1
    \right\}. \]
- en: Based on this characterization, it suffices to find a vector \(\mathbf{x}\)
    satisfying \(\sum_{u=1}^n x_u = 0\) and \(\sum_{u = 1}^n x_u^2=1\) such that \(\sum_{\{u,
    v\} \in E} (x_u - x_v)^2 = 0\). Indeed, since \(\mu_2 \geq 0\) and any such \(\mathbf{x}\)
    gives an upper bound on \(\mu_2\), we then necessarily have that \(\mu_2 = 0\).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这种描述，我们只需要找到一个向量 \(\mathbf{x}\)，它满足 \(\sum_{u=1}^n x_u = 0\) 和 \(\sum_{u =
    1}^n x_u^2=1\)，并且使得 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2 = 0\)。确实，由于 \(\mu_2
    \geq 0\) 并且任何这样的 \(\mathbf{x}\) 都给出了 \(\mu_2\) 的上界，因此我们必然有 \(\mu_2 = 0\)。
- en: For \(\sum_{\{u, v\} \in E} (x_u - x_v)^2\) to be \(0\), one might be tempted
    to take a constant vector \(\mathbf{x}\). But then we could not satisfy \(\sum_{u=1}^n
    x_u = 0\) and \(\sum_{u = 1}^n x_u^2=1\) simultaneously. Instead, we modify this
    guess slightly. Because the graph has two connected components, there is no edge
    between \(V_1\) and \(V_2\). Hence we can assign a different value to each component
    and still get \(\sum_{\{u, v\} \in E} (x_u - x_v)^2 = 0\). So we look for a vector
    \(\mathbf{x} = (x_1, \ldots, x_n)\) of the form
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2\) 为 \(0\)，人们可能会倾向于取一个常数向量 \(\mathbf{x}\)。但这样我们就不能同时满足
    \(\sum_{u=1}^n x_u = 0\) 和 \(\sum_{u = 1}^n x_u^2=1\)。相反，我们稍微修改这个猜测。因为图有两个连通分量，\(V_1\)
    和 \(V_2\) 之间没有边。因此，我们可以为每个分量分配不同的值，同时仍然得到 \(\sum_{\{u, v\} \in E} (x_u - x_v)^2
    = 0\)。因此，我们寻找一个形式为 \(\mathbf{x} = (x_1, \ldots, x_n)\) 的向量
- en: \[\begin{split} x_u = \begin{cases} \alpha, & \text{if $u \in V_1$,}\\ \beta,
    & \text{if $u \in V_2$.} \end{cases} \end{split}\]
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} x_u = \begin{cases} \alpha, & \text{if $u \in V_1$,}\\ \beta,
    & \text{if $u \in V_2$.} \end{cases} \end{split}\]
- en: To satisfy the constraints on \(\mathbf{x}\), we require
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足 \(\mathbf{x}\) 的约束条件，我们需要
- en: \[ \sum_{u=1}^n x_u = \sum_{u \in V_1} \alpha + \sum_{u \in V_2} \beta = |V_1|
    \alpha + |V_2| \beta = 0, \]
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{u=1}^n x_u = \sum_{u \in V_1} \alpha + \sum_{u \in V_2} \beta = |V_1|
    \alpha + |V_2| \beta = 0, \]
- en: and
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ \sum_{u=1}^n x_u^2 = \sum_{u \in V_1} \alpha^2 + \sum_{u \in V_2} \beta^2
    = |V_1| \alpha^2 + |V_2| \beta^2 = 1. \]
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{u=1}^n x_u^2 = \sum_{u \in V_1} \alpha^2 + \sum_{u \in V_2} \beta^2
    = |V_1| \alpha^2 + |V_2| \beta^2 = 1. \]
- en: Replacing the first equation in the second one, we get
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 将第二个方程中的第一个方程替换，我们得到
- en: \[ |V_1| \left(\frac{-|V_2|\beta}{|V_1|}\right)^2 + |V_2| \beta^2 = \frac{|V_2|^2
    \beta^2}{|V_1|} + |V_2| \beta^2 = 1, \]
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |V_1| \left(\frac{-|V_2|\beta}{|V_1|}\right)^2 + |V_2| \beta^2 = \frac{|V_2|^2
    \beta^2}{|V_1|} + |V_2| \beta^2 = 1, \]
- en: or
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: \[ \beta^2 = \frac{|V_1|}{|V_2|(|V_2| + |V_1|)} = \frac{|V_1|}{n |V_2|}. \]
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \beta^2 = \frac{|V_1|}{|V_2|(|V_2| + |V_1|)} = \frac{|V_1|}{n |V_2|}. \]
- en: Take
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 取
- en: \[ \beta = - \sqrt{\frac{|V_1|}{n |V_2|}}, \qquad \alpha = \frac{-|V_2|\beta}{|V_1|}
    = \sqrt{\frac{|V_2|}{n |V_1|}}. \]
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \beta = - \sqrt{\frac{|V_1|}{n |V_2|}}, \qquad \alpha = \frac{-|V_2|\beta}{|V_1|}
    = \sqrt{\frac{|V_2|}{n |V_1|}}. \]
- en: The vector \(\mathbf{x}\) we constructed is in fact an eigenvector of \(L\).
    Indeed, let \(B\) be an oriented incidence matrix of \(G\). Then, for \(e_k =
    \{u,v\}\), \((B^T \mathbf{x})_k\) is either \(x_u - x_v\) or \(x_v - x_u\). In
    both cases, that is \(0\). So \(L \mathbf{x} = B B^T \mathbf{x} = \mathbf{0}\),
    that is, \(\mathbf{x}\) is an eigenvector of \(L\) with eigenvalue \(0\).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构造的向量 \(\mathbf{x}\) 实际上是 \(L\) 的一个特征向量。确实，设 \(B\) 是 \(G\) 的一个有向关联矩阵。那么，对于
    \(e_k = \{u,v\}\)，\((B^T \mathbf{x})_k\) 要么是 \(x_u - x_v\)，要么是 \(x_v - x_u\)。在两种情况下，都是
    \(0\)。所以 \(L \mathbf{x} = B B^T \mathbf{x} = \mathbf{0}\)，即 \(\mathbf{x}\) 是 \(L\)
    的一个特征向量，其特征值为 \(0\)。
- en: We have shown that \(\mu_2 = 0\) when \(G\) has two connected components. A
    slight modification of this argument shows that \(\mu_2 = 0\) whenever \(G\) is
    not connected. \(\lhd\)
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经证明，当 \(G\) 有两个连通分量时，\(\mu_2 = 0\)。对这个论证的微小修改表明，当 \(G\) 不连通时，\(\mu_2 = 0\)。\(\lhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(有克莱德、双子星和 ChatGPT 的帮助)*'
- en: '**1** Which of the following is NOT a property of the Laplacian matrix \(L\)
    of a graph \(G\)?'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 以下哪项不是图 \(G\) 的拉普拉斯矩阵 \(L\) 的性质？'
- en: a) \(L\) is symmetric.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(L\) 是对称的。
- en: b) \(L\) is positive semidefinite.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(L\) 是正半定矩阵。
- en: c) The constant unit vector \(\frac{1}{\sqrt{n}}(1,\ldots,1)\) is an eigenvector
    of \(L\) with eigenvalue 0.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: c) 常数单位向量 \(\frac{1}{\sqrt{n}}(1,\ldots,1)\) 是 \(L\) 的特征向量，其特征值为 0。
- en: d) \(L\) is positive definite.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(L\) 是正定矩阵。
- en: '**2** Which vector is known as the Fiedler vector?'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 哪个向量被称为 Fiedler 向量？'
- en: a) The eigenvector corresponding to the largest eigenvalue of the Laplacian
    matrix.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: a) 与拉普拉斯矩阵的最大特征值对应的特征向量。
- en: b) The eigenvector corresponding to the smallest eigenvalue of the Laplacian
    matrix.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: b) 与拉普拉斯矩阵的最小特征值对应的特征向量。
- en: c) The eigenvector corresponding to the second smallest eigenvalue of the Laplacian
    matrix.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: c) 与拉普拉斯矩阵的第二小特征值对应的特征向量。
- en: d) The eigenvector corresponding to the average of all eigenvalues of the Laplacian
    matrix.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: d) 与拉普拉斯矩阵所有特征值的平均值对应的特征向量。
- en: '**3** For a connected graph \(G\), which of the following statements about
    the second smallest eigenvalue \(\mu_2\) of its Laplacian matrix is true?'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 对于一个连通图 \(G\)，关于其拉普拉斯矩阵的第二小特征值 \(\mu_2\) 的以下哪个陈述是正确的？'
- en: a) \(\mu_2 = 0\)
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\mu_2 = 0\)
- en: b) \(\mu_2 < 0\)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\mu_2 < 0\)
- en: c) \(\mu_2 > 0\)
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mu_2 > 0\)
- en: d) The value of \(\mu_2\) cannot be determined without additional information.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: d) 在没有额外信息的情况下，无法确定 \(\mu_2\) 的值。
- en: '**4** The Laplacian quadratic form \(\mathbf{x}^T L \mathbf{x}\) for a graph
    \(G\) with Laplacian matrix \(L\) can be written as:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 对于具有拉普拉斯矩阵 \(L\) 的图 \(G\)，其拉普拉斯二次型 \(\mathbf{x}^T L \mathbf{x}\) 可以表示为：'
- en: \[ \mathbf{x}^T L \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2. \]
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2. \]
- en: What does this quadratic form measure?
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这个二次型测量了什么？
- en: a) The average distance between vertices in the graph.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: a) 图中顶点之间的平均距离。
- en: b) The number of connected components in the graph.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: b) 图中的连通分量数。
- en: c) The “smoothness” of the function \(x\) over the graph.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: c) 函数 \(x\) 在图上的“平滑性”。
- en: d) The degree of each vertex in the graph.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: d) 图中每个顶点的度数。
- en: '**5** The Laplacian matrix \(L\) of a graph \(G\) can be decomposed as \(L
    = B B^T\), where \(B\) is an oriented incidence matrix. What does this decomposition
    imply about \(L\)?'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 图 \(G\) 的拉普拉斯矩阵 \(L\) 可以分解为 \(L = B B^T\)，其中 \(B\) 是一个有向关联矩阵。这种分解对 \(L\)
    有什么含义？'
- en: a) \(L\) is positive definite
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(L\) 是正定矩阵
- en: b) \(L\) is symmetric and positive semidefinite
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(L\) 是对称的正半定矩阵
- en: c) \(L\) is antisymmetric
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(L\) 是反对称的
- en: d) \(L\) is a diagonal matrix
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(L\) 是对角矩阵
- en: 'Answer for 1: d. Justification: The text states that “because \(L\) is positive
    semidefinite, the eigenvalues are nonnegative,” but it does not claim that \(L\)
    is positive definite.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 答案1：d. 证明：文本指出，“因为 \(L\) 是正半定矩阵，所以特征值都是非负的，”但它并没有声称 \(L\) 是正定矩阵。
- en: 'Answer for 2: c. Justification: The text refers to the eigenvector corresponding
    to \(\mu_2\) (the second smallest eigenvalue) as the Fiedler vector.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 答案2：c. 证明：文本将对应于 \(\mu_2\)（第二个最小的特征值）的特征向量称为菲德勒向量。
- en: 'Answer for 3: c. Justification: The text proves that “If \(G\) is connected,
    then the Laplacian eigenvalue \(\mu_2 > 0\).”'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 答案3：c. 证明：文本证明，“如果 \(G\) 是连通的，那么拉普拉斯特征值 \(\mu_2 > 0\)。”
- en: 'Answer for 4: c. Justification: The text states that “the Laplacian quadratic
    form measures how ‘smooth’ the function \(\mathbf{x}\) is over the graph in the
    following sense. A small value of \(\mathbf{x}^T L \mathbf{x}\) indicates that
    adjacent vertices tend to get assigned close values.”'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 答案4：c. 证明：文本指出，“拉普拉斯二次型在以下意义上衡量函数 \(\mathbf{x}\) 在图上的‘平滑’程度。 \(\mathbf{x}^T
    L \mathbf{x}\) 的值较小表示相邻顶点倾向于被分配到接近的值。”
- en: 'Answer for 5: b. Justification: The text states, “Let \(B\) be an oriented
    incidence matrix of \(G\). By construction, \(L = B B^T\). This implies that \(L\)
    is symmetric and positive semidefinite.”'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 答案5：b. 证明：文本指出，“设 \(B\) 是 \(G\) 的有向关联矩阵。根据构造，\(L = B B^T\)。这意味着 \(L\) 是对称的正半定矩阵。”
