["```py\nx = torch.tensor([1.,0.,-1.], requires_grad=True)\ny = torch.tensor([0.,1.])\nW0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]])\nW1 = torch.tensor([[-1.,0.],[2.,-1.]])\n\nz0 = x\nz1 = W0 @ z0\nz2 = W1 @ z1\nf = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)\n\nprint(z0) \n```", "```py\ntensor([ 1.,  0., -1.], requires_grad=True) \n```", "```py\nprint(z1) \n```", "```py\ntensor([1., 1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(z2) \n```", "```py\ntensor([-1.,  1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(f) \n```", "```py\ntensor(0.5000, grad_fn=<MulBackward0>) \n```", "```py\nwith torch.no_grad():\n    F0 = W0\n    F1 = W1 @ F0\n    grad_f = (z2 - y).unsqueeze(0) @ F1\n\nprint(F0) \n```", "```py\ntensor([[ 0.,  1., -1.],\n        [ 2.,  0.,  1.]]) \n```", "```py\nprint(F1) \n```", "```py\ntensor([[ 0., -1.,  1.],\n        [-2.,  2., -3.]]) \n```", "```py\nprint(grad_f) \n```", "```py\ntensor([[ 0.,  1., -1.]]) \n```", "```py\nf.backward()\nprint(x.grad) \n```", "```py\ntensor([ 0.,  1., -1.]) \n```", "```py\nwith torch.no_grad():\n    G2 = (z2 - y).unsqueeze(0)\n    G1 = G2 @ W1\n    grad_f = G1 @ W0\n\nprint(G2) \n```", "```py\ntensor([[-1.,  0.]]) \n```", "```py\nprint(G1) \n```", "```py\ntensor([[1., 0.]]) \n```", "```py\nprint(grad_f) \n```", "```py\ntensor([[ 0.,  1., -1.]]) \n```", "```py\nx = torch.tensor([1.,0.,-1.])\ny = torch.tensor([0.,1.])\nW0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]], requires_grad=True)\nW1 = torch.tensor([[-1.,0.],[2.,-1.]], requires_grad=True)\n\nz0 = x\nz1 = W0 @ z0\nz2 = W1 @ z1\nf = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)\n\nprint(z0) \n```", "```py\ntensor([ 1.,  0., -1.]) \n```", "```py\nprint(z1) \n```", "```py\ntensor([1., 1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(z2) \n```", "```py\ntensor([-1.,  1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(f) \n```", "```py\ntensor(0.5000, grad_fn=<MulBackward0>) \n```", "```py\nf.backward() \n```", "```py\nprint(W0.grad) \n```", "```py\ntensor([[ 1.,  0., -1.],\n        [ 0.,  0., -0.]]) \n```", "```py\nprint(W1.grad) \n```", "```py\ntensor([[-1., -1.],\n        [-0., -0.]]) \n```", "```py\nwith torch.no_grad():\n    grad_W0 = torch.kron((z2 - y).unsqueeze(0) @ W1, z0.unsqueeze(0))\n    grad_W1 = torch.kron((z2 - y).unsqueeze(0), z1.unsqueeze(0))\n\nprint(grad_W0) \n```", "```py\ntensor([[ 1.,  0., -1.,  0.,  0., -0.]]) \n```", "```py\nprint(grad_W1) \n```", "```py\ntensor([[-1., -1.,  0.,  0.]]) \n```", "```py\nx = torch.tensor([1.,0.,-1.], requires_grad=True)\ny = torch.tensor([0.,1.])\nW0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]])\nW1 = torch.tensor([[-1.,0.],[2.,-1.]])\n\nz0 = x\nz1 = W0 @ z0\nz2 = W1 @ z1\nf = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)\n\nprint(z0) \n```", "```py\ntensor([ 1.,  0., -1.], requires_grad=True) \n```", "```py\nprint(z1) \n```", "```py\ntensor([1., 1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(z2) \n```", "```py\ntensor([-1.,  1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(f) \n```", "```py\ntensor(0.5000, grad_fn=<MulBackward0>) \n```", "```py\nwith torch.no_grad():\n    F0 = W0\n    F1 = W1 @ F0\n    grad_f = (z2 - y).unsqueeze(0) @ F1\n\nprint(F0) \n```", "```py\ntensor([[ 0.,  1., -1.],\n        [ 2.,  0.,  1.]]) \n```", "```py\nprint(F1) \n```", "```py\ntensor([[ 0., -1.,  1.],\n        [-2.,  2., -3.]]) \n```", "```py\nprint(grad_f) \n```", "```py\ntensor([[ 0.,  1., -1.]]) \n```", "```py\nf.backward()\nprint(x.grad) \n```", "```py\ntensor([ 0.,  1., -1.]) \n```", "```py\nwith torch.no_grad():\n    G2 = (z2 - y).unsqueeze(0)\n    G1 = G2 @ W1\n    grad_f = G1 @ W0\n\nprint(G2) \n```", "```py\ntensor([[-1.,  0.]]) \n```", "```py\nprint(G1) \n```", "```py\ntensor([[1., 0.]]) \n```", "```py\nprint(grad_f) \n```", "```py\ntensor([[ 0.,  1., -1.]]) \n```", "```py\nx = torch.tensor([1.,0.,-1.])\ny = torch.tensor([0.,1.])\nW0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]], requires_grad=True)\nW1 = torch.tensor([[-1.,0.],[2.,-1.]], requires_grad=True)\n\nz0 = x\nz1 = W0 @ z0\nz2 = W1 @ z1\nf = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)\n\nprint(z0) \n```", "```py\ntensor([ 1.,  0., -1.]) \n```", "```py\nprint(z1) \n```", "```py\ntensor([1., 1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(z2) \n```", "```py\ntensor([-1.,  1.], grad_fn=<MvBackward0>) \n```", "```py\nprint(f) \n```", "```py\ntensor(0.5000, grad_fn=<MulBackward0>) \n```", "```py\nf.backward() \n```", "```py\nprint(W0.grad) \n```", "```py\ntensor([[ 1.,  0., -1.],\n        [ 0.,  0., -0.]]) \n```", "```py\nprint(W1.grad) \n```", "```py\ntensor([[-1., -1.],\n        [-0., -0.]]) \n```", "```py\nwith torch.no_grad():\n    grad_W0 = torch.kron((z2 - y).unsqueeze(0) @ W1, z0.unsqueeze(0))\n    grad_W1 = torch.kron((z2 - y).unsqueeze(0), z1.unsqueeze(0))\n\nprint(grad_W0) \n```", "```py\ntensor([[ 1.,  0., -1.,  0.,  0., -0.]]) \n```", "```py\nprint(grad_W1) \n```", "```py\ntensor([[-1., -1.,  0.,  0.]]) \n```"]