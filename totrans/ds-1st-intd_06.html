<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Chapter 2 Reading in data locally and from the web</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Chapter 2 Reading in data locally and from the web</h1>
<blockquote>原文：<a href="https://datasciencebook.ca/reading.html">https://datasciencebook.ca/reading.html</a></blockquote>
<div id="reading" class="section level1 hasAnchor" number="2">

<div id="overview-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Overview<a href="reading.html#overview-1" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>In this chapter, you’ll learn to read tabular data of various formats into R
from your local device (e.g., your laptop) and the web. “Reading” (or “loading”)
is the process of
converting data (stored as plain text, a database, HTML, etc.) into an object
(e.g., a data frame) that R can easily access and manipulate. Thus reading data
is the gateway to any data analysis; you won’t be able to analyze data unless
you’ve loaded it first. And because there are many ways to store data, there
are similarly many ways to read data into R. The more time you spend upfront
matching the data reading method to the type of data you have, the less time
you will have to devote to re-formatting, cleaning and wrangling your data (the
second step to all data analyses). It’s like making sure your shoelaces are
tied well before going for a run so that you don’t trip later on!</p>
</div>
<div id="chapter-learning-objectives-1" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Chapter learning objectives<a href="reading.html#chapter-learning-objectives-1" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>By the end of the chapter, readers will be able to do the following:</p>
<ul>
<li>Define the types of path and use them to locate files:
<ul>
<li>absolute file path</li>
<li>relative file path</li>
<li>Uniform Resource Locator (URL)</li>
</ul></li>
<li>Read data into R from various types of path using:
<ul>
<li><code>read_csv</code></li>
<li><code>read_tsv</code></li>
<li><code>read_csv2</code></li>
<li><code>read_delim</code></li>
<li><code>read_excel</code></li>
</ul></li>
<li>Compare and contrast the <code>read_*</code> functions.</li>
<li>Describe when to use the following <code>read_*</code> function arguments:
<ul>
<li><code>skip</code></li>
<li><code>delim</code></li>
<li><code>col_names</code></li>
</ul></li>
<li>Choose the appropriate <code>tidyverse</code> <code>read_*</code> function and function arguments to load a given plain text tabular data set into R.</li>
<li>Use the <code>rename</code> function to rename columns in a data frame.</li>
<li>Use <code>read_excel</code> function and arguments to load a sheet from an excel file into R.</li>
<li>Work with databases using functions from <code>dbplyr</code> and <code>DBI</code>:
<ul>
<li>Connect to a database with <code>dbConnect</code>.</li>
<li>List tables in the database with <code>dbListTables</code>.</li>
<li>Create a reference to a database table with <code>tbl</code>.</li>
<li>Bring data from a database into R using <code>collect</code>.</li>
</ul></li>
<li>Use <code>write_csv</code> to save a data frame to a <code>.csv</code> file.</li>
<li>(<em>Optional</em>) Obtain data from the web using scraping and application programming interfaces (APIs):
<ul>
<li>Read HTML source code from a URL using the <code>rvest</code> package.</li>
<li>Read data from the NASA “Astronomy Picture of the Day” API using the <code>httr2</code> package.</li>
<li>Compare downloading tabular data from a plain text file (e.g., <code>.csv</code>), accessing data from an API, and scraping the HTML source code from a website.</li>
</ul></li>
</ul>
</div>
<div id="absolute-and-relative-file-paths" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Absolute and relative file paths<a href="reading.html#absolute-and-relative-file-paths" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>This chapter will discuss the different functions we can use to import data
into R, but before we can talk about <em>how</em> we read the data into R with these
functions, we first need to talk about <em>where</em> the data lives. When you load a
data set into R, you first need to tell R where those files live. The file
could live on your computer (<em>local</em>)
or somewhere on the internet (<em>remote</em>).</p>
<p>The place where the file lives on your computer is referred to as its “path”. You can
think of the path as directions to the file. There are two kinds of paths:
<em>relative</em> paths and <em>absolute</em> paths. A relative path indicates where the file is
with respect to your <em>working directory</em> (i.e., “where you are currently”) on the computer.
On the other hand, an absolute path indicates where the file is
with respect to the computer’s filesystem base (or <em>root</em>) folder, regardless of where you are working.</p>
<p>Suppose our computer’s filesystem looks like the picture in Figure
<a href="reading.html#fig:file-system-for-export-to-intro-datascience">2.1</a>. We are working in a
file titled <code>project3.ipynb</code>, and our current working directory is <code>project3</code>;
typically, as is the case here, the working directory is the directory containing the file you are currently
working on.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:file-system-for-export-to-intro-datascience"/>
<img src="../Images/9fd3036c264ffe4949dd0ea85733528c.png" alt="Example file system." width="100%" data-original-src="https://datasciencebook.ca/img/reading/filesystem.png"/>
<p class="caption">
Figure 2.1: Example file system.
</p>
</div>
<p>Let’s say we wanted to open the <code>happiness_report.csv</code> file. We have two options to indicate
where the file is: using a relative path, or using an absolute path.
The absolute path of the file always starts with a slash <code>/</code>—representing the root folder on the computer—and
proceeds by listing out the sequence of folders you would have to enter to reach the file, each separated by another slash <code>/</code>.
So in this case, <code>happiness_report.csv</code> would be reached by starting at the root, and entering the <code>home</code> folder,
then the <code>dsci-100</code> folder, then the <code>project3</code> folder, and then finally the <code>data</code> folder. So its absolute
path would be <code>/home/dsci-100/project3/data/happiness_report.csv</code>. We can load the file using its absolute path
as a string passed to the <code>read_csv</code> function.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="reading.html#cb30-1" tabindex="-1"/>happy_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"/home/dsci-100/project3/data/happiness_report.csv"</span>)</span></code></pre></div>
<p>If we instead wanted to use a relative path, we would need to list out the sequence of steps needed to get from our current
working directory to the file, with slashes <code>/</code> separating each step. Since we are currently in the <code>project3</code> folder,
we just need to enter the <code>data</code> folder to reach our desired file. Hence the relative path is <code>data/happiness_report.csv</code>,
and we can load the file using its relative path as a string passed to <code>read_csv</code>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="reading.html#cb31-1" tabindex="-1"/>happy_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/happiness_report.csv"</span>)</span></code></pre></div>
<p>Note that there is no forward slash at the beginning of a relative path; if we accidentally typed <code>"/data/happiness_report.csv"</code>,
R would look for a folder named <code>data</code> in the root folder of the computer—but that doesn’t exist!</p>
<p>Aside from specifying places to go in a path using folder names (like <code>data</code> and <code>project3</code>), we can also specify two additional
special places: the <em>current directory</em> and the <em>previous directory</em>.
We indicate the current working directory with a single dot <code>.</code>, and
the previous directory with two dots <code>..</code>. So for instance, if we wanted to reach the <code>bike_share.csv</code> file from the <code>project3</code> folder, we could
use the relative path <code>../project2/bike_share.csv</code>. We can even combine these two; for example, we could reach the <code>bike_share.csv</code> file using
the (very silly) path <code>../project2/../project2/./bike_share.csv</code> with quite a few redundant directions: it says to go back a folder, then open <code>project2</code>,
then go back a folder again, then open <code>project2</code> again, then stay in the current directory, then finally get to <code>bike_share.csv</code>. Whew, what a long trip!</p>
<p>So which kind of path should you use: relative, or absolute? Generally speaking, you should use relative paths.
Using a relative path helps ensure that your code can be run
on a different computer (and as an added bonus, relative paths are often shorter—easier to type!).
This is because a file’s relative path is often the same across different computers, while a
file’s absolute path (the names of
all of the folders between the computer’s root, represented by <code>/</code>, and the file) isn’t usually the same
across different computers. For example, suppose Fatima and Jayden are working on a
project together on the <code>happiness_report.csv</code> data. Fatima’s file is stored at</p>
<p><code>/home/Fatima/project3/data/happiness_report.csv</code>,</p>
<p>while Jayden’s is stored at</p>
<p><code>/home/Jayden/project3/data/happiness_report.csv</code>.</p>
<p>Even though Fatima and Jayden stored their files in the same place on their
computers (in their home folders), the absolute paths are different due to
their different usernames. If Jayden has code that loads the
<code>happiness_report.csv</code> data using an absolute path, the code won’t work on
Fatima’s computer. But the relative path from inside the <code>project3</code> folder
(<code>data/happiness_report.csv</code>) is the same on both computers; any code that uses
relative paths will work on both! In the additional resources section,
we include a link to a short video on the
difference between absolute and relative paths. You can also check out the
<code>here</code> package, which provides methods for finding and constructing file paths
in R.</p>
<p>Beyond files stored on your computer (i.e., locally), we also need a way to locate resources
stored elsewhere on the internet (i.e., remotely). For this purpose we use a
<em>Uniform Resource Locator (URL)</em>, i.e., a web address that looks something
like <a href="https://datasciencebook.ca/" class="uri">https://datasciencebook.ca/</a>. URLs indicate the location of a resource on the internet, and
start with a web domain, followed by a forward slash <code>/</code>, and then a path
to where the resource is located on the remote machine. </p>
</div>
<div id="reading-tabular-data-from-a-plain-text-file-into-r" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Reading tabular data from a plain text file into R<a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r" class="anchor-section" aria-label="Anchor link to header"/></h2>
<div id="readcsv" class="section level3 hasAnchor" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> <code>read_csv</code> to read in comma-separated values files<a href="reading.html#readcsv" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Now that we have learned about <em>where</em> data could be, we will learn about <em>how</em>
to import data into R using various functions. Specifically, we will learn how
to <em>read</em> tabular data from a plain text file (a document containing only text)
<em>into</em> R and <em>write</em> tabular data to a file <em>out of</em> R. The function we use to do this
depends on the file’s format. For example, in the last chapter, we learned about using
the <code>tidyverse</code> <code>read_csv</code> function when reading <code>.csv</code> (<strong>c</strong>omma-<strong>s</strong>eparated <strong>v</strong>alues)
files. In that case, the separator or <em>delimiter</em> that divided our columns was a
comma (<code>,</code>). We only learned the case where the data matched the expected defaults
of the <code>read_csv</code> function
(column names are present, and commas are used as the delimiter between columns).
In this section, we will learn how to read
files that do not satisfy the default expectations of <code>read_csv</code>.</p>
<p>Before we jump into the cases where the data aren’t in the expected default format
for <code>tidyverse</code> and <code>read_csv</code>, let’s revisit the more straightforward
case where the defaults hold, and the only argument we need to give to the function
is the path to the file, <code>data/can_lang.csv</code>. The <code>can_lang</code> data set contains
language data from the 2016 Canadian census.
We put <code>data/</code> before the file’s
name when we are loading the data set because this data set is located in a
sub-folder, named <code>data</code>, relative to where we are running our R code.
Here is what the text in the file <code>data/can_lang.csv</code> looks like.</p>
<pre class="code"><code>category,language,mother_tongue,most_at_home,most_at_work,lang_known
Aboriginal languages,"Aboriginal languages, n.o.s.",590,235,30,665
Non-Official &amp; Non-Aboriginal languages,Afrikaans,10260,4785,85,23415
Non-Official &amp; Non-Aboriginal languages,"Afro-Asiatic languages, n.i.e.",1150,44
Non-Official &amp; Non-Aboriginal languages,Akan (Twi),13460,5985,25,22150
Non-Official &amp; Non-Aboriginal languages,Albanian,26895,13135,345,31930
Aboriginal languages,"Algonquian languages, n.i.e.",45,10,0,120
Aboriginal languages,Algonquin,1260,370,40,2480
Non-Official &amp; Non-Aboriginal languages,American Sign Language,2685,3020,1145,21
Non-Official &amp; Non-Aboriginal languages,Amharic,22465,12785,200,33670</code></pre>
<p>And here is a review of how we can use <code>read_csv</code> to load it into R. First we
load the <code>tidyverse</code> package to gain access to useful
functions for reading the data.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="reading.html#cb33-1" tabindex="-1"/><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>Next we use <code>read_csv</code> to load the data into R, and in that call we specify the
relative path to the file. Note that it is normal and expected that a message is
printed out after using the <code>read_csv</code> and related functions. This message lets you know the data types
of each of the columns that R inferred while reading the data into R. In the
future when we use this and related functions to load data in this book, we will
silence these messages to help with the readability of the book.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="reading.html#cb34-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/can_lang.csv"</span>)</span></code></pre></div>
<pre><code>## Rows: 214 Columns: 6
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: ","
## chr (2): category, language
## dbl (4): mother_tongue, most_at_home, most_at_work, lang_known
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div style="page-break-after: always;"/>
<p>Finally, to view the first 10 rows of the data frame,
we must call it:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="reading.html#cb36-1" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
</div>
<div id="skipping-rows-when-reading-in-data" class="section level3 hasAnchor" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Skipping rows when reading in data<a href="reading.html#skipping-rows-when-reading-in-data" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Oftentimes, information about how data was collected, or other relevant
information, is included at the top of the data file. This information is
usually written in sentence and paragraph form, with no delimiter because it is
not organized into columns. An example of this is shown below. This information
gives the data scientist useful context and information about the data,
however, it is not well formatted or intended to be read into a data frame cell
along with the tabular data that follows later in the file.</p>
<pre class="code"><code>Data source: https://ttimbers.github.io/canlang/
Data originally published in: Statistics Canada Census of Population 2016.
Reproduced and distributed on an as-is basis with their permission.
category,language,mother_tongue,most_at_home,most_at_work,lang_known
Aboriginal languages,"Aboriginal languages, n.o.s.",590,235,30,665
Non-Official &amp; Non-Aboriginal languages,Afrikaans,10260,4785,85,23415
Non-Official &amp; Non-Aboriginal languages,"Afro-Asiatic languages, n.i.e.",1150,44
Non-Official &amp; Non-Aboriginal languages,Akan (Twi),13460,5985,25,22150
Non-Official &amp; Non-Aboriginal languages,Albanian,26895,13135,345,31930
Aboriginal languages,"Algonquian languages, n.i.e.",45,10,0,120
Aboriginal languages,Algonquin,1260,370,40,2480
Non-Official &amp; Non-Aboriginal languages,American Sign Language,2685,3020,1145,21
Non-Official &amp; Non-Aboriginal languages,Amharic,22465,12785,200,33670</code></pre>
<p>With this extra information being present at the top of the file, using
<code>read_csv</code> as we did previously does not allow us to correctly load the data
into R. In the case of this file we end up only reading in one column of the
data set. In contrast to the normal and expected messages above, this time R
prints out a warning for us indicating that there might be a problem with how
our data is being read in. </p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="reading.html#cb39-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/can_lang_meta-data.csv"</span>)</span></code></pre></div>
<pre><code>## Warning: One or more parsing issues, call `problems()` on your data frame for details,
## e.g.:
##   dat &lt;- vroom(...)
##   problems(dat)</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="reading.html#cb41-1" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 217 × 1
##    `Data source: https://ttimbers.github.io/canlang/`                           
##    &lt;chr&gt;                                                                        
##  1 "Data originally published in: Statistics Canada Census of Population 2016." 
##  2 "Reproduced and distributed on an as-is basis with their permission."        
##  3 "category,language,mother_tongue,most_at_home,most_at_work,lang_known"       
##  4 "Aboriginal languages,\"Aboriginal languages, n.o.s.\",590,235,30,665"       
##  5 "Non-Official &amp; Non-Aboriginal languages,Afrikaans,10260,4785,85,23415"      
##  6 "Non-Official &amp; Non-Aboriginal languages,\"Afro-Asiatic languages, n.i.e.\",…
##  7 "Non-Official &amp; Non-Aboriginal languages,Akan (Twi),13460,5985,25,22150"     
##  8 "Non-Official &amp; Non-Aboriginal languages,Albanian,26895,13135,345,31930"     
##  9 "Aboriginal languages,\"Algonquian languages, n.i.e.\",45,10,0,120"          
## 10 "Aboriginal languages,Algonquin,1260,370,40,2480"                            
## # ℹ 207 more rows</code></pre>
<p>To successfully read data like this into R, the <code>skip</code>
argument can be useful to tell R
how many lines to skip before
it should start reading in the data. In the example above, we would set this
value to 3.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="reading.html#cb43-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/can_lang_meta-data.csv"</span>,</span>
<span id="cb43-2"><a href="reading.html#cb43-2" tabindex="-1"/>                         <span class="at">skip =</span> <span class="dv">3</span>)</span>
<span id="cb43-3"><a href="reading.html#cb43-3" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
<p>How did we know to skip three lines? We looked at the data! The first three lines
of the data had information we didn’t need to import:</p>
<pre class="code"><code>Data source: https://ttimbers.github.io/canlang/
Data originally published in: Statistics Canada Census of Population 2016.
Reproduced and distributed on an as-is basis with their permission.</code></pre>
<p>The column names began at line 4, so we skipped the first three lines.</p>
</div>
<div id="read_tsv-to-read-in-tab-separated-values-files" class="section level3 hasAnchor" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> <code>read_tsv</code> to read in tab-separated values files<a href="reading.html#read_tsv-to-read-in-tab-separated-values-files" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Another common way data is stored is with tabs as the delimiter. Notice the
data file, <code>can_lang.tsv</code>, has tabs in between the columns instead of
commas.</p>
<pre class="code"><code>category    language    mother_tongue   most_at_home    most_at_work    lang_kno
Aboriginal languages    Aboriginal languages, n.o.s.    590 235 30  665
Non-Official &amp; Non-Aboriginal languages Afrikaans   10260   4785    85  23415
Non-Official &amp; Non-Aboriginal languages Afro-Asiatic languages, n.i.e.  1150
Non-Official &amp; Non-Aboriginal languages Akan (Twi)  13460   5985    25  22150
Non-Official &amp; Non-Aboriginal languages Albanian    26895   13135   345 31930
Aboriginal languages    Algonquian languages, n.i.e.    45  10  0   120
Aboriginal languages    Algonquin   1260    370 40  2480
Non-Official &amp; Non-Aboriginal languages American Sign Language  2685    3020
Non-Official &amp; Non-Aboriginal languages Amharic 22465   12785   200 33670</code></pre>
<p>We can use the <code>read_tsv</code> function
to read in <code>.tsv</code> (<strong>t</strong>ab <strong>s</strong>eparated <strong>v</strong>alues) files.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="reading.html#cb47-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">"data/can_lang.tsv"</span>)</span>
<span id="cb47-2"><a href="reading.html#cb47-2" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
<p>If you compare the data frame here to the data frame we obtained in Section
<a href="reading.html#readcsv">2.4.1</a> using <code>read_csv</code>, you’ll notice that they look identical:
they have the same number of columns and rows, the same column names, and the same entries! So
even though we needed to use a different
function depending on the file format, our resulting data frame
(<code>canlang_data</code>) in both cases was the same.</p>
</div>
<div id="read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r" class="section level3 hasAnchor" number="2.4.4">
<h3><span class="header-section-number">2.4.4</span> <code>read_delim</code> as a more flexible method to get tabular data into R<a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>The <code>read_csv</code> and <code>read_tsv</code> functions are actually just special cases of the more general
<code>read_delim</code> function. We can use
<code>read_delim</code> to import both comma and tab-separated values files, and more; we just
have to specify the delimiter.
For example, the <code>can_lang_no_names.tsv</code> file contains a different version of
this same data set with no column names and uses tabs as the delimiter
instead of commas.
Here is how the file would look in a plain text editor:</p>
<pre class="code"><code>Aboriginal languages    Aboriginal languages, n.o.s.    590 235 30  665
Non-Official &amp; Non-Aboriginal languages Afrikaans   10260   4785    85  23415
Non-Official &amp; Non-Aboriginal languages Afro-Asiatic languages, n.i.e.  1150
Non-Official &amp; Non-Aboriginal languages Akan (Twi)  13460   5985    25  22150
Non-Official &amp; Non-Aboriginal languages Albanian    26895   13135   345 31930
Aboriginal languages    Algonquian languages, n.i.e.    45  10  0   120
Aboriginal languages    Algonquin   1260    370 40  2480
Non-Official &amp; Non-Aboriginal languages American Sign Language  2685    3020
Non-Official &amp; Non-Aboriginal languages Amharic 22465   12785   200 33670
Non-Official &amp; Non-Aboriginal languages Arabic  419890  223535  5585    629055</code></pre>
<p>To read this into R using the <code>read_delim</code> function, we specify the path
to the file as the first argument, provide
the tab character <code>"\t"</code> as the <code>delim</code> argument,
and set the <code>col_names</code> argument to <code>FALSE</code> to denote that there are no column names
provided in the data. Note that the <code>read_csv</code>, <code>read_tsv</code>, and <code>read_delim</code> functions
all have a <code>col_names</code> argument with
the default value <code>TRUE</code>.</p>
<blockquote>
<p><strong>Note:</strong> <code>\t</code> is an example of an <em>escaped character</em>,
which always starts with a backslash (<code>\</code>).
Escaped characters are used to represent non-printing characters
(like the tab) or those with special meanings (such as quotation marks).</p>
</blockquote>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="reading.html#cb50-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">"data/can_lang_no_names.tsv"</span>,</span>
<span id="cb50-2"><a href="reading.html#cb50-2" tabindex="-1"/>                           <span class="at">delim =</span> <span class="st">"</span><span class="sc">\t</span><span class="st">"</span>,</span>
<span id="cb50-3"><a href="reading.html#cb50-3" tabindex="-1"/>                           <span class="at">col_names =</span> <span class="cn">FALSE</span>)</span>
<span id="cb50-4"><a href="reading.html#cb50-4" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    X1                                      X2             X3     X4    X5     X6
##    &lt;chr&gt;                                   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 Aboriginal languages                    Aborigina…    590    235    30    665
##  2 Non-Official &amp; Non-Aboriginal languages Afrikaans   10260   4785    85  23415
##  3 Non-Official &amp; Non-Aboriginal languages Afro-Asia…   1150    445    10   2775
##  4 Non-Official &amp; Non-Aboriginal languages Akan (Twi)  13460   5985    25  22150
##  5 Non-Official &amp; Non-Aboriginal languages Albanian    26895  13135   345  31930
##  6 Aboriginal languages                    Algonquia…     45     10     0    120
##  7 Aboriginal languages                    Algonquin    1260    370    40   2480
##  8 Non-Official &amp; Non-Aboriginal languages American …   2685   3020  1145  21930
##  9 Non-Official &amp; Non-Aboriginal languages Amharic     22465  12785   200  33670
## 10 Non-Official &amp; Non-Aboriginal languages Arabic     419890 223535  5585 629055
## # ℹ 204 more rows</code></pre>
<p>Data frames in R need to have column names. Thus if you read in data
without column names, R will assign names automatically. In this example,
R assigns the column names <code>X1, X2, X3, X4, X5, X6</code>.
It is best to rename your columns manually in this scenario. The current
column names (<code>X1, X2</code>, etc.) are not very descriptive and will make your analysis confusing.
To rename your columns, you can use the <code>rename</code> function
from <a href="https://dplyr.tidyverse.org/">the <code>dplyr</code> R package</a> <span class="citation">(<a href="#ref-dplyr">Wickham, François, et al. 2021</a>)</span>
(one of the packages
loaded with <code>tidyverse</code>, so we don’t need to load it separately). The first
argument is the data set, and in the subsequent arguments you
write <code>new_name = old_name</code> for the selected variables to
rename. We rename the <code>X1, X2, ..., X6</code>
columns in the <code>canlang_data</code> data frame to more descriptive names below.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="reading.html#cb52-1" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">rename</span>(canlang_data,</span>
<span id="cb52-2"><a href="reading.html#cb52-2" tabindex="-1"/>       <span class="at">category =</span> X1,</span>
<span id="cb52-3"><a href="reading.html#cb52-3" tabindex="-1"/>       <span class="at">language =</span> X2,</span>
<span id="cb52-4"><a href="reading.html#cb52-4" tabindex="-1"/>       <span class="at">mother_tongue =</span> X3,</span>
<span id="cb52-5"><a href="reading.html#cb52-5" tabindex="-1"/>       <span class="at">most_at_home =</span> X4,</span>
<span id="cb52-6"><a href="reading.html#cb52-6" tabindex="-1"/>       <span class="at">most_at_work =</span> X5,</span>
<span id="cb52-7"><a href="reading.html#cb52-7" tabindex="-1"/>       <span class="at">lang_known =</span> X6)</span>
<span id="cb52-8"><a href="reading.html#cb52-8" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
</div>
<div id="reading-tabular-data-directly-from-a-url" class="section level3 hasAnchor" number="2.4.5">
<h3><span class="header-section-number">2.4.5</span> Reading tabular data directly from a URL<a href="reading.html#reading-tabular-data-directly-from-a-url" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>We can also use <code>read_csv</code>, <code>read_tsv</code>, or <code>read_delim</code> (and related functions)
to read in data directly from a <strong>U</strong>niform <strong>R</strong>esource <strong>L</strong>ocator (URL) that
contains tabular data. Here, we provide the URL of a remote file to
<code>read_*</code>, instead of a path to a local file on our
computer. We need to surround the URL with quotes similar to when we specify a
path on our local computer. All other arguments that we use are the same as
when using these functions with a local file on our computer.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="reading.html#cb54-1" tabindex="-1"/>url <span class="ot">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/UBC-DSCI/data/main/can_lang.csv"</span></span>
<span id="cb54-2"><a href="reading.html#cb54-2" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(url)</span>
<span id="cb54-3"><a href="reading.html#cb54-3" tabindex="-1"/></span>
<span id="cb54-4"><a href="reading.html#cb54-4" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
</div>
<div id="downloading-data-from-a-url" class="section level3 hasAnchor" number="2.4.6">
<h3><span class="header-section-number">2.4.6</span> Downloading data from a URL<a href="reading.html#downloading-data-from-a-url" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Occasionally the data available at a URL is not formatted nicely enough to use
<code>read_csv</code>, <code>read_tsv</code>, <code>read_delim</code>, or other related functions to read the data
directly into R. In situations where it is necessary to download a file
to our local computer prior to working with it in R, we can use the <code>download.file</code>
function. The first argument is the URL, and the second is a path where we would
like to store the downloaded file.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="reading.html#cb56-1" tabindex="-1"/><span class="fu">download.file</span>(url, <span class="st">"data/can_lang.csv"</span>)</span>
<span id="cb56-2"><a href="reading.html#cb56-2" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/can_lang.csv"</span>)</span>
<span id="cb56-3"><a href="reading.html#cb56-3" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
</div>
<div id="previewing-a-data-file-before-reading-it-into-r" class="section level3 hasAnchor" number="2.4.7">
<h3><span class="header-section-number">2.4.7</span> Previewing a data file before reading it into R<a href="reading.html#previewing-a-data-file-before-reading-it-into-r" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>In many of the examples above, we gave you previews of the data file before we read
it into R. Previewing data is essential to see whether or not there are column
names, what the delimiters are, and if there are lines you need to skip.
You should do this yourself when trying to read in data files: open the file in
whichever text editor you prefer to inspect its contents prior to reading it into R.</p>
</div>
</div>
<div id="reading-tabular-data-from-a-microsoft-excel-file" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Reading tabular data from a Microsoft Excel file<a href="reading.html#reading-tabular-data-from-a-microsoft-excel-file" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>There are many other ways to store tabular data sets beyond plain text files,
and similarly, many ways to load those data sets into R. For example, it is
very common to encounter, and need to load into R, data stored as a Microsoft
Excel spreadsheet (with the file name
extension <code>.xlsx</code>). To be able to do this, a key thing to know is that even
though <code>.csv</code> and <code>.xlsx</code> files look almost identical when loaded into Excel,
the data themselves are stored completely differently. While <code>.csv</code> files are
plain text files, where the characters you see when you open the file in a text
editor are exactly the data they represent, this is not the case for <code>.xlsx</code>
files. Take a look at a snippet of what a <code>.xlsx</code> file would look like in a text editor:</p>
<pre><code>,?'O
    _rels/.rels???J1??&gt;E?{7?
&lt;?V????w8?'J???'QrJ???Tf?d??d?o?wZ'???@&gt;?4'?|??hlIo??F
t                                                       8f??3wn
????t??u"/
          %~Ed2??&lt;?w??
                       ?Pd(??J-?E???7?'t(?-GZ?????y???c~N?g[^_r?4
                                                                  yG?O
                                                                      ?K??G?


     ]TUEe??O??c[???????6q??s??d?m???\???H?^????3} ?rZY? ?:L60?^?????XTP+?|?
X?a??4VT?,D?Jq</code></pre>
<p>This type of file representation allows Excel files to store additional things
that you cannot store in a <code>.csv</code> file, such as fonts, text formatting,
graphics, multiple sheets and more. And despite looking odd in a plain text
editor, we can read Excel spreadsheets into R using the <code>readxl</code> package
developed specifically for this
purpose. </p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="reading.html#cb59-1" tabindex="-1"/><span class="fu">library</span>(readxl)</span>
<span id="cb59-2"><a href="reading.html#cb59-2" tabindex="-1"/></span>
<span id="cb59-3"><a href="reading.html#cb59-3" tabindex="-1"/>canlang_data <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">"data/can_lang.xlsx"</span>)</span>
<span id="cb59-4"><a href="reading.html#cb59-4" tabindex="-1"/>canlang_data</span></code></pre></div>
<pre><code>## # A tibble: 214 × 6
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ 204 more rows</code></pre>
<p>If the <code>.xlsx</code> file has multiple sheets, you have to use the <code>sheet</code> argument
to specify the sheet number or name. You can also specify cell ranges using the
<code>range</code> argument. This functionality is useful when a single sheet contains
multiple tables (a sad thing that happens to many Excel spreadsheets since this
makes reading in data more difficult).</p>
<p>As with plain text files, you should always explore the data file before
importing it into R. Exploring the data beforehand helps you decide which
arguments you need to load the data into R successfully. If you do not have
the Excel program on your computer, you can use other programs to preview the
file. Examples include Google Sheets and Libre Office.</p>
<p>In Table <a href="reading.html#tab:read-table">2.1</a> we summarize the <code>read_*</code> functions we covered
in this chapter. We also include the <code>read_csv2</code> function for data separated by
semicolons <code>;</code>, which you may run into with data sets where the decimal is
represented by a comma instead of a period (as with some data sets from
European countries).</p>
<table>
<caption><span id="tab:read-table">Table 2.1: </span> Summary of <code>read_*</code> functions</caption>
<thead>
<tr class="header">
<th>Data File Type</th>
<th>R Function</th>
<th>R Package</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Comma (<code>,</code>) separated files</td>
<td><code>read_csv</code></td>
<td><code>readr</code></td>
</tr>
<tr class="even">
<td>Tab (<code>\t</code>) separated files</td>
<td><code>read_tsv</code></td>
<td><code>readr</code></td>
</tr>
<tr class="odd">
<td>Semicolon (<code>;</code>) separated files</td>
<td><code>read_csv2</code></td>
<td><code>readr</code></td>
</tr>
<tr class="even">
<td>Various formats (<code>.csv</code>, <code>.tsv</code>)</td>
<td><code>read_delim</code></td>
<td><code>readr</code></td>
</tr>
<tr class="odd">
<td>Excel files (<code>.xlsx</code>)</td>
<td><code>read_excel</code></td>
<td><code>readxl</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Note:</strong> <code>readr</code> is a part of the <code>tidyverse</code> package so we did not need to load
this package separately since we loaded <code>tidyverse</code>.</p>
</blockquote>
</div>
<div id="reading-data-from-a-database" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Reading data from a database<a href="reading.html#reading-data-from-a-database" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>Another very common form of data storage is the relational database. Databases
are great when you have large data sets or multiple users
working on a project. There are many relational database management systems,
such as SQLite, MySQL, PostgreSQL, Oracle,
and many more. These
different relational database management systems each have their own advantages
and limitations. Almost all employ SQL (<em>structured query language</em>) to obtain
data from the database. But you don’t need to know SQL to analyze data from
a database; several packages have been written that allow you to connect to
relational databases and use the R programming language
to obtain data. In this book, we will give examples of how to do this
using R with SQLite and PostgreSQL databases.</p>
<div id="reading-data-from-a-sqlite-database" class="section level3 hasAnchor" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> Reading data from a SQLite database<a href="reading.html#reading-data-from-a-sqlite-database" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>SQLite is probably the simplest relational database system
that one can use in combination with R. SQLite databases are self-contained, and are
usually stored and accessed locally on one computer from
a file with a <code>.db</code> extension (or sometimes an <code>.sqlite</code> extension).
Similar to Excel files, these are not plain text
files and cannot be read in a plain text editor.</p>
<p>The first thing you need to do to read data into R from a database is to
connect to the database. We do that using the <code>dbConnect</code> function from the
<code>DBI</code> (database interface) package. This does not read
in the data, but simply tells R where the database is and opens up a
communication channel that R can use to send SQL commands to the database.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="reading.html#cb61-1" tabindex="-1"/><span class="fu">library</span>(DBI)</span>
<span id="cb61-2"><a href="reading.html#cb61-2" tabindex="-1"/></span>
<span id="cb61-3"><a href="reading.html#cb61-3" tabindex="-1"/>canlang_conn <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(RSQLite<span class="sc">::</span><span class="fu">SQLite</span>(), <span class="st">"data/can_lang.db"</span>)</span></code></pre></div>
<p>Often relational databases have many tables; thus, in order to retrieve
data from a database, you need to know the name of the table
in which the data is stored. You can get the names of
all the tables in the database using the <code>dbListTables</code>
function:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="reading.html#cb62-1" tabindex="-1"/>tables <span class="ot">&lt;-</span> <span class="fu">dbListTables</span>(canlang_conn)</span>
<span id="cb62-2"><a href="reading.html#cb62-2" tabindex="-1"/>tables</span></code></pre></div>
<pre><code>## [1] "lang"</code></pre>
<p>The <code>dbListTables</code> function returned only one name, which tells us
that there is only one table in this database. To reference a table in the
database (so that we can perform operations like selecting columns and filtering rows), we
use the <code>tbl</code> function from the <code>dbplyr</code> package. The object returned
by the <code>tbl</code> function allows us to work with data
stored in databases as if they were just regular data frames; but secretly, behind
the scenes, <code>dbplyr</code> is turning your function calls (e.g., <code>select</code> and <code>filter</code>)
into SQL queries!</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="reading.html#cb64-1" tabindex="-1"/><span class="fu">library</span>(dbplyr)</span>
<span id="cb64-2"><a href="reading.html#cb64-2" tabindex="-1"/></span>
<span id="cb64-3"><a href="reading.html#cb64-3" tabindex="-1"/>lang_db <span class="ot">&lt;-</span> <span class="fu">tbl</span>(canlang_conn, <span class="st">"lang"</span>)</span>
<span id="cb64-4"><a href="reading.html#cb64-4" tabindex="-1"/>lang_db</span></code></pre></div>
<pre><code>## # Source:   table&lt;lang&gt; [?? x 6]
## # Database: sqlite 3.41.2 [/home/rstudio/introduction-to-datascience/data/can_lang.db]
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Non-Official &amp; N… Afrikaa…         10260         4785           85      23415
##  3 Non-Official &amp; N… Afro-As…          1150          445           10       2775
##  4 Non-Official &amp; N… Akan (T…         13460         5985           25      22150
##  5 Non-Official &amp; N… Albanian         26895        13135          345      31930
##  6 Aboriginal langu… Algonqu…            45           10            0        120
##  7 Aboriginal langu… Algonqu…          1260          370           40       2480
##  8 Non-Official &amp; N… America…          2685         3020         1145      21930
##  9 Non-Official &amp; N… Amharic          22465        12785          200      33670
## 10 Non-Official &amp; N… Arabic          419890       223535         5585     629055
## # ℹ more rows</code></pre>
<p>Although it looks like we just got a data frame from the database, we didn’t!
It’s a <em>reference</em>; the data is still stored only in the SQLite database. The
<code>dbplyr</code> package works this way because databases are often more efficient at selecting, filtering
and joining large data sets than R. And typically the database will not even
be stored on your computer, but rather a more powerful machine somewhere on the
web. So R is lazy and waits to bring this data into memory until you explicitly
tell it to using the <code>collect</code> function.
Figure <a href="reading.html#fig:01-ref-vs-tibble">2.2</a> highlights the difference
between a <code>tibble</code> object in R and the output we just created. Notice in the table
on the right, the first two lines of the output indicate the source is SQL. The
last line doesn’t show how many rows there are (R is trying to avoid performing
expensive query operations), whereas the output for the <code>tibble</code> object does.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:01-ref-vs-tibble"/>
<img src="../Images/644b8e6e6420e21cc8ece51f5a45cc35.png" alt="Comparison of a reference to data in a database and a tibble in R." width="80%" data-original-src="https://datasciencebook.ca/_main_files/figure-html/01-ref-vs-tibble-1.png"/>
<p class="caption">
Figure 2.2: Comparison of a reference to data in a database and a tibble in R.
</p>
</div>
<p>We can look at the SQL commands that are sent to the database when we write
<code>tbl(canlang_conn, "lang")</code> in R with the <code>show_query</code> function from the
<code>dbplyr</code> package. </p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="reading.html#cb66-1" tabindex="-1"/><span class="fu">show_query</span>(<span class="fu">tbl</span>(canlang_conn, <span class="st">"lang"</span>))</span></code></pre></div>
<pre><code>## &lt;SQL&gt;
## SELECT *
## FROM `lang`</code></pre>
<p>The output above shows the SQL code that is sent to the database. When we
write <code>tbl(canlang_conn, "lang")</code> in R, in the background, the function is
translating the R code into SQL, sending that SQL to the database, and then translating the
response for us. So <code>dbplyr</code> does all the hard work of translating from R to SQL and back for us;
we can just stick with R!</p>
<p>With our <code>lang_db</code> table reference for the 2016 Canadian Census data in hand, we
can mostly continue onward as if it were a regular data frame. For example, let’s do the same exercise
from Chapter <a href="intro.html#intro">1</a>: we will obtain only those rows corresponding to Aboriginal languages, and keep only
the <code>language</code> and <code>mother_tongue</code> columns.
We can use the <code>filter</code> function to obtain only certain rows. Below we filter the data to include only Aboriginal languages.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="reading.html#cb68-1" tabindex="-1"/>aboriginal_lang_db <span class="ot">&lt;-</span> <span class="fu">filter</span>(lang_db, category <span class="sc">==</span> <span class="st">"Aboriginal languages"</span>)</span>
<span id="cb68-2"><a href="reading.html#cb68-2" tabindex="-1"/>aboriginal_lang_db</span></code></pre></div>
<pre><code>## # Source:   SQL [?? x 6]
## # Database: sqlite 3.41.2 [/home/rstudio/introduction-to-datascience/data/can_lang.db]
##    category          language mother_tongue most_at_home most_at_work lang_known
##    &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1 Aboriginal langu… Aborigi…           590          235           30        665
##  2 Aboriginal langu… Algonqu…            45           10            0        120
##  3 Aboriginal langu… Algonqu…          1260          370           40       2480
##  4 Aboriginal langu… Athabas…            50           10            0         85
##  5 Aboriginal langu… Atikame…          6150         5465         1100       6645
##  6 Aboriginal langu… Babine …           110           20           10        210
##  7 Aboriginal langu… Beaver             190           50            0        340
##  8 Aboriginal langu… Blackfo…          2815         1110           85       5645
##  9 Aboriginal langu… Carrier           1025          250           15       2100
## 10 Aboriginal langu… Cayuga              45           10           10        125
## # ℹ more rows</code></pre>
<p>Above you can again see the hints that this data is not actually stored in R yet:
the source is <code>SQL [?? x 6]</code> and the output says <code>... more rows</code> at the end
(both indicating that R does not know how many rows there are in total!),
and a database type <code>sqlite</code> is listed.
We didn’t use the <code>collect</code> function because we are not ready to bring the data into R yet.
We can still use the database to do some work to obtain <em>only</em> the small amount of data we want to work with locally
in R. Let’s add the second part of our database query: selecting only the <code>language</code> and <code>mother_tongue</code> columns
using the <code>select</code> function.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="reading.html#cb70-1" tabindex="-1"/>aboriginal_lang_selected_db <span class="ot">&lt;-</span> <span class="fu">select</span>(aboriginal_lang_db, language, mother_tongue)</span>
<span id="cb70-2"><a href="reading.html#cb70-2" tabindex="-1"/>aboriginal_lang_selected_db</span></code></pre></div>
<pre><code>## # Source:   SQL [?? x 2]
## # Database: sqlite 3.41.2 [/home/rstudio/introduction-to-datascience/data/can_lang.db]
##    language                     mother_tongue
##    &lt;chr&gt;                                &lt;dbl&gt;
##  1 Aboriginal languages, n.o.s.           590
##  2 Algonquian languages, n.i.e.            45
##  3 Algonquin                             1260
##  4 Athabaskan languages, n.i.e.            50
##  5 Atikamekw                             6150
##  6 Babine (Wetsuwet'en)                   110
##  7 Beaver                                 190
##  8 Blackfoot                             2815
##  9 Carrier                               1025
## 10 Cayuga                                  45
## # ℹ more rows</code></pre>
<p>Now you can see that the database will return only the two columns we asked for with the <code>select</code> function.
In order to actually retrieve this data in R as a data frame,
we use the <code>collect</code> function.
Below you will see that after running <code>collect</code>, R knows that the retrieved
data has 67 rows, and there is no database listed any more.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="reading.html#cb72-1" tabindex="-1"/>aboriginal_lang_data <span class="ot">&lt;-</span> <span class="fu">collect</span>(aboriginal_lang_selected_db)</span>
<span id="cb72-2"><a href="reading.html#cb72-2" tabindex="-1"/>aboriginal_lang_data</span></code></pre></div>
<pre><code>## # A tibble: 67 × 2
##    language                     mother_tongue
##    &lt;chr&gt;                                &lt;dbl&gt;
##  1 Aboriginal languages, n.o.s.           590
##  2 Algonquian languages, n.i.e.            45
##  3 Algonquin                             1260
##  4 Athabaskan languages, n.i.e.            50
##  5 Atikamekw                             6150
##  6 Babine (Wetsuwet'en)                   110
##  7 Beaver                                 190
##  8 Blackfoot                             2815
##  9 Carrier                               1025
## 10 Cayuga                                  45
## # ℹ 57 more rows</code></pre>
<p>Aside from knowing the number of rows, the data looks pretty similar in both
outputs shown above. And <code>dbplyr</code> provides many more functions (not just <code>filter</code>)
that you can use to directly feed the database reference (<code>lang_db</code>) into
downstream analysis functions (e.g., <code>ggplot2</code> for data visualization).
But <code>dbplyr</code> does not provide <em>every</em> function that we need for analysis;
we do eventually need to call <code>collect</code>.
For example, look what happens when we try to use <code>nrow</code> to count rows
in a data frame: </p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="reading.html#cb74-1" tabindex="-1"/><span class="fu">nrow</span>(aboriginal_lang_selected_db)</span></code></pre></div>
<pre><code>## [1] NA</code></pre>
<p>or <code>tail</code> to preview the last six rows of a data frame:
</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="reading.html#cb76-1" tabindex="-1"/><span class="fu">tail</span>(aboriginal_lang_selected_db)</span></code></pre></div>
<pre><code>## Error: tail() is not supported by sql sources</code></pre>
<div style="page-break-after: always;"/>
<p>Additionally, some operations will not work to extract columns or single values
from the reference given by the <code>tbl</code> function. Thus, once you have finished
your data wrangling of the <code>tbl</code> database reference object, it is advisable to
bring it into R as a data frame using <code>collect</code>.
But be very careful using <code>collect</code>: databases are often <em>very</em> big,
and reading an entire table into R might take a long time to run or even possibly
crash your machine. So make sure you use <code>filter</code> and <code>select</code> on the database table
to reduce the data to a reasonable size before using <code>collect</code> to read it into R!</p>
</div>
<div id="reading-data-from-a-postgresql-database" class="section level3 hasAnchor" number="2.6.2">
<h3><span class="header-section-number">2.6.2</span> Reading data from a PostgreSQL database<a href="reading.html#reading-data-from-a-postgresql-database" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>PostgreSQL (also called Postgres) is a very popular
and open-source option for relational database software.
Unlike SQLite,
PostgreSQL uses a client–server database engine, as it was designed to be used
and accessed on a network. This means that you have to provide more information
to R when connecting to Postgres databases. The additional information that you
need to include when you call the <code>dbConnect</code> function is listed below:</p>
<ul>
<li><code>dbname</code>: the name of the database (a single PostgreSQL instance can host more than one database)</li>
<li><code>host</code>: the URL pointing to where the database is located</li>
<li><code>port</code>: the communication endpoint between R and the PostgreSQL database (usually <code>5432</code>)</li>
<li><code>user</code>: the username for accessing the database</li>
<li><code>password</code>: the password for accessing the database</li>
</ul>
<p>Additionally, we must use the <code>RPostgres</code> package instead of <code>RSQLite</code> in the
<code>dbConnect</code> function call. Below we demonstrate how to connect to a version of
the <code>can_mov_db</code> database, which contains information about Canadian movies.
Note that the <code>host</code> (<code>fakeserver.stat.ubc.ca</code>), <code>user</code> (<code>user0001</code>), and
<code>password</code> (<code>abc123</code>) below are <em>not real</em>; you will not actually
be able to connect to a database using this information.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="reading.html#cb78-1" tabindex="-1"/><span class="fu">library</span>(RPostgres)</span>
<span id="cb78-2"><a href="reading.html#cb78-2" tabindex="-1"/>canmov_conn <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(RPostgres<span class="sc">::</span><span class="fu">Postgres</span>(), <span class="at">dbname =</span> <span class="st">"can_mov_db"</span>,</span>
<span id="cb78-3"><a href="reading.html#cb78-3" tabindex="-1"/>                        <span class="at">host =</span> <span class="st">"fakeserver.stat.ubc.ca"</span>, <span class="at">port =</span> <span class="dv">5432</span>,</span>
<span id="cb78-4"><a href="reading.html#cb78-4" tabindex="-1"/>                        <span class="at">user =</span> <span class="st">"user0001"</span>, <span class="at">password =</span> <span class="st">"abc123"</span>)</span></code></pre></div>
<p>After opening the connection, everything looks and behaves almost identically
to when we were using an SQLite database in R. For example, we can again use
<code>dbListTables</code> to find out what tables are in the <code>can_mov_db</code> database:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="reading.html#cb79-1" tabindex="-1"/><span class="fu">dbListTables</span>(canmov_conn)</span></code></pre></div>
<pre><code> [1] "themes"            "medium"           "titles"     "title_aliases"       "forms"
 [6] "episodes"          "names"      "names_occupations" "occupation"       "ratings"</code></pre>
<p>We see that there are 10 tables in this database. Let’s first look at the
<code>"ratings"</code> table to find the lowest rating that exists in the <code>can_mov_db</code>
database:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="reading.html#cb81-1" tabindex="-1"/>ratings_db <span class="ot">&lt;-</span> <span class="fu">tbl</span>(canmov_conn, <span class="st">"ratings"</span>)</span>
<span id="cb81-2"><a href="reading.html#cb81-2" tabindex="-1"/>ratings_db</span></code></pre></div>
<pre><code># Source:   table&lt;ratings&gt; [?? x 3]
# Database: postgres [user0001@fakeserver.stat.ubc.ca:5432/can_mov_db]
   title              average_rating num_votes
   &lt;chr&gt;                    &lt;dbl&gt;     &lt;int&gt;
 1 The Grand Seduction       6.6       150
 2 Rhymes for Young Ghouls   6.3      1685
 3 Mommy                     7.5      1060
 4 Incendies                 6.1      1101
 5 Bon Cop, Bad Cop          7.0       894
 6 Goon                      5.5      1111
 7 Monsieur Lazhar           5.6       610
 8 What if                   5.3      1401
 9 The Barbarian Invations   5.8        99
10 Away from Her             6.9      2311
# … with more rows</code></pre>
<p>To find the lowest rating that exists in the data base, we first need to
extract the <code>average_rating</code> column using <code>select</code>:
</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="reading.html#cb83-1" tabindex="-1"/>avg_rating_db <span class="ot">&lt;-</span> <span class="fu">select</span>(ratings_db, average_rating)</span>
<span id="cb83-2"><a href="reading.html#cb83-2" tabindex="-1"/>avg_rating_db</span></code></pre></div>
<pre><code># Source:   lazy query [?? x 1]
# Database: postgres [user0001@fakeserver.stat.ubc.ca:5432/can_mov_db]
   average_rating
            &lt;dbl&gt;
 1            6.6
 2            6.3
 3            7.5
 4            6.1
 5            7.0
 6            5.5
 7            5.6
 8            5.3
 9            5.8
10            6.9
# … with more rows</code></pre>
<p>Next we use <code>min</code> to find the minimum rating in that column:
</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="reading.html#cb85-1" tabindex="-1"/><span class="fu">min</span>(avg_rating_db)</span></code></pre></div>
<pre><code>Error in min(avg_rating_db) : invalid 'type' (list) of argument</code></pre>
<p>Instead of the minimum, we get an error! This is another example of when we
need to use the <code>collect</code> function to bring the data into R for further
computation:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="reading.html#cb87-1" tabindex="-1"/>avg_rating_data <span class="ot">&lt;-</span> <span class="fu">collect</span>(avg_rating_db)</span>
<span id="cb87-2"><a href="reading.html#cb87-2" tabindex="-1"/><span class="fu">min</span>(avg_rating_data)</span></code></pre></div>
<pre><code>[1] 1</code></pre>
<p>We see the lowest rating given to a movie is 1, indicating that it must have
been a really bad movie…</p>
</div>
<div id="why-should-we-bother-with-databases-at-all" class="section level3 hasAnchor" number="2.6.3">
<h3><span class="header-section-number">2.6.3</span> Why should we bother with databases at all?<a href="reading.html#why-should-we-bother-with-databases-at-all" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Opening a database
involved a lot more effort than just opening a <code>.csv</code>, <code>.tsv</code>, or any of the
other plain text or Excel formats. We had to open a connection to the database,
then use <code>dbplyr</code> to translate <code>tidyverse</code>-like
commands (<code>filter</code>, <code>select</code> etc.) into SQL commands that the database
understands, and then finally <code>collect</code> the results. And not
all <code>tidyverse</code> commands can currently be translated to work with
databases. For example, we can compute a mean with a database
but can’t easily compute a median. So you might be wondering: why should we use
databases at all?</p>
<p>Databases are beneficial in a large-scale setting:</p>
<ul>
<li>They enable storing large data sets across multiple computers with backups.</li>
<li>They provide mechanisms for ensuring data integrity and validating input.</li>
<li>They provide security and data access control.</li>
<li>They allow multiple users to access data simultaneously
and remotely without conflicts and errors.
For example, there are billions of Google searches conducted daily in 2021 <span class="citation">(<a href="#ref-googlesearches">Real Time Statistics Project 2021</a>)</span>.
Can you imagine if Google stored all of the data
from those searches in a single <code>.csv</code> file!? Chaos would ensue!</li>
</ul>
</div>
</div>
<div id="writing-data-from-r-to-a-.csv-file" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Writing data from R to a <code>.csv</code> file<a href="reading.html#writing-data-from-r-to-a-.csv-file" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>At the middle and end of a data analysis, we often want to write a data frame
that has changed (either through filtering, selecting, mutating or summarizing)
to a file to share it with others or use it for another step in the analysis.
The most straightforward way to do this is to use the <code>write_csv</code> function
from the <code>tidyverse</code> package. The default
arguments for this file are to use a comma (<code>,</code>) as the delimiter and include
column names. Below we demonstrate creating a new version of the Canadian
languages data set without the official languages category according to the
Canadian 2016 Census, and then writing this to a <code>.csv</code> file:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="reading.html#cb89-1" tabindex="-1"/>no_official_lang_data <span class="ot">&lt;-</span> <span class="fu">filter</span>(can_lang, category <span class="sc">!=</span> <span class="st">"Official languages"</span>)</span>
<span id="cb89-2"><a href="reading.html#cb89-2" tabindex="-1"/><span class="fu">write_csv</span>(no_official_lang_data, <span class="st">"data/no_official_languages.csv"</span>)</span></code></pre></div>
</div>
<div id="obtaining-data-from-the-web" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Obtaining data from the web<a href="reading.html#obtaining-data-from-the-web" class="anchor-section" aria-label="Anchor link to header"/></h2>
<blockquote>
<p><strong>Note:</strong> This section is not required reading for the remainder of the textbook. It
is included for those readers interested in learning a little bit more about
how to obtain different types of data from the web.</p>
</blockquote>
<p>Data doesn’t just magically appear on your computer; you need to get it from
somewhere. Earlier in the chapter we showed you how to access data stored in a
plain text, spreadsheet-like format (e.g., comma- or tab-separated) from a web
URL using one of the <code>read_*</code> functions from the <code>tidyverse</code>. But as time goes
on, it is increasingly uncommon to find data (especially large amounts of data)
in this format available for download from a URL. Instead, websites now often
offer something known as an <strong>a</strong>pplication <strong>p</strong>rogramming <strong>i</strong>nterface
(API), which
provides a programmatic way to ask for subsets of a data set. This allows the
website owner to control <em>who</em> has access to the data, <em>what portion</em> of the
data they have access to, and <em>how much</em> data they can access. Typically, the
website owner will give you a <em>token</em> or <em>key</em> (a secret string of characters somewhat
like a password) that you have to provide when accessing the API.</p>
<p>Another interesting thought: websites themselves <em>are</em> data! When you type a
URL into your browser window, your browser asks the <em>web server</em> (another
computer on the internet whose job it is to respond to requests for the
website) to give it the website’s data, and then your browser translates that
data into something you can see. If the website shows you some information that
you’re interested in, you could <em>create</em> a data set for yourself by copying and
pasting that information into a file. This process of taking information
directly from what a website displays is called
<em>web scraping</em> (or sometimes <em>screen scraping</em>). Now, of course, copying and pasting
information manually is a painstaking and error-prone process, especially when
there is a lot of information to gather. So instead of asking your browser to
translate the information that the web server provides into something you can
see, you can collect that data programmatically—in the form of
<strong>h</strong>yper<strong>t</strong>ext <strong>m</strong>arkup <strong>l</strong>anguage
(HTML)
and <strong>c</strong>ascading <strong>s</strong>tyle <strong>s</strong>heet (CSS) code—and process it
to extract useful information. HTML provides the
basic structure of a site and tells the webpage how to display the content
(e.g., titles, paragraphs, bullet lists etc.), whereas CSS helps style the
content and tells the webpage how the HTML elements should
be presented (e.g., colors, layouts, fonts etc.).</p>
<p>This subsection will show you the basics of both web scraping
with the <a href="https://rvest.tidyverse.org/"><code>rvest</code> R package</a> <span class="citation">(<a href="#ref-rvest">Wickham 2021a</a>)</span>
and accessing the NASA “Astronomy Picture of the Day” API
using the <a href="https://httr2.r-lib.org/"><code>httr2</code> R package</a> <span class="citation">(<a href="#ref-httr2">Wickham 2023</a>)</span>.</p>
<div id="web-scraping" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> Web scraping<a href="reading.html#web-scraping" class="anchor-section" aria-label="Anchor link to header"/></h3>
<div id="html-and-css-selectors" class="section level4 unnumbered hasAnchor">
<h4>HTML and CSS selectors<a href="reading.html#html-and-css-selectors" class="anchor-section" aria-label="Anchor link to header"/></h4>
<p>When you enter a URL into your browser, your browser connects to the
web server at that URL and asks for the <em>source code</em> for the website.
This is the data that the browser translates
into something you can see; so if we
are going to create our own data by scraping a website, we have to first understand
what that data looks like! For example, let’s say we are interested
in knowing the average rental price (per square foot) of the most recently
available one-bedroom apartments in Vancouver
on <a href="https://vancouver.craigslist.org">Craiglist</a>. When we visit the Vancouver Craigslist
website and search for one-bedroom apartments,
we should see something similar to Figure <a href="reading.html#fig:craigslist-human">2.3</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:craigslist-human"/>
<img src="../Images/fce9741a1b5a134651ced601de368d33.png" alt="Craigslist webpage of advertisements for one-bedroom apartments." width="100%" data-original-src="https://datasciencebook.ca/img/reading/craigslist_human.png"/>
<p class="caption">
Figure 2.3: Craigslist webpage of advertisements for one-bedroom apartments.
</p>
</div>
<p>Based on what our browser shows us, it’s pretty easy to find the size and price
for each apartment listed. But we would like to be able to obtain that information
using R, without any manual human effort or copying and pasting. We do this by
examining the <em>source code</em> that the web server actually sent our browser to
display for us. We show a snippet of it below; the
entire source
is <a href="https://github.com/UBC-DSCI/introduction-to-datascience/blob/main/img/reading/website_source.txt">included with the code for this book</a>:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb90-1"><a href="reading.html#cb90-1" tabindex="-1"/><span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-meta"</span><span class="kw">&gt;</span></span>
<span id="cb90-2"><a href="reading.html#cb90-2" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-price"</span><span class="kw">&gt;</span>$800<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-3"><a href="reading.html#cb90-3" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"housing"</span><span class="kw">&gt;</span></span>
<span id="cb90-4"><a href="reading.html#cb90-4" tabindex="-1"/>            1br -</span>
<span id="cb90-5"><a href="reading.html#cb90-5" tabindex="-1"/>        <span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-6"><a href="reading.html#cb90-6" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-hood"</span><span class="kw">&gt;</span> (13768 108th Avenue)<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-7"><a href="reading.html#cb90-7" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-tags"</span><span class="kw">&gt;</span></span>
<span id="cb90-8"><a href="reading.html#cb90-8" tabindex="-1"/>            <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"maptag"</span> <span class="er">data-pid</span><span class="ot">=</span><span class="st">"6786042973"</span><span class="kw">&gt;</span>map<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-9"><a href="reading.html#cb90-9" tabindex="-1"/>        <span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-10"><a href="reading.html#cb90-10" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"banish icon icon-trash"</span> <span class="er">role</span><span class="ot">=</span><span class="st">"button"</span><span class="kw">&gt;</span></span>
<span id="cb90-11"><a href="reading.html#cb90-11" tabindex="-1"/>            <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"screen-reader-text"</span><span class="kw">&gt;</span>hide this posting<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-12"><a href="reading.html#cb90-12" tabindex="-1"/>        <span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-13"><a href="reading.html#cb90-13" tabindex="-1"/>    <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"unbanish icon icon-trash red"</span> <span class="er">role</span><span class="ot">=</span><span class="st">"button"</span><span class="kw">&gt;&lt;/span&gt;</span></span>
<span id="cb90-14"><a href="reading.html#cb90-14" tabindex="-1"/>    <span class="kw">&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">"#"</span> <span class="er">class</span><span class="ot">=</span><span class="st">"restore-link"</span><span class="kw">&gt;</span></span>
<span id="cb90-15"><a href="reading.html#cb90-15" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"restore-narrow-text"</span><span class="kw">&gt;</span>restore<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-16"><a href="reading.html#cb90-16" tabindex="-1"/>        <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"restore-wide-text"</span><span class="kw">&gt;</span>restore this posting<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-17"><a href="reading.html#cb90-17" tabindex="-1"/>    <span class="kw">&lt;/a&gt;</span></span>
<span id="cb90-18"><a href="reading.html#cb90-18" tabindex="-1"/>    <span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-price"</span><span class="kw">&gt;</span>$2285<span class="kw">&lt;/span&gt;</span></span>
<span id="cb90-19"><a href="reading.html#cb90-19" tabindex="-1"/><span class="kw">&lt;/span&gt;</span></span></code></pre></div>
<p>Oof…you can tell that the source code for a web page is not really designed
for humans to understand easily. However, if you look through it closely, you
will find that the information we’re interested in is hidden among the muck.
For example, near the top of the snippet
above you can see a line that looks like</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb91-1"><a href="reading.html#cb91-1" tabindex="-1"/><span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-price"</span><span class="kw">&gt;</span>$800<span class="kw">&lt;/span&gt;</span></span></code></pre></div>
<p>That snippet is definitely storing the price of a particular apartment. With some more
investigation, you should be able to find things like the date and time of the
listing, the address of the listing, and more. So this source code most likely
contains all the information we are interested in!</p>
<p>Let’s dig into that line above a bit more. You can see that
that bit of code has an <em>opening tag</em> (words between <code>&lt;</code> and <code>&gt;</code>, like
<code>&lt;span&gt;</code>) and a <em>closing tag</em> (the same with a slash, like <code>&lt;/span&gt;</code>). HTML
source code generally stores its data between opening and closing tags like
these. Tags are keywords that tell the web browser how to display or format
the content. Above you can see that the information we want (<code>$800</code>) is stored
between an opening and closing tag (<code>&lt;span&gt;</code> and <code>&lt;/span&gt;</code>). In the opening
tag, you can also see a very useful “class” (a special word that is sometimes
included with opening tags): <code>class="result-price"</code>. Since we want R to
programmatically sort through all of the source code for the website to find
apartment prices, maybe we can look for all the tags with the <code>"result-price"</code>
class, and grab the information between the opening and closing tag. Indeed,
take a look at another line of the source snippet above:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb92-1"><a href="reading.html#cb92-1" tabindex="-1"/><span class="kw">&lt;span</span> <span class="er">class</span><span class="ot">=</span><span class="st">"result-price"</span><span class="kw">&gt;</span>$2285<span class="kw">&lt;/span&gt;</span></span></code></pre></div>
<p>It’s yet another price for an apartment listing, and the tags surrounding it
have the <code>"result-price"</code> class. Wonderful! Now that we know what pattern we
are looking for—a dollar amount between opening and closing tags that have the
<code>"result-price"</code> class—we should be able to use code to pull out all of the
matching patterns from the source code to obtain our data. This sort of “pattern”
is known as a <em>CSS selector</em> (where CSS stands for <strong>c</strong>ascading <strong>s</strong>tyle <strong>s</strong>heet).</p>
<p>The above was a simple example of “finding the pattern to look for”; many
websites are quite a bit larger and more complex, and so is their website
source code. Fortunately, there are tools available to make this process
easier. For example,
<a href="https://selectorgadget.com/">SelectorGadget</a> is
an open-source tool that simplifies identifying the generating
and finding of CSS selectors.
At the end of the chapter in the additional resources section, we include a link to
a short video on how to install and use the SelectorGadget tool to
obtain CSS selectors for use in web scraping.
After installing and enabling the tool, you can click the
website element for which you want an appropriate selector. For
example, if we click the price of an apartment listing, we
find that SelectorGadget shows us the selector <code>.result-price</code>
in its toolbar, and highlights all the other apartment
prices that would be obtained using that selector (Figure <a href="reading.html#fig:sg1">2.4</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sg1"/>
<img src="../Images/6bf9321fa7f33a1d701629a65a413364.png" alt="Using the SelectorGadget on a Craigslist webpage to obtain the CCS selector useful for obtaining apartment prices." width="100%" data-original-src="https://datasciencebook.ca/img/reading/sg1.png"/>
<p class="caption">
Figure 2.4: Using the SelectorGadget on a Craigslist webpage to obtain the CCS selector useful for obtaining apartment prices.
</p>
</div>
<p>If we then click the size of an apartment listing, SelectorGadget shows us
the <code>span</code> selector, and highlights many of the lines on the page; this indicates that the
<code>span</code> selector is not specific enough to capture only apartment sizes (Figure <a href="reading.html#fig:sg3">2.5</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sg3"/>
<img src="../Images/f2bbd137a9a2a37135db206878c2f424.png" alt="Using the SelectorGadget on a Craigslist webpage to obtain a CCS selector useful for obtaining apartment sizes." width="100%" data-original-src="https://datasciencebook.ca/img/reading/sg3.png"/>
<p class="caption">
Figure 2.5: Using the SelectorGadget on a Craigslist webpage to obtain a CCS selector useful for obtaining apartment sizes.
</p>
</div>
<p>To narrow the selector, we can click one of the highlighted elements that
we <em>do not</em> want. For example, we can deselect the “pic/map” links,
resulting in only the data we want highlighted using the <code>.housing</code> selector (Figure <a href="reading.html#fig:sg2">2.6</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sg2"/>
<img src="../Images/823b84515ed7ca73018a23f0291e87fb.png" alt="Using the SelectorGadget on a Craigslist webpage to refine the CCS selector to one that is most useful for obtaining apartment sizes." width="100%" data-original-src="https://datasciencebook.ca/img/reading/sg2.png"/>
<p class="caption">
Figure 2.6: Using the SelectorGadget on a Craigslist webpage to refine the CCS selector to one that is most useful for obtaining apartment sizes.
</p>
</div>
<p>So to scrape information about the square footage and rental price
of apartment listings, we need to use
the two CSS selectors <code>.housing</code> and <code>.result-price</code>, respectively.
The selector gadget returns them to us as a comma-separated list (here
<code>.housing , .result-price</code>), which is exactly the format we need to provide to
R if we are using more than one CSS selector.</p>
<p><strong>Caution: are you allowed to scrape that website?</strong></p>
<p><em>Before</em> scraping data from the web, you should always check whether or not
you are <em>allowed</em> to scrape it! There are two documents that are important
for this: the <code>robots.txt</code> file and the Terms of Service
document. If we take a look at <a href="https://www.craigslist.org/about/terms.of.use">Craigslist’s Terms of Service document</a>,
we find the following text: <em>“You agree not to copy/collect CL content
via robots, spiders, scripts, scrapers, crawlers, or any automated or manual equivalent (e.g., by hand).”</em>
So unfortunately, without explicit permission, we are not allowed to scrape the website.</p>
<p>What to do now? Well, we <em>could</em> ask the owner of Craigslist for permission to scrape.
However, we are not likely to get a response, and even if we did they would not likely give us permission.
The more realistic answer is that we simply cannot scrape Craigslist. If we still want
to find data about rental prices in Vancouver, we must go elsewhere.
To continue learning how to scrape data from the web, let’s instead
scrape data on the population of Canadian cities from Wikipedia.
We have checked the <a href="https://foundation.wikimedia.org/wiki/Terms_of_Use/en">Terms of Service document</a>,
and it does not mention that web scraping is disallowed.
We will use the SelectorGadget tool to pick elements that we are interested in
(city names and population counts) and deselect others to indicate that we are not
interested in them (province names), as shown in Figure <a href="reading.html#fig:sg4">2.7</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sg4"/>
<img src="../Images/269904fe994aa7a23ceec98ef4e61929.png" alt="Using the SelectorGadget on a Wikipedia webpage." width="100%" data-original-src="https://datasciencebook.ca/img/reading/sg4.png"/>
<p class="caption">
Figure 2.7: Using the SelectorGadget on a Wikipedia webpage.
</p>
</div>
<p>We include a link to a short video tutorial on this process at the end of the chapter
in the additional resources section. SelectorGadget provides in its toolbar
the following list of CSS selectors to use:</p>
<pre><code>td:nth-child(8) ,
td:nth-child(4) ,
.largestCities-cell-background+ td a</code></pre>
<p>Now that we have the CSS selectors that describe the properties of the elements
that we want to target, we can use them to find certain elements in web pages and extract data.</p>
</div>
<div id="using-rvest" class="section level4 unnumbered hasAnchor">
<h4>Using <code>rvest</code><a href="reading.html#using-rvest" class="anchor-section" aria-label="Anchor link to header"/></h4>
<p>We will use the <code>rvest</code> R package to scrape data from the Wikipedia page.
We start by loading the <code>rvest</code> package:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="reading.html#cb94-1" tabindex="-1"/><span class="fu">library</span>(rvest)</span></code></pre></div>
<p>Next, we tell R what page we want to scrape by providing the webpage’s URL in quotations to the function <code>read_html</code>:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="reading.html#cb95-1" tabindex="-1"/>page <span class="ot">&lt;-</span> <span class="fu">read_html</span>(<span class="st">"https://en.wikipedia.org/wiki/Canada"</span>)</span></code></pre></div>
<p>The <code>read_html</code> function directly downloads the source code for the page at
the URL you specify, just like your browser would if you navigated to that site. But
instead of displaying the website to you, the <code>read_html</code> function just returns
the HTML source code itself, which we have
stored in the <code>page</code> variable. Next, we send the page object to the <code>html_nodes</code>
function, along with the CSS selectors we obtained from
the SelectorGadget tool. Make sure to surround the selectors with quotation marks; the function, <code>html_nodes</code>, expects that
argument is a string. We store the result of the <code>html_nodes</code> function in the <code>population_nodes</code> variable.
Note that below we use the <code>paste</code> function with a comma separator (<code>sep=","</code>)
to build the list of selectors. The <code>paste</code> function converts
elements to characters and combines the values into a list. We use this function to
build the list of selectors to maintain code readability; this avoids
having a very long line of code.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="reading.html#cb96-1" tabindex="-1"/>selectors <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"td:nth-child(8)"</span>,</span>
<span id="cb96-2"><a href="reading.html#cb96-2" tabindex="-1"/>             <span class="st">"td:nth-child(4)"</span>,</span>
<span id="cb96-3"><a href="reading.html#cb96-3" tabindex="-1"/>             <span class="st">".largestCities-cell-background+ td a"</span>, <span class="at">sep =</span> <span class="st">","</span>)</span>
<span id="cb96-4"><a href="reading.html#cb96-4" tabindex="-1"/></span>
<span id="cb96-5"><a href="reading.html#cb96-5" tabindex="-1"/>population_nodes <span class="ot">&lt;-</span> <span class="fu">html_nodes</span>(page, selectors)</span>
<span id="cb96-6"><a href="reading.html#cb96-6" tabindex="-1"/><span class="fu">head</span>(population_nodes)</span></code></pre></div>
<pre><code>## {xml_nodeset (6)}
## [1] &lt;a href="/wiki/Greater_Toronto_Area" title="Greater Toronto Area"&gt;Toronto ...
## [2] &lt;td style="text-align:right;"&gt;6,202,225&lt;/td&gt;
## [3] &lt;a href="/wiki/London,_Ontario" title="London, Ontario"&gt;London&lt;/a&gt;
## [4] &lt;td style="text-align:right;"&gt;543,551\n&lt;/td&gt;
## [5] &lt;a href="/wiki/Greater_Montreal" title="Greater Montreal"&gt;Montreal&lt;/a&gt;
## [6] &lt;td style="text-align:right;"&gt;4,291,732&lt;/td&gt;</code></pre>
<blockquote>
<p><strong>Note:</strong> <code>head</code> is a function that is often useful for viewing only a short
summary of an R object, rather than the whole thing (which may be quite a lot
to look at). For example, here <code>head</code> shows us only the first 6 items in the
<code>population_nodes</code> object. Note that some R objects by default print only a
small summary. For example, <code>tibble</code> data frames only show you the first 10 rows.
But not <em>all</em> R objects do this, and that’s where the <code>head</code> function helps
summarize things for you.</p>
</blockquote>
<p>Each of the items in the <code>population_nodes</code> list is a <em>node</em> from the HTML
document that matches the CSS selectors you specified. A <em>node</em> is an HTML tag
pair (e.g., <code>&lt;td&gt;</code> and <code>&lt;/td&gt;</code> which defines the cell of a table) combined with
the content stored between the tags. For our CSS selector <code>td:nth-child(4)</code>, an
example node that would be selected would be:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb98-1"><a href="reading.html#cb98-1" tabindex="-1"/><span class="kw">&lt;td</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-align:left;background:#f0f0f0;"</span><span class="kw">&gt;</span></span>
<span id="cb98-2"><a href="reading.html#cb98-2" tabindex="-1"/><span class="kw">&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">"/wiki/London,_Ontario"</span> <span class="er">title</span><span class="ot">=</span><span class="st">"London, Ontario"</span><span class="kw">&gt;</span>London<span class="kw">&lt;/a&gt;</span></span>
<span id="cb98-3"><a href="reading.html#cb98-3" tabindex="-1"/><span class="kw">&lt;/td&gt;</span></span></code></pre></div>
<p>Next we extract the meaningful data—in other words, we get rid of the
HTML code syntax and tags—from the nodes using the <code>html_text</code> function.
In the case of the example node above, <code>html_text</code> function returns <code>"London"</code>.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="reading.html#cb99-1" tabindex="-1"/>population_text <span class="ot">&lt;-</span> <span class="fu">html_text</span>(population_nodes)</span>
<span id="cb99-2"><a href="reading.html#cb99-2" tabindex="-1"/><span class="fu">head</span>(population_text)</span></code></pre></div>
<pre><code>## [1] "Toronto"   "6,202,225" "London"    "543,551\n" "Montreal"  "4,291,732"</code></pre>
<p>Fantastic! We seem to have extracted the data of interest from the
raw HTML source code. But we are not quite done; the data
is not yet in an optimal format for data analysis. Both the city names and
population are encoded as characters in a single vector, instead of being in a
data frame with one character column for city and one numeric column for
population (like a spreadsheet).
Additionally, the populations contain commas (not useful for programmatically
dealing with numbers), and some even contain a line break character at the end
(<code>\n</code>). In Chapter <a href="wrangling.html#wrangling">3</a>, we will learn more about how to <em>wrangle</em> data
such as this into a more useful format for data analysis using R.</p>
</div>
</div>
<div id="using-an-api" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Using an API<a href="reading.html#using-an-api" class="anchor-section" aria-label="Anchor link to header"/></h3>
<p>Rather than posting a data file at a URL for you to download, many websites these days
provide an API that must be accessed through a programming language like R. The benefit of using an API
is that data owners have much more control over the data they provide to users. However, unlike
web scraping, there is no consistent way to access an API across websites. Every website typically
has its own API designed especially for its own use case. Therefore we will just provide one example
of accessing data through an API in this book, with the hope that it gives you enough of a basic
idea that you can learn how to use another API if needed. In particular, in this book we will show you the basics
of how to use the <code>httr2</code> package in R to access data from the NASA “Astronomy Picture
of the Day” API (a great source of desktop backgrounds, by the way—take a look at the stunning
picture of the Rho-Ophiuchi cloud complex <span class="citation">(<a href="#ref-rhoophiuchi">NASA et al. 2023</a>)</span> in Figure <a href="reading.html#fig:NASA-API-Rho-Ophiuchi">2.8</a> from July 13, 2023!).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NASA-API-Rho-Ophiuchi"/>
<img src="../Images/f6be3afe960e9cd751fbe8e84a464f01.png" alt="The James Webb Space Telescope’s NIRCam image of the Rho Ophiuchi molecular cloud complex." width="60%" data-original-src="https://datasciencebook.ca/img/reading/NASA-API-Rho-Ophiuchi.png"/>
<p class="caption">
Figure 2.8: The James Webb Space Telescope’s NIRCam image of the Rho Ophiuchi molecular cloud complex.
</p>
</div>
<p>First, you will need to visit the <a href="https://api.nasa.gov/">NASA APIs page</a> and generate an API key (i.e., a password used to identify you when accessing the API).
Note that a valid email address is required to
associate with the key. The signup form looks something like Figure <a href="reading.html#fig:NASA-API-signup">2.9</a>.
After filling out the basic information, you will receive the token via email.
Make sure to store the key in a safe place, and keep it private.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NASA-API-signup"/>
<img src="../Images/f9d351d8fb5738968f95efbcdae55ebc.png" alt="Generating the API access token for the NASA API" width="100%" data-original-src="https://datasciencebook.ca/img/reading/NASA-API-signup.png"/>
<p class="caption">
Figure 2.9: Generating the API access token for the NASA API
</p>
</div>
<p><strong>Caution: think about your API usage carefully!</strong></p>
<p>When you access an API, you are initiating a transfer of data from a web server
to your computer. Web servers are expensive to run and do not have infinite resources.
If you try to ask for <em>too much data</em> at once, you can use up a huge amount of the server’s bandwidth.
If you try to ask for data <em>too frequently</em>—e.g., if you
make many requests to the server in quick succession—you can also bog the server down and make
it unable to talk to anyone else. Most servers have mechanisms to revoke your access if you are not
careful, but you should try to prevent issues from happening in the first place by being extra careful
with how you write and run your code. You should also keep in mind that when a website owner
grants you API access, they also usually specify a limit (or <em>quota</em>) of how much data you can ask for.
Be careful not to overrun your quota! So <em>before</em> we try to use the API, we will first visit
<a href="https://api.nasa.gov/">the NASA website</a> to see what limits we should abide by when using the API.
These limits are outlined in Figure <a href="reading.html#fig:NASA-API-limits">2.10</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NASA-API-limits"/>
<img src="../Images/52a5a5613d26a12c2dd51cefdcd85827.png" alt="The NASA website specifies an hourly limit of 1,000 requests." width="100%" data-original-src="https://datasciencebook.ca/img/reading/NASA-API-limits.png"/>
<p class="caption">
Figure 2.10: The NASA website specifies an hourly limit of 1,000 requests.
</p>
</div>
<p>After checking the NASA website, it seems like we can send at most 1,000 requests per hour.
That should be more than enough for our purposes in this section.</p>
<div id="accessing-the-nasa-api" class="section level4 unnumbered hasAnchor">
<h4>Accessing the NASA API<a href="reading.html#accessing-the-nasa-api" class="anchor-section" aria-label="Anchor link to header"/></h4>
<p>The NASA API is what is known as an <em>HTTP API</em>: this is a particularly common
kind of API, where you can obtain data simply by accessing a
particular URL as if it were a regular website. To make a query to the NASA
API, we need to specify three things. First, we specify the URL <em>endpoint</em> of
the API, which is simply a URL that helps the remote server understand which
API you are trying to access. NASA offers a variety of APIs, each with its own
endpoint; in the case of the NASA “Astronomy Picture of the Day” API, the URL
endpoint is <code>https://api.nasa.gov/planetary/apod</code>. Second, we write <code>?</code>, which denotes that a
list of <em>query parameters</em> will follow. And finally, we specify a list of
query parameters of the form <code>parameter=value</code>, separated by <code>&amp;</code> characters. The NASA
“Astronomy Picture of the Day” API accepts the parameters shown in
Figure <a href="reading.html#fig:NASA-API-parameters">2.11</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NASA-API-parameters"/>
<img src="../Images/ac798b62914337d9da99f6715321b5f4.png" alt="The set of parameters that you can specify when querying the NASA &quot;Astronomy Picture of the Day&quot; API, along with syntax, default settings, and a description of each." width="100%" data-original-src="https://datasciencebook.ca/img/reading/NASA-API-parameters.png"/>
<p class="caption">
Figure 2.11: The set of parameters that you can specify when querying the NASA “Astronomy Picture of the Day” API, along with syntax, default settings, and a description of each.
</p>
</div>
<p>So for example, to obtain the image of the day
from July 13, 2023, the API query would have two parameters: <code>api_key=YOUR_API_KEY</code>
and <code>date=2023-07-13</code>. Remember to replace <code>YOUR_API_KEY</code> with the API key you
received from NASA in your email! Putting it all together, the query will look like the following:</p>
<pre><code>https://api.nasa.gov/planetary/apod?api_key=YOUR_API_KEY&amp;date=2023-07-13</code></pre>
<p>If you try putting this URL into your web browser, you’ll actually find that the server
responds to your request with some text:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb102-1"><a href="reading.html#cb102-1" tabindex="-1"/><span class="fu">{</span><span class="dt">"date"</span><span class="fu">:</span><span class="st">"2023-07-13"</span><span class="fu">,</span><span class="dt">"explanation"</span><span class="fu">:</span><span class="st">"A mere 390 light-years away, Sun-like stars</span></span>
<span id="cb102-2"><a href="reading.html#cb102-2" tabindex="-1"/><span class="st">and future planetary systems are forming in the Rho Ophiuchi molecular cloud</span></span>
<span id="cb102-3"><a href="reading.html#cb102-3" tabindex="-1"/><span class="st">complex, the closest star-forming region to our fair planet. The James Webb</span></span>
<span id="cb102-4"><a href="reading.html#cb102-4" tabindex="-1"/><span class="st">Space Telescope's NIRCam peered into the nearby natal chaos to capture this</span></span>
<span id="cb102-5"><a href="reading.html#cb102-5" tabindex="-1"/><span class="st">infrared image at an inspiring scale. The spectacular cosmic snapshot was</span></span>
<span id="cb102-6"><a href="reading.html#cb102-6" tabindex="-1"/><span class="st">released to celebrate the successful first year of Webb's exploration of the</span></span>
<span id="cb102-7"><a href="reading.html#cb102-7" tabindex="-1"/><span class="st">Universe. The frame spans less than a light-year across the Rho Ophiuchi region</span></span>
<span id="cb102-8"><a href="reading.html#cb102-8" tabindex="-1"/><span class="st">and contains about 50 young stars. Brighter stars clearly sport Webb's</span></span>
<span id="cb102-9"><a href="reading.html#cb102-9" tabindex="-1"/><span class="st">characteristic pattern of diffraction spikes. Huge jets of shocked molecular</span></span>
<span id="cb102-10"><a href="reading.html#cb102-10" tabindex="-1"/><span class="st">hydrogen blasting from newborn stars are red in the image, with the large,</span></span>
<span id="cb102-11"><a href="reading.html#cb102-11" tabindex="-1"/><span class="st">yellowish dusty cavity carved out by the energetic young star near its center.</span></span>
<span id="cb102-12"><a href="reading.html#cb102-12" tabindex="-1"/><span class="st">Near some stars in the stunning image are shadows cast by their protoplanetary</span></span>
<span id="cb102-13"><a href="reading.html#cb102-13" tabindex="-1"/><span class="st">disks."</span><span class="fu">,</span><span class="dt">"hdurl"</span><span class="fu">:</span><span class="st">"https://apod.nasa.gov/apod/image/2307/STScI-01_RhoOph.png"</span><span class="fu">,</span></span>
<span id="cb102-14"><a href="reading.html#cb102-14" tabindex="-1"/><span class="dt">"media_type"</span><span class="fu">:</span><span class="st">"image"</span><span class="fu">,</span><span class="dt">"service_version"</span><span class="fu">:</span><span class="st">"v1"</span><span class="fu">,</span><span class="dt">"title"</span><span class="fu">:</span><span class="st">"Webb's</span></span>
<span id="cb102-15"><a href="reading.html#cb102-15" tabindex="-1"/><span class="st">Rho Ophiuchi"</span><span class="fu">,</span><span class="dt">"url"</span><span class="fu">:</span><span class="st">"https://apod.nasa.gov/apod/image/2307/STScI-01_RhoOph1024.png"</span><span class="fu">}</span></span></code></pre></div>
<p>Neat! There is definitely some data there, but it’s a bit hard to
see what it all is. As it turns out, this is a common format for data called
<em>JSON</em> (JavaScript Object Notation).
We won’t encounter this kind of data much in this book,
but for now you can interpret this data as <code>key : value</code> pairs separated by
commas. For example, if you look closely, you’ll see that the first entry is
<code>"date":"2023-07-13"</code>, which indicates that we indeed successfully received
data corresponding to July 13, 2023.</p>
<p>So now our job is to do all of this programmatically in R. We will load
the <code>httr2</code> package, and construct the query using the <code>request</code> function, which takes a single URL argument;
you will recognize the same query URL that we pasted into the browser earlier.
We will then send the query using the <code>req_perform</code> function, and finally
obtain a JSON representation of the response using the <code>resp_body_json</code> function.
</p>
<!-- we have disabled the below code for reproducibility, with hidden setting
of the nasa_data object. But you can reproduce this using the DEMO_KEY key -->
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="reading.html#cb103-1" tabindex="-1"/><span class="fu">library</span>(httr2)</span>
<span id="cb103-2"><a href="reading.html#cb103-2" tabindex="-1"/></span>
<span id="cb103-3"><a href="reading.html#cb103-3" tabindex="-1"/>req <span class="ot">&lt;-</span> <span class="fu">request</span>(<span class="st">"https://api.nasa.gov/planetary/apod?api_key=YOUR_API_KEY&amp;date=2023-07-13"</span>)</span>
<span id="cb103-4"><a href="reading.html#cb103-4" tabindex="-1"/>resp <span class="ot">&lt;-</span> <span class="fu">req_perform</span>(req)</span>
<span id="cb103-5"><a href="reading.html#cb103-5" tabindex="-1"/>nasa_data_single <span class="ot">&lt;-</span> <span class="fu">resp_body_json</span>(resp)</span>
<span id="cb103-6"><a href="reading.html#cb103-6" tabindex="-1"/>nasa_data_single</span></code></pre></div>
<pre><code>## $date
## [1] "2023-07-13"
## 
## $explanation
## [1] "A mere 390 light-years away, Sun-like stars and future planetary systems are forming in the Rho Ophiuchi molecular cloud complex, the closest star-forming region to our fair planet. The James Webb Space Telescope's NIRCam peered into the nearby natal chaos to capture this infrared image at an inspiring scale. The spectacular cosmic snapshot was released to celebrate the successful first year of Webb's exploration of the Universe. The frame spans less than a light-year across the Rho Ophiuchi region and contains about 50 young stars. Brighter stars clearly sport Webb's characteristic pattern of diffraction spikes. Huge jets of shocked molecular hydrogen blasting from newborn stars are red in the image, with the large, yellowish dusty cavity carved out by the energetic young star near its center. Near some stars in the stunning image are shadows cast by their protoplanetary disks."
## 
## $hdurl
## [1] "https://apod.nasa.gov/apod/image/2307/STScI-01_RhoOph.png"
## 
## $media_type
## [1] "image"
## 
## $service_version
## [1] "v1"
## 
## $title
## [1] "Webb's Rho Ophiuchi"
## 
## $url
## [1] "https://apod.nasa.gov/apod/image/2307/STScI-01_RhoOph1024.png"</code></pre>
<p>We can obtain more records at once by using the <code>start_date</code> and <code>end_date</code> parameters, as
shown in the table of parameters in <a href="reading.html#fig:NASA-API-parameters">2.11</a>.
Let’s obtain all the records between May 1, 2023, and July 13, 2023, and store the result
in an object called <code>nasa_data</code>; now the response
will take the form of an R <em>list</em> (you’ll learn more about these in Chapter <a href="wrangling.html#wrangling">3</a>).
Each item in the list will correspond to a single day’s record (just like the <code>nasa_data_single</code> object),
and there will be 74 items total, one for each day between the start and end dates:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="reading.html#cb105-1" tabindex="-1"/>req <span class="ot">&lt;-</span> <span class="fu">request</span>(<span class="st">"https://api.nasa.gov/planetary/apod?api_key=YOUR_API_KEY&amp;start_date=2023-05-01&amp;end_date=2023-07-13"</span>)</span>
<span id="cb105-2"><a href="reading.html#cb105-2" tabindex="-1"/>resp <span class="ot">&lt;-</span> <span class="fu">req_perform</span>(req)</span>
<span id="cb105-3"><a href="reading.html#cb105-3" tabindex="-1"/>nasa_data <span class="ot">&lt;-</span> <span class="fu">resp_body_json</span>(response)</span>
<span id="cb105-4"><a href="reading.html#cb105-4" tabindex="-1"/><span class="fu">length</span>(nasa_data)</span></code></pre></div>
<pre><code>## [1] 74</code></pre>
<p>For further data processing using the techniques in this book, you’ll need to turn this list of items
into a data frame. Here we will extract the <code>date</code>, <code>title</code>, <code>copyright</code>, and <code>url</code> variables
from the JSON data, and construct a data frame using the extracted information.</p>
<blockquote>
<p><strong>Note:</strong> Understanding this code is not required for the remainder of the textbook. It is included for those
readers who would like to parse JSON data into a data frame in their own data analyses.</p>
</blockquote>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="reading.html#cb107-1" tabindex="-1"/>nasa_df_all <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="fu">bind_rows</span>(<span class="fu">lapply</span>(nasa_data, as.data.frame.list)))</span>
<span id="cb107-2"><a href="reading.html#cb107-2" tabindex="-1"/>nasa_df <span class="ot">&lt;-</span> <span class="fu">select</span>(nasa_df_all, date, title, copyright, url)</span>
<span id="cb107-3"><a href="reading.html#cb107-3" tabindex="-1"/>nasa_df</span></code></pre></div>
<pre><code>## # A tibble: 74 × 4
##    date       title                                        copyright       url  
##    &lt;chr&gt;      &lt;chr&gt;                                        &lt;chr&gt;           &lt;chr&gt;
##  1 2023-05-01 Carina Nebula North                          "\nCarlos Tayl… http…
##  2 2023-05-02 Flat Rock Hills on Mars                      "\nNASA, \nJPL… http…
##  3 2023-05-03 Centaurus A: A Peculiar Island of Stars      "\nMarco Loren… http…
##  4 2023-05-04 The Galaxy, the Jet, and a Famous Black Hole  &lt;NA&gt;           http…
##  5 2023-05-05 Shackleton from ShadowCam                     &lt;NA&gt;           http…
##  6 2023-05-06 Twilight in a Flower                         "Dario Giannob… http…
##  7 2023-05-07 The Helix Nebula from CFHT                    &lt;NA&gt;           http…
##  8 2023-05-08 The Spanish Dancer Spiral Galaxy              &lt;NA&gt;           http…
##  9 2023-05-09 Shadows of Earth                             "\nMarcella Gi… http…
## 10 2023-05-10 Milky Way over Egyptian Desert               "\nAmr Abdulwa… http…
## # ℹ 64 more rows</code></pre>
<p>Success—we have created a small data set using the NASA
API! This data is also quite different from what we obtained from web scraping;
the extracted information is readily available in a JSON format, as opposed to raw
HTML code (although not <em>every</em> API will provide data in such a nice format).
From this point onward, the <code>nasa_df</code> data frame is stored on your
machine, and you can play with it to your heart’s content. For example, you can use
<code>write_csv</code> to save it to a file and <code>read_csv</code> to read it into R again later;
and after reading the next few chapters you will have the skills to
do even more interesting things! If you decide that you want
to ask any of the various NASA APIs for more data
(see <a href="https://api.nasa.gov/">the list of awesome NASA APIS here</a>
for more examples of what is possible), just be mindful as usual about how much
data you are requesting and how frequently you are making requests.</p>
</div>
</div>
</div>
<div id="exercises-1" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Exercises<a href="reading.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"/></h2>
<p>Practice exercises for the material covered in this chapter
can be found in the accompanying
<a href="https://worksheets.datasciencebook.ca">worksheets repository</a>
in the “Reading in data locally and from the web” row.
You can launch an interactive version of the worksheet in your browser by clicking the “launch binder” button.
You can also preview a non-interactive version of the worksheet by clicking “view worksheet.”
If you instead decide to download the worksheet and run it on your own machine,
make sure to follow the instructions for computer setup
found in Chapter <a href="setup.html#setup">13</a>. This will ensure that the automated feedback
and guidance that the worksheets provide will function as intended.</p>
</div>
<div id="additional-resources" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Additional resources<a href="reading.html#additional-resources" class="anchor-section" aria-label="Anchor link to header"/></h2>
<ul>
<li>The <a href="https://readr.tidyverse.org/"><code>readr</code> documentation</a>
provides the documentation for many of the reading functions we cover in this chapter.
It is where you should look if you want to learn more about the functions in this
chapter, the full set of arguments you can use, and other related functions.
The site also provides a very nice cheat sheet that summarizes many of the data
wrangling functions from this chapter.</li>
<li>Sometimes you might run into data in such poor shape that none of the reading
functions we cover in this chapter work. In that case, you can consult the
<a href="https://r4ds.had.co.nz/data-import.html">data import chapter</a> from <em>R for Data
Science</em> <span class="citation">(<a href="#ref-wickham2016r">Wickham and Grolemund 2016</a>)</span>, which goes into a lot more detail about how R parses
text from files into data frames.</li>
<li>The <a href="https://here.r-lib.org/"><code>here</code> R package</a> <span class="citation">(<a href="#ref-here">Müller 2020</a>)</span>
provides a way for you to construct or find your files’ paths.</li>
<li>The <a href="https://readxl.tidyverse.org/"><code>readxl</code> documentation</a> provides more
details on reading data from Excel, such as reading in data with multiple
sheets, or specifying the cells to read in.</li>
<li>The <a href="https://github.com/leeper/rio"><code>rio</code> R package</a> <span class="citation">(<a href="#ref-rio">Leeper 2021</a>)</span> provides an alternative
set of tools for reading and writing data in R. It aims to be a “Swiss army
knife” for data reading/writing/converting, and supports a wide variety of data
types (including data formats generated by other statistical software like SPSS
and SAS).</li>
<li>A <a href="https://www.youtube.com/embed/ephId3mYu9o">video</a> from the Udacity
course <em>Linux Command Line Basics</em> provides a good explanation of absolute versus relative paths.</li>
<li>If you read the subsection on obtaining data from the web via scraping and
APIs, we provide two companion tutorial video links for how to use the
SelectorGadget tool to obtain desired CSS selectors for:
<ul>
<li><a href="https://www.youtube.com/embed/YdIWI6K64zo">extracting the data for apartment listings on Craigslist</a>, and</li>
<li><a href="https://www.youtube.com/embed/O9HKbdhqYzk">extracting Canadian city names and populations from Wikipedia</a>.</li>
</ul></li>
<li>The <a href="https://dmi3kno.github.io/polite/"><code>polite</code> R package</a> <span class="citation">(<a href="#ref-polite">Perepolkin 2021</a>)</span> provides
a set of tools for responsibly scraping data from websites.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"/></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-rio" class="csl-entry">
Leeper, Thomas. 2021. <em><span class="nocase">rio R package</span></em>. <a href="https://cloud.r-project.org/web/packages/rio/index.html">https://cloud.r-project.org/web/packages/rio/index.html</a>.
</div>
<div id="ref-here" class="csl-entry">
Müller, Kirill. 2020. <em><span class="nocase">here R package</span></em>. <a href="https://here.r-lib.org/">https://here.r-lib.org/</a>.
</div>
<div id="ref-rhoophiuchi" class="csl-entry">
NASA, ESA, CSA, STScI, K. Pontoppidan (STScI), and A. Pagan (STScI). 2023. <span>“Rho Ophiuchi Cloud Complex.”</span> <em>URL: Https://Esawebb.org/Images/Weic2316a/</em>.
</div>
<div id="ref-polite" class="csl-entry">
Perepolkin, Dmytro. 2021. <em><span class="nocase">polite R package</span></em>. <a href="https://dmi3kno.github.io/polite/">https://dmi3kno.github.io/polite/</a>.
</div>
<div id="ref-googlesearches" class="csl-entry">
Real Time Statistics Project. 2021. <span>“Internet Live Stats: Google Search Statistics.”</span> <a href="https://www.internetlivestats.com/google-search-statistics/">https://www.internetlivestats.com/google-search-statistics/</a>.
</div>
<div id="ref-rvest" class="csl-entry">
———. 2021a. <em><span class="nocase">rvest R package</span></em>. <a href="https://rvest.tidyverse.org/">https://rvest.tidyverse.org/</a>.
</div>
<div id="ref-httr2" class="csl-entry">
———. 2023. <em>Httr2: Perform HTTP Requests and Process the Responses</em>. <a href="https://httr2.r-lib.org">https://httr2.r-lib.org</a>.
</div>
<div id="ref-dplyr" class="csl-entry">
Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2021. <em><span class="nocase">dplyr R package</span></em>. <a href="https://dplyr.tidyverse.org/">https://dplyr.tidyverse.org/</a>.
</div>
<div id="ref-wickham2016r" class="csl-entry">
Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. O’Reilly. <a href="https://r4ds.had.co.nz/">https://r4ds.had.co.nz/</a>.
</div>
</div>
                
</body>
</html>