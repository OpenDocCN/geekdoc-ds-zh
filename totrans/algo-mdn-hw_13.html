<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Cost of Branching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The Cost of Branching</h1>
<blockquote>原文：<a href="https://en.algorithmica.org/hpc/pipelining/branching/">https://en.algorithmica.org/hpc/pipelining/branching/</a></blockquote><div id="search"><input id="search-bar" type="search" placeholder="Search this book…" oninput="search()"/><div id="search-count"/><div id="search-results"/></div><header><div class="info"/></header><article><p>When a CPU encounters a conditional jump or <a href="/hpc/architecture/indirect">any other type of branching</a>, it doesn’t just sit idle until its condition is computed — instead, it starts <em>speculatively executing</em> the branch that seems more likely to be taken immediately. During execution, the CPU computes statistics about branches taken on each instruction, and after some time, they start to predict them by recognizing common patterns.</p><p>For this reason, the true “cost” of a branch largely depends on how well it can be predicted by the CPU. If it is a pure 50/50 coin toss, you have to suffer a <a href="../hazards">control hazard</a> and discard the entire pipeline, taking another 15-20 cycles to build up again. And if the branch is always or never taken, you pay almost nothing except checking the condition.</p><span class="anchor" id="an-experiment"/><h2><a class="anchor-link" href="https://en.algorithmica.org/hpc/pipelining/branching/#an-experiment">#</a>An Experiment</h2><p>As a case study, we are going to create an array of random integers between 0 and 99 inclusive:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">100</span><span class="p">;</span>
</span></span></code></pre></div><p>Then we create a loop where we sum up all its elements under 50:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">volatile</span> <span class="kt">int</span> <span class="n">s</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span></code></pre></div><p>We set $N = 10^6$ and run this loop many times over so that the <a href="/hpc/cpu-cache/bandwidth">cold cache</a> effect doesn’t mess up our results. We mark our accumulator variable as <code>volatile</code> so that the compiler doesn’t vectorize the loop, interleave its iterations, or “cheat” in any other way.</p><p>On Clang, this produces assembly that looks like this:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nasm" data-lang="nasm"><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">rcx</span><span class="p">,</span> <span class="o">-</span><span class="mi">4000000</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jmp</span>  <span class="nv">body</span>
</span></span><span class="line"><span class="cl"><span class="nl">counter:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">add</span>  <span class="nb">rcx</span><span class="p">,</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jz</span>   <span class="nv">finished</span>   <span class="c1">; "jump if rcx became zero"</span>
</span></span><span class="line"><span class="cl"><span class="nl">body:</span>
</span></span><span class="line"><span class="cl">    <span class="nf">mov</span>  <span class="nb">edx</span><span class="p">,</span> <span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rcx</span> <span class="o">+</span> <span class="nv">a</span> <span class="o">+</span> <span class="mi">4000000</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="nf">cmp</span>  <span class="nb">edx</span><span class="p">,</span> <span class="mi">49</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jg</span>   <span class="nv">counter</span>
</span></span><span class="line"><span class="cl">    <span class="nf">add</span>  <span class="kt">dword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rsp</span> <span class="o">+</span> <span class="mi">12</span><span class="p">],</span> <span class="nb">edx</span>
</span></span><span class="line"><span class="cl">    <span class="nf">jmp</span>  <span class="nv">counter</span>
</span></span></code></pre></div><p>Our goal is to simulate a completely unpredictable branch, and we successfully achieve it: the code takes ~14 CPU cycles per element. For a very rough estimate of what it is supposed to be, we can assume that the branches alternate between <code>&lt;</code> and <code>&gt;=</code>, and the pipeline is mispredicted every other iteration. Then, every two iterations:</p><ul><li>We discard the pipeline, which is 19 cycles deep on Zen 2 (i.e., it has 19 stages, each taking one cycle).</li><li>We need a memory fetch and a comparison, which costs ~5 cycles. We can check the conditions of even and odd iterations concurrently, so let’s assume we only pay it once per 2 iterations.</li><li>In the case of the <code>&lt;</code> branch, we need another ~4 cycles to add <code>a[i]</code> to a volatile (memory-stored) variable <code>s</code>.</li></ul><p>Therefore, on average, we need to spend $(4 + 5 + 19) / 2 = 14$ cycles per element, matching what we measured.</p><span class="anchor" id="branch-prediction"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/pipelining/branching/#branch-prediction">#</a>Branch Prediction</h3><p>We can replace the hardcoded <code>50</code> with a tweakable parameter <code>P</code> that effectively sets the probability of the <code>&lt;</code> branch:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">P</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span></code></pre></div><p>Now, if we benchmark it for different values of <code>P</code>, we get an interesting-looking graph:</p><p><figure><img src="../Images/fcf131b2df49e5a5fa7490ba395ae86a.png" data-original-src="https://en.algorithmica.org/hpc/pipelining/img/probabilities.svg"/><figcaption/></figure></p><p>Its peak is at 50-55%, as expected: branch misprediction is the most expensive thing here. This graph is asymmetrical: it takes just ~1 cycle to only check conditions that are never satisfied (<code>P = 0</code>), and ~7 cycles for the sum if the branch is always taken (<code>P = 100</code>).</p><p>This graph is not unimodal: there is another local minimum at around 85-90%. We spend ~6.15 cycles per element there or about 10-15% faster than when we always take the branch, accounting for the fact that we need to perform fewer additions. Branch misprediction stops affecting the performance at this point because when it happens, not the whole instruction buffer is discarded, but only the operations that were speculatively scheduled. Essentially, that 10-15% mispredict rate is the equilibrium point where we can see far enough in the pipeline not to stall but still save 10-15% on taking the cheaper <code>&gt;=</code> branch.</p><p>Note that it costs almost nothing to check for a condition that never or almost never occurs. This is why programmers use runtime exceptions and base case checks so profusely: if they are indeed rare, they don’t really cost anything.</p><span class="anchor" id="pattern-detection"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/pipelining/branching/#pattern-detection">#</a>Pattern Detection</h3><p>In our example, everything that was needed for efficient branch prediction is a hardware statistics counter. If we historically took branch A more often than branch B, then it makes sense to speculatively execute branch A. But branch predictors on modern CPUs are considerably more advanced than that and can detect much more complicated patterns.</p><p>Let’s fix <code>P</code> back at 50, and then sort the array first before the main summation loop:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">100</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">n</span><span class="p">);</span>
</span></span></code></pre></div><p>We are still processing the same elements, but in a different order, and instead of 14 cycles, it now runs in a little bit more than 4, which is exactly the average of the cost of the pure <code>&lt;</code> and <code>&gt;=</code> branches.</p><p>The branch predictor can pick up on much more complicated patterns than just “always left, then always right” or “left-right-left-right.” If we just decrease the size of the array $N$ to 1000 (without sorting it), then the branch predictor memorizes the entire sequence of comparisons, and the benchmark again measures at around 4 cycles — in fact, even slightly fewer than in the sorted array case, because in the former case branch predictor needs to spend some time flicking between the “always yes” and “always no” states.</p><span class="anchor" id="hinting-likeliness-of-branches"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/pipelining/branching/#hinting-likeliness-of-branches">#</a>Hinting Likeliness of Branches</h3><p>If you know beforehand which branch is more likely, it may be beneficial to <a href="/hpc/compilation/situational">pass that information</a> to the compiler:</p><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">P</span><span class="p">)</span> <span class="na">[[likely]]</span>
</span></span><span class="line"><span class="cl">        <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span></code></pre></div><p>When <code>P = 75</code>, it measures around ~7.3 cycles per element, while the original version without the hint needs ~8.3.</p><p>This hint does not eliminate the branch or communicate anything to the branch predictor, but it changes the <a href="/hpc/architecture/layout">machine code layout</a> in a way that lets the CPU front-end process the more likely branch slightly faster (although usually by no more than one cycle).</p><p>This optimization is only beneficial when you know which branch is more likely to be taken before the compilation stage. When the branch is fundamentally unpredictable, we can try to remove it completely using <em>predication</em> — a profoundly important technique that we are going to explore in <a href="../branchless">the next section</a>.</p><span class="anchor" id="acknowledgements"/><h3><a class="anchor-link" href="https://en.algorithmica.org/hpc/pipelining/branching/#acknowledgements">#</a>Acknowledgements</h3><p>This case study is inspired by <a href="https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array">the most upvoted Stack Overflow question ever</a>.</p></article><div class="nextprev"><div class="left"><a href="https://en.algorithmica.org/hpc/pipelining/hazards/" id="prev-article">← Pipeline Hazards</a></div><div class="right"><a href="https://en.algorithmica.org/hpc/pipelining/branchless/" id="next-article">Branchless Programming →</a></div></div>    
</body>
</html>