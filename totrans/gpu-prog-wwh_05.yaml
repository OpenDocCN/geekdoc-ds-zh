- en: The GPU hardware and software ecosystem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU硬件和软件生态系统
- en: 原文：[https://enccs.github.io/gpu-programming/2-gpu-ecosystem/](https://enccs.github.io/gpu-programming/2-gpu-ecosystem/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://enccs.github.io/gpu-programming/2-gpu-ecosystem/](https://enccs.github.io/gpu-programming/2-gpu-ecosystem/)
- en: '*[GPU programming: why, when and how?](../)* **   The GPU hardware and software
    ecosystem'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*[GPU编程：为什么、何时以及如何？](../)* **   GPU硬件和软件生态系统'
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/2-gpu-ecosystem.rst)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在GitHub上编辑](https://github.com/ENCCS/gpu-programming/blob/main/content/2-gpu-ecosystem.rst)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Questions
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: What are the differences between GPUs and CPUs?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU和CPU之间有什么区别？
- en: What GPU software stacks are available? What do they provide?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的GPU软件堆栈有哪些？它们提供什么？
- en: Objectives
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Understand the fundamental differences between GPUs and CPUs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解GPU和CPU之间的基本区别
- en: Explore the major GPU software suites available, such as CUDA, ROCm, and oneAPI,
    and gain a basic understanding of them
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索可用的主要GPU软件套件，如CUDA、ROCm和oneAPI，并对其有一个基本的了解
- en: Instructor note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 20 min teaching
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20分钟教学
- en: 0 min exercises
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0分钟练习
- en: Overview of GPU hardware
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU硬件概述
- en: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
- en: A comparison of the CPU and GPU architecture. CPU (left) has complex core structure
    and pack several cores on a single chip. GPU cores are very simple in comparison,
    they also share data and control between each other. This allows to pack more
    cores on a single chip, thus achieving very high compute density.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: CPU（左侧）具有复杂的内核结构，并在单个芯片上集成多个核心。与GPU核心相比，CPU核心非常简单，它们之间也共享数据和控制。这使得可以在单个芯片上集成更多的核心，从而实现非常高的计算密度。
- en: In short
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之
- en: Accelerators offer high performance due to their scalability and high density
    of compute elements.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于其可扩展性和计算元素的密集度，加速器提供高性能。
- en: They have separate circuit boards connected to CPUs via PCIe bus, with their
    own memory.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们通过PCIe总线连接到CPU，拥有自己的内存。
- en: CPUs copy data from their own memory to the GPU memory, execute the program,
    and copy the results back.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU将数据从自己的内存复制到GPU内存，执行程序，并将结果复制回来。
- en: GPUs run thousands of threads simultaneously, quickly switching between them
    to hide memory operations.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU同时运行数千个线程，快速地在它们之间切换以隐藏内存操作。
- en: Effective data management and access pattern is critical on the GPU to avoid
    running out of memory.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上，有效的数据管理和访问模式对于避免内存耗尽至关重要。
- en: 'Accelerators are a separate main circuit board with the processor, memory,
    power management, etc. It is connected to the motherboard with CPUs via PCIe bus.
    Having its own memory means that the data has to be copied to and from it (not
    neceseraly true anymore). CPU acts as a main processor, controlling the execution
    workflow. It copies the data from its own memory to the GPU memory, executes the
    program and copies the results back. GPUs runs tens of thousands of threads simultaneously
    on thousands of cores and does not do much of the data management. With many cores
    trying to access the memory simultaneously and with little cache available, the
    accelerator can run out of memory very quickly. This makes the data management
    and its access pattern is essential on the GPU. Accelerators like to be overloaded
    with the number of threads, because they can switch between threads very quickly.
    This allows to hide the memory operations: while some threads wait, others can
    compute.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器是一个独立的电路板，包含处理器、内存、电源管理等。它通过PCIe总线连接到带有CPU的主板。拥有自己的内存意味着数据必须被复制到和从它（现在可能不再是这样了）。CPU作为主处理器，控制执行流程。它将数据从自己的内存复制到GPU内存，执行程序，并将结果复制回来。GPU在数千个核心上同时运行数万个线程，并不进行太多的数据管理。当许多核心同时尝试访问内存并且缓存有限时，加速器可能会很快耗尽内存。这使得数据管理和其访问模式在GPU上至关重要。加速器喜欢被大量的线程所超载，因为它们可以非常快速地在线程之间切换。这允许隐藏内存操作：当一些线程等待时，其他线程可以进行计算。
- en: 'A very important feature of the accelerators is their scalability. Computational
    cores on accelerators are usually grouped into multiprocessors. The multiprocessors
    share the data and logical elements. This allows to achieve a very high density
    of compute elements on a GPU. This also allows the scaling: more multiprocessors
    means more raw performance and this is very easy to achieve with more transistors
    available.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器的一个重要特性是其可扩展性。加速器上的计算核心通常被分组为多处理器。多处理器共享数据和逻辑元素。这允许在GPU上实现非常高的计算元素密度。这也允许进行扩展：更多的多处理器意味着更高的原始性能，而且通过更多的晶体管实现这一点非常容易。
- en: How do GPUs differ from CPUs?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU与CPU有何不同？
- en: CPUs and GPUs were designed with different goals in mind. While the CPU is designed
    to excel at executing a sequence of operations, called a thread, as fast as possible
    and can execute a few tens of these threads in parallel, the GPU is designed to
    excel at executing many thousands of them in parallel. GPUs were initially developed
    for highly-parallel task of graphic processing and therefore designed such that
    more transistors are devoted to data processing rather than data caching and flow
    control. More transistors dedicated to data processing is beneficial for highly
    parallel computations; the GPU can hide memory access latencies with computation,
    instead of relying on large data caches and complex flow control to avoid long
    memory access latencies, both of which are expensive in terms of transistors.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和GPU的设计目标不同。虽然CPU旨在尽可能快地执行一系列操作，即线程，并且可以并行执行几十个这样的线程，但GPU旨在并行执行成千上万的线程。GPU最初是为高度并行的图形处理任务开发的，因此设计时更多地致力于数据处理而不是数据缓存和流控制。更多用于数据处理的晶体管对高度并行的计算有益；GPU可以通过计算来隐藏内存访问延迟，而不是依赖于大型数据缓存和复杂的流控制来避免长时间的内存访问延迟，这两者从晶体管的角度来看都是昂贵的。
- en: '| CPU | GPU |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| CPU | GPU |'
- en: '| --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| General purpose | Highly specialized for parallelism |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 通用 | 高度专门化于并行 |'
- en: '| Good for serial processing | Good for parallel processing |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 适合串行处理 | 适合并行处理 |'
- en: '| Great for task parallelism | Great for data parallelism |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 适合任务并行 | 适合数据并行 |'
- en: '| Low latency per thread | High-throughput |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 每线程低延迟 | 高吞吐量 |'
- en: '| Large area dedicated cache and control | Hundreds of floating-point execution
    units |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 专用的大面积缓存和控制 | 数百个浮点执行单元 |'
- en: GPU platforms
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU平台
- en: GPUs come together with software stacks or APIs that work in conjunction with
    the hardware and give a standard way for the software to interact with the GPU
    hardware. They are used by software developers to write code that can take advantage
    of the parallel processing power of the GPU, and they provide a standard way for
    software to interact with the GPU hardware. Typically, they provide access to
    low-level functionality, such as memory management, data transfer between the
    CPU and the GPU, and the scheduling and execution of parallel processing tasks
    on the GPU. They may also provide higher level functions and libraries optimized
    for specific HPC workloads, like linear algebra or fast Fourier transforms. Finally,
    in order to facilitate the developers to optimize and write correct codes, debugging
    and profiling tools are also included.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: GPU与软件堆栈或API一起提供，这些API与硬件协同工作，为软件与GPU硬件的交互提供了一种标准方式。它们被软件开发者用来编写可以利用GPU并行处理能力的代码，并为软件与GPU硬件的交互提供了一种标准方式。通常，它们提供对底层功能，如内存管理、CPU和GPU之间的数据传输以及GPU上并行处理任务的调度和执行的访问。它们还可能提供针对特定HPC工作负载（如线性代数或快速傅里叶变换）优化的高级功能和库。最后，为了帮助开发者优化和编写正确的代码，还包含了调试和性能分析工具。
- en: '*NVIDIA*, *AMD*, and *Intel* are the major companies which design and produces
    GPUs for HPC providing each its own suite **CUDA**, **ROCm**, and respectively
    **oneAPI**. This way they can offer optimization, differentiation (offering unique
    features tailored to their devices), vendor lock-in, licensing, and royalty fees,
    which can result in better performance, profitability, and customer loyalty. There
    are also cross-platform APIs such **DirectCompute** (only for Windows operating
    system), **OpenCL**, and **SYCL**.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*NVIDIA*、*AMD*和*Intel*是设计并生产用于HPC的GPU的主要公司，它们各自提供自己的套件**CUDA**、**ROCm**和分别的**oneAPI**。这样，它们可以提供优化、差异化（提供针对其设备定制的独特功能）、供应商锁定、许可和版税费用，这可能导致更好的性能、盈利能力和客户忠诚度。还有跨平台API，如**DirectCompute**（仅适用于Windows操作系统）、**OpenCL**和**SYCL**。'
- en: CUDA - In short
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA - 简而言之
- en: 'CUDA: NVIDIA’s parallel computing platform'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA：NVIDIA的并行计算平台
- en: 'Components: CUDA Toolkit & CUDA driver'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件：CUDA工具包与CUDA驱动程序
- en: Supports C, C++, and Fortran languages
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C、C++和Fortran语言
- en: 'CUDA API Libraries: cuBLAS, cuFFT, cuRAND, cuSPARSE'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA API库：cuBLAS、cuFFT、cuRAND、cuSPARSE
- en: Accelerate complex computations on GPUs
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上加速复杂计算
- en: 'Compilers: nvcc, nvc, nvc++, nvfortran'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器：nvcc、nvc、nvc++、nvfortran
- en: Support GPU and multicore CPU programming
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持GPU和多核CPU编程
- en: Compatible with OpenACC and OpenMP
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 兼容OpenACC和OpenMP
- en: 'Debugging tools: cuda-gdb, compute-sanitizer'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试工具：cuda-gdb、compute-sanitizer
- en: Debug GPU and CPU code simultaneously
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时调试GPU和CPU代码
- en: Identify memory access issues
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别内存访问问题
- en: 'Performance analysis tools: NVIDIA Nsight Systems, NVIDIA Nsight Compute'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析工具：NVIDIA Nsight Systems、NVIDIA Nsight Compute
- en: Analyze system-wide and kernel-level performance
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析系统级和内核级性能
- en: Optimize CPU and GPU usage, memory bandwidth, instruction throughput
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化CPU和GPU的使用，内存带宽，指令吞吐量
- en: Comprehensive CUDA ecosystem with extensive tools and features
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的CUDA生态系统，具有广泛的工具和功能
- en: ROCm - In short
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm - 简而言之
- en: 'ROCm: Open software platform for AMD accelerators'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROCm：AMD加速器的开源软件平台
- en: Built for open portability across multiple vendors and architectures
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为跨多个供应商和架构的开放可移植性而构建
- en: Offers libraries, compilers, and development tools for AMD GPUs
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供AMD GPU的库、编译器和开发工具
- en: Supports C, C++, and Fortran languages
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C、C++和Fortran语言
- en: Support GPU and multicore CPU programming
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持GPU和多核CPU编程
- en: 'Debugging: `roc-gdb` command line tool'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试：`roc-gdb`命令行工具
- en: Facilitates debugging of GPU programs
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进GPU程序的调试
- en: 'Performance analysis: `rocprof` and `roctracer` tools'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析：`rocprof`和`roctracer`工具
- en: Analyze and optimize program performance
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析和优化程序性能
- en: Supports various heterogeneous programming models such as **HIP**, **OpenMP**,
    and **OpenCL**
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持各种异构编程模型，如**HIP**、**OpenMP**和**OpenCL**
- en: Heterogeneous-Computing Interface for Portability (HIP)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异构计算接口（HIP）
- en: Enables source portability for NVIDIA and AMD platforms, Intel in plan
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现NVIDIA和AMD平台的源可移植性，Intel计划中
- en: Provides `hipcc` compiler driver and runtime libraries
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供`hipcc`编译器驱动程序和运行时库
- en: 'Libraries: Prefixed with `roc` for AMD platforms'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库：以`roc`前缀针对AMD平台
- en: Can be called directly from HIP
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可直接从HIP调用
- en: '`hip`-prefixed wrappers ensure portability with no performance cost'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hip`前缀的包装确保无性能成本的可移植性'
- en: oneAPI - In short
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI - 简而言之
- en: 'Intel oneAPI: Unified software toolkit for optimizing and deploying applications
    across various architectures'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：跨各种架构优化和部署应用的统一软件工具包
- en: Supports CPUs, GPUs, and FPGAs
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持CPU、GPU和FPGA
- en: Enables code reusability and performance portability
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现代码重用和性能可移植性
- en: 'Intel oneAPI Base Toolkit: Core set of tools and libraries for high-performance,
    data-centric applications'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI Base Toolkit：高性能、数据为中心应用的核心工具和库集合
- en: Includes C++ compiler with SYCL support
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含具有SYCL支持的C++编译器
- en: Features Collective Communications Library, Data Analytics Library, Deep Neural
    Networks Library, and more
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特点包括集体通信库、数据分析库、深度神经网络库等
- en: 'Additional toolkits: Intel oneAPI HPC Toolkit'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外工具包：Intel oneAPI HPC工具包
- en: Contains compilers, debugging tools, MPI library, and performance analysis tool
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含编译器、调试工具、MPI库和性能分析工具
- en: 'Multiple programming models and languages supported:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种编程模型和语言：
- en: OpenMP, Classic Fortran, C++, SYCL
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenMP、经典Fortran、C++、SYCL
- en: Unless custom Intel libraries are used, the code is portable to other OpenMP
    and SYCL frameworks
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非使用自定义Intel库，否则代码可移植到其他OpenMP和SYCL框架
- en: 'DPC++ Compiler: Supports Intel, NVIDIA, and AMD GPUs'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DPC++编译器：支持Intel、NVIDIA和AMD GPU
- en: Targets Intel GPUs using oneAPI Level Zero interface
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对使用oneAPI Level Zero接口的Intel GPU
- en: Added support for NVIDIA GPUs with CUDA and AMD GPUs with ROCm
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加了支持CUDA的NVIDIA GPU和ROCm的AMD GPU
- en: 'Debugging and performance analysis tools: Intel Adviser, Intel Vtune Profiler,
    Cluster Checker, Inspector, Intel Trace Analyzer and Collector, Intel Distribution
    for GDB'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试和性能分析工具：Intel Adviser、Intel Vtune Profiler、Cluster Checker、Inspector、Intel
    Trace Analyzer and Collector、Intel Distribution for GDB
- en: Comprehensive and unified approach to heterogeneous computing
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异构计算的全面统一方法
- en: Abstracts complexities and provides consistent programming interface
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象复杂度并提供一致的编程接口
- en: Promotes code reusability, productivity, and performance portability
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进代码重用、生产力和性能可移植性
- en: CUDA
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUDA
- en: '**Compute Unified Device Architecture** is the parallel computing platform
    from NVIDIA. The CUDA API provides a comprehensive set of functions and tools
    for developing high-performance applications that run on NVIDIA GPUs. It consists
    of two main components: the CUDA Toolkit and the CUDA driver. The toolkit provides
    a set of libraries, compilers, and development tools for programming and optimizing
    CUDA applications, while the driver is responsible for communication between the
    host CPU and the device GPU. CUDA is designed to work with programming languages
    such as C, C++, and Fortran.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**统一计算设备架构**是 NVIDIA 的并行计算平台。CUDA API 为开发在 NVIDIA GPU 上运行的高性能应用程序提供了一套全面的函数和工具。它由两个主要组件组成：CUDA
    工具包和 CUDA 驱动程序。工具包提供了一套用于编程和优化 CUDA 应用程序的库、编译器和开发工具，而驱动程序负责主机 CPU 和设备 GPU 之间的通信。CUDA
    设计用于与 C、C++ 和 Fortran 等编程语言一起工作。'
- en: 'CUDA API provides many highly optimize libraries such as: **cuBLAS** (for linear
    algebra operations, such a dense matrix multiplication), **cuFFT** (for performing
    fast Fourier transforms), **cuRAND** (for generating pseudo-random numbers), **cuSPARSE**
    (for sparse matrices operations). Using these libraries, developers can quickly
    and easily accelerate complex computations on NVIDIA GPUs without having to write
    low-level GPU code themselves.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA API 提供了许多高度优化的库，例如：**cuBLAS**（用于线性代数运算，例如密集矩阵乘法）、**cuFFT**（用于执行快速傅里叶变换）、**cuRAND**（用于生成伪随机数）、**cuSPARSE**（用于稀疏矩阵运算）。使用这些库，开发者可以快速轻松地加速在
    NVIDIA GPU 上进行的复杂计算，而无需自己编写底层 GPU 代码。
- en: 'There are several compilers that can be used for developing and executing code
    on NVIDIA GPUs: **nvcc**. The latest versions are based on the widely used LLVM
    (low level virtual machine) open source compiler infrastructure. nvcc produces
    optimized code for NVIDIA GPUs and drives a supported host compiler for AMD, Intel,
    OpenPOWER, and Arm CPUs.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种编译器可用于在 NVIDIA GPU 上开发和执行代码：**nvcc**。最新版本基于广泛使用的 LLVM（低级虚拟机）开源编译器基础设施。nvcc
    为 NVIDIA GPU 生成优化代码，并驱动支持 AMD、Intel、OpenPOWER 和 Arm CPU 的主机编译器。
- en: In addition to this are provided **nvc** (C11 compiler), **nvc++** (C++17 compiler),
    and **nvfortran** (ISO Fortran 2003 compiler). These compilers can as well create
    code for execution on the NVIDIA GPUs, and also support GPU and multicore CPU
    programming with parallel language features, OpeanACC and OpenMP.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提供了 **nvc**（C11 编译器）、**nvc++**（C++17 编译器）和 **nvfortran**（ISO Fortran 2003
    编译器）。这些编译器不仅可以创建在 NVIDIA GPU 上执行的代码，还支持使用并行语言特性 OpenACC 和 OpenMP 进行 GPU 和多核 CPU
    编程。
- en: When programming mistakes are inevitable they have to be fixed as soon as possible.
    The CUDA toolkit includes the command line tool **cuda-gdb** which can be used
    to find errors in the code. It is an extension to GDB, the GNU Project debugger.
    The existing GDB debugging features are inherently present for debugging the host
    code, and additional features have been provided to support debugging CUDA device
    code, allowing simultaneous debugging of both GPU and CPU code within the same
    application. The tool provides developers with a mechanism for debugging CUDA
    applications running on actual hardware. This enables developers to debug applications
    without the potential variations introduced by simulation and emulation environments.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当编程错误不可避免时，它们必须尽快修复。CUDA 工具包包括命令行工具 **cuda-gdb**，可用于查找代码中的错误。它是 GNU 项目调试器 GDB
    的扩展。现有的 GDB 调试功能本身适用于调试主机代码，并提供了额外的功能以支持调试 CUDA 设备代码，允许在同一应用程序中同时调试 GPU 和 CPU
    代码。该工具为开发者提供了一种调试在真实硬件上运行的 CUDA 应用程序的方法。这使得开发者能够在没有模拟和仿真环境引入的潜在变化的情况下调试应用程序。
- en: 'In addition to this the command line tool **compute-sanitizer** can be used
    to look exclusively for memory access problems: unallocated buffers, out of bounds
    accesses, race conditions, and uninitialized variables.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，命令行工具 **compute-sanitizer** 可以用于专门查找内存访问问题：未分配的缓冲区、越界访问、竞态条件和未初始化的变量。
- en: Finally, in order to utilize the GPUs at maximum some performance analysis tools.
    NVIDIA provides NVIDIA Nsight Systems and NVIDIA Nsight Compute tools for helping
    the developers to optimize their applications. The former, NVIDIA Nsight Systems,
    is a system-wide performance analysis tool that provides detailed metrics on both
    CPU and GPU usage, memory bandwidth, and other system-level metrics. The latter,
    NVIDIA Nsight Compute, is a kernel-level performance analysis tool that allows
    developers to analyze the performance of individual CUDA kernels. It provides
    detailed metrics on kernel execution, including memory usage, instruction throughput,
    and occupancy. These tools have graphical which can be used for all steps of the
    performance analysis, however on supercomputers it is recommended to use the command
    line interface for collecting the information needed and then visualize and analyse
    the results using the graphical interface on personal computers.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了最大限度地利用GPU，需要一些性能分析工具。NVIDIA提供了NVIDIA Nsight Systems和NVIDIA Nsight Compute工具，以帮助开发者优化他们的应用程序。前者，NVIDIA
    Nsight Systems，是一个系统级性能分析工具，它提供了关于CPU和GPU使用情况、内存带宽以及其他系统级指标的详细指标。后者，NVIDIA Nsight
    Compute，是一个内核级性能分析工具，允许开发者分析单个CUDA内核的性能。它提供了关于内核执行的详细指标，包括内存使用、指令吞吐量和占用率。这些工具具有图形界面，可用于性能分析的各个步骤，然而在超级计算机上，建议使用命令行界面来收集所需信息，然后使用个人计算机上的图形界面可视化和分析结果。
- en: Apart from what was presented above there are many others tools and features
    provided by NVIDIA. The CUDA ecosystem is very well developed.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上面提到的，NVIDIA还提供了许多其他工具和功能。CUDA生态系统非常发达。
- en: ROCm
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROCm
- en: ROCm is an open software platform allowing researchers to tap the power of AMD
    accelerators. The ROCm platform is built on the foundation of open portability,
    supporting environments across multiple accelerator vendors and architectures.
    In some way it is very similar to CUDA API. It contains libraries, compilers,
    and development tools for programming and optimizing programs for AMD GPUs. For
    debugging, it provides the command line tool `rocgdb`, while for performance analysis
    `rocprof` and `roctracer`. In order to produce code for the AMD GPUs, one can
    use the Heterogeneous-Computing Interface for Portability (HIP). HIP is a C++
    runtime API and a set of tools that allows developers to write portable GPU-accelerated
    code for both NVIDIA and AMD platforms. It provides the `hipcc` compiler driver,
    which will call the appropriate toolchain depending on the desired platform. On
    the AMD ROCm platform, HIP provides a header and runtime library built on top
    of the HIP-Clang (ROCm compiler). On an NVIDIA platform, HIP provides a header
    file which translates from the HIP runtime APIs to CUDA runtime APIs. The header
    file contains mostly inlined functions and thus has very low overhead. The code
    is then compiled with `nvcc`, the standard C++ compiler provided with CUDA. On
    AMD platforms, libraries are prefixed by `roc`, which can be called directly from
    HIP. In order to make portable calls, one can call the libraries using `hip`-prefixed
    wrappers. These wrappers can be used at no performance cost and ensure that HIP
    code can be used on other platforms with no changes. Libraries included in the
    ROCm, are almost one-to-one equivalent to the ones supplied with CUDA.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm是一个开源软件平台，允许研究人员利用AMD加速器的强大功能。ROCm平台建立在开放可移植性的基础上，支持多个加速器和架构的环境。在某种程度上，它与CUDA
    API非常相似。它包含用于为AMD GPU编程和优化的库、编译器和开发工具。对于调试，它提供了命令行工具`rocgdb`，而对于性能分析，则提供了`rocprof`和`roctracer`。为了为AMD
    GPU生成代码，可以使用异构计算接口可移植性（HIP）。HIP是一个C++运行时API和一系列工具，允许开发者编写适用于NVIDIA和AMD平台的可移植GPU加速代码。它提供了`hipcc`编译器驱动程序，该驱动程序将根据所需的平台调用适当的工具链。在AMD
    ROCm平台上，HIP提供了一个基于HIP-Clang（ROCm编译器）的标头和运行时库。在NVIDIA平台上，HIP提供了一个将HIP运行时API转换为CUDA运行时API的标头文件。该头文件主要包含内联函数，因此开销非常低。然后使用`nvcc`编译器，这是CUDA附带的标准C++编译器，来编译代码。在AMD平台上，库以`roc`为前缀，可以直接从HIP调用。为了进行可移植调用，可以使用以`hip`为前缀的包装器。这些包装器无需任何性能开销，并确保HIP代码可以在其他平台上使用而无需更改。ROCm中包含的库几乎与CUDA提供的库一一对应。
- en: ROCm also integrates with popular machine learning frameworks such as TensorFlow
    and PyTorch and provides optimized libraries and drivers to accelerate machine
    learning workloads on AMD GPUs enabling the researchers to leverage the power
    of ROCm and AMD accelerators to train and deploy machine learning models efficiently.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm还集成了流行的机器学习框架，如TensorFlow和PyTorch，并提供优化的库和驱动程序，以加速在AMD GPU上运行的机器学习工作负载，使研究人员能够有效地利用ROCm和AMD加速器的力量来训练和部署机器学习模型。
- en: oneAPI
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: oneAPI
- en: '**Intel oneAPI** is a unified software toolkit developed by Intel that allows
    developers to optimize and deploy applications across a variety of architectures,
    including CPUs, GPUs, and FPGAs. It provides a comprehensive set of tools, libraries,
    and frameworks, enabling developers to leverage the full potential of heterogeneous
    computing environments. With oneAPI, the developers can write code once and deploy
    it across different hardware targets without the need for significant modifications
    or rewriting. This approach promotes code reusability, productivity, and performance
    portability, as it abstracts the complexities of heterogeneous computing and provides
    a consistent programming interface based on open standards.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**Intel oneAPI** 是英特尔开发的一个统一的软件工具包，它允许开发者优化和部署跨多种架构的应用程序，包括CPU、GPU和FPGA。它提供了一套全面的工具、库和框架，使开发者能够充分利用异构计算环境的全部潜力。使用oneAPI，开发者可以编写一次代码，并在不同的硬件目标上部署，无需进行重大修改或重写。这种方法促进了代码的可重用性、生产力和性能的可移植性，因为它抽象了异构计算的复杂性，并基于开放标准提供了一个一致的编程接口。'
- en: The core of suite is **Intel oneAPI Base Toolkit**, a set of tools and libraries
    for developing high-performance, data-centric applications across diverse architectures.
    It features an industry-leading C++ compiler that implements SYCL, an evolution
    of C++ for heterogeneous computing. It includes the **Collective Communications
    Library**, the **Data Analytics Library**, the **Deep Neural Networks Library**,
    the **DPC++/C++ Compiler**, the **DPC++ Library**, the **Math Kernel Library**,
    the **Threading Building Blocks**, debugging tool **Intel Distribution for GDB**,
    performance analysis tools **Intel Adviser** and **Intel Vtune Profiler**, the
    **Video Processing Library**, **Intel Distribution for Python**, the **DPC++ Compatibility
    Tool**, the **FPGA Add-on for oneAPI Base Toolkit**, the **Integrated Performance
    Primitives**. This can be complemented with additional toolkits. The **Intel oneAPI
    HPC Toolkit** contains **DPC++/C++ Compiler**, **Fortran** and **C++** Compiler
    Classic, debugging tools **Cluster Checker** and **Inspector**, **Intel MPI Library**,
    and performance analysis tool **Intel Trace Analyzer and Collector**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 套件的核心是**Intel oneAPI Base Toolkit**，这是一套用于在多种架构上开发高性能、数据为中心的应用程序的工具和库。它具有业界领先的C++编译器，实现了C++的演变——SYCL，用于异构计算。它包括**集体通信库**、**数据分析库**、**深度神经网络库**、**DPC++/C++编译器**、**DPC++库**、**数学内核库**、**线程构建块**、调试工具**Intel
    Distribution for GDB**、性能分析工具**Intel Adviser**和**Intel Vtune Profiler**、**视频处理库**、**Intel
    Distribution for Python**、**DPC++兼容性工具**、**oneAPI Base Toolkit的FPGA附加组件**、**集成性能原语**。这可以补充额外的工具包。**Intel
    oneAPI HPC Toolkit**包含**DPC++/C++编译器**、**Fortran**和**C++**编译器经典、调试工具**Cluster
    Checker**和**Inspector**、**Intel MPI库**以及性能分析工具**Intel Trace Analyzer and Collector**。
- en: oneAPI supports multiple programming models and programming languages. It enables
    developers to write **OpenMP** codes targeting multi-core CPUs and Intel GPUs
    using the Classic Fortran and C++ compilers and as well **SYCL** programs for
    GPUs and FPGAs using the **DPC++** compiler. Initially, the **DPC++** compiler
    only targeted Intel GPUs using the **oneAPI Level Zero** low-level programming
    interface, but now support for NVIDIA GPUs (using CUDA) and AMD GPUs (using ROCm)
    has been added. Overall, Intel oneAPI offers a comprehensive and unified approach
    to heterogeneous computing, empowering developers to optimize and deploy applications
    across different architectures with ease. By abstracting the complexities and
    providing a consistent programming interface, oneAPI promotes code reusability,
    productivity, and performance portability, making it an invaluable toolkit for
    developers in the era of diverse computing platforms.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI 支持多种编程模型和编程语言。它使开发者能够使用经典 Fortran 和 C++ 编译器编写针对多核 CPU 和英特尔 GPU 的 **OpenMP**
    代码，以及使用 **DPC++** 编译器为 GPU 和 FPGA 编写 **SYCL** 程序。最初，**DPC++** 编译器仅针对使用 **oneAPI
    Level Zero** 低级编程接口的英特尔 GPU，但现在已增加了对 NVIDIA GPU（使用 CUDA）和 AMD GPU（使用 ROCm）的支持。总的来说，英特尔
    oneAPI 提供了一种全面且统一的方法来处理异构计算，使开发者能够轻松地在不同的架构上优化和部署应用程序。通过抽象复杂性和提供一致的编程接口，oneAPI
    促进代码重用性、生产力和性能的可移植性，使其成为多元计算平台时代开发者不可或缺的工具包。
- en: Differences and similarities
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差异与相似之处
- en: GPUs in general support different features, even among the same producer. In
    general newer cards come with extra features and sometimes old features are not
    supported anymore. It is important when compiling to create binaries targeting
    the specific architecture when compiling. A binary built for a newer card will
    not run on older devices, while a binary build for older devices might not run
    efficiently on newer architectures. In CUDA the compute capability which is targeted
    is specified by the `-arch=sm_XY`, where `X` specifies the major architecture
    and it is between 1 and 9, and `Y` the minor. When using HIP on NVIDIA platforms
    one needs to use compiling option `--gpu-architecture=sm_XY`, while on AMD platforms
    `--offload-arch=gfxabc` ( where `abc` is the architecture code such as `90a` for
    the MI200 series or `908` for MI100 series). Note that in the case of portable
    (single source) programs one would specify `openmp` as well as target for compilation,
    enabling to run the same code on multicore CPU.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，GPU 支持不同的功能，即使在同一生产者之间也是如此。通常，新卡会带来额外的功能，有时旧功能可能不再受支持。在编译时，创建针对特定架构的二进制文件很重要。为较新卡构建的二进制文件无法在较旧设备上运行，而为较旧设备构建的二进制文件可能在较新架构上运行效率不高。在
    CUDA 中，目标计算能力通过 `-arch=sm_XY` 指定，其中 `X` 指定主架构，介于 1 和 9 之间，而 `Y` 指定次架构。当在 NVIDIA
    平台上使用 HIP 时，需要使用编译选项 `--gpu-architecture=sm_XY`，而在 AMD 平台上使用 `--offload-arch=gfxabc`（其中
    `abc` 是架构代码，例如 MI200 系列的 `90a` 或 MI100 系列的 `908`）。请注意，在可移植（单源）程序的情况下，还需要指定 `openmp`
    以及编译目标，以便能够在多核 CPU 上运行相同的代码。
- en: Terminology
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 术语
- en: Hardware
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件
- en: '| NVIDIA | AMD | Intel |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | AMD | Intel |'
- en: '| --- | --- | --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Streaming processor/streaming core | SIMD lane | Processing element |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 流处理器/流核心 | SIMD 通道 | 处理单元 |'
- en: '| SIMT unit | SIMD unit | Vector engine (XVE) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| SIMT 单元 | SIMD 单元 | 向量引擎 (XVE) |'
- en: '| Streaming Multiprocessor (SM) | Computing Unit (CU) | Xe-core / Execution
    unit (EU) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 流式多处理器 (SM) | 计算单元 (CU) | Xe 核心 / 执行单元 (EU) |'
- en: '| GPU processing clusters (GPC) | Compute Engine | Xe-slice |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| GPU 处理集群 (GPC) | 计算引擎 | Xe-slice |'
- en: Please keep in mind, that this table is only a rough approximation. Each GPU
    architecture is different, and it’s impossible to make a 1-to-1 mapping between
    terms used by different vendors.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个表格只是一个粗略的近似。每个 GPU 架构都是不同的，不可能在不同供应商使用的术语之间进行一对一的映射。
- en: Summary
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: GPUs are designed to execute thousands of threads simultaneously, making them
    highly parallel processors. In contrast, CPUs excel at executing a smaller number
    of threads in parallel.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 被设计成可以同时执行数千个线程，使其成为高度并行的处理器。相比之下，CPU 在并行执行较少线程方面表现出色。
- en: GPUs allocate a larger portion of transistors to data processing rather than
    data caching and flow control. This prioritization of data processing enables
    GPUs to effectively handle parallel computations and hide memory access latencies
    through computation.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 将更大的晶体管部分分配给数据处理，而不是数据缓存和流量控制。这种对数据处理的优先级使得 GPU 能够有效地处理并行计算，并通过计算隐藏内存访问延迟。
- en: GPU producers provide comprehensive toolkits, libraries, and compilers for developing
    high-performance applications that leverage the parallel processing power of GPUs.
    Examples include CUDA (NVIDIA), ROCm (AMD), and oneAPI (Intel).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU生产商为开发利用GPU并行处理能力的应用程序提供全面的工具包、库和编译器。例如，CUDA（NVIDIA）、ROCm（AMD）和oneAPI（Intel）。
- en: These platforms offer debugging tools (e.g., `cuda-gdb`, `rocgdb`) and performance
    analysis tools (e.g., NVIDIA Nsight Systems, NVIDIA Nsight Compute, `rocprof`,
    `roctracer`) to facilitate code optimization and ensure efficient utilization
    of GPU resources.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些平台提供调试工具（例如，`cuda-gdb`、`rocgdb`）和性能分析工具（例如，NVIDIA Nsight Systems、NVIDIA Nsight
    Compute、`rocprof`、`roctracer`），以促进代码优化并确保GPU资源的有效利用。
- en: Exercises
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: GPUs and memory
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: GPU和内存
- en: Which statement about the relationship between GPUs and memory is true?
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPU和内存之间关系的哪个陈述是正确的？
- en: GPUs are not affected by memory access latencies.
  id: totrans-124
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU不受内存访问延迟的影响。
- en: GPUs can run out of memory quickly with many cores trying to access the memory
    simultaneously.
  id: totrans-125
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当许多内核同时尝试访问内存时，GPU可能会快速耗尽内存。
- en: GPUs have an unlimited cache size.
  id: totrans-126
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU具有无限的缓存大小。
- en: GPUs prefer to run with a minimal number of threads to manage memory effectively.
  id: totrans-127
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU更喜欢以最少的线程数量运行，以有效地管理内存。
- en: Solution
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The correct answer is B). This is true because GPUs run many threads simultaneously
    on thousands of cores, and with limited cache available, this can lead to the
    GPU running out of memory quickly if many cores are trying to access the memory
    simultaneously. This is why data management and access patterns are essential
    in GPU computing.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是B）。这是因为GPU在数千个内核上同时运行许多线程，并且由于缓存有限，如果许多内核同时尝试访问内存，这可能导致GPU快速耗尽内存。这就是为什么数据管理和访问模式在GPU计算中至关重要。
- en: Keypoints
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs vs. CPUs, key differences between them
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU与CPU，它们之间的关键区别
- en: GPU software suites, support specific GPU features, programming models, compatibility
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU软件套件，支持特定的GPU功能，编程模型，兼容性
- en: Applications of GPUs [Previous](../1-gpu-history/ "Why GPUs?") [Next](../3-gpu-problems/
    "What problems fit to GPU?")
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU的应用程序[上一页](../1-gpu-history/ "为什么使用GPU？") [下一页](../3-gpu-problems/ "适合GPU的问题？")
- en: '* * *'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: © Copyright 2023-2024, The contributors.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ©版权所有 2023-2024，贡献者。
- en: Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). Questions
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Sphinx](https://www.sphinx-doc.org/)和由[Read the Docs](https://readthedocs.org)提供的[主题](https://github.com/readthedocs/sphinx_rtd_theme)构建。问题
- en: What are the differences between GPUs and CPUs?
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU和CPU之间的区别是什么？
- en: What GPU software stacks are available? What do they provide?
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的GPU软件堆栈有哪些？它们提供什么？
- en: Objectives
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Understand the fundamental differences between GPUs and CPUs
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解GPU和CPU之间的基本区别
- en: Explore the major GPU software suites available, such as CUDA, ROCm, and oneAPI,
    and gain a basic understanding of them
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索可用的主要GPU软件套件，例如CUDA、ROCm和oneAPI，并对其有一个基本的了解
- en: Instructor note
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 20 min teaching
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20分钟教学
- en: 0 min exercises
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0分钟练习
- en: Overview of GPU hardware
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU硬件概述
- en: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
- en: A comparison of the CPU and GPU architecture. CPU (left) has complex core structure
    and pack several cores on a single chip. GPU cores are very simple in comparison,
    they also share data and control between each other. This allows to pack more
    cores on a single chip, thus achieving very high compute density.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: CPU（左）具有复杂的内核结构，并在单个芯片上集成多个内核。与CPU内核相比，GPU内核非常简单，它们之间也共享数据和控制。这使得可以在单个芯片上集成更多内核，从而实现非常高的计算密度。
- en: In short
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之
- en: Accelerators offer high performance due to their scalability and high density
    of compute elements.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速器由于其可扩展性和计算元素的密集度而提供高性能。
- en: They have separate circuit boards connected to CPUs via PCIe bus, with their
    own memory.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们通过PCIe总线连接到CPU，并拥有自己的电路板。
- en: CPUs copy data from their own memory to the GPU memory, execute the program,
    and copy the results back.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU将数据从自己的内存复制到GPU内存，执行程序，并将结果复制回来。
- en: GPUs run thousands of threads simultaneously, quickly switching between them
    to hide memory operations.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU同时运行数千个线程，快速地在它们之间切换以隐藏内存操作。
- en: Effective data management and access pattern is critical on the GPU to avoid
    running out of memory.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上，有效的数据管理和访问模式至关重要，以避免内存不足。
- en: 'Accelerators are a separate main circuit board with the processor, memory,
    power management, etc. It is connected to the motherboard with CPUs via PCIe bus.
    Having its own memory means that the data has to be copied to and from it (not
    neceseraly true anymore). CPU acts as a main processor, controlling the execution
    workflow. It copies the data from its own memory to the GPU memory, executes the
    program and copies the results back. GPUs runs tens of thousands of threads simultaneously
    on thousands of cores and does not do much of the data management. With many cores
    trying to access the memory simultaneously and with little cache available, the
    accelerator can run out of memory very quickly. This makes the data management
    and its access pattern is essential on the GPU. Accelerators like to be overloaded
    with the number of threads, because they can switch between threads very quickly.
    This allows to hide the memory operations: while some threads wait, others can
    compute.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器是一个独立的电路板，包含处理器、内存、电源管理等。它通过PCIe总线连接到CPU的主板。拥有自己的内存意味着数据必须被复制到和从它那里（现在可能不再是这种情况）。CPU作为主处理器，控制执行工作流程。它将数据从自己的内存复制到GPU内存，执行程序，并将结果复制回来。GPU在数千个核心上同时运行数万个线程，并且不做太多的数据管理。由于许多核心同时尝试访问内存，且缓存有限，加速器可能会很快耗尽内存。这使得数据管理和其访问模式在GPU上至关重要。加速器喜欢被线程数量超载，因为它们可以非常快速地在线程之间切换。这允许隐藏内存操作：当一些线程等待时，其他线程可以计算。
- en: 'A very important feature of the accelerators is their scalability. Computational
    cores on accelerators are usually grouped into multiprocessors. The multiprocessors
    share the data and logical elements. This allows to achieve a very high density
    of compute elements on a GPU. This also allows the scaling: more multiprocessors
    means more raw performance and this is very easy to achieve with more transistors
    available.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器的一个重要特性是其可扩展性。加速器上的计算核心通常被分组为多处理器。多处理器共享数据和逻辑元素。这允许在GPU上实现非常高的计算元素密度。这也允许进行扩展：更多的多处理器意味着更高的原始性能，而且通过更多的晶体管很容易实现。
- en: How do GPUs differ from CPUs?
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU与CPU有何不同？
- en: CPUs and GPUs were designed with different goals in mind. While the CPU is designed
    to excel at executing a sequence of operations, called a thread, as fast as possible
    and can execute a few tens of these threads in parallel, the GPU is designed to
    excel at executing many thousands of them in parallel. GPUs were initially developed
    for highly-parallel task of graphic processing and therefore designed such that
    more transistors are devoted to data processing rather than data caching and flow
    control. More transistors dedicated to data processing is beneficial for highly
    parallel computations; the GPU can hide memory access latencies with computation,
    instead of relying on large data caches and complex flow control to avoid long
    memory access latencies, both of which are expensive in terms of transistors.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和GPU的设计初衷不同。虽然CPU旨在尽可能快地执行一系列操作，称为线程，并且可以并行执行几十个这样的线程，但GPU旨在并行执行成千上万的线程。GPU最初是为高度并行的图形处理任务开发的，因此设计时更多地致力于数据处理而不是数据缓存和流量控制。更多用于数据处理的晶体管对高度并行的计算有益；GPU可以通过计算来隐藏内存访问延迟，而不是依赖于大型数据缓存和复杂的流量控制来避免长时间的内存访问延迟，这两者从晶体管的角度来看都是昂贵的。
- en: '| CPU | GPU |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| CPU | GPU |'
- en: '| --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| General purpose | Highly specialized for parallelism |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 通用 | 高度针对并行性 |'
- en: '| Good for serial processing | Good for parallel processing |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 适合串行处理 | 适合并行处理 |'
- en: '| Great for task parallelism | Great for data parallelism |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 适合任务并行 | 适合数据并行 |'
- en: '| Low latency per thread | High-throughput |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 每线程低延迟 | 高吞吐量 |'
- en: '| Large area dedicated cache and control | Hundreds of floating-point execution
    units |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 大面积专用缓存和控制 | 数百个浮点执行单元 |'
- en: GPU platforms
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU平台
- en: GPUs come together with software stacks or APIs that work in conjunction with
    the hardware and give a standard way for the software to interact with the GPU
    hardware. They are used by software developers to write code that can take advantage
    of the parallel processing power of the GPU, and they provide a standard way for
    software to interact with the GPU hardware. Typically, they provide access to
    low-level functionality, such as memory management, data transfer between the
    CPU and the GPU, and the scheduling and execution of parallel processing tasks
    on the GPU. They may also provide higher level functions and libraries optimized
    for specific HPC workloads, like linear algebra or fast Fourier transforms. Finally,
    in order to facilitate the developers to optimize and write correct codes, debugging
    and profiling tools are also included.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: GPU与软件堆栈或API结合使用，与硬件协同工作，为软件与GPU硬件的交互提供标准方式。软件开发者使用这些工具编写可以利用GPU并行处理能力的代码，并为软件与GPU硬件的交互提供标准方式。通常，它们提供对底层功能，如内存管理、CPU和GPU之间的数据传输以及GPU上并行处理任务的调度和执行。它们还可能提供针对特定HPC工作负载（如线性代数或快速傅里叶变换）优化的高级功能和库。最后，为了帮助开发者优化和编写正确的代码，还包含调试和性能分析工具。
- en: '*NVIDIA*, *AMD*, and *Intel* are the major companies which design and produces
    GPUs for HPC providing each its own suite **CUDA**, **ROCm**, and respectively
    **oneAPI**. This way they can offer optimization, differentiation (offering unique
    features tailored to their devices), vendor lock-in, licensing, and royalty fees,
    which can result in better performance, profitability, and customer loyalty. There
    are also cross-platform APIs such **DirectCompute** (only for Windows operating
    system), **OpenCL**, and **SYCL**.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**NVIDIA**、**AMD**和**Intel**是设计并生产用于HPC的GPU的主要公司，它们分别提供自己的套件**CUDA**、**ROCm**和**oneAPI**。这样，它们可以提供优化、差异化（提供针对其设备定制的独特功能）、供应商锁定、许可和版税费用，这可能导致更好的性能、盈利能力和客户忠诚度。还有跨平台的API，如**DirectCompute**（仅适用于Windows操作系统）、**OpenCL**和**SYCL**。'
- en: CUDA - In short
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA - 简而言之
- en: 'CUDA: NVIDIA’s parallel computing platform'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA：NVIDIA的并行计算平台
- en: 'Components: CUDA Toolkit & CUDA driver'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件：CUDA Toolkit & CUDA驱动程序
- en: Supports C, C++, and Fortran languages
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C、C++和Fortran语言
- en: 'CUDA API Libraries: cuBLAS, cuFFT, cuRAND, cuSPARSE'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA API库：cuBLAS、cuFFT、cuRAND、cuSPARSE
- en: Accelerate complex computations on GPUs
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速GPU上的复杂计算
- en: 'Compilers: nvcc, nvc, nvc++, nvfortran'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器：nvcc、nvc、nvc++、nvfortran
- en: Support GPU and multicore CPU programming
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持GPU和多核CPU编程
- en: Compatible with OpenACC and OpenMP
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 兼容OpenACC和OpenMP
- en: 'Debugging tools: cuda-gdb, compute-sanitizer'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试工具：cuda-gdb、compute-sanitizer
- en: Debug GPU and CPU code simultaneously
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时调试GPU和CPU代码
- en: Identify memory access issues
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别内存访问问题
- en: 'Performance analysis tools: NVIDIA Nsight Systems, NVIDIA Nsight Compute'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析工具：NVIDIA Nsight Systems、NVIDIA Nsight Compute
- en: Analyze system-wide and kernel-level performance
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析系统级和内核级性能
- en: Optimize CPU and GPU usage, memory bandwidth, instruction throughput
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化CPU和GPU使用，内存带宽，指令吞吐量
- en: Comprehensive CUDA ecosystem with extensive tools and features
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的CUDA生态系统，具有广泛的功能和工具
- en: ROCm - In short
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm - 简而言之
- en: 'ROCm: Open software platform for AMD accelerators'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROCm：AMD加速器的开源软件平台
- en: Built for open portability across multiple vendors and architectures
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为跨多个供应商和架构的开放可移植性而构建
- en: Offers libraries, compilers, and development tools for AMD GPUs
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为AMD GPU提供库、编译器和开发工具
- en: Supports C, C++, and Fortran languages
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C、C++和Fortran语言
- en: Support GPU and multicore CPU programming
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持GPU和多核CPU编程
- en: 'Debugging: `roc-gdb` command line tool'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试：`roc-gdb`命令行工具
- en: Facilitates debugging of GPU programs
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进GPU程序的调试
- en: 'Performance analysis: `rocprof` and `roctracer` tools'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析：`rocprof`和`roctracer`工具
- en: Analyze and optimize program performance
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析和优化程序性能
- en: Supports various heterogeneous programming models such as **HIP**, **OpenMP**,
    and **OpenCL**
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持各种异构编程模型，如**HIP**、**OpenMP**和**OpenCL**
- en: Heterogeneous-Computing Interface for Portability (HIP)
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异构计算接口（Heterogeneous-Computing Interface for Portability, HIP）
- en: Enables source portability for NVIDIA and AMD platforms, Intel in plan
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使NVIDIA和AMD平台实现源便携性，Intel计划中
- en: Provides `hipcc` compiler driver and runtime libraries
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供`hipcc`编译器驱动程序和运行时库
- en: 'Libraries: Prefixed with `roc` for AMD platforms'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库：以`roc`为前缀，适用于AMD平台
- en: Can be called directly from HIP
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可直接从HIP调用
- en: '`hip`-prefixed wrappers ensure portability with no performance cost'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hip`前缀的包装器确保了无性能成本的便携性'
- en: oneAPI - In short
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI - 简而言之
- en: 'Intel oneAPI: Unified software toolkit for optimizing and deploying applications
    across various architectures'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：用于在各种架构上优化和部署应用程序的统一软件工具包
- en: Supports CPUs, GPUs, and FPGAs
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 CPU、GPU 和 FPGA
- en: Enables code reusability and performance portability
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现代码重用性和性能可移植性
- en: 'Intel oneAPI Base Toolkit: Core set of tools and libraries for high-performance,
    data-centric applications'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI Base Toolkit：用于高性能、数据为中心应用的核心工具和库集合
- en: Includes C++ compiler with SYCL support
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含支持 SYCL 的 C++ 编译器
- en: Features Collective Communications Library, Data Analytics Library, Deep Neural
    Networks Library, and more
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能包括集体通信库、数据分析库、深度神经网络库等
- en: 'Additional toolkits: Intel oneAPI HPC Toolkit'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他工具包：Intel oneAPI HPC Toolkit
- en: Contains compilers, debugging tools, MPI library, and performance analysis tool
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含编译器、调试工具、MPI 库和性能分析工具
- en: 'Multiple programming models and languages supported:'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种编程模型和语言：
- en: OpenMP, Classic Fortran, C++, SYCL
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenMP、经典Fortran、C++、SYCL
- en: Unless custom Intel libraries are used, the code is portable to other OpenMP
    and SYCL frameworks
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非使用自定义的 Intel 库，否则代码可移植到其他 OpenMP 和 SYCL 框架
- en: 'DPC++ Compiler: Supports Intel, NVIDIA, and AMD GPUs'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DPC++ 编译器：支持 Intel、NVIDIA 和 AMD GPU
- en: Targets Intel GPUs using oneAPI Level Zero interface
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 oneAPI Level Zero 接口针对 Intel GPU
- en: Added support for NVIDIA GPUs with CUDA and AMD GPUs with ROCm
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加了支持 NVIDIA GPU 的 CUDA 和 AMD GPU 的 ROCm
- en: 'Debugging and performance analysis tools: Intel Adviser, Intel Vtune Profiler,
    Cluster Checker, Inspector, Intel Trace Analyzer and Collector, Intel Distribution
    for GDB'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试和性能分析工具：Intel Adviser、Intel Vtune Profiler、Cluster Checker、Inspector、Intel
    Trace Analyzer and Collector、Intel Distribution for GDB
- en: Comprehensive and unified approach to heterogeneous computing
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对异构计算的综合统一方法
- en: Abstracts complexities and provides consistent programming interface
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象复杂性并提供一致的编程接口
- en: Promotes code reusability, productivity, and performance portability
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进代码重用性、生产力和性能可移植性
- en: CUDA
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUDA
- en: '**Compute Unified Device Architecture** is the parallel computing platform
    from NVIDIA. The CUDA API provides a comprehensive set of functions and tools
    for developing high-performance applications that run on NVIDIA GPUs. It consists
    of two main components: the CUDA Toolkit and the CUDA driver. The toolkit provides
    a set of libraries, compilers, and development tools for programming and optimizing
    CUDA applications, while the driver is responsible for communication between the
    host CPU and the device GPU. CUDA is designed to work with programming languages
    such as C, C++, and Fortran.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**统一计算设备架构**是 NVIDIA 的并行计算平台。CUDA API 提供了一套全面的函数和工具，用于开发在 NVIDIA GPU 上运行的高性能应用程序。它由两个主要组件组成：CUDA
    Toolkit 和 CUDA 驱动程序。工具包提供了一套库、编译器和开发工具，用于编程和优化 CUDA 应用程序，而驱动程序负责主机 CPU 和设备 GPU
    之间的通信。CUDA 设计用于与 C、C++ 和 Fortran 等编程语言一起工作。'
- en: 'CUDA API provides many highly optimize libraries such as: **cuBLAS** (for linear
    algebra operations, such a dense matrix multiplication), **cuFFT** (for performing
    fast Fourier transforms), **cuRAND** (for generating pseudo-random numbers), **cuSPARSE**
    (for sparse matrices operations). Using these libraries, developers can quickly
    and easily accelerate complex computations on NVIDIA GPUs without having to write
    low-level GPU code themselves.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA API 提供了许多高度优化的库，例如：**cuBLAS**（用于线性代数运算，如稠密矩阵乘法）、**cuFFT**（用于执行快速傅里叶变换）、**cuRAND**（用于生成伪随机数）、**cuSPARSE**（用于稀疏矩阵运算）。使用这些库，开发者可以快速轻松地加速
    NVIDIA GPU 上的复杂计算，而无需自己编写低级 GPU 代码。
- en: 'There are several compilers that can be used for developing and executing code
    on NVIDIA GPUs: **nvcc**. The latest versions are based on the widely used LLVM
    (low level virtual machine) open source compiler infrastructure. nvcc produces
    optimized code for NVIDIA GPUs and drives a supported host compiler for AMD, Intel,
    OpenPOWER, and Arm CPUs.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个编译器可用于在 NVIDIA GPU 上开发和执行代码：**nvcc**。最新版本基于广泛使用的 LLVM（低级虚拟机）开源编译器基础设施。nvcc
    为 NVIDIA GPU 生成优化代码，并驱动支持 AMD、Intel、OpenPOWER 和 Arm CPU 的主机编译器。
- en: In addition to this are provided **nvc** (C11 compiler), **nvc++** (C++17 compiler),
    and **nvfortran** (ISO Fortran 2003 compiler). These compilers can as well create
    code for execution on the NVIDIA GPUs, and also support GPU and multicore CPU
    programming with parallel language features, OpeanACC and OpenMP.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 此外还提供了 **nvc**（C11 编译器）、**nvc++**（C++17 编译器）和 **nvfortran**（ISO Fortran 2003
    编译器）。这些编译器也可以为 NVIDIA GPU 创建代码，并支持使用并行语言特性 OpenACC 和 OpenMP 进行 GPU 和多核 CPU 编程。
- en: When programming mistakes are inevitable they have to be fixed as soon as possible.
    The CUDA toolkit includes the command line tool **cuda-gdb** which can be used
    to find errors in the code. It is an extension to GDB, the GNU Project debugger.
    The existing GDB debugging features are inherently present for debugging the host
    code, and additional features have been provided to support debugging CUDA device
    code, allowing simultaneous debugging of both GPU and CPU code within the same
    application. The tool provides developers with a mechanism for debugging CUDA
    applications running on actual hardware. This enables developers to debug applications
    without the potential variations introduced by simulation and emulation environments.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当编程错误不可避免时，它们必须尽快修复。CUDA 工具包包括命令行工具 **cuda-gdb**，可用于查找代码中的错误。它是 GNU 项目调试器 GDB
    的扩展。现有的 GDB 调试功能本身适用于调试主机代码，并且还提供了额外的功能来支持调试 CUDA 设备代码，允许在同一应用程序中同时调试 GPU 和 CPU
    代码。该工具为开发者提供了一种调试在真实硬件上运行的 CUDA 应用程序的方法。这使得开发者能够在没有模拟和仿真环境引入的潜在变化的情况下调试应用程序。
- en: 'In addition to this the command line tool **compute-sanitizer** can be used
    to look exclusively for memory access problems: unallocated buffers, out of bounds
    accesses, race conditions, and uninitialized variables.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述内容，命令行工具 **compute-sanitizer** 可以专门用于查找内存访问问题：未分配的缓冲区、越界访问、竞态条件和未初始化的变量。
- en: Finally, in order to utilize the GPUs at maximum some performance analysis tools.
    NVIDIA provides NVIDIA Nsight Systems and NVIDIA Nsight Compute tools for helping
    the developers to optimize their applications. The former, NVIDIA Nsight Systems,
    is a system-wide performance analysis tool that provides detailed metrics on both
    CPU and GPU usage, memory bandwidth, and other system-level metrics. The latter,
    NVIDIA Nsight Compute, is a kernel-level performance analysis tool that allows
    developers to analyze the performance of individual CUDA kernels. It provides
    detailed metrics on kernel execution, including memory usage, instruction throughput,
    and occupancy. These tools have graphical which can be used for all steps of the
    performance analysis, however on supercomputers it is recommended to use the command
    line interface for collecting the information needed and then visualize and analyse
    the results using the graphical interface on personal computers.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了最大限度地利用 GPU，需要一些性能分析工具。NVIDIA 提供了 NVIDIA Nsight Systems 和 NVIDIA Nsight
    Compute 工具，以帮助开发者优化他们的应用程序。前者，NVIDIA Nsight Systems，是一个系统级性能分析工具，它提供了关于 CPU 和
    GPU 使用情况、内存带宽以及其他系统级指标的详细指标。后者，NVIDIA Nsight Compute，是一个内核级性能分析工具，允许开发者分析单个 CUDA
    内核的性能。它提供了关于内核执行的详细指标，包括内存使用、指令吞吐量和占用率。这些工具具有图形界面，可用于性能分析的各个步骤，然而在超级计算机上，建议使用命令行界面来收集所需信息，然后使用个人计算机上的图形界面可视化和分析结果。
- en: Apart from what was presented above there are many others tools and features
    provided by NVIDIA. The CUDA ecosystem is very well developed.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上面提到的，NVIDIA 还提供了许多其他工具和功能。CUDA 生态系统非常完善。
- en: ROCm
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROCm
- en: ROCm is an open software platform allowing researchers to tap the power of AMD
    accelerators. The ROCm platform is built on the foundation of open portability,
    supporting environments across multiple accelerator vendors and architectures.
    In some way it is very similar to CUDA API. It contains libraries, compilers,
    and development tools for programming and optimizing programs for AMD GPUs. For
    debugging, it provides the command line tool `rocgdb`, while for performance analysis
    `rocprof` and `roctracer`. In order to produce code for the AMD GPUs, one can
    use the Heterogeneous-Computing Interface for Portability (HIP). HIP is a C++
    runtime API and a set of tools that allows developers to write portable GPU-accelerated
    code for both NVIDIA and AMD platforms. It provides the `hipcc` compiler driver,
    which will call the appropriate toolchain depending on the desired platform. On
    the AMD ROCm platform, HIP provides a header and runtime library built on top
    of the HIP-Clang (ROCm compiler). On an NVIDIA platform, HIP provides a header
    file which translates from the HIP runtime APIs to CUDA runtime APIs. The header
    file contains mostly inlined functions and thus has very low overhead. The code
    is then compiled with `nvcc`, the standard C++ compiler provided with CUDA. On
    AMD platforms, libraries are prefixed by `roc`, which can be called directly from
    HIP. In order to make portable calls, one can call the libraries using `hip`-prefixed
    wrappers. These wrappers can be used at no performance cost and ensure that HIP
    code can be used on other platforms with no changes. Libraries included in the
    ROCm, are almost one-to-one equivalent to the ones supplied with CUDA.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm是一个开放软件平台，允许研究人员利用AMD加速器的强大功能。ROCm平台建立在开放可移植性的基础上，支持多个加速器供应商和架构的环境。在某种程度上，它与CUDA
    API非常相似。它包含用于为AMD GPU编程和优化程序的库、编译器和开发工具。为了调试，它提供了命令行工具`rocgdb`，而为了性能分析，提供了`rocprof`和`roctracer`。为了生成AMD
    GPU的代码，可以使用异构计算接口可移植性（HIP）。HIP是一个C++运行时API和一系列工具，允许开发者为NVIDIA和AMD平台编写可移植的GPU加速代码。它提供了`hipcc`编译器驱动程序，该驱动程序将根据所需的平台调用适当的工具链。在AMD
    ROCm平台上，HIP提供了一套基于HIP-Clang（ROCm编译器）的头部和运行时库。在NVIDIA平台上，HIP提供了一套将HIP运行时API转换为CUDA运行时API的头文件。该头文件主要包含内联函数，因此开销非常低。然后使用`nvcc`编译器，这是CUDA提供的标准C++编译器，进行编译。在AMD平台上，库以`roc`为前缀，可以直接从HIP调用。为了进行可移植调用，可以使用以`hip`为前缀的包装器。这些包装器可以在不牺牲性能的情况下使用，并确保HIP代码可以在其他平台上使用而无需更改。ROCm中包含的库几乎与CUDA提供的库一一对应。
- en: ROCm also integrates with popular machine learning frameworks such as TensorFlow
    and PyTorch and provides optimized libraries and drivers to accelerate machine
    learning workloads on AMD GPUs enabling the researchers to leverage the power
    of ROCm and AMD accelerators to train and deploy machine learning models efficiently.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm还集成了流行的机器学习框架，如TensorFlow和PyTorch，并为AMD GPU提供了优化的库和驱动程序，以加速机器学习工作负载。这使得研究人员能够有效地利用ROCm和AMD加速器的强大功能来训练和部署机器学习模型。
- en: oneAPI
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: oneAPI
- en: '**Intel oneAPI** is a unified software toolkit developed by Intel that allows
    developers to optimize and deploy applications across a variety of architectures,
    including CPUs, GPUs, and FPGAs. It provides a comprehensive set of tools, libraries,
    and frameworks, enabling developers to leverage the full potential of heterogeneous
    computing environments. With oneAPI, the developers can write code once and deploy
    it across different hardware targets without the need for significant modifications
    or rewriting. This approach promotes code reusability, productivity, and performance
    portability, as it abstracts the complexities of heterogeneous computing and provides
    a consistent programming interface based on open standards.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**英特尔oneAPI**是由英特尔开发的一个统一的软件工具包，允许开发者优化和部署跨多种架构的应用程序，包括CPU、GPU和FPGA。它提供了一套全面的工具、库和框架，使开发者能够充分利用异构计算环境的全部潜力。使用oneAPI，开发者可以编写一次代码，并在不同的硬件目标上部署，无需进行重大修改或重写。这种方法促进了代码的可重用性、生产力和性能可移植性，因为它抽象了异构计算的复杂性，并提供了一个基于开放标准的统一编程接口。'
- en: The core of suite is **Intel oneAPI Base Toolkit**, a set of tools and libraries
    for developing high-performance, data-centric applications across diverse architectures.
    It features an industry-leading C++ compiler that implements SYCL, an evolution
    of C++ for heterogeneous computing. It includes the **Collective Communications
    Library**, the **Data Analytics Library**, the **Deep Neural Networks Library**,
    the **DPC++/C++ Compiler**, the **DPC++ Library**, the **Math Kernel Library**,
    the **Threading Building Blocks**, debugging tool **Intel Distribution for GDB**,
    performance analysis tools **Intel Adviser** and **Intel Vtune Profiler**, the
    **Video Processing Library**, **Intel Distribution for Python**, the **DPC++ Compatibility
    Tool**, the **FPGA Add-on for oneAPI Base Toolkit**, the **Integrated Performance
    Primitives**. This can be complemented with additional toolkits. The **Intel oneAPI
    HPC Toolkit** contains **DPC++/C++ Compiler**, **Fortran** and **C++** Compiler
    Classic, debugging tools **Cluster Checker** and **Inspector**, **Intel MPI Library**,
    and performance analysis tool **Intel Trace Analyzer and Collector**.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Suite的核心是**Intel oneAPI Base Toolkit**，这是一套用于在多种架构上开发高性能、数据为中心的应用程序的工具和库。它包含业界领先的C++编译器，该编译器实现了SYCL，这是针对异构计算的C++的演变。它包括**集体通信库**、**数据分析库**、**深度神经网络库**、**DPC++/C++编译器**、**DPC++库**、**数学内核库**、**线程构建块**、调试工具**Intel
    Distribution for GDB**、性能分析工具**Intel Adviser**和**Intel Vtune Profiler**、**视频处理库**、**Intel
    Distribution for Python**、**DPC++兼容性工具**、**oneAPI Base Toolkit的FPGA附加组件**、**集成性能原语**。这可以补充额外的工具包。**Intel
    oneAPI HPC Toolkit**包含**DPC++/C++编译器**、**Fortran**和**C++**编译器经典、调试工具**Cluster
    Checker**和**Inspector**、**Intel MPI库**以及性能分析工具**Intel Trace Analyzer and Collector**。
- en: oneAPI supports multiple programming models and programming languages. It enables
    developers to write **OpenMP** codes targeting multi-core CPUs and Intel GPUs
    using the Classic Fortran and C++ compilers and as well **SYCL** programs for
    GPUs and FPGAs using the **DPC++** compiler. Initially, the **DPC++** compiler
    only targeted Intel GPUs using the **oneAPI Level Zero** low-level programming
    interface, but now support for NVIDIA GPUs (using CUDA) and AMD GPUs (using ROCm)
    has been added. Overall, Intel oneAPI offers a comprehensive and unified approach
    to heterogeneous computing, empowering developers to optimize and deploy applications
    across different architectures with ease. By abstracting the complexities and
    providing a consistent programming interface, oneAPI promotes code reusability,
    productivity, and performance portability, making it an invaluable toolkit for
    developers in the era of diverse computing platforms.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI支持多种编程模型和编程语言。它使开发者能够使用经典Fortran和C++编译器编写针对多核CPU和Intel GPU的**OpenMP**代码，以及使用**DPC++**编译器编写针对GPU和FPGA的**SYCL**程序。最初，**DPC++**编译器仅针对使用**oneAPI
    Level Zero**低级编程接口的Intel GPU，但现在已增加了对NVIDIA GPU（使用CUDA）和AMD GPU（使用ROCm）的支持。总体而言，Intel
    oneAPI提供了一种全面统一的异构计算方法，使开发者能够轻松地在不同架构上优化和部署应用程序。通过抽象复杂性和提供一致的编程接口，oneAPI促进了代码的可重用性、生产力和性能的可移植性，使其成为多样化计算平台时代开发者不可或缺的工具包。
- en: Differences and similarities
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差异与相似之处
- en: GPUs in general support different features, even among the same producer. In
    general newer cards come with extra features and sometimes old features are not
    supported anymore. It is important when compiling to create binaries targeting
    the specific architecture when compiling. A binary built for a newer card will
    not run on older devices, while a binary build for older devices might not run
    efficiently on newer architectures. In CUDA the compute capability which is targeted
    is specified by the `-arch=sm_XY`, where `X` specifies the major architecture
    and it is between 1 and 9, and `Y` the minor. When using HIP on NVIDIA platforms
    one needs to use compiling option `--gpu-architecture=sm_XY`, while on AMD platforms
    `--offload-arch=gfxabc` ( where `abc` is the architecture code such as `90a` for
    the MI200 series or `908` for MI100 series). Note that in the case of portable
    (single source) programs one would specify `openmp` as well as target for compilation,
    enabling to run the same code on multicore CPU.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，GPU支持不同的功能，即使在同一制造商之间也是如此。一般来说，新卡带有额外的功能，有时旧功能可能不再受支持。在编译时，创建针对特定架构的二进制文件很重要。为较新卡构建的二进制文件无法在较旧设备上运行，而为较旧设备构建的二进制文件可能在较新架构上运行效率不高。在CUDA中，目标计算能力由`-arch=sm_XY`指定，其中`X`指定主架构，介于1到9之间，而`Y`指定次架构。当在NVIDIA平台上使用HIP时，需要使用编译选项`--gpu-architecture=sm_XY`，而在AMD平台上使用`--offload-arch=gfxabc`（其中`abc`是架构代码，例如MI200系列的`90a`或MI100系列的`908`）。请注意，在可移植（单源）程序的情况下，还需要指定`openmp`以及编译目标，以便在多核CPU上运行相同的代码。
- en: Terminology
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 术语
- en: Hardware
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件
- en: '| NVIDIA | AMD | Intel |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | AMD | Intel |'
- en: '| --- | --- | --- |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Streaming processor/streaming core | SIMD lane | Processing element |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 流处理器/流核心 | SIMD通道 | 处理单元 |'
- en: '| SIMT unit | SIMD unit | Vector engine (XVE) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| SIMT单元 | SIMD单元 | 向量引擎（XVE） |'
- en: '| Streaming Multiprocessor (SM) | Computing Unit (CU) | Xe-core / Execution
    unit (EU) |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 流式多处理器（SM） | 计算单元（CU） | Xe-core / 执行单元（EU） |'
- en: '| GPU processing clusters (GPC) | Compute Engine | Xe-slice |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| GPU处理集群（GPC） | 计算引擎 | Xe-slice |'
- en: Please keep in mind, that this table is only a rough approximation. Each GPU
    architecture is different, and it’s impossible to make a 1-to-1 mapping between
    terms used by different vendors.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个表格只是一个粗略的近似。每个GPU架构都不同，不可能在不同供应商使用的术语之间进行一对一的映射。
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: GPUs are designed to execute thousands of threads simultaneously, making them
    highly parallel processors. In contrast, CPUs excel at executing a smaller number
    of threads in parallel.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU被设计为同时执行数千个线程，使其成为高度并行的处理器。相比之下，CPU擅长并行执行较少的线程。
- en: GPUs allocate a larger portion of transistors to data processing rather than
    data caching and flow control. This prioritization of data processing enables
    GPUs to effectively handle parallel computations and hide memory access latencies
    through computation.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU将更大的晶体管部分分配给数据处理，而不是数据缓存和流量控制。这种对数据处理的优先级使得GPU能够有效地处理并行计算，并通过计算隐藏内存访问延迟。
- en: GPU producers provide comprehensive toolkits, libraries, and compilers for developing
    high-performance applications that leverage the parallel processing power of GPUs.
    Examples include CUDA (NVIDIA), ROCm (AMD), and oneAPI (Intel).
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU制造商为开发利用GPU并行处理能力的应用程序提供全面的工具包、库和编译器。例如，CUDA（NVIDIA）、ROCm（AMD）和oneAPI（Intel）。
- en: These platforms offer debugging tools (e.g., `cuda-gdb`, `rocgdb`) and performance
    analysis tools (e.g., NVIDIA Nsight Systems, NVIDIA Nsight Compute, `rocprof`,
    `roctracer`) to facilitate code optimization and ensure efficient utilization
    of GPU resources.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些平台提供调试工具（例如，`cuda-gdb`、`rocgdb`）和性能分析工具（例如，NVIDIA Nsight Systems、NVIDIA Nsight
    Compute、`rocprof`、`roctracer`），以促进代码优化并确保高效利用GPU资源。
- en: Exercises
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: GPUs and memory
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: GPU和内存
- en: Which statement about the relationship between GPUs and memory is true?
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPU和内存之间关系的哪个说法是正确的？
- en: GPUs are not affected by memory access latencies.
  id: totrans-255
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU不受内存访问延迟的影响。
- en: GPUs can run out of memory quickly with many cores trying to access the memory
    simultaneously.
  id: totrans-256
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当许多核心同时尝试访问内存时，GPU可能会很快耗尽内存。
- en: GPUs have an unlimited cache size.
  id: totrans-257
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU具有无限的缓存大小。
- en: GPUs prefer to run with a minimal number of threads to manage memory effectively.
  id: totrans-258
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU更喜欢以最少的线程数量运行，以有效地管理内存。
- en: Solution
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The correct answer is B). This is true because GPUs run many threads simultaneously
    on thousands of cores, and with limited cache available, this can lead to the
    GPU running out of memory quickly if many cores are trying to access the memory
    simultaneously. This is why data management and access patterns are essential
    in GPU computing.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是B）。这是因为GPU在数千个核心上同时运行许多线程，并且由于可用的缓存有限，如果许多核心同时尝试访问内存，这可能导致GPU很快耗尽内存。这就是为什么数据管理和访问模式在GPU计算中至关重要。
- en: Keypoints
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs vs. CPUs, key differences between them
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU与CPU的比较，它们之间的关键区别
- en: GPU software suites, support specific GPU features, programming models, compatibility
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU软件套件，支持特定的GPU功能、编程模型、兼容性
- en: Applications of GPUs
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU的应用
- en: Overview of GPU hardware
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU硬件概述
- en: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/CPUAndGPU.png](../Images/5ce80b7df9d38eb82456fd4a1e1b295c.png)'
- en: A comparison of the CPU and GPU architecture. CPU (left) has complex core structure
    and pack several cores on a single chip. GPU cores are very simple in comparison,
    they also share data and control between each other. This allows to pack more
    cores on a single chip, thus achieving very high compute density.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和GPU架构的比较。CPU（左侧）具有复杂的内核结构，并在单个芯片上集成多个核心。相比之下，GPU核心非常简单，它们之间也共享数据和控制。这使得可以在单个芯片上集成更多核心，从而实现非常高的计算密度。
- en: In short
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之
- en: Accelerators offer high performance due to their scalability and high density
    of compute elements.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速器由于其可扩展性和计算元素的密集度，提供了高性能。
- en: They have separate circuit boards connected to CPUs via PCIe bus, with their
    own memory.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们有独立的电路板，通过PCIe总线连接到CPU，并拥有自己的内存。
- en: CPUs copy data from their own memory to the GPU memory, execute the program,
    and copy the results back.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU将数据从其自己的内存复制到GPU内存，执行程序，并将结果复制回来。
- en: GPUs run thousands of threads simultaneously, quickly switching between them
    to hide memory operations.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU可以同时运行数千个线程，快速地在它们之间切换，以隐藏内存操作。
- en: Effective data management and access pattern is critical on the GPU to avoid
    running out of memory.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上，有效的数据管理和访问模式是避免内存不足的关键。
- en: 'Accelerators are a separate main circuit board with the processor, memory,
    power management, etc. It is connected to the motherboard with CPUs via PCIe bus.
    Having its own memory means that the data has to be copied to and from it (not
    neceseraly true anymore). CPU acts as a main processor, controlling the execution
    workflow. It copies the data from its own memory to the GPU memory, executes the
    program and copies the results back. GPUs runs tens of thousands of threads simultaneously
    on thousands of cores and does not do much of the data management. With many cores
    trying to access the memory simultaneously and with little cache available, the
    accelerator can run out of memory very quickly. This makes the data management
    and its access pattern is essential on the GPU. Accelerators like to be overloaded
    with the number of threads, because they can switch between threads very quickly.
    This allows to hide the memory operations: while some threads wait, others can
    compute.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器是一个独立的主体电路板，包含处理器、内存、电源管理等。它通过PCIe总线连接到带有CPU的主板。拥有自己的内存意味着数据必须被复制到和从它那里（现在可能不再是这种情况）。CPU作为主处理器，控制执行工作流程。它将数据从其自己的内存复制到GPU内存，执行程序，并将结果复制回来。GPU在数千个核心上同时运行数万个线程，并且不进行太多的数据管理。由于许多核心同时尝试访问内存，并且可用的缓存很少，加速器可能会很快耗尽内存。这使得数据管理和其访问模式在GPU上变得至关重要。加速器喜欢被线程数量超载，因为它们可以非常快速地在线程之间切换。这允许隐藏内存操作：当一些线程等待时，其他线程可以进行计算。
- en: 'A very important feature of the accelerators is their scalability. Computational
    cores on accelerators are usually grouped into multiprocessors. The multiprocessors
    share the data and logical elements. This allows to achieve a very high density
    of compute elements on a GPU. This also allows the scaling: more multiprocessors
    means more raw performance and this is very easy to achieve with more transistors
    available.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器的一个非常重要的特性是其可扩展性。加速器上的计算核心通常被分组到多处理器中。多处理器共享数据和逻辑元素。这允许在GPU上实现非常高的计算元素密度。这也允许扩展：更多的多处理器意味着更多的原始性能，并且通过更多的晶体管很容易实现。
- en: How do GPUs differ from CPUs?
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU与CPU有何不同？
- en: CPUs and GPUs were designed with different goals in mind. While the CPU is designed
    to excel at executing a sequence of operations, called a thread, as fast as possible
    and can execute a few tens of these threads in parallel, the GPU is designed to
    excel at executing many thousands of them in parallel. GPUs were initially developed
    for highly-parallel task of graphic processing and therefore designed such that
    more transistors are devoted to data processing rather than data caching and flow
    control. More transistors dedicated to data processing is beneficial for highly
    parallel computations; the GPU can hide memory access latencies with computation,
    instead of relying on large data caches and complex flow control to avoid long
    memory access latencies, both of which are expensive in terms of transistors.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 和 GPU 是基于不同的目标设计的。虽然 CPU 设计用于尽可能快地执行一系列操作，称为线程，并且可以并行执行几十个这样的线程，但 GPU 设计用于并行执行成千上万的线程。GPU
    最初是为高度并行的图形处理任务开发的，因此设计时更注重数据处理而不是数据缓存和流控制。更多用于数据处理的晶体管对高度并行计算有益；GPU 可以通过计算来隐藏内存访问延迟，而不是依赖于大型数据缓存和复杂的流控制来避免长时间的内存访问延迟，这两者从晶体管的角度来看都是昂贵的。
- en: '| CPU | GPU |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| CPU | GPU |'
- en: '| --- | --- |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| General purpose | Highly specialized for parallelism |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 通用 | 高度专门化以支持并行处理 |'
- en: '| Good for serial processing | Good for parallel processing |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 适用于串行处理 | 适用于并行处理 |'
- en: '| Great for task parallelism | Great for data parallelism |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 适用于任务并行处理 | 适用于数据并行处理 |'
- en: '| Low latency per thread | High-throughput |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 每线程低延迟 | 高吞吐量 |'
- en: '| Large area dedicated cache and control | Hundreds of floating-point execution
    units |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 大面积专用缓存和控制 | 数百个浮点执行单元 |'
- en: GPU platforms
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 平台
- en: GPUs come together with software stacks or APIs that work in conjunction with
    the hardware and give a standard way for the software to interact with the GPU
    hardware. They are used by software developers to write code that can take advantage
    of the parallel processing power of the GPU, and they provide a standard way for
    software to interact with the GPU hardware. Typically, they provide access to
    low-level functionality, such as memory management, data transfer between the
    CPU and the GPU, and the scheduling and execution of parallel processing tasks
    on the GPU. They may also provide higher level functions and libraries optimized
    for specific HPC workloads, like linear algebra or fast Fourier transforms. Finally,
    in order to facilitate the developers to optimize and write correct codes, debugging
    and profiling tools are also included.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 与软件堆栈或 API 一起提供，这些 API 与硬件协同工作，为软件与 GPU 硬件交互提供标准方式。软件开发者使用这些 API 编写能够利用
    GPU 并行处理能力的代码，并为软件与 GPU 硬件交互提供标准方式。通常，它们提供对底层功能（如内存管理、CPU 和 GPU 之间的数据传输以及 GPU
    上并行处理任务的调度和执行）的访问。它们还可能提供针对特定 HPC 工作负载（如线性代数或快速傅里叶变换）优化的高级功能和库。最后，为了帮助开发者优化和编写正确的代码，还包含了调试和性能分析工具。
- en: '*NVIDIA*, *AMD*, and *Intel* are the major companies which design and produces
    GPUs for HPC providing each its own suite **CUDA**, **ROCm**, and respectively
    **oneAPI**. This way they can offer optimization, differentiation (offering unique
    features tailored to their devices), vendor lock-in, licensing, and royalty fees,
    which can result in better performance, profitability, and customer loyalty. There
    are also cross-platform APIs such **DirectCompute** (only for Windows operating
    system), **OpenCL**, and **SYCL**.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '*NVIDIA*、*AMD* 和 *Intel* 是设计并生产 HPC GPU 的主要公司，它们各自提供自己的套件 **CUDA**、**ROCm**
    和 **oneAPI**。这样，它们可以提供优化、差异化（提供针对其设备定制的独特功能）、供应商锁定、许可和版税费用，这些都可以带来更好的性能、盈利能力和客户忠诚度。还有跨平台
    API，如 **DirectCompute**（仅适用于 Windows 操作系统）、**OpenCL** 和 **SYCL**。'
- en: CUDA - In short
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA - 简而言之
- en: 'CUDA: NVIDIA’s parallel computing platform'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA：NVIDIA 的并行计算平台
- en: 'Components: CUDA Toolkit & CUDA driver'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件：CUDA 工具包 & CUDA 驱动程序
- en: Supports C, C++, and Fortran languages
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 C、C++ 和 Fortran 语言
- en: 'CUDA API Libraries: cuBLAS, cuFFT, cuRAND, cuSPARSE'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA API 库：cuBLAS, cuFFT, cuRAND, cuSPARSE
- en: Accelerate complex computations on GPUs
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 GPU 上加速复杂计算
- en: 'Compilers: nvcc, nvc, nvc++, nvfortran'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器：nvcc, nvc, nvc++, nvfortran
- en: Support GPU and multicore CPU programming
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 GPU 和多核 CPU 编程
- en: Compatible with OpenACC and OpenMP
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 兼容 OpenACC 和 OpenMP
- en: 'Debugging tools: cuda-gdb, compute-sanitizer'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试工具：cuda-gdb, compute-sanitizer
- en: Debug GPU and CPU code simultaneously
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时调试 GPU 和 CPU 代码
- en: Identify memory access issues
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别内存访问问题
- en: 'Performance analysis tools: NVIDIA Nsight Systems, NVIDIA Nsight Compute'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析工具：NVIDIA Nsight Systems、NVIDIA Nsight Compute
- en: Analyze system-wide and kernel-level performance
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析系统级和内核级性能
- en: Optimize CPU and GPU usage, memory bandwidth, instruction throughput
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化CPU和GPU的使用，内存带宽，指令吞吐量
- en: Comprehensive CUDA ecosystem with extensive tools and features
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的CUDA生态系统，具有广泛的功能和工具
- en: ROCm - In short
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm - 简而言之
- en: 'ROCm: Open software platform for AMD accelerators'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROCm：AMD加速器的开源软件平台
- en: Built for open portability across multiple vendors and architectures
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为跨多个供应商和架构的开放可移植性而构建
- en: Offers libraries, compilers, and development tools for AMD GPUs
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供AMD GPU的库、编译器和开发工具
- en: Supports C, C++, and Fortran languages
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持C、C++和Fortran语言
- en: Support GPU and multicore CPU programming
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持GPU和多核CPU编程
- en: 'Debugging: `roc-gdb` command line tool'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试：`roc-gdb`命令行工具
- en: Facilitates debugging of GPU programs
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 便于GPU程序的调试
- en: 'Performance analysis: `rocprof` and `roctracer` tools'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析：`rocprof`和`roctracer`工具
- en: Analyze and optimize program performance
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析和优化程序性能
- en: Supports various heterogeneous programming models such as **HIP**, **OpenMP**,
    and **OpenCL**
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持各种异构编程模型，如**HIP**、**OpenMP**和**OpenCL**
- en: Heterogeneous-Computing Interface for Portability (HIP)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异构计算接口（Heterogeneous-Computing Interface for Portability，简称HIP）
- en: Enables source portability for NVIDIA and AMD platforms, Intel in plan
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现了NVIDIA和AMD平台的源代码可移植性，英特尔计划中
- en: Provides `hipcc` compiler driver and runtime libraries
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了`hipcc`编译器驱动程序和运行时库
- en: 'Libraries: Prefixed with `roc` for AMD platforms'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库：以`roc`为前缀，适用于AMD平台
- en: Can be called directly from HIP
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可直接从HIP调用
- en: '`hip`-prefixed wrappers ensure portability with no performance cost'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hip`前缀的包装器确保了无性能成本的可移植性'
- en: oneAPI - In short
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI - 简而言之
- en: 'Intel oneAPI: Unified software toolkit for optimizing and deploying applications
    across various architectures'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI：跨各种架构优化和部署应用的统一软件工具包
- en: Supports CPUs, GPUs, and FPGAs
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 CPU、GPU和FPGA
- en: Enables code reusability and performance portability
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进了代码重用性和性能可移植性
- en: 'Intel oneAPI Base Toolkit: Core set of tools and libraries for high-performance,
    data-centric applications'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intel oneAPI基础工具包：高性能、数据为中心应用的核心工具和库集合
- en: Includes C++ compiler with SYCL support
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含支持SYCL的C++编译器
- en: Features Collective Communications Library, Data Analytics Library, Deep Neural
    Networks Library, and more
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特性包括集体通信库、数据分析库、深度神经网络库等
- en: 'Additional toolkits: Intel oneAPI HPC Toolkit'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他工具包：Intel oneAPI HPC工具包
- en: Contains compilers, debugging tools, MPI library, and performance analysis tool
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含编译器、调试工具、MPI库和性能分析工具
- en: 'Multiple programming models and languages supported:'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种编程模型和语言：
- en: OpenMP, Classic Fortran, C++, SYCL
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenMP、经典Fortran、C++、SYCL
- en: Unless custom Intel libraries are used, the code is portable to other OpenMP
    and SYCL frameworks
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非使用自定义英特尔库，否则代码可移植到其他OpenMP和SYCL框架
- en: 'DPC++ Compiler: Supports Intel, NVIDIA, and AMD GPUs'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DPC++ 编译器：支持英特尔、NVIDIA和AMD GPU
- en: Targets Intel GPUs using oneAPI Level Zero interface
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用oneAPI Level Zero接口针对英特尔GPU
- en: Added support for NVIDIA GPUs with CUDA and AMD GPUs with ROCm
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加了支持CUDA的NVIDIA GPU和ROCm的AMD GPU
- en: 'Debugging and performance analysis tools: Intel Adviser, Intel Vtune Profiler,
    Cluster Checker, Inspector, Intel Trace Analyzer and Collector, Intel Distribution
    for GDB'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试和性能分析工具：英特尔顾问（Intel Adviser）、英特尔Vtune分析器（Intel Vtune Profiler）、集群检查器（Cluster
    Checker）、检查器（Inspector）、英特尔跟踪分析器和收集器（Intel Trace Analyzer and Collector）、英特尔GDB分发版（Intel
    Distribution for GDB）
- en: Comprehensive and unified approach to heterogeneous computing
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合统一的异构计算方法
- en: Abstracts complexities and provides consistent programming interface
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象复杂性并提供一致的编程接口
- en: Promotes code reusability, productivity, and performance portability
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进代码重用性、生产力和性能可移植性
- en: CUDA
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUDA
- en: '**Compute Unified Device Architecture** is the parallel computing platform
    from NVIDIA. The CUDA API provides a comprehensive set of functions and tools
    for developing high-performance applications that run on NVIDIA GPUs. It consists
    of two main components: the CUDA Toolkit and the CUDA driver. The toolkit provides
    a set of libraries, compilers, and development tools for programming and optimizing
    CUDA applications, while the driver is responsible for communication between the
    host CPU and the device GPU. CUDA is designed to work with programming languages
    such as C, C++, and Fortran.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '**Compute Unified Device Architecture** 是 NVIDIA 的并行计算平台。CUDA API 为开发在 NVIDIA
    GPU 上运行的高性能应用程序提供了一套全面的函数和工具。它由两个主要组件组成：CUDA 工具包和 CUDA 驱动程序。工具包提供了一套库、编译器和开发工具，用于编程和优化
    CUDA 应用程序，而驱动程序负责主机 CPU 和设备 GPU 之间的通信。CUDA 设计用于与 C、C++ 和 Fortran 等编程语言一起工作。'
- en: 'CUDA API provides many highly optimize libraries such as: **cuBLAS** (for linear
    algebra operations, such a dense matrix multiplication), **cuFFT** (for performing
    fast Fourier transforms), **cuRAND** (for generating pseudo-random numbers), **cuSPARSE**
    (for sparse matrices operations). Using these libraries, developers can quickly
    and easily accelerate complex computations on NVIDIA GPUs without having to write
    low-level GPU code themselves.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA API 提供了许多高度优化的库，例如：**cuBLAS**（用于线性代数运算，例如密集矩阵乘法）、**cuFFT**（用于执行快速傅里叶变换）、**cuRAND**（用于生成伪随机数）、**cuSPARSE**（用于稀疏矩阵运算）。使用这些库，开发者可以快速轻松地加速在
    NVIDIA GPU 上进行的复杂计算，而无需自己编写底层 GPU 代码。
- en: 'There are several compilers that can be used for developing and executing code
    on NVIDIA GPUs: **nvcc**. The latest versions are based on the widely used LLVM
    (low level virtual machine) open source compiler infrastructure. nvcc produces
    optimized code for NVIDIA GPUs and drives a supported host compiler for AMD, Intel,
    OpenPOWER, and Arm CPUs.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种编译器可用于在 NVIDIA GPU 上开发和执行代码：**nvcc**。最新版本基于广泛使用的 LLVM（低级虚拟机）开源编译器基础设施。nvcc
    为 NVIDIA GPU 生成优化代码，并驱动支持 AMD、Intel、OpenPOWER 和 Arm CPU 的主机编译器。
- en: In addition to this are provided **nvc** (C11 compiler), **nvc++** (C++17 compiler),
    and **nvfortran** (ISO Fortran 2003 compiler). These compilers can as well create
    code for execution on the NVIDIA GPUs, and also support GPU and multicore CPU
    programming with parallel language features, OpeanACC and OpenMP.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提供了 **nvc**（C11 编译器）、**nvc++**（C++17 编译器）和 **nvfortran**（ISO Fortran 2003
    编译器）。这些编译器同样可以创建在 NVIDIA GPU 上执行的代码，并支持使用并行语言功能 OpenACC 和 OpenMP 进行 GPU 和多核 CPU
    编程。
- en: When programming mistakes are inevitable they have to be fixed as soon as possible.
    The CUDA toolkit includes the command line tool **cuda-gdb** which can be used
    to find errors in the code. It is an extension to GDB, the GNU Project debugger.
    The existing GDB debugging features are inherently present for debugging the host
    code, and additional features have been provided to support debugging CUDA device
    code, allowing simultaneous debugging of both GPU and CPU code within the same
    application. The tool provides developers with a mechanism for debugging CUDA
    applications running on actual hardware. This enables developers to debug applications
    without the potential variations introduced by simulation and emulation environments.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 当编程错误不可避免时，它们必须尽快修复。CUDA 工具包包括命令行工具 **cuda-gdb**，可用于查找代码中的错误。它是 GNU 项目调试器 GDB
    的扩展。现有的 GDB 调试功能本身适用于调试主机代码，并提供了额外的功能以支持调试 CUDA 设备代码，允许在同一应用程序中同时调试 GPU 和 CPU
    代码。该工具为开发者提供了一种调试在真实硬件上运行的 CUDA 应用程序的方法。这使得开发者能够在没有模拟和仿真环境引入的潜在变化的情况下调试应用程序。
- en: 'In addition to this the command line tool **compute-sanitizer** can be used
    to look exclusively for memory access problems: unallocated buffers, out of bounds
    accesses, race conditions, and uninitialized variables.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，命令行工具 **compute-sanitizer** 可以用于专门查找内存访问问题：未分配的缓冲区、越界访问、竞态条件和未初始化的变量。
- en: Finally, in order to utilize the GPUs at maximum some performance analysis tools.
    NVIDIA provides NVIDIA Nsight Systems and NVIDIA Nsight Compute tools for helping
    the developers to optimize their applications. The former, NVIDIA Nsight Systems,
    is a system-wide performance analysis tool that provides detailed metrics on both
    CPU and GPU usage, memory bandwidth, and other system-level metrics. The latter,
    NVIDIA Nsight Compute, is a kernel-level performance analysis tool that allows
    developers to analyze the performance of individual CUDA kernels. It provides
    detailed metrics on kernel execution, including memory usage, instruction throughput,
    and occupancy. These tools have graphical which can be used for all steps of the
    performance analysis, however on supercomputers it is recommended to use the command
    line interface for collecting the information needed and then visualize and analyse
    the results using the graphical interface on personal computers.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了最大限度地利用GPU，需要一些性能分析工具。NVIDIA提供了NVIDIA Nsight Systems和NVIDIA Nsight Compute工具，以帮助开发者优化他们的应用程序。前者，NVIDIA
    Nsight Systems，是一个系统级性能分析工具，提供了关于CPU和GPU使用、内存带宽以及其他系统级指标的详细指标。后者，NVIDIA Nsight
    Compute，是一个内核级性能分析工具，允许开发者分析单个CUDA内核的性能。它提供了关于内核执行的详细指标，包括内存使用、指令吞吐量和占用率。这些工具具有图形界面，可用于性能分析的各个步骤，然而在超级计算机上，建议使用命令行界面来收集所需的信息，然后使用个人计算机上的图形界面可视化和分析结果。
- en: Apart from what was presented above there are many others tools and features
    provided by NVIDIA. The CUDA ecosystem is very well developed.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述内容之外，NVIDIA还提供了许多其他工具和功能。CUDA生态系统非常完善。
- en: ROCm
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROCm
- en: ROCm is an open software platform allowing researchers to tap the power of AMD
    accelerators. The ROCm platform is built on the foundation of open portability,
    supporting environments across multiple accelerator vendors and architectures.
    In some way it is very similar to CUDA API. It contains libraries, compilers,
    and development tools for programming and optimizing programs for AMD GPUs. For
    debugging, it provides the command line tool `rocgdb`, while for performance analysis
    `rocprof` and `roctracer`. In order to produce code for the AMD GPUs, one can
    use the Heterogeneous-Computing Interface for Portability (HIP). HIP is a C++
    runtime API and a set of tools that allows developers to write portable GPU-accelerated
    code for both NVIDIA and AMD platforms. It provides the `hipcc` compiler driver,
    which will call the appropriate toolchain depending on the desired platform. On
    the AMD ROCm platform, HIP provides a header and runtime library built on top
    of the HIP-Clang (ROCm compiler). On an NVIDIA platform, HIP provides a header
    file which translates from the HIP runtime APIs to CUDA runtime APIs. The header
    file contains mostly inlined functions and thus has very low overhead. The code
    is then compiled with `nvcc`, the standard C++ compiler provided with CUDA. On
    AMD platforms, libraries are prefixed by `roc`, which can be called directly from
    HIP. In order to make portable calls, one can call the libraries using `hip`-prefixed
    wrappers. These wrappers can be used at no performance cost and ensure that HIP
    code can be used on other platforms with no changes. Libraries included in the
    ROCm, are almost one-to-one equivalent to the ones supplied with CUDA.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm是一个开放软件平台，允许研究人员利用AMD加速器的强大功能。ROCm平台建立在开放可移植性的基础上，支持多个加速器供应商和架构的环境。在某种程度上，它与CUDA
    API非常相似。它包含用于为AMD GPU编程和优化的库、编译器和开发工具。为了调试，它提供了命令行工具`rocgdb`，而为了性能分析，提供了`rocprof`和`roctracer`。为了生成AMD
    GPU的代码，可以使用异构计算接口（HIP）。HIP是一个C++运行时API和一系列工具，允许开发者为NVIDIA和AMD平台编写可移植的GPU加速代码。它提供了`hipcc`编译器驱动程序，该驱动程序将根据所需的平台调用适当的工具链。在AMD
    ROCm平台上，HIP提供基于HIP-Clang（ROCm编译器）的标头和运行时库。在NVIDIA平台上，HIP提供将HIP运行时API转换为CUDA运行时API的标头文件。该头文件主要包含内联函数，因此开销非常低。然后使用`nvcc`编译器，这是CUDA提供的标准C++编译器，进行编译。在AMD平台上，库以`roc`为前缀，可以直接从HIP调用。为了进行可移植调用，可以使用以`hip`为前缀的包装器。这些包装器可以在不牺牲性能的情况下使用，并确保HIP代码可以在其他平台上使用而无需更改。ROCm中包含的库几乎与CUDA提供的库一一对应。
- en: ROCm also integrates with popular machine learning frameworks such as TensorFlow
    and PyTorch and provides optimized libraries and drivers to accelerate machine
    learning workloads on AMD GPUs enabling the researchers to leverage the power
    of ROCm and AMD accelerators to train and deploy machine learning models efficiently.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm还集成了流行的机器学习框架，如TensorFlow和PyTorch，并为AMD GPU上的机器学习工作负载提供优化的库和驱动程序，使研究人员能够有效地利用ROCm和AMD加速器的力量来训练和部署机器学习模型。
- en: oneAPI
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: oneAPI
- en: '**Intel oneAPI** is a unified software toolkit developed by Intel that allows
    developers to optimize and deploy applications across a variety of architectures,
    including CPUs, GPUs, and FPGAs. It provides a comprehensive set of tools, libraries,
    and frameworks, enabling developers to leverage the full potential of heterogeneous
    computing environments. With oneAPI, the developers can write code once and deploy
    it across different hardware targets without the need for significant modifications
    or rewriting. This approach promotes code reusability, productivity, and performance
    portability, as it abstracts the complexities of heterogeneous computing and provides
    a consistent programming interface based on open standards.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '**Intel oneAPI**是由Intel开发的一个统一的软件工具包，它允许开发者在包括CPU、GPU和FPGA在内的各种架构上优化和部署应用程序。它提供了一套全面的工具、库和框架，使开发者能够充分利用异构计算环境的全部潜力。使用oneAPI，开发者可以编写一次代码，并在不同的硬件目标上部署，无需进行重大修改或重写。这种方法促进了代码的可重用性、生产力和性能的可移植性，因为它抽象了异构计算的复杂性，并提供了一个基于开放标准的统一编程接口。'
- en: The core of suite is **Intel oneAPI Base Toolkit**, a set of tools and libraries
    for developing high-performance, data-centric applications across diverse architectures.
    It features an industry-leading C++ compiler that implements SYCL, an evolution
    of C++ for heterogeneous computing. It includes the **Collective Communications
    Library**, the **Data Analytics Library**, the **Deep Neural Networks Library**,
    the **DPC++/C++ Compiler**, the **DPC++ Library**, the **Math Kernel Library**,
    the **Threading Building Blocks**, debugging tool **Intel Distribution for GDB**,
    performance analysis tools **Intel Adviser** and **Intel Vtune Profiler**, the
    **Video Processing Library**, **Intel Distribution for Python**, the **DPC++ Compatibility
    Tool**, the **FPGA Add-on for oneAPI Base Toolkit**, the **Integrated Performance
    Primitives**. This can be complemented with additional toolkits. The **Intel oneAPI
    HPC Toolkit** contains **DPC++/C++ Compiler**, **Fortran** and **C++** Compiler
    Classic, debugging tools **Cluster Checker** and **Inspector**, **Intel MPI Library**,
    and performance analysis tool **Intel Trace Analyzer and Collector**.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: Suite的核心是**Intel oneAPI Base Toolkit**，这是一套用于在多种架构上开发高性能、以数据为中心的应用程序的工具和库。它包含业界领先的C++编译器，该编译器实现了SYCL，这是针对异构计算的C++的演变。它包括**集体通信库**、**数据分析库**、**深度神经网络库**、**DPC++/C++编译器**、**DPC++库**、**数学内核库**、**线程构建块**、调试工具**Intel
    Distribution for GDB**、性能分析工具**Intel Adviser**和**Intel Vtune Profiler**、**视频处理库**、**Intel
    Distribution for Python**、**DPC++兼容性工具**、**oneAPI Base Toolkit的FPGA附加组件**、**集成性能原语**。这可以补充额外的工具包。**Intel
    oneAPI HPC Toolkit**包含**DPC++/C++编译器**、**Fortran**和**C++**编译器经典、调试工具**Cluster
    Checker**和**Inspector**、**Intel MPI库**以及性能分析工具**Intel Trace Analyzer and Collector**。
- en: oneAPI supports multiple programming models and programming languages. It enables
    developers to write **OpenMP** codes targeting multi-core CPUs and Intel GPUs
    using the Classic Fortran and C++ compilers and as well **SYCL** programs for
    GPUs and FPGAs using the **DPC++** compiler. Initially, the **DPC++** compiler
    only targeted Intel GPUs using the **oneAPI Level Zero** low-level programming
    interface, but now support for NVIDIA GPUs (using CUDA) and AMD GPUs (using ROCm)
    has been added. Overall, Intel oneAPI offers a comprehensive and unified approach
    to heterogeneous computing, empowering developers to optimize and deploy applications
    across different architectures with ease. By abstracting the complexities and
    providing a consistent programming interface, oneAPI promotes code reusability,
    productivity, and performance portability, making it an invaluable toolkit for
    developers in the era of diverse computing platforms.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI支持多种编程模型和编程语言。它使开发者能够使用经典Fortran和C++编译器编写针对多核CPU和英特尔GPU的**OpenMP**代码，以及使用**DPC++**编译器为GPU和FPGA编写**SYCL**程序。最初，**DPC++**编译器仅针对使用**oneAPI
    Level Zero**低级编程接口的英特尔GPU，但现在已增加了对NVIDIA GPU（使用CUDA）和AMD GPU（使用ROCm）的支持。总体而言，英特尔oneAPI提供了一种全面且统一的异构计算方法，使开发者能够轻松地在不同架构上优化和部署应用程序。通过抽象复杂性和提供一致的编程接口，oneAPI促进了代码的可重用性、生产力和性能可移植性，使其成为多元计算平台时代开发者不可或缺的工具包。
- en: Differences and similarities
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差异和相似之处
- en: GPUs in general support different features, even among the same producer. In
    general newer cards come with extra features and sometimes old features are not
    supported anymore. It is important when compiling to create binaries targeting
    the specific architecture when compiling. A binary built for a newer card will
    not run on older devices, while a binary build for older devices might not run
    efficiently on newer architectures. In CUDA the compute capability which is targeted
    is specified by the `-arch=sm_XY`, where `X` specifies the major architecture
    and it is between 1 and 9, and `Y` the minor. When using HIP on NVIDIA platforms
    one needs to use compiling option `--gpu-architecture=sm_XY`, while on AMD platforms
    `--offload-arch=gfxabc` ( where `abc` is the architecture code such as `90a` for
    the MI200 series or `908` for MI100 series). Note that in the case of portable
    (single source) programs one would specify `openmp` as well as target for compilation,
    enabling to run the same code on multicore CPU.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，GPU支持不同的功能，即使在同一制造商之间也是如此。通常，新卡会带有额外的功能，有时旧功能可能不再受支持。在编译时，创建针对特定架构的二进制文件很重要。为较新卡构建的二进制文件无法在较旧设备上运行，而为较旧设备构建的二进制文件可能在较新架构上运行效率不高。在CUDA中，目标计算能力由`-arch=sm_XY`指定，其中`X`指定主架构，介于1到9之间，而`Y`指定次架构。当在NVIDIA平台上使用HIP时，需要使用编译选项`--gpu-architecture=sm_XY`，而在AMD平台上使用`--offload-arch=gfxabc`（其中`abc`是架构代码，例如MI200系列的`90a`或MI100系列的`908`）。请注意，在可移植（单源）程序的情况下，还需要指定`openmp`以及编译目标，以便能够在多核CPU上运行相同的代码。
- en: Terminology
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 术语
- en: Hardware
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件
- en: '| NVIDIA | AMD | Intel |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | AMD | Intel |'
- en: '| --- | --- | --- |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Streaming processor/streaming core | SIMD lane | Processing element |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 流式处理器/流式核心 | SIMD通道 | 处理器 |'
- en: '| SIMT unit | SIMD unit | Vector engine (XVE) |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| SIMT单元 | SIMD单元 | 向量引擎（XVE） |'
- en: '| Streaming Multiprocessor (SM) | Computing Unit (CU) | Xe-core / Execution
    unit (EU) |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 流式多处理器（SM） | 计算单元（CU） | Xe核心/执行单元（EU） |'
- en: '| GPU processing clusters (GPC) | Compute Engine | Xe-slice |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| GPU处理集群（GPC） | 计算引擎 | Xe切片 |'
- en: Please keep in mind, that this table is only a rough approximation. Each GPU
    architecture is different, and it’s impossible to make a 1-to-1 mapping between
    terms used by different vendors.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个表格只是一个粗略的近似。每个GPU架构都是不同的，不可能在不同供应商使用的术语之间进行一对一的映射。
- en: CUDA
  id: totrans-367
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUDA
- en: '**Compute Unified Device Architecture** is the parallel computing platform
    from NVIDIA. The CUDA API provides a comprehensive set of functions and tools
    for developing high-performance applications that run on NVIDIA GPUs. It consists
    of two main components: the CUDA Toolkit and the CUDA driver. The toolkit provides
    a set of libraries, compilers, and development tools for programming and optimizing
    CUDA applications, while the driver is responsible for communication between the
    host CPU and the device GPU. CUDA is designed to work with programming languages
    such as C, C++, and Fortran.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '**统一计算设备架构**是来自NVIDIA的并行计算平台。CUDA API提供了一套全面的函数和工具，用于开发在NVIDIA GPU上运行的高性能应用程序。它由两个主要组件组成：CUDA工具包和CUDA驱动程序。工具包提供了一套库、编译器和开发工具，用于编程和优化CUDA应用程序，而驱动程序负责主机CPU和设备GPU之间的通信。CUDA旨在与编程语言如C、C++和Fortran一起工作。'
- en: 'CUDA API provides many highly optimize libraries such as: **cuBLAS** (for linear
    algebra operations, such a dense matrix multiplication), **cuFFT** (for performing
    fast Fourier transforms), **cuRAND** (for generating pseudo-random numbers), **cuSPARSE**
    (for sparse matrices operations). Using these libraries, developers can quickly
    and easily accelerate complex computations on NVIDIA GPUs without having to write
    low-level GPU code themselves.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA API提供了许多高度优化的库，例如：**cuBLAS**（用于线性代数运算，如稠密矩阵乘法）、**cuFFT**（用于执行快速傅里叶变换）、**cuRAND**（用于生成伪随机数）、**cuSPARSE**（用于稀疏矩阵运算）。使用这些库，开发者可以快速轻松地加速在NVIDIA
    GPU上的复杂计算，而无需自己编写低级GPU代码。
- en: 'There are several compilers that can be used for developing and executing code
    on NVIDIA GPUs: **nvcc**. The latest versions are based on the widely used LLVM
    (low level virtual machine) open source compiler infrastructure. nvcc produces
    optimized code for NVIDIA GPUs and drives a supported host compiler for AMD, Intel,
    OpenPOWER, and Arm CPUs.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种编译器可用于在NVIDIA GPU上开发和执行代码：**nvcc**。最新版本基于广泛使用的LLVM（低级虚拟机）开源编译器基础设施。nvcc为NVIDIA
    GPU生成优化代码，并驱动支持AMD、Intel、OpenPOWER和Arm CPU的主机编译器。
- en: In addition to this are provided **nvc** (C11 compiler), **nvc++** (C++17 compiler),
    and **nvfortran** (ISO Fortran 2003 compiler). These compilers can as well create
    code for execution on the NVIDIA GPUs, and also support GPU and multicore CPU
    programming with parallel language features, OpeanACC and OpenMP.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还提供了**nvc**（C11编译器）、**nvc++**（C++17编译器）和**nvfortran**（ISO Fortran 2003编译器）。这些编译器同样可以创建在NVIDIA
    GPU上执行的代码，并支持使用并行语言特性（如OpenACC和OpenMP）进行GPU和多核CPU编程。
- en: When programming mistakes are inevitable they have to be fixed as soon as possible.
    The CUDA toolkit includes the command line tool **cuda-gdb** which can be used
    to find errors in the code. It is an extension to GDB, the GNU Project debugger.
    The existing GDB debugging features are inherently present for debugging the host
    code, and additional features have been provided to support debugging CUDA device
    code, allowing simultaneous debugging of both GPU and CPU code within the same
    application. The tool provides developers with a mechanism for debugging CUDA
    applications running on actual hardware. This enables developers to debug applications
    without the potential variations introduced by simulation and emulation environments.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 当编程错误不可避免时，它们必须尽快修复。CUDA工具包包括命令行工具**cuda-gdb**，可用于查找代码中的错误。它是GNU项目调试器GDB的扩展。现有的GDB调试功能本身适用于调试主机代码，并提供了额外的功能以支持调试CUDA设备代码，允许在同一应用程序中同时调试GPU和CPU代码。该工具为开发者提供了一种调试在真实硬件上运行的CUDA应用程序的机制。这使得开发者能够在没有模拟和仿真环境引入的潜在变化的情况下调试应用程序。
- en: 'In addition to this the command line tool **compute-sanitizer** can be used
    to look exclusively for memory access problems: unallocated buffers, out of bounds
    accesses, race conditions, and uninitialized variables.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以使用命令行工具**compute-sanitizer**专门查找内存访问问题：未分配的缓冲区、越界访问、竞态条件和未初始化的变量。
- en: Finally, in order to utilize the GPUs at maximum some performance analysis tools.
    NVIDIA provides NVIDIA Nsight Systems and NVIDIA Nsight Compute tools for helping
    the developers to optimize their applications. The former, NVIDIA Nsight Systems,
    is a system-wide performance analysis tool that provides detailed metrics on both
    CPU and GPU usage, memory bandwidth, and other system-level metrics. The latter,
    NVIDIA Nsight Compute, is a kernel-level performance analysis tool that allows
    developers to analyze the performance of individual CUDA kernels. It provides
    detailed metrics on kernel execution, including memory usage, instruction throughput,
    and occupancy. These tools have graphical which can be used for all steps of the
    performance analysis, however on supercomputers it is recommended to use the command
    line interface for collecting the information needed and then visualize and analyse
    the results using the graphical interface on personal computers.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了最大限度地利用GPU，需要一些性能分析工具。NVIDIA提供了NVIDIA Nsight Systems和NVIDIA Nsight Compute工具，以帮助开发者优化他们的应用程序。前者，NVIDIA
    Nsight Systems，是一个系统级性能分析工具，提供了关于CPU和GPU使用、内存带宽和其他系统级指标的详细指标。后者，NVIDIA Nsight
    Compute，是一个内核级性能分析工具，允许开发者分析单个CUDA内核的性能。它提供了关于内核执行的详细指标，包括内存使用、指令吞吐量和占用率。这些工具具有图形界面，可用于性能分析的各个步骤，然而在超级计算机上，建议使用命令行界面来收集所需的信息，然后使用个人计算机上的图形界面可视化和分析结果。
- en: Apart from what was presented above there are many others tools and features
    provided by NVIDIA. The CUDA ecosystem is very well developed.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上面提到的工具和功能外，NVIDIA还提供了许多其他工具。CUDA生态系统非常完善。
- en: ROCm
  id: totrans-376
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROCm
- en: ROCm is an open software platform allowing researchers to tap the power of AMD
    accelerators. The ROCm platform is built on the foundation of open portability,
    supporting environments across multiple accelerator vendors and architectures.
    In some way it is very similar to CUDA API. It contains libraries, compilers,
    and development tools for programming and optimizing programs for AMD GPUs. For
    debugging, it provides the command line tool `rocgdb`, while for performance analysis
    `rocprof` and `roctracer`. In order to produce code for the AMD GPUs, one can
    use the Heterogeneous-Computing Interface for Portability (HIP). HIP is a C++
    runtime API and a set of tools that allows developers to write portable GPU-accelerated
    code for both NVIDIA and AMD platforms. It provides the `hipcc` compiler driver,
    which will call the appropriate toolchain depending on the desired platform. On
    the AMD ROCm platform, HIP provides a header and runtime library built on top
    of the HIP-Clang (ROCm compiler). On an NVIDIA platform, HIP provides a header
    file which translates from the HIP runtime APIs to CUDA runtime APIs. The header
    file contains mostly inlined functions and thus has very low overhead. The code
    is then compiled with `nvcc`, the standard C++ compiler provided with CUDA. On
    AMD platforms, libraries are prefixed by `roc`, which can be called directly from
    HIP. In order to make portable calls, one can call the libraries using `hip`-prefixed
    wrappers. These wrappers can be used at no performance cost and ensure that HIP
    code can be used on other platforms with no changes. Libraries included in the
    ROCm, are almost one-to-one equivalent to the ones supplied with CUDA.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm是一个开源软件平台，允许研究人员利用AMD加速器的强大功能。ROCm平台建立在开放可移植性的基础上，支持多个加速器和架构的环境。在某种程度上，它与CUDA
    API非常相似。它包含用于为AMD GPU编程和优化的库、编译器和开发工具。对于调试，它提供了命令行工具`rocgdb`，而对于性能分析，则提供了`rocprof`和`roctracer`。为了生成AMD
    GPU的代码，可以使用异构计算接口（HIP）。HIP是一个C++运行时API和一系列工具，允许开发者编写适用于NVIDIA和AMD平台的可移植GPU加速代码。它提供了`hipcc`编译器驱动程序，该驱动程序将根据所需的平台调用适当的工具链。在AMD
    ROCm平台上，HIP提供基于HIP-Clang（ROCm编译器）的标头和运行时库。在NVIDIA平台上，HIP提供将HIP运行时API转换为CUDA运行时API的标头文件。该头文件主要包含内联函数，因此开销非常低。然后使用`nvcc`编译器（CUDA提供的标准C++编译器）编译代码。在AMD平台上，库以`roc`为前缀，可以直接从HIP调用。为了进行可移植调用，可以使用以`hip`为前缀的包装器。这些包装器不会产生性能成本，并确保HIP代码可以在其他平台上使用而无需更改。ROCm中包含的库几乎与CUDA提供的库一一对应。
- en: ROCm also integrates with popular machine learning frameworks such as TensorFlow
    and PyTorch and provides optimized libraries and drivers to accelerate machine
    learning workloads on AMD GPUs enabling the researchers to leverage the power
    of ROCm and AMD accelerators to train and deploy machine learning models efficiently.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: ROCm还集成了流行的机器学习框架，如TensorFlow和PyTorch，并提供优化的库和驱动程序，以加速在AMD GPU上运行的机器学习工作负载，使研究人员能够有效地利用ROCm和AMD加速器的力量来训练和部署机器学习模型。
- en: oneAPI
  id: totrans-379
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: oneAPI
- en: '**Intel oneAPI** is a unified software toolkit developed by Intel that allows
    developers to optimize and deploy applications across a variety of architectures,
    including CPUs, GPUs, and FPGAs. It provides a comprehensive set of tools, libraries,
    and frameworks, enabling developers to leverage the full potential of heterogeneous
    computing environments. With oneAPI, the developers can write code once and deploy
    it across different hardware targets without the need for significant modifications
    or rewriting. This approach promotes code reusability, productivity, and performance
    portability, as it abstracts the complexities of heterogeneous computing and provides
    a consistent programming interface based on open standards.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '**Intel oneAPI**是由英特尔开发的一个统一的软件工具包，允许开发者优化和部署跨多种架构（包括CPU、GPU和FPGA）的应用程序。它提供了一套全面的工具、库和框架，使开发者能够充分利用异构计算环境的全部潜力。使用oneAPI，开发者可以编写一次代码，并在不同的硬件目标上部署，无需进行重大修改或重写。这种方法促进了代码的可重用性、生产力和性能的可移植性，因为它抽象了异构计算的复杂性，并基于开放标准提供了一个一致的编程接口。'
- en: The core of suite is **Intel oneAPI Base Toolkit**, a set of tools and libraries
    for developing high-performance, data-centric applications across diverse architectures.
    It features an industry-leading C++ compiler that implements SYCL, an evolution
    of C++ for heterogeneous computing. It includes the **Collective Communications
    Library**, the **Data Analytics Library**, the **Deep Neural Networks Library**,
    the **DPC++/C++ Compiler**, the **DPC++ Library**, the **Math Kernel Library**,
    the **Threading Building Blocks**, debugging tool **Intel Distribution for GDB**,
    performance analysis tools **Intel Adviser** and **Intel Vtune Profiler**, the
    **Video Processing Library**, **Intel Distribution for Python**, the **DPC++ Compatibility
    Tool**, the **FPGA Add-on for oneAPI Base Toolkit**, the **Integrated Performance
    Primitives**. This can be complemented with additional toolkits. The **Intel oneAPI
    HPC Toolkit** contains **DPC++/C++ Compiler**, **Fortran** and **C++** Compiler
    Classic, debugging tools **Cluster Checker** and **Inspector**, **Intel MPI Library**,
    and performance analysis tool **Intel Trace Analyzer and Collector**.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 该套件的核心是**Intel oneAPI Base Toolkit**，一套用于在多种架构上开发高性能、数据为中心的应用程序的工具和库。它包含业界领先的C++编译器，实现了C++的异构计算进化版SYCL。它包括**集体通信库**、**数据分析库**、**深度神经网络库**、**DPC++/C++编译器**、**DPC++库**、**数学内核库**、**线程构建块**、调试工具**Intel
    Distribution for GDB**、性能分析工具**Intel Adviser**和**Intel Vtune Profiler**、**视频处理库**、**Intel
    Distribution for Python**、**DPC++兼容性工具**、**oneAPI Base Toolkit的FPGA附加组件**、**集成性能原语**。这可以补充额外的工具包。**Intel
    oneAPI HPC Toolkit**包含**DPC++/C++编译器**、**Fortran**和**C++**编译器经典版、调试工具**Cluster
    Checker**和**Inspector**、**Intel MPI库**以及性能分析工具**Intel Trace Analyzer and Collector**。
- en: oneAPI supports multiple programming models and programming languages. It enables
    developers to write **OpenMP** codes targeting multi-core CPUs and Intel GPUs
    using the Classic Fortran and C++ compilers and as well **SYCL** programs for
    GPUs and FPGAs using the **DPC++** compiler. Initially, the **DPC++** compiler
    only targeted Intel GPUs using the **oneAPI Level Zero** low-level programming
    interface, but now support for NVIDIA GPUs (using CUDA) and AMD GPUs (using ROCm)
    has been added. Overall, Intel oneAPI offers a comprehensive and unified approach
    to heterogeneous computing, empowering developers to optimize and deploy applications
    across different architectures with ease. By abstracting the complexities and
    providing a consistent programming interface, oneAPI promotes code reusability,
    productivity, and performance portability, making it an invaluable toolkit for
    developers in the era of diverse computing platforms.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: oneAPI支持多种编程模型和编程语言。它使开发者能够使用经典Fortran和C++编译器编写针对多核CPU和Intel GPU的**OpenMP**代码，以及使用**DPC++**编译器为GPU和FPGA编写**SYCL**程序。最初，**DPC++**编译器仅针对使用**oneAPI
    Level Zero**低级编程接口的Intel GPU，但现在已添加了对NVIDIA GPU（使用CUDA）和AMD GPU（使用ROCm）的支持。总体而言，Intel
    oneAPI提供了一种全面统一的异构计算方法，使开发者能够轻松优化和部署跨不同架构的应用程序。通过抽象复杂性和提供一致的编程接口，oneAPI促进了代码的可重用性、生产力和性能的可移植性，使其成为多元计算平台时代开发者不可或缺的工具包。
- en: Differences and similarities
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差异和相似之处
- en: GPUs in general support different features, even among the same producer. In
    general newer cards come with extra features and sometimes old features are not
    supported anymore. It is important when compiling to create binaries targeting
    the specific architecture when compiling. A binary built for a newer card will
    not run on older devices, while a binary build for older devices might not run
    efficiently on newer architectures. In CUDA the compute capability which is targeted
    is specified by the `-arch=sm_XY`, where `X` specifies the major architecture
    and it is between 1 and 9, and `Y` the minor. When using HIP on NVIDIA platforms
    one needs to use compiling option `--gpu-architecture=sm_XY`, while on AMD platforms
    `--offload-arch=gfxabc` ( where `abc` is the architecture code such as `90a` for
    the MI200 series or `908` for MI100 series). Note that in the case of portable
    (single source) programs one would specify `openmp` as well as target for compilation,
    enabling to run the same code on multicore CPU.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，GPU支持不同的特性，即使在同一生产者之间也是如此。通常，新卡会带来额外的功能，有时旧功能可能不再被支持。在编译时，创建针对特定架构的二进制文件非常重要。为较新卡构建的二进制文件无法在旧设备上运行，而为旧设备构建的二进制文件可能在较新架构上运行效率不高。在CUDA中，目标计算能力通过`-arch=sm_XY`指定，其中`X`指定主架构，介于1到9之间，而`Y`指定次架构。当在NVIDIA平台上使用HIP时，需要使用编译选项`--gpu-architecture=sm_XY`，而在AMD平台上使用`--offload-arch=gfxabc`（其中`abc`是架构代码，例如MI200系列的`90a`或MI100系列的`908`）。请注意，在可移植（单源）程序的情况下，还需要指定`openmp`以及编译目标，以便在多核CPU上运行相同的代码。
- en: Terminology
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 术语
- en: Hardware
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件
- en: '| NVIDIA | AMD | Intel |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | AMD | Intel |'
- en: '| --- | --- | --- |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Streaming processor/streaming core | SIMD lane | Processing element |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 流处理器/流核心 | SIMD 通道 | 处理单元 |'
- en: '| SIMT unit | SIMD unit | Vector engine (XVE) |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| SIMT 单元 | SIMD 单元 | 向量引擎 (XVE) |'
- en: '| Streaming Multiprocessor (SM) | Computing Unit (CU) | Xe-core / Execution
    unit (EU) |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 流式多处理器 (SM) | 计算单元 (CU) | Xe核心 / 执行单元 (EU) |'
- en: '| GPU processing clusters (GPC) | Compute Engine | Xe-slice |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| GPU处理集群 (GPC) | 计算引擎 | Xe-slice |'
- en: Please keep in mind, that this table is only a rough approximation. Each GPU
    architecture is different, and it’s impossible to make a 1-to-1 mapping between
    terms used by different vendors.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，此表仅是一个粗略的近似。每个GPU架构都不同，不可能在不同供应商使用的术语之间进行一对一的映射。
- en: Summary
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: GPUs are designed to execute thousands of threads simultaneously, making them
    highly parallel processors. In contrast, CPUs excel at executing a smaller number
    of threads in parallel.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU被设计为同时执行数千个线程，使其成为高度并行的处理器。相比之下，CPU擅长并行执行较少数量的线程。
- en: GPUs allocate a larger portion of transistors to data processing rather than
    data caching and flow control. This prioritization of data processing enables
    GPUs to effectively handle parallel computations and hide memory access latencies
    through computation.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU将更大的晶体管部分分配给数据处理，而不是数据缓存和流量控制。这种对数据处理的优先级使得GPU能够有效地处理并行计算，并通过计算隐藏内存访问延迟。
- en: GPU producers provide comprehensive toolkits, libraries, and compilers for developing
    high-performance applications that leverage the parallel processing power of GPUs.
    Examples include CUDA (NVIDIA), ROCm (AMD), and oneAPI (Intel).
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU生产商为开发利用GPU并行处理能力的应用程序提供全面的工具包、库和编译器。例如，CUDA（NVIDIA），ROCm（AMD）和oneAPI（Intel）。
- en: These platforms offer debugging tools (e.g., `cuda-gdb`, `rocgdb`) and performance
    analysis tools (e.g., NVIDIA Nsight Systems, NVIDIA Nsight Compute, `rocprof`,
    `roctracer`) to facilitate code optimization and ensure efficient utilization
    of GPU resources.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些平台提供了调试工具（例如，`cuda-gdb`，`rocgdb`）和性能分析工具（例如，NVIDIA Nsight Systems，NVIDIA Nsight
    Compute，`rocprof`，`roctracer`），以促进代码优化并确保高效利用GPU资源。
- en: Exercises
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: GPUs and memory
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: GPU与内存
- en: Which statement about the relationship between GPUs and memory is true?
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPU与内存之间关系的哪个陈述是正确的？
- en: GPUs are not affected by memory access latencies.
  id: totrans-402
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU不受内存访问延迟的影响。
- en: GPUs can run out of memory quickly with many cores trying to access the memory
    simultaneously.
  id: totrans-403
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当许多核心同时尝试访问内存时，GPU可能会迅速耗尽内存。
- en: GPUs have an unlimited cache size.
  id: totrans-404
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU具有无限的缓存大小。
- en: GPUs prefer to run with a minimal number of threads to manage memory effectively.
  id: totrans-405
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU倾向于以最少的线程数量运行，以有效地管理内存。
- en: Solution
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The correct answer is B). This is true because GPUs run many threads simultaneously
    on thousands of cores, and with limited cache available, this can lead to the
    GPU running out of memory quickly if many cores are trying to access the memory
    simultaneously. This is why data management and access patterns are essential
    in GPU computing.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是B）。这是因为GPU在数千个核心上同时运行许多线程，并且由于可用的缓存有限，如果许多核心同时尝试访问内存，这可能导致GPU很快耗尽内存。这就是为什么数据管理和访问模式在GPU计算中至关重要。
- en: Keypoints
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs vs. CPUs, key differences between them
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU与CPU的比较，它们之间的关键区别
- en: GPU software suites, support specific GPU features, programming models, compatibility
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU软件套件，支持特定的GPU功能、编程模型、兼容性
- en: Applications of GPUs*
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU的应用*
