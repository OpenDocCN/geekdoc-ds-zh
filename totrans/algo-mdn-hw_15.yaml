- en: Instruction Tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://en.algorithmica.org/hpc/pipelining/tables/](https://en.algorithmica.org/hpc/pipelining/tables/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Interleaving the stages of execution is a general idea in digital electronics,
    and it is applied not only in the main CPU pipeline, but also on the level of
    separate instructions and [memory](/hpc/cpu-cache/mlp). Most execution units have
    their own little pipelines and can take another instruction just one or two cycles
    after the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this context, it makes sense to use two different “[costs](/hpc/complexity)”
    for instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Latency*: how many cycles are needed to receive the results of an instruction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Throughput*: how many instructions can be, on average, executed per cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can get latency and throughput numbers for a specific architecture from
    special documents called [instruction tables](https://www.agner.org/optimize/instruction_tables.pdf).
    Here are some sample values for my Zen 2 (all specified for 32-bit operands, if
    there is any difference):'
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Latency | RThroughput |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `jmp` | - | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `mov r, r` | - | 1/4 |'
  prefs: []
  type: TYPE_TB
- en: '| `mov r, m` | 4 | 1/2 |'
  prefs: []
  type: TYPE_TB
- en: '| `mov m, r` | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `add` | 1 | 1/3 |'
  prefs: []
  type: TYPE_TB
- en: '| `cmp` | 1 | 1/4 |'
  prefs: []
  type: TYPE_TB
- en: '| `popcnt` | 1 | 1/4 |'
  prefs: []
  type: TYPE_TB
- en: '| `mul` | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `div` | 13-28 | 13-28 |'
  prefs: []
  type: TYPE_TB
- en: 'Some comments:'
  prefs: []
  type: TYPE_NORMAL
- en: Because our minds are so used to the cost model where “more” means “worse,”
    people mostly use *reciprocals* of throughput instead of throughput.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a certain instruction is especially frequent, its execution unit could be
    duplicated to increase its throughput — possibly to even more than one, but not
    higher than the [decode width](/hpc/architecture/layout).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some instructions have a latency of 0\. This means that these instruction are
    used to control the scheduler and don’t reach the execution stage. They still
    have non-zero reciprocal throughput because the [CPU front-end](/hpc/architecture/layout)
    still needs to process them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Most instructions are pipelined, and if they have the reciprocal throughput
    of $n$, this usually means that their execution unit can take another instruction
    after $n$ cycles (and if it is below 1, this means that there are multiple execution
    units, all capable of taking another instruction on the next cycle). One notable
    exception is [integer division](/hpc/arithmetic/division): it is either very poorly
    pipelined or not pipelined at all.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some instructions have variable latency, depending on not only the size, but
    also the values of the operands. For memory operations (including fused ones like
    `add`), the latency is usually specified for the best case (an L1 cache hit).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more important little details, but this mental model will suffice
    for now.
  prefs: []
  type: TYPE_NORMAL
- en: '[← Branchless Programming](https://en.algorithmica.org/hpc/pipelining/branchless/)[Throughput
    Computing →](https://en.algorithmica.org/hpc/pipelining/throughput/)'
  prefs: []
  type: TYPE_NORMAL
