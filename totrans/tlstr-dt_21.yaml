- en: 11  Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://tellingstorieswithdata.com/11-eda.html](https://tellingstorieswithdata.com/11-eda.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Preparation](./09-clean_and_prepare.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[11  Exploratory data analysis](./11-eda.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prerequisites**'
  prefs: []
  type: TYPE_NORMAL
- en: Read *The Future of Data Analysis*, ([Tukey 1962](99-references.html#ref-tukey1962future))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: John Tukey, the twentieth century statistician, made many contributions to statistics.
    From this paper focus on Part 1 “General Considerations”, which was ahead of its
    time about the ways in which we ought to learn something from data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Read *Best Practices in Data Cleaning*, ([Osborne 2012](99-references.html#ref-bestpracticesindatacleaning))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on Chapter 6 “Dealing with Missing or Incomplete Data” which is a chapter-length
    treatment of this issue.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Read *R for Data Science*, ([Wickham, Çetinkaya-Rundel, and Grolemund [2016]
    2023](99-references.html#ref-r4ds))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on Chapter 11 “Exploratory data analysis”, which provides a written self-contained
    EDA worked example.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Watch *Whole game*, ([Wickham 2018](99-references.html#ref-hadleycodes))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A video providing a self-contained EDA worked example. One nice aspect is that
    you get to see an expert make mistakes and then fix them.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key concepts and skills**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploratory data analysis is the process of coming to terms with a new dataset
    by looking at the data, constructing graphs, tables, and models. We want to understand
    three aspects:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: each individual variable by itself;
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: each individual in the context of other, relevant, variables; and
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: the data that are not there.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: During EDA we want to come to understand the issues and features of the dataset
    and how this may affect analysis decisions. We are especially concerned about
    missing values and outliers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software and packages**'
  prefs: []
  type: TYPE_NORMAL
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`arrow` ([Richardson et al. 2023](99-references.html#ref-arrow))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lubridate` ([Grolemund and Wickham 2011](99-references.html#ref-GrolemundWickham2011))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mice` ([van Buuren and Groothuis-Oudshoorn 2011](99-references.html#ref-mice))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`naniar` ([Tierney et al. 2021](99-references.html#ref-naniar))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`opendatatoronto` ([Gelfand 2022](99-references.html#ref-citeSharla))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*## 11.1 Introduction'
  prefs: []
  type: TYPE_NORMAL
- en: The future of data analysis can involve great progress, the overcoming of real
    difficulties, and the provision of a great service to all fields of science and
    technology. Will it? That remains to us, to our willingness to take up the rocky
    road of real problems in preference to the smooth road of unreal assumptions,
    arbitrary criteria, and abstract results without real attachments. Who is for
    the challenge?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tukey ([1962, 64](99-references.html#ref-tukey1962future)).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploratory data analysis is never finished. It is the active process of exploring
    and becoming familiar with our data. Like a farmer with their hands in the earth,
    we need to know every contour and aspect of our data. We need to know how it changes,
    what it shows, hides, and what are its limits. Exploratory data analysis (EDA)
    is the unstructured process of doing this.
  prefs: []
  type: TYPE_NORMAL
- en: EDA is a means to an end. While it will inform the entire paper, especially
    the data section, it is not typically something that ends up in the final paper.
    The way to proceed is to make a separate Quarto document. Add code and brief notes
    on-the-go. Do not delete previous code, just add to it. By the end of it we will
    have created a useful notebook that captures your exploration of the dataset.
    This is a document that will guide the subsequent analysis and modeling.
  prefs: []
  type: TYPE_NORMAL
- en: EDA draws on a variety of skills and there are a lot of options when conducting
    EDA ([Staniak and Biecek 2019](99-references.html#ref-staniak2019landscape)).
    Every tool should be considered. Look at the data and scroll through it. Make
    tables, plots, summary statistics, even some models. The key is to iterate, move
    quickly rather than perfectly, and come to a thorough understanding of the data.
    Interestingly, coming to thoroughly understand the data that we have often helps
    us understand what we do not have.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are interested in the following process:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand the distribution and properties of individual variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand relationships between variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand what is not there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no one correct process or set of steps that are required to undertake
    and complete EDA. Instead, the relevant steps and tools depend on the data and
    question of interest. As such, in this chapter we will illustrate approaches to
    EDA through various examples of EDA including US state populations, subway delays
    in Toronto, and Airbnb listings in London. We also build on [Chapter 6](06-farm.html)
    and return to missing data.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2 1975 United States population and income data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a first example we consider US state populations as of 1975\. This dataset
    is built into R with `state.x77`. Here is what the dataset looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE2]*  *We want to get a quick sense of the data. The first step is to have
    a look at the top and bottom of it with `head()` and `tail()`, then a random selection,
    and finally to focus on the variables and their class with `glimpse()`. The random
    selection is an important aspect, and when you use `head()` you should also quickly
    consider a random selection.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE4]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE6]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE8]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE10]****  ***We are then interested in understanding key summary statistics,
    such as the minimum, median, and maximum values for numeric variables with `summary()`
    from base R and the number of observations.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE12]*  *Finally, it is especially important to understand the behavior
    of these key summary statistics at the limits. In particular, one approach is
    to randomly remove some observations and compare what happens to them. For instance,
    we can randomly create five datasets that differ on the basis of which observations
    were removed. We can then compare the summary statistics. If any of them are especially
    different, then we would want to look at the observations that were removed as
    they may contain observations with high influence.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 11.1: Comparing the mean population when different states are randomly
    removed'
  prefs: []
  type: TYPE_NORMAL
- en: '| Seed | Mean | Ignored states |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 4,469 | Arkansas, Rhode Island, Alabama, North Dakota, Minnesota |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4,027 | Massachusetts, Iowa, Colorado, West Virginia, New York |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4,086 | California, Idaho, Rhode Island, Oklahoma, South Carolina |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4,391 | Hawaii, Arizona, Connecticut, Utah, New Jersey |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4,340 | Alaska, Texas, Iowa, Hawaii, South Dakota |*  *In the case of
    the populations of US states, we know that larger states, such as California and
    New York, will have an out sized effect on our estimate of the mean. [Table 11.1](#tbl-summarystatesrandom)
    supports that, as we can see that when we use seeds 2 and 3, there is a lower
    mean.******  ***## 11.3 Missing data'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have discussed missing data a lot throughout this book, especially in [Chapter
    6](06-farm.html). Here we return to it because understanding missing data tends
    to be a substantial focus of EDA. When we find missing data—and there are always
    missing data of some sort or another—we want to establish what type of missingness
    we are dealing with. Focusing on known-missing observations, that is where there
    are observations that we can see are missing in the dataset, based on Gelman,
    Hill, and Vehtari ([2020, 323](99-references.html#ref-gelmanhillvehtari2020))
    we consider three main categories of missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: Missing Completely At Random;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Missing at Random; and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Missing Not At Random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When data are Missing Completely At Random (MCAR), observations are missing
    from the dataset independent of any other variables—whether in the dataset or
    not. As discussed in [Chapter 6](06-farm.html), when data are MCAR there are fewer
    concerns about summary statistics and inference, but data are rarely MCAR. Even
    if they were it would be difficult to be convinced of this. Nonetheless we can
    simulate an example. For instance we can remove the population data for three
    randomly selected states.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE15]*  *When observations are Missing at Random (MAR) they are missing
    from the dataset in a way that is related to other variables in the dataset. For
    instance, it may be that we are interested in understanding the effect of income
    and gender on political participation, and so we gather information on these three
    variables. But perhaps for some reason males are less likely to respond to a question
    about income.'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the US states dataset, we can simulate a MAR dataset by making
    the three US states with the highest population not have an observation for income.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE17]*  *Finally when observations are Missing Not At Random (MNAR) they
    are missing from the dataset in a way that is related to either unobserved variables,
    or the missing variable itself. For instance, it may be that respondents with
    a higher income, or that respondents with higher education (a variable that we
    did not collect), are less likely to fill in their income.'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the US states dataset, we can simulate a MNAR dataset by making
    the three US states with the highest population not have an observation for population.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE19]*  *The best approach will be bespoke to the circumstances, but in
    general we want to use simulation to better understand the implications of our
    choices. From a data side we can choose to remove observations that are missing
    or input a value. (There are also options on the model side, but those are beyond
    the scope of this book.) These approaches have their place, but need to be used
    with humility and well communicated. The use of simulation is critical.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can return to our US states dataset, generate some missing data, and consider
    a few common approaches for dealing with missing data, and compare the implied
    values for each state, and the overall US mean population. We consider the following
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: Drop observations with missing data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Impute the mean of observations without missing data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use multiple imputation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To drop the observations with missing data, we can use `mean()`. By default
    it will exclude observations with missing values in its calculation. To impute
    the mean, we construct a second dataset with the observations with missing data
    removed. We then compute the mean of the population column, and impute that into
    the missing values in the original dataset. Multiple imputation involves creating
    many potential datasets, conducting inference, and then bringing them together
    potentially though averaging ([Gelman and Hill 2007, 542](99-references.html#ref-gelmanandhill)).
    We can implement multiple imputation with `mice()` from `mice`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 11.2: Comparing the imputed values of population for three US states
    and the overall mean population'
  prefs: []
  type: TYPE_NORMAL
- en: '| Observation | Drop missing | Input mean | Multiple imputation | Actual |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Florida |  | 4,308 | 11,197 | 8,277 |'
  prefs: []
  type: TYPE_TB
- en: '| Montana |  | 4,308 | 4,589 | 746 |'
  prefs: []
  type: TYPE_TB
- en: '| New Hampshire |  | 4,308 | 813 | 812 |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | 4,308 | 4,308 | 4,382 | 4,246 |'
  prefs: []
  type: TYPE_TB
- en: '[Table 11.2](#tbl-imputationoptions) makes it clear that none of these approaches
    should be naively imposed. For instance, Florida’s population should be 8,277\.
    Imputing the mean across all the states would result in an estimate of 4,308,
    and multiple imputation results in an estimate of 11,197, the former is too low
    and the latter is too high. If imputation is the answer, it may be better to look
    for a different question. It is worth pointing out that it was developed for specific
    circumstances of limiting public disclosure of private information ([Horton and
    Lipsitz 2001](99-references.html#ref-myboynick)).'
  prefs: []
  type: TYPE_NORMAL
- en: Nothing can make up for missing data ([Manski 2022](99-references.html#ref-manskiwow)).
    The conditions under which it makes sense to impute the mean or the prediction
    based on multiple imputation are not common, and even more rare is our ability
    to verify them. What to do depends on the circumstances and purpose of the analysis.
    Simulating the removal of observations that we have and then implementing various
    options can help us better understand the trade-offs we face. Whatever choice
    is made—and there is rarely a clear-cut solution—try to document and communicate
    what was done, and explore the effect of different choices on subsequent estimates.
    We recommend proceeding by simulating different scenarios that remove some of
    the data that we have, and evaluating how the approaches differ.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, more prosaically, but just as importantly, sometimes missing data
    is encoded in the variable with particular values. For instance, while R has the
    option of “NA”, sometimes numerical data is entered as “-99” or alternatively
    as a very large integer such as “9999999”, if it is missing. In the case of the
    Nationscape survey dataset introduced in [Chapter 8](08-hunt.html), there are
    three types of known missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '“888”: “Asked in this wave, but not asked of this respondent”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“999”: “Not sure, don’t know”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“.”: Respondent skipped'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is always worth looking explicitly for values that seem like they do not
    belong and investigating them. Graphs and tables are especially useful for this
    purpose.****  ***## 11.4 TTC subway delays
  prefs: []
  type: TYPE_NORMAL
- en: As a second, and more involved, example of EDA we use `opendatatoronto`, introduced
    in [Chapter 2](02-drinking_from_a_fire_hose.html), and the `tidyverse` to obtain
    and explore data about the Toronto subway system. We want to get a sense of the
    delays that have occurred.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, we download the data on Toronto Transit Commission (TTC) subway delays
    in 2021\. The data are available as an Excel file with a separate sheet for each
    month. We are interested in 2021 so we filter to just that year then download
    it using `get_resource()` from `opendatatoronto` and bring the months together
    with `bind_rows()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE22]'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset has a variety of columns, and we can find out more about each of
    them by downloading the codebook. The reason for each delay is coded, and so we
    can also download the explanations. One variable of interest appears is “min_delay”,
    which gives the extent of the delay in minutes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*There is no one way to explore a dataset while conducting EDA, but we are
    usually especially interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: What should the variables look like? For instance, what is their class, what
    are the values, and what does the distribution of these look like?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What aspects are surprising, both in terms of data that are there that we do
    not expect, such as outliers, but also in terms of data that we may expect but
    do not have, such as missing data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a goal for our analysis. For instance, in this case, it might be
    understanding the factors such as stations and the time of day that are associated
    with delays. While we would not answer these questions formally here, we might
    explore what an answer could look like.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to document all aspects as we go through and note anything surprising.
    We are looking to create a record of the steps and assumptions that we made as
    we were going because these will be important when we come to modeling. In the
    natural sciences, a research notebook of this type can even be a legal document
    ([Ryan 2015](99-references.html#ref-nihtalk)).
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.1 Distribution and properties of individual variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should check that the variables are what they say they are. If they are not,
    then we need to work out what to do. For instance, should we change them, or possibly
    even remove them? It is also important to ensure that the class of the variables
    is as we expect. For instance, variables that should be a factor are a factor
    and those that should be a character are a character. And that we do not accidentally
    have, say, factors as numbers, or vice versa. One way to do this is to use `unique()`,
    and another is to use `table()`. There is no universal answer to which variables
    should be of certain classes, because the answer depends on the context.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE25]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE27]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE29]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE31]****  ***We have likely issues in terms of the subway lines. Some of
    them have a clear fix, but not all. One option would be to drop them, but we would
    need to think about whether these errors might be correlated with something that
    is of interest. If they were then we may be dropping important information. There
    is usually no one right answer, because it will usually depend on what we are
    using the data for. We would note the issue, as we continued with EDA and then
    decide later about what to do. For now, we will remove all the lines that are
    not the ones that we know to be correct based on the codebook.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE33]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]*  **Entire careers are spent understanding missing data, and the presence,
    or lack, of missing values can haunt an analysis. To get started we could look
    at known-unknowns, which are the NAs for each variable. For instance, we could
    create counts by variable.'
  prefs: []
  type: TYPE_NORMAL
- en: In this case we have many missing values in “bound” and two in “line”. For these
    known-unknowns, as discussed in [Chapter 6](06-farm.html), we are interested in
    whether they are missing at random. We want to, ideally, show that data happened
    to just drop out. But this is unlikely, and so we are usually trying to look at
    what is systematic about how the data are missing.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes data happen to be duplicated. If we did not notice this, then our
    analysis would be wrong in ways that we would not be able to consistently expect.
    There are a variety of ways to look for duplicated rows, but `get_dupes()` from
    `janitor` is especially useful.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE36]*  *This dataset has many duplicates. We are interested in whether
    there is something systematic going on. Remembering that during EDA we are trying
    to quickly come to terms with a dataset, one way forward is to flag this as an
    issue to come back to and explore later, and to just remove duplicates for now
    using `distinct()`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '*The station names have many errors.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE39]*  *We could try to quickly bring a little order to the chaos by just
    taking just the first word or first few words, accounting for names like “ST.
    CLAIR” and “ST. PATRICK” by checking if the name starts with “ST”, as well as
    distinguishing between stations like “DUNDAS” and “DUNDAS WEST” by checking if
    the name contains “WEST”. Again, we are just trying to get a sense of the data,
    not necessarily make binding decisions here. We use `word()` from `stringr` to
    extract specific words from the station names.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE41]*  *We need to see the data in its original state to understand it,
    and we often use bar charts, scatterplots, line plots, and histograms for this.
    During EDA we are not so concerned with whether the graph looks nice, but are
    instead trying to acquire a sense of the data as quickly as possible. We can start
    by looking at the distribution of “min_delay”, which is one outcome of interest.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/8a9b99ee22fa1af410bb6b2439ea689c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Distribution of delay
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50ca0ed779df9dc83af1bebb2137ea3e.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) With a log scale
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.1: Distribution of delay, in minutes'
  prefs: []
  type: TYPE_NORMAL
- en: The largely empty graph in [Figure 11.1 (a)](#fig-delayhist-1) suggests the
    presence of outliers. There are a variety of ways to try to understand what could
    be going on, but one quick way to proceed is to use logarithms, remembering that
    we would expect values of zero to drop away ([Figure 11.1 (b)](#fig-delayhist-2)).
  prefs: []
  type: TYPE_NORMAL
- en: This initial exploration suggests there are a small number of large delays that
    we might like to explore further. We will join this dataset with “delay_codes”
    to understand what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE44]*  *From this we can see that the 348 minute delay was due to “Traction
    Power Rail Related”, the 343 minute delay was due to “Signals - Track Circuit
    Problems”, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Another thing that we are looking for is various groupings of the data, especially
    where sub-groups may end up with only a small number of observations in them.
    This is because our analysis could be especially influenced by them. One quick
    way to do this is to group the data by a variable that is of interest, for instance,
    “line”, using color.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/5d93caf906b1f2f1a651f162c6d0b814.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Density
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b9779bdc38c21edbfb0dc28def522b7.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Frequency
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.2: Distribution of delay, in minutes'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11.2 (a)](#fig-delaydensity-1) uses density so that we can look at
    the distributions more comparably, but we should also be aware of differences
    in frequency ([Figure 11.2 (b)](#fig-delaydensity-2)). In this case, we see that
    “SHP” and “SRT” have much smaller counts.'
  prefs: []
  type: TYPE_NORMAL
- en: To group by another variable, we can add facets ([Figure 11.3](#fig-delayfreqfacet)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/e4ad22b79fc2b82d73586a8d2de3fc20.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.3: Frequency of the distribution of delay, in minutes, by day*  *We
    can also plot the top five stations by mean delay, faceted by line ([Figure 11.4](#fig-whatisthisagraphforants)).
    This raises something that we would need to follow up on, which is what is “ZONE”
    in “YU”?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/052d63dcb2cf6ea6d9a27e4b0be1c74b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.4: Top five stations, by mean delay and line*  *As discussed in [Chapter
    9](09-clean_and_prepare.html), dates are often difficult to work with because
    they are so prone to having issues. For this reason, it is especially important
    to consider them during EDA. Let us create a graph by week, to see if there is
    any seasonality over the course of a year. When using dates, `lubridate` is especially
    useful. For instance, we can look at the average delay, of those that were delayed,
    by week, using `week()` to construct the weeks ([Figure 11.5](#fig-delaybyweek)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/a311d1974189d0ca293725f3e2b5a356.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.5: Average delay, in minutes, by week, for the Toronto subway*  *Now
    let us look at the proportion of delays that were greater than ten minutes ([Figure 11.6](#fig-longdelaybyweek)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/12e2ac75f3f2b9511167f379f5879e91.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.6: Delays longer than ten minutes, by week, for the Toronto subway*  *These
    figures, tables, and analysis may not have a place in a final paper. Instead,
    they allow us to become comfortable with the data. We note aspects about each
    that stand out, as well as the warnings and any implications or aspects to return
    to.****************  ***### 11.4.2 Relationships between variables'
  prefs: []
  type: TYPE_NORMAL
- en: We are also interested in looking at the relationship between two variables.
    We will draw heavily on graphs for this. Appropriate types, for different circumstances,
    were discussed in [Chapter 5](05-graphs_tables_maps.html). Scatter plots are especially
    useful for continuous variables, and are a good precursor to modeling. For instance,
    we may be interested in the relationship between the delay and the gap, which
    is the number of minutes between trains ([Figure 11.7](#fig-delayvsgap)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/896f5cd070a739e7e0ebe45039e898ee.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.7: Relationship between delay and gap for the Toronto subway in 2021*  *The
    relationship between categorical variables takes more work, but we could also,
    for instance, look at the top five reasons for delay by station. We may be interested
    in whether they differ, and how any difference could be modelled ([Figure 11.8](#fig-categorical)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/2482269d77a1d1a92ccfa48affde2679.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.8: Relationship between categorical variables for the Toronto subway
    in 2021*******  ***## 11.5 Airbnb listings in London, England'
  prefs: []
  type: TYPE_NORMAL
- en: In this case study we look at Airbnb listings in London, England, as at 14 March
    2023\. The dataset is from [Inside Airbnb](http://insideairbnb.com) ([Cox 2021](99-references.html#ref-airbnbdata))
    and we will read it from their website, and then save a local copy. We can give
    `read_csv()` a link to where the dataset is and it will download it. This helps
    with reproducibility because the source is clear. But as that link could change
    at any time, longer-term reproducibility, as well as wanting to minimize the effect
    on the Inside Airbnb servers, suggests that we should also save a local copy of
    the data and then use that.
  prefs: []
  type: TYPE_NORMAL
- en: To get the dataset that we need, go to Inside Airbnb \(\rightarrow\) “Data”
    \(\rightarrow\) “Get the Data”, then scroll down to London. We are interested
    in the “listings dataset”, and we right click to get the URL that we need ([Figure 11.9](#fig-getairbnb)).
    Inside Airbnb update the data that they make available, and so the particular
    dataset that is available will change over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7a7913defa654e1329ba9411063eb1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Obtaining the Airbnb data from Inside Airbnb'
  prefs: []
  type: TYPE_NORMAL
- en: As the original dataset is not ours, we should not make that public without
    first getting written permission. For instance, we may want to add it to our inputs
    folder, but use a “.gitignore” entry, covered in [Chapter 3](03-workflow.html),
    to ensure that we do not push it to GitHub. The “guess_max” option in `read_csv()`
    helps us avoid having to specify the column types. Usually `read_csv()` takes
    a best guess at the column types based on the first few rows. But sometimes those
    first ones are misleading and so “guess_max” forces it to look at a larger number
    of rows to try to work out what is going on. Paste the URL that we copied from
    Inside Airbnb into the URL part. And once it is downloaded, save a local copy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '*We should refer to this local copy of our data when we run our scripts to
    explore the data, rather than asking the Inside Airbnb servers for the data each
    time. It might be worth even commenting out this call to their servers to ensure
    that we do not accidentally stress their service.'
  prefs: []
  type: TYPE_NORMAL
- en: Again, add this filename—“airbnb_data.csv”—to the “.gitignore” file so that
    it is not pushed to GitHub. The size of the dataset will create complications
    that we would like to avoid.
  prefs: []
  type: TYPE_NORMAL
- en: While we need to archive this CSV because that is the original, unedited data,
    at more than 100MB it is a little unwieldy. For exploratory purposes we will create
    a parquet file with selected variables (we do this in an iterative way, using
    `names(airbnb_data)` to work out the variable names).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '*### 11.5.1 Distribution and properties of individual variables'
  prefs: []
  type: TYPE_NORMAL
- en: First we might be interested in price. It is a character at the moment and so
    we need to convert it to a numeric. This is a common problem and we need to be
    a little careful that it does not all just convert to NAs. If we just force the
    price variable to be a numeric then it will go to NA because there are a lot of
    characters where it is unclear what the numeric equivalent is, such as “$”. We
    need to remove those characters first.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE55]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE57]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE59]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]***  ***Now we can look at the distribution of prices ([Figure 11.10
    (a)](#fig-airbnbpricesfirst-1)). There are outliers, so again we might like to
    consider it on the log scale ([Figure 11.10 (b)](#fig-airbnbpricesfirst-2)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/9f5cee458ac2576879fcb7e6b8b4bc7e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Distribution of prices
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4ca5739cc2869e2dde32513e8d9e1166.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Using the log scale for prices more than $1,000
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.10: Distribution of prices of London Airbnb rentals in March 2023'
  prefs: []
  type: TYPE_NORMAL
- en: Turning to [Figure 11.11](#fig-airbnbpricesbunch), if we focus on prices that
    are less than $1,000, then we see that most properties have a nightly price less
    than $250 ([Figure 11.11 (a)](#fig-airbnbpricesbunch-1)). In the same way that
    we saw some bunching in ages in [Chapter 9](09-clean_and_prepare.html), it looks
    like there is some bunching of prices here. It might be that this is happening
    around numbers ending in zero or nine. Let us just zoom in on prices between $90
    and $210, out of interest, but change the bins to be smaller ([Figure 11.11 (b)](#fig-airbnbpricesbunch-2)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/4b23383cd528d896de95b6b4da5ee894.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prices less than $1,000 suggest some bunching
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/370f9fd8337c861a7ea7e38ca0e115b1.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Prices between $90 and $210 illustrate the bunching more clearly
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.11: Distribution of prices for Airbnb listings in London in March
    2023'
  prefs: []
  type: TYPE_NORMAL
- en: For now, we will just remove all prices that are more than $999.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '*Superhosts are especially experienced Airbnb hosts, and we might be interested
    to learn more about them. For instance, a host either is or is not a superhost,
    and so we would not expect any NAs. But we can see that there are NAs. It might
    be that the host removed a listing or similar, but this is something that we would
    need to look further into.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE65]*  *We will also want to create a binary variable from this. It is
    true/false at the moment, which is fine for the modeling, but there are a handful
    of situations where it will be easier if we have a 0/1\. And for now we will just
    remove anyone with a NA for whether they are a superhost.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '*On Airbnb, guests can give one to five star ratings across a variety of different
    aspects, including cleanliness, accuracy, value, and others. But when we look
    at the reviews in our dataset, it is clear that it is effectively a binary, and
    almost entirely the case that either the rating is five stars or not ([Figure 11.12](#fig-airbnbreviews)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/6c273b02b72ec2312728d4e65503137e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.12: Distribution of review scores rating for London Airbnb rentals
    in March 2023*  *We would like to deal with the NAs in “review_scores_rating”,
    but this is more complicated as there are a lot of them. It may be that this is
    just because they do not have any reviews.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE69]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE71]**  **These properties do not have a review rating yet because they
    do not have enough reviews. It is a large proportion of the total, at almost a
    fifth of them so we might like to look at this in more detail using counts. We
    are interested to see whether there is something systematic happening with these
    properties. For instance, if the NAs were being driven by, say, some requirement
    of a minimum number of reviews, then we would expect they would all be missing.'
  prefs: []
  type: TYPE_NORMAL
- en: One approach would be to just focus on those that are not missing and the main
    review score ([Figure 11.13](#fig-airbnbreviewsselected)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/abb4252309a1edaec89cc94fdfbe7b2d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.13: Distribution of review scores for London Airbnb rentals in March
    2023*  *For now, we will remove anyone with an NA in their main review score,
    even though this will remove roughly 20 per cent of observations. If we ended
    up using this dataset for actual analysis, then we would want to justify this
    decision in an appendix or similar.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '*Another important factor is how quickly a host responds to an inquiry. Airbnb
    allows hosts up to 24 hours to respond, but encourages responses within an hour.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE75]*  *It is unclear how a host could have a response time of NA. It may
    be this is related to some other variable. Interestingly it seems like what looks
    like “NAs” in “host_response_time” variable are not coded as proper NAs, but are
    instead being treated as another category. We will recode them to be actual NAs
    and change the variable to be a factor.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '*There is an issue with NAs as there are a lot of them. For instance, we might
    be interested to see if there is a relationship with the review score ([Figure 11.14](#fig-airbnbreviewsselectednasresponse)).
    There are a lot that have an overall review of 100.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/4d934408bcd5a59ac3ef523b1f8bf87d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.14: Distribution of review scores for properties with NA response
    time, for London Airbnb rentals in March 2023*  *Usually missing values are dropped
    by `ggplot2`. We can use `geom_miss_point()` from `naniar` to include them in
    the graph ([Figure 11.15](#fig-visualisemissing)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/19c02d503924cb82a5d7d7bfa37c5d80.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.15: Missing values in London Airbnb data, by host response time*  *For
    now, we will remove anyone with a NA in their response time. This will again remove
    roughly another 20 per cent of the observations.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '*We might be interested in how many properties a host has on Airbnb ([Figure 11.16](#fig-airbnbhostlisting)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/8acfd478a7a4e7cf51ee42bf31983845.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.16: Distribution of the number of properties a host has on Airbnb,
    for London Airbnb rentals in March 2023*  *Based on [Figure 11.16](#fig-airbnbhostlisting)
    we can see there are a large number who have somewhere in the 2-500 properties
    range, with the usual long tail. The number with that many listings is unexpected
    and worth following up on. And there are a bunch with NA that we will need to
    deal with.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE82]*  *There is nothing that immediately jumps out as odd about the people
    with more than ten listings, but at the same time it is still not clear. For now,
    we will move on and focus on only those with one property for simplicity.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]********************  ***### 11.5.2 Relationships between variables'
  prefs: []
  type: TYPE_NORMAL
- en: We might like to make some graphs to see if there are any relationships between
    variables that become clear. Some aspects that come to mind are looking at prices
    and comparing with reviews, superhosts, number of properties, and neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: We can look at the relationship between price and reviews, and whether they
    are a super-host, for properties with more than one review ([Figure 11.17](#fig-priceandreview)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '*![](../Images/0f46e01095a89b1c83e70fec7adffef8.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.17: Relationship between price and review and whether a host is a
    superhost, for London Airbnb rentals in March 2023*  *One of the aspects that
    may make someone a superhost is how quickly they respond to inquiries. One could
    imagine that being a superhost involves quickly saying yes or no to inquiries.
    Let us look at the data. First, we want to look at the possible values of superhost
    by their response times.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE86]*  *Fortunately, it looks like when we removed the reviews rows we
    removed any NAs from whether they were a superhost, but if we go back and look
    into that we may need to check again. We could build a table that looks at a hosts
    response time by whether they are a superhost using `tabyl()` from `janitor`.
    It is clear that if a host does not respond within an hour then it is unlikely
    that they are a superhost.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE88]*  *Finally, we could look at neighborhood. The data provider has attempted
    to clean the neighborhood variable for us, so we will use that variable for now.
    Although if we ended up using this variable for our actual analysis we would want
    to examine how it was constructed.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE90]*  *We will quickly run a model on our dataset. We will cover modeling
    in more detail in [Chapter 12](12-ijalm.html), but we can use models during EDA
    to help get a better sense of relationships that may exist between multiple variables
    in a dataset. For instance, we may like to see whether we can forecast whether
    someone is a superhost, and the factors that go into explaining that. As the outcome
    is binary, this is a good opportunity to use logistic regression. We expect that
    superhost status will be associated with faster responses and better reviews.
    Specifically, the model that we estimate is:'
  prefs: []
  type: TYPE_NORMAL
- en: \[\mbox{Prob(Is superhost} = 1) = \mbox{logit}^{-1}\left( \beta_0 + \beta_1
    \mbox{Response time} + \beta_2 \mbox{Reviews} + \epsilon\right)\]
  prefs: []
  type: TYPE_NORMAL
- en: We estimate the model using `glm`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '*After installing and loading `modelsummary` we can have a quick look at the
    results using `modelsummary()` ([Table 11.3](#tbl-modelsummarylogisticregressionsuper)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '*Table 11.3: Explaining whether a host is a superhost based on their response
    time'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | (1) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | -16.369 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.673) |'
  prefs: []
  type: TYPE_TB
- en: '| host_response_timewithin a day | 2.230 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.361) |'
  prefs: []
  type: TYPE_TB
- en: '| host_response_timewithin a few hours | 3.035 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.359) |'
  prefs: []
  type: TYPE_TB
- en: '| host_response_timewithin an hour | 3.279 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.358) |'
  prefs: []
  type: TYPE_TB
- en: '| review_scores_rating | 2.545 |'
  prefs: []
  type: TYPE_TB
- en: '|  | (0.116) |'
  prefs: []
  type: TYPE_TB
- en: '| Num.Obs. | 14152 |'
  prefs: []
  type: TYPE_TB
- en: '| AIC | 14948.4 |'
  prefs: []
  type: TYPE_TB
- en: '| BIC | 14986.2 |'
  prefs: []
  type: TYPE_TB
- en: '| Log.Lik. | -7469.197 |'
  prefs: []
  type: TYPE_TB
- en: '| F | 197.407 |'
  prefs: []
  type: TYPE_TB
- en: '| RMSE | 0.42 |*  *We see that each of the levels is positively associated
    with the probability of being a superhost. However, having a host that responds
    within an hour is associated with individuals that are superhosts in our dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: We will save this analysis dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]***********  ***## 11.6 Concluding remarks'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we have considered exploratory data analysis (EDA), which is
    the active process of getting to know a dataset. We focused on missing data, the
    distributions of variables, and the relationships between variables. And we extensively
    used graphs and tables to do this.
  prefs: []
  type: TYPE_NORMAL
- en: The approaches to EDA will vary depending on context, and the issues and features
    that are encountered in the dataset. It will also depend on your skills, for instance
    it is common to consider regression models, and dimensionality reduction approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7 Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Practice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*(Plan)* Consider the following scenario: *We have some data on age from a
    social media company that has about 80 per cent of the US population on the platform.*
    Please sketch what that dataset could look like and then sketch a graph that you
    could build to show all observations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation. Use parquet due to size. Please include ten tests based on the simulated
    data. Submit a link to a GitHub Gist that contains your code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Acquire)* Please describe a possible source of such a dataset.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched. Submit
    a link to a GitHub Gist that contains your code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*(Communicate)* Please write one page about what you did, and be careful to
    discuss some of the threats to the estimate that you make based on the sample.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Summarize Tukey ([1962](99-references.html#ref-tukey1962future)) in a few paragraphs
    and then relate it to data science.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In your own words what is exploratory data analysis (please write at least three
    paragraphs, and include citations and examples)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose you have a dataset called “my_data”, which has two columns: “first_col”
    and “second_col”. Please write some R code that would generate a graph (the type
    of graph does not matter). Submit a link to a GitHub Gist that contains your code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Consider a dataset that has 500 observations and three variables, so there
    are 1,500 cells. If 100 of the rows are missing a cell for at least one of the
    columns, then would you: a) remove the whole row from your dataset, b) try to
    run your analysis on the data as is, or c) some other procedure? What if your
    dataset had 10,000 rows instead, but the same number of missing rows? Discuss,
    with examples and citations, in at least three paragraphs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please discuss three ways of identifying unusual values, writing at least one
    paragraph for each.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a categorical and continuous variable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a factor and an integer variable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we think about who is systematically excluded from a dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using `opendatatoronto`, download the data on mayoral campaign contributions
    for 2014\. (Note: the 2014 file you will get from `get_resource()` contains many
    sheets, so just keep the sheet that relates to the mayor election).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clean up the data format (fixing the parsing issue and standardizing the column
    names using `janitor`).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarize the variables in the dataset. Are there missing values, and if so,
    should we be worried about them? Is every variable in the format it should be?
    If not, create new variable(s) that are in the right format.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Visually explore the distribution of values of the contributions. What contributions
    are notable outliers? Do they share similar characteristic(s)? It may be useful
    to plot the distribution of contributions without these outliers to get a better
    sense of most of the data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'List the top five candidates in each of these categories: 1) total contributions;
    2) mean contribution; and 3) number of contributions.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat that process, but without contributions from the candidates themselves.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How many contributors gave money to more than one candidate?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: List three geoms that produce graphs that have bars in `ggplot()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider a dataset with 10,000 observations and 27 variables. For each observation,
    there is at least one missing variable. Please discuss, in a paragraph or two,
    the steps that you would take to understand what is going on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Known missing data are those that leave holes in your dataset. But what about
    data that were never collected? Please look at McClelland ([2019](99-references.html#ref-mcclelland2019lock))
    and Luscombe and McClelland ([2020](99-references.html#ref-luscombe2020policing)).
    Look into how they gathered their dataset and what it took to put this together.
    What is in the dataset and why? What is missing and why? How could this affect
    the results? How might similar biases enter into other datasets that you have
    used or read about?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Class activities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fix the following file names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Consider Anscombe’s Quartet, introduced in [Chapter 5](05-graphs_tables_maps.html).
    We will randomly remove certain observations. Please pretend you are given the
    dataset with missing data. Pick one of the approaches to dealing with missing
    data from [Chapter 6](06-farm.html) and [Chapter 11](#sec-exploratory-data-analysis),
    then write code to implement your choice. Compare:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the results with the actual observations;
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: the summary statistics with the actual summary statistics; and
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: build a graph that shows the missing and actual data on the one graph.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE96]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]*  ***   Redo the exercise, but with the following dataset. What is
    the main difference in this case?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '*[PRE99]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]*  ***   Using pair programming (being sure to switch every 5 minutes),
    create a new R project, then read in the following dataset from Bombieri et al.
    ([2023](99-references.html#ref-Bombieri2023)) and explore it by adding code and
    notes to a Quarto document.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '**   Play the role of a data scientist partnering with a subject expert by
    pairing up with another student. Your partner gets to pick a topic, and a question,
    and it should be something they know well but you do not (perhaps something about
    their country, if they are an international student). You need to work with them
    to develop an analysis plan, simulate some data, and create a graph that they
    can use.*****  ***### Task'
  prefs: []
  type: TYPE_NORMAL
- en: Pick one of the following options. Use Quarto, and include an appropriate title,
    author, date, link to a GitHub repo, and citations. Submit a PDF.
  prefs: []
  type: TYPE_NORMAL
- en: '**Option 1:**'
  prefs: []
  type: TYPE_NORMAL
- en: Repeat the missing data exercise conducted for the US states and population,
    but for the “bill_length_mm” variable in the `penguins()` dataset available from
    `palmerpenguins`. Compare the imputed value with the actual value.
  prefs: []
  type: TYPE_NORMAL
- en: Write at least two pages about what you did and what you found.
  prefs: []
  type: TYPE_NORMAL
- en: Following this, please pair with another student and exchange your written work.
    Update it based on their feedback, and be sure to acknowledge them by name in
    your paper.
  prefs: []
  type: TYPE_NORMAL
- en: '**Option 2:**'
  prefs: []
  type: TYPE_NORMAL
- en: Carry out an Airbnb EDA but for Paris.
  prefs: []
  type: TYPE_NORMAL
- en: '**Option 3:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please write at least two pages about the topic: “what is missing data and
    what should you do about it?”'
  prefs: []
  type: TYPE_NORMAL
- en: Following this, please pair with another student and exchange your written work.
    Update it based on their feedback, and be sure to acknowledge them by name in
    your paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'Arel-Bundock, Vincent. 2022\. “modelsummary: Data and Model Summaries in R.”
    *Journal of Statistical Software* 103 (1): 1–23\. [https://doi.org/10.18637/jss.v103.i01](https://doi.org/10.18637/jss.v103.i01).———.
    2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,” “Markdown,”
    “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Bombieri,
    Giulia, Vincenzo Penteriani, Kamran Almasieh, Hüseyin Ambarlı, Mohammad Reza Ashrafzadeh,
    Chandan Surabhi Das, Nishith Dharaiya, et al. 2023\. “A Worldwide Perspective
    on Large Carnivore Attacks on Humans.” *PLOS Biology* 21 (1): e3001946\. [https://doi.org/10.1371/journal.pbio.3001946](https://doi.org/10.1371/journal.pbio.3001946).Cox,
    Murray. 2021\. “Inside Airbnb—Toronto Data.” [http://insideairbnb.com/get-the-data.html](http://insideairbnb.com/get-the-data.html).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gelfand,
    Sharla. 2022\. *opendatatoronto: Access the City of Toronto Open Data Portal*.
    [https://CRAN.R-project.org/package=opendatatoronto](https://CRAN.R-project.org/package=opendatatoronto).Gelman,
    Andrew, and Jennifer Hill. 2007\. *Data Analysis Using Regression and Multilevel/Hierarchical
    Models*. 1st ed. Cambridge University Press.Gelman, Andrew, Jennifer Hill, and
    Aki Vehtari. 2020\. *Regression and Other Stories*. Cambridge University Press.
    [https://avehtari.github.io/ROS-Examples/](https://avehtari.github.io/ROS-Examples/).Grolemund,
    Garrett, and Hadley Wickham. 2011\. “Dates and Times Made Easy with lubridate.”
    *Journal of Statistical Software* 40 (3): 1–25\. [https://doi.org/10.18637/jss.v040.i03](https://doi.org/10.18637/jss.v040.i03).Horton,
    Nicholas, and Stuart Lipsitz. 2001\. “Multiple Imputation in Practice.” *The American
    Statistician* 55 (3): 244–54\. [https://doi.org/10.1198/000313001317098266](https://doi.org/10.1198/000313001317098266).Luscombe,
    Alex, and Alexander McClelland. 2020\. “Policing the Pandemic: Tracking the Policing
    of Covid-19 Across Canada,” April. [https://doi.org/10.31235/osf.io/9pn27](https://doi.org/10.31235/osf.io/9pn27).Manski,
    Charles. 2022\. “Inference with Imputed Data: The Allure of Making Stuff Up.”
    arXiv. [https://doi.org/10.48550/arXiv.2205.07388](https://doi.org/10.48550/arXiv.2205.07388).McClelland,
    Alexander. 2019\. “‘Lock This Whore up’: Legal Violence and Flows of Information
    Precipitating Personal Violence Against People Criminalised for HIV-Related Crimes
    in Canada.” *European Journal of Risk Regulation* 10 (1): 132–47\. [https://doi.org/10.1017/err.2019.20](https://doi.org/10.1017/err.2019.20).Osborne,
    Jason. 2012\. *Best Practices in Data Cleaning: A Complete Guide to Everything
    You Need to Do Before and After Collecting Your Data*. SAGE Publications.R Core
    Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Richardson,
    Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane,
    Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2023\. *arrow: Integration
    to Apache Arrow*. [https://CRAN.R-project.org/package=arrow](https://CRAN.R-project.org/package=arrow).Ryan,
    Philip. 2015\. “Keeping a Lab Notebook.” *YouTube*, May. [https://youtu.be/-MAIuaOL64I](https://youtu.be/-MAIuaOL64I).Staniak,
    Mateusz, and Przemysław Biecek. 2019\. “The Landscape of R Packages for Automated
    Exploratory Data Analysis.” *The R Journal* 11 (2): 347–69\. [https://doi.org/10.32614/RJ-2019-033](https://doi.org/10.32614/RJ-2019-033).Tierney,
    Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021\. *naniar: Data Structures,
    Summaries, and Visualisations for Missing Data*. [https://CRAN.R-project.org/package=naniar](https://CRAN.R-project.org/package=naniar).Tukey,
    John. 1962\. “The Future of Data Analysis.” *The Annals of Mathematical Statistics*
    33 (1): 1–67\. [https://doi.org/10.1214/aoms/1177704711](https://doi.org/10.1214/aoms/1177704711).van
    Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011\. “mice: Multivariate Imputation
    by Chained Equations in R.” *Journal of Statistical Software* 45 (3): 1–67\. [https://doi.org/10.18637/jss.v045.i03](https://doi.org/10.18637/jss.v045.i03).Wickham,
    Hadley. 2018\. “Whole Game.” *YouTube*, January. [https://youtu.be/go5Au01Jrvs](https://youtu.be/go5Au01Jrvs).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).Wickham,
    Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. (2016) 2023\. *R for Data
    Science*. 2nd ed. O’Reilly Media. [https://r4ds.hadley.nz](https://r4ds.hadley.nz).****************'
  prefs: []
  type: TYPE_NORMAL
