- en: 5.8\. Online supplementary materials#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5.8\. 在线补充材料#
- en: 原文：[https://mmids-textbook.github.io/chap05_specgraph/supp/roch-mmids-specgraph-supp.html](https://mmids-textbook.github.io/chap05_specgraph/supp/roch-mmids-specgraph-supp.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap05_specgraph/supp/roch-mmids-specgraph-supp.html](https://mmids-textbook.github.io/chap05_specgraph/supp/roch-mmids-specgraph-supp.html)
- en: 5.8.1\. Quizzes, solutions, code, etc.[#](#quizzes-solutions-code-etc "Link
    to this heading")
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8.1\. 测验、解决方案、代码等。[#](#quizzes-solutions-code-etc "链接到本标题")
- en: 5.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.1\. 仅代码[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 下面可以访问一个包含本章代码的交互式 Jupyter 笔记本（推荐使用 Google Colab）。鼓励您对其进行尝试。一些建议的计算练习散布在其中。笔记本也可以作为幻灯片使用。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
- en: 5.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.2\. 自我评估测验[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以找到更广泛的自我评估测验的网络版本。
- en: '[Section 5.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.2 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
- en: '[Section 5.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.3 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
- en: '[Section 5.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.4 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
- en: '[Section 5.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.5 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
- en: '[Section 5.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.6 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
- en: 5.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在此处访问本章的自动生成的测验（推荐使用 Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
- en: 5.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.4\. 奇数编号预热练习的解决方案[#](#solutions-to-odd-numbered-warm-up-exercises "链接到本标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在克劳德、Gemini 和 ChatGPT 的帮助下)*'
- en: '**E5.2.1** \(V = \{1, 2, 3, 4\}\), \(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\). This follows directly from the definition of a graph as a pair \(G =
    (V, E)\).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.1** \(V = \{1, 2, 3, 4\}\), \(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\)。这直接来自图作为一对 \(G = (V, E)\) 的定义。'
- en: '**E5.2.3** One possible path is \(1 \sim 2 \sim 4\). Its length is 2, since
    it consists of two edges.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.3** 一种可能的路径是 \(1 \sim 2 \sim 4\)。它的长度是 2，因为它由两个边组成。'
- en: '**E5.2.5** \(\delta^-(2) = 1\), \(\delta^+(2) = 2\). The in-degree of a vertex
    \(v\) is the number of edges with destination \(v\), and the out-degree is the
    number of edges with source \(v\).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.5** \(\delta^-(2) = 1\), \(\delta^+(2) = 2\)。一个顶点 \(v\) 的入度是目标为 \(v\)
    的边的数量，出度是源为 \(v\) 的边的数量。'
- en: '**E5.2.7** The graph \(G\) is not connected. There is no path between vertex
    1 and vertex 4, indicating that the graph is not connected.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.7** 图 \(G\) 是不连通的。顶点 1 和顶点 4 之间没有路径，这表明图是不连通的。'
- en: '**E5.2.9** The number of connected components is 1\. There is a path between
    every pair of vertices, so the graph is connected, having only one connected component.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.9** 连通分量的数量是 1。每对顶点之间都存在路径，因此图是连通的，只有一个连通分量。'
- en: '**E5.2.11**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.11**'
- en: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if vertex \(i\) is incident to edge \(j\), and 0 otherwise.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 入口 \(B_{ij}\) 为 1 如果顶点 \(i\) 与边 \(j\) 相邻，否则为 0。
- en: '**E5.2.13**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.13**'
- en: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if edge \(j\) leaves vertex \(i\), -1 if edge \(j\)
    enters vertex \(i\), and 0 otherwise.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 入口 \(B_{ij}\) 为 1 如果边 \(j\) 离开顶点 \(i\)，为 -1 如果边 \(j\) 进入顶点 \(i\)，否则为 0。
- en: '**E5.2.15** The Petersen graph is 3-regular, as stated in the text.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.15** 彼得森图是 3-正则的，正如文本所述。'
- en: '**E5.3.1** We can find the eigenvectors of \(A\) and normalize them to get
    an orthonormal basis. The characteristic polynomial of \(A\) is \((5-\lambda)^2
    - 9 = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\), so the eigenvalues
    are 2 and 8\. For \(\lambda = 2\), an eigenvector is \(\begin{pmatrix} -1 \\ 1
    \end{pmatrix}\), and for \(\lambda = 8\), an eigenvector is \(\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\). Normalizing these vectors, we get the matrix'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.1** 我们可以找到 \(A\) 的特征向量并将它们归一化以得到一个正交基。\(A\) 的特征多项式是 \((5-\lambda)^2
    - 9 = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\)，因此特征值是 2 和 8。对于
    \(\lambda = 2\)，一个特征向量是 \(\begin{pmatrix} -1 \\ 1 \end{pmatrix}\)，对于 \(\lambda
    = 8\)，一个特征向量是 \(\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)。归一化这些向量，我们得到矩阵'
- en: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
- en: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
- en: '**E5.3.5** To find the eigenvalues, we solve the characteristic equation: \(\det(A
    - \lambda I) = \begin{vmatrix} 2-\lambda & -1 \\ -1 & 2-\lambda \end{vmatrix}
    = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = (\lambda - 1)(\lambda - 3) =
    0\). So the eigenvalues are \(\lambda_1 = 3\) and \(\lambda_2 = 1\). To find the
    eigenvectors, we solve \((A - \lambda_i I)\mathbf{v}_i = 0\) for each eigenvalue:
    For \(\lambda_1 = 3\): \(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1
    = \mathbf{0}\), which gives \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_1 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1
    \end{pmatrix}\). For \(\lambda_2 = 1\): \(\begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2
    = \mathbf{0}\), which gives \(\mathbf{v}_2 = c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_2 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1
    \end{pmatrix}\). To verify the variational characterization for \(\lambda_1\):
    \(R_A(\mathbf{v}_1) = \frac{\langle \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle
    \mathbf{v}_1, \mathbf{v}_1 \rangle} = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix}
    2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2
    - 1 - 1 + 2) = 3 = \lambda_1\). For any unit vector \(\mathbf{u} = \begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix}\), we have: \(R_A(\mathbf{u}) = \begin{pmatrix}
    \cos\theta & \sin\theta \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\), with equality
    when \(\theta = \frac{\pi}{4}\), which corresponds to \(\mathbf{u} = \mathbf{v}_1\).
    Thus, \(\lambda_1 = \max_{\mathbf{u} \neq \mathbf{0}} R_A(\mathbf{u})\).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.5** 要找到特征值，我们解特征方程：\(\det(A - \lambda I) = \begin{vmatrix} 2-\lambda
    & -1 \\ -1 & 2-\lambda \end{vmatrix} = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda
    + 3 = (\lambda - 1)(\lambda - 3) = 0\)。所以特征值是 \(\lambda_1 = 3\) 和 \(\lambda_2
    = 1\)。要找到特征向量，我们为每个特征值解 \((A - \lambda_i I)\mathbf{v}_i = 0\)：对于 \(\lambda_1 =
    3\)：\(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1 = \mathbf{0}\)，这给出
    \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)。归一化后，我们得到 \(\mathbf{v}_1
    = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)。对于 \(\lambda_2 = 1\)：\(\begin{pmatrix}
    1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2 = \mathbf{0}\)，这给出 \(\mathbf{v}_2 =
    c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)。归一化后，我们得到 \(\mathbf{v}_2 = \frac{1}{\sqrt{2}}\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\)。为了验证 \(\lambda_1\) 的变分特征：\(R_A(\mathbf{v}_1) = \frac{\langle
    \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle \mathbf{v}_1, \mathbf{v}_1 \rangle}
    = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 &
    2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2 - 1 - 1 +
    2) = 3 = \lambda_1\)。对于任何单位向量 \(\mathbf{u} = \begin{pmatrix} \cos\theta \\ \sin\theta
    \end{pmatrix}\)，我们有：\(R_A(\mathbf{u}) = \begin{pmatrix} \cos\theta & \sin\theta
    \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} \cos\theta
    \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\)，当 \(\theta
    = \frac{\pi}{4}\) 时取等号，这对应于 \(\mathbf{u} = \mathbf{v}_1\)。因此，\(\lambda_1 = \max_{\mathbf{u}
    \neq \mathbf{0}} R_A(\mathbf{u})\)。'
- en: '**E5.3.7** First, we find the eigenvalues corresponding to the given eigenvectors:
    \(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\), so \(\lambda_1 =
    3\). \(A\mathbf{v}_2 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \mathbf{v}_2\), so \(\lambda_2 =
    1\). \(A\mathbf{v}_3 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix}
    = 3\mathbf{v}_3\), so \(\lambda_3 = 3\).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.7** 首先，我们找到与给定特征向量对应的特征值：\(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0
    \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\
    1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix}
    = 3\mathbf{v}_1\)，所以 \(\lambda_1 = 3\)。\(A\mathbf{v}_2 = \begin{pmatrix} 1 & 2
    & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix}
    -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix}
    = \mathbf{v}_2\)，所以 \(\lambda_2 = 1\)。\(A\mathbf{v}_3 = \begin{pmatrix} 1 & 2
    & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
    = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix} = 3\mathbf{v}_3\)，所以 \(\lambda_3 =
    3\)。'
- en: So the eigenvalues are \(\lambda_1 = 3\), \(\lambda_2 = 1\), and \(\lambda_3
    = 3\). Note that \(\lambda_2\) is the second smallest eigenvalue.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特征值是 \(\lambda_1 = 3\), \(\lambda_2 = 1\), 和 \(\lambda_3 = 3\)。注意，\(\lambda_2\)
    是第二个最小的特征值。
- en: 'Now, let’s verify the variational characterization for \(\lambda_2\). Any vector
    \(\mathbf{u} \in V_2\) can be written as \(\mathbf{u} = c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2\) for some scalars \(c_1\) and \(c_2\). Then:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们验证 \(\lambda_2\) 的变分特征。任何向量 \(\mathbf{u} \in V_2\) 可以表示为 \(\mathbf{u}
    = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2\)，其中 \(c_1\) 和 \(c_2\) 是一些标量。然后：
- en: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), since \(\mathbf{v}_1\) and \(\mathbf{v}_2\)
    are orthonormal.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), 因为 \(\mathbf{v}_1\) 和 \(\mathbf{v}_2\)
    是正交归一的。
- en: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    since \(A\mathbf{v}_1 = 3\mathbf{v}_1\) and \(A\mathbf{v}_2 = \mathbf{v}_2\).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    因为 \(A\mathbf{v}_1 = 3\mathbf{v}_1\) 和 \(A\mathbf{v}_2 = \mathbf{v}_2\).
- en: 'Therefore, \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    for all \(\mathbf{u} \neq \mathbf{0}\) in \(V_2\), with equality when \(c_1 =
    0\). Thus: \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})
    = 1 = R_A(\mathbf{v}_2)\).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    对于 \(V_2\) 中所有 \(\mathbf{u} \neq \mathbf{0}\) 都成立，当 \(c_1 = 0\) 时取等号。因此：\(\lambda_2
    = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u}) = 1 = R_A(\mathbf{v}_2)\).
- en: So indeed, the second smallest eigenvalue \(\lambda_2\) satisfies the variational
    characterization \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})\).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第二小的特征值 \(\lambda_2\) 满足变分特征 \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u}
    \in V_2} R_A(\mathbf{u})\).
- en: '**E5.4.1** The degree matrix \(D\) is'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.1** 度矩阵 \(D\) 是'
- en: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
- en: 'The Laplacian matrix \(L\) is \(L = D - A\):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '拉普拉斯矩阵 \(L\) 是 \(L = D - A\):'
- en: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
- en: '**E5.4.3**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.3**'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
- en: '**E5.4.5** Let’s verify that \(\mathbf{y}_1\) and \(\mathbf{y}_2\) are eigenvectors
    of \(L\):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.5** 让我们验证 \(\mathbf{y}_1\) 和 \(\mathbf{y}_2\) 是 \(L\) 的特征向量：'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
- en: So, \(\mathbf{y}_1\) is an eigenvector with eigenvalue \(\mu_1 = 0\), and \(\mathbf{y}_2\)
    is an eigenvector with eigenvalue \(\mu_2 = 2 - \sqrt{2}\).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(\mathbf{y}_1\) 是一个特征值为 \(\mu_1 = 0\) 的特征向量，而 \(\mathbf{y}_2\) 是一个特征值为 \(\mu_2
    = 2 - \sqrt{2}\) 的特征向量。
- en: '**E5.4.7** The maximum degree of \(K_4\) is \(\bar{\delta} = 3\). Using the
    bounds \(\bar{\delta} + 1 \leq \mu_n \leq 2\bar{\delta}\), we have:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.7** \(K_4\) 的最大度数为 \(\bar{\delta} = 3\)。使用界限 \(\bar{\delta} + 1 \leq
    \mu_n \leq 2\bar{\delta}\)，我们得到：'
- en: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
- en: '**E5.4.9** The diagonal entry \(L_{ii}\) is the degree of vertex \(i\), and
    the off-diagonal entry \(L_{ij}\) (for \(i \neq j\)) is \(-1\) if vertices \(i\)
    and \(j\) are adjacent, and 0 otherwise. Thus, the sum of the entries in row \(i\)
    is'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.9** 对角线元素 \(L_{ii}\) 是顶点 \(i\) 的度数，非对角线元素 \(L_{ij}\)（对于 \(i \neq j\)）如果顶点
    \(i\) 和 \(j\) 相邻则为 \(-1\)，否则为0。因此，第 \(i\) 行元素之和'
- en: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
- en: '**E5.4.11** For any vector \(\mathbf{x} \in \mathbb{R}^n\), we have'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.11** 对于任何向量 \(\mathbf{x} \in \mathbb{R}^n\)，我们有'
- en: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
- en: Since this holds for all \(\mathbf{x}\), \(L_G\) is positive semidefinite.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这对所有 \(\mathbf{x}\) 都成立，\(L_G\) 是正半定的。
- en: '**E5.4.13** In a complete graph, each vertex has degree \(n-1\). Thus, the
    Laplacian matrix is \(L_G = nI - J\), where \(I\) is the identity matrix and \(J\)
    is the all-ones matrix. The eigenvalues of \(J\) are \(n\) (with multiplicity
    1) and, because \(J\) has rank one, 0 (with multiplicity \(n-1\)). Therefore,
    the eigenvalues of \(L_G\) are 0 (with multiplicity 1) and \(n\) (with multiplicity
    \(n-1\)).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.13** 在一个完全图中，每个顶点的度数为 \(n-1\)。因此，拉普拉斯矩阵是 \(L_G = nI - J\)，其中 \(I\) 是单位矩阵，\(J\)
    是全一矩阵。\(J\) 的特征值为 \(n\)（重数1）和，因为 \(J\) 的秩为1，0（重数 \(n-1\)）。因此，\(L_G\) 的特征值为0（重数1）和
    \(n\)（重数 \(n-1\)）。'
- en: '**E5.5.1** \(|E(S, S^c)| = 2\) (the edges between \(S\) and \(S^c\) are \(\{1,
    2\}\) and \(\{2, 3\}\)), and \(\min\{|S|, |S^c|\} = 1\). Therefore, \(\phi(S)
    = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}} = 2\).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.1** \(|E(S, S^c)| = 2\)（\(S\) 和 \(S^c\) 之间的边是 \(\{1, 2\}\) 和 \(\{2,
    3\}\)），且 \(\min\{|S|, |S^c|\} = 1\)。因此，\(\phi(S) = \frac{|E(S, S^c)|}{\min\{|S|,
    |S^c|\}} = 2\)。'
- en: '**E5.5.3** In a connected graph with \(n\) vertices, the numerator of the cut
    ratio is at least 1, and the denominator is at most \(n/2\), which is achieved
    by cutting the graph into two equal parts. Therefore, the smallest possible value
    of the isoperimetric number is \(\frac{1}{n/2} = \frac{2}{n}\). For \(n = 6\),
    this is \(\frac{1}{3}\).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.3** 在一个有 \(n\) 个顶点的连通图中，割比的上限至少为1，下限最多为 \(n/2\)，这是通过将图切成两个相等的部分来实现的。因此，等周数的最小可能值是
    \(\frac{1}{n/2} = \frac{2}{n}\)。对于 \(n = 6\)，这是 \(\frac{1}{3}\)。'
- en: '**E5.5.5** The Cheeger Inequality also states that \(\frac{\phi_G^2}{2\bar{\delta}}
    \leq \mu_2\). Therefore, \(\phi_G \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot
    4 \cdot 0.5} = 2\).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.5** 切比雪夫不等式还表明 \(\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2\)。因此，\(\phi_G
    \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot 4 \cdot 0.5} = 2\)。'
- en: '**E5.5.7** Let \(\mathbf{v}_1 = (1, 1, 1, 1)/2\), \(\mathbf{v}_2 = (-1, -1,
    1, 1)/2\), \(\mathbf{v}_3 = (1, -1, -1, 1)/2\), and \(\mathbf{v}_4 = (1, -1, 1,
    -1)/2\). These vectors form an orthonormal list. We can verify that these are
    eigenvectors of \(L\) and find their corresponding eigenvalues:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.7** 设 \(\mathbf{v}_1 = (1, 1, 1, 1)/2\)，\(\mathbf{v}_2 = (-1, -1, 1,
    1)/2\)，\(\mathbf{v}_3 = (1, -1, -1, 1)/2\)，和 \(\mathbf{v}_4 = (1, -1, 1, -1)/2\)。这些向量构成一个正交归一列表。我们可以验证这些是
    \(L\) 的特征向量，并找到它们对应的特征值：'
- en: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
- en: Therefore, the corresponding eigenvalues are \(\mu_1 = 0\), \(\mu_2 = 2\), \(\mu_3
    = 2\), and \(\mu_4 = 4\).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，相应的特征值是 \(\mu_1 = 0\)，\(\mu_2 = 2\)，\(\mu_3 = 2\)，和 \(\mu_4 = 4\)。
- en: '**E5.5.9** Using the Fiedler vector \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\), an
    order is \(\pi(1) = 1\), \(\pi(2) = 2\), \(\pi(3) = 3\), \(\pi(4) = 4\).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.9** 使用 Fiedler 向量 \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\)，一个顺序是 \(\pi(1)
    = 1\)，\(\pi(2) = 2\)，\(\pi(3) = 3\)，\(\pi(4) = 4\)。'
- en: '**E5.5.11** To find the isoperimetric number, we need to consider all possible
    cuts and find the minimum cut ratio.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.11** 为了找到等周数，我们需要考虑所有可能的切割并找到最小的切割比率。'
- en: 'Let’s consider all possible cuts:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑所有可能的切割：
- en: \(S = \{1\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，因此 \(\phi(S) =
    2\)。
- en: \(S = \{1, 2\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 2\), so \(\phi(S)
    = 1\).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 2\)，因此 \(\phi(S)
    = 1\)。
- en: \(S = \{1, 2, 3\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，因此 \(\phi(S)
    = 2\)。
- en: \(S = \{1, 2, 3, 4\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 0\), so
    \(\phi(S)\) is undefined.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3, 4\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 0\)，因此 \(\phi(S)\)
    是未定义的。
- en: etc.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等等。
- en: The minimum cut ratio is \(1\), achieved by the cut \(S = \{1, 2\}\). Therefore,
    the isoperimetric number of the graph is \(\phi_G = 1\).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最小切割比率是 \(1\)，由切割 \(S = \{1, 2\}\) 实现。因此，图的等周数是 \(\phi_G = 1\)。
- en: 'Comparing this to the results from E5.5.8 and E5.5.10:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将其与 E5.5.8 和 E5.5.10 的结果进行比较：
- en: In E5.5.8, we found that the Fiedler vector is either \((-1, -1, 1, 1)/2\),
    which suggests a cut separating vertices \(\{1, 2\}\) from \(\{3, 4\}\).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.8 中，我们发现 Fiedler 向量是 \((-1, -1, 1, 1)/2\)，这表明一个切割将顶点 \(\{1, 2\}\) 与 \(\{3,
    4\}\) 分隔开来。
- en: In E5.5.10, using the ordering based on the Fiedler vector, we found that the
    cut with the smallest ratio is \(S_2 = \{1, 2\}\), with a cut ratio of \(1\).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.10 中，使用基于 Fiedler 向量的排序，我们发现最小比率的切割是 \(S_2 = \{1, 2\}\)，切割比率为 \(1\)。
- en: Both the Fiedler vector and the spectral clustering algorithm based on it correctly
    identify the cut that achieves the isoperimetric number (Cheeger constant) of
    the graph.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Fiedler 向量和基于它的谱聚类算法都能正确地识别出实现图等周数（Cheeger 常数）的切割。
- en: 'Now, let’s compare the isoperimetric number to the bounds given by Cheeger’s
    inequality. From E5.5.7, we know that the second smallest eigenvalue of the Laplacian
    matrix is \(\mu_2 = 2\). The maximum degree of the graph is \(\bar{\delta} = 2\).
    Cheeger’s inequality states that:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将等周数与 Cheeger 不等式给出的界限进行比较。从 E5.5.7，我们知道拉普拉斯矩阵的第二个最小特征值是 \(\mu_2 = 2\)。图的度数最大值是
    \(\bar{\delta} = 2\)。Cheeger 不等式表明：
- en: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
- en: 'Plugging in the values, we get:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将值代入，我们得到：
- en: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
- en: 'which simplifies to:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 简化为：
- en: \[\frac{1}{16} \leq 2 \leq 2\]
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{1}{16} \leq 2 \leq 2\]
- en: We can see that the isoperimetric number \(\phi_G = 1\) satisfies the bounds
    given by Cheeger’s inequality.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到等周数 \(\phi_G = 1\) 满足Cheeger不等式给出的界限。
- en: '**E5.5.13**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.13**'
- en: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
- en: The degree matrix \(D\) is a diagonal matrix where each entry \(D_{ii}\) is
    the degree of vertex \(i\).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 度矩阵 \(D\) 是一个对角矩阵，其中每个条目 \(D_{ii}\) 是顶点 \(i\) 的度数。
- en: '**E5.5.15**'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.15**'
- en: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
- en: The cutset consists of edges between \(S\) and \(S^c\). The cut ratio \(\phi(S)\)
    is the size of the cutset divided by the size of the smaller subset.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 切割集由 \(S\) 和 \(S^c\) 之间的边组成。切割比 \(\phi(S)\) 是切割集的大小除以较小子集的大小。
- en: '**E5.5.17**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.17**'
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code creates and displays the graph with the cut edges highlighted in red.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建并显示带有红色高亮切割边的图。
- en: '**E5.6.1** The expected number of edges is \(\mathbb{E}[|E|] = \binom{n}{2}p
    = \binom{6}{2} \cdot 0.4 = 15 \cdot 0.4 = 6\).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.1** 期望边数为 \(\mathbb{E}[|E|] = \binom{n}{2}p = \binom{6}{2} \cdot 0.4
    = 15 \cdot 0.4 = 6\)。'
- en: '**E5.6.3** The expected number of triangles is \(\mathbb{E}[|T_3|] = \binom{n}{3}p^3
    = \binom{10}{3} \cdot 0.3^3 = 120 \cdot 0.027 = 3.24\). The expected triangle
    density is \(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3 = 0.3^3 = 0.027\).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.3** 期望三角形数量为 \(\mathbb{E}[|T_3|] = \binom{n}{3}p^3 = \binom{10}{3} \cdot
    0.3^3 = 120 \cdot 0.027 = 3.24\)。期望三角形密度为 \(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3
    = 0.3^3 = 0.027\)。'
- en: '**E5.6.5** The block assignment matrix \(Z\) is given by:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.5** 块分配矩阵 \(Z\) 给出如下：'
- en: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
- en: '**E5.6.7** The degree of a vertex in \(G(4, 0.5)\) follows a binomial distribution
    \(\mathrm{Bin}(3, 0.5)\). The probabilities are:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.7** 在 \(G(4, 0.5)\) 中，顶点的度数遵循二项分布 \(\mathrm{Bin}(3, 0.5)\)。概率如下：'
- en: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
- en: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
- en: '**E5.6.9** The variance is \(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot
    (1 - p) = 3 \cdot 0.5 \cdot 0.5 = 0.75\).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.9** 方差为 \(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot (1 - p) = 3
    \cdot 0.5 \cdot 0.5 = 0.75\)。'
- en: '**E5.6.11** Since vertex 2 is in block \(C_1\) and vertex 4 is in block \(C_2\),
    the probability of an edge between them is \(b_{1,2} = 1/4\).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.11** 由于顶点2在块 \(C_1\) 中，顶点4在块 \(C_2\) 中，它们之间边的概率为 \(b_{1,2} = 1/4\)。'
- en: '**E5.6.13** The expected degree of each vertex is \((p+q)n/2 = (1)(8)/2 = 4\).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.13** 每个顶点的期望度数为 \((p+q)n/2 = (1)(8)/2 = 4\)。'
- en: '**E5.6.15** Let \(A_{i,j}\) be the indicator random variable for the presence
    of edge \(\{i,j\}\). Then the number of edges is \(X = \sum_{i<j} A_{i,j}\). Since
    the edges are independent,'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.15** 设 \(A_{i,j}\) 为边 \(\{i,j\}\) 存在的指示随机变量。那么边的数量为 \(X = \sum_{i<j}
    A_{i,j}\)。由于边是独立的，'
- en: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
- en: 5.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.5\. 学习成果[#](#learning-outcomes "链接到这个标题")
- en: Define undirected and directed graphs, and identify their key components such
    as vertices, edges, paths, and cycles.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无向图和有向图，并识别它们的关键组件，如顶点、边、路径和环。
- en: Recognize special types of graphs, including cliques, trees, forests, and directed
    acyclic graphs (DAGs).
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别特殊类型的图，包括完全图、树、森林和有向无环图（DAGs）。
- en: Determine the connectivity of a graph and identify its connected components.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定图的连通性并识别其连通分量。
- en: Construct the adjacency matrix, incidence matrix, and Laplacian matrix representations
    of a graph.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建图的邻接矩阵、关联矩阵和拉普拉斯矩阵表示。
- en: Prove key properties of the Laplacian matrix, such as symmetry and positive
    semidefiniteness.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明拉普拉斯矩阵的关键性质，如对称性和正半定性。
- en: Extend the concepts of graphs and their matrix representations to weighted graphs.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图及其矩阵表示的概念扩展到加权图。
- en: Implement graph representations and algorithms using the NetworkX package in
    Python.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python中的NetworkX包实现图表示和算法。
- en: Apply graph theory concepts to model and analyze real-world networks and relationships.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图论概念应用于建模和分析现实世界的网络和关系。
- en: Outline the proof of the Spectral Theorem using a sequence of orthogonal transformations
    to diagonalize a matrix.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一系列正交变换对矩阵进行对角化的方法概述谱定理的证明。
- en: Define the Rayleigh quotient and explain its relationship to eigenvectors and
    eigenvalues.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义雷利商并解释它与特征向量和特征值的关系。
- en: Prove the variational characterizations of the largest, smallest, and second
    smallest eigenvalues of a symmetric matrix using the Rayleigh quotient.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用雷利商证明对称矩阵的最大、最小和第二小特征值的变分特征。
- en: State the Courant-Fischer Theorem and interpret its local and global formulas
    for the eigenvalues of a symmetric matrix.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Courant-Fischer定理，并解释其局部和全局公式在表征对称矩阵特征值方面的含义。
- en: Apply the Courant-Fischer Theorem to characterize the third smallest eigenvalue
    of a symmetric matrix.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用Courant-Fischer定理来表征对称矩阵的第三小特征值。
- en: State the key properties of the Laplacian matrix, including symmetry, positive
    semidefiniteness, and the constant eigenvector associated with the zero eigenvalue.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述拉普拉斯矩阵的关键性质，包括对称性、正半定性和与零特征值相关的常数特征向量。
- en: Prove the relationship between graph connectivity and the second smallest eigenvalue
    (algebraic connectivity) of the Laplacian matrix.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明图连通性与拉普拉斯矩阵的第二小特征值（代数连通性）之间的关系。
- en: Derive bounds on the largest eigenvalue of the Laplacian matrix using the maximum
    degree of the graph.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图的最大度数推导拉普拉斯矩阵最大特征值的界限。
- en: Formulate the variational characterization of the second smallest eigenvalue
    of the Laplacian matrix as a constrained optimization problem.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将拉普拉斯矩阵第二小特征值的变分特征表述为一个约束优化问题。
- en: Explain how the eigenvectors of the Laplacian matrix can be used for graph drawing
    and revealing the underlying geometry of the graph, using the variational characterization.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释如何使用拉普拉斯矩阵的特征向量进行图绘制并揭示图的潜在几何结构，使用变分特征。
- en: Compute the Laplacian matrix and its eigenvalues and eigenvectors for simple
    graphs, and interpret the results in terms of graph connectivity and geometry.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算简单图的拉普拉斯矩阵及其特征值和特征向量，并从图连通性和几何的角度解释结果。
- en: Compute the cut ratio and the isoperimetric number (Cheeger constant) for a
    given graph cut.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定图切割的切割比和等周数（Cheeger常数）。
- en: State the Cheeger Inequality and explain its significance in relating the isoperimetric
    number to the second smallest Laplacian eigenvalue.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Cheeger不等式，并解释其在将等周数与第二小拉普拉斯特征值相关联方面的意义。
- en: Describe the main steps of the graph-cutting algorithm based on the Fiedler
    vector.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述基于Fiedler向量的图切割算法的主要步骤。
- en: Analyze the performance guarantees of the Fiedler vector-based graph-cutting
    algorithm and compare them to the optimal cut.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析基于Fiedler向量的图切割算法的性能保证，并将其与最优切割进行比较。
- en: Apply spectral clustering techniques to identify communities within a graph,
    and evaluate the quality of the resulting partitions.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用谱聚类技术来识别图中的社区，并评估结果分区的好坏。
- en: Formulate the minimum bisection problem as a discrete optimization problem and
    relax it into a continuous optimization problem related to the Laplacian matrix.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将最小二分问题表述为一个离散优化问题，并将其松弛为一个与拉普拉斯矩阵相关的连续优化问题。
- en: Define the inhomogeneous Erdős-Rényi (ER) random graph model and explain how
    it generalizes the standard ER model.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义非齐次Erdős-Rényi（ER）随机图模型，并解释它如何推广标准ER模型。
- en: Generate inhomogeneous ER graphs and analyze their properties, such as edge
    density and the probability of connectivity, using Python and NetworkX.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python和NetworkX生成非齐次ER图，并分析其性质，如边密度和连通概率。
- en: Calculate the expected number of edges and triangles in an ER random graph.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算ER随机图中边的期望数量和三角形的概率。
- en: Describe the stochastic blockmodel (SBM) and its role in creating random graphs
    with planted partitions, and explain how it relates to the concept of homophily.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述随机块模型（SBM）及其在创建具有植入划分的随机图中的作用，并解释它与同质性的关系。
- en: Construct SBMs with specified block assignments and edge probabilities, and
    visualize the resulting graphs using Python and NetworkX.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建具有指定块分配和边概率的SBM，并使用Python和NetworkX可视化结果图。
- en: Compute the expected adjacency matrix of an SBM given the block assignment matrix
    and connection probabilities.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定块分配矩阵和连接概率的SBM的期望邻接矩阵。
- en: Apply spectral clustering algorithms to SBMs and evaluate their performance
    in recovering the ground truth community structure.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将谱聚类算法应用于SBM，并评估其在恢复地面真实社区结构方面的性能。
- en: Analyze the simplified symmetric stochastic blockmodel (SSBM) and derive the
    spectral decomposition of its expected adjacency matrix.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析简化的对称随机块模型（SSBM）并推导其期望邻接矩阵的谱分解。
- en: Explain the relationship between the eigenvectors of the expected Laplacian
    matrix and the community structure in the SSBM.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释期望拉普拉斯矩阵的特征向量与SSBM中的社区结构之间的关系。
- en: Investigate the behavior of the eigenvalues of the Laplacian matrix for large
    random graphs and discuss the connection to random matrix theory.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究大型随机图拉普拉斯矩阵的特征值的行为，并讨论与随机矩阵理论的联系。
- en: \(\aleph\)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 5.8.2\. Additional sections[#](#additional-sections "Link to this heading")
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8.2\. 其他部分[#](#additional-sections "链接到本标题")
- en: 5.8.2.1\. Spectral properties of SBM[#](#spectral-properties-of-sbm "Link to
    this heading")
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.1\. SBM的谱性质[#](#spectral-properties-of-sbm "链接到本标题")
- en: The SBM provides an alternative explanation for the efficacy of spectral clustering.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: SBM为谱聚类的有效性提供了一个替代解释。
- en: 'We use a toy version of the model. Specifically, we assume that:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用模型的一个玩具版本。具体来说，我们假设：
- en: The number of vertices \(n\) is even.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点数 \(n\) 是偶数。
- en: Vertices \(1,\ldots,n/2\) are in block \(C_1\) while vertices \(n/2+1,\ldots,n\)
    are in block \(C_2\).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点 \(1,\ldots,n/2\) 在块 \(C_1\) 中，而顶点 \(n/2+1,\ldots,n\) 在块 \(C_2\) 中。
- en: The intra-block connection probability is \(b_{1,1} = b_{2,2} = p\) and the
    inter-block connection probability is \(b_{1,2} = b_{2,1} = q < p\), with \(p,
    q \in (0,1)\).
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块内连接概率是 \(b_{1,1} = b_{2,2} = p\)，块间连接概率是 \(b_{1,2} = b_{2,1} = q < p\)，其中 \(p,
    q \in (0,1)\)。
- en: We allow self-loops, whose probability are the intra-block connection probability.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们允许自环，其概率是块内连接概率。
- en: In that case, the matrix \(M\) is the block matrix
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在那种情况下，矩阵 \(M\) 是一个分块矩阵
- en: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
- en: where \(J \in \mathbb{R}^{n/2 \times n/2}\) is the all-one matrix. We refer
    to this model as the symmetric stochastic blockmodel (SSBM).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(J \in \mathbb{R}^{n/2 \times n/2}\) 是全一矩阵。我们称这个模型为对称随机块模型（SSBM）。
- en: The matrix \(M\) is symmetric. Hence it has a spectral decomposition. It is
    straightforward to compute. Let \(\mathbf{1}_m\) be the all-one vector of size
    \(m\).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 是对称的。因此它有一个谱分解。计算是直接的。令 \(\mathbf{1}_m\) 为大小为 \(m\) 的全一向量。
- en: '**LEMMA** **(Spectral Decomposition of SSBM)** Consider the matrix \(M\) above.
    Let'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(SSBM的谱分解)** 考虑上面的矩阵 \(M\)。令'
- en: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{and}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{和}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: Let \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) be an orthonormal basis of \((\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\})^\perp\). Denote by \(Q\) the matrix whose columns are \(\mathbf{q}_1,\ldots,\mathbf{q}_n\).
    Let
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) 为 \((\mathrm{span}\{\mathbf{q}_1, \mathbf{q}_2\})^\perp\)
    的一个正交归一基。记 \(Q\) 为列向量分别为 \(\mathbf{q}_1,\ldots,\mathbf{q}_n\) 的矩阵。令
- en: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{and} \quad \lambda_2 = \frac{p
    - q}{2} n. \]
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{和} \quad \lambda_2 = \frac{p -
    q}{2} n. \]
- en: Let \(\lambda_3,\ldots,\lambda_n = 0\). Denote by \(\Lambda\) the diagonal matrix
    with diagonal entries \(\lambda_1,\ldots,\lambda_n\).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 令 \(\lambda_3,\ldots,\lambda_n = 0\)。记 \(\Lambda\) 为对角线元素为 \(\lambda_1,\ldots,\lambda_n\)
    的对角矩阵。
- en: Then a spectral decomposition of \(M\) is given by
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然后给出了 \(M\) 的一个谱分解
- en: \[ M = Q \Lambda Q^T. \]
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: \[ M = Q \Lambda Q^T. \]
- en: In particular, \(\mathbf{q}_i\) is an eigenvector of \(M\) with eigenvalue \(\lambda_i\).
    \(\flat\)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，\(\mathbf{q}_i\) 是 \(M\) 的一个特征向量，其特征值为 \(\lambda_i\)。\(\flat\)
- en: '*Proof:* We start with \(\mathbf{q}_1\) and note that by the formula for the
    multiplication of block matrices and the definition of \(J\)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*：我们从 \(\mathbf{q}_1\) 开始，并注意到根据分块矩阵的乘法公式和 \(J\) 的定义'
- en: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
- en: Similarly
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 同样
- en: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
- en: Matrix \(M\) has rank 2 since it only has two distinct columns (assuming \(p
    \neq q\)). By the *Spectral Theorem*, there is an orthonormal basis of eigenvectors.
    We have shown that \(\mathbf{q}_1\) and \(\mathbf{q}_2\) are eigenvectors with
    nonzero eigenvalues (again using that \(p \neq q\)). So the remaining eigenvectors
    must form a basis of the orthogonal complement of \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) and they must have eigenvalue \(0\) since they lie in the null
    space. In particular,
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 的秩为 2，因为它只有两列是不同的（假设 \(p \neq q\)）。根据**谱定理**，存在一个正交基。我们已经证明了 \(\mathbf{q}_1\)
    和 \(\mathbf{q}_2\) 是具有非零特征值的特征向量（再次使用 \(p \neq q\)）。因此，剩余的特征向量必须构成 \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) 的正交补的基，并且它们必须具有特征值 \(0\)，因为它们位于零空间中。特别是，
- en: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
- en: That proves the claim. \(\square\)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了该命题。\(\square\)
- en: Why is this relevant to graph cutting? We first compute the expected Laplacian
    matrix. For this we need to expected degree of each vertex. This is obtained as
    follows
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这与图切割相关？我们首先计算期望的拉普拉斯矩阵。为此，我们需要每个顶点的期望度。这可以通过以下方式获得
- en: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
- en: where we counted the self-loop (if present) once. The same holds for the other
    vertices. So
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们只计算了自环（如果存在）一次。对于其他顶点也是如此。因此
- en: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
- en: For any eigenvector \(\mathbf{q}_i\) of \(M\), we note that
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于\(M\)的任意特征向量\(\mathbf{q}_i\)，我们注意到
- en: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
- en: that is, \(\mathbf{q}_i\) is also an eigenvector of \(\overline{L}\). Its eigenvalues
    are therefore
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 即，\(\mathbf{q}_i\)也是\(\overline{L}\)的一个特征向量。因此，它的特征值是
- en: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
- en: When \(p > q\), \(q n\) is the second smallest eigenvalue of \(\overline{L}\)
    with corresponding eigenvector
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当\(p > q\)时，\(q n\)是\(\overline{L}\)的第二小特征值，对应的特征向量
- en: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: 'The key observation:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 关键观察：
- en: The eigenvector corresponding to the second smallest eigenvalue of \(\overline{L}\)
    perfectly encodes the community structure by assigning \(1/\sqrt{n}\) to the vertices
    in block \(C_1\) and \(-1/\sqrt{n}\) to the vertices in block \(C_2\)!
  id: totrans-183
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与\(\overline{L}\)的第二小特征值对应的特征向量完美地通过将\(1/\sqrt{n}\)分配给块\(C_1\)中的顶点，将\(-1/\sqrt{n}\)分配给块\(C_2\)中的顶点来编码社区结构！
- en: Now, in reality, we do not get to observe \(\overline{L}\). Instead we compute
    the actual Laplacian \(L\), a random matrix whose expectation if \(\overline{L}\).
    But it turns out that, for large \(n\), the eigenvectors of \(L\) corresponding
    to its two smallest eigenvalues are close to \(\mathbf{q}_1\) and \(\mathbf{q}_2\).
    Hence we can recover the community structure approximately from \(L\). This is
    far from obvious since \(L\) and \(\overline{L}\) are very different matrices.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在现实中，我们无法观察到\(\overline{L}\)。相反，我们计算实际的拉普拉斯算子\(L\)，这是一个期望为\(\overline{L}\)的随机矩阵。但结果证明，对于大的\(n\)，\(L\)对应其两个最小特征值的特征向量接近\(\mathbf{q}_1\)和\(\mathbf{q}_2\)。因此，我们可以从\(L\)中近似恢复社区结构。这远非显而易见，因为\(L\)和\(\overline{L}\)是两个非常不同的矩阵。
- en: A formal proof of this claim is beyond this course. But we illustrate it numerically
    next.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这个断言的正式证明超出了本课程的范围。但我们将通过数值方法来展示它。
- en: '**NUMERICAL CORNER:** We first construct the block assignment and matrix \(M\)
    in the case of SSBM.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：** 我们首先在SSBM的情况下构建块分配和矩阵\(M\)。'
- en: '[PRE1]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here is an example.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子。
- en: '[PRE2]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The eigenvectors and eigenvalues of the Laplacian in this case are:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，拉普拉斯算子的特征向量和特征值是：
- en: '[PRE5]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The first eigenvalue is roughly \(0\) as expected with an eigenvector which
    is proportional to the all-one vector. The second eigenvalue is somewhat close
    to the expected \(q n = 0.2 \cdot 10 = 2\) with an eigenvector that has different
    signs on the two blocks. This is consistent with our prediction.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，第一个特征值大约为\(0\)，对应的特征向量与全一向量成比例。第二个特征值与预期的\(q n = 0.2 \cdot 10 = 2\)相当接近，对应的特征向量在两个块上有不同的符号。这与我们的预测一致。
- en: The eigenvalues exhibit an interesting behavior that is common for random matrices.
    This is easier to see for larger \(n\).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值表现出随机矩阵中常见的有趣行为。对于较大的\(n\)，这更容易看出。
- en: '[PRE12]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
- en: The first two eigenvalues are close to \(0\) and \(0.2 \cdot 100 = 20\) as expected.
    The rest of the eigenvalues are centered around \( (0.2 + 0.8) 100 /2 = 50\),
    but they are quite spread out, with a density resembling a half-circle. This is
    related to [Wigner’s semicircular law](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)
    which plays a key role in random matrix theory.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个特征值接近\(0\)和\(0.2 \cdot 100 = 20\)，正如预期的那样。其余的特征值围绕\( (0.2 + 0.8) 100 /2 =
    50\)，但它们分布得很广，密度类似于半圆。这与[Wigner的半圆定律](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)有关，这在随机矩阵理论中起着关键作用。
- en: \(\unlhd\)
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.8.2.2\. Weyl’s inequality[#](#weyls-inequality "Link to this heading")
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.2\. Weyl的不等式[#](#weyls-inequality "链接到这个标题")
- en: We prove an inequality on the sensitivity of eigenvalues which is useful in
    certain applications.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们证明了关于特征值敏感性的一个不等式，这在某些应用中是有用的。
- en: For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), we let \(\lambda_j(C)\),
    \(j=1, \ldots, d\), be the eigenvalues of \(C\) in non-increasing order with corresponding
    orthonormal eigenvectors \(\mathbf{v}_j\), \(j=1, \ldots, d\). The following lemma
    is one version of what is known as *Weyl’s Inequality*.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，我们让 \(\lambda_j(C)\)，\(j=1, \ldots,
    d\)，是 \(C\) 的非递减顺序特征值，对应正交归一特征向量 \(\mathbf{v}_j\)，\(j=1, \ldots, d\)。以下引理是所谓 *Weyl
    不等式* 的一种形式。
- en: '**LEMMA** **(Weyl)** Let \(A \in \mathbb{R}^{d \times d}\) and \(B \in \mathbb{R}^{d
    \times d}\) be symmetric matrices. Then, for all \(j=1, \ldots, d\),'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(Weyl)** 设 \(A \in \mathbb{R}^{d \times d}\) 和 \(B \in \mathbb{R}^{d
    \times d}\) 是对称矩阵。那么，对于所有 \(j=1, \ldots, d\)，'
- en: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
- en: where \(\|C\|_2\) is the induced \(2\)-norm of \(C\). \(\flat\)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\|C\|_2\) 是 \(C\) 的诱导 \(2\)-范数。\(\flat\)
- en: '*Proof idea:* We use the extremal characterization of the eigenvalues together
    with a dimension argument.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们使用特征值的极值特征与维度论证。'
- en: '*Proof:* For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), define the
    subspaces'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，定义子空间'
- en: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{and}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{和}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
- en: where \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) form an orthonormal basis of eigenvectors
    of \(C\). Let \(H = B - A\). We prove only the upper bound. The other direction
    follows from interchanging the roles of \(A\) and \(B\). Because
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) 构成 \(C\) 的特征向量的正交归一基。令 \(H = B - A\)。我们只证明上界。其他方向可以通过交换
    \(A\) 和 \(B\) 的角色得到。因为
- en: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
- en: it it can be shown (Try it!) that
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）：
- en: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
- en: Hence the \(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) is non-empty. Let
    \(\mathbf{v}\) be a unit vector in that intersection.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) 非空。令 \(\mathbf{v}\) 是该交集中的一个单位向量。
- en: By *Courant-Fischer*,
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 *Courant-Fischer*，
- en: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
- en: Moreover, by *Cauchy-Schwarz*, since \(\|\mathbf{v}\|=1\)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，根据 *Cauchy-Schwarz*，由于 \(\|\mathbf{v}\|=1\)
- en: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
- en: which proves the claim. \(\square\)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了命题。 \(\square\)
- en: 5.8.2.3\. Weighted case[#](#weighted-case "Link to this heading")
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.3\. 加权情况[#](#weighted-case "链接到本标题")
- en: The concepts we have introduced can also be extended to weighted graphs, that
    is, graphs with weights on the edges. These weights might be a measure of the
    strength of the connection for instance. In this section, we briefly describe
    this extension, which is the basis for a [discrete calculus](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所介绍的概念也可以扩展到加权图，即具有边权重的图。这些权重可能是连接强度的度量。在本节中，我们简要描述这种扩展，这是 [离散微积分](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs)
    的基础。
- en: '**DEFINITION** **(Weighted Graph or Digraph)** A weighted graph (or weighted
    digraph) is a triple \(G = (V, E, w)\) where \((V, E)\) is a graph (or directed
    graph) and \(w : E \to \mathbb{R}_+\) is a function that assigns positive real
    weights to the edges. For ease of notation, we write \(w_e = w_{ij} = w(i,j)\)
    for the weight of edge \(e = \{i,j\}\) (or \(e = (i,j)\) in the directed case).
    \(\natural\)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图或有向图)** 加权图（或加权有向图）是一个三元组 \(G = (V, E, w)\)，其中 \((V, E)\) 是一个图（或有向图），且
    \(w : E \to \mathbb{R}_+\) 是一个函数，它将正实数权重分配给边。为了方便起见，我们写 \(w_e = w_{ij} = w(i,j)\)
    表示边 \(e = \{i,j\}\)（或在有向情况下 \(e = (i,j)\)）的权重。\(\natural\)'
- en: As we did for graphs, we denote the vertices \(\{1,\ldots, n\}\) and the edges
    \(\{e_1,\ldots, e_{m}\}\), where \(n = |V|\) and \(m =|E|\). Properties of graphs
    can be generalized naturally. For instance, one defines the degree of a vertex
    \(i\) as, in the undirected case,
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如同我们对图所做的那样，我们表示顶点 \(\{1,\ldots, n\}\) 和边 \(\{e_1,\ldots, e_{m}\}\)，其中 \(n =
    |V|\) 和 \(m =|E|\)。图的性质可以自然地推广。例如，我们定义顶点 \(i\) 的度为，在无向情况下，
- en: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
- en: Similarly, in the directed case, the out-degree and in-degree are
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在有向情况下，出度和入度如下
- en: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{and} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{和} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
- en: In the undirected case, the adjacency matrix is generalized as follows. (A similar
    generalization holds for the directed case.)
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在无向情况下，邻接矩阵的推广如下。（对于有向情况也有类似的推广。）
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Graph)** Let \(G = (V, E, w)\)
    be a weighted graph with \(n = |V|\) vertices. The adjacency matrix \(A\) of \(G\)
    is the \(n\times n\) symmetric matrix defined as'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图的邻接矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点的加权图。\(G\) 的邻接矩阵
    \(A\) 是一个 \(n\times n\) 的对称矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: A similar generalization holds for the directed case.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有向情况，也有类似的推广。
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Digraph)** Let \(G = (V, E,
    w)\) be a weighted digraph with \(n = |V|\) vertices. The adjacency matrix \(A\)
    of \(G\) is the \(n\times n\) matrix defined as'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权有向图的邻接矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点的加权有向图。\(G\)
    的邻接矩阵 \(A\) 是一个 \(n\times n\) 的矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: '**Laplacian matrix for weighted graphs** In the case of a weighted graph, the
    Laplacian can then be defined as follows.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权图的拉普拉斯矩阵** 在加权图的情况下，拉普拉斯矩阵可以定义为以下。'
- en: '**DEFINITION** **(Laplacian for Weighted Graph)** Let \(G = (V, E, w)\) be
    a weighted graph with \(n = |V|\) vertices and adjacency matrix \(A\). Let \(D
    = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) be the weighted degree matrix.
    The Laplacian matrix associated to \(G\) is defined as \(L = D - A\). \(\natural\)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图的拉普拉斯矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点和邻接矩阵 \(A\)
    的加权图。设 \(D = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) 为加权度矩阵。与 \(G\) 相关的拉普拉斯矩阵定义为
    \(L = D - A\)。 \(\natural\)'
- en: It can be shown (Try it!) that the Laplacian quadratic form satisfies in the
    weighted case
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）在加权情况下拉普拉斯二次型满足
- en: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\).
- en: 'As a positive semidefinite matrix (Exercise: Why?), the weighted Laplacian
    has an orthonormal basis of eigenvectors with nonnegative eigenvalues that satisfy
    the variational characterization we derived above. In particular, if we denote
    the eigenvalues \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\), it follows from
    *Courant-Fischer* that'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 作为正半定矩阵（练习：为什么？），加权拉普拉斯矩阵具有正交归一的特征向量基，其特征值非负，满足我们上面推导出的变分特征。特别是，如果我们表示特征值为 \(0
    = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\)，根据 *Courant-Fischer*，可以得出
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
- en: If we generalize the cut ratio as
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将割比推广为
- en: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\) 和令
- en: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
- en: it can be shown (Try it!) that
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）在加权情况下
- en: \[ \mu_2 \leq 2 \phi_G \]
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 \leq 2 \phi_G \]
- en: as in the unweighted case.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 与无权情况相同。
- en: '**Normalized Laplacian** Other variants of the Laplacian matrix have also been
    studied. We introduced the normalized Laplacian next. Recall that in the weighted
    case, the degree is defined as \(\delta(i) = \sum_{j:\{i,j\} \in E} w_{i,j}\).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化拉普拉斯矩阵** 拉普拉斯矩阵的其他变体也已研究。接下来我们介绍了归一化拉普拉斯矩阵。回想一下，在加权情况下，度定义为 \(\delta(i)
    = \sum_{j:\{i,j\} \in E} w_{i,j}\)。'
- en: '**DEFINITION** **(Normalized Laplacian)** The normalized Laplacian of \(G =
    (V,E,w)\) with adjacency matrix \(A\) and degree matrix \(D\) is defined as'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（归一化拉普拉斯矩阵）** \(G = (V,E,w)\) 的归一化拉普拉斯矩阵，其邻接矩阵为 \(A\)，度矩阵为 \(D\)，定义为'
- en: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
- en: \(\natural\)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: Using our previous observations about multiplication by diagonal matrices, the
    entries of \(\mathcal{L}\) are
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前关于对角矩阵乘法的观察，\(\mathcal{L}\) 的项为
- en: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j} = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j} = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
- en: 'We also note the following relation to the Laplacian matrix:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到与拉普拉斯矩阵的以下关系：
- en: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
- en: 'We check that the normalized Laplacian is symmetric:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查归一化拉普拉斯矩阵是对称的：
- en: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
- en: It is also positive semidefinite. Indeed,
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 它也是正半定的。实际上，
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
- en: by the properties of the Laplacian matrix.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 通过拉普拉斯矩阵的性质。
- en: Hence by the *Spectral Theorem*, we can write
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据 *谱定理*，我们可以写出
- en: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
- en: where the \(\mathbf{z}_i\)s are orthonormal eigenvectors of \(\mathcal{L}\)
    and the eigenvalues satisfy \(0 \leq \eta_1 \leq \eta_2 \leq \cdots \leq \eta_n\).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{z}_i\) 是 \(\mathcal{L}\) 的正交特征向量，并且特征值满足 \(0 \leq \eta_1 \leq \eta_2
    \leq \cdots \leq \eta_n\).
- en: 'One more observation: because the constant vector is eigenvector of \(L\) with
    eigenvalue \(0\), we get that \(D^{1/2} \mathbf{1}\) is an eigenvector of \(\mathcal{L}\)
    with eigenvalue \(0\). So \(\eta_1 = 0\) and we set'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察：因为常量向量是 \(L\) 的特征向量，其特征值为 \(0\)，我们得到 \(D^{1/2} \mathbf{1}\) 是 \(\mathcal{L}\)
    的特征向量，其特征值为 \(0\)。因此 \(\eta_1 = 0\)，我们设
- en: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
- en: which makes \(\mathbf{z}_1\) into a unit norm vector.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 \(\mathbf{z}_1\) 成为一个单位范数向量。
- en: The relationship to the Laplacian matrix immediately implies (prove it!) that
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 与拉普拉斯矩阵的关系立即暗示（证明它！）：
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\).
- en: Through the change of variables
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 通过变量变换
- en: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
- en: '*Courant-Fischer* gives this time (Why?)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '*Courant-Fischer* 这次给出了（为什么？）'
- en: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
- en: For a subset of vertices \(S \subseteq V\), let
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顶点子集 \(S \subseteq V\)，令
- en: \[ |S|_w = \sum_{i \in S} \delta(i), \]
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |S|_w = \sum_{i \in S} \delta(i), \]
- en: which we refer to as the volume of \(S\). It is measure of the size of \(S\)
    weighted by the degrees.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其称为 \(S\) 的体积。这是 \(S\) 大小加权度数的度量。
- en: If we consider the normalized cut ratio, or bottleneck ratio,
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑归一化切割比率，或瓶颈比率，
- en: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\)，并令
- en: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
- en: it can be shown (Try it!) that
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试试看！）：
- en: \[ \eta_2 \leq 2 \phi^N_G. \]
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 \leq 2 \phi^N_G. \]
- en: The normalized cut ratio is similar to the cut ratio, except that the notion
    of balance of the cut is measured in terms of volume. Note that this concept is
    also useful in the unweighted case.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化切割比率与切割比率类似，不同之处在于切割的平衡性是以体积来衡量的。请注意，这个概念在无权情况下也很有用。
- en: We will an application of the normalized Laplacian later in this chapter.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面讨论归一化拉普拉斯的应用。
- en: 5.8.2.4\. Image segmentation[#](#image-segmentation "Link to this heading")
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.4\. 图像分割[#](#image-segmentation "链接到本标题")
- en: 'We give a different, more involved application of the ideas developed in this
    topic to image segmentation. Let us quote Wikipedia:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将给出这个主题中发展出的想法在图像分割上的不同、更复杂的应用。让我们引用维基百科：
- en: In computer vision, image segmentation is the process of partitioning a digital
    image into multiple segments (sets of pixels, also known as image objects). The
    goal of segmentation is to simplify and/or change the representation of an image
    into something that is more meaningful and easier to analyze. Image segmentation
    is typically used to locate objects and boundaries (lines, curves, etc.) in images.
    More precisely, image segmentation is the process of assigning a label to every
    pixel in an image such that pixels with the same label share certain characteristics.
  id: totrans-294
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在计算机视觉中，图像分割是将数字图像分割成多个段（像素集，也称为图像对象）的过程。分割的目的是简化图像的表示，或者将其改变为更有意义且更容易分析的形式。图像分割通常用于在图像中定位对象和边界（线条、曲线等）。更确切地说，图像分割是将标签分配给图像中的每个像素，使得具有相同标签的像素具有某些共同特征。
- en: Throughout, we will use the [`scikit-image`](https://scikit-image.org) library
    for processing images.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们将使用 `scikit-image` 库来处理图像。
- en: '[PRE14]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As an example, here is a picture of cell nuclei taken through optical microscopy
    as part of some medical experiment. It is taken from [here](https://www.kaggle.com/c/data-science-bowl-2018/data).
    Here we used the function [`skimage.io.imread`](https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread)
    to load an image from file.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 作为例子，这里是一张通过光学显微镜拍摄的细胞核图片，作为某些医学实验的一部分。图片来自 [这里](https://www.kaggle.com/c/data-science-bowl-2018/data)。在这里，我们使用了函数
    `skimage.io.imread` 从文件中加载图像。
- en: '[PRE15]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
- en: Suppose that, as part of this experiment, we have a large number of such images
    and need to keep track of the cell nuclei in some way (maybe count how many there
    are, or track them from frame to frame). A natural pre-processing step is to identify
    the cell nuclei in the image. We use image segmentation for this purpose.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在这个实验的一部分，我们有一大批这样的图像，并且需要以某种方式跟踪细胞核（也许计算有多少个，或者从一帧跟踪到另一帧）。一个自然的预处理步骤是识别图像中的细胞核。我们使用图像分割来完成这个目的。
- en: We will come back to the example below. Let us start with some further examples.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回到下面的例子。让我们先看看一些其他的例子。
- en: We will first work with the following [map of Wisconsin regions](https://www.dhs.wisconsin.gov/areaadmin/index.htm).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用以下 [威斯康星州地区地图](https://www.dhs.wisconsin.gov/areaadmin/index.htm)。
- en: '[PRE16]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
- en: A color image such as this one is encoded as a \(3\)-dimensional array (or [tensor](https://en.wikipedia.org/wiki/Tensor)),
    meaning that it is an array with \(3\) indices (unlike matrices which have only
    two indices).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的彩色图像被编码为 \(3\) 维数组（或 [张量](https://en.wikipedia.org/wiki/Tensor)），这意味着它具有
    \(3\) 个索引（与只有两个索引的矩阵不同）。
- en: '[PRE17]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first two indices capture the position of a pixel. The third index capture
    the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model). Put differently,
    each pixel in the image has three numbers (between 0 and 255) attached to it that
    encodes its color.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个索引捕获像素的位置。第三个索引捕获 [RGB 颜色模型](https://en.wikipedia.org/wiki/RGB_color_model)。换句话说，图像中的每个像素都附有三个（介于0到255之间）的数字，这些数字编码了它的颜色。
- en: 'For instance, at position \((300,400)\) the RGB color is:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在位置 \((300,400)\) 的 RGB 颜色是：
- en: '[PRE19]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
- en: To perform image segmentation using the spectral graph theory we have developed,
    we transform our image into a graph.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用我们开发的谱图理论进行图像分割，我们将图像转换成图。
- en: The first step is to coarsen the image by creating super-pixels, or regions
    of pixels that are close and have similar color. For this purpose, we will use
    [`skimage.segmentation.slic`](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic),
    which in essence uses \(k\)-means clustering on the color space to identify blobs
    of pixels that are in close proximity and have similar colors. It takes as imput
    a number of super-pixels desired (`n_segments`), a compactness parameter (`compactness`)
    and a smoothing parameter (`sigma`). The output is a label assignment for each
    pixel in the form of a \(2\)-dimensional array.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是通过创建超像素，即颜色相似且接近的像素区域，来对图像进行粗化。为此，我们将使用[`skimage.segmentation.slic`](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic)，它本质上是在颜色空间上使用\(k\)-means聚类来识别颜色相似且接近的像素块。它接受所需的超像素数量（`n_segments`）、紧密度参数（`compactness`）和光滑参数（`sigma`）作为输入。输出是每个像素的标签分配，形式为二维数组。
- en: 'On the choice of the parameter `compactness` via [scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过[scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic)选择参数`compactness`时：
- en: Balances color proximity and space proximity. Higher values give more weight
    to space proximity, making superpixel shapes more square/cubic. This parameter
    depends strongly on image contrast and on the shapes of objects in the image.
    We recommend exploring possible values on a log scale, e.g., 0.01, 0.1, 1, 10,
    100, before refining around a chosen value.
  id: totrans-317
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 平衡颜色接近度和空间接近度。较高的值会给空间接近度更多的权重，使超像素形状更接近正方形/立方体。此参数强烈依赖于图像对比度和图像中物体的形状。我们建议在选定值周围在对数尺度上探索可能的值，例如，0.01、0.1、1、10、100。
- en: The parameter `sigma` controls the level of [blurring](https://en.wikipedia.org/wiki/Gaussian_blur)
    applied to the image as a pre-processing step. In practice, experimentation is
    required to choose good parameters.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`sigma`控制对图像应用的前处理步骤中的模糊程度。在实践中，需要通过实验来选择合适的参数。
- en: '[PRE22]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: A neat way to vizualize the super-pixels is to use the function [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    which takes as input an image and an array of labels. In the mode `kind='avg'`,
    it outputs a new image where the color of each pixel is replaced with the average
    color of its label (that is, the average of the RGB color over all pixels with
    the same label). As they say, an image is worth a thousand words - let’s just
    see what it does.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数[`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)可视化超像素是一种巧妙的方法，该函数以图像和一个标签数组作为输入。在`kind='avg'`模式下，它输出一个新图像，其中每个像素的颜色被其标签的平均颜色所替代（即，所有具有相同标签的像素的RGB颜色的平均值）。正如他们所说，一张图片胜过千言万语——让我们看看它到底做了什么。
- en: '[PRE24]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
- en: Recall that our goal is to turn our original image into a graph. After the first
    step of creating super-pixels, the second step is to form a graph whose nodes
    are the super-pixels. Edges are added between adjacent super-pixels and a weight
    is given to each edge which reflects the difference in mean color between the
    two.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们的目标是把原始图像转换成图。在创建超像素的第一步之后，第二步是形成一个图，其节点是超像素。在相邻的超像素之间添加边，并为每条边分配一个权重，该权重反映了两个超像素之间平均颜色的差异。
- en: 'We use [`skimage.graph.rag_mean_color`](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color).
    In mode `similarity`, it uses the following weight formula (quoting the documentation):'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用[`skimage.graph.rag_mean_color`](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color)。在`similarity`模式下，它使用以下权重公式（引用文档）：
- en: The weight between two adjacent regions is exp(-d^2/sigma) where d=|c1-c2|,
    where c1 and c2 are the mean colors of the two regions. It represents how similar
    two regions are.
  id: totrans-328
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 两个相邻区域之间的权重是exp(-d^2/sigma)，其中d=|c1-c2|，c1和c2是两个区域的平均颜色。它表示两个区域之间的相似程度。
- en: The output, which is known as a region adjacency graph (RAG), is a `NetworkX`
    graph and can be manipulated using that package.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 输出，被称为区域邻接图（RAG），是一个`NetworkX`图，可以使用该包进行操作。
- en: '[PRE27]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
- en: '`scikit-image` also provides a more effective way of vizualizing a RAG, using
    the function [`skimage.future.graph.show_rag`](https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag).
    Here the graph is super-imposed on the image and the edge weights are depicted
    by their color.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-image`还提供了一个更有效的方式来可视化RAG，使用函数`skimage.future.graph.show_rag`。在这里，图被叠加在图像上，边权重通过颜色表示。'
- en: '[PRE28]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
- en: We can apply the spectral clustering techniques we have developed in this chapter.
    Next we compute a spectral decomposition of the weighted Laplacian and plot the
    eigenvalues.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以应用本章中开发的谱聚类技术。接下来，我们计算加权拉普拉斯算子的谱分解并绘制特征值。
- en: '[PRE29]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
- en: From the theory, this suggests that there are roughly 15 components in this
    graph. We project to \(15\) dimensions and apply \(k\)-means clustering to find
    segments. Rather than using our own implementation, we use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    from the [`scikit-learn`](https://scikit-learn.org/stable/index.html) library.
    That implementation uses the [\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)
    initialization, which is particularly effective in practice. A label assignment
    for each node can be accessed using `labels_`.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上看，这表明这个图中大约有15个组件。我们将投影到15个维度，并应用k-means聚类来找到分割区域。我们不是使用自己的实现，而是使用来自`scikit-learn`库的`sklearn.cluster.KMeans`。该实现使用[\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)初始化，这在实践中特别有效。每个节点的标签分配可以通过`labels_`访问。
- en: '[PRE32]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To vizualize the segmentation, we assign to each segment (i.e., collection
    of super-pixels) a random color. This can be done using [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    again, this time in mode `kind=''overlay''`. First, we assign to each pixel from
    the original image its label under this clustering. Recall that `labels1` assigns
    to each pixel its super-pixel (represented by a node of the RAG), so that applying
    `assign_seg` element-wise to `labels1` results is assigning a cluster to each
    pixel. In code:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化分割，我们为每个分割区域（即超像素集合）分配一个随机颜色。这可以通过再次使用`skimage.color.label2rgb`函数来实现，这次在模式`kind='overlay'`下。首先，我们将原始图像中的每个像素的标签分配给它在这个聚类下的标签。回想一下，`labels1`将每个像素分配给其超像素（由RAG的节点表示），因此将`assign_seg`逐元素应用于`labels1`的结果是将一个簇分配给每个像素。在代码中：
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
- en: As you can see, the result is reasonable but far from perfect.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，结果是合理的，但远非完美。
- en: For ease of use, we encapsulate the main steps above in sub-routines.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们将上述主要步骤封装在子例程中。
- en: '[PRE39]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Let’s try a more complicated image. This one is taken from [here](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个更复杂的图像。这张图片来自[这里](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/)。
- en: '[PRE43]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
- en: Recall that the choice of parameters requires significant fidgeting.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，参数的选择需要大量的调整。
- en: '[PRE44]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
- en: '[PRE45]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
- en: '[PRE46]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
- en: Again, the results are far from perfect - but not unreasonable.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，结果远非完美 - 但也不算不合理。
- en: Finally, we return to our medical example. We first reload the image and find
    super-pixels.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回到我们的医学示例。我们首先重新加载图像并找到超像素。
- en: '[PRE47]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
- en: We then form the weighted Laplacian and plot its eigenvalues. This time, about
    \(40\) dimensions seem appropriate.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们形成加权拉普拉斯算子并绘制其特征值。这次，大约 \(40\) 维看起来是合适的。
- en: '[PRE48]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
- en: '[PRE49]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
- en: This method is quite finicky. The choice of parameters affects the results significantly.
    You should see for yourself.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法相当挑剔。参数的选择会显著影响结果。您应该亲自看看。
- en: We mention that `scikit-image` has an implementation of a closely related method,
    Normalized Cut, [`skimage.graph.cut_normalized`](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized).
    Rather than performing \(k\)-means after projection, it recursively performs \(2\)-way
    cuts on the RAG and resulting subgraphs.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到 `scikit-image` 有一个与该方法密切相关的方法的实现，即归一化切割，`skimage.graph.cut_normalized`。[`skimage.graph.cut_normalized`](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized)。它不是在投影后执行
    \(k\)-means，而是在 RAG 和结果子图上递归执行双向切割。
- en: We try it next. The results are similar as you can see.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来尝试。结果如您所见，相似。
- en: '[PRE50]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
- en: There are many other image segmentation methods. See for example [here](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多其他图像分割方法。例如，请参阅[这里](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation)。
- en: 5.8.1\. Quizzes, solutions, code, etc.[#](#quizzes-solutions-code-etc "Link
    to this heading")
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8.1\. 问答，解答，代码等。[#](#quizzes-solutions-code-etc "链接到本标题")
- en: 5.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.1\. 仅代码。[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码的交互式 Jupyter 笔记本可以通过以下链接访问（推荐使用 Google Colab）。鼓励您对其进行尝试。一些建议的计算练习散布在其中。该笔记本也可以作为幻灯片查看。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
- en: 5.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.2\. 自我评估问答。[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以找到更全面的自我评估问答的网页版本。
- en: '[Section 5.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.2 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
- en: '[Section 5.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.3节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
- en: '[Section 5.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.4节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
- en: '[Section 5.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.5节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
- en: '[Section 5.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.6节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
- en: 5.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-393
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 本章自动生成的测验可以在此处访问（推荐使用Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
- en: 5.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.4\. 奇数练习题的解答[#](#solutions-to-odd-numbered-warm-up-exercises "链接到本标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在克劳德、双子星和ChatGPT的帮助下)*'
- en: '**E5.2.1** \(V = \{1, 2, 3, 4\}\), \(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\). This follows directly from the definition of a graph as a pair \(G =
    (V, E)\).'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.1** \(V = \{1, 2, 3, 4\}\)，\(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\)。这直接来自图作为一对\(G = (V, E)\)的定义。'
- en: '**E5.2.3** One possible path is \(1 \sim 2 \sim 4\). Its length is 2, since
    it consists of two edges.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.3** 一个可能的路径是\(1 \sim 2 \sim 4\)。它的长度是2，因为它由两个边组成。'
- en: '**E5.2.5** \(\delta^-(2) = 1\), \(\delta^+(2) = 2\). The in-degree of a vertex
    \(v\) is the number of edges with destination \(v\), and the out-degree is the
    number of edges with source \(v\).'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.5** \(\delta^-(2) = 1\)，\(\delta^+(2) = 2\)。顶点\(v\)的入度是目标为\(v\)的边的数量，出度是源为\(v\)的边的数量。'
- en: '**E5.2.7** The graph \(G\) is not connected. There is no path between vertex
    1 and vertex 4, indicating that the graph is not connected.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.7** 图\(G\)不是连通的。顶点1和顶点4之间没有路径，这表明图不是连通的。'
- en: '**E5.2.9** The number of connected components is 1\. There is a path between
    every pair of vertices, so the graph is connected, having only one connected component.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.9** 连通分量的数量是1。每对顶点之间都存在路径，因此图是连通的，只有一个连通分量。'
- en: '**E5.2.11**'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.11**'
- en: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if vertex \(i\) is incident to edge \(j\), and 0 otherwise.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 如果顶点\(i\)与边\(j\)相关联，则\(B_{ij}\)的值为1，否则为0。
- en: '**E5.2.13**'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.13**'
- en: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if edge \(j\) leaves vertex \(i\), -1 if edge \(j\)
    enters vertex \(i\), and 0 otherwise.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 如果边\(j\)离开顶点\(i\)，则\(B_{ij}\)的值为1；如果边\(j\)进入顶点\(i\)，则\(B_{ij}\)的值为-1；否则为0。
- en: '**E5.2.15** The Petersen graph is 3-regular, as stated in the text.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.15** 彼得森图是3-正则的，正如文本所述。'
- en: '**E5.3.1** We can find the eigenvectors of \(A\) and normalize them to get
    an orthonormal basis. The characteristic polynomial of \(A\) is \((5-\lambda)^2
    - 9 = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\), so the eigenvalues
    are 2 and 8\. For \(\lambda = 2\), an eigenvector is \(\begin{pmatrix} -1 \\ 1
    \end{pmatrix}\), and for \(\lambda = 8\), an eigenvector is \(\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\). Normalizing these vectors, we get the matrix'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.1** 我们可以找到\(A\)的特征向量，并将它们归一化以得到一个正交基。\(A\)的特征多项式是\((5-\lambda)^2 - 9
    = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\)，因此特征值是2和8。对于\(\lambda
    = 2\)，一个特征向量是\(\begin{pmatrix} -1 \\ 1 \end{pmatrix}\)，对于\(\lambda = 8\)，一个特征向量是\(\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\)。归一化这些向量，我们得到矩阵'
- en: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
- en: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
- en: '**E5.3.5** To find the eigenvalues, we solve the characteristic equation: \(\det(A
    - \lambda I) = \begin{vmatrix} 2-\lambda & -1 \\ -1 & 2-\lambda \end{vmatrix}
    = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = (\lambda - 1)(\lambda - 3) =
    0\). So the eigenvalues are \(\lambda_1 = 3\) and \(\lambda_2 = 1\). To find the
    eigenvectors, we solve \((A - \lambda_i I)\mathbf{v}_i = 0\) for each eigenvalue:
    For \(\lambda_1 = 3\): \(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1
    = \mathbf{0}\), which gives \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_1 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1
    \end{pmatrix}\). For \(\lambda_2 = 1\): \(\begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2
    = \mathbf{0}\), which gives \(\mathbf{v}_2 = c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_2 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1
    \end{pmatrix}\). To verify the variational characterization for \(\lambda_1\):
    \(R_A(\mathbf{v}_1) = \frac{\langle \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle
    \mathbf{v}_1, \mathbf{v}_1 \rangle} = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix}
    2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2
    - 1 - 1 + 2) = 3 = \lambda_1\). For any unit vector \(\mathbf{u} = \begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix}\), we have: \(R_A(\mathbf{u}) = \begin{pmatrix}
    \cos\theta & \sin\theta \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\), with equality
    when \(\theta = \frac{\pi}{4}\), which corresponds to \(\mathbf{u} = \mathbf{v}_1\).
    Thus, \(\lambda_1 = \max_{\mathbf{u} \neq \mathbf{0}} R_A(\mathbf{u})\).'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.5** 要找到特征值，我们解特征方程：\(\det(A - \lambda I) = \begin{vmatrix} 2-\lambda
    & -1 \\ -1 & 2-\lambda \end{vmatrix} = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda
    + 3 = (\lambda - 1)(\lambda - 3) = 0\). 因此，特征值是 \(\lambda_1 = 3\) 和 \(\lambda_2
    = 1\). 要找到特征向量，我们为每个特征值解 \((A - \lambda_i I)\mathbf{v}_i = 0\): 对于 \(\lambda_1
    = 3\): \(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1 = \mathbf{0}\)，这给出
    \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\). 归一化后，我们得到 \(\mathbf{v}_1
    = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1 \end{pmatrix}\). 对于 \(\lambda_2 =
    1\): \(\begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2 = \mathbf{0}\)，这给出
    \(\mathbf{v}_2 = c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\). 归一化后，我们得到 \(\mathbf{v}_2
    = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\). 要验证 \(\lambda_1\)
    的变分特征：\(R_A(\mathbf{v}_1) = \frac{\langle \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle
    \mathbf{v}_1, \mathbf{v}_1 \rangle} = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix}
    2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2
    - 1 - 1 + 2) = 3 = \lambda_1\). 对于任何单位向量 \(\mathbf{u} = \begin{pmatrix} \cos\theta
    \\ \sin\theta \end{pmatrix}\)，我们有：\(R_A(\mathbf{u}) = \begin{pmatrix} \cos\theta
    & \sin\theta \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\)，当 \(\theta
    = \frac{\pi}{4}\) 时取等号，这对应于 \(\mathbf{u} = \mathbf{v}_1\). 因此，\(\lambda_1 = \max_{\mathbf{u}
    \neq \mathbf{0}} R_A(\mathbf{u})\).'
- en: '**E5.3.7** First, we find the eigenvalues corresponding to the given eigenvectors:
    \(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\), so \(\lambda_1 =
    3\). \(A\mathbf{v}_2 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \mathbf{v}_2\), so \(\lambda_2 =
    1\). \(A\mathbf{v}_3 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix}
    = 3\mathbf{v}_3\), so \(\lambda_3 = 3\).'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.7** 首先，我们找到与给定特征向量对应的特征值：\(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0
    \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\
    1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix}
    = 3\mathbf{v}_1\), 所以 \(\lambda_1 = 3\). \(A\mathbf{v}_2 = \begin{pmatrix} 1 &
    2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix}
    -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix}
    = \mathbf{v}_2\), 所以 \(\lambda_2 = 1\). \(A\mathbf{v}_3 = \begin{pmatrix} 1 &
    2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
    = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix} = 3\mathbf{v}_3\), 所以 \(\lambda_3
    = 3\).'
- en: So the eigenvalues are \(\lambda_1 = 3\), \(\lambda_2 = 1\), and \(\lambda_3
    = 3\). Note that \(\lambda_2\) is the second smallest eigenvalue.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 所以特征值是 \(\lambda_1 = 3\), \(\lambda_2 = 1\), 和 \(\lambda_3 = 3\)。注意，\(\lambda_2\)
    是第二个最小的特征值。
- en: 'Now, let’s verify the variational characterization for \(\lambda_2\). Any vector
    \(\mathbf{u} \in V_2\) can be written as \(\mathbf{u} = c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2\) for some scalars \(c_1\) and \(c_2\). Then:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们验证 \(\lambda_2\) 的变分特征。任何向量 \(\mathbf{u} \in V_2\) 可以写成 \(\mathbf{u} =
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2\) 的形式，其中 \(c_1\) 和 \(c_2\) 是一些标量。然后：
- en: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), since \(\mathbf{v}_1\) and \(\mathbf{v}_2\)
    are orthonormal.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), 因为 \(\mathbf{v}_1\) 和 \(\mathbf{v}_2\)
    是正交归一的。
- en: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    since \(A\mathbf{v}_1 = 3\mathbf{v}_1\) and \(A\mathbf{v}_2 = \mathbf{v}_2\).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    因为 \(A\mathbf{v}_1 = 3\mathbf{v}_1\) 和 \(A\mathbf{v}_2 = \mathbf{v}_2\).
- en: 'Therefore, \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    for all \(\mathbf{u} \neq \mathbf{0}\) in \(V_2\), with equality when \(c_1 =
    0\). Thus: \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})
    = 1 = R_A(\mathbf{v}_2)\).'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    对于 \(V_2\) 中所有 \(\mathbf{u} \neq \mathbf{0}\) 都成立，当 \(c_1 = 0\) 时取等号。因此：\(\lambda_2
    = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u}) = 1 = R_A(\mathbf{v}_2)\).
- en: So indeed, the second smallest eigenvalue \(\lambda_2\) satisfies the variational
    characterization \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})\).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第二个最小的特征值 \(\lambda_2\) 确实满足变分特征 \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u}
    \in V_2} R_A(\mathbf{u})\).
- en: '**E5.4.1** The degree matrix \(D\) is'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.1** 度矩阵 \(D\) 是'
- en: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
- en: 'The Laplacian matrix \(L\) is \(L = D - A\):'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '拉普拉斯矩阵 \(L\) 是 \(L = D - A\):'
- en: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
- en: '**E5.4.3**'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.3**'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
- en: '**E5.4.5** Let’s verify that \(\mathbf{y}_1\) and \(\mathbf{y}_2\) are eigenvectors
    of \(L\):'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.5** 让我们验证 \(\mathbf{y}_1\) 和 \(\mathbf{y}_2\) 是 \(L\) 的特征向量：'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
- en: So, \(\mathbf{y}_1\) is an eigenvector with eigenvalue \(\mu_1 = 0\), and \(\mathbf{y}_2\)
    is an eigenvector with eigenvalue \(\mu_2 = 2 - \sqrt{2}\).
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(\mathbf{y}_1\) 是一个特征向量，其特征值为 \(\mu_1 = 0\)，而 \(\mathbf{y}_2\) 是一个特征向量，其特征值为
    \(\mu_2 = 2 - \sqrt{2}\)。
- en: '**E5.4.7** The maximum degree of \(K_4\) is \(\bar{\delta} = 3\). Using the
    bounds \(\bar{\delta} + 1 \leq \mu_n \leq 2\bar{\delta}\), we have:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.7** \(K_4\) 的最大度数为 \(\bar{\delta} = 3\)。使用界限 \(\bar{\delta} + 1 \leq
    \mu_n \leq 2\bar{\delta}\)，我们得到：'
- en: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
- en: '**E5.4.9** The diagonal entry \(L_{ii}\) is the degree of vertex \(i\), and
    the off-diagonal entry \(L_{ij}\) (for \(i \neq j\)) is \(-1\) if vertices \(i\)
    and \(j\) are adjacent, and 0 otherwise. Thus, the sum of the entries in row \(i\)
    is'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.9** 对角元素 \(L_{ii}\) 是顶点 \(i\) 的度数，非对角元素 \(L_{ij}\)（对于 \(i \neq j\)）如果顶点
    \(i\) 和 \(j\) 相邻则为 \(-1\)，否则为 0。因此，第 \(i\) 行元素之和'
- en: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
- en: '**E5.4.11** For any vector \(\mathbf{x} \in \mathbb{R}^n\), we have'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.11** 对于任何向量 \(\mathbf{x} \in \mathbb{R}^n\)，我们有'
- en: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
- en: Since this holds for all \(\mathbf{x}\), \(L_G\) is positive semidefinite.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这对所有 \(\mathbf{x}\) 都成立，\(L_G\) 是正半定的。
- en: '**E5.4.13** In a complete graph, each vertex has degree \(n-1\). Thus, the
    Laplacian matrix is \(L_G = nI - J\), where \(I\) is the identity matrix and \(J\)
    is the all-ones matrix. The eigenvalues of \(J\) are \(n\) (with multiplicity
    1) and, because \(J\) has rank one, 0 (with multiplicity \(n-1\)). Therefore,
    the eigenvalues of \(L_G\) are 0 (with multiplicity 1) and \(n\) (with multiplicity
    \(n-1\)).'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.13** 在一个完全图中，每个顶点的度数为 \(n-1\)。因此，拉普拉斯矩阵是 \(L_G = nI - J\)，其中 \(I\) 是单位矩阵，\(J\)
    是全1矩阵。\(J\) 的特征值为 \(n\)（重数1）和，因为 \(J\) 的秩为1，0（重数 \(n-1\)）。因此，\(L_G\) 的特征值为 0（重数1）和
    \(n\)（重数 \(n-1\)）。'
- en: '**E5.5.1** \(|E(S, S^c)| = 2\) (the edges between \(S\) and \(S^c\) are \(\{1,
    2\}\) and \(\{2, 3\}\)), and \(\min\{|S|, |S^c|\} = 1\). Therefore, \(\phi(S)
    = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}} = 2\).'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.1** \(|E(S, S^c)| = 2\)（\(S\) 和 \(S^c\) 之间的边是 \(\{1, 2\}\) 和 \(\{2,
    3\}\)），且 \(\min\{|S|, |S^c|\} = 1\)。因此，\(\phi(S) = \frac{|E(S, S^c)|}{\min\{|S|,
    |S^c|\}} = 2\)。'
- en: '**E5.5.3** In a connected graph with \(n\) vertices, the numerator of the cut
    ratio is at least 1, and the denominator is at most \(n/2\), which is achieved
    by cutting the graph into two equal parts. Therefore, the smallest possible value
    of the isoperimetric number is \(\frac{1}{n/2} = \frac{2}{n}\). For \(n = 6\),
    this is \(\frac{1}{3}\).'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.3** 在一个有 \(n\) 个顶点的连通图中，割比的上限至少为 1，下限最多为 \(n/2\)，这是通过将图切成两个相等部分实现的。因此，等周数的最小可能值为
    \(\frac{1}{n/2} = \frac{2}{n}\)。对于 \(n = 6\)，这是 \(\frac{1}{3}\)。'
- en: '**E5.5.5** The Cheeger Inequality also states that \(\frac{\phi_G^2}{2\bar{\delta}}
    \leq \mu_2\). Therefore, \(\phi_G \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot
    4 \cdot 0.5} = 2\).'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.5** Cheeger 不等式还表明 \(\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2\)。因此，\(\phi_G
    \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot 4 \cdot 0.5} = 2\).'
- en: '**E5.5.7** Let \(\mathbf{v}_1 = (1, 1, 1, 1)/2\), \(\mathbf{v}_2 = (-1, -1,
    1, 1)/2\), \(\mathbf{v}_3 = (1, -1, -1, 1)/2\), and \(\mathbf{v}_4 = (1, -1, 1,
    -1)/2\). These vectors form an orthonormal list. We can verify that these are
    eigenvectors of \(L\) and find their corresponding eigenvalues:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.7** 令 \(\mathbf{v}_1 = (1, 1, 1, 1)/2\)，\(\mathbf{v}_2 = (-1, -1, 1,
    1)/2\)，\(\mathbf{v}_3 = (1, -1, -1, 1)/2\)，\(\mathbf{v}_4 = (1, -1, 1, -1)/2\)。这些向量构成一个正交归一列表。我们可以验证这些是
    \(L\) 的特征向量，并找到它们对应的特征值：'
- en: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
- en: Therefore, the corresponding eigenvalues are \(\mu_1 = 0\), \(\mu_2 = 2\), \(\mu_3
    = 2\), and \(\mu_4 = 4\).
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，相应的特征值为 \(\mu_1 = 0\)，\(\mu_2 = 2\)，\(\mu_3 = 2\)，和 \(\mu_4 = 4\)。
- en: '**E5.5.9** Using the Fiedler vector \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\), an
    order is \(\pi(1) = 1\), \(\pi(2) = 2\), \(\pi(3) = 3\), \(\pi(4) = 4\).'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.9** 使用 Fiedler 向量 \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\)，一个排序是 \(\pi(1)
    = 1\)，\(\pi(2) = 2\)，\(\pi(3) = 3\)，\(\pi(4) = 4\)。'
- en: '**E5.5.11** To find the isoperimetric number, we need to consider all possible
    cuts and find the minimum cut ratio.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.11** 要找到等周数，我们需要考虑所有可能的切割并找到最小的切割比率。'
- en: 'Let’s consider all possible cuts:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑所有可能的切割：
- en: \(S = \{1\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，因此 \(\phi(S) =
    2\)。
- en: \(S = \{1, 2\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 2\), so \(\phi(S)
    = 1\).
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 2\)，因此 \(\phi(S)
    = 1\)。
- en: \(S = \{1, 2, 3\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，因此 \(\phi(S)
    = 2\)。
- en: \(S = \{1, 2, 3, 4\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 0\), so
    \(\phi(S)\) is undefined.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3, 4\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 0\)，因此 \(\phi(S)\)
    是未定义的。
- en: etc.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等等。
- en: The minimum cut ratio is \(1\), achieved by the cut \(S = \{1, 2\}\). Therefore,
    the isoperimetric number of the graph is \(\phi_G = 1\).
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 最小的切割比率为 \(1\)，由切割 \(S = \{1, 2\}\) 实现。因此，该图的等周数为 \(\phi_G = 1\)。
- en: 'Comparing this to the results from E5.5.8 and E5.5.10:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些结果与 E5.5.8 和 E5.5.10 的结果进行比较：
- en: In E5.5.8, we found that the Fiedler vector is either \((-1, -1, 1, 1)/2\),
    which suggests a cut separating vertices \(\{1, 2\}\) from \(\{3, 4\}\).
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.8 中，我们发现 Fiedler 向量是 \((-1, -1, 1, 1)/2\)，这表明切割将顶点 \(\{1, 2\}\) 与 \(\{3,
    4\}\) 分离。
- en: In E5.5.10, using the ordering based on the Fiedler vector, we found that the
    cut with the smallest ratio is \(S_2 = \{1, 2\}\), with a cut ratio of \(1\).
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.10 中，根据 Fiedler 向量的排序，我们找到了最小比率的切割 \(S_2 = \{1, 2\}\)，切割比率为 \(1\)。
- en: Both the Fiedler vector and the spectral clustering algorithm based on it correctly
    identify the cut that achieves the isoperimetric number (Cheeger constant) of
    the graph.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 既是Fiedler向量也是基于它的谱聚类算法正确地识别了达到图等周数（Cheeger常数）的切割。
- en: 'Now, let’s compare the isoperimetric number to the bounds given by Cheeger’s
    inequality. From E5.5.7, we know that the second smallest eigenvalue of the Laplacian
    matrix is \(\mu_2 = 2\). The maximum degree of the graph is \(\bar{\delta} = 2\).
    Cheeger’s inequality states that:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将等周数与Cheeger不等式给出的界限进行比较。从E5.5.7我们知道，拉普拉斯矩阵的第二小特征值是\(\mu_2 = 2\)。图的最大度数为\(\bar{\delta}
    = 2\)。Cheeger不等式表明：
- en: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
- en: 'Plugging in the values, we get:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 将值代入，我们得到：
- en: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
- en: 'which simplifies to:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这简化为：
- en: \[\frac{1}{16} \leq 2 \leq 2\]
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{1}{16} \leq 2 \leq 2\]
- en: We can see that the isoperimetric number \(\phi_G = 1\) satisfies the bounds
    given by Cheeger’s inequality.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，等周数\(\phi_G = 1\)满足Cheeger不等式给出的界限。
- en: '**E5.5.13**'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.13**'
- en: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
- en: The degree matrix \(D\) is a diagonal matrix where each entry \(D_{ii}\) is
    the degree of vertex \(i\).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 度矩阵\(D\)是一个对角矩阵，其中每个条目\(D_{ii}\)是顶点\(i\)的度数。
- en: '**E5.5.15**'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.15**'
- en: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
- en: The cutset consists of edges between \(S\) and \(S^c\). The cut ratio \(\phi(S)\)
    is the size of the cutset divided by the size of the smaller subset.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 切割集由\(S\)和\(S^c\)之间的边组成。切割比\(\phi(S)\)是切割集的大小除以较小子集的大小。
- en: '**E5.5.17**'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.17**'
- en: '[PRE51]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This code creates and displays the graph with the cut edges highlighted in red.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建并显示带有红色高亮切割边的图。
- en: '**E5.6.1** The expected number of edges is \(\mathbb{E}[|E|] = \binom{n}{2}p
    = \binom{6}{2} \cdot 0.4 = 15 \cdot 0.4 = 6\).'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.1** 边的期望数量是\(\mathbb{E}[|E|] = \binom{n}{2}p = \binom{6}{2} \cdot 0.4
    = 15 \cdot 0.4 = 6\).'
- en: '**E5.6.3** The expected number of triangles is \(\mathbb{E}[|T_3|] = \binom{n}{3}p^3
    = \binom{10}{3} \cdot 0.3^3 = 120 \cdot 0.027 = 3.24\). The expected triangle
    density is \(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3 = 0.3^3 = 0.027\).'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.3** 三角形的期望数量是\(\mathbb{E}[|T_3|] = \binom{n}{3}p^3 = \binom{10}{3} \cdot
    0.3^3 = 120 \cdot 0.027 = 3.24\)。期望三角形密度是\(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3
    = 0.3^3 = 0.027\).'
- en: '**E5.6.5** The block assignment matrix \(Z\) is given by:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.5** 块分配矩阵\(Z\)给出：'
- en: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
- en: '**E5.6.7** The degree of a vertex in \(G(4, 0.5)\) follows a binomial distribution
    \(\mathrm{Bin}(3, 0.5)\). The probabilities are:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.7** 在\(G(4, 0.5)\)中的顶点度数服从二项分布\(\mathrm{Bin}(3, 0.5)\)。概率如下：'
- en: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
- en: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
- en: '**E5.6.9** The variance is \(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot
    (1 - p) = 3 \cdot 0.5 \cdot 0.5 = 0.75\).'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.9** 方差是\(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot (1 - p) = 3
    \cdot 0.5 \cdot 0.5 = 0.75\).'
- en: '**E5.6.11** Since vertex 2 is in block \(C_1\) and vertex 4 is in block \(C_2\),
    the probability of an edge between them is \(b_{1,2} = 1/4\).'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.11** 由于顶点2在块\(C_1\)中，顶点4在块\(C_2\)中，它们之间边的概率是\(b_{1,2} = 1/4\).'
- en: '**E5.6.13** The expected degree of each vertex is \((p+q)n/2 = (1)(8)/2 = 4\).'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.13** 每个顶点的期望度数为\((p+q)n/2 = (1)(8)/2 = 4\).'
- en: '**E5.6.15** Let \(A_{i,j}\) be the indicator random variable for the presence
    of edge \(\{i,j\}\). Then the number of edges is \(X = \sum_{i<j} A_{i,j}\). Since
    the edges are independent,'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.15** 设\(A_{i,j}\)为边\(\{i,j\}\)存在的指示随机变量。那么边的数量是\(X = \sum_{i<j} A_{i,j}\)。由于边是独立的，'
- en: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
- en: 5.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-487
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.5\. 学习成果[#](#learning-outcomes "链接到这个标题")
- en: Define undirected and directed graphs, and identify their key components such
    as vertices, edges, paths, and cycles.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无向图和有向图，并识别它们的关键组件，如顶点、边、路径和环。
- en: Recognize special types of graphs, including cliques, trees, forests, and directed
    acyclic graphs (DAGs).
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别特殊类型的图，包括完全图、树、森林和有向无环图（DAGs）。
- en: Determine the connectivity of a graph and identify its connected components.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定图的连通性并识别其连通分量。
- en: Construct the adjacency matrix, incidence matrix, and Laplacian matrix representations
    of a graph.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造图的邻接矩阵、关联矩阵和Laplacian矩阵表示。
- en: Prove key properties of the Laplacian matrix, such as symmetry and positive
    semidefiniteness.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明Laplacian矩阵的关键性质，如对称性和正半定。
- en: Extend the concepts of graphs and their matrix representations to weighted graphs.
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图及其矩阵表示的概念扩展到加权图。
- en: Implement graph representations and algorithms using the NetworkX package in
    Python.
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python中的NetworkX包实现图表示和算法。
- en: Apply graph theory concepts to model and analyze real-world networks and relationships.
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图论概念应用于模型化和分析现实世界的网络和关系。
- en: Outline the proof of the Spectral Theorem using a sequence of orthogonal transformations
    to diagonalize a matrix.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概述使用一系列正交变换对矩阵进行对角化的Spectral定理的证明。
- en: Define the Rayleigh quotient and explain its relationship to eigenvectors and
    eigenvalues.
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义Rayleigh商并解释其与特征向量和特征值的关系。
- en: Prove the variational characterizations of the largest, smallest, and second
    smallest eigenvalues of a symmetric matrix using the Rayleigh quotient.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Rayleigh商证明对称矩阵的最大、最小和第二小特征值的变分特征。
- en: State the Courant-Fischer Theorem and interpret its local and global formulas
    for the eigenvalues of a symmetric matrix.
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Courant-Fischer定理并解释其局部和全局公式，用于对称矩阵的特征值。
- en: Apply the Courant-Fischer Theorem to characterize the third smallest eigenvalue
    of a symmetric matrix.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用Courant-Fischer定理来表征对称矩阵的第三小特征值。
- en: State the key properties of the Laplacian matrix, including symmetry, positive
    semidefiniteness, and the constant eigenvector associated with the zero eigenvalue.
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Laplacian矩阵的关键性质，包括对称性、正半定性和与零特征值相关的常数特征向量。
- en: Prove the relationship between graph connectivity and the second smallest eigenvalue
    (algebraic connectivity) of the Laplacian matrix.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明图连通性与Laplacian矩阵的第二小特征值（代数连通性）之间的关系。
- en: Derive bounds on the largest eigenvalue of the Laplacian matrix using the maximum
    degree of the graph.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用图的最大度数推导Laplacian矩阵最大特征值的界限。
- en: Formulate the variational characterization of the second smallest eigenvalue
    of the Laplacian matrix as a constrained optimization problem.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Laplacian矩阵的第二小特征值的变分特征表述为一个约束优化问题。
- en: Explain how the eigenvectors of the Laplacian matrix can be used for graph drawing
    and revealing the underlying geometry of the graph, using the variational characterization.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释如何使用Laplacian矩阵的特征向量进行图绘制并揭示图的潜在几何结构，使用变分特征。
- en: Compute the Laplacian matrix and its eigenvalues and eigenvectors for simple
    graphs, and interpret the results in terms of graph connectivity and geometry.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算简单图的Laplacian矩阵及其特征值和特征向量，并从图连通性和几何角度解释结果。
- en: Compute the cut ratio and the isoperimetric number (Cheeger constant) for a
    given graph cut.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定图割的割比和等周数（Cheeger常数）。
- en: State the Cheeger Inequality and explain its significance in relating the isoperimetric
    number to the second smallest Laplacian eigenvalue.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Cheeger不等式并解释其在将等周数与第二小Laplacian特征值相关联中的重要性。
- en: Describe the main steps of the graph-cutting algorithm based on the Fiedler
    vector.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述基于Fiedler向量的图割算法的主要步骤。
- en: Analyze the performance guarantees of the Fiedler vector-based graph-cutting
    algorithm and compare them to the optimal cut.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析基于 Fiedler 向量的图切割算法的性能保证，并将其与最优切割进行比较。
- en: Apply spectral clustering techniques to identify communities within a graph,
    and evaluate the quality of the resulting partitions.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用谱聚类技术来识别图中的社区，并评估所得分区质量。
- en: Formulate the minimum bisection problem as a discrete optimization problem and
    relax it into a continuous optimization problem related to the Laplacian matrix.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将最小二分问题表述为一个离散优化问题，并将其松弛为一个与拉普拉斯矩阵相关的连续优化问题。
- en: Define the inhomogeneous Erdős-Rényi (ER) random graph model and explain how
    it generalizes the standard ER model.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义非齐次 Erdős-Rényi (ER) 随机图模型，并解释它如何推广标准 ER 模型。
- en: Generate inhomogeneous ER graphs and analyze their properties, such as edge
    density and the probability of connectivity, using Python and NetworkX.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 和 NetworkX 生成非齐次 ER 图，并分析其属性，如边密度和连通性概率。
- en: Calculate the expected number of edges and triangles in an ER random graph.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算 ER 随机图中期望的边数和三角形数。
- en: Describe the stochastic blockmodel (SBM) and its role in creating random graphs
    with planted partitions, and explain how it relates to the concept of homophily.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述随机块模型 (SBM) 及其在创建具有植入分区的随机图中的作用，并解释它与同质性的关系。
- en: Construct SBMs with specified block assignments and edge probabilities, and
    visualize the resulting graphs using Python and NetworkX.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 和 NetworkX 构建具有指定块分配和边概率的 SBMs，并使用 Python 和 NetworkX 可视化生成的图。
- en: Compute the expected adjacency matrix of an SBM given the block assignment matrix
    and connection probabilities.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据块分配矩阵和连接概率计算 SBM 的期望邻接矩阵。
- en: Apply spectral clustering algorithms to SBMs and evaluate their performance
    in recovering the ground truth community structure.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将谱聚类算法应用于 SBMs，并评估其在恢复真实社区结构方面的性能。
- en: Analyze the simplified symmetric stochastic blockmodel (SSBM) and derive the
    spectral decomposition of its expected adjacency matrix.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析简化的对称随机块模型 (SSBM) 并推导其期望邻接矩阵的谱分解。
- en: Explain the relationship between the eigenvectors of the expected Laplacian
    matrix and the community structure in the SSBM.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释期望拉普拉斯矩阵的特征向量与 SSBM 中的社区结构之间的关系。
- en: Investigate the behavior of the eigenvalues of the Laplacian matrix for large
    random graphs and discuss the connection to random matrix theory.
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究大随机图的拉普拉斯矩阵特征值的行为，并讨论与随机矩阵理论的联系。
- en: \(\aleph\)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 5.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-524
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.1\. 仅代码[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 下面可以访问一个包含本章代码的交互式 Jupyter 笔记本（推荐使用 Google Colab）。鼓励您对其进行实验。一些建议的计算练习散布在其中。笔记本也可以作为幻灯片查看。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb)
    ([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html)'
- en: 5.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.2\. 自我评估测验[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以获取更全面的自我评估测验版本。
- en: '[Section 5.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.2 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html)'
- en: '[Section 5.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 5.3 节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html)'
- en: '[Section 5.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.4节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html)'
- en: '[Section 5.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.5节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html)'
- en: '[Section 5.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5.6节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html)'
- en: 5.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-535
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的本章测验可以在以下链接中访问（推荐使用Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb))'
- en: 5.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-538
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.4\. 奇数练习题的解答[#](#solutions-to-odd-numbered-warm-up-exercises "链接到本标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在Claude、Gemini和ChatGPT的帮助下)*'
- en: '**E5.2.1** \(V = \{1, 2, 3, 4\}\), \(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\). This follows directly from the definition of a graph as a pair \(G =
    (V, E)\).'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.1** \(V = \{1, 2, 3, 4\}\), \(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3,
    4\}\}\)。这直接来自图作为一对\(G = (V, E)\)的定义。'
- en: '**E5.2.3** One possible path is \(1 \sim 2 \sim 4\). Its length is 2, since
    it consists of two edges.'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.3** 一个可能的路径是\(1 \sim 2 \sim 4\)。它的长度是2，因为它由两个边组成。'
- en: '**E5.2.5** \(\delta^-(2) = 1\), \(\delta^+(2) = 2\). The in-degree of a vertex
    \(v\) is the number of edges with destination \(v\), and the out-degree is the
    number of edges with source \(v\).'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.5** \(\delta^-(2) = 1\)，\(\delta^+(2) = 2\)。顶点\(v\)的入度是目标为\(v\)的边的数量，出度是源为\(v\)的边的数量。'
- en: '**E5.2.7** The graph \(G\) is not connected. There is no path between vertex
    1 and vertex 4, indicating that the graph is not connected.'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.7** 图\(G\)是不连通的。顶点1和顶点4之间没有路径，这表明图是不连通的。'
- en: '**E5.2.9** The number of connected components is 1\. There is a path between
    every pair of vertices, so the graph is connected, having only one connected component.'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.9** 连通分量的数量是1。每对顶点之间都存在路径，因此图是连通的，只有一个连通分量。'
- en: '**E5.2.11**'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.11**'
- en: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 1
    & 0 & 1 \\ 0 & 0 & 1 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if vertex \(i\) is incident to edge \(j\), and 0 otherwise.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 如果顶点\(i\)与边\(j\)相关联，则条目\(B_{ij}\)为1，否则为0。
- en: '**E5.2.13**'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.13**'
- en: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} B = \begin{pmatrix} -1 & 0 & 1 & 0 \\ 1 & -1 & 0 & -1 \\ 0 &
    1 & -1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}. \end{split}\]
- en: The entry \(B_{ij}\) is 1 if edge \(j\) leaves vertex \(i\), -1 if edge \(j\)
    enters vertex \(i\), and 0 otherwise.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 如果边\(j\)离开顶点\(i\)，则条目\(B_{ij}\)为1；如果边\(j\)进入顶点\(i\)，则条目\(B_{ij}\)为-1；否则为0。
- en: '**E5.2.15** The Petersen graph is 3-regular, as stated in the text.'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.2.15** 彼得森图是3-正则的，正如文本中所述。'
- en: '**E5.3.1** We can find the eigenvectors of \(A\) and normalize them to get
    an orthonormal basis. The characteristic polynomial of \(A\) is \((5-\lambda)^2
    - 9 = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\), so the eigenvalues
    are 2 and 8\. For \(\lambda = 2\), an eigenvector is \(\begin{pmatrix} -1 \\ 1
    \end{pmatrix}\), and for \(\lambda = 8\), an eigenvector is \(\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\). Normalizing these vectors, we get the matrix'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.1** 我们可以找到\(A\)的特征向量，并将它们归一化以得到一个正交基。\(A\)的特征多项式是\((5-\lambda)^2 - 9
    = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\)，因此特征值是2和8。对于\(\lambda
    = 2\)，一个特征向量是\(\begin{pmatrix} -1 \\ 1 \end{pmatrix}\)，对于\(\lambda = 8\)，一个特征向量是\(\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\)。归一化这些向量，我们得到矩阵'
- en: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} W = \begin{pmatrix} -1/\sqrt{2} & 1/\sqrt{2} \\ 1/\sqrt{2} &
    1/\sqrt{2} \end{pmatrix}. \end{split}\]
- en: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.3** \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \langle \mathbf{u}, A\mathbf{u} \rangle = \begin{pmatrix}
    \frac{\sqrt{3}}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 & 1 \\ 1 & 2
    \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix}
    = \frac{7}{2}\).'
- en: '**E5.3.5** To find the eigenvalues, we solve the characteristic equation: \(\det(A
    - \lambda I) = \begin{vmatrix} 2-\lambda & -1 \\ -1 & 2-\lambda \end{vmatrix}
    = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = (\lambda - 1)(\lambda - 3) =
    0\). So the eigenvalues are \(\lambda_1 = 3\) and \(\lambda_2 = 1\). To find the
    eigenvectors, we solve \((A - \lambda_i I)\mathbf{v}_i = 0\) for each eigenvalue:
    For \(\lambda_1 = 3\): \(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1
    = \mathbf{0}\), which gives \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_1 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1
    \end{pmatrix}\). For \(\lambda_2 = 1\): \(\begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2
    = \mathbf{0}\), which gives \(\mathbf{v}_2 = c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\).
    Normalizing, we get \(\mathbf{v}_2 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1
    \end{pmatrix}\). To verify the variational characterization for \(\lambda_1\):
    \(R_A(\mathbf{v}_1) = \frac{\langle \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle
    \mathbf{v}_1, \mathbf{v}_1 \rangle} = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix}
    2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2
    - 1 - 1 + 2) = 3 = \lambda_1\). For any unit vector \(\mathbf{u} = \begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix}\), we have: \(R_A(\mathbf{u}) = \begin{pmatrix}
    \cos\theta & \sin\theta \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix}
    \cos\theta \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\), with equality
    when \(\theta = \frac{\pi}{4}\), which corresponds to \(\mathbf{u} = \mathbf{v}_1\).
    Thus, \(\lambda_1 = \max_{\mathbf{u} \neq \mathbf{0}} R_A(\mathbf{u})\).'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.5** 要找到特征值，我们解特征方程：\(\det(A - \lambda I) = \begin{vmatrix} 2-\lambda
    & -1 \\ -1 & 2-\lambda \end{vmatrix} = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda
    + 3 = (\lambda - 1)(\lambda - 3) = 0\)。因此，特征值是 \(\lambda_1 = 3\) 和 \(\lambda_2
    = 1\)。为了找到特征向量，我们解每个特征值对应的方程 \((A - \lambda_i I)\mathbf{v}_i = 0\)：对于 \(\lambda_1
    = 3\)：\(\begin{pmatrix} -1 & -1 \\ -1 & -1 \end{pmatrix}\mathbf{v}_1 = \mathbf{0}\)，这给出
    \(\mathbf{v}_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)。归一化后，我们得到 \(\mathbf{v}_1
    = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)。对于 \(\lambda_2 = 1\)：\(\begin{pmatrix}
    1 & -1 \\ -1 & 1 \end{pmatrix}\mathbf{v}_2 = \mathbf{0}\)，这给出 \(\mathbf{v}_2 =
    c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)。归一化后，我们得到 \(\mathbf{v}_2 = \frac{1}{\sqrt{2}}\begin{pmatrix}
    1 \\ 1 \end{pmatrix}\)。为了验证 \(\lambda_1\) 的变分特征：\(R_A(\mathbf{v}_1) = \frac{\langle
    \mathbf{v}_1, A\mathbf{v}_1 \rangle}{\langle \mathbf{v}_1, \mathbf{v}_1 \rangle}
    = \frac{1}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 &
    2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2 - 1 - 1 +
    2) = 3 = \lambda_1\)。对于任何单位向量 \(\mathbf{u} = \begin{pmatrix} \cos\theta \\ \sin\theta
    \end{pmatrix}\)，我们有：\(R_A(\mathbf{u}) = \begin{pmatrix} \cos\theta & \sin\theta
    \end{pmatrix}\begin{pmatrix} 2 & -1 \\ -1 & 2 \end{pmatrix}\begin{pmatrix} \cos\theta
    \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta
    = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\)，当 \(\theta
    = \frac{\pi}{4}\) 时取等号，这对应于 \(\mathbf{u} = \mathbf{v}_1\)。因此，\(\lambda_1 = \max_{\mathbf{u}
    \neq \mathbf{0}} R_A(\mathbf{u})\)。'
- en: '**E5.3.7** First, we find the eigenvalues corresponding to the given eigenvectors:
    \(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\), so \(\lambda_1 =
    3\). \(A\mathbf{v}_2 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}}
    \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \mathbf{v}_2\), so \(\lambda_2 =
    1\). \(A\mathbf{v}_3 = \begin{pmatrix} 1 & 2 & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix}
    \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix}
    = 3\mathbf{v}_3\), so \(\lambda_3 = 3\).'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.3.7** 首先，我们找到对应给定特征向量的特征值：\(A\mathbf{v}_1 = \begin{pmatrix} 1 & 2 & 0
    \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\
    1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix}
    = 3\mathbf{v}_1\)，所以 \(\lambda_1 = 3\)。\(A\mathbf{v}_2 = \begin{pmatrix} 1 & 2
    & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix}
    -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix}
    = \mathbf{v}_2\)，所以 \(\lambda_2 = 1\)。\(A\mathbf{v}_3 = \begin{pmatrix} 1 & 2
    & 0 \\ 2 & 1 & 0 \\ 0 & 0 & 3 \end{pmatrix} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
    = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix} = 3\mathbf{v}_3\)，所以 \(\lambda_3 =
    3\)。'
- en: So the eigenvalues are \(\lambda_1 = 3\), \(\lambda_2 = 1\), and \(\lambda_3
    = 3\). Note that \(\lambda_2\) is the second smallest eigenvalue.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特征值是 \(\lambda_1 = 3\), \(\lambda_2 = 1\), 和 \(\lambda_3 = 3\)。注意，\(\lambda_2\)
    是第二个最小的特征值。
- en: 'Now, let’s verify the variational characterization for \(\lambda_2\). Any vector
    \(\mathbf{u} \in V_2\) can be written as \(\mathbf{u} = c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2\) for some scalars \(c_1\) and \(c_2\). Then:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们验证 \(\lambda_2\) 的变分特征描述。任何向量 \(\mathbf{u} \in V_2\) 可以写成 \(\mathbf{u}
    = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2\) 的形式，其中 \(c_1\) 和 \(c_2\) 是一些标量。然后：
- en: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), since \(\mathbf{v}_1\) and \(\mathbf{v}_2\)
    are orthonormal.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, \mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = c_1^2 \langle \mathbf{v}_1, \mathbf{v}_1
    \rangle + 2c_1c_2 \langle \mathbf{v}_1, \mathbf{v}_2 \rangle + c_2^2 \langle \mathbf{v}_2,
    \mathbf{v}_2 \rangle = c_1^2 + c_2^2\), since \(\mathbf{v}_1\) and \(\mathbf{v}_2\)
    are orthonormal.
- en: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    since \(A\mathbf{v}_1 = 3\mathbf{v}_1\) and \(A\mathbf{v}_2 = \mathbf{v}_2\).
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: \(\langle \mathbf{u}, A\mathbf{u} \rangle = \langle c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2,
    A(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) \rangle = \langle c_1 \mathbf{v}_1 + c_2
    \mathbf{v}_2, 3c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 \rangle = 3c_1^2 + c_2^2\),
    since \(A\mathbf{v}_1 = 3\mathbf{v}_1\) and \(A\mathbf{v}_2 = \mathbf{v}_2\).
- en: 'Therefore, \(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    for all \(\mathbf{u} \neq \mathbf{0}\) in \(V_2\), with equality when \(c_1 =
    0\). Thus: \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})
    = 1 = R_A(\mathbf{v}_2)\).'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(R_A(\mathbf{u}) = \frac{\langle \mathbf{u}, A\mathbf{u} \rangle}{\langle
    \mathbf{u}, \mathbf{u} \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)
    对于 \(V_2\) 中所有 \(\mathbf{u} \neq \mathbf{0}\) 都成立，当 \(c_1 = 0\) 时取等号。因此：\(\lambda_2
    = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u}) = 1 = R_A(\mathbf{v}_2)\)。
- en: So indeed, the second smallest eigenvalue \(\lambda_2\) satisfies the variational
    characterization \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u} \in V_2} R_A(\mathbf{u})\).
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，确实，第二个最小的特征值 \(\lambda_2\) 满足变分特征描述 \(\lambda_2 = \min_{\mathbf{0} \neq \mathbf{u}
    \in V_2} R_A(\mathbf{u})\)。
- en: '**E5.4.1** The degree matrix \(D\) is'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.1** 度矩阵 \(D\) 是'
- en: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 \\ 0 & 0
    & 2 & 0 \\ 0 & 0 & 0 & 2 \end{pmatrix}. \end{split}\]
- en: 'The Laplacian matrix \(L\) is \(L = D - A\):'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '拉普拉斯矩阵 \(L\) 是 \(L = D - A\):'
- en: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L = \begin{pmatrix} 1 & -1 & 0 & 0 \\ -1 & 3 & -1 & -1 \\ 0
    & -1 & 2 & -1 \\ 0 & -1 & -1 & 2 \end{pmatrix}. \end{split}\]
- en: '**E5.4.3**'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.3**'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 & 0\\ -1 & 2
    & -1 & 0 & 0\\ 0 & -1 & 3 & -1 & -1\\ -1 & 0 & -1 & 2 & 0\\ 0 & 0 & -1 & 0 & 1
    \end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix} 1\\ 1\\ 1\\ 1\\ 1 \end{pmatrix}
    = \frac{1}{\sqrt{5}}\begin{pmatrix} 0\\ 0\\ 0\\ 0\\ 0 \end{pmatrix} = 0 \cdot
    \mathbf{y}_1. \end{split}\]
- en: '**E5.4.5** Let’s verify that \(\mathbf{y}_1\) and \(\mathbf{y}_2\) are eigenvectors
    of \(L\):'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.5** 让我们验证 \(\mathbf{y}_1\) 和 \(\mathbf{y}_2\) 是 \(L\) 的特征向量：'
- en: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{y}_1 = \begin{pmatrix} 1 & -1 & 0 & 0\\ -1 & 2 & -1
    & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
    1\\ 1\\ 1\\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{y}_1, \end{split}\]\[\begin{split} L\mathbf{y}_2 = \begin{pmatrix}
    1 & -1 & 0 & 0\\ -1 & 2 & -1 & 0\\ 0 & -1 & 2 & -1\\ 0 & 0 & -1 & 1 \end{pmatrix}
    \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}\\
    -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \frac{1}{2}\begin{pmatrix} 1\\ \frac{1}{\sqrt{2}}\\
    -\frac{1}{\sqrt{2}}\\ -1 \end{pmatrix} = (2 - \sqrt{2}) \cdot \mathbf{y}_2. \end{split}\]
- en: So, \(\mathbf{y}_1\) is an eigenvector with eigenvalue \(\mu_1 = 0\), and \(\mathbf{y}_2\)
    is an eigenvector with eigenvalue \(\mu_2 = 2 - \sqrt{2}\).
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(\mathbf{y}_1\) 是特征值为 \(\mu_1 = 0\) 的特征向量，而 \(\mathbf{y}_2\) 是特征值为 \(\mu_2
    = 2 - \sqrt{2}\) 的特征向量。
- en: '**E5.4.7** The maximum degree of \(K_4\) is \(\bar{\delta} = 3\). Using the
    bounds \(\bar{\delta} + 1 \leq \mu_n \leq 2\bar{\delta}\), we have:'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.7** \(K_4\) 的最大度数为 \(\bar{\delta} = 3\)。使用界限 \(\bar{\delta} + 1 \leq
    \mu_n \leq 2\bar{\delta}\)，我们得到：'
- en: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6. \]
- en: '**E5.4.9** The diagonal entry \(L_{ii}\) is the degree of vertex \(i\), and
    the off-diagonal entry \(L_{ij}\) (for \(i \neq j\)) is \(-1\) if vertices \(i\)
    and \(j\) are adjacent, and 0 otherwise. Thus, the sum of the entries in row \(i\)
    is'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.9** 对角线元素 \(L_{ii}\) 是顶点 \(i\) 的度数，而偏对角线元素 \(L_{ij}\)（对于 \(i \neq j\)）如果顶点
    \(i\) 和 \(j\) 相邻则为 \(-1\)，否则为 0。因此，第 \(i\) 行元素之和为'
- en: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0. \]'
- en: '**E5.4.11** For any vector \(\mathbf{x} \in \mathbb{R}^n\), we have'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.11** 对于任意向量 \(\mathbf{x} \in \mathbb{R}^n\)，我们有'
- en: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T L_G \mathbf{x} = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0. \]
- en: Since this holds for all \(\mathbf{x}\), \(L_G\) is positive semidefinite.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这对所有 \(\mathbf{x}\) 都成立，\(L_G\) 是正半定的。
- en: '**E5.4.13** In a complete graph, each vertex has degree \(n-1\). Thus, the
    Laplacian matrix is \(L_G = nI - J\), where \(I\) is the identity matrix and \(J\)
    is the all-ones matrix. The eigenvalues of \(J\) are \(n\) (with multiplicity
    1) and, because \(J\) has rank one, 0 (with multiplicity \(n-1\)). Therefore,
    the eigenvalues of \(L_G\) are 0 (with multiplicity 1) and \(n\) (with multiplicity
    \(n-1\)).'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.4.13** 在完全图中，每个顶点的度数为 \(n-1\)。因此，拉普拉斯矩阵为 \(L_G = nI - J\)，其中 \(I\) 是单位矩阵，\(J\)
    是全 1 矩阵。\(J\) 的特征值为 \(n\)（重数为 1）和，因为 \(J\) 的秩为 1，0（重数为 \(n-1\)）。因此，\(L_G\) 的特征值为
    0（重数为 1）和 \(n\)（重数为 \(n-1\)）。'
- en: '**E5.5.1** \(|E(S, S^c)| = 2\) (the edges between \(S\) and \(S^c\) are \(\{1,
    2\}\) and \(\{2, 3\}\)), and \(\min\{|S|, |S^c|\} = 1\). Therefore, \(\phi(S)
    = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}} = 2\).'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.1** \(|E(S, S^c)| = 2\)（\(S\) 和 \(S^c\) 之间的边是 \(\{1, 2\}\) 和 \(\{2,
    3\}\)），且 \(\min\{|S|, |S^c|\} = 1\)。因此，\(\phi(S) = \frac{|E(S, S^c)|}{\min\{|S|,
    |S^c|\}} = 2\)。'
- en: '**E5.5.3** In a connected graph with \(n\) vertices, the numerator of the cut
    ratio is at least 1, and the denominator is at most \(n/2\), which is achieved
    by cutting the graph into two equal parts. Therefore, the smallest possible value
    of the isoperimetric number is \(\frac{1}{n/2} = \frac{2}{n}\). For \(n = 6\),
    this is \(\frac{1}{3}\).'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.3** 在具有 \(n\) 个顶点的连通图中，割比的分子至少为 1，分母最多为 \(n/2\)，这是通过将图切成两个相等部分实现的。因此，等周数的最小可能值为
    \(\frac{1}{n/2} = \frac{2}{n}\)。对于 \(n = 6\)，这个值是 \(\frac{1}{3}\)。'
- en: '**E5.5.5** The Cheeger Inequality also states that \(\frac{\phi_G^2}{2\bar{\delta}}
    \leq \mu_2\). Therefore, \(\phi_G \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot
    4 \cdot 0.5} = 2\).'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.5** Cheeger 不等式还表明 \(\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2\)。因此，\(\phi_G
    \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot 4 \cdot 0.5} = 2\)。'
- en: '**E5.5.7** Let \(\mathbf{v}_1 = (1, 1, 1, 1)/2\), \(\mathbf{v}_2 = (-1, -1,
    1, 1)/2\), \(\mathbf{v}_3 = (1, -1, -1, 1)/2\), and \(\mathbf{v}_4 = (1, -1, 1,
    -1)/2\). These vectors form an orthonormal list. We can verify that these are
    eigenvectors of \(L\) and find their corresponding eigenvalues:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.7** 令 \(\mathbf{v}_1 = (1, 1, 1, 1)/2\)，\(\mathbf{v}_2 = (-1, -1, 1,
    1)/2\)，\(\mathbf{v}_3 = (1, -1, -1, 1)/2\)，和 \(\mathbf{v}_4 = (1, -1, 1, -1)/2\)。这些向量构成一个正交归一列表。我们可以验证这些是
    \(L\) 的特征向量，并找到它们对应的特征值：'
- en: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} L\mathbf{v}_1 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 &
    -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix}
    1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}
    = 0 \cdot \mathbf{v}_1, \end{split}\]\[\begin{split} L\mathbf{v}_2 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} -1 \\ -1 \\ 1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    -2 \\ -2 \\ 2 \\ 2 \end{pmatrix} = 2 \cdot \mathbf{v}_2, \end{split}\]\[\begin{split}
    L\mathbf{v}_3 = \begin{pmatrix} 2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 &
    2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix} \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\
    -1 \\ 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 2 \\ -2 \\ -2 \\ 2 \end{pmatrix}
    = 2 \cdot \mathbf{v}_3, \end{split}\]\[\begin{split} L\mathbf{v}_4 = \begin{pmatrix}
    2 & -1 & 0 & -1 \\ -1 & 2 & -1 & 0 \\ 0 & -1 & 2 & -1 \\ -1 & 0 & -1 & 2 \end{pmatrix}
    \frac{1}{2}\begin{pmatrix} 1 \\ -1 \\ 1 \\ -1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix}
    4 \\ -4 \\ 4 \\ -4 \end{pmatrix} = 4 \cdot \mathbf{v}_4. \end{split}\]
- en: Therefore, the corresponding eigenvalues are \(\mu_1 = 0\), \(\mu_2 = 2\), \(\mu_3
    = 2\), and \(\mu_4 = 4\).
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，相应的特征值为 \(\mu_1 = 0\)，\(\mu_2 = 2\)，\(\mu_3 = 2\)，和 \(\mu_4 = 4\)。
- en: '**E5.5.9** Using the Fiedler vector \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\), an
    order is \(\pi(1) = 1\), \(\pi(2) = 2\), \(\pi(3) = 3\), \(\pi(4) = 4\).'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.9** 使用 Fiedler 向量 \(\mathbf{v}_2 = (-1, -1, 1, 1)/2\)，一个顺序是 \(\pi(1)
    = 1\)，\(\pi(2) = 2\)，\(\pi(3) = 3\)，\(\pi(4) = 4\)。'
- en: '**E5.5.11** To find the isoperimetric number, we need to consider all possible
    cuts and find the minimum cut ratio.'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.11** 要找到等周数，我们需要考虑所有可能的切割并找到最小切割比率。'
- en: 'Let’s consider all possible cuts:'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑所有可能的切割：
- en: \(S = \{1\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，所以 \(\phi(S) =
    2\)。
- en: \(S = \{1, 2\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 2\), so \(\phi(S)
    = 1\).
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 2\)，所以 \(\phi(S)
    = 1\)。
- en: \(S = \{1, 2, 3\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 1\), so \(\phi(S)
    = 2\).
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 1\)，所以 \(\phi(S)
    = 2\)。
- en: \(S = \{1, 2, 3, 4\}\), \(|E(S, S^c)| = 2\), \(\min\{|S|, |S^c|\} = 0\), so
    \(\phi(S)\) is undefined.
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(S = \{1, 2, 3, 4\}\)，\(|E(S, S^c)| = 2\)，\(\min\{|S|, |S^c|\} = 0\)，所以 \(\phi(S)\)
    是未定义的。
- en: etc.
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等等。
- en: The minimum cut ratio is \(1\), achieved by the cut \(S = \{1, 2\}\). Therefore,
    the isoperimetric number of the graph is \(\phi_G = 1\).
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 最小切割比率为 \(1\)，由切割 \(S = \{1, 2\}\) 实现。因此，该图的等周数为 \(\phi_G = 1\)。
- en: 'Comparing this to the results from E5.5.8 and E5.5.10:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 将此与 E5.5.8 和 E5.5.10 的结果进行比较：
- en: In E5.5.8, we found that the Fiedler vector is either \((-1, -1, 1, 1)/2\),
    which suggests a cut separating vertices \(\{1, 2\}\) from \(\{3, 4\}\).
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.8 中，我们发现 Fiedler 向量要么是 \((-1, -1, 1, 1)/2\)，这表明一个切割将顶点 \(\{1, 2\}\) 与
    \(\{3, 4\}\) 分隔开来。
- en: In E5.5.10, using the ordering based on the Fiedler vector, we found that the
    cut with the smallest ratio is \(S_2 = \{1, 2\}\), with a cut ratio of \(1\).
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 E5.5.10 中，基于 Fiedler 向量的排序，我们发现最小比率的切割是 \(S_2 = \{1, 2\}\)，切割比率为 \(1\)。
- en: Both the Fiedler vector and the spectral clustering algorithm based on it correctly
    identify the cut that achieves the isoperimetric number (Cheeger constant) of
    the graph.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: Fiedler 向量和基于它的谱聚类算法都能正确识别出实现图等周数（Cheeger 常数）的切割。
- en: 'Now, let’s compare the isoperimetric number to the bounds given by Cheeger’s
    inequality. From E5.5.7, we know that the second smallest eigenvalue of the Laplacian
    matrix is \(\mu_2 = 2\). The maximum degree of the graph is \(\bar{\delta} = 2\).
    Cheeger’s inequality states that:'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将等周数与 Cheeger 不等式给出的界限进行比较。从 E5.5.7，我们知道拉普拉斯矩阵的第二个最小特征值为 \(\mu_2 = 2\)。图的最大度数为
    \(\bar{\delta} = 2\)。Cheeger 不等式表明：
- en: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]
- en: 'Plugging in the values, we get:'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 将数值代入，我们得到：
- en: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]
- en: 'which simplifies to:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以简化为：
- en: \[\frac{1}{16} \leq 2 \leq 2\]
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{1}{16} \leq 2 \leq 2\]
- en: We can see that the isoperimetric number \(\phi_G = 1\) satisfies the bounds
    given by Cheeger’s inequality.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到等周数 \(\phi_G = 1\) 满足 Cheeger 不等式给出的界限。
- en: '**E5.5.13**'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.13**'
- en: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} D = \begin{pmatrix} 2 & 0 & 0 & 0 & 0 \\ 0 & 3 & 0 & 0 & 0 \\
    0 & 0 & 3 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ \end{pmatrix} \end{split}\]
- en: The degree matrix \(D\) is a diagonal matrix where each entry \(D_{ii}\) is
    the degree of vertex \(i\).
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 度矩阵 \(D\) 是一个对角矩阵，其中每个条目 \(D_{ii}\) 是顶点 \(i\) 的度数。
- en: '**E5.5.15**'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.15**'
- en: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3 \]\[
    \phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5 \]
- en: The cutset consists of edges between \(S\) and \(S^c\). The cut ratio \(\phi(S)\)
    is the size of the cutset divided by the size of the smaller subset.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 切割集由 \(S\) 和 \(S^c\) 之间的边组成。切割比 \(\phi(S)\) 是切割集的大小除以较小子集的大小。
- en: '**E5.5.17**'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.5.17**'
- en: '[PRE52]'
  id: totrans-613
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This code creates and displays the graph with the cut edges highlighted in red.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建并显示带有红色高亮切割边的图。
- en: '**E5.6.1** The expected number of edges is \(\mathbb{E}[|E|] = \binom{n}{2}p
    = \binom{6}{2} \cdot 0.4 = 15 \cdot 0.4 = 6\).'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.1** 边的期望数量为 \(\mathbb{E}[|E|] = \binom{n}{2}p = \binom{6}{2} \cdot 0.4
    = 15 \cdot 0.4 = 6\)。'
- en: '**E5.6.3** The expected number of triangles is \(\mathbb{E}[|T_3|] = \binom{n}{3}p^3
    = \binom{10}{3} \cdot 0.3^3 = 120 \cdot 0.027 = 3.24\). The expected triangle
    density is \(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3 = 0.3^3 = 0.027\).'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.3** 三角形的期望数量为 \(\mathbb{E}[|T_3|] = \binom{n}{3}p^3 = \binom{10}{3}
    \cdot 0.3^3 = 120 \cdot 0.027 = 3.24\)。期望三角形密度为 \(\mathbb{E}[|T_3|/\binom{n}{3}]
    = p^3 = 0.3^3 = 0.027\)。'
- en: '**E5.6.5** The block assignment matrix \(Z\) is given by:'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.5** 块分配矩阵 \(Z\) 为：'
- en: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} Z = \begin{pmatrix} 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 1 & 0 \\ 0 &
    1 \\ 0 & 1 \\ 0 & 1 \\ 0 & 1 \end{pmatrix}. \end{split}\]
- en: '**E5.6.7** The degree of a vertex in \(G(4, 0.5)\) follows a binomial distribution
    \(\mathrm{Bin}(3, 0.5)\). The probabilities are:'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.7** \(G(4, 0.5)\) 中顶点的度数遵循二项分布 \(\mathrm{Bin}(3, 0.5)\)。概率如下：'
- en: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)
- en: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)
- en: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)
- en: '**E5.6.9** The variance is \(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot
    (1 - p) = 3 \cdot 0.5 \cdot 0.5 = 0.75\).'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.9** 方差为 \(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot (1 - p) = 3
    \cdot 0.5 \cdot 0.5 = 0.75\).'
- en: '**E5.6.11** Since vertex 2 is in block \(C_1\) and vertex 4 is in block \(C_2\),
    the probability of an edge between them is \(b_{1,2} = 1/4\).'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.11** 由于顶点 2 在块 \(C_1\) 中，顶点 4 在块 \(C_2\) 中，它们之间边的概率为 \(b_{1,2} = 1/4\)。'
- en: '**E5.6.13** The expected degree of each vertex is \((p+q)n/2 = (1)(8)/2 = 4\).'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.13** 每个顶点的期望度数为 \((p+q)n/2 = (1)(8)/2 = 4\)。'
- en: '**E5.6.15** Let \(A_{i,j}\) be the indicator random variable for the presence
    of edge \(\{i,j\}\). Then the number of edges is \(X = \sum_{i<j} A_{i,j}\). Since
    the edges are independent,'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '**E5.6.15** 设 \(A_{i,j}\) 为边 \(\{i,j\}\) 存在的指示随机变量。则边的数量为 \(X = \sum_{i<j}
    A_{i,j}\)。由于边是独立的，'
- en: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathrm{Var}[X] &= \mathrm{Var}\left[\sum_{i<j} A_{i,j}\right]
    \\ &= \sum_{i<j} \mathrm{Var}[A_{i,j}] \\ &= \sum_{i<j} m_{i,j}(1-m_{i,j}) \\
    &= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right)
    + \frac{1}{2}\left(1-\frac{1}{2}\right) \\ &= \frac{11}{16}. \end{align*}\]
- en: 5.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-629
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.1.5\. 学习成果[#](#learning-outcomes "链接到本标题")
- en: Define undirected and directed graphs, and identify their key components such
    as vertices, edges, paths, and cycles.
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无向图和有向图，并识别其关键组件，如顶点、边、路径和环。
- en: Recognize special types of graphs, including cliques, trees, forests, and directed
    acyclic graphs (DAGs).
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别特殊类型的图，包括完全图、树、森林和有向无环图（DAGs）。
- en: Determine the connectivity of a graph and identify its connected components.
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定图的连通性并识别其连通分量。
- en: Construct the adjacency matrix, incidence matrix, and Laplacian matrix representations
    of a graph.
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造图的邻接矩阵、关联矩阵和拉普拉斯矩阵表示。
- en: Prove key properties of the Laplacian matrix, such as symmetry and positive
    semidefiniteness.
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明拉普拉斯矩阵的关键性质，如对称性和正半定性。
- en: Extend the concepts of graphs and their matrix representations to weighted graphs.
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图及其矩阵表示的概念扩展到加权图。
- en: Implement graph representations and algorithms using the NetworkX package in
    Python.
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python中的NetworkX包实现图表示和算法。
- en: Apply graph theory concepts to model and analyze real-world networks and relationships.
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图论概念应用于建模和分析现实世界的网络和关系。
- en: Outline the proof of the Spectral Theorem using a sequence of orthogonal transformations
    to diagonalize a matrix.
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一系列正交变换对矩阵进行对角化的方法概述谱定理的证明。
- en: Define the Rayleigh quotient and explain its relationship to eigenvectors and
    eigenvalues.
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义Rayleigh商并解释其与特征向量和特征值的关系。
- en: Prove the variational characterizations of the largest, smallest, and second
    smallest eigenvalues of a symmetric matrix using the Rayleigh quotient.
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Rayleigh商证明对称矩阵的最大、最小和第二小特征值的变分表征。
- en: State the Courant-Fischer Theorem and interpret its local and global formulas
    for the eigenvalues of a symmetric matrix.
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Courant-Fischer定理并解释其关于对称矩阵特征值的局部和全局公式。
- en: Apply the Courant-Fischer Theorem to characterize the third smallest eigenvalue
    of a symmetric matrix.
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用Courant-Fischer定理来表征对称矩阵的第三小特征值。
- en: State the key properties of the Laplacian matrix, including symmetry, positive
    semidefiniteness, and the constant eigenvector associated with the zero eigenvalue.
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述拉普拉斯矩阵的关键性质，包括对称性、正半定性和与零特征值相关的常数特征向量。
- en: Prove the relationship between graph connectivity and the second smallest eigenvalue
    (algebraic connectivity) of the Laplacian matrix.
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明图连通性与拉普拉斯矩阵的第二小特征值（代数连通性）之间的关系。
- en: Derive bounds on the largest eigenvalue of the Laplacian matrix using the maximum
    degree of the graph.
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图的度数最大值推导拉普拉斯矩阵最大特征值的界限。
- en: Formulate the variational characterization of the second smallest eigenvalue
    of the Laplacian matrix as a constrained optimization problem.
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将拉普拉斯矩阵的第二小特征值的变分表征作为约束优化问题来表述。
- en: Explain how the eigenvectors of the Laplacian matrix can be used for graph drawing
    and revealing the underlying geometry of the graph, using the variational characterization.
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释如何使用变分表征利用拉普拉斯矩阵的特征向量进行图绘制并揭示图的潜在几何结构。
- en: Compute the Laplacian matrix and its eigenvalues and eigenvectors for simple
    graphs, and interpret the results in terms of graph connectivity and geometry.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于简单图，计算拉普拉斯矩阵及其特征值和特征向量，并从图连通性和几何角度解释结果。
- en: Compute the cut ratio and the isoperimetric number (Cheeger constant) for a
    given graph cut.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定图割的割比和等周数（Cheeger常数）。
- en: State the Cheeger Inequality and explain its significance in relating the isoperimetric
    number to the second smallest Laplacian eigenvalue.
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述Cheeger不等式并解释其在将等周数与第二小拉普拉斯特征值相关联中的重要性。
- en: Describe the main steps of the graph-cutting algorithm based on the Fiedler
    vector.
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Fiedler向量描述图切割算法的主要步骤。
- en: Analyze the performance guarantees of the Fiedler vector-based graph-cutting
    algorithm and compare them to the optimal cut.
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析基于 Fiedler 向量的图切割算法的性能保证，并将其与最优切割进行比较。
- en: Apply spectral clustering techniques to identify communities within a graph,
    and evaluate the quality of the resulting partitions.
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将谱聚类技术应用于识别图中的社区，并评估结果划分的质量。
- en: Formulate the minimum bisection problem as a discrete optimization problem and
    relax it into a continuous optimization problem related to the Laplacian matrix.
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将最小二分问题表述为离散优化问题，并将其松弛为与拉普拉斯矩阵相关的连续优化问题。
- en: Define the inhomogeneous Erdős-Rényi (ER) random graph model and explain how
    it generalizes the standard ER model.
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义非齐次 Erdős-Rényi (ER) 随机图模型，并解释它如何推广标准 ER 模型。
- en: Generate inhomogeneous ER graphs and analyze their properties, such as edge
    density and the probability of connectivity, using Python and NetworkX.
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成非齐次 ER 图，并使用 Python 和 NetworkX 分析其属性，如边密度和连通性概率。
- en: Calculate the expected number of edges and triangles in an ER random graph.
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算 ER 随机图中期望的边数和三角形数。
- en: Describe the stochastic blockmodel (SBM) and its role in creating random graphs
    with planted partitions, and explain how it relates to the concept of homophily.
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述随机块模型 (SBM) 及其在创建具有植入划分的随机图中的作用，并解释它与同质性的概念之间的关系。
- en: Construct SBMs with specified block assignments and edge probabilities, and
    visualize the resulting graphs using Python and NetworkX.
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建具有指定块分配和边概率的 SBM，并使用 Python 和 NetworkX 可视化结果图。
- en: Compute the expected adjacency matrix of an SBM given the block assignment matrix
    and connection probabilities.
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据块分配矩阵和连接概率计算 SBM 的期望邻接矩阵。
- en: Apply spectral clustering algorithms to SBMs and evaluate their performance
    in recovering the ground truth community structure.
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将谱聚类算法应用于 SBM，并评估其在恢复真实社区结构方面的性能。
- en: Analyze the simplified symmetric stochastic blockmodel (SSBM) and derive the
    spectral decomposition of its expected adjacency matrix.
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析简化的对称随机块模型 (SSBM) 并推导其期望邻接矩阵的谱分解。
- en: Explain the relationship between the eigenvectors of the expected Laplacian
    matrix and the community structure in the SSBM.
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释期望拉普拉斯矩阵的特征向量与 SSBM 中的社区结构之间的关系。
- en: Investigate the behavior of the eigenvalues of the Laplacian matrix for large
    random graphs and discuss the connection to random matrix theory.
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究大随机图的拉普拉斯矩阵的特征值的行为，并讨论与随机矩阵理论的联系。
- en: \(\aleph\)
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 5.8.2\. Additional sections[#](#additional-sections "Link to this heading")
  id: totrans-666
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8.2. Additional sections[#](#additional-sections "链接到本标题")
- en: 5.8.2.1\. Spectral properties of SBM[#](#spectral-properties-of-sbm "Link to
    this heading")
  id: totrans-667
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.1\. SBM 的谱性质[#](#spectral-properties-of-sbm "链接到本标题")
- en: The SBM provides an alternative explanation for the efficacy of spectral clustering.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: SBM 为谱聚类的有效性提供了一个替代解释。
- en: 'We use a toy version of the model. Specifically, we assume that:'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用模型的一个玩具版本。具体来说，我们假设：
- en: The number of vertices \(n\) is even.
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点数 \(n\) 是偶数。
- en: Vertices \(1,\ldots,n/2\) are in block \(C_1\) while vertices \(n/2+1,\ldots,n\)
    are in block \(C_2\).
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点 \(1,\ldots,n/2\) 位于块 \(C_1\) 中，而顶点 \(n/2+1,\ldots,n\) 位于块 \(C_2\) 中。
- en: The intra-block connection probability is \(b_{1,1} = b_{2,2} = p\) and the
    inter-block connection probability is \(b_{1,2} = b_{2,1} = q < p\), with \(p,
    q \in (0,1)\).
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块内连接概率是 \(b_{1,1} = b_{2,2} = p\)，块间连接概率是 \(b_{1,2} = b_{2,1} = q < p\)，其中 \(p,
    q \in (0,1)\)。
- en: We allow self-loops, whose probability are the intra-block connection probability.
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们允许自环，其概率是块内连接概率。
- en: In that case, the matrix \(M\) is the block matrix
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 在那种情况下，矩阵 \(M\) 是一个块矩阵
- en: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
- en: where \(J \in \mathbb{R}^{n/2 \times n/2}\) is the all-one matrix. We refer
    to this model as the symmetric stochastic blockmodel (SSBM).
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(J \in \mathbb{R}^{n/2 \times n/2}\) 是全一矩阵。我们将此模型称为对称随机块模型 (SSBM)。
- en: The matrix \(M\) is symmetric. Hence it has a spectral decomposition. It is
    straightforward to compute. Let \(\mathbf{1}_m\) be the all-one vector of size
    \(m\).
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 是对称的。因此它有一个谱分解。计算很简单。设 \(\mathbf{1}_m\) 为大小为 \(m\) 的全一向量。
- en: '**LEMMA** **(Spectral Decomposition of SSBM)** Consider the matrix \(M\) above.
    Let'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(SSBM 的谱分解)** 考虑上述矩阵 \(M\)。设'
- en: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{and}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{和}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: Let \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) be an orthonormal basis of \((\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\})^\perp\). Denote by \(Q\) the matrix whose columns are \(\mathbf{q}_1,\ldots,\mathbf{q}_n\).
    Let
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) 为 \((\mathrm{span}\{\mathbf{q}_1, \mathbf{q}_2\})^\perp\)
    的一个正交基。记 \(Q\) 为列向量为 \(\mathbf{q}_1,\ldots,\mathbf{q}_n\) 的矩阵。令
- en: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{and} \quad \lambda_2 = \frac{p
    - q}{2} n. \]
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{和} \quad \lambda_2 = \frac{p -
    q}{2} n. \]
- en: Let \(\lambda_3,\ldots,\lambda_n = 0\). Denote by \(\Lambda\) the diagonal matrix
    with diagonal entries \(\lambda_1,\ldots,\lambda_n\).
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 令 \(\lambda_3,\ldots,\lambda_n = 0\)。记 \(\Lambda\) 为对角线元素为 \(\lambda_1,\ldots,\lambda_n\)
    的对角矩阵。
- en: Then a spectral decomposition of \(M\) is given by
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 \(M\) 的谱分解由以下给出
- en: \[ M = Q \Lambda Q^T. \]
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: \[ M = Q \Lambda Q^T. \]
- en: In particular, \(\mathbf{q}_i\) is an eigenvector of \(M\) with eigenvalue \(\lambda_i\).
    \(\flat\)
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，\(\mathbf{q}_i\) 是 \(M\) 的特征向量，其特征值为 \(\lambda_i\)。 \(\flat\)
- en: '*Proof:* We start with \(\mathbf{q}_1\) and note that by the formula for the
    multiplication of block matrices and the definition of \(J\)'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 我们从 \(\mathbf{q}_1\) 开始，并注意到通过分块矩阵乘法的公式和 \(J\) 的定义'
- en: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
- en: Similarly
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地
- en: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
- en: Matrix \(M\) has rank 2 since it only has two distinct columns (assuming \(p
    \neq q\)). By the *Spectral Theorem*, there is an orthonormal basis of eigenvectors.
    We have shown that \(\mathbf{q}_1\) and \(\mathbf{q}_2\) are eigenvectors with
    nonzero eigenvalues (again using that \(p \neq q\)). So the remaining eigenvectors
    must form a basis of the orthogonal complement of \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) and they must have eigenvalue \(0\) since they lie in the null
    space. In particular,
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 的秩为 2，因为它只有两个不同的列（假设 \(p \neq q\)）。根据**谱定理**，存在一个特征向量的正交基。我们已经证明 \(\mathbf{q}_1\)
    和 \(\mathbf{q}_2\) 是具有非零特征值的特征向量（再次使用 \(p \neq q\)）。因此，剩余的特征向量必须形成 \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) 的正交补的基，并且它们必须具有特征值 \(0\)，因为它们位于零空间中。特别是，
- en: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
- en: That proves the claim. \(\square\)
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了断言。 \(\square\)
- en: Why is this relevant to graph cutting? We first compute the expected Laplacian
    matrix. For this we need to expected degree of each vertex. This is obtained as
    follows
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这与图切割相关？我们首先计算期望的拉普拉斯矩阵。为此，我们需要每个顶点的期望度。这如下获得
- en: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
- en: where we counted the self-loop (if present) once. The same holds for the other
    vertices. So
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们只计算了自环（如果有的话）一次。其他顶点也是如此。因此
- en: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
- en: For any eigenvector \(\mathbf{q}_i\) of \(M\), we note that
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(M\) 的任何特征向量 \(\mathbf{q}_i\)，我们注意到
- en: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
- en: that is, \(\mathbf{q}_i\) is also an eigenvector of \(\overline{L}\). Its eigenvalues
    are therefore
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 即，\(\mathbf{q}_i\) 也是 \(\overline{L}\) 的一个特征向量。因此，它的特征值是
- en: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
- en: When \(p > q\), \(q n\) is the second smallest eigenvalue of \(\overline{L}\)
    with corresponding eigenvector
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(p > q\) 时，\(q n\) 是 \(\overline{L}\) 的第二个最小特征值，对应的特征向量为
- en: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: 'The key observation:'
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 关键观察：
- en: The eigenvector corresponding to the second smallest eigenvalue of \(\overline{L}\)
    perfectly encodes the community structure by assigning \(1/\sqrt{n}\) to the vertices
    in block \(C_1\) and \(-1/\sqrt{n}\) to the vertices in block \(C_2\)!
  id: totrans-704
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(\overline{L}\) 的第二个最小特征值对应的特征向量通过将 \(1/\sqrt{n}\) 分配给 \(C_1\) 块中的顶点，将 \(-1/\sqrt{n}\)
    分配给 \(C_2\) 块中的顶点完美地编码了社区结构！
- en: Now, in reality, we do not get to observe \(\overline{L}\). Instead we compute
    the actual Laplacian \(L\), a random matrix whose expectation if \(\overline{L}\).
    But it turns out that, for large \(n\), the eigenvectors of \(L\) corresponding
    to its two smallest eigenvalues are close to \(\mathbf{q}_1\) and \(\mathbf{q}_2\).
    Hence we can recover the community structure approximately from \(L\). This is
    far from obvious since \(L\) and \(\overline{L}\) are very different matrices.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在现实中，我们无法观察到 \(\overline{L}\)。相反，我们计算实际的拉普拉斯矩阵 \(L\)，这是一个期望为 \(\overline{L}\)
    的随机矩阵。但是，对于大的 \(n\)，\(L\) 的对应于其两个最小特征值的特征向量接近 \(\mathbf{q}_1\) 和 \(\mathbf{q}_2\)。因此，我们可以从
    \(L\) 中近似恢复社区结构。这远非显而易见，因为 \(L\) 和 \(\overline{L}\) 是非常不同的矩阵。
- en: A formal proof of this claim is beyond this course. But we illustrate it numerically
    next.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个断言的正式证明超出了本课程的范围。但我们将通过数值方法来展示它。
- en: '**NUMERICAL CORNER:** We first construct the block assignment and matrix \(M\)
    in the case of SSBM.'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落**：我们首先在 SSBM 的情况下构建块分配和矩阵 \(M\)。'
- en: '[PRE53]'
  id: totrans-708
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Here is an example.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子。
- en: '[PRE54]'
  id: totrans-710
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-712
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The eigenvectors and eigenvalues of the Laplacian in this case are:'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，拉普拉斯矩阵的特征向量和特征值如下：
- en: '[PRE57]'
  id: totrans-714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-716
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-719
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-720
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The first eigenvalue is roughly \(0\) as expected with an eigenvector which
    is proportional to the all-one vector. The second eigenvalue is somewhat close
    to the expected \(q n = 0.2 \cdot 10 = 2\) with an eigenvector that has different
    signs on the two blocks. This is consistent with our prediction.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个特征值大致为 \(0\)，正如预期的那样，对应的特征向量与全一向量成比例。第二个特征值与预期的 \(q n = 0.2 \cdot 10 = 2\)
    相当接近，对应的特征向量在两个块上有不同的符号。这与我们的预测一致。
- en: The eigenvalues exhibit an interesting behavior that is common for random matrices.
    This is easier to see for larger \(n\).
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值表现出随机矩阵中常见的有趣行为。对于较大的 \(n\)，这更容易看出。
- en: '[PRE64]'
  id: totrans-723
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-724
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
  id: totrans-725
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
- en: The first two eigenvalues are close to \(0\) and \(0.2 \cdot 100 = 20\) as expected.
    The rest of the eigenvalues are centered around \( (0.2 + 0.8) 100 /2 = 50\),
    but they are quite spread out, with a density resembling a half-circle. This is
    related to [Wigner’s semicircular law](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)
    which plays a key role in random matrix theory.
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个特征值如预期的那样接近 \(0\) 和 \(0.2 \cdot 100 = 20\)。其余的特征值围绕 \( (0.2 + 0.8) 100 /2
    = 50\)，但它们分布得很广，密度类似于半圆。这与 [Wigner 的半圆定律](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)
    有关，这在随机矩阵理论中起着关键作用。
- en: \(\unlhd\)
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.8.2.2\. Weyl’s inequality[#](#weyls-inequality "Link to this heading")
  id: totrans-728
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.2\. Weyl 不等式[#](#weyls-inequality "链接到这个标题")
- en: We prove an inequality on the sensitivity of eigenvalues which is useful in
    certain applications.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 我们证明了关于特征值敏感性的一个不等式，这在某些应用中很有用。
- en: For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), we let \(\lambda_j(C)\),
    \(j=1, \ldots, d\), be the eigenvalues of \(C\) in non-increasing order with corresponding
    orthonormal eigenvectors \(\mathbf{v}_j\), \(j=1, \ldots, d\). The following lemma
    is one version of what is known as *Weyl’s Inequality*.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，我们令 \(\lambda_j(C)\)，\(j=1, \ldots,
    d\)，为 \(C\) 的特征值，按非递增顺序排列，对应的正交归一特征向量为 \(\mathbf{v}_j\)，\(j=1, \ldots, d\)。以下引理是所谓
    *Weyl 不等式* 的一种形式。
- en: '**LEMMA** **(Weyl)** Let \(A \in \mathbb{R}^{d \times d}\) and \(B \in \mathbb{R}^{d
    \times d}\) be symmetric matrices. Then, for all \(j=1, \ldots, d\),'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(Weyl)** 设 \(A \in \mathbb{R}^{d \times d}\) 和 \(B \in \mathbb{R}^{d
    \times d}\) 为对称矩阵。那么，对于所有 \(j=1, \ldots, d\)，'
- en: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
- en: where \(\|C\|_2\) is the induced \(2\)-norm of \(C\). \(\flat\)
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\|C\|_2\) 是 \(C\) 的诱导 \(2\)-范数。 \(\flat\)
- en: '*Proof idea:* We use the extremal characterization of the eigenvalues together
    with a dimension argument.'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路*: 我们使用特征值的极值特征与维度论证相结合。'
- en: '*Proof:* For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), define the
    subspaces'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明*: 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，定义子空间'
- en: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{and}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{和}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
- en: where \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) form an orthonormal basis of eigenvectors
    of \(C\). Let \(H = B - A\). We prove only the upper bound. The other direction
    follows from interchanging the roles of \(A\) and \(B\). Because
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) 形成特征向量 \(C\) 的正交归一基。设 \(H = B - A\)。我们只证明上界。其他方向可以通过交换
    \(A\) 和 \(B\) 的角色得出。因为
- en: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
- en: it it can be shown (Try it!) that
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以证明（试试看！）：
- en: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
- en: Hence the \(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) is non-empty. Let
    \(\mathbf{v}\) be a unit vector in that intersection.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) 是非空的。设 \(\mathbf{v}\) 是该交集中的一个单位向量。
- en: By *Courant-Fischer*,
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 *Courant-Fischer*，
- en: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
- en: Moreover, by *Cauchy-Schwarz*, since \(\|\mathbf{v}\|=1\)
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，根据 *Cauchy-Schwarz*，由于 \(\|\mathbf{v}\|=1\)
- en: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
- en: which proves the claim. \(\square\)
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了命题。 \(\square\)
- en: 5.8.2.3\. Weighted case[#](#weighted-case "Link to this heading")
  id: totrans-747
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.3\. 加权情况[#](#weighted-case "链接到本标题")
- en: The concepts we have introduced can also be extended to weighted graphs, that
    is, graphs with weights on the edges. These weights might be a measure of the
    strength of the connection for instance. In this section, we briefly describe
    this extension, which is the basis for a [discrete calculus](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs).
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所引入的概念也可以扩展到加权图中，即具有边权的图。这些权重可能是连接强度的度量。在本节中，我们简要描述这种扩展，这是离散微积分的基础。[离散微积分](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs)。
- en: '**DEFINITION** **(Weighted Graph or Digraph)** A weighted graph (or weighted
    digraph) is a triple \(G = (V, E, w)\) where \((V, E)\) is a graph (or directed
    graph) and \(w : E \to \mathbb{R}_+\) is a function that assigns positive real
    weights to the edges. For ease of notation, we write \(w_e = w_{ij} = w(i,j)\)
    for the weight of edge \(e = \{i,j\}\) (or \(e = (i,j)\) in the directed case).
    \(\natural\)'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图或有向图)** 加权图（或加权有向图）是一个三元组 \(G = (V, E, w)\)，其中 \((V, E)\) 是一个图（或有向图），且
    \(w : E \to \mathbb{R}_+\) 是一个函数，它将正实数权重分配给边。为了方便起见，我们写 \(w_e = w_{ij} = w(i,j)\)
    表示边 \(e = \{i,j\}\)（或在有向情况下 \(e = (i,j)\)）的权重。 \(\natural\)'
- en: As we did for graphs, we denote the vertices \(\{1,\ldots, n\}\) and the edges
    \(\{e_1,\ldots, e_{m}\}\), where \(n = |V|\) and \(m =|E|\). Properties of graphs
    can be generalized naturally. For instance, one defines the degree of a vertex
    \(i\) as, in the undirected case,
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在图中所做的那样，我们表示顶点 \(\{1,\ldots, n\}\) 和边 \(\{e_1,\ldots, e_{m}\}\)，其中 \(n
    = |V|\) 和 \(m =|E|\)。图的性质可以自然地推广。例如，定义顶点 \(i\) 的度为，在无向情况下，
- en: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
- en: Similarly, in the directed case, the out-degree and in-degree are
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在有向情况中，出度和入度分别是
- en: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{and} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{和} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
- en: In the undirected case, the adjacency matrix is generalized as follows. (A similar
    generalization holds for the directed case.)
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 在无向情况中，邻接矩阵被推广如下。（对于有向情况也有类似的推广。）
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Graph)** Let \(G = (V, E, w)\)
    be a weighted graph with \(n = |V|\) vertices. The adjacency matrix \(A\) of \(G\)
    is the \(n\times n\) symmetric matrix defined as'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图的邻接矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点的加权图。\(G\) 的邻接矩阵
    \(A\) 是一个 \(n\times n\) 的对称矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: A similar generalization holds for the directed case.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有向情况也有类似的推广。
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Digraph)** Let \(G = (V, E,
    w)\) be a weighted digraph with \(n = |V|\) vertices. The adjacency matrix \(A\)
    of \(G\) is the \(n\times n\) matrix defined as'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权有向图的邻接矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点的加权有向图。\(G\)
    的邻接矩阵 \(A\) 是一个 \(n\times n\) 的矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: '**Laplacian matrix for weighted graphs** In the case of a weighted graph, the
    Laplacian can then be defined as follows.'
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权图的拉普拉斯矩阵** 在加权图的情况下，拉普拉斯矩阵可以定义为以下。'
- en: '**DEFINITION** **(Laplacian for Weighted Graph)** Let \(G = (V, E, w)\) be
    a weighted graph with \(n = |V|\) vertices and adjacency matrix \(A\). Let \(D
    = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) be the weighted degree matrix.
    The Laplacian matrix associated to \(G\) is defined as \(L = D - A\). \(\natural\)'
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图的拉普拉斯矩阵)** 设 \(G = (V, E, w)\) 为一个具有 \(n = |V|\) 个顶点和邻接矩阵 \(A\)
    的加权图。设 \(D = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) 为加权度矩阵。与 \(G\) 相关的拉普拉斯矩阵定义为
    \(L = D - A\)。 \(\natural\)'
- en: It can be shown (Try it!) that the Laplacian quadratic form satisfies in the
    weighted case
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）在加权情况下，拉普拉斯二次型满足
- en: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\).
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\).
- en: 'As a positive semidefinite matrix (Exercise: Why?), the weighted Laplacian
    has an orthonormal basis of eigenvectors with nonnegative eigenvalues that satisfy
    the variational characterization we derived above. In particular, if we denote
    the eigenvalues \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\), it follows from
    *Courant-Fischer* that'
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 作为正半定矩阵（练习：为什么？），加权拉普拉斯矩阵具有非负特征值的正交归一特征向量基，这些特征值满足我们上面推导出的变分特征。特别是，如果我们表示特征值为
    \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\)，根据 *Courant-Fischer*，可以得出
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
- en: If we generalize the cut ratio as
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将割比推广为
- en: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\)，并令
- en: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
- en: it can be shown (Try it!) that
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试试看！）：
- en: \[ \mu_2 \leq 2 \phi_G \]
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 \leq 2 \phi_G \]
- en: as in the unweighted case.
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 如同无权情况。
- en: '**Normalized Laplacian** Other variants of the Laplacian matrix have also been
    studied. We introduced the normalized Laplacian next. Recall that in the weighted
    case, the degree is defined as \(\delta(i) = \sum_{j:\{i,j\} \in E} w_{i,j}\).'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化拉普拉斯矩阵** 拉普拉斯矩阵的其他变体也已被研究。我们接下来介绍了归一化拉普拉斯矩阵。回想一下，在加权情况下，度定义为 \(\delta(i)
    = \sum_{j:\{i,j\} \in E} w_{i,j}\)。'
- en: '**DEFINITION** **(Normalized Laplacian)** The normalized Laplacian of \(G =
    (V,E,w)\) with adjacency matrix \(A\) and degree matrix \(D\) is defined as'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（归一化拉普拉斯矩阵）** \(G = (V,E,w)\) 的归一化拉普拉斯矩阵，其中 \(A\) 是邻接矩阵，\(D\) 是度矩阵，定义为'
- en: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
- en: \(\natural\)
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: Using our previous observations about multiplication by diagonal matrices, the
    entries of \(\mathcal{L}\) are
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前关于对角矩阵乘法的观察，\(\mathcal{L}\) 的项为
- en: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j} = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j}) = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
- en: 'We also note the following relation to the Laplacian matrix:'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到以下与拉普拉斯矩阵的关系：
- en: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
- en: 'We check that the normalized Laplacian is symmetric:'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查归一化拉普拉斯矩阵是对称的：
- en: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
- en: It is also positive semidefinite. Indeed,
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 它也是正半定的。实际上，
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
- en: by the properties of the Laplacian matrix.
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 由拉普拉斯矩阵的性质。
- en: Hence by the *Spectral Theorem*, we can write
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据 *谱定理*，我们可以写出
- en: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
- en: where the \(\mathbf{z}_i\)s are orthonormal eigenvectors of \(\mathcal{L}\)
    and the eigenvalues satisfy \(0 \leq \eta_1 \leq \eta_2 \leq \cdots \leq \eta_n\).
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{z}_i\) 是 \(\mathcal{L}\) 的正交归一特征向量，并且特征值满足 \(0 \leq \eta_1 \leq
    \eta_2 \leq \cdots \leq \eta_n\)。
- en: 'One more observation: because the constant vector is eigenvector of \(L\) with
    eigenvalue \(0\), we get that \(D^{1/2} \mathbf{1}\) is an eigenvector of \(\mathcal{L}\)
    with eigenvalue \(0\). So \(\eta_1 = 0\) and we set'
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察：因为常量向量是 \(L\) 的特征向量，其特征值为 \(0\)，所以我们得到 \(D^{1/2} \mathbf{1}\) 是 \(\mathcal{L}\)
    的特征向量，其特征值为 \(0\)。因此 \(\eta_1 = 0\)，我们设
- en: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
- en: which makes \(\mathbf{z}_1\) into a unit norm vector.
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 \(\mathbf{z}_1\) 成为一个单位范数向量。
- en: The relationship to the Laplacian matrix immediately implies (prove it!) that
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: 与拉普拉斯矩阵的关系立即暗示（证明它！）：
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\).
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\).
- en: Through the change of variables
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 通过变量变换
- en: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
- en: '*Courant-Fischer* gives this time (Why?)'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: '*Courant-Fischer* 给出了这个结果（为什么？）'
- en: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
- en: For a subset of vertices \(S \subseteq V\), let
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顶点子集 \(S \subseteq V\)，设
- en: \[ |S|_w = \sum_{i \in S} \delta(i), \]
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |S|_w = \sum_{i \in S} \delta(i), \]
- en: which we refer to as the volume of \(S\). It is measure of the size of \(S\)
    weighted by the degrees.
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其称为 \(S\) 的体积。这是 \(S\) 大小的一个加权度量。
- en: If we consider the normalized cut ratio, or bottleneck ratio,
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑归一化切割比率，或瓶颈比率，
- en: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\)，并设
- en: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
- en: it can be shown (Try it!) that
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试试看！）：
- en: \[ \eta_2 \leq 2 \phi^N_G. \]
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 \leq 2 \phi^N_G. \]
- en: The normalized cut ratio is similar to the cut ratio, except that the notion
    of balance of the cut is measured in terms of volume. Note that this concept is
    also useful in the unweighted case.
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化切割比率与切割比率类似，不同之处在于切割平衡的概念是通过体积来衡量的。请注意，这个概念在无权情况中也是有用的。
- en: We will an application of the normalized Laplacian later in this chapter.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面讨论归一化拉普拉斯的应用。
- en: 5.8.2.4\. Image segmentation[#](#image-segmentation "Link to this heading")
  id: totrans-813
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.4\. 图像分割[#](#image-segmentation "链接到这个标题")
- en: 'We give a different, more involved application of the ideas developed in this
    topic to image segmentation. Let us quote Wikipedia:'
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将给出这个主题中发展出的思想在图像分割中的不同、更复杂的应用。让我们引用维基百科：
- en: In computer vision, image segmentation is the process of partitioning a digital
    image into multiple segments (sets of pixels, also known as image objects). The
    goal of segmentation is to simplify and/or change the representation of an image
    into something that is more meaningful and easier to analyze. Image segmentation
    is typically used to locate objects and boundaries (lines, curves, etc.) in images.
    More precisely, image segmentation is the process of assigning a label to every
    pixel in an image such that pixels with the same label share certain characteristics.
  id: totrans-815
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在计算机视觉中，图像分割是将数字图像分割成多个段（像素集，也称为图像对象）的过程。分割的目的是简化图像表示，或将其转换为更有意义且更容易分析的形式。图像分割通常用于在图像中定位对象和边界（线条、曲线等）。更精确地说，图像分割是将标签分配给图像中的每个像素，使得具有相同标签的像素具有某些共同特征。
- en: Throughout, we will use the [`scikit-image`](https://scikit-image.org) library
    for processing images.
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们将使用 `scikit-image`（https://scikit-image.org）库来处理图像。
- en: '[PRE66]'
  id: totrans-817
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: As an example, here is a picture of cell nuclei taken through optical microscopy
    as part of some medical experiment. It is taken from [here](https://www.kaggle.com/c/data-science-bowl-2018/data).
    Here we used the function [`skimage.io.imread`](https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread)
    to load an image from file.
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是一张通过光学显微镜拍摄的细胞核图片，作为某些医学实验的一部分。图片来源于[这里](https://www.kaggle.com/c/data-science-bowl-2018/data)。在这里，我们使用了函数
    `skimage.io.imread`（https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread）从文件中加载图像。
- en: '[PRE67]'
  id: totrans-819
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
  id: totrans-820
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
- en: Suppose that, as part of this experiment, we have a large number of such images
    and need to keep track of the cell nuclei in some way (maybe count how many there
    are, or track them from frame to frame). A natural pre-processing step is to identify
    the cell nuclei in the image. We use image segmentation for this purpose.
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在这个实验中，我们有一大批这样的图像，并且需要以某种方式跟踪细胞核（可能计数有多少个，或者从一帧跟踪到另一帧）。一个自然的预处理步骤是在图像中识别细胞核。我们为此目的使用图像分割。
- en: We will come back to the example below. Let us start with some further examples.
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回到下面的例子。让我们先看看一些其他的例子。
- en: We will first work with the following [map of Wisconsin regions](https://www.dhs.wisconsin.gov/areaadmin/index.htm).
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用以下 [威斯康星州地区图](https://www.dhs.wisconsin.gov/areaadmin/index.htm)。
- en: '[PRE68]'
  id: totrans-824
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
  id: totrans-825
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
- en: A color image such as this one is encoded as a \(3\)-dimensional array (or [tensor](https://en.wikipedia.org/wiki/Tensor)),
    meaning that it is an array with \(3\) indices (unlike matrices which have only
    two indices).
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的彩色图像被编码为三维数组（或 [张量](https://en.wikipedia.org/wiki/Tensor)），这意味着它有三个索引（与只有两个索引的矩阵不同）。
- en: '[PRE69]'
  id: totrans-827
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-828
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The first two indices capture the position of a pixel. The third index capture
    the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model). Put differently,
    each pixel in the image has three numbers (between 0 and 255) attached to it that
    encodes its color.
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个索引捕获像素的位置。第三个索引捕获 [RGB 颜色模型](https://en.wikipedia.org/wiki/RGB_color_model)。换句话说，图像中的每个像素都附有三个数字（介于0到255之间），这些数字编码了其颜色。
- en: 'For instance, at position \((300,400)\) the RGB color is:'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在位置 \((300,400)\) 的 RGB 颜色是：
- en: '[PRE71]'
  id: totrans-831
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-832
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-833
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
  id: totrans-834
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
- en: To perform image segmentation using the spectral graph theory we have developed,
    we transform our image into a graph.
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们开发的频谱图理论进行图像分割，我们首先将图像转换为图。
- en: The first step is to coarsen the image by creating super-pixels, or regions
    of pixels that are close and have similar color. For this purpose, we will use
    [`skimage.segmentation.slic`](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic),
    which in essence uses \(k\)-means clustering on the color space to identify blobs
    of pixels that are in close proximity and have similar colors. It takes as imput
    a number of super-pixels desired (`n_segments`), a compactness parameter (`compactness`)
    and a smoothing parameter (`sigma`). The output is a label assignment for each
    pixel in the form of a \(2\)-dimensional array.
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是通过创建超像素（即颜色相似且邻近的像素区域）来细化图像。为此，我们将使用 `skimage.segmentation.slic`，它本质上是在颜色空间上使用
    \(k\) 均值聚类来识别颜色相似且邻近的像素块。它接受所需的超像素数量（`n_segments`）、紧凑度参数（`compactness`）和平滑参数（`sigma`）作为输入。输出是每个像素的标签分配，形式为二维数组。
- en: 'On the choice of the parameter `compactness` via [scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic):'
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: 关于通过 [scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic)
    选择参数 `compactness`：
- en: Balances color proximity and space proximity. Higher values give more weight
    to space proximity, making superpixel shapes more square/cubic. This parameter
    depends strongly on image contrast and on the shapes of objects in the image.
    We recommend exploring possible values on a log scale, e.g., 0.01, 0.1, 1, 10,
    100, before refining around a chosen value.
  id: totrans-838
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 平衡颜色邻近度和空间邻近度。较高的值赋予空间邻近度更高的权重，使超像素形状更加方形/立方形。此参数强烈依赖于图像对比度和图像中物体的形状。我们建议在以对数刻度探索可能的值之前，先在选定的值周围进行细化，例如，0.01，0.1，1，10，100。
- en: The parameter `sigma` controls the level of [blurring](https://en.wikipedia.org/wiki/Gaussian_blur)
    applied to the image as a pre-processing step. In practice, experimentation is
    required to choose good parameters.
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 `sigma` 控制对图像应用的前处理模糊程度。[模糊](https://en.wikipedia.org/wiki/Gaussian_blur)
    在实践中需要通过实验来选择合适的参数。
- en: '[PRE74]'
  id: totrans-840
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-841
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: A neat way to vizualize the super-pixels is to use the function [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    which takes as input an image and an array of labels. In the mode `kind='avg'`,
    it outputs a new image where the color of each pixel is replaced with the average
    color of its label (that is, the average of the RGB color over all pixels with
    the same label). As they say, an image is worth a thousand words - let’s just
    see what it does.
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数 `skimage.color.label2rgb`（[链接](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)）来可视化超像素是一种整洁的方法，该函数接受一个图像和一个标签数组作为输入。在
    `kind='avg'` 模式下，它输出一个新图像，其中每个像素的颜色被其标签的平均颜色所替换（即，所有具有相同标签的像素的RGB颜色的平均值）。正如他们所说，一张图片胜过千言万语——让我们看看它做了什么。
- en: '[PRE76]'
  id: totrans-843
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-844
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-845
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
  id: totrans-846
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
- en: Recall that our goal is to turn our original image into a graph. After the first
    step of creating super-pixels, the second step is to form a graph whose nodes
    are the super-pixels. Edges are added between adjacent super-pixels and a weight
    is given to each edge which reflects the difference in mean color between the
    two.
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们的目标是把原始图像转换成图。在创建超像素的第一步之后，第二步是形成一个图，其节点是超像素。在相邻的超像素之间添加边，并为每条边分配一个权重，该权重反映了两个区域平均颜色之间的差异。
- en: 'We use [`skimage.graph.rag_mean_color`](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color).
    In mode `similarity`, it uses the following weight formula (quoting the documentation):'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `skimage.graph.rag_mean_color`（[链接](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color)）。在
    `similarity` 模式下，它使用以下权重公式（引用文档）：
- en: The weight between two adjacent regions is exp(-d^2/sigma) where d=|c1-c2|,
    where c1 and c2 are the mean colors of the two regions. It represents how similar
    two regions are.
  id: totrans-849
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 两个相邻区域之间的权重是 exp(-d^2/sigma)，其中 d=|c1-c2|，c1 和 c2 是两个区域的平均颜色。它表示两个区域有多相似。
- en: The output, which is known as a region adjacency graph (RAG), is a `NetworkX`
    graph and can be manipulated using that package.
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: 输出，被称为区域邻接图（RAG），是一个 `NetworkX` 图，可以使用该包进行操作。
- en: '[PRE79]'
  id: totrans-851
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
  id: totrans-852
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
- en: '`scikit-image` also provides a more effective way of vizualizing a RAG, using
    the function [`skimage.future.graph.show_rag`](https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag).
    Here the graph is super-imposed on the image and the edge weights are depicted
    by their color.'
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-image` 还提供了一个更有效的方式来可视化RAG，使用函数 `skimage.future.graph.show_rag`（[链接](https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag)）。在这里，图被叠加在图像上，边权重通过颜色表示。'
- en: '[PRE80]'
  id: totrans-854
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
  id: totrans-855
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
- en: We can apply the spectral clustering techniques we have developed in this chapter.
    Next we compute a spectral decomposition of the weighted Laplacian and plot the
    eigenvalues.
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以应用本章中开发的谱聚类技术。接下来，我们计算加权拉普拉斯算子的谱分解并绘制特征值。
- en: '[PRE81]'
  id: totrans-857
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-858
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-859
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
  id: totrans-860
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
- en: From the theory, this suggests that there are roughly 15 components in this
    graph. We project to \(15\) dimensions and apply \(k\)-means clustering to find
    segments. Rather than using our own implementation, we use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    from the [`scikit-learn`](https://scikit-learn.org/stable/index.html) library.
    That implementation uses the [\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)
    initialization, which is particularly effective in practice. A label assignment
    for each node can be accessed using `labels_`.
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上看，这表明这张图中大约有15个组件。我们将数据投影到 \(15\) 维，并应用 \(k\)-means 聚类来找到段。我们不是使用自己的实现，而是使用来自
    `scikit-learn` 库的 `sklearn.cluster.KMeans`。该实现使用 [\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)
    初始化，这在实践中特别有效。可以使用 `labels_` 访问每个节点的标签分配。
- en: '[PRE84]'
  id: totrans-862
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-863
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'To vizualize the segmentation, we assign to each segment (i.e., collection
    of super-pixels) a random color. This can be done using [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    again, this time in mode `kind=''overlay''`. First, we assign to each pixel from
    the original image its label under this clustering. Recall that `labels1` assigns
    to each pixel its super-pixel (represented by a node of the RAG), so that applying
    `assign_seg` element-wise to `labels1` results is assigning a cluster to each
    pixel. In code:'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: '为了可视化分割，我们为每个段（即超像素集合）分配一个随机颜色。这可以通过再次使用 `skimage.color.label2rgb` 实现，这次在模式
    `kind=''overlay''` 下。首先，我们将原始图像中的每个像素的标签分配给它在这个聚类下的标签。回想一下，`labels1` 将每个像素分配给其超像素（由
    RAG 的节点表示），因此将 `assign_seg` 元素应用于 `labels1` 的结果是将每个像素分配给一个簇。在代码中： '
- en: '[PRE86]'
  id: totrans-865
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-866
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-867
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-868
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-869
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
  id: totrans-870
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
- en: As you can see, the result is reasonable but far from perfect.
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，结果合理，但远非完美。
- en: For ease of use, we encapsulate the main steps above in sub-routines.
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们将上述主要步骤封装在子程序中。
- en: '[PRE91]'
  id: totrans-873
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-874
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-875
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-876
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Let’s try a more complicated image. This one is taken from [here](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/).
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个更复杂的图像。这张图片来自[这里](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/)。
- en: '[PRE95]'
  id: totrans-878
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
  id: totrans-879
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
- en: Recall that the choice of parameters requires significant fidgeting.
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，参数的选择需要大量的调整。
- en: '[PRE96]'
  id: totrans-881
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
  id: totrans-882
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
- en: '[PRE97]'
  id: totrans-883
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
  id: totrans-884
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
- en: '[PRE98]'
  id: totrans-885
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
  id: totrans-886
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
- en: Again, the results are far from perfect - but not unreasonable.
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，结果远非完美——但也不算不合理。
- en: Finally, we return to our medical example. We first reload the image and find
    super-pixels.
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回到我们的医学示例。我们首先重新加载图像并找到超像素。
- en: '[PRE99]'
  id: totrans-889
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
  id: totrans-890
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
- en: We then form the weighted Laplacian and plot its eigenvalues. This time, about
    \(40\) dimensions seem appropriate.
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后形成加权拉普拉斯算子并绘制其特征值。这次，大约 \(40\) 维看起来是合适的。
- en: '[PRE100]'
  id: totrans-892
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
  id: totrans-893
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
- en: '[PRE101]'
  id: totrans-894
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
  id: totrans-895
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
- en: This method is quite finicky. The choice of parameters affects the results significantly.
    You should see for yourself.
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法相当挑剔。参数的选择会显著影响结果。您应该亲自看看。
- en: We mention that `scikit-image` has an implementation of a closely related method,
    Normalized Cut, [`skimage.graph.cut_normalized`](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized).
    Rather than performing \(k\)-means after projection, it recursively performs \(2\)-way
    cuts on the RAG and resulting subgraphs.
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到，`scikit-image` 有一个与该方法密切相关的方法的实现，即归一化切割，[`skimage.graph.cut_normalized`](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized)。它不是在投影后执行
    \(k\)-means，而是在 RAG 和结果子图上递归执行双向切割。
- en: We try it next. The results are similar as you can see.
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来尝试一下。结果如您所见相似。
- en: '[PRE102]'
  id: totrans-899
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
  id: totrans-900
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
- en: There are many other image segmentation methods. See for example [here](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation).
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他的图像分割方法。例如，请参阅[这里](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation)。
- en: 5.8.2.1\. Spectral properties of SBM[#](#spectral-properties-of-sbm "Link to
    this heading")
  id: totrans-902
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.1\. SBM的谱性质[#](#spectral-properties-of-sbm "链接到本标题")
- en: The SBM provides an alternative explanation for the efficacy of spectral clustering.
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: SBM为谱聚类的有效性提供了一个替代解释。
- en: 'We use a toy version of the model. Specifically, we assume that:'
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用模型的一个玩具版本。具体来说，我们假设：
- en: The number of vertices \(n\) is even.
  id: totrans-905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点数 \(n\) 是偶数。
- en: Vertices \(1,\ldots,n/2\) are in block \(C_1\) while vertices \(n/2+1,\ldots,n\)
    are in block \(C_2\).
  id: totrans-906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶点 \(1,\ldots,n/2\) 在块 \(C_1\) 中，而顶点 \(n/2+1,\ldots,n\) 在块 \(C_2\) 中。
- en: The intra-block connection probability is \(b_{1,1} = b_{2,2} = p\) and the
    inter-block connection probability is \(b_{1,2} = b_{2,1} = q < p\), with \(p,
    q \in (0,1)\).
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块内连接概率为 \(b_{1,1} = b_{2,2} = p\)，块间连接概率为 \(b_{1,2} = b_{2,1} = q < p\)，其中 \(p,
    q \in (0,1)\)。
- en: We allow self-loops, whose probability are the intra-block connection probability.
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们允许自环，其概率与块内连接概率相同。
- en: In that case, the matrix \(M\) is the block matrix
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，矩阵 \(M\) 是一个块矩阵
- en: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} M = \begin{pmatrix} p J & q J\\ qJ & pJ \end{pmatrix}, \end{split}\]
- en: where \(J \in \mathbb{R}^{n/2 \times n/2}\) is the all-one matrix. We refer
    to this model as the symmetric stochastic blockmodel (SSBM).
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(J \in \mathbb{R}^{n/2 \times n/2}\) 是全一矩阵。我们将此模型称为对称随机块模型（SSBM）。
- en: The matrix \(M\) is symmetric. Hence it has a spectral decomposition. It is
    straightforward to compute. Let \(\mathbf{1}_m\) be the all-one vector of size
    \(m\).
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 是对称的。因此它有一个谱分解。计算起来很简单。令 \(\mathbf{1}_m\) 为大小为 \(m\) 的全一向量。
- en: '**LEMMA** **(Spectral Decomposition of SSBM)** Consider the matrix \(M\) above.
    Let'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(SSBM的谱分解)** 考虑上述矩阵 \(M\)。令'
- en: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{and}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_1 = \frac{1}{\sqrt{n}} \mathbf{1}_n \quad \text{和}
    \quad \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ -
    \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: Let \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) be an orthonormal basis of \((\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\})^\perp\). Denote by \(Q\) the matrix whose columns are \(\mathbf{q}_1,\ldots,\mathbf{q}_n\).
    Let
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(\mathbf{q}_3,\ldots,\mathbf{q}_n\) 为 \((\mathrm{span}\{\mathbf{q}_1, \mathbf{q}_2\})^\perp\)
    的一个正交基。用 \(Q\) 表示列向量分别为 \(\mathbf{q}_1,\ldots,\mathbf{q}_n\) 的矩阵。令
- en: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{and} \quad \lambda_2 = \frac{p
    - q}{2} n. \]
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_1 = \frac{p + q}{2} n \quad \text{和} \quad \lambda_2 = \frac{p -
    q}{2} n. \]
- en: Let \(\lambda_3,\ldots,\lambda_n = 0\). Denote by \(\Lambda\) the diagonal matrix
    with diagonal entries \(\lambda_1,\ldots,\lambda_n\).
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: 令 \(\lambda_3,\ldots,\lambda_n = 0\)。用 \(\Lambda\) 表示对角线元素为 \(\lambda_1,\ldots,\lambda_n\)
    的对角矩阵。
- en: Then a spectral decomposition of \(M\) is given by
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 \(M\) 的谱分解给出
- en: \[ M = Q \Lambda Q^T. \]
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: \[ M = Q \Lambda Q^T. \]
- en: In particular, \(\mathbf{q}_i\) is an eigenvector of \(M\) with eigenvalue \(\lambda_i\).
    \(\flat\)
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，\(\mathbf{q}_i\) 是 \(M\) 的一个特征向量，其特征值为 \(\lambda_i\)。\(\flat\)
- en: '*Proof:* We start with \(\mathbf{q}_1\) and note that by the formula for the
    multiplication of block matrices and the definition of \(J\)'
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明* 我们从 \(\mathbf{q}_1\) 开始，并注意到根据块矩阵乘法公式和 \(J\) 的定义'
- en: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_1 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \mathbf{1}_n \\ &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    + q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p + q) J \mathbf{1}_{\frac{n}{2}}\\
    (p + q) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p + q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_1 \mathbf{q}_1. \end{align*}\]
- en: Similarly
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地
- en: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} M \mathbf{q}_2 &= \begin{pmatrix} p J & q J\\ q J & p J \end{pmatrix}
    \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} p J \mathbf{1}_{\frac{n}{2}}
    - q J \mathbf{1}_{\frac{n}{2}}\\ q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix} (p - q) J \mathbf{1}_{\frac{n}{2}}\\
    (q - p) J \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \frac{1}{\sqrt{n}} \begin{pmatrix}
    (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\ (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
    \end{pmatrix} \\ &= \frac{p - q}{2} \sqrt{n} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}}\\
    - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\ &= \lambda_2 \mathbf{q}_2. \end{align*}\]
- en: Matrix \(M\) has rank 2 since it only has two distinct columns (assuming \(p
    \neq q\)). By the *Spectral Theorem*, there is an orthonormal basis of eigenvectors.
    We have shown that \(\mathbf{q}_1\) and \(\mathbf{q}_2\) are eigenvectors with
    nonzero eigenvalues (again using that \(p \neq q\)). So the remaining eigenvectors
    must form a basis of the orthogonal complement of \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) and they must have eigenvalue \(0\) since they lie in the null
    space. In particular,
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 \(M\) 的秩为 2，因为它只有两个不同的列（假设 \(p \neq q\)）。根据**谱定理**，存在一个正交基的特征向量。我们已经证明 \(\mathbf{q}_1\)
    和 \(\mathbf{q}_2\) 是具有非零特征值的特征向量（再次使用 \(p \neq q\)）。因此，剩余的特征向量必须形成 \(\mathrm{span}\{\mathbf{q}_1,
    \mathbf{q}_2\}\) 的正交补的基，并且它们必须具有特征值 \(0\)，因为它们位于零空间中。特别是，
- en: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_3 = \lambda_4 = \ldots = \lambda_n = 0. \]
- en: That proves the claim. \(\square\)
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了该主张。 \(\square\)
- en: Why is this relevant to graph cutting? We first compute the expected Laplacian
    matrix. For this we need to expected degree of each vertex. This is obtained as
    follows
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这与图割相关？我们首先计算期望的拉普拉斯矩阵。为此，我们需要每个顶点的期望度。这可以通过以下方式获得
- en: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[\delta(1)] = \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right] =
    \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}] = \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n
    q = (p + q) \frac{n}{2}, \]
- en: where we counted the self-loop (if present) once. The same holds for the other
    vertices. So
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们只计算了自环（如果有的话）一次。其他顶点也是如此。因此
- en: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} := \E[L] = \E[D] - \E[A] = (p + q) \frac{n}{2} I_{n \times n}
    - M. \]
- en: For any eigenvector \(\mathbf{q}_i\) of \(M\), we note that
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(M\) 的任意特征向量 \(\mathbf{q}_i\)，我们注意到
- en: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
  id: totrans-933
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \overline{L} \,\mathbf{q}_i = (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i
    - M \mathbf{q}_i = \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
    \]
- en: that is, \(\mathbf{q}_i\) is also an eigenvector of \(\overline{L}\). Its eigenvalues
    are therefore
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 即，\(\mathbf{q}_i\) 也是 \(\overline{L}\) 的特征向量。因此，它的特征值是
- en: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (p + q) \frac{n}{2} - \frac{p + q}{2} n = 0, \quad (p + q) \frac{n}{2} -
    \frac{p - q}{2} n = q n, \quad (p + q) \frac{n}{2}. \]
- en: When \(p > q\), \(q n\) is the second smallest eigenvalue of \(\overline{L}\)
    with corresponding eigenvector
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(p > q\) 时，\(q n\) 是 \(\overline{L}\) 的第二小特征值，对应的特征向量
- en: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{q}_2 = \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2}
    \\ - \mathbf{1}_{n/2} \end{pmatrix}. \end{split}\]
- en: 'The key observation:'
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 关键观察：
- en: The eigenvector corresponding to the second smallest eigenvalue of \(\overline{L}\)
    perfectly encodes the community structure by assigning \(1/\sqrt{n}\) to the vertices
    in block \(C_1\) and \(-1/\sqrt{n}\) to the vertices in block \(C_2\)!
  id: totrans-939
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对应于 \(\overline{L}\) 第二小特征值的特征向量通过将 \(1/\sqrt{n}\) 分配给 \(C_1\) 块中的顶点，将 \(-1/\sqrt{n}\)
    分配给 \(C_2\) 块中的顶点，完美地编码了社区结构！
- en: Now, in reality, we do not get to observe \(\overline{L}\). Instead we compute
    the actual Laplacian \(L\), a random matrix whose expectation if \(\overline{L}\).
    But it turns out that, for large \(n\), the eigenvectors of \(L\) corresponding
    to its two smallest eigenvalues are close to \(\mathbf{q}_1\) and \(\mathbf{q}_2\).
    Hence we can recover the community structure approximately from \(L\). This is
    far from obvious since \(L\) and \(\overline{L}\) are very different matrices.
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在现实中，我们无法观察到 \(\overline{L}\)。相反，我们计算实际的拉普拉斯矩阵 \(L\)，这是一个期望值为 \(\overline{L}\)
    的随机矩阵。但结果是，对于大的 \(n\)，\(L\) 的对应于其两个最小特征值的特征向量接近 \(\mathbf{q}_1\) 和 \(\mathbf{q}_2\)。因此，我们可以从
    \(L\) 中近似恢复社区结构。这远非显而易见，因为 \(L\) 和 \(\overline{L}\) 是非常不同的矩阵。
- en: A formal proof of this claim is beyond this course. But we illustrate it numerically
    next.
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个断言的正式证明超出了本课程的范围。但我们将通过数值方法来展示它。
- en: '**NUMERICAL CORNER:** We first construct the block assignment and matrix \(M\)
    in the case of SSBM.'
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：** 我们首先在 SSBM 的情况下构建块分配和矩阵 \(M\)。'
- en: '[PRE103]'
  id: totrans-943
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Here is an example.
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子。
- en: '[PRE104]'
  id: totrans-945
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-946
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'The eigenvectors and eigenvalues of the Laplacian in this case are:'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，拉普拉斯矩阵的特征向量和特征值如下：
- en: '[PRE107]'
  id: totrans-949
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-950
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-951
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-952
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-953
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-954
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-955
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: The first eigenvalue is roughly \(0\) as expected with an eigenvector which
    is proportional to the all-one vector. The second eigenvalue is somewhat close
    to the expected \(q n = 0.2 \cdot 10 = 2\) with an eigenvector that has different
    signs on the two blocks. This is consistent with our prediction.
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，第一个特征值大约为 \(0\)，对应的特征向量与全一向量成比例。第二个特征值略接近预期的 \(q n = 0.2 \cdot 10 = 2\)，对应的特征向量在两个块上有不同的符号。这与我们的预测一致。
- en: The eigenvalues exhibit an interesting behavior that is common for random matrices.
    This is easier to see for larger \(n\).
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值表现出随机矩阵中常见的有趣行为。对于较大的 \(n\)，这更容易看出。
- en: '[PRE114]'
  id: totrans-958
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-959
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
  id: totrans-960
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/c310cb9e0454e14839e37ace47a3a2e6be6493c406b477b7b6e5d1cc26e660e9.png](../Images/c13e5512c5c6416c42ab21f7a26e3278.png)'
- en: The first two eigenvalues are close to \(0\) and \(0.2 \cdot 100 = 20\) as expected.
    The rest of the eigenvalues are centered around \( (0.2 + 0.8) 100 /2 = 50\),
    but they are quite spread out, with a density resembling a half-circle. This is
    related to [Wigner’s semicircular law](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)
    which plays a key role in random matrix theory.
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个特征值接近 \(0\) 和 \(0.2 \cdot 100 = 20\)，正如预期的那样。其余的特征值围绕 \( (0.2 + 0.8) 100
    /2 = 50\)，但它们分布得很广，密度类似于半圆。这与 [Wigner 的半圆定律](https://en.wikipedia.org/wiki/Wigner_semicircle_distribution)有关，这在随机矩阵理论中起着关键作用。
- en: \(\unlhd\)
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 5.8.2.2\. Weyl’s inequality[#](#weyls-inequality "Link to this heading")
  id: totrans-963
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.2\. Weyl 的不等式[#](#weyls-inequality "链接到这个标题")
- en: We prove an inequality on the sensitivity of eigenvalues which is useful in
    certain applications.
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: 我们证明了一个关于特征值敏感度的不等式，这在某些应用中很有用。
- en: For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), we let \(\lambda_j(C)\),
    \(j=1, \ldots, d\), be the eigenvalues of \(C\) in non-increasing order with corresponding
    orthonormal eigenvectors \(\mathbf{v}_j\), \(j=1, \ldots, d\). The following lemma
    is one version of what is known as *Weyl’s Inequality*.
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，我们令 \(\lambda_j(C)\)，\(j=1, \ldots,
    d\)，为 \(C\) 的特征值，按非递减顺序排列，对应的正交归一特征向量为 \(\mathbf{v}_j\)，\(j=1, \ldots, d\)。以下引理是所谓
    *Weyl 不等式* 的一种形式。
- en: '**LEMMA** **(Weyl)** Let \(A \in \mathbb{R}^{d \times d}\) and \(B \in \mathbb{R}^{d
    \times d}\) be symmetric matrices. Then, for all \(j=1, \ldots, d\),'
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(Weyl)** 设 \(A \in \mathbb{R}^{d \times d}\) 和 \(B \in \mathbb{R}^{d
    \times d}\) 为对称矩阵。那么，对于所有 \(j=1, \ldots, d\)，'
- en: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right| \leq \|B- A\|_2
    \]
- en: where \(\|C\|_2\) is the induced \(2\)-norm of \(C\). \(\flat\)
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\|C\|_2\) 是 \(C\) 的诱导 \(2\)-范数。 \(\flat\)
- en: '*Proof idea:* We use the extremal characterization of the eigenvalues together
    with a dimension argument.'
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明思路:* 我们使用特征值的极值特征与维度论证。'
- en: '*Proof:* For a symmetric matrix \(C \in \mathbb{R}^{d \times d}\), define the
    subspaces'
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 对于一个对称矩阵 \(C \in \mathbb{R}^{d \times d}\)，定义子空间'
- en: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{and}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots, \mathbf{v}_k) \quad\text{和}\quad
    \mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots, \mathbf{v}_d) \]
- en: where \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) form an orthonormal basis of eigenvectors
    of \(C\). Let \(H = B - A\). We prove only the upper bound. The other direction
    follows from interchanging the roles of \(A\) and \(B\). Because
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{v}_1,\ldots,\mathbf{v}_d\) 构成 \(C\) 的特征向量的正交归一基。令 \(H = B - A\)。我们只证明上界。其他方向可以通过交换
    \(A\) 和 \(B\) 的角色得到。因为
- en: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}(\mathcal{V}_j(B)) + \mathrm{dim}(\mathcal{W}_{d-j+1}(A)) = j
    + (d-j+1) = d+1 \]
- en: it it can be shown (Try it!) that
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）
- en: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right) \geq
    d+1 - d = 1. \]
- en: Hence the \(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) is non-empty. Let
    \(\mathbf{v}\) be a unit vector in that intersection.
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 \(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\) 非空。令 \(\mathbf{v}\) 为该交集中的一个单位向量。
- en: By *Courant-Fischer*,
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 *Courant-Fischer*，
- en: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda_j(B) \leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle = \langle \mathbf{v},
    A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle \leq \lambda_j(A)
    + \langle \mathbf{v}, H \mathbf{v}\rangle. \]
- en: Moreover, by *Cauchy-Schwarz*, since \(\|\mathbf{v}\|=1\)
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，根据 *Cauchy-Schwarz*，由于 \(\|\mathbf{v}\|=1\)
- en: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\|
    \leq \|H\|_2 \]
- en: which proves the claim. \(\square\)
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了该命题。 \(\square\)
- en: 5.8.2.3\. Weighted case[#](#weighted-case "Link to this heading")
  id: totrans-982
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.3\. 加权情况[#](#weighted-case "链接到本标题")
- en: The concepts we have introduced can also be extended to weighted graphs, that
    is, graphs with weights on the edges. These weights might be a measure of the
    strength of the connection for instance. In this section, we briefly describe
    this extension, which is the basis for a [discrete calculus](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs).
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所介绍的概念也可以扩展到加权图，即具有边权重的图。这些权重可能是连接强度的度量。在本节中，我们简要描述这种扩展，这是 [离散微积分](https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs)
    的基础。
- en: '**DEFINITION** **(Weighted Graph or Digraph)** A weighted graph (or weighted
    digraph) is a triple \(G = (V, E, w)\) where \((V, E)\) is a graph (or directed
    graph) and \(w : E \to \mathbb{R}_+\) is a function that assigns positive real
    weights to the edges. For ease of notation, we write \(w_e = w_{ij} = w(i,j)\)
    for the weight of edge \(e = \{i,j\}\) (or \(e = (i,j)\) in the directed case).
    \(\natural\)'
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(加权图或有向图)** 加权图（或加权有向图）是一个三元组 \(G = (V, E, w)\)，其中 \((V, E)\) 是一个图（或有向图），且
    \(w : E \to \mathbb{R}_+\) 是一个函数，它将正实数权重分配给边。为了方便记号，我们写 \(w_e = w_{ij} = w(i,j)\)
    表示边 \(e = \{i,j\}\)（或在有向情况下 \(e = (i,j)\)）的权重。 \(\natural\)'
- en: As we did for graphs, we denote the vertices \(\{1,\ldots, n\}\) and the edges
    \(\{e_1,\ldots, e_{m}\}\), where \(n = |V|\) and \(m =|E|\). Properties of graphs
    can be generalized naturally. For instance, one defines the degree of a vertex
    \(i\) as, in the undirected case,
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在图论中所做的那样，我们表示顶点集合 \(\{1,\ldots, n\}\) 和边集合 \(\{e_1,\ldots, e_{m}\}\)，其中
    \(n = |V|\) 和 \(m =|E|\)。图的性质可以自然地推广。例如，我们定义顶点 \(i\) 的度数为，在无向情况下，
- en: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \delta(i) = \sum_{j:\{i,j\} \in E} w_{ij}. \]
- en: Similarly, in the directed case, the out-degree and in-degree are
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在有向情况下，出度和入度是
- en: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{and} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ \delta^+(i) = \sum_{j: (i,j) \in E} w_{ij} \qquad \text{和} \qquad \delta^+(i)
    = \sum_{j: (j,i) \in E} w_{ij}. \]'
- en: In the undirected case, the adjacency matrix is generalized as follows. (A similar
    generalization holds for the directed case.)
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: 在无向情况下，邻接矩阵的推广如下。（对于有向情况也有类似的推广。）
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Graph)** Let \(G = (V, E, w)\)
    be a weighted graph with \(n = |V|\) vertices. The adjacency matrix \(A\) of \(G\)
    is the \(n\times n\) symmetric matrix defined as'
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（加权图的邻接矩阵）** 设 \(G = (V, E, w)\) 是一个具有 \(n = |V|\) 个顶点的加权图。\(G\) 的邻接矩阵
    \(A\) 是一个 \(n\times n\) 的对称矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $\{i,j\} \in E$}\\
    0 & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: A similar generalization holds for the directed case.
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有向情况，也有类似的推广。
- en: '**DEFINITION** **(Adjacency Matrix for Weighted Digraph)** Let \(G = (V, E,
    w)\) be a weighted digraph with \(n = |V|\) vertices. The adjacency matrix \(A\)
    of \(G\) is the \(n\times n\) matrix defined as'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（加权有向图的邻接矩阵）** 设 \(G = (V, E, w)\) 是一个具有 \(n = |V|\) 个顶点的加权有向图。\(G\)
    的邻接矩阵 \(A\) 是一个 \(n\times n\) 的矩阵，定义为'
- en: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} A_{ij} = \begin{cases} w_{ij} & \text{if $(i,j) \in E$}\\ 0
    & \text{o.w.} \end{cases} \end{align*}\]
- en: \(\natural\)
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: '**Laplacian matrix for weighted graphs** In the case of a weighted graph, the
    Laplacian can then be defined as follows.'
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权图的拉普拉斯矩阵** 在加权图的情况下，拉普拉斯矩阵可以定义为以下。'
- en: '**DEFINITION** **(Laplacian for Weighted Graph)** Let \(G = (V, E, w)\) be
    a weighted graph with \(n = |V|\) vertices and adjacency matrix \(A\). Let \(D
    = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) be the weighted degree matrix.
    The Laplacian matrix associated to \(G\) is defined as \(L = D - A\). \(\natural\)'
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（加权图的拉普拉斯矩阵）** 设 \(G = (V, E, w)\) 是一个具有 \(n = |V|\) 个顶点和邻接矩阵 \(A\)
    的加权图。设 \(D = \mathrm{diag}(\delta(1), \ldots, \delta(n))\) 是加权度矩阵。与 \(G\) 相关的拉普拉斯矩阵定义为
    \(L = D - A\)。\(\natural\)'
- en: It can be shown (Try it!) that the Laplacian quadratic form satisfies in the
    weighted case
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）在加权情况下拉普拉斯二次型满足
- en: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \langle \mathbf{x}, L \mathbf{x} \rangle = \sum_{\{i,j\} \in E} w_{ij} (x_i
    - x_j)^2 \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\).
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\)。
- en: 'As a positive semidefinite matrix (Exercise: Why?), the weighted Laplacian
    has an orthonormal basis of eigenvectors with nonnegative eigenvalues that satisfy
    the variational characterization we derived above. In particular, if we denote
    the eigenvalues \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\), it follows from
    *Courant-Fischer* that'
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 作为正半定矩阵（练习：为什么？），加权拉普拉斯矩阵具有正交归一的特征向量基，其特征值非负，并满足我们上面推导出的变分特征。特别是，如果我们表示特征值为
    \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\)，根据 *Courant-Fischer*，可以得出
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
- en: If we generalize the cut ratio as
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将割比推广为
- en: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}} \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\)，并设
- en: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi_G = \min\left\{ \phi(S)\,:\, \emptyset \neq S \subset V \right\} \]
- en: it can be shown (Try it!) that
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试一试！）有
- en: \[ \mu_2 \leq 2 \phi_G \]
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu_2 \leq 2 \phi_G \]
- en: as in the unweighted case.
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: 与无权情况相同。
- en: '**Normalized Laplacian** Other variants of the Laplacian matrix have also been
    studied. We introduced the normalized Laplacian next. Recall that in the weighted
    case, the degree is defined as \(\delta(i) = \sum_{j:\{i,j\} \in E} w_{i,j}\).'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化拉普拉斯矩阵** 其他拉普拉斯矩阵的变体也已被研究。我们接下来介绍了归一化拉普拉斯矩阵。回想一下，在加权情况下，度数定义为 \(\delta(i)
    = \sum_{j:\{i,j\} \in E} w_{i,j}\)。'
- en: '**DEFINITION** **(Normalized Laplacian)** The normalized Laplacian of \(G =
    (V,E,w)\) with adjacency matrix \(A\) and degree matrix \(D\) is defined as'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(归一化拉普拉斯矩阵)** \(G = (V,E,w)\) 的归一化拉普拉斯矩阵，其中 \(A\) 是邻接矩阵，\(D\) 是度矩阵，定义为'
- en: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = I - D^{-1/2} A D^{-1/2}. \]
- en: \(\natural\)
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: Using our previous observations about multiplication by diagonal matrices, the
    entries of \(\mathcal{L}\) are
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: 利用我们之前关于对角矩阵乘法的观察，\(\mathcal{L}\) 的项为
- en: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j} = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathcal{L})_{i,j} = (I - (D^{-1/2} A D^{-1/2})_{i,j} = 1 - \frac{a_{i,j}}{\sqrt{\delta(i)
    \delta(j)}}. \]
- en: 'We also note the following relation to the Laplacian matrix:'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到与拉普拉斯矩阵的关系：
- en: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = D^{-1/2} L D^{-1/2}. \]
- en: 'We check that the normalized Laplacian is symmetric:'
  id: totrans-1019
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查归一化拉普拉斯矩阵是对称的：
- en: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathcal{L}^T &= I^T - (D^{-1/2} A D^{-1/2})^T\\ &= I - (D^{-1/2})^T
    A^T (D^{-1/2})^T\\ &= I - D^{-1/2} A D^{-1/2}\\ &= \mathcal{L}. \end{align*}\]
- en: It is also positive semidefinite. Indeed,
  id: totrans-1021
  prefs: []
  type: TYPE_NORMAL
  zh: 它也是正半定的。确实，
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
    = (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x}) \geq 0, \]
- en: by the properties of the Laplacian matrix.
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 由拉普拉斯矩阵的性质。
- en: Hence by the *Spectral Theorem*, we can write
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据**谱定理**，我们可以写出
- en: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L} = \sum_{i=1}^n \eta_i \mathbf{z}_i \mathbf{z}_i^T, \]
- en: where the \(\mathbf{z}_i\)s are orthonormal eigenvectors of \(\mathcal{L}\)
    and the eigenvalues satisfy \(0 \leq \eta_1 \leq \eta_2 \leq \cdots \leq \eta_n\).
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{z}_i\) 是 \(\mathcal{L}\) 的正交归一特征向量，并且特征值满足 \(0 \leq \eta_1 \leq
    \eta_2 \leq \cdots \leq \eta_n\)。
- en: 'One more observation: because the constant vector is eigenvector of \(L\) with
    eigenvalue \(0\), we get that \(D^{1/2} \mathbf{1}\) is an eigenvector of \(\mathcal{L}\)
    with eigenvalue \(0\). So \(\eta_1 = 0\) and we set'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察：因为常向量是 \(L\) 的特征向量，其特征值为 \(0\)，所以我们得到 \(D^{1/2} \mathbf{1}\) 是 \(\mathcal{L}\)
    的特征向量，其特征值为 \(0\)。因此 \(\eta_1 = 0\)，我们设
- en: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (\mathbf{z}_1)_i = \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
    = \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n], \]
- en: which makes \(\mathbf{z}_1\) into a unit norm vector.
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 \(\mathbf{z}_1\) 成为一个单位范数向量。
- en: The relationship to the Laplacian matrix immediately implies (prove it!) that
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: 与拉普拉斯矩阵的关系立即表明（证明它！）：
- en: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{x}^T \mathcal{L} \mathbf{x} = \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}}
    - \frac{x_j}{\sqrt{\delta(j)}}\right)^2, \]
- en: for \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\).
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\)。
- en: Through the change of variables
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: 通过变量变换
- en: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \frac{x_i}{\sqrt{\delta(i)}}, \]
- en: '*Courant-Fischer* gives this time (Why?)'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: '*Courant-Fischer* 给出了这次（为什么？）'
- en: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 = \min\left\{ \sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\, \mathbf{y}
    = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0, \sum_{u
    = 1}^n \delta(u) y_u^2 = 1 \right\}. \]
- en: For a subset of vertices \(S \subseteq V\), let
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顶点子集 \(S \subseteq V\)，设
- en: \[ |S|_w = \sum_{i \in S} \delta(i), \]
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |S|_w = \sum_{i \in S} \delta(i), \]
- en: which we refer to as the volume of \(S\). It is measure of the size of \(S\)
    weighted by the degrees.
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其称为 \(S\) 的体积。它是 \(S\) 大小的度量，按度数加权。
- en: If we consider the normalized cut ratio, or bottleneck ratio,
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑归一化切割比，或瓶颈比，
- en: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N(S) = \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
    \]
- en: for \(\emptyset \neq S \subset V\) and let
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\emptyset \neq S \subset V\)，设
- en: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \phi^N_G = \min\left\{ \phi^N(S)\,:\, \emptyset \neq S \subset V \right\}
    \]
- en: it can be shown (Try it!) that
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明（试试看！）这样的
- en: \[ \eta_2 \leq 2 \phi^N_G. \]
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \eta_2 \leq 2 \phi^N_G. \]
- en: The normalized cut ratio is similar to the cut ratio, except that the notion
    of balance of the cut is measured in terms of volume. Note that this concept is
    also useful in the unweighted case.
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化切割比率与切割比率类似，不同之处在于切割平衡的概念是用体积来衡量的。请注意，这个概念在无权情况下也很有用。
- en: We will an application of the normalized Laplacian later in this chapter.
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面部分介绍归一化拉普拉斯算子的一个应用。
- en: 5.8.2.4\. Image segmentation[#](#image-segmentation "Link to this heading")
  id: totrans-1048
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8.2.4\. 图像分割[#](#image-segmentation "链接到这个标题")
- en: 'We give a different, more involved application of the ideas developed in this
    topic to image segmentation. Let us quote Wikipedia:'
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将给出这个主题中发展出的想法在图像分割上的不同、更复杂的应用。让我们引用维基百科：
- en: In computer vision, image segmentation is the process of partitioning a digital
    image into multiple segments (sets of pixels, also known as image objects). The
    goal of segmentation is to simplify and/or change the representation of an image
    into something that is more meaningful and easier to analyze. Image segmentation
    is typically used to locate objects and boundaries (lines, curves, etc.) in images.
    More precisely, image segmentation is the process of assigning a label to every
    pixel in an image such that pixels with the same label share certain characteristics.
  id: totrans-1050
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在计算机视觉中，图像分割是将数字图像分割成多个段（像素集，也称为图像对象）的过程。分割的目的是简化图像表示或将其转换为更有意义且更容易分析的形式。图像分割通常用于在图像中定位对象和边界（线条、曲线等）。更确切地说，图像分割是将标签分配给图像中的每个像素，使得具有相同标签的像素具有某些共同特征。
- en: Throughout, we will use the [`scikit-image`](https://scikit-image.org) library
    for processing images.
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们将使用`[`scikit-image](https://scikit-image.org)`库来处理图像。
- en: '[PRE116]'
  id: totrans-1052
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: As an example, here is a picture of cell nuclei taken through optical microscopy
    as part of some medical experiment. It is taken from [here](https://www.kaggle.com/c/data-science-bowl-2018/data).
    Here we used the function [`skimage.io.imread`](https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread)
    to load an image from file.
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是一张通过光学显微镜拍摄的细胞核图片，作为某些医学实验的一部分。图片来自[这里](https://www.kaggle.com/c/data-science-bowl-2018/data)。在这里，我们使用了函数`[`skimage.io.imread](https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread)`从文件中加载图像。
- en: '[PRE117]'
  id: totrans-1054
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
  id: totrans-1055
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/97466aec7bce35e54824c2c5e06887867f2842611eaf3732aeddf742f92cd10a.png](../Images/b66f83b52d9b11d0de7f40288586ce34.png)'
- en: Suppose that, as part of this experiment, we have a large number of such images
    and need to keep track of the cell nuclei in some way (maybe count how many there
    are, or track them from frame to frame). A natural pre-processing step is to identify
    the cell nuclei in the image. We use image segmentation for this purpose.
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在这个实验中，我们有一大批这样的图像，并且需要以某种方式跟踪细胞核（可能计数有多少个，或者从一帧跟踪到另一帧）。一个自然的预处理步骤是识别图像中的细胞核。我们使用图像分割来完成这个目的。
- en: We will come back to the example below. Let us start with some further examples.
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回到下面的例子。让我们先看看一些进一步的例子。
- en: We will first work with the following [map of Wisconsin regions](https://www.dhs.wisconsin.gov/areaadmin/index.htm).
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用以下[威斯康星州地区地图](https://www.dhs.wisconsin.gov/areaadmin/index.htm)。
- en: '[PRE118]'
  id: totrans-1059
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
  id: totrans-1060
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/01522a0eaaf3a16ba3949def4e39f361f25796dc87411fa8ec5eab3c2899f2ce.png](../Images/b3847f3c93be42a38b89f12fdc9dbb12.png)'
- en: A color image such as this one is encoded as a \(3\)-dimensional array (or [tensor](https://en.wikipedia.org/wiki/Tensor)),
    meaning that it is an array with \(3\) indices (unlike matrices which have only
    two indices).
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: 一张如图这样的彩色图像被编码为三维数组（或[张量](https://en.wikipedia.org/wiki/Tensor))，这意味着它有三个索引（与只有两个索引的矩阵不同）。
- en: '[PRE119]'
  id: totrans-1062
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-1063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: The first two indices capture the position of a pixel. The third index capture
    the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model). Put differently,
    each pixel in the image has three numbers (between 0 and 255) attached to it that
    encodes its color.
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个索引捕获像素的位置。第三个索引捕获[RGB颜色模型](https://en.wikipedia.org/wiki/RGB_color_model)。换句话说，图像中的每个像素都附有三个数字（介于0到255之间），这些数字编码了它的颜色。
- en: 'For instance, at position \((300,400)\) the RGB color is:'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在位置(300,400)的RGB颜色是：
- en: '[PRE121]'
  id: totrans-1066
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-1067
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-1068
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
  id: totrans-1069
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/13b8e08064348a7fea064b045068e2d0414b2d1683ceddb1bc8773f2db0ede76.png](../Images/c1276f6e98c715b5fb7749fec4e9e8f4.png)'
- en: To perform image segmentation using the spectral graph theory we have developed,
    we transform our image into a graph.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们开发的频谱图理论进行图像分割，我们将我们的图像转换成一个图。
- en: The first step is to coarsen the image by creating super-pixels, or regions
    of pixels that are close and have similar color. For this purpose, we will use
    [`skimage.segmentation.slic`](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic),
    which in essence uses \(k\)-means clustering on the color space to identify blobs
    of pixels that are in close proximity and have similar colors. It takes as imput
    a number of super-pixels desired (`n_segments`), a compactness parameter (`compactness`)
    and a smoothing parameter (`sigma`). The output is a label assignment for each
    pixel in the form of a \(2\)-dimensional array.
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是通过创建超像素，即颜色相似且接近的像素区域，来简化图像。为此，我们将使用 `skimage.segmentation.slic`（[链接](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic)），其本质上是在颜色空间上使用
    \(k\)-means 聚类来识别颜色相似且接近的像素块。它接受所需的超像素数量（`n_segments`）、紧凑度参数（`compactness`）和平滑参数（`sigma`）。输出是每个像素的标签分配，形式为一个二维数组。
- en: 'On the choice of the parameter `compactness` via [scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic):'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: 关于参数 `compactness` 的选择，请参阅 [scikit-image](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic)：
- en: Balances color proximity and space proximity. Higher values give more weight
    to space proximity, making superpixel shapes more square/cubic. This parameter
    depends strongly on image contrast and on the shapes of objects in the image.
    We recommend exploring possible values on a log scale, e.g., 0.01, 0.1, 1, 10,
    100, before refining around a chosen value.
  id: totrans-1073
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 平衡颜色接近度和空间接近度。较高的值赋予空间接近度更高的权重，使超像素形状更接近正方形/立方体。此参数强烈依赖于图像对比度和图像中物体的形状。我们建议在以对数刻度探索可能的值之前，先在选定的值周围进行细化，例如，0.01、0.1、1、10、100。
- en: The parameter `sigma` controls the level of [blurring](https://en.wikipedia.org/wiki/Gaussian_blur)
    applied to the image as a pre-processing step. In practice, experimentation is
    required to choose good parameters.
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 `sigma` 控制对图像应用的前处理步骤中的模糊程度。[模糊](https://en.wikipedia.org/wiki/Gaussian_blur)。在实际操作中，需要通过实验来选择合适的参数。
- en: '[PRE124]'
  id: totrans-1075
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-1076
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: A neat way to vizualize the super-pixels is to use the function [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    which takes as input an image and an array of labels. In the mode `kind='avg'`,
    it outputs a new image where the color of each pixel is replaced with the average
    color of its label (that is, the average of the RGB color over all pixels with
    the same label). As they say, an image is worth a thousand words - let’s just
    see what it does.
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化超像素的一个整洁方法是使用函数 `skimage.color.label2rgb`（[链接](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)），它接受一个图像和一个标签数组作为输入。在模式
    `kind='avg'` 下，它输出一个新图像，其中每个像素的颜色被其标签的平均颜色所替代（即，所有具有相同标签的像素的 RGB 颜色的平均值）。正如他们所说，一张图片胜过千言万语——让我们看看它到底做了什么。
- en: '[PRE126]'
  id: totrans-1078
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-1079
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-1080
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
  id: totrans-1081
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/7959aeea4b885bae42571d1446beddae6b8272cb0a592785efe289c5b481d97d.png](../Images/e3129bc4814ed40c14212f0ea836da19.png)'
- en: Recall that our goal is to turn our original image into a graph. After the first
    step of creating super-pixels, the second step is to form a graph whose nodes
    are the super-pixels. Edges are added between adjacent super-pixels and a weight
    is given to each edge which reflects the difference in mean color between the
    two.
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们的目标是把原始图像转换成一个图。在创建超像素的第一步之后，第二步是形成一个图，其节点是超像素。在相邻的超像素之间添加边，并为每条边分配一个权重，该权重反映了两个超像素之间平均颜色的差异。
- en: 'We use [`skimage.graph.rag_mean_color`](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color).
    In mode `similarity`, it uses the following weight formula (quoting the documentation):'
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `skimage.graph.rag_mean_color`（[链接](https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color)）。在
    `similarity` 模式下，它使用以下权重公式（引用文档）：
- en: The weight between two adjacent regions is exp(-d^2/sigma) where d=|c1-c2|,
    where c1 and c2 are the mean colors of the two regions. It represents how similar
    two regions are.
  id: totrans-1084
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 两个相邻区域之间的权重是 exp(-d^2/sigma)，其中 d=|c1-c2|，c1 和 c2 是两个区域的平均颜色。它表示两个区域有多相似。
- en: The output, which is known as a region adjacency graph (RAG), is a `NetworkX`
    graph and can be manipulated using that package.
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 输出，被称为区域邻接图（RAG），是一个`NetworkX`图，可以使用该包进行操作。
- en: '[PRE129]'
  id: totrans-1086
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
  id: totrans-1087
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/230bc75d3f1084bc07ca478f991bd5ced705add22482e96a084317bb211fb081.png](../Images/bb37436c8158e8a34ec74fa221b117a3.png)'
- en: '`scikit-image` also provides a more effective way of vizualizing a RAG, using
    the function [`skimage.future.graph.show_rag`](https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag).
    Here the graph is super-imposed on the image and the edge weights are depicted
    by their color.'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-image`还提供了一个更有效的方式来可视化RAG，使用函数`[`skimage.future.graph.show_rag`](https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag)。在这里，图被叠加在图像上，边权重通过颜色表示。'
- en: '[PRE130]'
  id: totrans-1089
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
  id: totrans-1090
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/8a74a1138feb384576ca2d04f1969c62068ac89d8007bd6c60571b02238c378d.png](../Images/849c34aaf5b7ff0e0edbd7a96bef3e4f.png)'
- en: We can apply the spectral clustering techniques we have developed in this chapter.
    Next we compute a spectral decomposition of the weighted Laplacian and plot the
    eigenvalues.
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以应用本章中开发的谱聚类技术。接下来，我们计算加权拉普拉斯算子的谱分解并绘制特征值。
- en: '[PRE131]'
  id: totrans-1092
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-1093
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-1094
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
  id: totrans-1095
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/35f7fdf29a2fda4096b00760443b1d7aedeceb12bdb718235b397a5193cff774.png](../Images/7cd4aa1ca84d37bfcc939bc25f473504.png)'
- en: From the theory, this suggests that there are roughly 15 components in this
    graph. We project to \(15\) dimensions and apply \(k\)-means clustering to find
    segments. Rather than using our own implementation, we use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    from the [`scikit-learn`](https://scikit-learn.org/stable/index.html) library.
    That implementation uses the [\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)
    initialization, which is particularly effective in practice. A label assignment
    for each node can be accessed using `labels_`.
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上看，这表明图中大约有15个组件。我们将数据投影到15个维度，并应用k-means聚类来找到段。我们不是使用自己的实现，而是使用来自`scikit-learn`库的`[`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)。该实现使用[\(k\)-means\(++\)](https://en.wikipedia.org/wiki/K-means%2B%2B)初始化，这在实践中特别有效。可以使用`labels_`访问每个节点的标签分配。
- en: '[PRE134]'
  id: totrans-1097
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: '[PRE135]'
  id: totrans-1098
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'To vizualize the segmentation, we assign to each segment (i.e., collection
    of super-pixels) a random color. This can be done using [`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)
    again, this time in mode `kind=''overlay''`. First, we assign to each pixel from
    the original image its label under this clustering. Recall that `labels1` assigns
    to each pixel its super-pixel (represented by a node of the RAG), so that applying
    `assign_seg` element-wise to `labels1` results is assigning a cluster to each
    pixel. In code:'
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化分割，我们为每个段（即超级像素的集合）分配一个随机颜色。这可以通过再次使用`[`skimage.color.label2rgb`](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb)`来完成，这次在模式`kind='overlay'`下。首先，我们将原始图像中的每个像素的标签分配给这个聚类。回想一下，`labels1`将每个像素分配给其超级像素（由RAG的节点表示），因此将`assign_seg`逐元素应用于`labels1`的结果是将一个簇分配给每个像素。在代码中：
- en: '[PRE136]'
  id: totrans-1100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: '[PRE137]'
  id: totrans-1101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-1102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: '[PRE139]'
  id: totrans-1103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-1104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
  id: totrans-1105
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/5aabdebf592677a0ae025884f681391b4f658489872b6a3d2b0ac134372946b4.png](../Images/d35fc1e0118ce41fd83d724b6ed4ed0b.png)'
- en: As you can see, the result is reasonable but far from perfect.
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，结果是合理的，但远非完美。
- en: For ease of use, we encapsulate the main steps above in sub-routines.
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于使用，我们将上述主要步骤封装在子程序中。
- en: '[PRE141]'
  id: totrans-1108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-1109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-1110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-1111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: Let’s try a more complicated image. This one is taken from [here](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/).
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个更复杂的图像。这张图片来自[这里](https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/)。
- en: '[PRE145]'
  id: totrans-1113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
  id: totrans-1114
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ffbfad2bbecf61e6ece848ef5ae22a7637c7fc18d200b285ae234c3468c213b2.png](../Images/1b8ad9014f9e0ecc4b6afbad4deca689.png)'
- en: Recall that the choice of parameters requires significant fidgeting.
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，参数的选择需要大量的调整。
- en: '[PRE146]'
  id: totrans-1116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
  id: totrans-1117
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/4d5e0ff3eed959013ca469b82626364e171eeee2de5a4e5e98111f328f4b67ac.png](../Images/e61b90b863a2bb5d77a156780ddc4898.png)'
- en: '[PRE147]'
  id: totrans-1118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
  id: totrans-1119
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9d2a898681451451a2db82660a24f7d69757b43f55f4314ccd08161ec7f528ea.png](../Images/ab217ef799ccdb23d1ef49e871bc0379.png)'
- en: '[PRE148]'
  id: totrans-1120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
  id: totrans-1121
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/439663d1e8381a740ff9db0be691c77db1a1eedbda596696d6f03b481d55ed43.png](../Images/0915e41ec9a5be32f78662924ffd0775.png)'
- en: Again, the results are far from perfect - but not unreasonable.
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，结果远非完美——但也不算不合理。
- en: Finally, we return to our medical example. We first reload the image and find
    super-pixels.
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回到我们的医学示例。我们首先重新加载图像并找到超像素。
- en: '[PRE149]'
  id: totrans-1124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
  id: totrans-1125
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e78b4d7d976169569b2d8223c75fc6a4bfddef251d88a030ebc48acd4dc02a22.png](../Images/aebbc424dbdb162039dbd74dd736c90a.png)'
- en: We then form the weighted Laplacian and plot its eigenvalues. This time, about
    \(40\) dimensions seem appropriate.
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们形成加权拉普拉斯算子并绘制其特征值。这次，大约 \(40\) 个维度看起来是合适的。
- en: '[PRE150]'
  id: totrans-1127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
  id: totrans-1128
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/9e8a00b5de0f0b92c8929fa508140d83f21bb7aba6c8accee6efd3b5b1681859.png](../Images/c6a0760eba98be16f4b3c9540e8f0519.png)'
- en: '[PRE151]'
  id: totrans-1129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
  id: totrans-1130
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/3b2c73655508b73097ed97881a720ff130f1d5ac41e1a12c10c87237952d3ef3.png](../Images/afe3edc4d3fc31871e23e544fb4c2542.png)'
- en: This method is quite finicky. The choice of parameters affects the results significantly.
    You should see for yourself.
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法相当挑剔。参数的选择会显著影响结果。您应该亲自看看。
- en: We mention that `scikit-image` has an implementation of a closely related method,
    Normalized Cut, [`skimage.graph.cut_normalized`](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized).
    Rather than performing \(k\)-means after projection, it recursively performs \(2\)-way
    cuts on the RAG and resulting subgraphs.
  id: totrans-1132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到 `scikit-image` 有一个与该方法密切相关的方法的实现，即归一化切割，`skimage.graph.cut_normalized`（[链接](https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized)）。它不是在投影后执行
    \(k\)-means，而是在 RAG 和结果子图上递归执行双向切割。
- en: We try it next. The results are similar as you can see.
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来尝试。结果如您所见，是相似的。
- en: '[PRE152]'
  id: totrans-1134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
  id: totrans-1135
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e09c9c323359a039a1f8bdac677f17df8c556b94f5811ba25723a203b5adf9d8.png](../Images/e021d21059fceddb156d0c352273b8a2.png)'
- en: There are many other image segmentation methods. See for example [here](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation).
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他的图像分割方法。例如，请参阅[这里](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation)。
