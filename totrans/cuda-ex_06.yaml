- en: '**Chapter 3 Introduction to CUDA C**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**第3章 CUDA C简介**'
- en: If you read [Chapter 1](ch01.html#ch01), we hope we have convinced you of both
    the immense computational power of graphics processors and that you are just the
    programmer to harness it. And if you continued through [Chapter 2](ch02.html#ch02),
    you should have a functioning environment set up in order to compile and run the
    code you’ll be writing in CUDA C. If you skipped the first chapters, perhaps you’re
    just skimming for code samples, perhaps you randomly opened to this page while
    browsing at a bookstore, or maybe you’re just dying to get started; that’s OK,
    too (we won’t tell). Either way, you’re ready to get started with the first code
    examples, so let’s go.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了[第1章](ch01.html#ch01)，我们希望已经说服你，图形处理器的计算能力是巨大的，而且你正是那个可以利用它的程序员。如果你继续阅读了[第2章](ch02.html#ch02)，你应该已经设置好了一个功能完整的环境，能够编译和运行你将在CUDA
    C中编写的代码。如果你跳过了前几章，也许你只是在浏览代码示例，或者你随便翻到这一页时，刚好在书店里看到了，或者你迫不及待地想要开始了；没关系，我们不会告诉别人。不管怎样，你现在已经准备好开始编写第一个代码示例了，开始吧。
- en: '**3.1 Chapter Objectives**'
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3.1 章节目标**'
- en: 'Through the course of this chapter, you will accomplish the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章过程中，你将完成以下任务：
- en: • You will write your first lines of code in CUDA C.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将编写你的第一行CUDA C代码。
- en: • You will learn the difference between code written for the *host* and code
    written for a *device*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习*主机*编写的代码和*设备*编写的代码之间的区别。
- en: • You will learn how to run device code from the host.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习如何从主机运行设备代码。
- en: • You will learn about the ways device memory can be used on CUDA-capable devices.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习如何在支持CUDA的设备上使用设备内存。
- en: • You will learn how to query your system for
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: • 你将学习如何查询系统的
- en: information on its CUDA-capable devices.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 了解其CUDA支持设备的信息。
- en: '**3.2 A First Program**'
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3.2 第一个程序**'
- en: Since we intend to learn CUDA C by example, let’s take a look at our first example
    of CUDA C. In accordance with the laws governing written works of computer programming,
    we begin by examining a “Hello, World!” example.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们打算通过示例学习CUDA C，让我们来看看第一个CUDA C示例。根据计算机编程的书面作品相关法律，我们从一个“Hello, World!”示例开始。
- en: '**3.2.1 Hello, World!**'
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**3.2.1 Hello, World!**'
- en: '![image](graphics/p0022-01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0022-01.jpg)'
- en: At this point, no doubt you’re wondering whether this book is a scam. Is this
    just C? Does CUDA C even exist? The answers to these questions are both in the
    affirmative; this book is not an elaborate ruse. This simple “Hello, World!” example
    is meant to illustrate that, at its most basic, there is no difference between
    CUDA C and the standard C to which you have grown accustomed.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，你或许会想，这本书是否是个骗局。难道这只是C语言吗？CUDA C到底存在吗？这些问题的答案都是肯定的；这本书并不是一个精心设计的骗局。这个简单的“Hello,
    World!”示例旨在说明，从最基本的角度看，CUDA C与你已经习惯的标准C没有任何区别。
- en: The simplicity of this example stems from the fact that it runs entirely on
    the *host*. This will be one of the important distinctions made in this book;
    we refer to the CPU and the system’s memory as the *host* and refer to the GPU
    and its memory as the *device*. This example resembles almost all the code you
    have ever written because it simply ignores any computing devices outside the
    host.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的简洁性源于它完全运行在*主机*上。书中将做出一个重要的区分：我们把CPU和系统内存称为*主机*，而把GPU和它的内存称为*设备*。这个示例几乎与你曾经编写的所有代码相似，因为它忽略了主机以外的任何计算设备。
- en: To remedy that sinking feeling that you’ve invested in nothing more than an
    expensive collection of trivialities, we will gradually build upon this simple
    example. Let’s look at something that uses the GPU (a *device*) to execute code.
    A function that executes on the device is typically called a *kernel*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免你产生一种投资于一个昂贵而琐碎的集合的沮丧感，我们将逐步在这个简单的示例基础上进行扩展。让我们来看一个利用GPU（*设备*）执行代码的例子。一个在设备上执行的函数通常称为*内核*。
- en: '**3.2.2 A Kernel Call**'
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**3.2.2 一个内核调用**'
- en: Now we will build upon our example with some code that should look more foreign
    than our plain-vanilla “Hello, World!” program.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在这个示例的基础上进行扩展，展示一些代码，这些代码看起来可能比我们平凡的“Hello, World!”程序更为陌生。
- en: '![image](graphics/p0023-01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0023-01.jpg)'
- en: 'This program makes two notable additions to the original “Hello, World!” example:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本程序对原始的“Hello, World!”示例做出了两个显著的扩展：
- en: • An empty function named `kernel()` qualified with `__global__`
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: • 一个空函数，命名为`kernel()`，并用`__global__`修饰符标记
- en: • A call to the empty function, embellished with `<<<1,1>>>`
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: • 调用空函数，并用`<<<1,1>>>`装饰
- en: As we saw in the previous section, code is compiled by your system’s standard
    C compiler by default. For example, GNU `gcc` might compile your host code on
    Linux operating systems, while Microsoft Visual C compiles it on Windows systems.
    The NVIDIA tools simply feed this host compiler your code, and everything behaves
    as it would in a world without CUDA.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中看到的，代码默认由系统的标准C编译器进行编译。例如，在Linux操作系统上，GNU `gcc`可能会编译你的主机代码，而在Windows系统上，Microsoft
    Visual C则会编译它。NVIDIA工具会将这些主机代码传递给编译器，其他一切行为与没有CUDA的世界中一样。
- en: Now we see that CUDA C adds the `__global__` qualifier to standard C. This mechanism
    alerts the compiler that a function should be compiled to run on a device instead
    of the host. In this simple example, `nvcc` gives the function `kernel()` to the
    compiler that handles device code, and it feeds `main()` to the host compiler
    as it did in the previous example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到，CUDA C在标准C中添加了`__global__`修饰符。这个机制会通知编译器某个函数应该被编译为在设备上运行，而不是在主机上运行。在这个简单的例子中，`nvcc`将函数`kernel()`交给处理设备代码的编译器，并将`main()`交给主机编译器，就像在前面的例子中一样。
- en: So, what is the mysterious call to `kernel()`, and why must we vandalize our
    standard C with angle brackets and a numeric tuple? Brace yourself, because this
    is where the magic happens.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，`kernel()`这个神秘的调用到底是什么，为什么我们必须用尖括号和数字元组来修改标准C代码？做好准备，因为魔法就在这里发生。
- en: We have seen that CUDA C needed a linguistic method for marking a function as
    device code. There is nothing special about this; it is shorthand to send host
    code to one compiler and device code to another compiler. The trick is actually
    in calling the device code from the host code. One of the benefits of CUDA C is
    that it provides this language integration so that device function calls look
    very much like host function calls. Later we will discuss what actually happens
    behind the scenes, but suffice to say that the CUDA compiler and runtime take
    care of the messy business of invoking device code from the host.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，CUDA C需要一种语言方法来标记函数为设备代码。这没有什么特别的，它只是一种简写方式，将主机代码发送给一个编译器，将设备代码发送给另一个编译器。诀窍实际上是在从主机代码调用设备代码时。CUDA
    C的一个好处是，它提供了这种语言集成，使得设备函数调用看起来非常像主机函数调用。稍后我们会讨论幕后发生的事情，但可以说，CUDA编译器和运行时系统会处理从主机调用设备代码时的复杂工作。
- en: So, the mysterious-looking call invokes device code, but why the angle brackets
    and numbers? The angle brackets denote arguments we plan to pass to the runtime
    system. These are not arguments to the device code but are parameters that will
    influence how the runtime will launch our device code. We will learn about these
    parameters to the runtime in the next chapter. Arguments to the device code itself
    get passed within the parentheses, just like any other function invocation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个看起来神秘的调用会激活设备代码，但为什么要用尖括号和数字呢？尖括号表示我们计划传递给运行时系统的参数。这些不是传递给设备代码的参数，而是会影响运行时如何启动设备代码的参数。我们将在下一章学习关于这些运行时参数的内容。传递给设备代码本身的参数会放在圆括号内，就像其他任何函数调用一样。
- en: '**3.2.3 Passing Parameters**'
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**3.2.3 参数传递**'
- en: 'We’ve promised the ability to pass parameters to our kernel, and the time has
    come for us to make good on that promise. Consider the following enhancement to
    our “Hello, World!” application:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经承诺可以向内核传递参数，现在是兑现这个承诺的时候了。请考虑以下我们“Hello, World!”应用的改进：
- en: '![image](graphics/p0025-01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0025-01.jpg)'
- en: 'You will notice a handful of new lines here, but these changes introduce only
    two concepts:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到这里有一些新行，但这些变化只引入了两个概念：
- en: • We can pass parameters to a kernel as we would with any C function.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: • 我们可以像调用任何C函数一样向内核传递参数。
- en: • We need to allocate memory to do anything useful on a device, such as return
    values to the host.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: • 我们需要分配内存才能在设备上执行任何有用的操作，例如将返回值传递给主机。
- en: There is nothing special about passing parameters to a kernel. The angle-bracket
    syntax notwithstanding, a kernel call looks and acts exactly like any function
    call in standard C. The runtime system takes care of any complexity introduced
    by the fact that these parameters need to get from the host to the device.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 向内核传递参数并没有什么特别的。尽管有尖括号语法，内核调用的形式和行为完全与标准C中的任何函数调用相同。运行时系统会处理这些参数从主机到设备传递过程中的复杂性。
- en: The more interesting addition is the allocation of memory using `cudaMalloc()`.
    This call behaves very similarly to the standard C call `malloc()`, but it tells
    the CUDA runtime to allocate the memory on the device. The first argument is a
    pointer to the pointer you want to hold the address of the newly allocated memory,
    and the second parameter is the size of the allocation you want to make. Besides
    the fact that your allocated memory pointer is not the function’s return value,
    this is identical behavior to `malloc()`, right down to the `void*` return type.
    The `HANDLE_ERROR()` that surrounds these calls is a utility macro that we have
    provided as part of this book’s support code. It simply detects that the call
    has returned an error, prints the associated error message, and exits the application
    with an `EXIT_FAILURE` code. Although you are free to use this code in your own
    applications, it is highly likely that this error-handling code will be insufficient
    in production code.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 更有趣的新增功能是使用`cudaMalloc()`分配内存。这个调用与标准C语言的`malloc()`非常相似，但它告诉CUDA运行时在设备上分配内存。第一个参数是一个指向指针的指针，指向你希望保存新分配内存地址的变量，第二个参数是你希望分配的内存大小。除了分配的内存指针不是函数的返回值这一点外，这与`malloc()`的行为完全相同，甚至返回类型也是`void*`。环绕这些调用的`HANDLE_ERROR()`是我们作为本书支持代码的一部分提供的实用宏。它简单地检测调用是否返回错误，打印相关错误信息，并以`EXIT_FAILURE`代码退出应用程序。虽然你可以在自己的应用程序中使用这段代码，但在生产代码中，这种错误处理代码很可能是不足够的。
- en: This raises a subtle but important point. Much of the simplicity and power of
    CUDA C derives from the ability to blur the line between host and device code.
    However, it is the responsibility of the programmer not to dereference the pointer
    returned by `cudaMalloc()` from code that executes on the host. Host code may
    pass this pointer around, perform arithmetic on it, or even cast it to a different
    type. But you cannot use it to read or write from memory.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个微妙但重要的点。CUDA C的许多简洁性和强大功能源于能够模糊主机代码和设备代码之间的界限。然而，程序员有责任避免在主机代码中解引用`cudaMalloc()`返回的指针。主机代码可以传递这个指针，进行算术运算，甚至将其转换为其他类型。但你不能用它来读写内存。
- en: 'Unfortunately, the compiler cannot protect you from this mistake, either. It
    will be perfectly happy to allow dereferences of device pointers in your host
    code because it looks like any other pointer in the application. We can summarize
    the restrictions on the usage of device pointers as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，编译器也无法保护你避免这个错误。它会很高兴地允许在主机代码中解引用设备指针，因为它看起来就像应用程序中的任何其他指针。我们可以总结出对设备指针使用的限制如下：
- en: You *can* pass pointers allocated with `cudaMalloc()` to functions that execute
    on the device.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你*可以*将使用`cudaMalloc()`分配的指针传递给在设备上执行的函数。
- en: You *can* use pointers allocated with `cudaMalloc()` to read or write memory
    from code that executes on the device.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你*可以*使用使用`cudaMalloc()`分配的指针在设备上执行的代码中读取或写入内存。
- en: You *can* pass pointers allocated with `cudaMalloc()` to functions that execute
    on the host.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你*可以*将使用`cudaMalloc()`分配的指针传递给在主机上执行的函数。
- en: You *cannot* use pointers allocated with `cudaMalloc()` to read or write memory
    from code that executes on the host.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你*不能*在主机上执行的代码中使用使用`cudaMalloc()`分配的指针来读取或写入内存。
- en: 'If you’ve been reading carefully, you might have anticipated the next lesson:
    We can’t use standard C’s `free()` function to release memory we’ve allocated
    with `cudaMalloc()`. To free memory we’ve allocated with `cudaMalloc()`, we need
    to use a call to `cudaFree()`, which behaves exactly like `free()` does.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细阅读过，你可能已经预见到了下一个课程：我们不能使用标准C语言的`free()`函数来释放使用`cudaMalloc()`分配的内存。要释放使用`cudaMalloc()`分配的内存，我们需要调用`cudaFree()`，其行为与`free()`完全相同。
- en: We’ve seen how to use the host to allocate and free memory on the device, but
    we’ve also made it painfully clear that you cannot modify this memory from the
    host. The remaining two lines of the sample program illustrate two of the most
    common methods for accessing device memory—by using device pointers from within
    device code and by using calls to `cudaMemcpy()`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何使用主机来分配和释放设备上的内存，但我们也明确指出，无法从主机修改这块内存。示例程序中的剩余两行展示了两种访问设备内存的常见方法——通过在设备代码中使用设备指针和通过调用`cudaMemcpy()`。
- en: We use pointers from within device code exactly the same way we use them in
    standard C that runs on the host code. The statement `*c = a + b` is as simple
    as it looks. It adds the parameters `a` and `b` together and stores the result
    in the memory pointed to by `c`. We hope this is almost too easy to even be interesting.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在设备代码中使用指针的方式与在主机代码中运行的标准C语言中使用指针的方式完全相同。语句`*c = a + b`看起来就像它所表现的那样简单。它将参数`a`和`b`相加，并将结果存储在`c`指向的内存中。我们希望这几乎简单到连有趣都不算。
- en: We listed the ways in which we can and cannot use device pointers from within
    device and host code. These caveats translate exactly as one might imagine when
    considering host pointers. Although we are free to pass host pointers around in
    device code, we run into trouble when we attempt to use a host pointer to access
    memory from within device code. To summarize, host pointers can access memory
    from host code, and device pointers can access memory from device code.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出了可以在设备代码和主机代码中使用设备指针的方式以及不能使用的方式。当考虑主机指针时，这些警告与预期完全一致。虽然我们可以在设备代码中传递主机指针，但当我们试图使用主机指针在设备代码中访问内存时，就会遇到问题。总结来说，主机指针可以在主机代码中访问内存，设备指针可以在设备代码中访问内存。
- en: As promised, we can also access memory on a device through calls to `cudaMemcpy()`
    from host code. These calls behave exactly like standard C `memcpy()` with an
    additional parameter to specify which of the source and destination pointers point
    to device memory. In the example, notice that the last parameter to `cudaMemcpy()`
    is `cudaMemcpyDeviceToHost`, instructing the runtime that the source pointer is
    a device pointer and the destination pointer is a host pointer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如承诺的那样，我们还可以通过从主机代码调用`cudaMemcpy()`来访问设备上的内存。这些调用的行为与标准C语言的`memcpy()`完全相同，只是多了一个额外的参数，用于指定源指针和目标指针中哪个指向设备内存。在此示例中，注意到`cudaMemcpy()`的最后一个参数是`cudaMemcpyDeviceToHost`，它指示运行时源指针是设备指针，目标指针是主机指针。
- en: Unsurprisingly, `cudaMemcpyHostToDevice` would indicate the opposite situation,
    where the source data is on the host and the destination is an address on the
    device. Finally, we can even specify that *both* pointers are on the device by
    passing `cudaMemcpyDeviceToDevice`. If the source and destination pointers are
    both on the host, we would simply use standard C’s `memcpy()` routine to copy
    between them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，`cudaMemcpyHostToDevice`表示相反的情况，即源数据在主机上，目标地址位于设备上。最后，我们甚至可以通过传递`cudaMemcpyDeviceToDevice`来指定*两个*指针都在设备上。如果源指针和目标指针都在主机上，我们只需使用标准C语言的`memcpy()`例程在它们之间复制。
- en: '**3.3 Querying Devices**'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3.3 查询设备**'
- en: Since we would like to be allocating memory and executing code on our device,
    it would be useful if our program had a way of knowing how much memory and what
    types of capabilities the device had. Furthermore, it is relatively common for
    people to have more than one CUDA-capable device per computer. In situations like
    this, we will definitely want a way to determine which processor is which.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望在设备上分配内存并执行代码，如果我们的程序能够知道设备具有多少内存以及哪些能力，将会非常有用。此外，对于每台计算机有多个支持CUDA的设备是相对常见的。在这种情况下，我们肯定需要一种方法来确定哪个处理器是哪一个。
- en: For example, many motherboards ship with integrated NVIDIA graphics processors.
    When a manufacturer or user adds a discrete graphics processor to this computer,
    it then possesses two CUDA-capable processors. Some NVIDIA products, like the
    GeForce GTX 295, ship with two GPUs on a single card. Computers that contain products
    such as this will also show two CUDA-capable processors.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，许多主板配备了集成的NVIDIA图形处理器。当制造商或用户为该计算机添加独立的图形处理器时，它就拥有了两个支持CUDA的处理器。一些NVIDIA产品，如GeForce
    GTX 295，配备了两颗GPU在一张卡上。包含此类产品的计算机也会显示两个支持CUDA的处理器。
- en: Before we get too deep into writing device code, we would love to have a mechanism
    for determining which devices (if any) are present and what capabilities each
    device supports. Fortunately, there is a very easy interface to determine this
    information. First, we will want to know how many devices in the system were built
    on the CUDA Architecture. These devices will be capable of executing kernels written
    in CUDA C. To get the count of CUDA devices, we call `cudaGetDeviceCount()`. Needless
    to say, we anticipate receiving an award for Most Creative Function Name.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入编写设备代码之前，我们希望有一种机制来确定系统中存在哪些设备（如果有的话），以及每个设备支持哪些功能。幸运的是，有一个非常简单的接口可以用来获取这些信息。首先，我们想知道系统中有多少设备是基于CUDA架构构建的。这些设备能够执行用CUDA
    C编写的内核。为了获取CUDA设备的数量，我们调用`cudaGetDeviceCount()`。不用说，我们期待因此获得“最具创意函数名奖”。
- en: '![image](graphics/p0028-01.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0028-01.jpg)'
- en: 'After calling `cudaGetDeviceCount()`, we can then iterate through the devices
    and query relevant information about each. The CUDA runtime returns us these properties
    in a structure of type `cudaDeviceProp`. What kind of properties can we retrieve?
    As of CUDA 3.0, the `cudaDeviceProp` structure contains the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`cudaGetDeviceCount()`之后，我们可以遍历设备，并查询每个设备的相关信息。CUDA运行时将这些属性返回给我们，以`cudaDeviceProp`类型的结构体表示。我们可以检索哪些类型的属性？截至CUDA
    3.0，`cudaDeviceProp`结构包含以下内容：
- en: '![image](graphics/p0028-02.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0028-02.jpg)'
- en: Some of these are self-explanatory; others bear some additional description
    (see [Table 3.1](ch03.html#ch03tab01)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些是显而易见的；其他则需要一些额外的描述（请参见[表 3.1](ch03.html#ch03tab01)）。
- en: '***Table 3.1*** CUDA Device Properties'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '***表 3.1*** CUDA 设备属性'
- en: '![image](graphics/t0029-01.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/t0029-01.jpg)'
- en: '![image](graphics/t0029-01.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/t0029-01.jpg)'
- en: 'We’d like to avoid going too far, too fast down our rabbit hole, so we will
    not go into extensive detail about these properties now. In fact, the previous
    list is missing some important details about some of these properties, so you
    will want to consult the *NVIDIA CUDA Reference Manual* for more information.
    When you move on to write your own applications, these properties will prove extremely
    useful. However, for now we will simply show how to query each device and report
    the properties of each. So far, our device query looks something like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望避免过快地深入探讨这个话题，因此现在不会详细讲解这些属性。事实上，前面的列表遗漏了一些关于这些属性的重要细节，所以你需要查阅*NVIDIA CUDA参考手册*以获取更多信息。当你开始编写自己的应用程序时，这些属性将非常有用。然而，目前我们只展示如何查询每个设备并报告其属性。到目前为止，我们的设备查询看起来是这样的：
- en: '![image](graphics/p0031-01.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0031-01.jpg)'
- en: 'Now that we know each of the fields available to us, we can expand on the ambiguous
    “Do something...” section and implement something marginally less trivial:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了可用的各个字段，我们可以扩展模糊的“执行某些操作...”部分，实施一个略微不那么琐碎的操作：
- en: '![image](graphics/p0032-01.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0032-01.jpg)'
- en: '![image](graphics/p0032-02.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0032-02.jpg)'
- en: '**3.4 Using Device Properties**'
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3.4 使用设备属性**'
- en: Other than writing an application that handily prints every detail of every
    CUDA-capable card, why might we be interested in the properties of each device
    in our system? Since we as software developers want everyone to think our software
    is fast, we might be interested in choosing the GPU with the most multiprocessors
    on which to run our code. Or if the kernel needs close interaction with the CPU,
    we might be interested in running our code on the integrated GPU that shares system
    memory with the CPU. These are both properties we can query with `cudaGetDeviceProperties()`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 除了编写一个方便的应用程序，打印出每个CUDA兼容卡的每个细节外，我们为什么要关注系统中每个设备的属性呢？由于我们作为软件开发人员希望每个人都认为我们的软件非常快，我们可能会对选择拥有最多多处理器的GPU来运行我们的代码感兴趣。或者，如果内核需要与CPU紧密交互，我们可能会对在与CPU共享系统内存的集成GPU上运行代码感兴趣。这些都是我们可以通过`cudaGetDeviceProperties()`查询的属性。
- en: Suppose that we are writing an application that depends on having double-precision
    floating-point support. After a quick consultation with Appendix A of the *NVIDIA
    CUDA Programming Guide*, we know that cards that have compute capability 1.3 or
    higher support double-precision floating-point math. So to successfully run the
    double-precision application that we’ve written, we need to find at least one
    device of compute capability 1.3 or higher.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在编写一个依赖于双精度浮点支持的应用程序。通过快速查阅《*NVIDIA CUDA编程指南*》的附录A，我们知道计算能力为1.3或更高的卡支持双精度浮点运算。因此，为了成功运行我们编写的双精度应用程序，我们需要找到至少一块计算能力为1.3或更高的设备。
- en: Based on what we have seen with `cudaGetDeviceCount()` and `cudaGetDeviceProperties()`,
    we could iterate through each device and look for one that either has a major
    version greater than 1 or has a major version of 1 and minor version greater than
    or equal to 3\. But since this relatively common procedure is also relatively
    annoying to perform, the CUDA runtime offers us an automated way to do this. We
    first fill a `cudaDeviceProp` structure with the properties we need our device
    to have.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们从`cudaGetDeviceCount()`和`cudaGetDeviceProperties()`中得到的信息，我们可以遍历每个设备，查找一个主版本大于1或者主版本为1且次版本大于等于3的设备。但由于这种相对常见的操作也相对麻烦，CUDA运行时为我们提供了一种自动化的方法来完成这项任务。我们首先填写一个`cudaDeviceProp`结构体，指定我们需要设备具备的属性。
- en: '![image](graphics/p0034-01.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0034-01.jpg)'
- en: After filling a `cudaDeviceProp` structure, we pass it to `cudaChooseDevice()`
    to have the CUDA runtime find a device that satisfies this constraint. The call
    to `cudaChooseDevice()` returns a device ID that we can then pass to `cudaSetDevice()`.
    From this point forward, all device operations will take place on the device we
    found in `cudaChooseDevice()`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在填写完`cudaDeviceProp`结构体后，我们将其传递给`cudaChooseDevice()`，让CUDA运行时找到一个满足该约束的设备。调用`cudaChooseDevice()`会返回一个设备ID，然后我们可以将其传递给`cudaSetDevice()`。从此以后，所有的设备操作将会在我们在`cudaChooseDevice()`中找到的设备上进行。
- en: '![image](graphics/p0034-02.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![image](graphics/p0034-02.jpg)'
- en: Systems with multiple GPUs are becoming more and more common. For example, many
    of NVIDIA’s motherboard chipsets contain integrated, CUDA-capable GPUs. When a
    discrete GPU is added to one of these systems, you suddenly have a multi-GPU platform.
    Moreover, NVIDIA’s SLI technology allows multiple discrete GPUs to be installed
    side by side. In either of these cases, your application may have a preference
    of one GPU over another. If your application depends on certain features of the
    GPU or depends on having the fastest GPU in the system, you should familiarize
    yourself with this API because there is no guarantee that the CUDA runtime will
    choose the best or most appropriate GPU for your application.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 多GPU系统变得越来越常见。例如，许多NVIDIA的主板芯片组都包含集成的CUDA支持GPU。当向这些系统中添加独立GPU时，你便拥有了一个多GPU平台。此外，NVIDIA的SLI技术允许多个独立GPU并排安装。在这些情况下，你的应用程序可能会偏好某一个GPU。如果你的应用程序依赖于GPU的某些功能，或者依赖于拥有系统中最快的GPU，你应该了解这个API，因为CUDA运行时无法保证为你的应用程序选择最合适或最快的GPU。
- en: '**3.5 Chapter Review**'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3.5 章节回顾**'
- en: We’ve finally gotten our hands dirty writing CUDA C, and ideally it has been
    less painful than you might have suspected. Fundamentally, CUDA C is standard
    C with some ornamentation to allow us to specify which code should run on the
    device and which should run on the host. By adding the keyword `__global__` before
    a function, we indicated to the compiler that we intend to run the function on
    the GPU. To use the GPU’s dedicated memory, we also learned a CUDA API similar
    to C’s `malloc()`, `memcpy()`, and `free()` APIs. The CUDA versions of these functions,
    `cudaMalloc()`, `cudaMemcpy()`, and `cudaFree()`, allow us to allocate device
    memory, copy data between the device and host, and free the device memory when
    we’ve finished with it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于开始动手编写CUDA C代码了，理想情况下，这应该比你想象的更加顺利。基本上，CUDA C是标准C语言的扩展，通过一些装饰性修改，使得我们能够指定哪些代码应该在设备上运行，哪些代码应该在主机上运行。通过在函数前加上`__global__`关键字，我们告诉编译器该函数应该在GPU上运行。为了使用GPU的专用内存，我们还学习了一个类似于C语言中的`malloc()`、`memcpy()`和`free()`的CUDA
    API。这些函数的CUDA版本，`cudaMalloc()`、`cudaMemcpy()`和`cudaFree()`，使我们能够分配设备内存、在设备和主机之间复制数据，并在完成后释放设备内存。
- en: As we progress through this book, we will see more interesting examples of how
    we can effectively use the device as a massively parallel coprocessor. For now,
    you should know how easy it is to get started with CUDA C, and in the next chapter
    we will see how easy it is to execute parallel code on the GPU.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们逐步深入本书，我们将看到更多有趣的例子，展示如何有效地将设备作为一个大规模并行协处理器。现在，您应该了解开始使用CUDA C是多么简单，在下一章中，我们将看到如何轻松地在GPU上执行并行代码。
