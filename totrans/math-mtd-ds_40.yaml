- en: '5.5\. Application: graph partitioning via spectral clustering#'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://mmids-textbook.github.io/chap05_specgraph/05_partitioning/roch-mmids-specgraph-partitioning.html](https://mmids-textbook.github.io/chap05_specgraph/05_partitioning/roch-mmids-specgraph-partitioning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this section, we use the spectral properties of the Laplacian of a graph
    to identify “good” cuts.
  prefs: []
  type: TYPE_NORMAL
- en: 5.5.1\. How to cut a graph[#](#how-to-cut-a-graph "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let \(G=(V, E)\) be a graph. Imagine that we are interested in finding a good
    cut. That is, roughly speaking, we seek to divide it into two disjoint subsets
    of vertices to achieve two goals simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: the two sets have relatively few edges between them
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: neither set is too small.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will show that the Laplacian eigenvectors provide useful information in order
    to perform this kind of graph cutting. First we formulate the problem formally.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cut ratio** One way to make the graph cutting more precise is to consider
    the following combinatorial quantity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Isoperimetric Number)** \(\idx{isoperimetric number}\xdi\)
    Let \(G=(V, E)\) be a graph. A cut\(\idx{cut}\xdi\) is a bipartition \((S, S^c)\)
    of the vertices of \(G\), where \(S\) and \(S^c = V\setminus S\) are non-empty
    subsets of \(V\). The corresponding cutset is the set of edges between \(S\) and
    \(S^c\)'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ E(S,S^c) = \{ \{i,j\} \in E : i \in S, j \in S^c \}. \]'
  prefs: []
  type: TYPE_NORMAL
- en: This is also known as the edge boundary of \(S\) (denoted \(\partial S\)). The
    size of the cutset\(\idx{cutset}\xdi\) is then \(|E(S,S^c)|\), the number of edges
    between \(S\) to \(S^c\). The cut ratio\(\idx{cut ratio}\xdi\) of \((S,S^c)\)
    is defined as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|, |S^c|\}} \]
  prefs: []
  type: TYPE_NORMAL
- en: and the isoperimetric number (or [Cheeger constant](https://en.wikipedia.org/wiki/Spectral_graph_theory#Cheeger_constant))\(\idx{Cheeger
    constant}\xdi\) of \(G\) is the smallest value this quantity can take on \(G\),
    that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi_G = \min_{\emptyset \neq S \subset V} \phi(S). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: 'In words: the cut ratio is attempting to minimize the number of edges across
    a cut, while penalizing cuts with a small number of vertices on either side. These
    correspond to the goals above and we will use this criterion to assess the quality
    of graph cuts.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Why do we need the denominator?* If we were to minimize only the numerator
    \(|E(S,S^c)|\) over all cuts (without the deonominator in \(\phi(S)\)), we would
    get what is known as the [minimum cut (or min-cut) problem](https://en.wikipedia.org/wiki/Minimum_cut).
    That problem is easier to solve. In particular, it can be solved using a beautiful
    [randomized algorithm](https://en.wikipedia.org/wiki/Karger%27s_algorithm). However,
    it tends to produce unbalanced cuts, where one side is much smaller than the other.
    This is not what we want here.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure:** Bridges are a good example of a bottleneck (i.e., a good cut) in
    a transportation network. (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bridges](../Images/cc1af6f4a7c4f2d7fde93d3160917989.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Random Tree)** We illustrate the definitions above on a tree,
    that is, a connected graph with no cycle. The function [`networkx.random_labeled_tree`](https://networkx.org/documentation/stable/reference/generated/networkx.generators.trees.random_labeled_tree.html)
    can produce a random one. As before we use a `seed` for reproducibility. Again,
    we use \(0,\ldots,n-1\) for the vertex set.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/2d38afa13c4b3f67959d61320268e3d2f6194a7ef1bd38797b0c53892bb7a732.png](../Images/bfa48d48a70dbd181dc398a4217fd612.png)'
  prefs: []
  type: TYPE_IMG
- en: Suppose we take \(S = \{0,1,2,3\}\). Then \(S^c = \{4,5\}\) and
  prefs: []
  type: TYPE_NORMAL
- en: \[ E(S,S^c) = \{\{1,5\}, \{2,4\}\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The cut ratio is then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|,|S^c|\}} = \frac{2}{2} = 1. \]
  prefs: []
  type: TYPE_NORMAL
- en: A better cut is given by \(S = \{0,1,5\}\). In that case \(S^c = \{2,3,4\}\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ E(S,S^c)= \{\{1,3\}\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|,|S^c|\}} = \frac{1}{3}. \]
  prefs: []
  type: TYPE_NORMAL
- en: This is also equal to \(\phi_G\). Indeed, in a connected graph with \(n\) vertices,
    the numerator is at least \(1\) and the denominator is at most \(n/2\), which
    is achieved here.
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**Cheeger’s inequalities** A key result of spectral graph theory establishes
    a quantitative relation between the isoperimetric number and the second smallest
    Laplacian eigenvalue.'
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Cheeger)** \(\idx{Cheeger''s inequality}\xdi\) Let \(G = (V,
    E)\) be a graph with \(n = |V|\) vertices and maximum degree \(\bar{\delta}\).
    Let \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) be its Laplacian eigenvalues.
    Then'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\phi_G^2}{2 \bar{\delta}} \leq \mu_2 \leq 2 \phi_G. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: We only prove the easy direction, \(\mu_2 \leq 2 \phi_G\), which shows explicitly
    how the connection between \(\mu_2\) and \(\phi_G\) comes about.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* To show that \(\mu_2 \leq 2 \phi_G\), we find an appropriate
    test vector to plug into the extremal characterization of \(\mu_2\) and link it
    to \(\phi_G\).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* Recall that, from the *Variational Characterization of \(\mu_2\)*,
    we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: '***Constructing a good test vector:*** We construct an \(\mathbf{x}\) that
    provides a good upper bound. Let \(\emptyset \neq S \subset V\) be a proper, nonempty
    subset of \(V\) such that \(0 < |S| \leq \frac{1}{2}|V|\). We choose a vector
    that takes one value on \(S\) and a different value on \(S^c\). Taking a cue from
    the two-component example above we consider the vector with entries'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} x_i = \begin{cases} \sqrt{\frac{|S^c|}{n |S|}} & \text{if $i
    \in S$}\\ - \sqrt{\frac{|S|}{n |S^c|}} & \text{if $i \in S^c$}. \end{cases} \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This choice ensures that
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{i=1}^n x_i &= \sum_{i\in S} \sqrt{\frac{|S^c|}{n |S|}}
    + \sum_{i\in S^c} \left(- \sqrt{\frac{|S|}{n |S^c|}}\right)\\ &= |S| \sqrt{\frac{|S^c|}{n
    |S|}} - |S^c| \sqrt{\frac{|S|}{n |S^c|}}\\ &= \sqrt{\frac{|S| |S^c|}{n}} - \sqrt{\frac{|S||S^c|
    }{n}}\\ &= 0, \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: as well
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{i=1}^n x_i^2 &= \sum_{i\in S} \left(\sqrt{\frac{|S^c|}{n
    |S|}}\right)^2 + \sum_{i\in S^c} \left(- \sqrt{\frac{|S|}{n |S^c|}}\right)^2\\
    &= |S| \frac{|S^c|}{n |S|} + |S^c| \frac{|S|}{n |S^c|}\\ &= \frac{|S^c| + |S|}{n}\\
    &=1. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the Laplacian quadratic form, we note that \(\mathbf{x}\) takes
    the same value everywhere on \(S\) (and on \(S^c\)). Hence the sum over edges
    reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{\{i, j\} \in E} (x_i - x_j)^2 &= \sum_{\substack{\{i,
    j\} \in E \\ x_i\neq x_j}} \left(\sqrt{\frac{|S^c|}{n |S|}} + \sqrt{\frac{|S|}{n
    |S^c|}}\right)^2\\ &= \sum_{\substack{\{i, j\} \in E \\ x_i\neq x_j}} \left(\frac{|S^c|
    + |S|}{\sqrt{n |S| |S^c|}}\right)^2\\ &= |E(S,S^c)|\frac{n}{|S| |S^c|}, \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that, for each edge \(\{i, j\} \in E\) where \(x_i \neq x_j\),
    one endvertex is in \(S\) and one endvertex is in \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the definition of the isoperimetric number:*** So for this choice
    of \(\mathbf{x}\) we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 \leq \sum_{\{i, j\} \in E} (x_i - x_j)^2 = \frac{n |E(S,S^c)|}{|S^c|
    |S|} = \frac{|E(S,S^c)|}{(|S^c|/n) |S|} \leq 2 \frac{|E(S,S^c)|}{|S|} \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(|S^c| \geq n/2\). This inequality holds for any \(S\) such
    that \(0 < |S| \leq \frac{1}{2}|V|\). In particular, it holds for the \(S\) producing
    the smallest value. Hence, by the definition of the isoperimetric number, we get
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 \leq 2 \phi_G \]
  prefs: []
  type: TYPE_NORMAL
- en: as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We return to the random tree example above. We claimed
    that \(\phi_G = 1/3\). The maximum degree is \(\bar{\delta} = 3\). We now compute
    \(\mu_2\). We first compute the Laplacian matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We now compute \(\mu_2\). We first compute the Laplacian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We check *Cheeger’s inequalities*. The left-hand side is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The right-hand side is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**A graph-cutting algorithm** We only proved the easy direction of *Cheeger’s
    inequalities*. It is however useful to sketch the other direction (the actual
    [Cheeger’s inequality](https://en.wikipedia.org/wiki/Cheeger_constant#Cheeger''s_inequality)
    in the graph context), as it contains an important algorithmic idea.'
  prefs: []
  type: TYPE_NORMAL
- en: '***An algorithm:*** The input is the graph \(G=(V,E)\). Let \(\mathbf{y}_2
    \in \mathbb{R}^n\) be the unit-norm eigenvector of the Laplacian matrix \(L\)
    associated to its second smallest eigenvalue \(\mu_2\), i.e., \(\mathbf{y}_2\)
    is the Fiedler vector. There is one entry of \(\mathbf{y}_2 = (y_{2,1}, \ldots,
    y_{2,n})\) for each vertex of \(G\). We use these entries to embed the graph \(G\)
    in \(\mathbb{R}\): vertex \(i\) is mapped to \(y_{2,i}\). Now order the entries
    \(y_{2,\pi(1)}, \ldots, y_{2,\pi(n)}\), where \(\pi\) is a [permutation](https://en.wikipedia.org/wiki/Permutation)\(\idx{permutation}\xdi\),
    that is, a re-ordering of \(1,\ldots,n\). Specifically, \(\pi(1)\) is the vertex
    corresponding to the smallest entry of \(\mathbf{y}_{2}\), \(\pi(2)\) is the second
    smallest, and so on. We consider only cuts of the form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ S_k = \{\pi(1), \ldots, \pi(k)\} \]
  prefs: []
  type: TYPE_NORMAL
- en: and we output the cut \((S_k, S_k^c)\) that minimizes the cut ratio
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S_k) = \frac{|E(S_k,S_k^c)|}{\min\{k, n-k\}}, \]
  prefs: []
  type: TYPE_NORMAL
- en: for the \(k \leq n-1\).
  prefs: []
  type: TYPE_NORMAL
- en: What can be proved rigorously (but we will not do this here) is that there exists
    some \(k^* \in\{1,\ldots,n-1\}\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 = \sum_{\{u, v\} \in E} (y_{2,u} - y_{2,v})^2 \geq \frac{\phi(S_{k^*})^2}{2
    \bar{\delta}} \geq \frac{\phi_G^2}{2 \bar{\delta}}, \]
  prefs: []
  type: TYPE_NORMAL
- en: which implies the lower bound in *Cheeger’s inequalities*. The leftmost inequality
    is the non-trivial one.
  prefs: []
  type: TYPE_NORMAL
- en: Since \(\mu_2 \leq 2 \phi_G\), this implies that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S_{k^*}) \leq \sqrt{4 \bar{\delta} \phi_G}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So \(\phi(S_{k^*})\) may not achieve \(\phi_G\), but we do get some guarantee
    on the quality of the cut produced by this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: See, for example, [[Kel](https://ocw.mit.edu/courses/mathematics/18-409-topics-in-theoretical-computer-science-an-algorithmists-toolkit-fall-2009/index.htm),
    Lecture 3, Section 4.2] for more details.
  prefs: []
  type: TYPE_NORMAL
- en: The above provides a heuristic to find a cut with provable guarantees. We implement
    it next. In contrast, the problem of finding a cut which minimizes the cut ratio
    is known to be [NP-hard](https://en.wikipedia.org/wiki/NP-hardness)\(\idx{NP-hardness}\xdi\),
    that is, roughly speaking it is computationally intractable.
  prefs: []
  type: TYPE_NORMAL
- en: We implement the graph cutting algorithm above.
  prefs: []
  type: TYPE_NORMAL
- en: We now implement this heuristic in Python. We first write an auxiliary function
    that takes as input an adjacency matrix, an ordering of the vertices and a value
    \(k\). It returns the cut ratio for the first \(k\) vertices in the order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Using the `cut_ratio` function, we first compute the Laplacian, find the second
    eigenvector and corresponding order of vertices. Then we compute the cut ratio
    for every \(k\). Finally we output the cut (both \(S_k\) and \(S_k^c\)) corresponding
    to the minimum, as a tuple of arrays.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Finally, to help visualize the output, we write a function coloring the vertices
    according to which side of the cut they are on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**NUMERICAL CORNER:** We will illustrate this on the path graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/4ebfff7c18330f27d88859052bc61ef4bf3023b05b644a97c42754c8bbfbdfcd.png](../Images/9060b16650e938e492286e8b623cd2cb.png)'
  prefs: []
  type: TYPE_IMG
- en: We apply our spectral-based cutting algorihtm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/2211d003904642e7dd7cb3c055a2d5959293cb510b165c444cc591a56f3c74c5.png](../Images/2f0dc8bc361ef1af11564249dcfd4461.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s try it on the grid graph. Can you guess what the cut will be?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/8473946b131310e3fb5eb51083f06728f05af3d93a601c7f6f8dcd0880c61d00.png](../Images/6b069ea231b753d5f8e27e249ea1456e.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**How to compute the second smallest eigenvalue?** There is one last piece
    of business to take care of. How do we compute the Fiedler vector? Previously,
    we have seen an iterative approach based on taking powers of the matrix to compute
    *the largest eigenvalue and corresponding eigenvector* of a positive semidefinite
    matrix. We show here how to adapt this approach to our task at hand. The details
    are left as a series of exercises.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we modify the Laplacian matrix to invert the order of the eigenvalues
    without changing the eigenvectors themselves. This way the smallest eigenvalues
    will become the largest ones. By the *Laplacian and Maximum Degree Lemma*, \(\mu_i
    \leq 2 \bar{\delta}\) for all \(i=1,\ldots,n\), where recall that \(\bar{\delta}\)
    is the largest degree of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Inverting the Order of Eigenvalues)** \(\idx{inverting the order
    of eigenvalues lemma}\xdi\) For \(i=1,\ldots,n\), let \(\lambda_i = 2 \bar{\delta}
    - \mu_i\). The matrix \(M = 2 \bar{\delta} I_{n\times n} - L\) is positive semidefinite
    and has eigenvector decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: \[ M = \sum_{i=1}^{n} \lambda_i \mathbf{y}_i \mathbf{y}_i^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: Second, our goal is now to compute the second largest eigenvalue of \(M\) –
    not the largest one. But we already know the largest one. It is \(\lambda_1 =
    2\bar{\delta} - \mu_1 = 2 \bar{\delta}\) and its associated eigenvector is \(\mathbf{y}_1
    = \frac{1}{\sqrt{n}}(1,\ldots,1)\). It turns out that we can simply apply power
    iteration with a starting vector that is orthogonal to \(\mathbf{y}_1\). Such
    a vector can be constructed by taking a random vector and subtracting its orthogonal
    projection on \(\mathbf{y}_1\).
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Power Iteration for the Second Largest Eigenvalue)** Assume that
    \(\mu_1 < \mu_2 < \mu_3\). Let \(\mathbf{x} \in \mathbb{R}^n\) be a vector such
    that \(\langle \mathbf{y}_1, \mathbf{x} \rangle = 0\) and \(\langle \mathbf{y}_2,
    \mathbf{x} \rangle > 0\). Then'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{M^{k} \mathbf{x}}{\|M^{k} \mathbf{x}\|} \to \mathbf{y}_2 \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(k \to +\infty\). If instead \(\langle \mathbf{y}_2, \mathbf{x} \rangle
    < 0\), then the limit is \(- \mathbf{y}_2\). \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '**The relaxation perspective** Here is another intuitive way to shed light
    on the effectiveness of spectral partitioning. Assume we have a graph \(G = (V,E)\)
    with an even number \(n = |V|\) of vertices. Suppose we are looking for the best
    balanced cut \((S,S^c)\) in the sense that it minimizes the number of edges \(|E(S,S^c)|\)
    across it over all cuts with \(|S| = |S^c| = n/2\). This is known as the [minimum
    bisection problem](https://link.springer.com/referenceworkentry/10.1007/978-1-4939-2864-4_231).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we can formulate this as the followign discrete optimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min\left\{\frac{1}{4} \sum_{\{i,j\} \in E} (x_i - x_j)^2\,:\, \mathbf{x}
    = (x_1,\ldots,x_n) \in \{-1,+1\}^n, \sum_{i=1}^n x_i = 0 \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The condition \(\mathbf{x} \in \{-1,+1\}^n\) implicitly assigns each vertex
    \(i\) to \(S\) (if \(x_i = -1\)) or \(S^c\) (if \(x_i=+1\)). The condition \(\sum_{i=1}^n
    x_i = 0\) then ensures that the cut \((S,S^c)\) is balanced, that is, that \(|S|
    = |S^c|\). Under this interpretation, the term \((x_i - x_j)^2\) is either \(0\)
    if \(i\) and \(j\) are on the same side of the cut, or \(4\) if they are on opposite
    sides.
  prefs: []
  type: TYPE_NORMAL
- en: This is a hard computational problem. One way to approach such a discrete optimization
    problem is to relax it. That is, to turn it into an optimization problem with
    continuous variables. Specifically here we consider instead
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min\left\{\frac{1}{4} \sum_{\{i,j\} \in E} (x_i - x_j)^2\,:\, \mathbf{x}
    = (x_1,\ldots,x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2
    = n\right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The optimal objective value of this relaxed problem is necessarily smaller or
    equal than the original one. Indeed any solution to the original problem satisfies
    the constraints of the relaxation. Up to a scaling factor, this last problem is
    equivalent to the variational characterization of \(\mu_2\). Indeed, one can prove
    that the minimum achieved is \(\frac{\mu_2 n}{4}\) (Try it!).
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We return to the [Karate Club dataset](https://en.wikipedia.org/wiki/Zachary%27s_karate_club).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure:** Dojo (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kids in a dojo](../Images/6b732b2a4c677bbb26d3e4d6e907880a.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We seek to find natural sub-communities. We use the spectral properties of the
    Laplacian. Specifically, we use our `spectral_cut2` and `viz_cut` functions to
    compute a good cut and vizualize it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/a0fae7b032318e0bf638db5fd30e11cead1d6304485bc0a49d38190321ba5a37.png](../Images/acf48fe63af2b9b2bb66e36917f2217f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is not trivial to assess the quality of the resulting cut. But this particular
    example has a known ground-truth community structure (which partly explains its
    widespread use). Quoting from [Wikipedia](https://en.wikipedia.org/wiki/Zachary%27s_karate_club):'
  prefs: []
  type: TYPE_NORMAL
- en: A social network of a karate club was studied by Wayne W. Zachary for a period
    of three years from 1970 to 1972\. The network captures 34 members of a karate
    club, documenting links between pairs of members who interacted outside the club.
    During the study a conflict arose between the administrator “John A” and instructor
    “Mr. Hi” (pseudonyms), which led to the split of the club into two. Half of the
    members formed a new club around Mr. Hi; members from the other part found a new
    instructor or gave up karate. Based on collected data Zachary correctly assigned
    all but one member of the club to the groups they actually joined after the split.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This ground truth is the following. We use [`numpy.nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero)
    to convert it into a cut.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/a0fae7b032318e0bf638db5fd30e11cead1d6304485bc0a49d38190321ba5a37.png](../Images/acf48fe63af2b9b2bb66e36917f2217f.png)'
  prefs: []
  type: TYPE_IMG
- en: You can check that our cut perfectly matches the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Investigate alternative graph partitioning algorithms, such
    as the Kernighan-Lin algorithm. Ask your favorite AI chatbot to explain how it
    works and compare its performance to spectral clustering on this dataset. ([Open
    In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following best describes the ‘cut ratio’ of a graph cut
    \((S, S^c)\)?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The ratio of the number of edges between \(S\) and \(S^c\) to the total number
    of edges in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: b) The ratio of the number of edges between \(S\) and \(S^c\) to the size of
    the smaller set, \(\min\{|S|, |S^c|\}\).
  prefs: []
  type: TYPE_NORMAL
- en: c) The ratio of the number of edges within \(S\) to the number of edges within
    \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: d) The ratio of the total number of edges in the graph to the number of edges
    between \(S\) and \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: '**2** What is the isoperimetric number (or Cheeger constant) of a graph \(G\)?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The largest value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: b) The smallest value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: c) The average value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: d) The median value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: '**3** What do *Cheeger’s inequalities* establish?'
  prefs: []
  type: TYPE_NORMAL
- en: a) A relationship between the isoperimetric number and the largest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: b) A relationship between the isoperimetric number and the second largest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: c) A relationship between the isoperimetric number and the smallest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: d) A relationship between the isoperimetric number and the second smallest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: '**4** In the context of spectral graph theory, what is the Fiedler vector?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The eigenvector associated with the largest eigenvalue of the Laplacian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: b) The eigenvector associated with the smallest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: c) The eigenvector associated with the second smallest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: d) The eigenvector associated with the second largest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**5** Which of the following is the relaxation of the minimum bisection problem
    presented in the text?'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \{-1, +1\}^n, \sum_{i=1}^n x_i = 0\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: a)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 =
    n\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: b)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} |x_i - x_j| : \mathbf{x} =
    (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 = n\right\}
    \]'
  prefs: []
  type: TYPE_NORMAL
- en: c)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \max \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 =
    n\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: d)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \max \frac{1}{4} \left\{\sum_{\{i,j\} \in E} |x_i - x_j| : \mathbf{x} =
    (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 = n\right\}
    \]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: b. Justification: The text defines the cut ratio as \(\phi(S)
    = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}}\), where \(|E(S, S^c)|\) is the number
    of edges between \(S\) and \(S^c\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: The text defines the isoperimetric number as
    “the smallest value [the cut ratio] can take on \(G\), that is, \(\phi_G = \min_{\emptyset
    \neq S \subset V} \phi(S)\).”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: d. Justification: The text states that “A key result of spectral
    graph theory establishes a quantitative relation between the isoperimetric number
    and the second smallest Laplacian eigenvalue.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: c. Justification: The text refers to the eigenvector associated
    with the second smallest eigenvalue of the Laplacian matrix as the Fiedler vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: a. Justification: The text replaces the constraint \(\mathbf{x}
    = (x_1, ..., x_n) \in \{-1, +1\}^n\) with \(\mathbf{x} = (x_1, ..., x_n) \in \mathbb{R}^n\)
    and adds the constraint \(\sum_{i=1}^n x_i^2 = n\) to maintain the balanced cut
    property.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.5.1\. How to cut a graph[#](#how-to-cut-a-graph "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let \(G=(V, E)\) be a graph. Imagine that we are interested in finding a good
    cut. That is, roughly speaking, we seek to divide it into two disjoint subsets
    of vertices to achieve two goals simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: the two sets have relatively few edges between them
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: neither set is too small.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will show that the Laplacian eigenvectors provide useful information in order
    to perform this kind of graph cutting. First we formulate the problem formally.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cut ratio** One way to make the graph cutting more precise is to consider
    the following combinatorial quantity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**DEFINITION** **(Isoperimetric Number)** \(\idx{isoperimetric number}\xdi\)
    Let \(G=(V, E)\) be a graph. A cut\(\idx{cut}\xdi\) is a bipartition \((S, S^c)\)
    of the vertices of \(G\), where \(S\) and \(S^c = V\setminus S\) are non-empty
    subsets of \(V\). The corresponding cutset is the set of edges between \(S\) and
    \(S^c\)'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ E(S,S^c) = \{ \{i,j\} \in E : i \in S, j \in S^c \}. \]'
  prefs: []
  type: TYPE_NORMAL
- en: This is also known as the edge boundary of \(S\) (denoted \(\partial S\)). The
    size of the cutset\(\idx{cutset}\xdi\) is then \(|E(S,S^c)|\), the number of edges
    between \(S\) to \(S^c\). The cut ratio\(\idx{cut ratio}\xdi\) of \((S,S^c)\)
    is defined as
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|, |S^c|\}} \]
  prefs: []
  type: TYPE_NORMAL
- en: and the isoperimetric number (or [Cheeger constant](https://en.wikipedia.org/wiki/Spectral_graph_theory#Cheeger_constant))\(\idx{Cheeger
    constant}\xdi\) of \(G\) is the smallest value this quantity can take on \(G\),
    that is,
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi_G = \min_{\emptyset \neq S \subset V} \phi(S). \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\natural\)
  prefs: []
  type: TYPE_NORMAL
- en: 'In words: the cut ratio is attempting to minimize the number of edges across
    a cut, while penalizing cuts with a small number of vertices on either side. These
    correspond to the goals above and we will use this criterion to assess the quality
    of graph cuts.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Why do we need the denominator?* If we were to minimize only the numerator
    \(|E(S,S^c)|\) over all cuts (without the deonominator in \(\phi(S)\)), we would
    get what is known as the [minimum cut (or min-cut) problem](https://en.wikipedia.org/wiki/Minimum_cut).
    That problem is easier to solve. In particular, it can be solved using a beautiful
    [randomized algorithm](https://en.wikipedia.org/wiki/Karger%27s_algorithm). However,
    it tends to produce unbalanced cuts, where one side is much smaller than the other.
    This is not what we want here.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure:** Bridges are a good example of a bottleneck (i.e., a good cut) in
    a transportation network. (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bridges](../Images/cc1af6f4a7c4f2d7fde93d3160917989.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: '**EXAMPLE:** **(A Random Tree)** We illustrate the definitions above on a tree,
    that is, a connected graph with no cycle. The function [`networkx.random_labeled_tree`](https://networkx.org/documentation/stable/reference/generated/networkx.generators.trees.random_labeled_tree.html)
    can produce a random one. As before we use a `seed` for reproducibility. Again,
    we use \(0,\ldots,n-1\) for the vertex set.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/2d38afa13c4b3f67959d61320268e3d2f6194a7ef1bd38797b0c53892bb7a732.png](../Images/bfa48d48a70dbd181dc398a4217fd612.png)'
  prefs: []
  type: TYPE_IMG
- en: Suppose we take \(S = \{0,1,2,3\}\). Then \(S^c = \{4,5\}\) and
  prefs: []
  type: TYPE_NORMAL
- en: \[ E(S,S^c) = \{\{1,5\}, \{2,4\}\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The cut ratio is then
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|,|S^c|\}} = \frac{2}{2} = 1. \]
  prefs: []
  type: TYPE_NORMAL
- en: A better cut is given by \(S = \{0,1,5\}\). In that case \(S^c = \{2,3,4\}\),
  prefs: []
  type: TYPE_NORMAL
- en: \[ E(S,S^c)= \{\{1,3\}\}, \]
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S) = \frac{|E(S,S^c)|}{\min\{|S|,|S^c|\}} = \frac{1}{3}. \]
  prefs: []
  type: TYPE_NORMAL
- en: This is also equal to \(\phi_G\). Indeed, in a connected graph with \(n\) vertices,
    the numerator is at least \(1\) and the denominator is at most \(n/2\), which
    is achieved here.
  prefs: []
  type: TYPE_NORMAL
- en: \(\lhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**Cheeger’s inequalities** A key result of spectral graph theory establishes
    a quantitative relation between the isoperimetric number and the second smallest
    Laplacian eigenvalue.'
  prefs: []
  type: TYPE_NORMAL
- en: '**THEOREM** **(Cheeger)** \(\idx{Cheeger''s inequality}\xdi\) Let \(G = (V,
    E)\) be a graph with \(n = |V|\) vertices and maximum degree \(\bar{\delta}\).
    Let \(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\) be its Laplacian eigenvalues.
    Then'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{\phi_G^2}{2 \bar{\delta}} \leq \mu_2 \leq 2 \phi_G. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\sharp\)
  prefs: []
  type: TYPE_NORMAL
- en: We only prove the easy direction, \(\mu_2 \leq 2 \phi_G\), which shows explicitly
    how the connection between \(\mu_2\) and \(\phi_G\) comes about.
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof idea:* To show that \(\mu_2 \leq 2 \phi_G\), we find an appropriate
    test vector to plug into the extremal characterization of \(\mu_2\) and link it
    to \(\phi_G\).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Proof:* Recall that, from the *Variational Characterization of \(\mu_2\)*,
    we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 = \min\left\{ \sum_{\{u, v\} \in E} (x_u - x_v)^2 \,:\, \mathbf{x}
    = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0, \sum_{u = 1}^n x_u^2
    = 1 \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: '***Constructing a good test vector:*** We construct an \(\mathbf{x}\) that
    provides a good upper bound. Let \(\emptyset \neq S \subset V\) be a proper, nonempty
    subset of \(V\) such that \(0 < |S| \leq \frac{1}{2}|V|\). We choose a vector
    that takes one value on \(S\) and a different value on \(S^c\). Taking a cue from
    the two-component example above we consider the vector with entries'
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} x_i = \begin{cases} \sqrt{\frac{|S^c|}{n |S|}} & \text{if $i
    \in S$}\\ - \sqrt{\frac{|S|}{n |S^c|}} & \text{if $i \in S^c$}. \end{cases} \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: This choice ensures that
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{i=1}^n x_i &= \sum_{i\in S} \sqrt{\frac{|S^c|}{n |S|}}
    + \sum_{i\in S^c} \left(- \sqrt{\frac{|S|}{n |S^c|}}\right)\\ &= |S| \sqrt{\frac{|S^c|}{n
    |S|}} - |S^c| \sqrt{\frac{|S|}{n |S^c|}}\\ &= \sqrt{\frac{|S| |S^c|}{n}} - \sqrt{\frac{|S||S^c|
    }{n}}\\ &= 0, \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: as well
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{i=1}^n x_i^2 &= \sum_{i\in S} \left(\sqrt{\frac{|S^c|}{n
    |S|}}\right)^2 + \sum_{i\in S^c} \left(- \sqrt{\frac{|S|}{n |S^c|}}\right)^2\\
    &= |S| \frac{|S^c|}{n |S|} + |S^c| \frac{|S|}{n |S^c|}\\ &= \frac{|S^c| + |S|}{n}\\
    &=1. \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the Laplacian quadratic form, we note that \(\mathbf{x}\) takes
    the same value everywhere on \(S\) (and on \(S^c\)). Hence the sum over edges
    reduces to
  prefs: []
  type: TYPE_NORMAL
- en: \[\begin{align*} \sum_{\{i, j\} \in E} (x_i - x_j)^2 &= \sum_{\substack{\{i,
    j\} \in E \\ x_i\neq x_j}} \left(\sqrt{\frac{|S^c|}{n |S|}} + \sqrt{\frac{|S|}{n
    |S^c|}}\right)^2\\ &= \sum_{\substack{\{i, j\} \in E \\ x_i\neq x_j}} \left(\frac{|S^c|
    + |S|}{\sqrt{n |S| |S^c|}}\right)^2\\ &= |E(S,S^c)|\frac{n}{|S| |S^c|}, \end{align*}\]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that, for each edge \(\{i, j\} \in E\) where \(x_i \neq x_j\),
    one endvertex is in \(S\) and one endvertex is in \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the definition of the isoperimetric number:*** So for this choice
    of \(\mathbf{x}\) we have'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 \leq \sum_{\{i, j\} \in E} (x_i - x_j)^2 = \frac{n |E(S,S^c)|}{|S^c|
    |S|} = \frac{|E(S,S^c)|}{(|S^c|/n) |S|} \leq 2 \frac{|E(S,S^c)|}{|S|} \]
  prefs: []
  type: TYPE_NORMAL
- en: where we used that \(|S^c| \geq n/2\). This inequality holds for any \(S\) such
    that \(0 < |S| \leq \frac{1}{2}|V|\). In particular, it holds for the \(S\) producing
    the smallest value. Hence, by the definition of the isoperimetric number, we get
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 \leq 2 \phi_G \]
  prefs: []
  type: TYPE_NORMAL
- en: as claimed. \(\square\)
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We return to the random tree example above. We claimed
    that \(\phi_G = 1/3\). The maximum degree is \(\bar{\delta} = 3\). We now compute
    \(\mu_2\). We first compute the Laplacian matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We now compute \(\mu_2\). We first compute the Laplacian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We check *Cheeger’s inequalities*. The left-hand side is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The right-hand side is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**A graph-cutting algorithm** We only proved the easy direction of *Cheeger’s
    inequalities*. It is however useful to sketch the other direction (the actual
    [Cheeger’s inequality](https://en.wikipedia.org/wiki/Cheeger_constant#Cheeger''s_inequality)
    in the graph context), as it contains an important algorithmic idea.'
  prefs: []
  type: TYPE_NORMAL
- en: '***An algorithm:*** The input is the graph \(G=(V,E)\). Let \(\mathbf{y}_2
    \in \mathbb{R}^n\) be the unit-norm eigenvector of the Laplacian matrix \(L\)
    associated to its second smallest eigenvalue \(\mu_2\), i.e., \(\mathbf{y}_2\)
    is the Fiedler vector. There is one entry of \(\mathbf{y}_2 = (y_{2,1}, \ldots,
    y_{2,n})\) for each vertex of \(G\). We use these entries to embed the graph \(G\)
    in \(\mathbb{R}\): vertex \(i\) is mapped to \(y_{2,i}\). Now order the entries
    \(y_{2,\pi(1)}, \ldots, y_{2,\pi(n)}\), where \(\pi\) is a [permutation](https://en.wikipedia.org/wiki/Permutation)\(\idx{permutation}\xdi\),
    that is, a re-ordering of \(1,\ldots,n\). Specifically, \(\pi(1)\) is the vertex
    corresponding to the smallest entry of \(\mathbf{y}_{2}\), \(\pi(2)\) is the second
    smallest, and so on. We consider only cuts of the form'
  prefs: []
  type: TYPE_NORMAL
- en: \[ S_k = \{\pi(1), \ldots, \pi(k)\} \]
  prefs: []
  type: TYPE_NORMAL
- en: and we output the cut \((S_k, S_k^c)\) that minimizes the cut ratio
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S_k) = \frac{|E(S_k,S_k^c)|}{\min\{k, n-k\}}, \]
  prefs: []
  type: TYPE_NORMAL
- en: for the \(k \leq n-1\).
  prefs: []
  type: TYPE_NORMAL
- en: What can be proved rigorously (but we will not do this here) is that there exists
    some \(k^* \in\{1,\ldots,n-1\}\) such that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \mu_2 = \sum_{\{u, v\} \in E} (y_{2,u} - y_{2,v})^2 \geq \frac{\phi(S_{k^*})^2}{2
    \bar{\delta}} \geq \frac{\phi_G^2}{2 \bar{\delta}}, \]
  prefs: []
  type: TYPE_NORMAL
- en: which implies the lower bound in *Cheeger’s inequalities*. The leftmost inequality
    is the non-trivial one.
  prefs: []
  type: TYPE_NORMAL
- en: Since \(\mu_2 \leq 2 \phi_G\), this implies that
  prefs: []
  type: TYPE_NORMAL
- en: \[ \phi(S_{k^*}) \leq \sqrt{4 \bar{\delta} \phi_G}. \]
  prefs: []
  type: TYPE_NORMAL
- en: So \(\phi(S_{k^*})\) may not achieve \(\phi_G\), but we do get some guarantee
    on the quality of the cut produced by this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: See, for example, [[Kel](https://ocw.mit.edu/courses/mathematics/18-409-topics-in-theoretical-computer-science-an-algorithmists-toolkit-fall-2009/index.htm),
    Lecture 3, Section 4.2] for more details.
  prefs: []
  type: TYPE_NORMAL
- en: The above provides a heuristic to find a cut with provable guarantees. We implement
    it next. In contrast, the problem of finding a cut which minimizes the cut ratio
    is known to be [NP-hard](https://en.wikipedia.org/wiki/NP-hardness)\(\idx{NP-hardness}\xdi\),
    that is, roughly speaking it is computationally intractable.
  prefs: []
  type: TYPE_NORMAL
- en: We implement the graph cutting algorithm above.
  prefs: []
  type: TYPE_NORMAL
- en: We now implement this heuristic in Python. We first write an auxiliary function
    that takes as input an adjacency matrix, an ordering of the vertices and a value
    \(k\). It returns the cut ratio for the first \(k\) vertices in the order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Using the `cut_ratio` function, we first compute the Laplacian, find the second
    eigenvector and corresponding order of vertices. Then we compute the cut ratio
    for every \(k\). Finally we output the cut (both \(S_k\) and \(S_k^c\)) corresponding
    to the minimum, as a tuple of arrays.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Finally, to help visualize the output, we write a function coloring the vertices
    according to which side of the cut they are on.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '**NUMERICAL CORNER:** We will illustrate this on the path graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/4ebfff7c18330f27d88859052bc61ef4bf3023b05b644a97c42754c8bbfbdfcd.png](../Images/9060b16650e938e492286e8b623cd2cb.png)'
  prefs: []
  type: TYPE_IMG
- en: We apply our spectral-based cutting algorihtm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/2211d003904642e7dd7cb3c055a2d5959293cb510b165c444cc591a56f3c74c5.png](../Images/2f0dc8bc361ef1af11564249dcfd4461.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s try it on the grid graph. Can you guess what the cut will be?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/8473946b131310e3fb5eb51083f06728f05af3d93a601c7f6f8dcd0880c61d00.png](../Images/6b069ea231b753d5f8e27e249ea1456e.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '**How to compute the second smallest eigenvalue?** There is one last piece
    of business to take care of. How do we compute the Fiedler vector? Previously,
    we have seen an iterative approach based on taking powers of the matrix to compute
    *the largest eigenvalue and corresponding eigenvector* of a positive semidefinite
    matrix. We show here how to adapt this approach to our task at hand. The details
    are left as a series of exercises.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we modify the Laplacian matrix to invert the order of the eigenvalues
    without changing the eigenvectors themselves. This way the smallest eigenvalues
    will become the largest ones. By the *Laplacian and Maximum Degree Lemma*, \(\mu_i
    \leq 2 \bar{\delta}\) for all \(i=1,\ldots,n\), where recall that \(\bar{\delta}\)
    is the largest degree of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Inverting the Order of Eigenvalues)** \(\idx{inverting the order
    of eigenvalues lemma}\xdi\) For \(i=1,\ldots,n\), let \(\lambda_i = 2 \bar{\delta}
    - \mu_i\). The matrix \(M = 2 \bar{\delta} I_{n\times n} - L\) is positive semidefinite
    and has eigenvector decomposition'
  prefs: []
  type: TYPE_NORMAL
- en: \[ M = \sum_{i=1}^{n} \lambda_i \mathbf{y}_i \mathbf{y}_i^T. \]
  prefs: []
  type: TYPE_NORMAL
- en: \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: Second, our goal is now to compute the second largest eigenvalue of \(M\) –
    not the largest one. But we already know the largest one. It is \(\lambda_1 =
    2\bar{\delta} - \mu_1 = 2 \bar{\delta}\) and its associated eigenvector is \(\mathbf{y}_1
    = \frac{1}{\sqrt{n}}(1,\ldots,1)\). It turns out that we can simply apply power
    iteration with a starting vector that is orthogonal to \(\mathbf{y}_1\). Such
    a vector can be constructed by taking a random vector and subtracting its orthogonal
    projection on \(\mathbf{y}_1\).
  prefs: []
  type: TYPE_NORMAL
- en: '**LEMMA** **(Power Iteration for the Second Largest Eigenvalue)** Assume that
    \(\mu_1 < \mu_2 < \mu_3\). Let \(\mathbf{x} \in \mathbb{R}^n\) be a vector such
    that \(\langle \mathbf{y}_1, \mathbf{x} \rangle = 0\) and \(\langle \mathbf{y}_2,
    \mathbf{x} \rangle > 0\). Then'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \frac{M^{k} \mathbf{x}}{\|M^{k} \mathbf{x}\|} \to \mathbf{y}_2 \]
  prefs: []
  type: TYPE_NORMAL
- en: as \(k \to +\infty\). If instead \(\langle \mathbf{y}_2, \mathbf{x} \rangle
    < 0\), then the limit is \(- \mathbf{y}_2\). \(\flat\)
  prefs: []
  type: TYPE_NORMAL
- en: '**The relaxation perspective** Here is another intuitive way to shed light
    on the effectiveness of spectral partitioning. Assume we have a graph \(G = (V,E)\)
    with an even number \(n = |V|\) of vertices. Suppose we are looking for the best
    balanced cut \((S,S^c)\) in the sense that it minimizes the number of edges \(|E(S,S^c)|\)
    across it over all cuts with \(|S| = |S^c| = n/2\). This is known as the [minimum
    bisection problem](https://link.springer.com/referenceworkentry/10.1007/978-1-4939-2864-4_231).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we can formulate this as the followign discrete optimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min\left\{\frac{1}{4} \sum_{\{i,j\} \in E} (x_i - x_j)^2\,:\, \mathbf{x}
    = (x_1,\ldots,x_n) \in \{-1,+1\}^n, \sum_{i=1}^n x_i = 0 \right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The condition \(\mathbf{x} \in \{-1,+1\}^n\) implicitly assigns each vertex
    \(i\) to \(S\) (if \(x_i = -1\)) or \(S^c\) (if \(x_i=+1\)). The condition \(\sum_{i=1}^n
    x_i = 0\) then ensures that the cut \((S,S^c)\) is balanced, that is, that \(|S|
    = |S^c|\). Under this interpretation, the term \((x_i - x_j)^2\) is either \(0\)
    if \(i\) and \(j\) are on the same side of the cut, or \(4\) if they are on opposite
    sides.
  prefs: []
  type: TYPE_NORMAL
- en: This is a hard computational problem. One way to approach such a discrete optimization
    problem is to relax it. That is, to turn it into an optimization problem with
    continuous variables. Specifically here we consider instead
  prefs: []
  type: TYPE_NORMAL
- en: \[ \min\left\{\frac{1}{4} \sum_{\{i,j\} \in E} (x_i - x_j)^2\,:\, \mathbf{x}
    = (x_1,\ldots,x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2
    = n\right\}. \]
  prefs: []
  type: TYPE_NORMAL
- en: The optimal objective value of this relaxed problem is necessarily smaller or
    equal than the original one. Indeed any solution to the original problem satisfies
    the constraints of the relaxation. Up to a scaling factor, this last problem is
    equivalent to the variational characterization of \(\mu_2\). Indeed, one can prove
    that the minimum achieved is \(\frac{\mu_2 n}{4}\) (Try it!).
  prefs: []
  type: TYPE_NORMAL
- en: '**NUMERICAL CORNER:** We return to the [Karate Club dataset](https://en.wikipedia.org/wiki/Zachary%27s_karate_club).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure:** Dojo (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kids in a dojo](../Images/6b732b2a4c677bbb26d3e4d6e907880a.png)'
  prefs: []
  type: TYPE_IMG
- en: \(\bowtie\)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We seek to find natural sub-communities. We use the spectral properties of the
    Laplacian. Specifically, we use our `spectral_cut2` and `viz_cut` functions to
    compute a good cut and vizualize it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/a0fae7b032318e0bf638db5fd30e11cead1d6304485bc0a49d38190321ba5a37.png](../Images/acf48fe63af2b9b2bb66e36917f2217f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is not trivial to assess the quality of the resulting cut. But this particular
    example has a known ground-truth community structure (which partly explains its
    widespread use). Quoting from [Wikipedia](https://en.wikipedia.org/wiki/Zachary%27s_karate_club):'
  prefs: []
  type: TYPE_NORMAL
- en: A social network of a karate club was studied by Wayne W. Zachary for a period
    of three years from 1970 to 1972\. The network captures 34 members of a karate
    club, documenting links between pairs of members who interacted outside the club.
    During the study a conflict arose between the administrator “John A” and instructor
    “Mr. Hi” (pseudonyms), which led to the split of the club into two. Half of the
    members formed a new club around Mr. Hi; members from the other part found a new
    instructor or gave up karate. Based on collected data Zachary correctly assigned
    all but one member of the club to the groups they actually joined after the split.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This ground truth is the following. We use [`numpy.nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero)
    to convert it into a cut.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![../../_images/a0fae7b032318e0bf638db5fd30e11cead1d6304485bc0a49d38190321ba5a37.png](../Images/acf48fe63af2b9b2bb66e36917f2217f.png)'
  prefs: []
  type: TYPE_IMG
- en: You can check that our cut perfectly matches the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: '**CHAT & LEARN** Investigate alternative graph partitioning algorithms, such
    as the Kernighan-Lin algorithm. Ask your favorite AI chatbot to explain how it
    works and compare its performance to spectral clustering on this dataset. ([Open
    In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb))
    \(\ddagger\)'
  prefs: []
  type: TYPE_NORMAL
- en: \(\unlhd\)
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Which of the following best describes the ‘cut ratio’ of a graph cut
    \((S, S^c)\)?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The ratio of the number of edges between \(S\) and \(S^c\) to the total number
    of edges in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: b) The ratio of the number of edges between \(S\) and \(S^c\) to the size of
    the smaller set, \(\min\{|S|, |S^c|\}\).
  prefs: []
  type: TYPE_NORMAL
- en: c) The ratio of the number of edges within \(S\) to the number of edges within
    \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: d) The ratio of the total number of edges in the graph to the number of edges
    between \(S\) and \(S^c\).
  prefs: []
  type: TYPE_NORMAL
- en: '**2** What is the isoperimetric number (or Cheeger constant) of a graph \(G\)?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The largest value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: b) The smallest value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: c) The average value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: d) The median value of the cut ratio over all possible cuts.
  prefs: []
  type: TYPE_NORMAL
- en: '**3** What do *Cheeger’s inequalities* establish?'
  prefs: []
  type: TYPE_NORMAL
- en: a) A relationship between the isoperimetric number and the largest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: b) A relationship between the isoperimetric number and the second largest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: c) A relationship between the isoperimetric number and the smallest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: d) A relationship between the isoperimetric number and the second smallest Laplacian
    eigenvalue.
  prefs: []
  type: TYPE_NORMAL
- en: '**4** In the context of spectral graph theory, what is the Fiedler vector?'
  prefs: []
  type: TYPE_NORMAL
- en: a) The eigenvector associated with the largest eigenvalue of the Laplacian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: b) The eigenvector associated with the smallest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: c) The eigenvector associated with the second smallest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: d) The eigenvector associated with the second largest eigenvalue of the Laplacian
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '**5** Which of the following is the relaxation of the minimum bisection problem
    presented in the text?'
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \{-1, +1\}^n, \sum_{i=1}^n x_i = 0\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: a)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 =
    n\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: b)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \min \frac{1}{4} \left\{\sum_{\{i,j\} \in E} |x_i - x_j| : \mathbf{x} =
    (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 = n\right\}
    \]'
  prefs: []
  type: TYPE_NORMAL
- en: c)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \max \frac{1}{4} \left\{\sum_{\{i,j\} \in E} (x_i - x_j)^2 : \mathbf{x}
    = (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 =
    n\right\} \]'
  prefs: []
  type: TYPE_NORMAL
- en: d)
  prefs: []
  type: TYPE_NORMAL
- en: '\[ \max \frac{1}{4} \left\{\sum_{\{i,j\} \in E} |x_i - x_j| : \mathbf{x} =
    (x_1, ..., x_n) \in \mathbb{R}^n, \sum_{i=1}^n x_i = 0, \sum_{i=1}^n x_i^2 = n\right\}
    \]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 1: b. Justification: The text defines the cut ratio as \(\phi(S)
    = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}}\), where \(|E(S, S^c)|\) is the number
    of edges between \(S\) and \(S^c\).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 2: b. Justification: The text defines the isoperimetric number as
    “the smallest value [the cut ratio] can take on \(G\), that is, \(\phi_G = \min_{\emptyset
    \neq S \subset V} \phi(S)\).”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 3: d. Justification: The text states that “A key result of spectral
    graph theory establishes a quantitative relation between the isoperimetric number
    and the second smallest Laplacian eigenvalue.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 4: c. Justification: The text refers to the eigenvector associated
    with the second smallest eigenvalue of the Laplacian matrix as the Fiedler vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer for 5: a. Justification: The text replaces the constraint \(\mathbf{x}
    = (x_1, ..., x_n) \in \{-1, +1\}^n\) with \(\mathbf{x} = (x_1, ..., x_n) \in \mathbb{R}^n\)
    and adds the constraint \(\sum_{i=1}^n x_i^2 = n\) to maintain the balanced cut
    property.'
  prefs: []
  type: TYPE_NORMAL
