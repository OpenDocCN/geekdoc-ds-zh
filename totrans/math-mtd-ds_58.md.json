["```py\nseed = 535\nrng = np.random.default_rng(seed) \n```", "```py\n[[x1, y1],\n [x2, y2],\n [x3, y3],\n ...\n [x1000, y1000]] \n```", "```py\n[[x1, x2, x3, ..., x1000],\n [y1, y2, y3, ..., y1000]] \n```", "```py\nmean = np.array([0., 0.])\ncov = np.array([[5., 0.], [0., 1.]])\nx, y = rng.multivariate_normal(mean, cov, 1000).T \n```", "```py\nprint(np.mean(x)) \n```", "```py\n-0.035322561120667575 \n```", "```py\nprint(np.mean(y)) \n```", "```py\n-0.009499619370100139 \n```", "```py\nx, y = rng.multivariate_normal(mean, cov, 10000).T\nprint(np.mean(x))\nprint(np.mean(y)) \n```", "```py\n-0.0076273930440971215\n-0.008874190869155479 \n```", "```py\naa_milne_arr = ['pooh', 'rabbit', 'piglet', 'christopher']\nprint(rng.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])) \n```", "```py\n['pooh' 'pooh' 'piglet' 'christopher' 'piglet'] \n```", "```py\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nmnist = datasets.MNIST(root='./data', train=True, \n                       download=True, transform=transforms.ToTensor())\ntrain_loader = DataLoader(mnist, batch_size=len(mnist), shuffle=False)\n\nimgs, labels = next(iter(train_loader))\nimgs = imgs.squeeze().numpy()\nlabels = labels.numpy()\nimgs = np.round(imgs) \n```", "```py\nnx_pixels, ny_pixels = imgs[0].shape\nnx_pixels, ny_pixels \n```", "```py\n(28, 28) \n```", "```py\nn_pixels = nx_pixels * ny_pixels\nn_pixels \n```", "```py\n784 \n```", "```py\n784 * np.log(2) / np.log(10) \n```", "```py\n236.00751660056122 \n```", "```py\ndef mh_transition_poisson(lmbd, n):\n    P = np.zeros((n,n))\n    for idx in range(n):\n        i = idx + 1 # index starts at 0 rather than 1\n        if (i > 1 and i < n):\n            P[idx, idx+1] = (1/2) * np.min(np.array([1, lmbd/(i+1)]))\n            P[idx, idx-1] = (1/2) * np.min(np.array([1, i/lmbd]))\n            P[idx, idx] = 1 - P[idx, idx+1] - P[idx, idx-1]\n        elif i == 1:\n            P[idx, idx+1] = (1/2) * np.min(np.array([1, lmbd/(i+1)]))\n            P[idx, idx] = 1 - P[idx, idx+1]\n        elif i == n:\n            P[idx, idx-1] = (1/2) * np.min(np.array([1, i/lmbd]))\n            P[idx, idx] = 1 - P[idx, idx-1]\n    return P \n```", "```py\nlmbd = 1\nn = 6 \n```", "```py\nP = mh_transition_poisson(lmbd, n)\nprint(P) \n```", "```py\n[[0.75       0.25       0\\.         0\\.         0\\.         0\\.        ]\n [0.5        0.33333333 0.16666667 0\\.         0\\.         0\\.        ]\n [0\\.         0.5        0.375      0.125      0\\.         0\\.        ]\n [0\\.         0\\.         0.5        0.4        0.1        0\\.        ]\n [0\\.         0\\.         0\\.         0.5        0.41666667 0.08333333]\n [0\\.         0\\.         0\\.         0\\.         0.5        0.5       ]] \n```", "```py\nseed = 535\nrng = np.random.default_rng(seed)\n\nmu = np.ones(n) / n\nT = 100\nX = mmids.SamplePath(rng, mu, P, T) \n```", "```py\nX[T] \n```", "```py\n2.0 \n```", "```py\nN_samples = 1000 # number of repetitions\n\nfreq_z = np.zeros(n) # init of frequencies sampled\nfor i in range(N_samples):\n    X = mmids.SamplePath(rng, mu, P, T)\n    freq_z[int(X[T])-1] += 1 # adjust for index starting at 0\n\nfreq_z = freq_z/N_samples \n```", "```py\nplt.bar(range(1,n+1),freq_z, color='lightblue', edgecolor='black')\nplt.show() \n```", "```py\ndef sigmoid(x): \n    return 1/(1 + np.exp(-x)) \n```", "```py\ndef rbm_mean_hidden(v, W, c):\n    return sigmoid(W.T @ v + c)\n\ndef rbm_mean_visible(h, W, b):\n    return sigmoid(W @ h + b) \n```", "```py\ndef rbm_gibbs_update(rng, v, W, b, c):\n    p_hidden = rbm_mean_hidden(v, W, c)\n    h = rng.binomial(1, p_hidden, p_hidden.shape)\n    p_visible = rbm_mean_visible(h, W, b)\n    v = rng.binomial(1, p_visible, p_visible.shape)\n    return v \n```", "```py\ndef rbm_gibbs_sampling(rng, k, v_0, W, b, c):\n    counter = 0\n    v = v_0\n    while counter < k:\n        v = rbm_gibbs_update(rng, v, W, b, c)\n        counter += 1\n    return v \n```", "```py\nfrom sklearn.neural_network import BernoulliRBM\n\nrbm = BernoulliRBM(random_state=seed, verbose=0) \n```", "```py\nmask = (labels == 0) | (labels == 1) | (labels == 5)\nimgs = imgs[mask]\nlabels = labels[mask] \n```", "```py\nX = imgs.reshape(len(imgs), -1) \n```", "```py\nrbm.n_components = 100\nrbm.learning_rate = 0.02\nrbm.batch_size = 50\nrbm.n_iter = 20\nrbm.fit(X) \n```", "```py\nBernoulliRBM(batch_size=50, learning_rate=0.02, n_components=100, n_iter=20,\n             random_state=535)\n```", "```py\nBernoulliRBM(batch_size=50, learning_rate=0.02, n_components=100, n_iter=20,\n             random_state=535)\n```", "```py\nW = rbm.components_.T\nW.shape \n```", "```py\n(784, 100) \n```", "```py\nb = rbm.intercept_visible_\nb.shape \n```", "```py\n(784,) \n```", "```py\nc = rbm.intercept_hidden_\nc.shape \n```", "```py\n(100,) \n```", "```py\nn_samples = 25\nz = rng.binomial(1, 0.5, (n_samples, n_pixels)) \n```", "```py\ndef rbm_mean_hidden(v, W, c):\n    return sigmoid(W.T @ v + c[:,np.newaxis])\n\ndef rbm_mean_visible(h, W, b):\n    return sigmoid(W @ h + b[:,np.newaxis]) \n```", "```py\ndef plot_imgs(z, n_imgs, nx_pixels, ny_pixels):\n    nx_imgs = np.floor(np.sqrt(n_imgs))\n    ny_imgs = np.ceil(np.sqrt(n_imgs))\n    plt.figure(figsize=(8, 8))\n    for i, comp in enumerate(z):\n        plt.subplot(int(nx_imgs), int(ny_imgs), i + 1)\n        plt.imshow(comp.reshape((nx_pixels, ny_pixels)), cmap='gray_r')\n        plt.xticks([]), plt.yticks([])\n    plt.show() \n```", "```py\nv_0 = z.T\ngen_v = rbm_gibbs_sampling(rng, 100, v_0, W, b, c)\n\nplot_imgs(gen_v.T, n_samples, nx_pixels, ny_pixels) \n```", "```py\nseed = 535\nrng = np.random.default_rng(seed) \n```", "```py\n[[x1, y1],\n [x2, y2],\n [x3, y3],\n ...\n [x1000, y1000]] \n```", "```py\n[[x1, x2, x3, ..., x1000],\n [y1, y2, y3, ..., y1000]] \n```", "```py\nmean = np.array([0., 0.])\ncov = np.array([[5., 0.], [0., 1.]])\nx, y = rng.multivariate_normal(mean, cov, 1000).T \n```", "```py\nprint(np.mean(x)) \n```", "```py\n-0.035322561120667575 \n```", "```py\nprint(np.mean(y)) \n```", "```py\n-0.009499619370100139 \n```", "```py\nx, y = rng.multivariate_normal(mean, cov, 10000).T\nprint(np.mean(x))\nprint(np.mean(y)) \n```", "```py\n-0.0076273930440971215\n-0.008874190869155479 \n```", "```py\naa_milne_arr = ['pooh', 'rabbit', 'piglet', 'christopher']\nprint(rng.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])) \n```", "```py\n['pooh' 'pooh' 'piglet' 'christopher' 'piglet'] \n```", "```py\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nmnist = datasets.MNIST(root='./data', train=True, \n                       download=True, transform=transforms.ToTensor())\ntrain_loader = DataLoader(mnist, batch_size=len(mnist), shuffle=False)\n\nimgs, labels = next(iter(train_loader))\nimgs = imgs.squeeze().numpy()\nlabels = labels.numpy()\nimgs = np.round(imgs) \n```", "```py\nnx_pixels, ny_pixels = imgs[0].shape\nnx_pixels, ny_pixels \n```", "```py\n(28, 28) \n```", "```py\nn_pixels = nx_pixels * ny_pixels\nn_pixels \n```", "```py\n784 \n```", "```py\n784 * np.log(2) / np.log(10) \n```", "```py\n236.00751660056122 \n```", "```py\ndef mh_transition_poisson(lmbd, n):\n    P = np.zeros((n,n))\n    for idx in range(n):\n        i = idx + 1 # index starts at 0 rather than 1\n        if (i > 1 and i < n):\n            P[idx, idx+1] = (1/2) * np.min(np.array([1, lmbd/(i+1)]))\n            P[idx, idx-1] = (1/2) * np.min(np.array([1, i/lmbd]))\n            P[idx, idx] = 1 - P[idx, idx+1] - P[idx, idx-1]\n        elif i == 1:\n            P[idx, idx+1] = (1/2) * np.min(np.array([1, lmbd/(i+1)]))\n            P[idx, idx] = 1 - P[idx, idx+1]\n        elif i == n:\n            P[idx, idx-1] = (1/2) * np.min(np.array([1, i/lmbd]))\n            P[idx, idx] = 1 - P[idx, idx-1]\n    return P \n```", "```py\nlmbd = 1\nn = 6 \n```", "```py\nP = mh_transition_poisson(lmbd, n)\nprint(P) \n```", "```py\n[[0.75       0.25       0\\.         0\\.         0\\.         0\\.        ]\n [0.5        0.33333333 0.16666667 0\\.         0\\.         0\\.        ]\n [0\\.         0.5        0.375      0.125      0\\.         0\\.        ]\n [0\\.         0\\.         0.5        0.4        0.1        0\\.        ]\n [0\\.         0\\.         0\\.         0.5        0.41666667 0.08333333]\n [0\\.         0\\.         0\\.         0\\.         0.5        0.5       ]] \n```", "```py\nseed = 535\nrng = np.random.default_rng(seed)\n\nmu = np.ones(n) / n\nT = 100\nX = mmids.SamplePath(rng, mu, P, T) \n```", "```py\nX[T] \n```", "```py\n2.0 \n```", "```py\nN_samples = 1000 # number of repetitions\n\nfreq_z = np.zeros(n) # init of frequencies sampled\nfor i in range(N_samples):\n    X = mmids.SamplePath(rng, mu, P, T)\n    freq_z[int(X[T])-1] += 1 # adjust for index starting at 0\n\nfreq_z = freq_z/N_samples \n```", "```py\nplt.bar(range(1,n+1),freq_z, color='lightblue', edgecolor='black')\nplt.show() \n```", "```py\ndef sigmoid(x): \n    return 1/(1 + np.exp(-x)) \n```", "```py\ndef rbm_mean_hidden(v, W, c):\n    return sigmoid(W.T @ v + c)\n\ndef rbm_mean_visible(h, W, b):\n    return sigmoid(W @ h + b) \n```", "```py\ndef rbm_gibbs_update(rng, v, W, b, c):\n    p_hidden = rbm_mean_hidden(v, W, c)\n    h = rng.binomial(1, p_hidden, p_hidden.shape)\n    p_visible = rbm_mean_visible(h, W, b)\n    v = rng.binomial(1, p_visible, p_visible.shape)\n    return v \n```", "```py\ndef rbm_gibbs_sampling(rng, k, v_0, W, b, c):\n    counter = 0\n    v = v_0\n    while counter < k:\n        v = rbm_gibbs_update(rng, v, W, b, c)\n        counter += 1\n    return v \n```", "```py\nfrom sklearn.neural_network import BernoulliRBM\n\nrbm = BernoulliRBM(random_state=seed, verbose=0) \n```", "```py\nmask = (labels == 0) | (labels == 1) | (labels == 5)\nimgs = imgs[mask]\nlabels = labels[mask] \n```", "```py\nX = imgs.reshape(len(imgs), -1) \n```", "```py\nrbm.n_components = 100\nrbm.learning_rate = 0.02\nrbm.batch_size = 50\nrbm.n_iter = 20\nrbm.fit(X) \n```", "```py\nBernoulliRBM(batch_size=50, learning_rate=0.02, n_components=100, n_iter=20,\n             random_state=535)\n```", "```py\nBernoulliRBM(batch_size=50, learning_rate=0.02, n_components=100, n_iter=20,\n             random_state=535)\n```", "```py\nW = rbm.components_.T\nW.shape \n```", "```py\n(784, 100) \n```", "```py\nb = rbm.intercept_visible_\nb.shape \n```", "```py\n(784,) \n```", "```py\nc = rbm.intercept_hidden_\nc.shape \n```", "```py\n(100,) \n```", "```py\nn_samples = 25\nz = rng.binomial(1, 0.5, (n_samples, n_pixels)) \n```", "```py\ndef rbm_mean_hidden(v, W, c):\n    return sigmoid(W.T @ v + c[:,np.newaxis])\n\ndef rbm_mean_visible(h, W, b):\n    return sigmoid(W @ h + b[:,np.newaxis]) \n```", "```py\ndef plot_imgs(z, n_imgs, nx_pixels, ny_pixels):\n    nx_imgs = np.floor(np.sqrt(n_imgs))\n    ny_imgs = np.ceil(np.sqrt(n_imgs))\n    plt.figure(figsize=(8, 8))\n    for i, comp in enumerate(z):\n        plt.subplot(int(nx_imgs), int(ny_imgs), i + 1)\n        plt.imshow(comp.reshape((nx_pixels, ny_pixels)), cmap='gray_r')\n        plt.xticks([]), plt.yticks([])\n    plt.show() \n```", "```py\nv_0 = z.T\ngen_v = rbm_gibbs_sampling(rng, 100, v_0, W, b, c)\n\nplot_imgs(gen_v.T, n_samples, nx_pixels, ny_pixels) \n```"]