- en: 11  Exploratory data analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 探索性数据分析
- en: 原文：[https://tellingstorieswithdata.com/11-eda.html](https://tellingstorieswithdata.com/11-eda.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://tellingstorieswithdata.com/11-eda.html](https://tellingstorieswithdata.com/11-eda.html)
- en: '[Preparation](./09-clean_and_prepare.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[准备](./09-clean_and_prepare.html)'
- en: '[11  Exploratory data analysis](./11-eda.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[11 探索性数据分析](./11-eda.html)'
- en: '**Prerequisites**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件**'
- en: Read *The Future of Data Analysis*, ([Tukey 1962](99-references.html#ref-tukey1962future))
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *《数据分析的未来》* ([Tukey 1962](99-references.html#ref-tukey1962future))
- en: John Tukey, the twentieth century statistician, made many contributions to statistics.
    From this paper focus on Part 1 “General Considerations”, which was ahead of its
    time about the ways in which we ought to learn something from data.
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20世纪的统计学家John Tukey对统计学做出了许多贡献。从这篇论文中关注第1部分“一般性考虑”，这是关于我们应该如何从数据中学习的一些前瞻性观点。
- en: Read *Best Practices in Data Cleaning*, ([Osborne 2012](99-references.html#ref-bestpracticesindatacleaning))
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *《数据清洗的最佳实践》* ([Osborne 2012](99-references.html#ref-bestpracticesindatacleaning))
- en: Focus on Chapter 6 “Dealing with Missing or Incomplete Data” which is a chapter-length
    treatment of this issue.
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于第6章“处理缺失或不完整数据”，这是对这一问题的章节长处理。
- en: Read *R for Data Science*, ([Wickham, Çetinkaya-Rundel, and Grolemund [2016]
    2023](99-references.html#ref-r4ds))
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *《数据科学中的R语言》* ([Wickham, Çetinkaya-Rundel, and Grolemund [2016] 2023](99-references.html#ref-r4ds))
- en: Focus on Chapter 11 “Exploratory data analysis”, which provides a written self-contained
    EDA worked example.
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于第11章“探索性数据分析”，其中提供了一个自包含的EDA工作示例。
- en: Watch *Whole game*, ([Wickham 2018](99-references.html#ref-hadleycodes))
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观看 *《Whole game》* ([Wickham 2018](99-references.html#ref-hadleycodes))
- en: A video providing a self-contained EDA worked example. One nice aspect is that
    you get to see an expert make mistakes and then fix them.
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个自包含的EDA工作示例的视频。一个很好的方面是，你可以看到专家犯错误，然后纠正它们。
- en: '**Key concepts and skills**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键概念和技能**'
- en: 'Exploratory data analysis is the process of coming to terms with a new dataset
    by looking at the data, constructing graphs, tables, and models. We want to understand
    three aspects:'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性数据分析是通过查看数据、构建图表、表格和模型来与新的数据集达成共识的过程。我们希望理解三个方面：
- en: each individual variable by itself;
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个变量本身；
- en: each individual in the context of other, relevant, variables; and
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在其他相关变量的背景下考虑每个个体；并且
- en: the data that are not there.
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那些不存在的数据。
- en: During EDA we want to come to understand the issues and features of the dataset
    and how this may affect analysis decisions. We are especially concerned about
    missing values and outliers.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在EDA过程中，我们希望了解数据集的问题和特征以及这可能如何影响分析决策。我们特别关注缺失值和异常值。
- en: '**Software and packages**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件和包**'
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础R ([R Core Team 2024](99-references.html#ref-citeR))
- en: '`arrow` ([Richardson et al. 2023](99-references.html#ref-arrow))'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arrow` ([Richardson et al. 2023](99-references.html#ref-arrow))'
- en: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
- en: '`lubridate` ([Grolemund and Wickham 2011](99-references.html#ref-GrolemundWickham2011))'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lubridate` ([Grolemund and Wickham 2011](99-references.html#ref-GrolemundWickham2011))'
- en: '`mice` ([van Buuren and Groothuis-Oudshoorn 2011](99-references.html#ref-mice))'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mice` ([van Buuren and Groothuis-Oudshoorn 2011](99-references.html#ref-mice))'
- en: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelsummary` ([Arel-Bundock 2022](99-references.html#ref-citemodelsummary))'
- en: '`naniar` ([Tierney et al. 2021](99-references.html#ref-naniar))'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`naniar` ([Tierney et al. 2021](99-references.html#ref-naniar))'
- en: '`opendatatoronto` ([Gelfand 2022](99-references.html#ref-citeSharla))'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opendatatoronto` ([Gelfand 2022](99-references.html#ref-citeSharla))'
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*## 11.1 Introduction'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*## 11.1 简介'
- en: The future of data analysis can involve great progress, the overcoming of real
    difficulties, and the provision of a great service to all fields of science and
    technology. Will it? That remains to us, to our willingness to take up the rocky
    road of real problems in preference to the smooth road of unreal assumptions,
    arbitrary criteria, and abstract results without real attachments. Who is for
    the challenge?
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据分析的未来可能涉及重大进步，克服真实困难，并为所有科学技术领域提供优质服务。会吗？这取决于我们，取决于我们是否愿意选择崎岖的真实问题之路，而不是平坦的不切实际的假设之路、任意的标准之路和缺乏实际关联的抽象结果之路。谁愿意接受挑战？
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tukey ([1962, 64](99-references.html#ref-tukey1962future)).
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Tukey ([1962, 64](99-references.html#ref-tukey1962future)).
- en: Exploratory data analysis is never finished. It is the active process of exploring
    and becoming familiar with our data. Like a farmer with their hands in the earth,
    we need to know every contour and aspect of our data. We need to know how it changes,
    what it shows, hides, and what are its limits. Exploratory data analysis (EDA)
    is the unstructured process of doing this.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性数据分析永远不会结束。它是探索和熟悉我们数据的一个积极过程。就像一个农民把手放在泥土里一样，我们需要了解我们数据的每一个轮廓和方面。我们需要知道它如何变化，它展示了什么，隐藏了什么，以及它的限制。探索性数据分析（EDA）是执行这一过程的非结构化过程。
- en: EDA is a means to an end. While it will inform the entire paper, especially
    the data section, it is not typically something that ends up in the final paper.
    The way to proceed is to make a separate Quarto document. Add code and brief notes
    on-the-go. Do not delete previous code, just add to it. By the end of it we will
    have created a useful notebook that captures your exploration of the dataset.
    This is a document that will guide the subsequent analysis and modeling.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: EDA是一个达到目的的手段。虽然它将告知整个论文，特别是数据部分，但它通常不会出现在最终的论文中。进行的方式是制作一个单独的Quarto文档。边走边添加代码和简短的笔记。不要删除以前的代码，只需添加即可。到那时，我们将创建一个有用的笔记本，捕捉你对数据集的探索。这是一个将指导后续分析和建模的文档。
- en: EDA draws on a variety of skills and there are a lot of options when conducting
    EDA ([Staniak and Biecek 2019](99-references.html#ref-staniak2019landscape)).
    Every tool should be considered. Look at the data and scroll through it. Make
    tables, plots, summary statistics, even some models. The key is to iterate, move
    quickly rather than perfectly, and come to a thorough understanding of the data.
    Interestingly, coming to thoroughly understand the data that we have often helps
    us understand what we do not have.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性数据分析（EDA）借鉴了多种技能，在执行EDA时有很多选项（[Staniak and Biecek 2019](99-references.html#ref-staniak2019landscape)）。每个工具都应该被考虑。查看数据并滚动浏览它。制作表格、绘图、汇总统计，甚至一些模型。关键是迭代，快速移动而不是完美，并全面理解数据。有趣的是，全面理解我们所拥有的数据往往有助于我们理解我们缺少什么。
- en: 'We are interested in the following process:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的过程如下：
- en: Understand the distribution and properties of individual variables.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解单个变量的分布和属性。
- en: Understand relationships between variables.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解变量之间的关系。
- en: Understand what is not there.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解那里没有的东西。
- en: There is no one correct process or set of steps that are required to undertake
    and complete EDA. Instead, the relevant steps and tools depend on the data and
    question of interest. As such, in this chapter we will illustrate approaches to
    EDA through various examples of EDA including US state populations, subway delays
    in Toronto, and Airbnb listings in London. We also build on [Chapter 6](06-farm.html)
    and return to missing data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一个正确的过程或一系列步骤是必须执行并完成EDA的。相反，相关的步骤和工具取决于数据和感兴趣的问题。因此，在本章中，我们将通过包括美国各州人口、多伦多的地铁延误和伦敦的Airbnb列表在内的各种EDA示例来说明EDA的方法。我们还基于[第6章](06-farm.html)并回到缺失数据。
- en: 11.2 1975 United States population and income data
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 1975年美国人口和收入数据
- en: 'As a first example we consider US state populations as of 1975\. This dataset
    is built into R with `state.x77`. Here is what the dataset looks like:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个例子，我们考虑1975年的美国各州人口。这个数据集包含在R的`state.x77`中。以下是数据集的概览：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*[PRE2]*  *We want to get a quick sense of the data. The first step is to have
    a look at the top and bottom of it with `head()` and `tail()`, then a random selection,
    and finally to focus on the variables and their class with `glimpse()`. The random
    selection is an important aspect, and when you use `head()` you should also quickly
    consider a random selection.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE2]* 我们希望快速了解数据。第一步是使用`head()`和`tail()`查看数据的顶部和底部，然后进行随机选择，最后使用`glimpse()`关注变量及其类别。随机选择是一个重要方面，当你使用`head()`时，也应该快速考虑随机选择。'
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE4]'
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE6]'
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE8]'
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*[PRE10]****  ***We are then interested in understanding key summary statistics,
    such as the minimum, median, and maximum values for numeric variables with `summary()`
    from base R and the number of observations.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE10]****  ***我们接下来感兴趣的是理解关键汇总统计量，例如使用基础R的`summary()`函数和数值变量的最小值、中位数和最大值，以及观测值的数量。'
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*[PRE12]*  *Finally, it is especially important to understand the behavior
    of these key summary statistics at the limits. In particular, one approach is
    to randomly remove some observations and compare what happens to them. For instance,
    we can randomly create five datasets that differ on the basis of which observations
    were removed. We can then compare the summary statistics. If any of them are especially
    different, then we would want to look at the observations that were removed as
    they may contain observations with high influence.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE12]*  *最后，特别重要的是要理解这些关键汇总统计量在极限情况下的行为。特别是，一种方法是通过随机删除一些观测值并比较它们的变化。例如，我们可以随机创建五个数据集，这些数据集在删除的观测值方面有所不同。然后我们可以比较汇总统计量。如果其中任何一个特别不同，那么我们就会想查看被删除的观测值，因为它们可能包含具有高影响力的观测值。'
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*Table 11.1: Comparing the mean population when different states are randomly
    removed'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*表11.1：比较随机删除不同州时的平均人口'
- en: '| Seed | Mean | Ignored states |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 种子 | 均值 | 忽略的州 |'
- en: '| --- | --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 4,469 | Arkansas, Rhode Island, Alabama, North Dakota, Minnesota |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 4,469 | 阿肯色州，罗德岛州，阿拉巴马州，北达科他州，明尼苏达州 |'
- en: '| 2 | 4,027 | Massachusetts, Iowa, Colorado, West Virginia, New York |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4,027 | 马萨诸塞州，爱荷华州，科罗拉多州，西弗吉尼亚州，纽约州 |'
- en: '| 3 | 4,086 | California, Idaho, Rhode Island, Oklahoma, South Carolina |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4,086 | 加利福尼亚州，爱达荷州，罗德岛州，俄克拉荷马州，南卡罗来纳州 |'
- en: '| 4 | 4,391 | Hawaii, Arizona, Connecticut, Utah, New Jersey |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4,391 | 夏威夷，亚利桑那，康涅狄格，犹他，新泽西 |'
- en: '| 5 | 4,340 | Alaska, Texas, Iowa, Hawaii, South Dakota |*  *In the case of
    the populations of US states, we know that larger states, such as California and
    New York, will have an out sized effect on our estimate of the mean. [Table 11.1](#tbl-summarystatesrandom)
    supports that, as we can see that when we use seeds 2 and 3, there is a lower
    mean.******  ***## 11.3 Missing data'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '| 5 | 4,340 | 阿拉斯加，德克萨斯，爱荷华，夏威夷，南达科他州 |*  *在考虑美国各州人口的情况下，我们知道像加利福尼亚和纽约这样的大州会对我们估计的均值产生不成比例的影响。[表11.1](#tbl-summarystatesrandom)支持这一点，因为我们可以看到，当我们使用种子2和3时，均值较低。******  ***##
    11.3 缺失数据'
- en: 'We have discussed missing data a lot throughout this book, especially in [Chapter
    6](06-farm.html). Here we return to it because understanding missing data tends
    to be a substantial focus of EDA. When we find missing data—and there are always
    missing data of some sort or another—we want to establish what type of missingness
    we are dealing with. Focusing on known-missing observations, that is where there
    are observations that we can see are missing in the dataset, based on Gelman,
    Hill, and Vehtari ([2020, 323](99-references.html#ref-gelmanhillvehtari2020))
    we consider three main categories of missing data:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们讨论了缺失数据很多，尤其是在[第6章](06-farm.html)。在这里，我们再次回到这个话题，因为理解缺失数据往往是探索性数据分析（EDA）的一个重要焦点。当我们发现缺失数据——而且总是存在某种形式的缺失数据——我们希望确定我们正在处理哪种类型的缺失。关注已知的缺失观测值，即那些在数据集中我们可以看到缺失的观测值，根据Gelman,
    Hill, 和 Vehtari ([2020, 323](99-references.html#ref-gelmanhillvehtari2020))，我们考虑三种主要的缺失数据类别：
- en: Missing Completely At Random;
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完全随机缺失（Missing Completely At Random）；
- en: Missing at Random; and
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机缺失（Missing at Random）；以及
- en: Missing Not At Random.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缺失非随机（Missing Not At Random）。
- en: When data are Missing Completely At Random (MCAR), observations are missing
    from the dataset independent of any other variables—whether in the dataset or
    not. As discussed in [Chapter 6](06-farm.html), when data are MCAR there are fewer
    concerns about summary statistics and inference, but data are rarely MCAR. Even
    if they were it would be difficult to be convinced of this. Nonetheless we can
    simulate an example. For instance we can remove the population data for three
    randomly selected states.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据完全随机缺失（MCAR）时，观测值从数据集中缺失是独立于任何其他变量的——无论这些变量是否在数据集中。正如在第6章[06-farm.html](06-farm.html)中讨论的那样，当数据MCAR时，对汇总统计量和推理的担忧较少，但数据很少是MCAR。即使它们是，也难以令人信服。尽管如此，我们可以模拟一个例子。例如，我们可以删除三个随机选择州的人口数据。
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*[PRE15]*  *When observations are Missing at Random (MAR) they are missing
    from the dataset in a way that is related to other variables in the dataset. For
    instance, it may be that we are interested in understanding the effect of income
    and gender on political participation, and so we gather information on these three
    variables. But perhaps for some reason males are less likely to respond to a question
    about income.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE15]*  *当观测值随机缺失（MAR）时，它们从数据集中缺失的方式与数据集中的其他变量相关。例如，我们可能对理解收入和性别对政治参与的影响感兴趣，因此我们收集了这三个变量的信息。但也许由于某种原因，男性不太可能对关于收入的问题做出回应。'
- en: In the case of the US states dataset, we can simulate a MAR dataset by making
    the three US states with the highest population not have an observation for income.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国州数据集的情况下，我们可以通过使三个人口最多的美国州没有收入观察值来模拟一个MNAR数据集。
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*[PRE17]*  *Finally when observations are Missing Not At Random (MNAR) they
    are missing from the dataset in a way that is related to either unobserved variables,
    or the missing variable itself. For instance, it may be that respondents with
    a higher income, or that respondents with higher education (a variable that we
    did not collect), are less likely to fill in their income.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE17]*  *最后，当观察值缺失不是随机（MNAR）时，它们从数据集中缺失的方式与未观察到的变量或缺失变量本身有关。例如，可能收入较高的受访者或受过更高教育（我们没有收集的变量）的受访者不太可能填写他们的收入。'
- en: In the case of the US states dataset, we can simulate a MNAR dataset by making
    the three US states with the highest population not have an observation for population.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国州数据集的情况下，我们可以通过使三个人口最多的美国州没有人口观察值来模拟一个MNAR数据集。
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*[PRE19]*  *The best approach will be bespoke to the circumstances, but in
    general we want to use simulation to better understand the implications of our
    choices. From a data side we can choose to remove observations that are missing
    or input a value. (There are also options on the model side, but those are beyond
    the scope of this book.) These approaches have their place, but need to be used
    with humility and well communicated. The use of simulation is critical.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE19]*  *最佳方法将根据具体情况定制，但通常我们希望通过模拟来更好地理解我们选择的影响。从数据方面来看，我们可以选择删除缺失的观察值或输入一个值。（模型方面也有选项，但这些超出了本书的范围。）这些方法有其适用之处，但需要谦逊地使用并良好沟通。使用模拟是至关重要的。'
- en: 'We can return to our US states dataset, generate some missing data, and consider
    a few common approaches for dealing with missing data, and compare the implied
    values for each state, and the overall US mean population. We consider the following
    options:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以回到我们的美国州数据集，生成一些缺失数据，并考虑一些处理缺失数据的常见方法，比较每个州和总体美国平均人口所隐含的值。我们考虑以下选项：
- en: Drop observations with missing data.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除缺失数据的观察值。
- en: Impute the mean of observations without missing data.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对无缺失数据的观察值的均值进行插补。
- en: Use multiple imputation.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用多重插补。
- en: To drop the observations with missing data, we can use `mean()`. By default
    it will exclude observations with missing values in its calculation. To impute
    the mean, we construct a second dataset with the observations with missing data
    removed. We then compute the mean of the population column, and impute that into
    the missing values in the original dataset. Multiple imputation involves creating
    many potential datasets, conducting inference, and then bringing them together
    potentially though averaging ([Gelman and Hill 2007, 542](99-references.html#ref-gelmanandhill)).
    We can implement multiple imputation with `mice()` from `mice`.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除缺失数据的观察值，我们可以使用`mean()`函数。默认情况下，它将排除计算中包含缺失值的观察值。要插补均值，我们构建一个第二数据集，其中删除了缺失数据的观察值。然后我们计算人口列的均值，并将其插补到原始数据集中的缺失值。多重插补涉及创建许多潜在的数据库集，进行推断，然后可能通过平均（[Gelman
    and Hill 2007, 542](99-references.html#ref-gelmanandhill)）将它们结合起来。我们可以使用`mice()`函数从`mice`包中实现多重插补。
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Table 11.2: Comparing the imputed values of population for three US states
    and the overall mean population'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*表11.2：比较三个美国州和总体平均人口的重置值'
- en: '| Observation | Drop missing | Input mean | Multiple imputation | Actual |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 观察 | 缺失值下降 | 输入均值 | 多重插补 | 实际 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Florida |  | 4,308 | 11,197 | 8,277 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 佛罗里达 |  | 4,308 | 11,197 | 8,277 |'
- en: '| Montana |  | 4,308 | 4,589 | 746 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 蒙大拿 |  | 4,308 | 4,589 | 746 |'
- en: '| New Hampshire |  | 4,308 | 813 | 812 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 新罕布什尔 |  | 4,308 | 813 | 812 |'
- en: '| Overall | 4,308 | 4,308 | 4,382 | 4,246 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 4,308 | 4,308 | 4,382 | 4,246 |'
- en: '[Table 11.2](#tbl-imputationoptions) makes it clear that none of these approaches
    should be naively imposed. For instance, Florida’s population should be 8,277\.
    Imputing the mean across all the states would result in an estimate of 4,308,
    and multiple imputation results in an estimate of 11,197, the former is too low
    and the latter is too high. If imputation is the answer, it may be better to look
    for a different question. It is worth pointing out that it was developed for specific
    circumstances of limiting public disclosure of private information ([Horton and
    Lipsitz 2001](99-references.html#ref-myboynick)).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: “999”： “不确定，不知道”
- en: Nothing can make up for missing data ([Manski 2022](99-references.html#ref-manskiwow)).
    The conditions under which it makes sense to impute the mean or the prediction
    based on multiple imputation are not common, and even more rare is our ability
    to verify them. What to do depends on the circumstances and purpose of the analysis.
    Simulating the removal of observations that we have and then implementing various
    options can help us better understand the trade-offs we face. Whatever choice
    is made—and there is rarely a clear-cut solution—try to document and communicate
    what was done, and explore the effect of different choices on subsequent estimates.
    We recommend proceeding by simulating different scenarios that remove some of
    the data that we have, and evaluating how the approaches differ.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 任何东西都无法弥补缺失的数据 ([Manski 2022](99-references.html#ref-manskiwow))。在哪些情况下，基于多重插补来估计均值或预测是有意义的并不常见，而验证这些情况的能力则更为罕见。具体应该怎么做取决于分析的具体情况和目的。模拟移除我们所拥有的观测数据，然后实施各种选项，可以帮助我们更好地理解我们所面临的权衡。无论做出什么选择——而且很少有一个明确的解决方案——都尽量记录和传达所做的工作，并探讨不同选择对后续估计的影响。我们建议通过模拟不同的场景来移除我们拥有的部分数据，并评估这些方法之间的差异。
- en: 'Finally, more prosaically, but just as importantly, sometimes missing data
    is encoded in the variable with particular values. For instance, while R has the
    option of “NA”, sometimes numerical data is entered as “-99” or alternatively
    as a very large integer such as “9999999”, if it is missing. In the case of the
    Nationscape survey dataset introduced in [Chapter 8](08-hunt.html), there are
    three types of known missing data:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，虽然更通俗，但同样重要的是，有时缺失数据被编码在变量中，具有特定的值。例如，虽然R有“NA”选项，但有时数值数据会被输入为“-99”或作为非常大的整数，如“9999999”，如果它是缺失的。在[第8章](08-hunt.html)中引入的Nationscape调查数据集中，存在三种已知的缺失数据类型：
- en: '“888”: “Asked in this wave, but not asked of this respondent”'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**11.4 TTC地铁延误**'
- en: '“999”: “Not sure, don’t know”'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为EDA的第二个、更复杂的例子，我们使用[第2章](02-drinking_from_a_fire_hose.html)中介绍的`opendatatoronto`和`tidyverse`来获取和探索有关多伦多地铁系统的数据。我们想要了解发生的延误情况。
- en: '“.”: Respondent skipped'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[表11.2](#tbl-imputationoptions)清楚地表明，这些方法都不应该被天真地应用。例如，佛罗里达的人口应该是8,277。对所有州进行均值插补会导致估计值为4,308，而多重插补的结果为11,197，前者太低，后者太高。如果插补是答案，可能更好的是寻找不同的问题。值得注意的是，它是为了特定的情境开发的，即限制私人信息的公开披露
    ([Horton and Lipsitz 2001](99-references.html#ref-myboynick))。'
- en: It is always worth looking explicitly for values that seem like they do not
    belong and investigating them. Graphs and tables are especially useful for this
    purpose.****  ***## 11.4 TTC subway delays
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 总是值得明确寻找那些看起来不属于的数据值，并对其进行调查。图表和表格在这方面特别有用。
- en: As a second, and more involved, example of EDA we use `opendatatoronto`, introduced
    in [Chapter 2](02-drinking_from_a_fire_hose.html), and the `tidyverse` to obtain
    and explore data about the Toronto subway system. We want to get a sense of the
    delays that have occurred.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们下载了2021年多伦多交通委员会（TTC）地铁延误的数据。这些数据以Excel文件的形式提供，每个月份都有一个单独的工作表。我们感兴趣的是2021年的数据，所以我们过滤出仅包含该年的数据，然后使用`opendatatoronto`中的`get_resource()`下载它，并使用`bind_rows()`将月份合并在一起。
- en: To begin, we download the data on Toronto Transit Commission (TTC) subway delays
    in 2021\. The data are available as an Excel file with a separate sheet for each
    month. We are interested in 2021 so we filter to just that year then download
    it using `get_resource()` from `opendatatoronto` and bring the months together
    with `bind_rows()`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: “888”： “在本轮调查中询问过，但没有询问过此受访者”
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE22]'
- en: The dataset has a variety of columns, and we can find out more about each of
    them by downloading the codebook. The reason for each delay is coded, and so we
    can also download the explanations. One variable of interest appears is “min_delay”,
    which gives the extent of the delay in minutes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有多种列，我们可以通过下载代码簿来了解更多关于每一列的信息。每个延迟的原因都被编码，因此我们也可以下载解释。一个有趣的变量是“min_delay”，它给出了延迟的分钟数。
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*There is no one way to explore a dataset while conducting EDA, but we are
    usually especially interested in:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*在进行EDA时探索数据集没有一种唯一的方法，但我们通常特别感兴趣的是：'
- en: What should the variables look like? For instance, what is their class, what
    are the values, and what does the distribution of these look like?
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量应该是什么样子？例如，它们的类别是什么，它们的值是什么，这些值的分布是什么样的？
- en: What aspects are surprising, both in terms of data that are there that we do
    not expect, such as outliers, but also in terms of data that we may expect but
    do not have, such as missing data.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令人惊讶的方面有哪些，无论是我们未预料到的数据，如异常值，还是我们可能预期但未拥有的数据，如缺失数据。
- en: Developing a goal for our analysis. For instance, in this case, it might be
    understanding the factors such as stations and the time of day that are associated
    with delays. While we would not answer these questions formally here, we might
    explore what an answer could look like.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为我们的分析制定一个目标。例如，在这种情况下，这可能意味着理解与延迟相关的因素，如车站和一天中的时间。虽然我们不会在这里正式回答这些问题，但我们可能会探索答案可能的样子。
- en: It is important to document all aspects as we go through and note anything surprising.
    We are looking to create a record of the steps and assumptions that we made as
    we were going because these will be important when we come to modeling. In the
    natural sciences, a research notebook of this type can even be a legal document
    ([Ryan 2015](99-references.html#ref-nihtalk)).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行过程中记录所有方面并注意任何令人惊讶的事情是很重要的。我们希望创建一个记录，记录我们在进行过程中所采取的步骤和假设，因为这些在我们建模时将非常重要。在自然科学中，这种类型的研究笔记甚至可以成为法律文件（[Ryan
    2015](99-references.html#ref-nihtalk)）。
- en: 11.4.1 Distribution and properties of individual variables
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.1 单个变量的分布和属性
- en: We should check that the variables are what they say they are. If they are not,
    then we need to work out what to do. For instance, should we change them, or possibly
    even remove them? It is also important to ensure that the class of the variables
    is as we expect. For instance, variables that should be a factor are a factor
    and those that should be a character are a character. And that we do not accidentally
    have, say, factors as numbers, or vice versa. One way to do this is to use `unique()`,
    and another is to use `table()`. There is no universal answer to which variables
    should be of certain classes, because the answer depends on the context.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该检查变量是否如其所说是的。如果不是，我们需要找出该怎么做。例如，我们应该改变它们，或者甚至可能删除它们？同样重要的是要确保变量的类别与我们预期的一致。例如，应该是因子的变量是因子，应该是字符的变量是字符。我们不会意外地将因子作为数字，或者相反。一种方法是使用`unique()`，另一种方法是使用`table()`。没有关于哪些变量应该是特定类别的普遍答案，因为答案取决于上下文。
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '*[PRE25]'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE25]'
- en: '[PRE26]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '*[PRE27]'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE27]'
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*[PRE29]'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE29]'
- en: '[PRE30]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '*[PRE31]****  ***We have likely issues in terms of the subway lines. Some of
    them have a clear fix, but not all. One option would be to drop them, but we would
    need to think about whether these errors might be correlated with something that
    is of interest. If they were then we may be dropping important information. There
    is usually no one right answer, because it will usually depend on what we are
    using the data for. We would note the issue, as we continued with EDA and then
    decide later about what to do. For now, we will remove all the lines that are
    not the ones that we know to be correct based on the codebook.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE31]****  ***在地铁线路方面，我们可能存在一些问题。其中一些有明确的解决方案，但并非所有。一个选择是删除它们，但我们需要考虑这些错误是否可能与某些感兴趣的事物相关。如果是这样，我们可能会丢失重要信息。通常没有唯一正确的答案，因为这通常取决于我们使用数据的目的。我们会记录这个问题，然后在我们继续进行EDA时决定下一步做什么。现在，我们将删除所有不是基于代码簿我们知道是正确的线路。'
- en: '[PRE32]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '*[PRE33]'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE33]'
- en: '[PRE34]*  **Entire careers are spent understanding missing data, and the presence,
    or lack, of missing values can haunt an analysis. To get started we could look
    at known-unknowns, which are the NAs for each variable. For instance, we could
    create counts by variable.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE34]*  **整个职业生涯都在理解缺失数据，缺失值的存在与否可能会困扰分析。为了开始，我们可以查看已知的未知数，即每个变量的NA。例如，我们可以按变量创建计数。**'
- en: In this case we have many missing values in “bound” and two in “line”. For these
    known-unknowns, as discussed in [Chapter 6](06-farm.html), we are interested in
    whether they are missing at random. We want to, ideally, show that data happened
    to just drop out. But this is unlikely, and so we are usually trying to look at
    what is systematic about how the data are missing.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们在“bound”中有许多缺失值，在“line”中有两个。对于这些已知的未知数，如[第6章](06-farm.html)中讨论的，我们感兴趣的是它们是否是随机缺失的。我们理想上想展示数据偶然丢失了。但这不太可能，所以我们通常试图了解数据缺失的系统特征。
- en: Sometimes data happen to be duplicated. If we did not notice this, then our
    analysis would be wrong in ways that we would not be able to consistently expect.
    There are a variety of ways to look for duplicated rows, but `get_dupes()` from
    `janitor` is especially useful.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有时数据会偶然重复。如果我们没有注意到这一点，那么我们的分析就会出错，而我们无法始终如一地预期。有各种方法可以查找重复的行，但`janitor`中的`get_dupes()`特别有用。
- en: '[PRE35]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '*[PRE36]*  *This dataset has many duplicates. We are interested in whether
    there is something systematic going on. Remembering that during EDA we are trying
    to quickly come to terms with a dataset, one way forward is to flag this as an
    issue to come back to and explore later, and to just remove duplicates for now
    using `distinct()`.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE36]*  *这个数据集有很多重复项。我们感兴趣的是是否有什么系统性的问题。记住，在EDA过程中，我们试图快速了解数据集，一种前进的方法是将这个问题标记为以后回来探索的问题，并暂时使用`distinct()`删除重复项。'
- en: '[PRE37]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '*The station names have many errors.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*站点名称有很多错误。'
- en: '[PRE38]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '*[PRE39]*  *We could try to quickly bring a little order to the chaos by just
    taking just the first word or first few words, accounting for names like “ST.
    CLAIR” and “ST. PATRICK” by checking if the name starts with “ST”, as well as
    distinguishing between stations like “DUNDAS” and “DUNDAS WEST” by checking if
    the name contains “WEST”. Again, we are just trying to get a sense of the data,
    not necessarily make binding decisions here. We use `word()` from `stringr` to
    extract specific words from the station names.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE39]*  *我们可以尝试通过只取第一个词或前几个词来快速为混乱的数据带来一点秩序，通过检查名字是否以“ST”开头来处理像“ST. CLAIR”和“ST.
    PATRICK”这样的名字，以及通过检查名字是否包含“WEST”来区分像“DUNDAS”和“DUNDAS WEST”这样的站点。再次强调，我们只是试图对数据有一个大致的了解，并不一定在这里做出决定。我们使用`stringr`中的`word()`函数从站点名称中提取特定的词。'
- en: '[PRE40]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '*[PRE41]*  *We need to see the data in its original state to understand it,
    and we often use bar charts, scatterplots, line plots, and histograms for this.
    During EDA we are not so concerned with whether the graph looks nice, but are
    instead trying to acquire a sense of the data as quickly as possible. We can start
    by looking at the distribution of “min_delay”, which is one outcome of interest.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE41]*  *我们需要看到数据在其原始状态下才能理解它，我们经常使用条形图、散点图、折线图和直方图来做到这一点。在EDA过程中，我们并不那么关心图表是否看起来很漂亮，而是试图尽快对数据有一个感觉。我们可以从查看“min_delay”的分布开始，这是我们感兴趣的一个结果。'
- en: '[PRE42]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '*![](../Images/8a9b99ee22fa1af410bb6b2439ea689c.png)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/8a9b99ee22fa1af410bb6b2439ea689c.png)'
- en: (a) Distribution of delay
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 延迟分布
- en: '![](../Images/50ca0ed779df9dc83af1bebb2137ea3e.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50ca0ed779df9dc83af1bebb2137ea3e.png)'
- en: (b) With a log scale
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 对数刻度
- en: 'Figure 11.1: Distribution of delay, in minutes'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：延迟分布，以分钟为单位
- en: The largely empty graph in [Figure 11.1 (a)](#fig-delayhist-1) suggests the
    presence of outliers. There are a variety of ways to try to understand what could
    be going on, but one quick way to proceed is to use logarithms, remembering that
    we would expect values of zero to drop away ([Figure 11.1 (b)](#fig-delayhist-2)).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.1 (a)](#fig-delayhist-1)中的大部分空白图表表明存在异常值。有各种方法试图理解可能发生的情况，但一种快速的方法是使用对数，记住我们预计零值会消失([图11.1
    (b)](#fig-delayhist-2))。'
- en: This initial exploration suggests there are a small number of large delays that
    we might like to explore further. We will join this dataset with “delay_codes”
    to understand what is going on.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这初步的探索表明，有一些较大的延迟，我们可能想进一步探索。我们将把这个数据集与“delay_codes”连接起来，以了解发生了什么。
- en: '[PRE43]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '*[PRE44]*  *From this we can see that the 348 minute delay was due to “Traction
    Power Rail Related”, the 343 minute delay was due to “Signals - Track Circuit
    Problems”, and so on.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE44]*  *从这些数据中我们可以看到，348分钟的延误是由于“牵引电力铁路相关”，343分钟的延误是由于“信号 - 轨道电路问题”，等等。'
- en: Another thing that we are looking for is various groupings of the data, especially
    where sub-groups may end up with only a small number of observations in them.
    This is because our analysis could be especially influenced by them. One quick
    way to do this is to group the data by a variable that is of interest, for instance,
    “line”, using color.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在寻找的是数据的各种分组，特别是当子组可能只有少量观察值时。这是因为我们的分析可能特别受它们的影响。一种快速的方法是按一个感兴趣的变量分组数据，例如，“线路”，使用颜色。
- en: '[PRE45]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '*![](../Images/5d93caf906b1f2f1a651f162c6d0b814.png)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/5d93caf906b1f2f1a651f162c6d0b814.png)'
- en: (a) Density
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 密度
- en: '![](../Images/0b9779bdc38c21edbfb0dc28def522b7.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b9779bdc38c21edbfb0dc28def522b7.png)'
- en: (b) Frequency
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 频率
- en: 'Figure 11.2: Distribution of delay, in minutes'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：延误分布（分钟）
- en: '[Figure 11.2 (a)](#fig-delaydensity-1) uses density so that we can look at
    the distributions more comparably, but we should also be aware of differences
    in frequency ([Figure 11.2 (b)](#fig-delaydensity-2)). In this case, we see that
    “SHP” and “SRT” have much smaller counts.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.2 (a)](#fig-delaydensity-1)使用密度，以便我们可以更比较地查看分布，但我们也应该注意频率的差异（[图11.2 (b)](#fig-delaydensity-2)）。在这种情况下，我们看到“SHP”和“SRT”的计数要小得多。'
- en: To group by another variable, we can add facets ([Figure 11.3](#fig-delayfreqfacet)).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要按另一个变量分组，我们可以添加面元（[图11.3](#fig-delayfreqfacet)）。
- en: '[PRE46]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '*![](../Images/e4ad22b79fc2b82d73586a8d2de3fc20.png)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/e4ad22b79fc2b82d73586a8d2de3fc20.png)'
- en: 'Figure 11.3: Frequency of the distribution of delay, in minutes, by day*  *We
    can also plot the top five stations by mean delay, faceted by line ([Figure 11.4](#fig-whatisthisagraphforants)).
    This raises something that we would need to follow up on, which is what is “ZONE”
    in “YU”?'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：按日分布的延误频率（分钟）*  *我们还可以按平均延误和线路绘制排名前五的车站（[图11.4](#fig-whatisthisagraphforants)）。这引发了一个我们需要跟进的问题，那就是“YU”中的“ZONE”是什么意思？
- en: '[PRE47]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '*![](../Images/052d63dcb2cf6ea6d9a27e4b0be1c74b.png)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/052d63dcb2cf6ea6d9a27e4b0be1c74b.png)'
- en: 'Figure 11.4: Top five stations, by mean delay and line*  *As discussed in [Chapter
    9](09-clean_and_prepare.html), dates are often difficult to work with because
    they are so prone to having issues. For this reason, it is especially important
    to consider them during EDA. Let us create a graph by week, to see if there is
    any seasonality over the course of a year. When using dates, `lubridate` is especially
    useful. For instance, we can look at the average delay, of those that were delayed,
    by week, using `week()` to construct the weeks ([Figure 11.5](#fig-delaybyweek)).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：按平均延误和线路排名前五的车站*  *如[第9章](09-clean_and_prepare.html)中所述，日期往往很难处理，因为它们很容易出现问题。因此，在EDA期间考虑它们尤为重要。让我们按周创建一个图表，看看一年中是否存在季节性。当使用日期时，`lubridate`特别有用。例如，我们可以使用`week()`构造周来查看延误的平均值，按周计算那些延误的情况（[图11.5](#fig-delaybyweek)）。
- en: '[PRE48]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '*![](../Images/a311d1974189d0ca293725f3e2b5a356.png)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/a311d1974189d0ca293725f3e2b5a356.png)'
- en: 'Figure 11.5: Average delay, in minutes, by week, for the Toronto subway*  *Now
    let us look at the proportion of delays that were greater than ten minutes ([Figure 11.6](#fig-longdelaybyweek)).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：按周计算的Toronto地铁的平均延误时间（分钟）*  *现在让我们看看超过十分钟的延误比例（[图11.6](#fig-longdelaybyweek)）。
- en: '[PRE49]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '*![](../Images/12e2ac75f3f2b9511167f379f5879e91.png)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/12e2ac75f3f2b9511167f379f5879e91.png)'
- en: 'Figure 11.6: Delays longer than ten minutes, by week, for the Toronto subway*  *These
    figures, tables, and analysis may not have a place in a final paper. Instead,
    they allow us to become comfortable with the data. We note aspects about each
    that stand out, as well as the warnings and any implications or aspects to return
    to.****************  ***### 11.4.2 Relationships between variables'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6：按周计算的Toronto地铁的超过十分钟的延误时间*  *这些图表、表格和分析可能不会出现在最终的论文中。相反，它们使我们能够熟悉数据。我们注意到每个图表的突出方面，以及警告和任何需要返回的启示或方面。****************  ***###
    11.4.2 变量之间的关系
- en: We are also interested in looking at the relationship between two variables.
    We will draw heavily on graphs for this. Appropriate types, for different circumstances,
    were discussed in [Chapter 5](05-graphs_tables_maps.html). Scatter plots are especially
    useful for continuous variables, and are a good precursor to modeling. For instance,
    we may be interested in the relationship between the delay and the gap, which
    is the number of minutes between trains ([Figure 11.7](#fig-delayvsgap)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还感兴趣于查看两个变量之间的关系。我们将大量使用图表来完成这项工作。在 [第 5 章](05-graphs_tables_maps.html) 中讨论了不同情况下适当的图表类型。散点图对于连续变量特别有用，并且是建模的良好先导。例如，我们可能对延误和间隔之间的关系感兴趣，间隔是列车之间的分钟数
    ([图 11.7](#fig-delayvsgap))。
- en: '[PRE50]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '*![](../Images/896f5cd070a739e7e0ebe45039e898ee.png)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/896f5cd070a739e7e0ebe45039e898ee.png)'
- en: 'Figure 11.7: Relationship between delay and gap for the Toronto subway in 2021*  *The
    relationship between categorical variables takes more work, but we could also,
    for instance, look at the top five reasons for delay by station. We may be interested
    in whether they differ, and how any difference could be modelled ([Figure 11.8](#fig-categorical)).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：2021 年多伦多地铁延误和间隔之间的关系*  *类别变量之间的关系需要更多的工作，但例如，我们也可以查看每个站点的延误前五名原因。我们可能对它们是否不同以及任何差异如何建模感兴趣
    ([图 11.8](#fig-categorical)))。
- en: '[PRE51]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '*![](../Images/2482269d77a1d1a92ccfa48affde2679.png)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/2482269d77a1d1a92ccfa48affde2679.png)'
- en: 'Figure 11.8: Relationship between categorical variables for the Toronto subway
    in 2021*******  ***## 11.5 Airbnb listings in London, England'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8：2021 年多伦多地铁的类别变量之间的关系*******  ***## 11.5 伦敦，英格兰的 Airbnb 列表
- en: In this case study we look at Airbnb listings in London, England, as at 14 March
    2023\. The dataset is from [Inside Airbnb](http://insideairbnb.com) ([Cox 2021](99-references.html#ref-airbnbdata))
    and we will read it from their website, and then save a local copy. We can give
    `read_csv()` a link to where the dataset is and it will download it. This helps
    with reproducibility because the source is clear. But as that link could change
    at any time, longer-term reproducibility, as well as wanting to minimize the effect
    on the Inside Airbnb servers, suggests that we should also save a local copy of
    the data and then use that.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本案例研究中，我们研究截至 2023 年 3 月 14 日的伦敦，英格兰的 Airbnb 列表。数据集来自 [Inside Airbnb](http://insideairbnb.com)
    ([Cox 2021](99-references.html#ref-airbnbdata))，我们将从他们的网站读取它，然后保存本地副本。我们可以给 `read_csv()`
    提供数据集的链接，它会下载它。这有助于可重复性，因为来源是明确的。但是，由于该链接可能会随时更改，长期的可重复性以及希望最小化对 Inside Airbnb
    服务器的冲击，建议我们还应保存数据的本地副本，然后使用它。
- en: To get the dataset that we need, go to Inside Airbnb \(\rightarrow\) “Data”
    \(\rightarrow\) “Get the Data”, then scroll down to London. We are interested
    in the “listings dataset”, and we right click to get the URL that we need ([Figure 11.9](#fig-getairbnb)).
    Inside Airbnb update the data that they make available, and so the particular
    dataset that is available will change over time.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取我们需要的数据集，请访问 Inside Airbnb \(\rightarrow\) “数据” \(\rightarrow\) “获取数据”，然后滚动到伦敦。我们感兴趣的是“列表数据集”，然后我们右键点击获取所需的
    URL ([图 11.9](#fig-getairbnb))。Inside Airbnb 会更新他们提供的数据，因此可用的特定数据集会随时间变化。
- en: '![](../Images/e7a7913defa654e1329ba9411063eb1d.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7a7913defa654e1329ba9411063eb1d.png)'
- en: 'Figure 11.9: Obtaining the Airbnb data from Inside Airbnb'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9：从 Inside Airbnb 获取 Airbnb 数据
- en: As the original dataset is not ours, we should not make that public without
    first getting written permission. For instance, we may want to add it to our inputs
    folder, but use a “.gitignore” entry, covered in [Chapter 3](03-workflow.html),
    to ensure that we do not push it to GitHub. The “guess_max” option in `read_csv()`
    helps us avoid having to specify the column types. Usually `read_csv()` takes
    a best guess at the column types based on the first few rows. But sometimes those
    first ones are misleading and so “guess_max” forces it to look at a larger number
    of rows to try to work out what is going on. Paste the URL that we copied from
    Inside Airbnb into the URL part. And once it is downloaded, save a local copy.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 由于原始数据集不属于我们，在没有首先获得书面许可的情况下，我们不应将其公开。例如，我们可能想将其添加到我们的输入文件夹中，但使用 [第 3 章](03-workflow.html)
    中介绍的“gitignore”条目，以确保我们不将其推送到 GitHub。`read_csv()` 中的“guess_max”选项帮助我们避免必须指定列类型。通常，`read_csv()`
    会根据前几行来最佳猜测列类型。但有时这些前几行可能会误导，因此“guess_max”强制它查看更多的行，以尝试弄清楚发生了什么。将我们从 Inside Airbnb
    复制的 URL 粘贴到 URL 部分。一旦下载，保存本地副本。
- en: '[PRE52]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '*We should refer to this local copy of our data when we run our scripts to
    explore the data, rather than asking the Inside Airbnb servers for the data each
    time. It might be worth even commenting out this call to their servers to ensure
    that we do not accidentally stress their service.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*在运行我们的脚本来探索数据时，我们应该参考这个本地数据副本，而不是每次都向Inside Airbnb服务器请求数据。甚至可能值得取消注释对他们的服务器调用，以确保我们不会意外地对其服务造成压力。'
- en: Again, add this filename—“airbnb_data.csv”—to the “.gitignore” file so that
    it is not pushed to GitHub. The size of the dataset will create complications
    that we would like to avoid.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，将此文件名——“airbnb_data.csv”——添加到“.gitignore”文件中，以便它不会被推送到GitHub。数据集的大小将造成一些我们希望避免的复杂问题。
- en: While we need to archive this CSV because that is the original, unedited data,
    at more than 100MB it is a little unwieldy. For exploratory purposes we will create
    a parquet file with selected variables (we do this in an iterative way, using
    `names(airbnb_data)` to work out the variable names).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们需要存档这个CSV文件，因为那是原始的、未经编辑的数据，但超过100MB的大小让它变得有些难以处理。为了探索目的，我们将创建一个包含选定变量的parquet文件（我们以迭代的方式做这件事，使用`names(airbnb_data)`来确定变量名）。
- en: '[PRE53]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '*### 11.5.1 Distribution and properties of individual variables'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '*### 11.5.1 单个变量的分布和属性'
- en: First we might be interested in price. It is a character at the moment and so
    we need to convert it to a numeric. This is a common problem and we need to be
    a little careful that it does not all just convert to NAs. If we just force the
    price variable to be a numeric then it will go to NA because there are a lot of
    characters where it is unclear what the numeric equivalent is, such as “$”. We
    need to remove those characters first.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可能对价格感兴趣。目前它是一个字符类型，因此我们需要将其转换为数值类型。这是一个常见问题，我们需要小心，不要让它全部转换为NAs。如果我们强制将价格变量转换为数值类型，那么它将变为NA，因为有很多字符不清楚其数值等价物，例如“$”。我们需要先删除这些字符。
- en: '[PRE54]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '*[PRE55]'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE55]'
- en: '[PRE56]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '*[PRE57]'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE57]'
- en: '[PRE58]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '*[PRE59]'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE59]'
- en: '[PRE60]***  ***Now we can look at the distribution of prices ([Figure 11.10
    (a)](#fig-airbnbpricesfirst-1)). There are outliers, so again we might like to
    consider it on the log scale ([Figure 11.10 (b)](#fig-airbnbpricesfirst-2)).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE60]***  ***现在我们可以查看价格分布（[图11.10 (a)](#fig-airbnbpricesfirst-1)）。存在异常值，所以我们可能还想考虑对数刻度（[图11.10
    (b)](#fig-airbnbpricesfirst-2)）。'
- en: '[PRE61]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '*![](../Images/9f5cee458ac2576879fcb7e6b8b4bc7e.png)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/9f5cee458ac2576879fcb7e6b8b4bc7e.png)'
- en: (a) Distribution of prices
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 价格分布
- en: '![](../Images/4ca5739cc2869e2dde32513e8d9e1166.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/4ca5739cc2869e2dde32513e8d9e1166.png)'
- en: (b) Using the log scale for prices more than $1,000
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 对于超过$1,000的价格使用对数刻度
- en: 'Figure 11.10: Distribution of prices of London Airbnb rentals in March 2023'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10：2023年3月伦敦Airbnb租赁的价格分布
- en: Turning to [Figure 11.11](#fig-airbnbpricesbunch), if we focus on prices that
    are less than $1,000, then we see that most properties have a nightly price less
    than $250 ([Figure 11.11 (a)](#fig-airbnbpricesbunch-1)). In the same way that
    we saw some bunching in ages in [Chapter 9](09-clean_and_prepare.html), it looks
    like there is some bunching of prices here. It might be that this is happening
    around numbers ending in zero or nine. Let us just zoom in on prices between $90
    and $210, out of interest, but change the bins to be smaller ([Figure 11.11 (b)](#fig-airbnbpricesbunch-2)).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 转到[图11.11](#fig-airbnbpricesbunch)，如果我们关注低于$1,000的价格，那么我们会看到大多数物业的每晚价格低于$250（[图11.11
    (a)](#fig-airbnbpricesbunch-1)）。就像我们在第9章中看到年龄的聚集一样，这里看起来价格也存在一些聚集。这可能是发生在以零或九结尾的数字周围。让我们出于好奇，放大$90到$210之间的价格，但将区间划分得更小（[图11.11
    (b)](#fig-airbnbpricesbunch-2)）。
- en: '[PRE62]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '*![](../Images/4b23383cd528d896de95b6b4da5ee894.png)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*![图片](../Images/4b23383cd528d896de95b6b4da5ee894.png)'
- en: (a) Prices less than $1,000 suggest some bunching
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 价格低于$1,000表明存在一些聚集
- en: '![](../Images/370f9fd8337c861a7ea7e38ca0e115b1.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/370f9fd8337c861a7ea7e38ca0e115b1.png)'
- en: (b) Prices between $90 and $210 illustrate the bunching more clearly
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 价格在$90到$210之间更清楚地说明了聚集
- en: 'Figure 11.11: Distribution of prices for Airbnb listings in London in March
    2023'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11：2023年3月伦敦Airbnb房源的价格分布
- en: For now, we will just remove all prices that are more than $999.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将只删除所有超过$999的价格。
- en: '[PRE63]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '*Superhosts are especially experienced Airbnb hosts, and we might be interested
    to learn more about them. For instance, a host either is or is not a superhost,
    and so we would not expect any NAs. But we can see that there are NAs. It might
    be that the host removed a listing or similar, but this is something that we would
    need to look further into.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*超级房东是经验丰富的 Airbnb 房东，我们可能想了解更多关于他们的信息。例如，房东要么是超级房东，要么不是，所以我们不期望有任何 NA。但我们可以看到有
    NA。可能是因为房东删除了列表或类似的事情，但这是我们需要进一步调查的事情。'
- en: '[PRE64]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '*[PRE65]*  *We will also want to create a binary variable from this. It is
    true/false at the moment, which is fine for the modeling, but there are a handful
    of situations where it will be easier if we have a 0/1\. And for now we will just
    remove anyone with a NA for whether they are a superhost.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE65]*  *我们还将从这个数据中创建一个二元变量。目前它是真/假，这对于建模来说是可行的，但在一些情况下，如果我们有一个 0/1 的变量会更容易。目前，我们将移除任何关于他们是否是超级房东的
    NA。'
- en: '[PRE66]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '*On Airbnb, guests can give one to five star ratings across a variety of different
    aspects, including cleanliness, accuracy, value, and others. But when we look
    at the reviews in our dataset, it is clear that it is effectively a binary, and
    almost entirely the case that either the rating is five stars or not ([Figure 11.12](#fig-airbnbreviews)).'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*在 Airbnb 上，客人可以对包括清洁度、准确性、价值等多个方面的一个到五星级进行评分。但当我们查看数据集中的评价时，很明显它实际上是一个二元的，几乎全部情况是评分是五星或不是
    ([图 11.12](#fig-airbnbreviews))。'
- en: '[PRE67]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '*![](../Images/6c273b02b72ec2312728d4e65503137e.png)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/6c273b02b72ec2312728d4e65503137e.png)'
- en: 'Figure 11.12: Distribution of review scores rating for London Airbnb rentals
    in March 2023*  *We would like to deal with the NAs in “review_scores_rating”,
    but this is more complicated as there are a lot of them. It may be that this is
    just because they do not have any reviews.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12：2023 年 3 月伦敦 Airbnb 租赁的评分分布*  *我们希望处理“review_scores_rating”中的缺失值，但这更为复杂，因为有很多缺失值。可能是因为这些房源没有任何评价。
- en: '[PRE68]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '*[PRE69]'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE69]'
- en: '[PRE70]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '*[PRE71]**  **These properties do not have a review rating yet because they
    do not have enough reviews. It is a large proportion of the total, at almost a
    fifth of them so we might like to look at this in more detail using counts. We
    are interested to see whether there is something systematic happening with these
    properties. For instance, if the NAs were being driven by, say, some requirement
    of a minimum number of reviews, then we would expect they would all be missing.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE71]**  **这些房源还没有评价评分，因为它们没有足够的评价。在总数中占很大比例，接近五分之一，所以我们可能想更详细地查看这一点。我们感兴趣的是看看这些房源是否有什么系统性的问题。例如，如果
    NA 是由，比如说，最低评价数量的要求驱动的，那么我们预计它们都会缺失。'
- en: One approach would be to just focus on those that are not missing and the main
    review score ([Figure 11.13](#fig-airbnbreviewsselected)).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法就是只关注那些没有缺失值的主要评价评分 ([图 11.13](#fig-airbnbreviewsselected))。
- en: '[PRE72]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '*![](../Images/abb4252309a1edaec89cc94fdfbe7b2d.png)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/abb4252309a1edaec89cc94fdfbe7b2d.png)'
- en: 'Figure 11.13: Distribution of review scores for London Airbnb rentals in March
    2023*  *For now, we will remove anyone with an NA in their main review score,
    even though this will remove roughly 20 per cent of observations. If we ended
    up using this dataset for actual analysis, then we would want to justify this
    decision in an appendix or similar.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13：2023 年 3 月伦敦 Airbnb 租赁的评分分布*  *目前，我们将移除任何主要评分中有 NA 的人，尽管这将移除大约 20% 的观测值。如果我们最终使用这个数据集进行实际分析，那么我们将在附录或类似的地方证明这个决定的合理性。
- en: '[PRE73]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '*Another important factor is how quickly a host responds to an inquiry. Airbnb
    allows hosts up to 24 hours to respond, but encourages responses within an hour.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*另一个重要因素是房东对询问的响应速度。Airbnb 允许房东最多在 24 小时内回复，但鼓励在 1 小时内回复。'
- en: '[PRE74]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '*[PRE75]*  *It is unclear how a host could have a response time of NA. It may
    be this is related to some other variable. Interestingly it seems like what looks
    like “NAs” in “host_response_time” variable are not coded as proper NAs, but are
    instead being treated as another category. We will recode them to be actual NAs
    and change the variable to be a factor.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE75]*  *不清楚房东如何会有 NA 的响应时间。可能这与其他变量有关。有趣的是，看起来在“host_response_time”变量中的“NA”并没有被编码为正确的
    NA，而是被当作另一个类别处理。我们将重新编码它们为实际的 NA，并将变量改为因子类型。'
- en: '[PRE76]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '*There is an issue with NAs as there are a lot of them. For instance, we might
    be interested to see if there is a relationship with the review score ([Figure 11.14](#fig-airbnbreviewsselectednasresponse)).
    There are a lot that have an overall review of 100.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*存在NA的问题，因为它们有很多。例如，我们可能想看看它们与评论分数之间是否存在关系（[图11.14](#fig-airbnbreviewsselectednasresponse)）。有很多评论总分是100。'
- en: '[PRE77]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '*![](../Images/4d934408bcd5a59ac3ef523b1f8bf87d.png)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/4d934408bcd5a59ac3ef523b1f8bf87d.png)'
- en: 'Figure 11.14: Distribution of review scores for properties with NA response
    time, for London Airbnb rentals in March 2023*  *Usually missing values are dropped
    by `ggplot2`. We can use `geom_miss_point()` from `naniar` to include them in
    the graph ([Figure 11.15](#fig-visualisemissing)).'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14：2023年3月伦敦Airbnb租赁中，回应时间缺失的物业评论分数分布*  *通常，缺失值会被`ggplot2`丢弃。我们可以使用`naniar`中的`geom_miss_point()`将它们包含在图表中（[图11.15](#fig-visualisemissing)）。
- en: '[PRE78]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '*![](../Images/19c02d503924cb82a5d7d7bfa37c5d80.png)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/19c02d503924cb82a5d7d7bfa37c5d80.png)'
- en: 'Figure 11.15: Missing values in London Airbnb data, by host response time*  *For
    now, we will remove anyone with a NA in their response time. This will again remove
    roughly another 20 per cent of the observations.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15：伦敦Airbnb数据中，根据房东回应时间缺失值的分布*  *目前，我们将移除任何回应时间中有NA的人。这又将再次移除大约20%的观测值。
- en: '[PRE79]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '*We might be interested in how many properties a host has on Airbnb ([Figure 11.16](#fig-airbnbhostlisting)).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可能对房东在Airbnb上拥有的物业数量感兴趣（[图11.16](#fig-airbnbhostlisting)）。'
- en: '[PRE80]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '*![](../Images/8acfd478a7a4e7cf51ee42bf31983845.png)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/8acfd478a7a4e7cf51ee42bf31983845.png)'
- en: 'Figure 11.16: Distribution of the number of properties a host has on Airbnb,
    for London Airbnb rentals in March 2023*  *Based on [Figure 11.16](#fig-airbnbhostlisting)
    we can see there are a large number who have somewhere in the 2-500 properties
    range, with the usual long tail. The number with that many listings is unexpected
    and worth following up on. And there are a bunch with NA that we will need to
    deal with.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.16：2023年3月伦敦Airbnb租赁中，房东在Airbnb上拥有的物业数量分布*  *根据[图11.16](#fig-airbnbhostlisting)，我们可以看到有很多人拥有大约2-500个物业，通常有一个长尾。拥有那么多列表的数量是出乎意料的，值得跟进。而且还有一大堆NA值，我们需要处理。
- en: '[PRE81]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '*[PRE82]*  *There is nothing that immediately jumps out as odd about the people
    with more than ten listings, but at the same time it is still not clear. For now,
    we will move on and focus on only those with one property for simplicity.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE82]*  *拥有超过十个列表的人并没有什么明显异常之处，但与此同时，这仍然不是很清楚。目前，我们将继续前进，仅关注那些只有一个属性的人以简化问题。'
- en: '[PRE83]********************  ***### 11.5.2 Relationships between variables'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE83]********************  ***### 11.5.2 变量之间的关系'
- en: We might like to make some graphs to see if there are any relationships between
    variables that become clear. Some aspects that come to mind are looking at prices
    and comparing with reviews, superhosts, number of properties, and neighborhood.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想绘制一些图表，看看变量之间是否存在任何明显的关系。一些想到的方面是查看价格并与评论、超级房东、物业数量和社区进行比较。
- en: We can look at the relationship between price and reviews, and whether they
    are a super-host, for properties with more than one review ([Figure 11.17](#fig-priceandreview)).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看价格与评论之间的关系，以及他们是否是超级房东，对于拥有多个评论的物业（[图11.17](#fig-priceandreview)）。
- en: '[PRE84]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '*![](../Images/0f46e01095a89b1c83e70fec7adffef8.png)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../Images/0f46e01095a89b1c83e70fec7adffef8.png)'
- en: 'Figure 11.17: Relationship between price and review and whether a host is a
    superhost, for London Airbnb rentals in March 2023*  *One of the aspects that
    may make someone a superhost is how quickly they respond to inquiries. One could
    imagine that being a superhost involves quickly saying yes or no to inquiries.
    Let us look at the data. First, we want to look at the possible values of superhost
    by their response times.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.17：2023年3月伦敦Airbnb租赁价格与评论之间的关系，以及房东是否为超级房东*  *可能使某人成为超级房东的一个方面是他们回应询问的速度。可以想象，成为超级房东可能涉及快速对询问说“是”或“否”。让我们看看数据。首先，我们想根据他们的回应时间查看超级房东的可能值。
- en: '[PRE85]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '*[PRE86]*  *Fortunately, it looks like when we removed the reviews rows we
    removed any NAs from whether they were a superhost, but if we go back and look
    into that we may need to check again. We could build a table that looks at a hosts
    response time by whether they are a superhost using `tabyl()` from `janitor`.
    It is clear that if a host does not respond within an hour then it is unlikely
    that they are a superhost.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE86]*  *幸运的是，看起来当我们删除了评价行时，我们也删除了任何关于他们是否是超级房东的NA值，但如果我们回头看看，我们可能需要再次检查。我们可以使用
    `janitor` 的 `tabyl()` 函数构建一个表格，查看房东的响应时间是否是超级房东。很明显，如果一个房东在一小时内没有响应，那么他们不太可能是超级房东。'
- en: '[PRE87]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '*[PRE88]*  *Finally, we could look at neighborhood. The data provider has attempted
    to clean the neighborhood variable for us, so we will use that variable for now.
    Although if we ended up using this variable for our actual analysis we would want
    to examine how it was constructed.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE88]*  *最后，我们可以看看社区。数据提供者已经尝试为我们清理了社区变量，所以现在我们将使用这个变量。尽管如果我们最终使用这个变量进行实际分析，我们希望检查它是如何构建的。'
- en: '[PRE89]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '*[PRE90]*  *We will quickly run a model on our dataset. We will cover modeling
    in more detail in [Chapter 12](12-ijalm.html), but we can use models during EDA
    to help get a better sense of relationships that may exist between multiple variables
    in a dataset. For instance, we may like to see whether we can forecast whether
    someone is a superhost, and the factors that go into explaining that. As the outcome
    is binary, this is a good opportunity to use logistic regression. We expect that
    superhost status will be associated with faster responses and better reviews.
    Specifically, the model that we estimate is:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE90]*  *我们将快速在我们的数据集上运行一个模型。我们将在第12章中更详细地介绍建模，但我们可以使用模型在EDA期间帮助更好地了解数据集中多个变量之间可能存在的关系。例如，我们可能想看看我们是否可以预测某人是否是超级房东，以及解释这一点的因素。由于结果是二元的，这是一个使用逻辑回归的好机会。我们预计超级房东状态将与更快的响应和更好的评价相关。具体来说，我们估计的模型是：'
- en: \[\mbox{Prob(Is superhost} = 1) = \mbox{logit}^{-1}\left( \beta_0 + \beta_1
    \mbox{Response time} + \beta_2 \mbox{Reviews} + \epsilon\right)\]
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: \[概率（是超级房东）= \mbox{logit}^{-1}\left( \beta_0 + \beta_1 \mbox{响应时间} + \beta_2
    \mbox{评价} + \epsilon\right)\]
- en: We estimate the model using `glm`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `glm` 估计模型。
- en: '[PRE91]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '*After installing and loading `modelsummary` we can have a quick look at the
    results using `modelsummary()` ([Table 11.3](#tbl-modelsummarylogisticregressionsuper)).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '*在安装和加载 `modelsummary` 之后，我们可以使用 `modelsummary()` 快速查看结果（[表11.3](#tbl-modelsummarylogisticregressionsuper)）。'
- en: '[PRE92]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '*Table 11.3: Explaining whether a host is a superhost based on their response
    time'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '*表11.3：根据响应时间解释房东是否是超级房东'
- en: '|  | (1) |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  | (1) |'
- en: '| --- | --- |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| (Intercept) | -16.369 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| (Intercept) | -16.369 |'
- en: '|  | (0.673) |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.673) |'
- en: '| host_response_timewithin a day | 2.230 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| host_response_timewithin a day | 2.230 |'
- en: '|  | (0.361) |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.361) |'
- en: '| host_response_timewithin a few hours | 3.035 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| host_response_timewithin a few hours | 3.035 |'
- en: '|  | (0.359) |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.359) |'
- en: '| host_response_timewithin an hour | 3.279 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| host_response_timewithin an hour | 3.279 |'
- en: '|  | (0.358) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.358) |'
- en: '| review_scores_rating | 2.545 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| review_scores_rating | 2.545 |'
- en: '|  | (0.116) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|  | (0.116) |'
- en: '| Num.Obs. | 14152 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| Num.Obs. | 14152 |'
- en: '| AIC | 14948.4 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| AIC | 14948.4 |'
- en: '| BIC | 14986.2 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| BIC | 14986.2 |'
- en: '| Log.Lik. | -7469.197 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| Log.Lik. | -7469.197 |'
- en: '| F | 197.407 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| F | 197.407 |'
- en: '| RMSE | 0.42 |*  *We see that each of the levels is positively associated
    with the probability of being a superhost. However, having a host that responds
    within an hour is associated with individuals that are superhosts in our dataset.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '| RMSE | 0.42 |*  *我们发现每个级别都与成为超级房东的概率呈正相关。然而，在我们的数据集中，响应时间在一小时内的房东与超级房东有关。'
- en: We will save this analysis dataset.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将保存这个分析数据集。
- en: '[PRE93]***********  ***## 11.6 Concluding remarks'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE93]***********  ***## 11.6 结论'
- en: In this chapter we have considered exploratory data analysis (EDA), which is
    the active process of getting to know a dataset. We focused on missing data, the
    distributions of variables, and the relationships between variables. And we extensively
    used graphs and tables to do this.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们考虑了探索性数据分析（EDA），这是了解数据集的积极过程。我们关注了缺失数据、变量的分布以及变量之间的关系。为此，我们广泛使用了图表和表格。
- en: The approaches to EDA will vary depending on context, and the issues and features
    that are encountered in the dataset. It will also depend on your skills, for instance
    it is common to consider regression models, and dimensionality reduction approaches.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: EDA的方法将根据上下文而变化，以及数据集中遇到的问题和特征。它还将取决于你的技能，例如，考虑回归模型和降维方法是常见的。
- en: 11.7 Exercises
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.7 练习
- en: Practice
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: '*(Plan)* Consider the following scenario: *We have some data on age from a
    social media company that has about 80 per cent of the US population on the platform.*
    Please sketch what that dataset could look like and then sketch a graph that you
    could build to show all observations.'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(计划)* 考虑以下场景：*我们有一些来自一个社交媒体公司的关于年龄的数据，该公司平台上约有80%的美国人口。* 请绘制该数据集可能的样子，然后绘制一个图形来展示所有观测值。'
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation. Use parquet due to size. Please include ten tests based on the simulated
    data. Submit a link to a GitHub Gist that contains your code.'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(模拟)* 请进一步考虑所描述的场景，并模拟这种情况。由于大小问题，请使用parquet。请包括基于模拟数据的十个测试。提交一个包含你代码的GitHub
    Gist链接。'
- en: '*(Acquire)* Please describe a possible source of such a dataset.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(获取)* 请描述此类数据集的可能来源。'
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched. Submit
    a link to a GitHub Gist that contains your code.'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(探索)* 请使用`ggplot2`构建你绘制的图形。提交一个包含你代码的GitHub Gist链接。'
- en: '*(Communicate)* Please write one page about what you did, and be careful to
    discuss some of the threats to the estimate that you make based on the sample.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(沟通)* 请写一页关于你所做的工作，并注意讨论基于样本所做的估计的一些威胁。'
- en: Quiz
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小测验
- en: Summarize Tukey ([1962](99-references.html#ref-tukey1962future)) in a few paragraphs
    and then relate it to data science.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用几段文字总结Tukey（[1962](99-references.html#ref-tukey1962future)）的观点，并将其与数据科学联系起来。
- en: In your own words what is exploratory data analysis (please write at least three
    paragraphs, and include citations and examples)?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用你自己的话来描述探索性数据分析（请至少写三段，并包括引用和例子）？
- en: 'Suppose you have a dataset called “my_data”, which has two columns: “first_col”
    and “second_col”. Please write some R code that would generate a graph (the type
    of graph does not matter). Submit a link to a GitHub Gist that contains your code.'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你有一个名为“my_data”的数据集，它有两个列：“first_col”和“second_col”。请编写一些R代码来生成一个图形（图形类型不重要）。提交一个包含你代码的GitHub
    Gist链接。
- en: 'Consider a dataset that has 500 observations and three variables, so there
    are 1,500 cells. If 100 of the rows are missing a cell for at least one of the
    columns, then would you: a) remove the whole row from your dataset, b) try to
    run your analysis on the data as is, or c) some other procedure? What if your
    dataset had 10,000 rows instead, but the same number of missing rows? Discuss,
    with examples and citations, in at least three paragraphs.'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑一个包含500个观测值和三个变量的数据集，因此有1500个单元格。如果100行至少有一列的单元格缺失，那么你会：a) 从数据集中删除整个行，b) 尝试在数据上进行分析，或者c)
    采用其他程序？如果数据集有10,000行，但缺失行数相同，会怎样？请至少用三个段落，通过例子和引用进行讨论。
- en: Please discuss three ways of identifying unusual values, writing at least one
    paragraph for each.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请讨论三种识别异常值的方法，每种方法至少写一段文字。
- en: What is the difference between a categorical and continuous variable?
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类别变量和连续变量之间的区别是什么？
- en: What is the difference between a factor and an integer variable?
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因子和整数变量之间的区别是什么？
- en: How can we think about who is systematically excluded from a dataset?
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何思考谁系统地被排除在数据集之外？
- en: 'Using `opendatatoronto`, download the data on mayoral campaign contributions
    for 2014\. (Note: the 2014 file you will get from `get_resource()` contains many
    sheets, so just keep the sheet that relates to the mayor election).'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`opendatatoronto`下载2014年的市长竞选捐款数据。（注意：从`get_resource()`获取的2014文件包含许多工作表，所以只需保留与市长选举相关的工作表）。
- en: Clean up the data format (fixing the parsing issue and standardizing the column
    names using `janitor`).
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理数据格式（修复解析问题并使用`janitor`标准化列名）。
- en: Summarize the variables in the dataset. Are there missing values, and if so,
    should we be worried about them? Is every variable in the format it should be?
    If not, create new variable(s) that are in the right format.
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结数据集中的变量。是否存在缺失值，如果有，我们应该担心它们吗？每个变量是否都处于正确的格式？如果不是，创建新的变量（s）以正确的格式。
- en: Visually explore the distribution of values of the contributions. What contributions
    are notable outliers? Do they share similar characteristic(s)? It may be useful
    to plot the distribution of contributions without these outliers to get a better
    sense of most of the data.
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化探索捐款值的分布。哪些捐款是显著的异常值？它们是否具有相似的特征（s）？可能有用的是，在不包括这些异常值的情况下绘制捐款的分布，以更好地了解大部分数据。
- en: 'List the top five candidates in each of these categories: 1) total contributions;
    2) mean contribution; and 3) number of contributions.'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出每个类别的顶级候选人：1）总捐款；2）平均捐款；3）捐款次数。
- en: Repeat that process, but without contributions from the candidates themselves.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复该过程，但不包括候选人的贡献。
- en: How many contributors gave money to more than one candidate?
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有多少贡献者向多个候选人捐款？
- en: List three geoms that produce graphs that have bars in `ggplot()`.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出三个在`ggplot()`中产生带有条形的图形的`geom`。
- en: Consider a dataset with 10,000 observations and 27 variables. For each observation,
    there is at least one missing variable. Please discuss, in a paragraph or two,
    the steps that you would take to understand what is going on.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑一个包含10,000个观测值和27个变量的数据集。对于每个观测值，至少有一个缺失变量。请在一两段文字中讨论，你会采取哪些步骤来理解发生了什么。
- en: Known missing data are those that leave holes in your dataset. But what about
    data that were never collected? Please look at McClelland ([2019](99-references.html#ref-mcclelland2019lock))
    and Luscombe and McClelland ([2020](99-references.html#ref-luscombe2020policing)).
    Look into how they gathered their dataset and what it took to put this together.
    What is in the dataset and why? What is missing and why? How could this affect
    the results? How might similar biases enter into other datasets that you have
    used or read about?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 已知的缺失数据是那些在你的数据集中留下空缺的数据。但从未收集到的数据呢？请参考McClelland ([2019](99-references.html#ref-mcclelland2019lock))
    和 Luscombe 及 McClelland ([2020](99-references.html#ref-luscombe2020policing))。研究他们如何收集数据集以及整合这些数据需要什么。数据集中有什么？为什么？有什么缺失？为什么？这可能会如何影响结果？类似的偏差可能会进入你使用或阅读过的其他数据集中吗？
- en: Class activities
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 课堂活动
- en: Fix the following file names.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复以下文件名。
- en: '[PRE94]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Consider Anscombe’s Quartet, introduced in [Chapter 5](05-graphs_tables_maps.html).
    We will randomly remove certain observations. Please pretend you are given the
    dataset with missing data. Pick one of the approaches to dealing with missing
    data from [Chapter 6](06-farm.html) and [Chapter 11](#sec-exploratory-data-analysis),
    then write code to implement your choice. Compare:'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑在[第5章](05-graphs_tables_maps.html)中介绍的Anscombe的四重奏。我们将随机删除某些观测值。请假设你得到了带有缺失数据的这个数据集。从[第6章](06-farm.html)和[第11章](#sec-exploratory-data-analysis)中选择处理缺失数据的方法之一，然后编写代码来实现你的选择。比较：
- en: the results with the actual observations;
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与实际观测值的结果；
- en: the summary statistics with the actual summary statistics; and
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与实际摘要统计量的摘要统计量；
- en: build a graph that shows the missing and actual data on the one graph.
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个图表上构建显示缺失数据和实际数据的图表。
- en: '[PRE95]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '*[PRE96]'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE96]'
- en: '[PRE97]*  ***   Redo the exercise, but with the following dataset. What is
    the main difference in this case?'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE97]*  ***   重新做这个练习，但使用以下数据集。在这种情况下，主要区别是什么？'
- en: '[PRE98]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '*[PRE99]'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE99]'
- en: '[PRE100]*  ***   Using pair programming (being sure to switch every 5 minutes),
    create a new R project, then read in the following dataset from Bombieri et al.
    ([2023](99-references.html#ref-Bombieri2023)) and explore it by adding code and
    notes to a Quarto document.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE100]*  ***   使用结对编程（确保每5分钟切换一次），创建一个新的R项目，然后从Bombieri等人([2023](99-references.html#ref-Bombieri2023))的数据集中读取以下数据集，并通过在Quarto文档中添加代码和注释来探索它。'
- en: '[PRE101]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '**   Play the role of a data scientist partnering with a subject expert by
    pairing up with another student. Your partner gets to pick a topic, and a question,
    and it should be something they know well but you do not (perhaps something about
    their country, if they are an international student). You need to work with them
    to develop an analysis plan, simulate some data, and create a graph that they
    can use.*****  ***### Task'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**   通过与其他学生配对，扮演与主题专家合作的数据科学家。你的合作伙伴可以选择一个主题和一个问题，这应该是他们非常了解而你不太了解的（如果他们是国际学生，可能是关于他们的国家）。你需要与他们合作制定分析计划，模拟一些数据，并创建一个他们可以使用的图表。*****  ***###
    任务'
- en: Pick one of the following options. Use Quarto, and include an appropriate title,
    author, date, link to a GitHub repo, and citations. Submit a PDF.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 选择以下选项之一。使用Quarto，包括适当的标题、作者、日期、GitHub仓库链接和引用。提交PDF。
- en: '**Option 1:**'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '**选项1：**'
- en: Repeat the missing data exercise conducted for the US states and population,
    but for the “bill_length_mm” variable in the `penguins()` dataset available from
    `palmerpenguins`. Compare the imputed value with the actual value.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 重复为美国各州和人口进行的缺失数据练习，但针对来自`palmerpenguins`的`penguins()`数据集中的“bill_length_mm”变量。比较估计值与实际值。
- en: Write at least two pages about what you did and what you found.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 至少写两页关于你所做和发现的内容。
- en: Following this, please pair with another student and exchange your written work.
    Update it based on their feedback, and be sure to acknowledge them by name in
    your paper.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，请与另一位学生配对并交换你们的书面作品。根据他们的反馈进行更新，并确保在你们的论文中通过姓名对他们表示感谢。
- en: '**Option 2:**'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '**选项 2：**'
- en: Carry out an Airbnb EDA but for Paris.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 对巴黎进行 Airbnb EDA 分析。
- en: '**Option 3:**'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '**选项 3：**'
- en: 'Please write at least two pages about the topic: “what is missing data and
    what should you do about it?”'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 请至少写两页关于以下主题的内容：“什么是缺失数据，你应该如何处理它？”
- en: Following this, please pair with another student and exchange your written work.
    Update it based on their feedback, and be sure to acknowledge them by name in
    your paper.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，请与另一位学生配对并交换你们的书面作品。根据他们的反馈进行更新，并确保在你们的论文中通过姓名对他们表示感谢。
- en: 'Arel-Bundock, Vincent. 2022\. “modelsummary: Data and Model Summaries in R.”
    *Journal of Statistical Software* 103 (1): 1–23\. [https://doi.org/10.18637/jss.v103.i01](https://doi.org/10.18637/jss.v103.i01).———.
    2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,” “Markdown,”
    “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Bombieri,
    Giulia, Vincenzo Penteriani, Kamran Almasieh, Hüseyin Ambarlı, Mohammad Reza Ashrafzadeh,
    Chandan Surabhi Das, Nishith Dharaiya, et al. 2023\. “A Worldwide Perspective
    on Large Carnivore Attacks on Humans.” *PLOS Biology* 21 (1): e3001946\. [https://doi.org/10.1371/journal.pbio.3001946](https://doi.org/10.1371/journal.pbio.3001946).Cox,
    Murray. 2021\. “Inside Airbnb—Toronto Data.” [http://insideairbnb.com/get-the-data.html](http://insideairbnb.com/get-the-data.html).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gelfand,
    Sharla. 2022\. *opendatatoronto: Access the City of Toronto Open Data Portal*.
    [https://CRAN.R-project.org/package=opendatatoronto](https://CRAN.R-project.org/package=opendatatoronto).Gelman,
    Andrew, and Jennifer Hill. 2007\. *Data Analysis Using Regression and Multilevel/Hierarchical
    Models*. 1st ed. Cambridge University Press.Gelman, Andrew, Jennifer Hill, and
    Aki Vehtari. 2020\. *Regression and Other Stories*. Cambridge University Press.
    [https://avehtari.github.io/ROS-Examples/](https://avehtari.github.io/ROS-Examples/).Grolemund,
    Garrett, and Hadley Wickham. 2011\. “Dates and Times Made Easy with lubridate.”
    *Journal of Statistical Software* 40 (3): 1–25\. [https://doi.org/10.18637/jss.v040.i03](https://doi.org/10.18637/jss.v040.i03).Horton,
    Nicholas, and Stuart Lipsitz. 2001\. “Multiple Imputation in Practice.” *The American
    Statistician* 55 (3): 244–54\. [https://doi.org/10.1198/000313001317098266](https://doi.org/10.1198/000313001317098266).Luscombe,
    Alex, and Alexander McClelland. 2020\. “Policing the Pandemic: Tracking the Policing
    of Covid-19 Across Canada,” April. [https://doi.org/10.31235/osf.io/9pn27](https://doi.org/10.31235/osf.io/9pn27).Manski,
    Charles. 2022\. “Inference with Imputed Data: The Allure of Making Stuff Up.”
    arXiv. [https://doi.org/10.48550/arXiv.2205.07388](https://doi.org/10.48550/arXiv.2205.07388).McClelland,
    Alexander. 2019\. “‘Lock This Whore up’: Legal Violence and Flows of Information
    Precipitating Personal Violence Against People Criminalised for HIV-Related Crimes
    in Canada.” *European Journal of Risk Regulation* 10 (1): 132–47\. [https://doi.org/10.1017/err.2019.20](https://doi.org/10.1017/err.2019.20).Osborne,
    Jason. 2012\. *Best Practices in Data Cleaning: A Complete Guide to Everything
    You Need to Do Before and After Collecting Your Data*. SAGE Publications.R Core
    Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Richardson,
    Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane,
    Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2023\. *arrow: Integration
    to Apache Arrow*. [https://CRAN.R-project.org/package=arrow](https://CRAN.R-project.org/package=arrow).Ryan,
    Philip. 2015\. “Keeping a Lab Notebook.” *YouTube*, May. [https://youtu.be/-MAIuaOL64I](https://youtu.be/-MAIuaOL64I).Staniak,
    Mateusz, and Przemysław Biecek. 2019\. “The Landscape of R Packages for Automated
    Exploratory Data Analysis.” *The R Journal* 11 (2): 347–69\. [https://doi.org/10.32614/RJ-2019-033](https://doi.org/10.32614/RJ-2019-033).Tierney,
    Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021\. *naniar: Data Structures,
    Summaries, and Visualisations for Missing Data*. [https://CRAN.R-project.org/package=naniar](https://CRAN.R-project.org/package=naniar).Tukey,
    John. 1962\. “The Future of Data Analysis.” *The Annals of Mathematical Statistics*
    33 (1): 1–67\. [https://doi.org/10.1214/aoms/1177704711](https://doi.org/10.1214/aoms/1177704711).van
    Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011\. “mice: Multivariate Imputation
    by Chained Equations in R.” *Journal of Statistical Software* 45 (3): 1–67\. [https://doi.org/10.18637/jss.v045.i03](https://doi.org/10.18637/jss.v045.i03).Wickham,
    Hadley. 2018\. “Whole Game.” *YouTube*, January. [https://youtu.be/go5Au01Jrvs](https://youtu.be/go5Au01Jrvs).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).Wickham,
    Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. (2016) 2023\. *R for Data
    Science*. 2nd ed. O’Reilly Media. [https://r4ds.hadley.nz](https://r4ds.hadley.nz).****************'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 'Arel-Bundock, Vincent. 2022\. “modelsummary: Data and Model Summaries in R.”
    *Journal of Statistical Software* 103 (1): 1–23\. [https://doi.org/10.18637/jss.v103.i01](https://doi.org/10.18637/jss.v103.i01).———.
    2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,” “Markdown,”
    “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Bombieri,
    Giulia, Vincenzo Penteriani, Kamran Almasieh, Hüseyin Ambarlı, Mohammad Reza Ashrafzadeh,
    Chandan Surabhi Das, Nishith Dharaiya, et al. 2023\. “A Worldwide Perspective
    on Large Carnivore Attacks on Humans.” *PLOS Biology* 21 (1): e3001946\. [https://doi.org/10.1371/journal.pbio.3001946](https://doi.org/10.1371/journal.pbio.3001946).Cox,
    Murray. 2021\. “Inside Airbnb—Toronto Data.” [http://insideairbnb.com/get-the-data.html](http://insideairbnb.com/get-the-data.html).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gelfand,
    Sharla. 2022\. *opendatatoronto: Access the City of Toronto Open Data Portal*.
    [https://CRAN.R-project.org/package=opendatatoronto](https://CRAN.R-project.org/package=opendatatoronto).Gelman,
    Andrew, and Jennifer Hill. 2007\. *Data Analysis Using Regression and Multilevel/Hierarchical
    Models*. 1st ed. Cambridge University Press.Gelman, Andrew, Jennifer Hill, and
    Aki Vehtari. 2020\. *Regression and Other Stories*. Cambridge University Press.
    [https://avehtari.github.io/ROS-Examples/](https://avehtari.github.io/ROS-Examples/).Grolemund,
    Garrett, and Hadley Wickham. 2011\. “Dates and Times Made Easy with lubridate.”
    *Journal of Statistical Software* 40 (3): 1–25\. [https://doi.org/10.18637/jss.v040.i03](https://doi.org/10.18637/jss.v040.i03).Horton,
    Nicholas, and Stuart Lipsitz. 2001\. “Multiple Imputation in Practice.” *The American
    Statistician* 55 (3): 244–54\. [https://doi.org/10.1198/000313001317098266](https://doi.org/10.1198/000313001317098266).Luscombe,
    Alex, and Alexander McClelland. 2020\. “Policing the Pandemic: Tracking the Policing
    of Covid-19 Across Canada,” April. [https://doi.org/10.31235/osf.io/9pn27](https://doi.org/10.31235/osf.io/9pn27).Manski,
    Charles. 2022\. “Inference with Imputed Data: The Allure of Making Stuff Up.”
    arXiv. [https://doi.org/10.48550/arXiv.2205.07388](https://doi.org/10.48550/arXiv.2205.07388).McClelland,
    Alexander. 2019\. “‘Lock This Whore up’: Legal Violence and Flows of Information
    Precipitating Personal Violence Against People Criminalised for HIV-Related Crimes
    in Canada.” *European Journal of Risk Regulation* 10 (1): 132–47\. [https://doi.org/10.1017/err.2019.20](https://doi.org/10.1017/err.2019.20).Osborne,
    Jason. 2012\. *Best Practices in Data Cleaning: A Complete Guide to Everything
    You Need to Do Before and After Collecting Your Data*. SAGE Publications.R Core
    Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Richardson,
    Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane,
    Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2023\. *arrow: Integration
    to Apache Arrow*. [https://CRAN.R-project.org/package=arrow](https://CRAN.R-project.org/package=arrow).Ryan,
    Philip. 2015\. “Keeping a Lab Notebook.” *YouTube*, May. [https://youtu.be/-MAIuaOL64I](https://youtu.be/-MAIuaOL64I).Staniak,
    Mateusz, and Przemysław Biecek. 2019\. “The Landscape of R Packages for Automated
    Exploratory Data Analysis.” *The R Journal* 11 (2): 347–69\. [https://doi.org/10.32614/RJ-2019-033](https://doi.org/10.32614/RJ-2019-033).Tierney,
    Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021\. *naniar: Data Structures,
    Summaries, and Visualisations for Missing Data*. [https://CRAN.R-project.org/package=naniar](https://CRAN.R-project.org/package=naniar).Tukey,
    John. 1962\. “The Future of Data Analysis.” *The Annals of Mathematical Statistics*
    33 (1): 1–67\. [https://doi.org/10.1214/aoms/1177704711](https://doi.org/10.1214/aoms/1177704711).van
    Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011\. “mice: Multivariate Imputation
    by Chained Equations in R.” *Journal of Statistical Software* 45 (3): 1–67\. [https://doi.org/10.18637/jss.v045.i03](https://doi.org/10.18637/jss.v045.i03).Wickham,
    Hadley. 2018\. “Whole Game.” *YouTube*, January. [https://youtu.be/go5Au01Jrvs](https://youtu.be/go5Au01Jrvs).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).Wickham,
    Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. (2016) 2023\. *R for Data
    Science*. 2nd ed. O’Reilly Media. [https://r4ds.hadley.nz](https://r4ds.hadley.nz).'
