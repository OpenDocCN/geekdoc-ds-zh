- en: 8.6\. Exercises#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8.6\. 练习题#
- en: 原文：[https://mmids-textbook.github.io/chap08_nn/exercises/roch-mmids-nn-exercises.html](https://mmids-textbook.github.io/chap08_nn/exercises/roch-mmids-nn-exercises.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap08_nn/exercises/roch-mmids-nn-exercises.html](https://mmids-textbook.github.io/chap08_nn/exercises/roch-mmids-nn-exercises.html)
- en: 8.6.1\. Warm-up worksheets[#](#warm-up-worksheets "Link to this heading")
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6.1\. 预习工作表[#](#warm-up-worksheets "链接到这个标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*(with help from Claude, Gemini, and ChatGPT)*'
- en: '**Section 8.2**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**第8.2节**'
- en: '**E8.2.1** Let \(A = \begin{pmatrix} 2 & 1 \\ 0 & -1 \end{pmatrix}\). Compute
    the vectorization \(\text{vec}(A)\).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.1** 设 \(A = \begin{pmatrix} 2 & 1 \\ 0 & -1 \end{pmatrix}\)。计算向量 \(\text{vec}(A)\)。'
- en: '**E8.2.2** Let \(\mathbf{a} = (2, -1, 3)\) and \(\mathbf{b} = (1, 0, -2)\).
    Compute the Hadamard product \(a \odot b\).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.2** 设 \(\mathbf{a} = (2, -1, 3)\) 和 \(\mathbf{b} = (1, 0, -2)\)。计算哈达玛积
    \(a \odot b\)。'
- en: '**E8.2.3** Let \(A = \begin{pmatrix} 1 & 2 \\ -1 & 0 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 3 & -1 \\ 2 & 1 \end{pmatrix}\). Compute the Kronecker product
    \(A \otimes B\).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.3** 设 \(A = \begin{pmatrix} 1 & 2 \\ -1 & 0 \end{pmatrix}\) 和 \(B =
    \begin{pmatrix} 3 & -1 \\ 2 & 1 \end{pmatrix}\)。计算克罗内克积 \(A \otimes B\)。'
- en: '**E8.2.4** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute the Hadamard product
    \(A \odot B\).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.4** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算哈达玛积 \(A \odot B\)。'
- en: '**E8.2.5** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute the Kronecker product
    \(A \otimes B\).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.5** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算克罗内克积 \(A \otimes B\)。'
- en: '**E8.2.6** Let \(\mathbf{f}(x, y) = (x^2y, \sin(xy), e^{x+y})\). Compute the
    Jacobian matrix of \(\mathbf{f}\) at the point \((1, \frac{\pi}{2})\).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.6** 设 \(\mathbf{f}(x, y) = (x^2y, \sin(xy), e^{x+y})\)。计算 \(\mathbf{f}\)
    在点 \((1, \frac{\pi}{2})\) 处的雅可比矩阵。'
- en: '**E8.2.7** Let \(\mathbf{f}(x, y) = (x^2 + y^2, xy)\) and \(\mathbf{g}(u, v)
    = (uv, u + v)\). Compute the Jacobian matrix of the composition \(\mathbf{g} \circ
    \mathbf{f}\) at the point \((1, 2)\).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.7** 设 \(\mathbf{f}(x, y) = (x^2 + y^2, xy)\) 和 \(\mathbf{g}(u, v) =
    (uv, u + v)\)。计算 \(\mathbf{g} \circ \mathbf{f}\) 在点 \((1, 2)\) 处的雅可比矩阵。'
- en: '**E8.2.8** Let \(\mathbf{a} = (1, 2, 3)\), \(\mathbf{b} = (4, 5, 6)\), and
    \(\mathbf{c} = (7, 8, 9)\). Compute \(\mathbf{a}^T(\mathbf{b} \odot \mathbf{c})\)
    and \(\mathbf{1}^T(\mathbf{a} \odot \mathbf{b} \odot \mathbf{c})\) and verify
    that they are equal.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.8** 设 \(\mathbf{a} = (1, 2, 3)\)，\(\mathbf{b} = (4, 5, 6)\)，和 \(\mathbf{c}
    = (7, 8, 9)\)。计算 \(\mathbf{a}^T(\mathbf{b} \odot \mathbf{c})\) 和 \(\mathbf{1}^T(\mathbf{a}
    \odot \mathbf{b} \odot \mathbf{c})\) 并验证它们相等。'
- en: '**E8.2.9** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute \((A \otimes B)^T\)
    and \(A^T \otimes B^T\) and verify that they are equal.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.9** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算 \((A \otimes B)^T\) 和 \(A^T \otimes B^T\) 并验证它们相等。'
- en: '**E8.2.10** Let \(\mathbf{g}(x, y) = (x^2y, x + y)\). Compute the Jacobian
    matrix \(J_{\mathbf{g}}(x, y)\).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.10** 设 \(\mathbf{g}(x, y) = (x^2y, x + y)\)。计算雅可比矩阵 \(J_{\mathbf{g}}(x,
    y)\)。'
- en: '**E8.2.11** Let \(f(x, y, z) = x^2 + y^2 + z^2\). Compute the gradient of \(f\)
    at the point \((1, 2, 3)\).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.11** 设 \(f(x, y, z) = x^2 + y^2 + z^2\)。计算 \(f\) 在点 \((1, 2, 3)\) 处的梯度。'
- en: '**E8.2.12** Let \(f(x) = 2x^3 - x\) and \(g(y) = y^2 + 1\). Compute the Jacobian
    of the composite function \(g \circ f\) at \(x = 1\).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.12** 设 \(f(x) = 2x^3 - x\) 和 \(g(y) = y^2 + 1\)。计算复合函数 \(g \circ f\)
    在 \(x = 1\) 处的雅可比矩阵。'
- en: '**E8.2.13** Let \(f(x, y) = xy\) and \(\mathbf{g}(x, y) = (x^2, y^2)\). Compute
    the Jacobian matrix of \(f \circ \mathbf{g}\) at the point \((1, 2)\).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.13** 设 \(f(x, y) = xy\) 和 \(\mathbf{g}(x, y) = (x^2, y^2)\)。计算 \(f \circ
    \mathbf{g}\) 在点 \((1, 2)\) 处的雅可比矩阵。'
- en: '**E8.2.14** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(\mathbf{b}
    = \begin{pmatrix} 5 \\ 6 \end{pmatrix}\). Define the function \(\mathbf{f}(\mathbf{x})
    = A \mathbf{x} + \mathbf{b}\). Compute the Jacobian matrix of \(\mathbf{f}\) at
    any point \(\mathbf{x} \in \mathbb{R}^2\).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.14** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(\mathbf{b}
    = \begin{pmatrix} 5 \\ 6 \end{pmatrix}\)。定义函数 \(\mathbf{f}(\mathbf{x}) = A \mathbf{x}
    + \mathbf{b}\)。计算 \(\mathbf{f}\) 在任意点 \(\mathbf{x} \in \mathbb{R}^2\) 处的雅可比矩阵。'
- en: '**E8.2.15** Let \(f(x) = \sin(x)\). Define the function \(\mathbf{g}(x, y,
    z) = (f(x), f(y), f(z))\). Compute the Jacobian matrix of \(\mathbf{g}\) at the
    point \((\frac{\pi}{2}, \frac{\pi}{4}, \frac{\pi}{6})\).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.15** 设 \(f(x) = \sin(x)\)。定义函数 \(\mathbf{g}(x, y, z) = (f(x), f(y),
    f(z))\)。计算 \(\mathbf{g}\) 在点 \((\frac{\pi}{2}, \frac{\pi}{4}, \frac{\pi}{6})\)
    处的雅可比矩阵。'
- en: '**E8.2.16** Use PyTorch to find the gradient of \(f(x) = x^3 - 4x\) at \(x
    = 2\). Provide the PyTorch code and the result.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.16** 使用 PyTorch 计算 \(f(x) = x^3 - 4x\) 在 \(x = 2\) 处的梯度。提供 PyTorch 代码和结果。'
- en: '**Section 8.3**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.3 节**'
- en: '**E8.3.1** Let \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 2 & 1 \\ -1 & 3 \end{pmatrix}\). How many elementary operations
    (additions and multiplications) does it take to compute \(AB\)?'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.1** 设 \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) 和 \(B =
    \begin{pmatrix} 2 & 1 \\ -1 & 3 \end{pmatrix}\)。计算 \(AB\) 需要进行多少次基本运算（加法和乘法）？'
- en: '**E8.3.2** Let \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) and \(\mathbf{v}
    = (2, -1)\). How many elementary operations (additions and multiplications) does
    it take to compute \(A\mathbf{v}\)?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.2** 设 \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) 和 \(\mathbf{v}
    = (2, -1)\)。计算 \(A\mathbf{v}\) 需要进行多少次基本运算（加法和乘法）？'
- en: '**E8.3.3** Let \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\) where \(\hat{\mathbf{y}}
    = (\hat{y}_1, \hat{y}_2)\). Compute \(J_{\ell}(\hat{\mathbf{y}})\).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.3** 设 \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\) 其中 \(\hat{\mathbf{y}}
    = (\hat{y}_1, \hat{y}_2)\)。计算 \(J_{\ell}(\hat{\mathbf{y}})\)。'
- en: '**E8.3.4** Let \(\mathbf{g}_0(\mathbf{z}_0) = \begin{pmatrix} 1 & 2 \\ -1 &
    0 \end{pmatrix} \mathbf{z}_0\) and \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\).
    Compute \(\nabla f(\mathbf{x})\) where \(f(\mathbf{x}) = \ell(\mathbf{g}_0(\mathbf{x}))\)
    and \(\mathbf{x} = (1, -1)\).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.4** 设 \(\mathbf{g}_0(\mathbf{z}_0) = \begin{pmatrix} 1 & 2 \\ -1 & 0
    \end{pmatrix} \mathbf{z}_0\) 和 \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\)。计算
    \(f(\mathbf{x}) = \ell(\mathbf{g}_0(\mathbf{x}))\) 在 \(\mathbf{x} = (1, -1)\)
    处的梯度 \(\nabla f(\mathbf{x})\)。'
- en: '**E8.3.5** Let \(\mathbf{g}_0\) and \(\ell\) be as in E8.3.4\. Let \(\mathbf{g}_1(\mathbf{z}_1)
    = \begin{pmatrix} -1 & 0 \\ 1 & 1 \end{pmatrix} \mathbf{z}_1\). Compute \(\nabla
    f(\mathbf{x})\) where \(f(\mathbf{x}) = \ell(\mathbf{g}_1(\mathbf{g}_0(\mathbf{x})))\)
    and \(\mathbf{x} = (1, -1)\) using the reverse mode.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.5** 设 \(\mathbf{g}_0\) 和 \(\ell\) 如 E8.3.4 所示。设 \(\mathbf{g}_1(\mathbf{z}_1)
    = \begin{pmatrix} -1 & 0 \\ 1 & 1 \end{pmatrix} \mathbf{z}_1\)。使用反向传播法计算 \(f(\mathbf{x})
    = \ell(\mathbf{g}_1(\mathbf{g}_0(\mathbf{x})))\) 在 \(\mathbf{x} = (1, -1)\) 处的梯度
    \(\nabla f(\mathbf{x})\)。'
- en: '**E8.3.6** Let \(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0) = \mathcal{W}_0 \mathbf{x}\)
    where \(\mathcal{W}_0 = \begin{pmatrix} w_0 & w_1 \\ w_2 & w_3 \end{pmatrix}\)
    and \(\mathbf{w}_0 = (w_0, w_1, w_2, w_3)\). Let \(\mathbf{x} = (-1, 1)\) be fixed.
    Compute the Jacobian \(J_{\mathbf{g}_0}(\mathbf{x}, \mathbf{w}_0)\) with respect
    to \(\mathbf{w}_0\) only by directly computing the necessary partial derivatives
    (i.e., without using the formulas in the text), and then compare to the formulas
    in the text.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.6** 设 \(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0) = \mathcal{W}_0 \mathbf{x}\)
    其中 \(\mathcal{W}_0 = \begin{pmatrix} w_0 & w_1 \\ w_2 & w_3 \end{pmatrix}\) 和
    \(\mathbf{w}_0 = (w_0, w_1, w_2, w_3)\)。设 \(\mathbf{x} = (-1, 1)\) 为固定值。仅通过直接计算必要的偏导数（即，不使用文本中的公式）来计算关于
    \(\mathbf{w}_0\) 的雅可比矩阵 \(J_{\mathbf{g}_0}(\mathbf{x}, \mathbf{w}_0)\)，然后与文本中的公式进行比较。'
- en: '**E8.3.7** Let \(g_1(\mathbf{z}_1, \mathbf{w}_1) = \mathcal{W}_1 \mathbf{z}_1\)
    where \(\mathcal{W}_1 = \begin{pmatrix} w_4 & w_5\end{pmatrix}\) and \(\mathbf{w}_1
    = (w_4, w_5)\). Compute \(J_{g_1}(\mathbf{z}_1, \mathbf{w}_1)\) with respect to
    both \(\mathbf{z}_1\) and \(\mathbf{w}_1\) by directly computing the necessary
    partial derivatives (i.e., without using the formulas in the text), and then compare
    to the formulas in the text.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.7** 设 \(g_1(\mathbf{z}_1, \mathbf{w}_1) = \mathcal{W}_1 \mathbf{z}_1\)
    其中 \(\mathcal{W}_1 = \begin{pmatrix} w_4 & w_5\end{pmatrix}\) 和 \(\mathbf{w}_1
    = (w_4, w_5)\)。直接计算必要的偏导数（即，不使用文本中的公式），分别对 \(\mathbf{z}_1\) 和 \(\mathbf{w}_1\)
    计算 \(J_{g_1}(\mathbf{z}_1, \mathbf{w}_1)\)，然后与文本中的公式进行比较。'
- en: '**E8.3.8** Let \(h(\mathbf{w}) = g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1)\) where \(\mathbf{g}_0\) and \(g_1\) are as in E8.3.6 and E8.3.7
    and \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1, w_2, w_3, w_4, w_5)\).
    Let \(\mathbf{x} = (-1, 1)\) be fixed. Compute \(J_h(\mathbf{w})\) by directly
    computing the necessary partial derivatives (i.e., without using the formulas
    in the text).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.8** 设 \(h(\mathbf{w}) = g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1)\) 其中 \(\mathbf{g}_0\) 和 \(g_1\) 如 E8.3.6 和 E8.3.7 所示，且 \(\mathbf{w}
    = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1, w_2, w_3, w_4, w_5)\)。设 \(\mathbf{x}
    = (-1, 1)\) 为固定值。通过直接计算必要的偏导数（即，不使用文本中的公式）来计算 \(J_h(\mathbf{w})\)。'
- en: '**E8.3.9** Let \(f(\mathbf{w}) = \ell(g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1))\) where \(\ell(\hat{y}) = \hat{y}^2\), \(\mathbf{g}_0\) and \(g_1\)
    are as in E8.3.6 and E8.3.7, and \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) =
    (w_0, w_1, w_2, w_3, w_4, w_5)\). Let \(\mathbf{x} = (-1, 1)\) be fixed. Compute
    \(J_f(\mathbf{w})\) by directly computing the necessary partial derivatives (i.e.,
    without using the formulas in the text), and then compare to the formulas in the
    text.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.9** 设 \(f(\mathbf{w}) = \ell(g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1))\)，其中 \(\ell(\hat{y}) = \hat{y}^2\)，\(\mathbf{g}_0\) 和 \(g_1\) 如
    E8.3.6 和 E8.3.7 中所述，且 \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1,
    w_2, w_3, w_4, w_5)\)。设 \(\mathbf{x} = (-1, 1)\) 为固定值。通过直接计算必要的偏导数（即，不使用文本中的公式）来计算
    \(J_f(\mathbf{w})\)，然后与文本中的公式进行比较。'
- en: '**Section 8.4**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**第8.4节**'
- en: '**E8.4.1** Given a dataset with 5 samples, compute the full gradient descent
    step and the expected SGD step with a batch size of 2\. Assume that the individual
    sample gradients are: \(\nabla f_{\mathbf{x}_1, y_1}(\mathbf{w}) = (1, 2)\), \(\nabla
    f_{\mathbf{x}_2, y_2}(\mathbf{w}) = (-1, 1)\), \(\nabla f_{\mathbf{x}_3, y_3}(\mathbf{w})
    = (0, -1)\), \(\nabla f_{\mathbf{x}_4, y_4}(\mathbf{w}) = (2, 0)\), and \(\nabla
    f_{\mathbf{x}_5, y_5}(\mathbf{w}) = (1, 1)\).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.1** 给定一个包含5个样本的数据集，计算全梯度下降步和批大小为2的期望随机梯度下降步。假设单个样本梯度为：\(\nabla f_{\mathbf{x}_1,
    y_1}(\mathbf{w}) = (1, 2)\)，\(\nabla f_{\mathbf{x}_2, y_2}(\mathbf{w}) = (-1,
    1)\)，\(\nabla f_{\mathbf{x}_3, y_3}(\mathbf{w}) = (0, -1)\)，\(\nabla f_{\mathbf{x}_4,
    y_4}(\mathbf{w}) = (2, 0)\)，和 \(\nabla f_{\mathbf{x}_5, y_5}(\mathbf{w}) = (1,
    1)\)。'
- en: '**E8.4.2** Compute the softmax function \(\boldsymbol{\gamma}(\mathbf{z})\)
    for \(\mathbf{z} = (1, -2, 0, 3)\).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.2** 计算对于 \(\mathbf{z} = (1, -2, 0, 3)\) 的softmax函数 \(\boldsymbol{\gamma}(\mathbf{z})\)。'
- en: '**E8.4.3** Compute the Kullback-Leibler divergence between the probability
    distributions \(\mathbf{p} = (0.2, 0.3, 0.5)\) and \(\mathbf{q} = (0.1, 0.4, 0.5)\).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.3** 计算概率分布 \(\mathbf{p} = (0.2, 0.3, 0.5)\) 和 \(\mathbf{q} = (0.1, 0.4,
    0.5)\) 之间的Kullback-Leibler散度。'
- en: '**E8.4.4** In linear regression with a single feature, the loss function for
    a single sample \((x, y)\) is given by'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.4** 在单特征线性回归中，单个样本 \((x, y)\) 的损失函数由以下公式给出'
- en: \[ \ell(w, b; x, y) = (wx + b - y)^2. \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \ell(w, b; x, y) = (wx + b - y)^2. \]
- en: Compute the gradients \(\frac{\partial \ell}{\partial w}\) and \(\frac{\partial
    \ell}{\partial b}\).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度 \(\frac{\partial \ell}{\partial w}\) 和 \(\frac{\partial \ell}{\partial
    b}\)。
- en: '**E8.4.5** Suppose we have a dataset with three samples: \((x_1, y_1) = (2,
    3)\), \((x_2, y_2) = (-1, 0)\), and \((x_3, y_3) = (1, 2)\). We want to perform
    mini-batch SGD for linear regression with a batch size of 2\. If the first mini-batch
    randomly selected is \(B = \{1, 3\}\), compute the SGD update for the parameters
    \(w\) and \(b\), assuming a learning rate of \(\alpha = 0.1\). The model is initialized
    at \(w = 1\) and \(b = 0\).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.5** 假设我们有一个包含三个样本的数据集：\((x_1, y_1) = (2, 3)\)，\((x_2, y_2) = (-1, 0)\)，和
    \((x_3, y_3) = (1, 2)\)。我们想要对线性回归进行批大小为2的迷你批随机梯度下降。如果第一个随机选择的迷你批是 \(B = \{1, 3\}\)，假设学习率为
    \(\alpha = 0.1\)，计算参数 \(w\) 和 \(b\) 的SGD更新，假设模型初始化为 \(w = 1\) 和 \(b = 0\)。'
- en: '**E8.4.6** For the linear regression problem with a single sample \((\mathbf{x},
    y) = ((1, 2), 3)\), compute the gradient of the loss function \(f(\mathbf{w})
    = (\mathbf{x}^T \mathbf{w} - y)^2\) at \(\mathbf{w} = (0, 0)\).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.6** 对于单样本线性回归问题 \((\mathbf{x}, y) = ((1, 2), 3)\)，计算损失函数 \(f(\mathbf{w})
    = (\mathbf{x}^T \mathbf{w} - y)^2\) 在 \(\mathbf{w} = (0, 0)\) 处的梯度。'
- en: '**E8.4.7** Consider the logistic regression loss function for a single sample
    \((x, y)\) where \(x \in \mathbb{R}\) and \(y \in \{0, 1\}\):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.7** 考虑单个样本 \((x, y)\) 的逻辑回归损失函数，其中 \(x \in \mathbb{R}\) 且 \(y \in \{0,
    1\}\):'
- en: \[ \ell(w; x, y) = -y \log(\sigma(wx)) - (1-y) \log(1 - \sigma(wx)), \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \ell(w; x, y) = -y \log(\sigma(wx)) - (1-y) \log(1 - \sigma(wx)), \]
- en: where \(\sigma(z) = \frac{1}{1 + e^{-z}}\) is the sigmoid function. Compute
    the gradient \(\nabla \ell(w; x, y)\) with respect to \(w\).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\sigma(z) = \frac{1}{1 + e^{-z}}\) 是sigmoid函数。计算关于 \(w\) 的梯度 \(\nabla \ell(w;
    x, y)\)。
- en: '**E8.4.8** Consider a multinomial logistic regression problem with three classes
    (\(K = 3\)). Given an input vector \(\mathbf{x} = (1, -1)\), and a weight matrix'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.8** 考虑一个有三个类别 (\(K = 3\)) 的多项式逻辑回归问题。给定一个输入向量 \(\mathbf{x} = (1, -1)\)
    和一个权重矩阵'
- en: \[\begin{split} W = \begin{pmatrix} 1 & 2 \\ -1 & 0 \\ 0 & 1 \end{pmatrix},
    \end{split}\]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} W = \begin{pmatrix} 1 & 2 \\ -1 & 0 \\ 0 & 1 \end{pmatrix},
    \end{split}\]
- en: compute the softmax output \(\boldsymbol{\gamma}(W\mathbf{x})\).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 计算softmax输出 \(\boldsymbol{\gamma}(W\mathbf{x})\)。
- en: '**E8.4.9** For the multinomial logistic regression problem with a single sample
    \((\mathbf{x}, \mathbf{y}) = ((1, 2), (0, 0, 1))\) and \(K = 3\) classes, compute
    the gradient of the loss function \(f(\mathbf{w}) = -\sum_{i=1}^K y_i \log \gamma_i(W\mathbf{x})\)
    at \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.9** 对于具有单个样本 \((\mathbf{x}, \mathbf{y}) = ((1, 2), (0, 0, 1))\) 和 \(K
    = 3\) 个类别的多项式逻辑回归问题，计算在 \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\)
    处损失函数 \(f(\mathbf{w}) = -\sum_{i=1}^K y_i \log \gamma_i(W\mathbf{x})\) 的梯度。'
- en: '**E8.4.10** For the linear regression problem with two samples \((\mathbf{x}_1,
    y_1) = ((1, 2), 3)\) and \((\mathbf{x}_2, y_2) = ((4, -1), 2)\), compute the full
    gradient at \(\mathbf{w} = (0, 0)\).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.10** 对于具有两个样本 \((\mathbf{x}_1, y_1) = ((1, 2), 3)\) 和 \((\mathbf{x}_2,
    y_2) = ((4, -1), 2)\) 的线性回归问题，计算在 \(\mathbf{w} = (0, 0)\) 处的完整梯度。'
- en: '**E8.4.11** For the multinomial logistic regression problem with two samples
    \((\mathbf{x}_1, \mathbf{y}_1) = ((1, 2), (0, 0, 1))\) and \((\mathbf{x}_2, \mathbf{y}_2)
    = ((4, -1), (1, 0, 0))\), and \(K = 3\) classes, compute the full gradient at
    \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.11** 对于具有两个样本 \((\mathbf{x}_1, \mathbf{y}_1) = ((1, 2), (0, 0, 1))\)
    和 \((\mathbf{x}_2, \mathbf{y}_2) = ((4, -1), (1, 0, 0))\) 的多项式逻辑回归问题，以及 \(K =
    3\) 个类别，计算在 \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\) 处的完整梯度。'
- en: '**E8.4.12** In a binary classification problem, the logistic regression model
    predicts probabilities of 0.8 and 0.3 for two samples. If the true labels for
    these samples are 1 and 0, respectively, compute the average cross-entropy loss.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.12** 在一个二元分类问题中，逻辑回归模型预测两个样本的概率为 0.8 和 0.3。如果这些样本的真实标签分别是 1 和 0，计算平均交叉熵损失。'
- en: '**E8.4.13** In a multi-class classification problem with four classes, a model
    predicts the following probability distribution for a sample: \((0.1, 0.2, 0.3,
    0.4)\). If the true label is the third class, what is the cross-entropy loss for
    this sample?'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.13** 在一个有四个类别的多类别分类问题中，一个模型预测一个样本的概率分布为 \((0.1, 0.2, 0.3, 0.4)\)。如果真实标签是第三个类别，那么这个样本的交叉熵损失是多少？'
- en: '**Section 8.5**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.5 节**'
- en: '**E8.5.1** Compute the sigmoid function \(\sigma(t)\) for the following values
    of \(t\): \(1, -1, 2\).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.1** 计算以下 \(t\) 值的 sigmoid 函数 \(\sigma(t)\)：\(1, -1, 2\)。'
- en: '**E8.5.2** Compute the derivative of the sigmoid function \(\sigma''(t)\) for
    the following values of \(t\): \(1, -1, 2\).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.2** 计算以下 \(t\) 值的 sigmoid 函数的导数 \(\sigma''(t)\)：\(1, -1, 2\)。'
- en: '**E8.5.3** Given the vector \(\mathbf{z} = (1, -1, 2)\), compute \(\bsigma(\mathbf{z})\)
    and \(\bsigma''(\mathbf{z})\).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.3** 给定向量 \(\mathbf{z} = (1, -1, 2)\)，计算 \(\bsigma(\mathbf{z})\) 和 \(\bsigma''(\mathbf{z})\)。'
- en: '**E8.5.4** Given the matrix \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\)
    and the vector \(\mathbf{x} = (1, 2)\), compute \(\bsigma(W\mathbf{x})\).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.4** 给定矩阵 \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\) 和向量 \(\mathbf{x}
    = (1, 2)\)，计算 \(\bsigma(W\mathbf{x})\)。'
- en: '**E8.5.5** Given the matrix \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\)
    and the vector \(\mathbf{x} = (1, 2)\), compute the Jacobian matrix of \(\bsigma(W\mathbf{x})\).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.5** 给定矩阵 \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\) 和向量 \(\mathbf{x}
    = (1, 2)\)，计算 \(\bsigma(W\mathbf{x})\) 的雅可比矩阵。'
- en: '**E8.5.6** Given the vectors \(\mathbf{y} = (0, 1)\) and \(\mathbf{z} = (0.3,
    0.7)\), compute the cross-entropy loss \(H(\mathbf{y}, \mathbf{z})\).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.6** 给定向量 \(\mathbf{y} = (0, 1)\) 和 \(\mathbf{z} = (0.3, 0.7)\)，计算交叉熵损失
    \(H(\mathbf{y}, \mathbf{z})\)。'
- en: '**E8.5.7** Given the vectors \(\mathbf{y} = (0, 1)\) and \(\mathbf{z} = (0.3,
    0.7)\), compute the gradient of the cross-entropy loss \(\nabla H(\mathbf{y},
    \mathbf{z})\).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.7** 给定向量 \(\mathbf{y} = (0, 1)\) 和 \(\mathbf{z} = (0.3, 0.7)\)，计算交叉熵损失
    \(\nabla H(\mathbf{y}, \mathbf{z})\) 的梯度。'
- en: '**E8.5.8** Given the vectors \(\mathbf{w} = (1, 2, -1, 0)\) and \(\mathbf{z}
    = (1, 2)\), compute \(\mathbb{A}_2[\mathbf{w}]\) and \(\mathbb{B}_2[\mathbf{z}]\).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.8** 给定向量 \(\mathbf{w} = (1, 2, -1, 0)\) 和 \(\mathbf{z} = (1, 2)\)，计算
    \(\mathbb{A}_2[\mathbf{w}]\) 和 \(\mathbb{B}_2[\mathbf{z}]\)。'
- en: 8.6.2\. Problems[#](#problems "Link to this heading")
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6.2\. 问题[#](#problems "链接到这个标题")
- en: '**8.1** Consider the affine map'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.1** 考虑仿射映射'
- en: \[ \mathbf{f}(\mathbf{x}) = A \mathbf{x} + \mathbf{b}, \]
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{f}(\mathbf{x}) = A \mathbf{x} + \mathbf{b}, \]
- en: 'where \(A \in \mathbb{R}^{m \times d}\) and \(\mathbf{b} = (b_1, \ldots, b_m)
    \in \mathbb{R}^m\). Let \(S \subseteq \mathbb{R}^m\) be a convex set. Show that
    the following set is convex:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(A \in \mathbb{R}^{m \times d}\) 且 \(\mathbf{b} = (b_1, \ldots, b_m) \in
    \mathbb{R}^m\)。设 \(S \subseteq \mathbb{R}^m\) 为一个凸集。证明以下集合是凸的：
- en: \[ T = \left\{ \mathbf{x} \in \mathbb{R}^d \,:\, \mathbf{f}(\mathbf{x}) \in
    S \right\}. \]
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: \[ T = \left\{ \mathbf{x} \in \mathbb{R}^d \,:\, \mathbf{f}(\mathbf{x}) \in
    S \right\}. \]
- en: \(\lhd\)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.2** (Adapted from [Khu]) Consider the vector-valued function \(\mathbf{f}
    = (f_1, \ldots, f_d) : \mathbb{R}^d \to \mathbb{R}^d\) defined as'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.2** （改编自[Khu]）考虑向量值函数 \(\mathbf{f} = (f_1, \ldots, f_d) : \mathbb{R}^d
    \to \mathbb{R}^d\)，定义为'
- en: \[ f_i(\mathbf{x}) = x_i^3, \]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f_i(\mathbf{x}) = x_i^3, \]
- en: for all \(\mathbf{x} \in \mathbb{R}^d\) and all \(i = 1, \ldots, d\).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(\mathbf{x} \in \mathbb{R}^d\) 和所有 \(i = 1, \ldots, d\)。
- en: a) Compute the Jacobian \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) for all \(\mathbf{x}\).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: a) 计算所有 \(\mathbf{x}\) 的雅可比矩阵 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\)。
- en: b) When is \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) invertible?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: b) 当 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) 是可逆的时候？
- en: c) When is \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) positive semidefinite? \(\lhd\)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: c) 当 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) 是正半定的时候？\(\lhd\)
- en: '**8.3** Let \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) be a symmetric
    matrix.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.3** 设 \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) 为一个对称矩阵。'
- en: a) Let \(\mathbf{v} = (v_1, \ldots, v_n) \in \mathbb{R}^n\) be an eigenvector
    of \(A\) with eigenvalue \(\lambda\). Let \(v_{i}\) be the largest element of
    \(\mathbf{v}\) in absolute value, that is, \(i \in \arg\max_j |v_j|\). Define
    the vector \(\mathbf{w} = (w_1, \ldots, w_n)\) as
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\mathbf{v} = (v_1, \ldots, v_n) \in \mathbb{R}^n\) 为 \(A\) 的一个特征向量，其特征值为
    \(\lambda\)。设 \(v_{i}\) 为 \(\mathbf{v}\) 中绝对值最大的元素，即 \(i \in \arg\max_j |v_j|\)。定义向量
    \(\mathbf{w} = (w_1, \ldots, w_n)\) 如下
- en: \[ w_j = \frac{v_j}{v_{i}}, \qquad j=1, \ldots, n. \]
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w_j = \frac{v_j}{v_{i}}, \qquad j=1, \ldots, n. \]
- en: Show that
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 证明
- en: \[ \lambda - a_{i,i} = \sum_{j \neq i} a_{i,j} w_j. \]
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda - a_{i,i} = \sum_{j \neq i} a_{i,j} w_j. \]
- en: b) Use (a) to show that, for any eigenvalue \(\lambda\) of \(A\), there is \(i\)
    such that
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使用(a)来证明，对于 \(A\) 的任意特征值 \(\lambda\)，存在 \(i\) 使得
- en: \[ |\lambda - a_{i,i}| \leq \sum_{j \neq i} |a_{i,j}|. \]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |\lambda - a_{i,i}| \leq \sum_{j \neq i} |a_{i,j}|. \]
- en: \(\lhd\)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.4** A symmetric matrix \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times
    n}\) with nonnegative elements on its diagonal is said to be diagonally dominant
    if for all \(i\)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.4** 一个对称矩阵 \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) 如果其对角线上的元素非负，并且对于所有
    \(i\)'
- en: \[ a_{i,i} \geq \sum_{j \neq i} |a_{i,j}|, \]
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: \[ a_{i,i} \geq \sum_{j \neq i} |a_{i,j}|, \]
- en: that is, each diagonal element is greater or equal than the sum of the absolute
    values of the other elements in its row. Use Problem 8.3 to prove that such a
    matrix is positive semidefinite. \(\lhd\)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 即，每个对角元素都大于或等于其行中其他元素的绝对值之和。使用问题8.3来证明这样的矩阵是正半定的。\(\lhd\)
- en: '**8.5** Consider multinomial logistic regression. Let'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.5** 考虑多项式逻辑回归。设'
- en: \[ R = I_{K \times K} \otimes \mathbf{x}^T, \]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[ R = I_{K \times K} \otimes \mathbf{x}^T, \]
- en: and
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ S = \mathrm{diag}\left( \bgamma \left( \mathbf{v} \right) \right) - \bgamma
    \left( \mathbf{v} \right) \, \bgamma \left( \mathbf{v} \right)^T \]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \[ S = \mathrm{diag}\left( \bgamma \left( \mathbf{v} \right) \right) - \bgamma
    \left( \mathbf{v} \right) \, \bgamma \left( \mathbf{v} \right)^T \]
- en: where
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[ \mathbf{v} = \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w}) \right). \]
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v} = \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w}) \right). \]
- en: a) Show that
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明
- en: \[ \nabla f(\mathbf{w}) = \Gamma \left( \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w})
    \right) \right) \]
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{w}) = \Gamma \left( \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w})
    \right) \right) \]
- en: where
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[ \Gamma (\mathbf{u}) = R (\mathbf{u} - \mathbf{y}). \]
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Gamma (\mathbf{u}) = R (\mathbf{u} - \mathbf{y}). \]
- en: b) Use the *Chain Rule* to show that
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使用**链式法则**来证明
- en: \[ H_f (\mathbf{w}) = R^T S R. \]
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: \[ H_f (\mathbf{w}) = R^T S R. \]
- en: c) Use (b) and the *Properties of the Kronecker Product* to show that
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用(b)和**克罗内克积的性质**来证明
- en: \[ H_f (\mathbf{w}) = \left( \mathrm{diag} \left( \bgamma \left( \mathcal{W}
    \mathbf{x} \right) \right) - \bgamma \left( \mathcal{W} \mathbf{x} \right) \,
    \bgamma \left( \mathcal{W} \mathbf{x} \right)^T \right) \otimes \mathbf{x} \mathbf{x}^T.
    \]
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: \[ H_f (\mathbf{w}) = \left( \mathrm{diag} \left( \bgamma \left( \mathcal{W}
    \mathbf{x} \right) \right) - \bgamma \left( \mathcal{W} \mathbf{x} \right) \,
    \bgamma \left( \mathcal{W} \mathbf{x} \right)^T \right) \otimes \mathbf{x} \mathbf{x}^T.
    \]
- en: \(\lhd\)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.6** Consider multinomial logistic regression. Use Problems 8.4 and 8.5
    to show that the objective function is convex. [*Hint:* It is enough to show that
    \(S\) (defined in Problem 8.5) is diagonally dominant. Why?] \(\lhd\)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.6** 考虑多项式逻辑回归。使用问题8.4和8.5来证明目标函数是凸的。[提示：只需证明 \(S\)（在问题8.5中定义）是对角占优的。为什么？]\(\lhd\)'
- en: '**8.7** Prove part a) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.7** 证明**克罗内克积性质引理**的部分a)。\(\lhd\)'
- en: '**8.8** Prove part b) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.8** 证明**克罗内克积性质引理**的部分b)。\(\lhd\)'
- en: '**8.9** Prove parts c) and d) of the *Kronecker Product Properties Lemma*.
    \(\lhd\)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.9** 证明**克罗内克积性质引理**的部分c)和d)。\(\lhd\)'
- en: '**8.10** Prove part e) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.10** 证明**克罗内克积性质引理**的部分e)。\(\lhd\)'
- en: '**8.11** Let \(A\) and \(B\) be symmetric matrices of size \(n \times n\) and
    \(m \times m\) respectively.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.11** 设 \(A\) 和 \(B\) 分别是大小为 \(n \times n\) 和 \(m \times m\) 的对称矩阵。'
- en: a) Show that \(A \otimes B\) is symmetric. [*Hint:* Use Problem 8.10.]
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明 \(A \otimes B\) 是对称的。[提示：使用问题 8.10。]
- en: b) Compute the eigenvectors and eigenvalues of \(A \otimes B\) in terms of the
    eigenvectors and eigenvalues of \(A\) and \(B\). [*Hint:* Try the Kronecker products
    of eigenvectors of \(A\) and \(B\).]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: b) 用 \(A\) 和 \(B\) 的特征向量和特征值来计算 \(A \otimes B\) 的特征向量和特征值。[提示：尝试 \(A\) 和 \(B\)
    的特征向量的克罗内克积。]
- en: c) Recall that the determinant of a symmetric matrix is the product of its eigenvalues.
    Show that
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: c) 回忆一下，对称矩阵的行列式是其特征值的乘积。证明
- en: \[ \mathrm{det}(A \otimes B) = \mathrm{det}(A)^n \,\mathrm{det}(B)^m. \]
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{det}(A \otimes B) = \mathrm{det}(A)^n \,\mathrm{det}(B)^m. \]
- en: \(\lhd\)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.12** Compute \(\mathrm{tr}(A \otimes B)\) in terms of \(\mathrm{tr}(A)\)
    and \(\mathrm{tr}(B)\). Justify your answer. \(\lhd\)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.12** 用 \(\mathrm{tr}(A)\) 和 \(\mathrm{tr}(B)\) 来计算 \(\mathrm{tr}(A \otimes
    B)\)。证明你的答案。 \(\lhd\)'
- en: '**8.13** a) Show that if \(D_1\) and \(D_2\) are square diagonal matrices,
    then so is \(D_1 \otimes D_2\).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.13** a) 证明如果 \(D_1\) 和 \(D_2\) 是方对角矩阵，那么 \(D_1 \otimes D_2\) 也是。 '
- en: b) Show that if \(Q_1\) and \(Q_2\) have orthonormal columns, so does \(Q_1
    \otimes Q_2\). \(\lhd\)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明如果 \(Q_1\) 和 \(Q_2\) 有正交归一列，那么 \(Q_1 \otimes Q_2\) 也是。 \(\lhd\)
- en: '**8.14** Let \(A_1 = U_1 \Sigma_1 V_1^T\) and \(A_2 = U_2 \Sigma_2 V_2^T\)
    be full SVDs of \(A_1, A_2 \in \mathbb{R}^{n \times n}\) respectively.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.14** 设 \(A_1 = U_1 \Sigma_1 V_1^T\) 和 \(A_2 = U_2 \Sigma_2 V_2^T\) 分别是
    \(A_1, A_2 \in \mathbb{R}^{n \times n}\) 的满秩奇异值分解。'
- en: a) Compute a full SVD of \(A_1 \otimes A_2\). [*Hint:* Use Problem 8.13.]
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: a) 计算一个 \(A_1 \otimes A_2\) 的满秩奇异值分解。[提示：使用问题 8.13。]
- en: b) Show that the rank of \(A_1 \otimes A_2\) is \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\).
    \(\lhd\)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明 \(A_1 \otimes A_2\) 的秩是 \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\)。 \(\lhd\)
- en: '**8.15** Let \(P_1\) and \(P_2\) be transition matrices.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.15** 设 \(P_1\) 和 \(P_2\) 是转移矩阵。'
- en: a) Let \(\bpi_1\) and \(\bpi_2\) (as row vectors) be stationary distributions
    of \(P_1\) and \(P_2\) respectively. Show that \(\bpi_1 \otimes \bpi_2\) is a
    stationary distribution of \(P_1 \otimes P_2\).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\bpi_1\) 和 \(\bpi_2\)（作为行向量）分别是 \(P_1\) 和 \(P_2\) 的平稳分布。证明 \(\bpi_1 \otimes
    \bpi_2\) 是 \(P_1 \otimes P_2\) 的平稳分布。
- en: b) Assume that \(P_1\) and \(P_2\) are both irreducible and lazy. Show that
    the same holds for \(P_1 \otimes P_2\). \(\lhd\)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: b) 假设 \(P_1\) 和 \(P_2\) 都是既约的又是懒惰的。证明 \(P_1 \otimes P_2\) 也是这样。 \(\lhd\)
- en: '**8.16** Let \(\mathbf{u}\) be a column vector and \(A, B\) be matrices of
    such size that one can form the matrix product \(AB\).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.16** 设 \(\mathbf{u}\) 为列向量，\(A, B\) 为可以形成矩阵乘积 \(AB\) 的矩阵。'
- en: a) Let \(\mathbf{a}_1^T, \ldots, \mathbf{a}_n^T\) be the rows of \(A\). Prove
    that
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\mathbf{a}_1^T, \ldots, \mathbf{a}_n^T\) 为 \(A\) 的行。证明
- en: \[\begin{split} A \otimes \mathbf{u} = \begin{pmatrix} \mathbf{u} \mathbf{a}_1^T\\
    \vdots\\ \mathbf{u} \mathbf{a}_n^T \end{pmatrix}. \end{split}\]
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A \otimes \mathbf{u} = \begin{pmatrix} \mathbf{u} \mathbf{a}_1^T\\
    \vdots\\ \mathbf{u} \mathbf{a}_n^T \end{pmatrix} \end{split}\]
- en: b) Prove part f) of the *Kronecker Product Properties Lemma*. \(\lhd\)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明**克罗内克积性质引理**的第 f) 部分。 \(\lhd\)
- en: '**8.17** Prove the *Composition of Continuous Functions Lemma*. \(\lhd\)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.17** 证明**连续函数的复合引理**。 \(\lhd\)'
- en: '**8.18** Consider the map \(X \mathbf{z}\) as a function of the entries of
    the matrix \(X \in \mathbb{R}^{n \times m}\). Specifically, for a fixed \(\mathbf{z}
    \in \mathbb{R}^m\), letting \((\mathbf{x}^{(i)})^T\) be the \(i\)-th row of \(X\)
    we define the function'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.18** 考虑映射 \(X \mathbf{z}\) 作为矩阵 \(X \in \mathbb{R}^{n \times m}\) 的元素的函数。具体来说，对于固定的
    \(\mathbf{z} \in \mathbb{R}^m\)，令 \((\mathbf{x}^{(i)})^T\) 为 \(X\) 的第 \(i\) 行，我们定义函数'
- en: \[\begin{split} \mathbf{f}(\mathbf{x}) = X \mathbf{z} = \begin{pmatrix} (\mathbf{x}^{(1)})^T
    \mathbf{z} \\ \vdots\\ (\mathbf{x}^{(n)})^T \mathbf{z} \end{pmatrix} \end{split}\]
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{f}(\mathbf{x}) = X \mathbf{z} = \begin{pmatrix} (\mathbf{x}^{(1)})^T
    \mathbf{z} \\ \vdots\\ (\mathbf{x}^{(n)})^T \mathbf{z} \end{pmatrix} \end{split}\]
- en: where \(\mathbf{x} = \mathrm{vec}(X^T) = (\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)})\).
    Show that \(\mathbf{f}\) is linear in \(\mathbf{x}\), that is, \(\mathbf{f}(\mathbf{x}
    + \mathbf{x}') = \mathbf{f}(\mathbf{x}) + \mathbf{f}(\mathbf{x}')\).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{x} = \mathrm{vec}(X^T) = (\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)})\).
    证明 \(\mathbf{f}\) 在 \(\mathbf{x}\) 上是线性的，即 \(\mathbf{f}(\mathbf{x} + \mathbf{x}')
    = \mathbf{f}(\mathbf{x}) + \mathbf{f}(\mathbf{x}')\).
- en: \(\lhd\)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.19** Let \(f(x_1, x_2) = \sin(x_1^2 + x_2) + \cos(x_1 x_2)\). Compute the
    gradient of \(f\) using the *Chain Rule* by defining appropriate functions \(\mathbf{g}\)
    and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.19** 设 \(f(x_1, x_2) = \sin(x_1^2 + x_2) + \cos(x_1 x_2)\)。通过定义适当的函数 \(\mathbf{g}\)
    和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用 **链式法则** 计算 \(f\) 的梯度。'
- en: \(\lhd\)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.20** Consider the function \(f(x_1, x_2, x_3) = \sqrt{x_1 + x_2^2 + \exp(x_3)}\).
    Find the gradient of \(f\) at the point \((1, 2, 0)\) using the *Chain Rule* by
    defining suitable functions \(\mathbf{g}\) and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.20** 考虑函数 \(f(x_1, x_2, x_3) = \sqrt{x_1 + x_2^2 + \exp(x_3)}\)。通过定义合适的函数
    \(\mathbf{g}\) 和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用 **链式法则** 在点 \((1, 2, 0)\)
    处找到 \(f\) 的梯度。'
- en: \(\lhd\)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.21** Consider the function \(f(x_1, x_2, x_3) = (x_1 + x_2^2)^3 + \sin(x_2
    x_3)\). Find the gradient of \(f\) using the *Chain Rule* by defining suitable
    functions \(\mathbf{g}\) and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.21** 考虑函数 \(f(x_1, x_2, x_3) = (x_1 + x_2^2)^3 + \sin(x_2 x_3)\)。通过定义合适的函数
    \(\mathbf{g}\) 和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用 **链式法则** 计算 \(f\) 的梯度。'
- en: \(\lhd\)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.22** For \(i=1, \ldots, n\), let \(f_i : D_i \to \mathbb{R}\), with \(D_i
    \subseteq \mathbb{R}\), be a continuously differentiable real-valued function
    of a single variable. Consider the vector-valued function \(\mathbf{f} : D_1 \times
    \cdots \times D_n \to \mathbb{R}^n\) defined as'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.22** 对于 \(i=1, \ldots, n\)，设 \(f_i : D_i \to \mathbb{R}\)，其中 \(D_i \subseteq
    \mathbb{R}\)，是关于单变量的连续可微实值函数。考虑定义在 \(D_1 \times \cdots \times D_n\) 上的向量值函数 \(\mathbf{f}
    : D_1 \times \cdots \times D_n \to \mathbb{R}^n\)，如下所示'
- en: \[ \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_n(\mathbf{x})) = (f_1(x_1),
    \ldots, f_n(x_n)). \]
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_n(\mathbf{x})) = (f_1(x_1),
    \ldots, f_n(x_n)). \]
- en: For \(\mathbf{x} = (x_1, \ldots, x_n)\) such that \(x_i\) is an interior point
    of \(D_i\) for all \(i\), compute the Jacobian \(J_{\mathbf{f}}(\mathbf{x})\).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1, \ldots, x_n)\) 满足 \(x_i\) 是 \(D_i\) 的内点对所有 \(i\) 成立，计算
    \(J_{\mathbf{f}}(\mathbf{x})\) 的雅可比矩阵。
- en: \(\lhd\)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.23** Let \(f\) be a real-valued function taking a matrix \(A = (a_{i,j})_{i,j}
    \in \mathbb{R}^{n \times n}\) as an input. Assume \(f\) is continuously differentiable
    in each entry of \(A\). Consider the following matrix derivative'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.23** 设 \(f\) 是一个取矩阵 \(A = (a_{i,j})_{i,j} \in \mathbb{R}^{n \times n}\)
    作为输入的实值函数。假设 \(f\) 在 \(A\) 的每个元素上都是连续可微的。考虑以下矩阵导数'
- en: \[\begin{split} \frac{\partial f(A)}{\partial A} = \begin{pmatrix} \frac{\partial
    f(A)}{\partial a_{1,1}} & \cdots & \frac{\partial f(A)}{\partial a_{1,n}}\\ \vdots
    & \ddots & \vdots\\ \frac{\partial f(A)}{\partial a_{n,1}} & \cdots & \frac{\partial
    f(A)}{\partial a_{n,n}} \end{pmatrix}. \end{split}\]
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \frac{\partial f(A)}{\partial A} = \begin{pmatrix} \frac{\partial
    f(A)}{\partial a_{1,1}} & \cdots & \frac{\partial f(A)}{\partial a_{1,n}}\\ \vdots
    & \ddots & \vdots\\ \frac{\partial f(A)}{\partial a_{n,1}} & \cdots & \frac{\partial
    f(A)}{\partial a_{n,n}} \end{pmatrix}. \end{split}\]
- en: a) Show that, for any \(B \in \mathbb{R}^{n \times n}\),
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明对于任意的 \(B \in \mathbb{R}^{n \times n}\),
- en: \[ \frac{\partial \,\mathrm{tr}(B^T A)}{\partial A} = B. \]
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \,\mathrm{tr}(B^T A)}{\partial A} = B. \]
- en: b) Show that, for any \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\),
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明对于任意的 \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\),
- en: \[ \frac{\partial \,\mathbf{x}^T A \mathbf{y}}{\partial A} = \mathbf{x} \mathbf{y}^T.
    \]
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \,\mathbf{x}^T A \mathbf{y}}{\partial A} = \mathbf{x} \mathbf{y}^T.
    \]
- en: \(\lhd\)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.24** Let \(A = (a_{i,j})_{i \in [n], j \in [m]} \in \mathbb{R}^{n \times
    m}\) and \(B = (b_{i,j})_{i \in [p], j \in [q]} \in \mathbb{R}^{p \times q}\)
    be arbitrary matrices. Their Kronecker product, denoted \(A \otimes B \in \mathbb{R}^{np
    \times mq}\), is the following matrix in block form'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.24** 设 \(A = (a_{i,j})_{i \in [n], j \in [m]} \in \mathbb{R}^{n \times
    m}\) 和 \(B = (b_{i,j})_{i \in [p], j \in [q]} \in \mathbb{R}^{p \times q}\) 是任意矩阵。它们的克罗内克积，记为
    \(A \otimes B \in \mathbb{R}^{np \times mq}\)，是以下分块形式的矩阵'
- en: \[\begin{split} A \otimes B = \begin{pmatrix} a_{1,1} B & \cdots & a_{1,m} B
    \\ \vdots & \ddots & \vdots \\ a_{n,1} B & \cdots & a_{n,m} B \end{pmatrix}. \end{split}\]
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A \otimes B = \begin{pmatrix} a_{1,1} B & \cdots & a_{1,m} B
    \\ \vdots & \ddots & \vdots \\ a_{n,1} B & \cdots & a_{n,m} B \end{pmatrix}. \end{split}\]
- en: 'The Kronecker product satisfies the following properties (which follow from
    block formulas, but which you do not have to prove): 1) if \(A, B, C, D\) are
    matrices of such size that one can form the matrix products \(AC\) and \(BD\),
    then \((A \otimes B)\,(C \otimes D) = (AC) \otimes (BD)\); 2) the transpose of
    \(A \otimes B\) is \((A \otimes B)^T = A^T \otimes B^T\).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 克罗内克积满足以下性质（这些性质由分块公式得出，但不需要证明）：1) 如果 \(A, B, C, D\) 是可以形成矩阵乘积 \(AC\) 和 \(BD\)
    的矩阵，那么 \((A \otimes B)\,(C \otimes D) = (AC) \otimes (BD)\)；2) \(A \otimes B\)
    的转置是 \((A \otimes B)^T = A^T \otimes B^T\).
- en: a) Show that if \(D_1\) and \(D_2\) are square diagonal matrices, then so is
    \(D_1 \otimes D_2\).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明如果 \(D_1\) 和 \(D_2\) 是方对角矩阵，那么 \(D_1 \otimes D_2\) 也是。
- en: b) Show that if \(Q_1\) and \(Q_2\) have orthonormal columns, so does \(Q_1
    \otimes Q_2\).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明如果 \(Q_1\) 和 \(Q_2\) 有正交归一列，那么 \(Q_1 \otimes Q_2\) 也有。
- en: c) Let \(A_1 = U_1 \Sigma_1 V_1^T\) and \(A_2 = U_2 \Sigma_2 V_2^T\) be full
    SVDs of \(A_1, A_2 \in \mathbb{R}^{n \times n}\) respectively. Compute a full
    SVD of \(A_1 \otimes A_2\).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: c) 设 \(A_1 = U_1 \Sigma_1 V_1^T\) 和 \(A_2 = U_2 \Sigma_2 V_2^T\) 分别是 \(A_1,
    A_2 \in \mathbb{R}^{n \times n}\) 的满SVD。计算 \(A_1 \otimes A_2\) 的满SVD。
- en: d) Let \(A_1\) and \(A_2\) be as in c). Show that the rank of \(A_1 \otimes
    A_2\) is \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: d) 设 \(A_1\) 和 \(A_2\) 如c)所述。证明 \(A_1 \otimes A_2\) 的秩为 \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\)。
- en: \(\lhd\)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: 8.6.1\. Warm-up worksheets[#](#warm-up-worksheets "Link to this heading")
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6.1\. 热身练习表[#](#warm-up-worksheets "链接到这个标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在Claude，Gemini和ChatGPT的帮助下)*'
- en: '**Section 8.2**'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**第8.2节**'
- en: '**E8.2.1** Let \(A = \begin{pmatrix} 2 & 1 \\ 0 & -1 \end{pmatrix}\). Compute
    the vectorization \(\text{vec}(A)\).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.1** 设 \(A = \begin{pmatrix} 2 & 1 \\ 0 & -1 \end{pmatrix}\)。计算向量 \(\text{vec}(A)\)。'
- en: '**E8.2.2** Let \(\mathbf{a} = (2, -1, 3)\) and \(\mathbf{b} = (1, 0, -2)\).
    Compute the Hadamard product \(a \odot b\).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.2** 设 \(\mathbf{a} = (2, -1, 3)\) 和 \(\mathbf{b} = (1, 0, -2)\)。计算Hadamard积
    \(a \odot b\)。'
- en: '**E8.2.3** Let \(A = \begin{pmatrix} 1 & 2 \\ -1 & 0 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 3 & -1 \\ 2 & 1 \end{pmatrix}\). Compute the Kronecker product
    \(A \otimes B\).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.3** 设 \(A = \begin{pmatrix} 1 & 2 \\ -1 & 0 \end{pmatrix}\) 和 \(B =
    \begin{pmatrix} 3 & -1 \\ 2 & 1 \end{pmatrix}\)。计算Kronecker积 \(A \otimes B\)。'
- en: '**E8.2.4** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute the Hadamard product
    \(A \odot B\).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.4** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算Hadamard积 \(A \odot B\)。'
- en: '**E8.2.5** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute the Kronecker product
    \(A \otimes B\).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.5** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算Kronecker积 \(A \otimes B\)。'
- en: '**E8.2.6** Let \(\mathbf{f}(x, y) = (x^2y, \sin(xy), e^{x+y})\). Compute the
    Jacobian matrix of \(\mathbf{f}\) at the point \((1, \frac{\pi}{2})\).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.6** 设 \(\mathbf{f}(x, y) = (x^2y, \sin(xy), e^{x+y})\)。计算 \(\mathbf{f}\)
    在点 \((1, \frac{\pi}{2})\) 处的雅可比矩阵。'
- en: '**E8.2.7** Let \(\mathbf{f}(x, y) = (x^2 + y^2, xy)\) and \(\mathbf{g}(u, v)
    = (uv, u + v)\). Compute the Jacobian matrix of the composition \(\mathbf{g} \circ
    \mathbf{f}\) at the point \((1, 2)\).'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.7** 设 \(\mathbf{f}(x, y) = (x^2 + y^2, xy)\) 和 \(\mathbf{g}(u, v) =
    (uv, u + v)\)。计算 \(\mathbf{g} \circ \mathbf{f}\) 在点 \((1, 2)\) 处的雅可比矩阵。'
- en: '**E8.2.8** Let \(\mathbf{a} = (1, 2, 3)\), \(\mathbf{b} = (4, 5, 6)\), and
    \(\mathbf{c} = (7, 8, 9)\). Compute \(\mathbf{a}^T(\mathbf{b} \odot \mathbf{c})\)
    and \(\mathbf{1}^T(\mathbf{a} \odot \mathbf{b} \odot \mathbf{c})\) and verify
    that they are equal.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.8** 设 \(\mathbf{a} = (1, 2, 3)\)，\(\mathbf{b} = (4, 5, 6)\)，和 \(\mathbf{c}
    = (7, 8, 9)\)。计算 \(\mathbf{a}^T(\mathbf{b} \odot \mathbf{c})\) 和 \(\mathbf{1}^T(\mathbf{a}
    \odot \mathbf{b} \odot \mathbf{c})\) 并验证它们相等。'
- en: '**E8.2.9** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix}\). Compute \((A \otimes B)^T\)
    and \(A^T \otimes B^T\) and verify that they are equal.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.9** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(B = \begin{pmatrix}
    5 & 6 \\ 7 & 8 \end{pmatrix}\)。计算 \((A \otimes B)^T\) 和 \(A^T \otimes B^T\) 并验证它们相等。'
- en: '**E8.2.10** Let \(\mathbf{g}(x, y) = (x^2y, x + y)\). Compute the Jacobian
    matrix \(J_{\mathbf{g}}(x, y)\).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.10** 设 \(\mathbf{g}(x, y) = (x^2y, x + y)\)。计算 \(J_{\mathbf{g}}(x, y)\)。'
- en: '**E8.2.11** Let \(f(x, y, z) = x^2 + y^2 + z^2\). Compute the gradient of \(f\)
    at the point \((1, 2, 3)\).'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.11** 设 \(f(x, y, z) = x^2 + y^2 + z^2\)。计算 \(f\) 在点 \((1, 2, 3)\) 处的梯度。'
- en: '**E8.2.12** Let \(f(x) = 2x^3 - x\) and \(g(y) = y^2 + 1\). Compute the Jacobian
    of the composite function \(g \circ f\) at \(x = 1\).'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.12** 设 \(f(x) = 2x^3 - x\) 和 \(g(y) = y^2 + 1\)。计算复合函数 \(g \circ f\)
    在 \(x = 1\) 处的雅可比矩阵。'
- en: '**E8.2.13** Let \(f(x, y) = xy\) and \(\mathbf{g}(x, y) = (x^2, y^2)\). Compute
    the Jacobian matrix of \(f \circ \mathbf{g}\) at the point \((1, 2)\).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.13** 设 \(f(x, y) = xy\) 和 \(\mathbf{g}(x, y) = (x^2, y^2)\)。计算 \(f \circ
    \mathbf{g}\) 在点 \((1, 2)\) 处的雅可比矩阵。'
- en: '**E8.2.14** Let \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) and \(\mathbf{b}
    = \begin{pmatrix} 5 \\ 6 \end{pmatrix}\). Define the function \(\mathbf{f}(\mathbf{x})
    = A \mathbf{x} + \mathbf{b}\). Compute the Jacobian matrix of \(\mathbf{f}\) at
    any point \(\mathbf{x} \in \mathbb{R}^2\).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.14** 设 \(A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\) 和 \(\mathbf{b}
    = \begin{pmatrix} 5 \\ 6 \end{pmatrix}\)。定义函数 \(\mathbf{f}(\mathbf{x}) = A \mathbf{x}
    + \mathbf{b}\)。计算 \(\mathbf{f}\) 在任意点 \(\mathbf{x} \in \mathbb{R}^2\) 处的雅可比矩阵。'
- en: '**E8.2.15** Let \(f(x) = \sin(x)\). Define the function \(\mathbf{g}(x, y,
    z) = (f(x), f(y), f(z))\). Compute the Jacobian matrix of \(\mathbf{g}\) at the
    point \((\frac{\pi}{2}, \frac{\pi}{4}, \frac{\pi}{6})\).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.15** 设 \(f(x) = \sin(x)\)。定义函数 \(\mathbf{g}(x, y, z) = (f(x), f(y),
    f(z))\)。计算 \(\mathbf{g}\) 在点 \((\frac{\pi}{2}, \frac{\pi}{4}, \frac{\pi}{6})\)
    处的雅可比矩阵。'
- en: '**E8.2.16** Use PyTorch to find the gradient of \(f(x) = x^3 - 4x\) at \(x
    = 2\). Provide the PyTorch code and the result.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.2.16** 使用 PyTorch 计算 \(f(x) = x^3 - 4x\) 在 \(x = 2\) 处的梯度。提供 PyTorch 代码和结果。'
- en: '**Section 8.3**'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.3 节**'
- en: '**E8.3.1** Let \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) and \(B
    = \begin{pmatrix} 2 & 1 \\ -1 & 3 \end{pmatrix}\). How many elementary operations
    (additions and multiplications) does it take to compute \(AB\)?'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.1** 设 \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) 和 \(B =
    \begin{pmatrix} 2 & 1 \\ -1 & 3 \end{pmatrix}\)。计算 \(AB\) 需要进行多少次基本运算（加法和乘法）？'
- en: '**E8.3.2** Let \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) and \(\mathbf{v}
    = (2, -1)\). How many elementary operations (additions and multiplications) does
    it take to compute \(A\mathbf{v}\)?'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.2** 设 \(A = \begin{pmatrix} 1 & -1 \\ 0 & 2 \end{pmatrix}\) 和 \(\mathbf{v}
    = (2, -1)\)。计算 \(A\mathbf{v}\) 需要进行多少次基本运算（加法和乘法）？'
- en: '**E8.3.3** Let \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\) where \(\hat{\mathbf{y}}
    = (\hat{y}_1, \hat{y}_2)\). Compute \(J_{\ell}(\hat{\mathbf{y}})\).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.3** 设 \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\) 其中 \(\hat{\mathbf{y}}
    = (\hat{y}_1, \hat{y}_2)\)。计算 \(J_{\ell}(\hat{\mathbf{y}})\)。'
- en: '**E8.3.4** Let \(\mathbf{g}_0(\mathbf{z}_0) = \begin{pmatrix} 1 & 2 \\ -1 &
    0 \end{pmatrix} \mathbf{z}_0\) and \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\).
    Compute \(\nabla f(\mathbf{x})\) where \(f(\mathbf{x}) = \ell(\mathbf{g}_0(\mathbf{x}))\)
    and \(\mathbf{x} = (1, -1)\).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.4** 设 \(\mathbf{g}_0(\mathbf{z}_0) = \begin{pmatrix} 1 & 2 \\ -1 & 0
    \end{pmatrix} \mathbf{z}_0\) 和 \(\ell(\hat{\mathbf{y}}) = \|\hat{\mathbf{y}}\|^2\)。计算
    \(f(\mathbf{x}) = \ell(\mathbf{g}_0(\mathbf{x}))\) 和 \(\mathbf{x} = (1, -1)\)
    时的 \(\nabla f(\mathbf{x})\)。'
- en: '**E8.3.5** Let \(\mathbf{g}_0\) and \(\ell\) be as in E8.3.4\. Let \(\mathbf{g}_1(\mathbf{z}_1)
    = \begin{pmatrix} -1 & 0 \\ 1 & 1 \end{pmatrix} \mathbf{z}_1\). Compute \(\nabla
    f(\mathbf{x})\) where \(f(\mathbf{x}) = \ell(\mathbf{g}_1(\mathbf{g}_0(\mathbf{x})))\)
    and \(\mathbf{x} = (1, -1)\) using the reverse mode.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.5** 设 \(\mathbf{g}_0\) 和 \(\ell\) 如 E8.3.4 所述。设 \(\mathbf{g}_1(\mathbf{z}_1)
    = \begin{pmatrix} -1 & 0 \\ 1 & 1 \end{pmatrix} \mathbf{z}_1\)。使用逆模式计算 \(f(\mathbf{x})
    = \ell(\mathbf{g}_1(\mathbf{g}_0(\mathbf{x})))\) 和 \(\mathbf{x} = (1, -1)\) 时的
    \(\nabla f(\mathbf{x})\)。'
- en: '**E8.3.6** Let \(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0) = \mathcal{W}_0 \mathbf{x}\)
    where \(\mathcal{W}_0 = \begin{pmatrix} w_0 & w_1 \\ w_2 & w_3 \end{pmatrix}\)
    and \(\mathbf{w}_0 = (w_0, w_1, w_2, w_3)\). Let \(\mathbf{x} = (-1, 1)\) be fixed.
    Compute the Jacobian \(J_{\mathbf{g}_0}(\mathbf{x}, \mathbf{w}_0)\) with respect
    to \(\mathbf{w}_0\) only by directly computing the necessary partial derivatives
    (i.e., without using the formulas in the text), and then compare to the formulas
    in the text.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.6** 设 \(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0) = \mathcal{W}_0 \mathbf{x}\)
    其中 \(\mathcal{W}_0 = \begin{pmatrix} w_0 & w_1 \\ w_2 & w_3 \end{pmatrix}\) 和
    \(\mathbf{w}_0 = (w_0, w_1, w_2, w_3)\)。设 \(\mathbf{x} = (-1, 1)\) 为固定点。仅通过直接计算必要的偏导数（即不使用文本中的公式），计算
    \(\mathbf{g}_0\) 关于 \(\mathbf{w}_0\) 的雅可比 \(J_{\mathbf{g}_0}(\mathbf{x}, \mathbf{w}_0)\)，然后与文本中的公式进行比较。'
- en: '**E8.3.7** Let \(g_1(\mathbf{z}_1, \mathbf{w}_1) = \mathcal{W}_1 \mathbf{z}_1\)
    where \(\mathcal{W}_1 = \begin{pmatrix} w_4 & w_5\end{pmatrix}\) and \(\mathbf{w}_1
    = (w_4, w_5)\). Compute \(J_{g_1}(\mathbf{z}_1, \mathbf{w}_1)\) with respect to
    both \(\mathbf{z}_1\) and \(\mathbf{w}_1\) by directly computing the necessary
    partial derivatives (i.e., without using the formulas in the text), and then compare
    to the formulas in the text.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.7** 设 \(g_1(\mathbf{z}_1, \mathbf{w}_1) = \mathcal{W}_1 \mathbf{z}_1\)
    其中 \(\mathcal{W}_1 = \begin{pmatrix} w_4 & w_5\end{pmatrix}\) 和 \(\mathbf{w}_1
    = (w_4, w_5)\)。通过直接计算必要的偏导数（即不使用文本中的公式），计算 \(J_{g_1}(\mathbf{z}_1, \mathbf{w}_1)\)
    关于 \(\mathbf{z}_1\) 和 \(\mathbf{w}_1\) 的雅可比，然后与文本中的公式进行比较。'
- en: '**E8.3.8** Let \(h(\mathbf{w}) = g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1)\) where \(\mathbf{g}_0\) and \(g_1\) are as in E8.3.6 and E8.3.7
    and \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1, w_2, w_3, w_4, w_5)\).
    Let \(\mathbf{x} = (-1, 1)\) be fixed. Compute \(J_h(\mathbf{w})\) by directly
    computing the necessary partial derivatives (i.e., without using the formulas
    in the text).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.8** 设 \(h(\mathbf{w}) = g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1)\)，其中 \(\mathbf{g}_0\) 和 \(g_1\) 如 E8.3.6 和 E8.3.7 所述，且 \(\mathbf{w}
    = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1, w_2, w_3, w_4, w_5)\)。设 \(\mathbf{x}
    = (-1, 1)\) 为固定值。通过直接计算必要的偏导数（即，不使用文本中的公式）来计算 \(J_h(\mathbf{w})\)。'
- en: '**E8.3.9** Let \(f(\mathbf{w}) = \ell(g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1))\) where \(\ell(\hat{y}) = \hat{y}^2\), \(\mathbf{g}_0\) and \(g_1\)
    are as in E8.3.6 and E8.3.7, and \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) =
    (w_0, w_1, w_2, w_3, w_4, w_5)\). Let \(\mathbf{x} = (-1, 1)\) be fixed. Compute
    \(J_f(\mathbf{w})\) by directly computing the necessary partial derivatives (i.e.,
    without using the formulas in the text), and then compare to the formulas in the
    text.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.3.9** 设 \(f(\mathbf{w}) = \ell(g_1(\mathbf{g}_0(\mathbf{x}, \mathbf{w}_0),
    \mathbf{w}_1))\)，其中 \(\ell(\hat{y}) = \hat{y}^2\)，\(\mathbf{g}_0\) 和 \(g_1\) 如
    E8.3.6 和 E8.3.7 所述，且 \(\mathbf{w} = (\mathbf{w}_0, \mathbf{w}_1) = (w_0, w_1,
    w_2, w_3, w_4, w_5)\)。设 \(\mathbf{x} = (-1, 1)\) 为固定值。通过直接计算必要的偏导数（即，不使用文本中的公式）来计算
    \(J_f(\mathbf{w})\)，然后与文本中的公式进行比较。'
- en: '**Section 8.4**'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.4 节**'
- en: '**E8.4.1** Given a dataset with 5 samples, compute the full gradient descent
    step and the expected SGD step with a batch size of 2\. Assume that the individual
    sample gradients are: \(\nabla f_{\mathbf{x}_1, y_1}(\mathbf{w}) = (1, 2)\), \(\nabla
    f_{\mathbf{x}_2, y_2}(\mathbf{w}) = (-1, 1)\), \(\nabla f_{\mathbf{x}_3, y_3}(\mathbf{w})
    = (0, -1)\), \(\nabla f_{\mathbf{x}_4, y_4}(\mathbf{w}) = (2, 0)\), and \(\nabla
    f_{\mathbf{x}_5, y_5}(\mathbf{w}) = (1, 1)\).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.1** 给定一个包含 5 个样本的数据集，计算全梯度下降步骤和批大小为 2 的期望随机梯度下降步骤。假设单个样本的梯度为：\(\nabla
    f_{\mathbf{x}_1, y_1}(\mathbf{w}) = (1, 2)\)，\(\nabla f_{\mathbf{x}_2, y_2}(\mathbf{w})
    = (-1, 1)\)，\(\nabla f_{\mathbf{x}_3, y_3}(\mathbf{w}) = (0, -1)\)，\(\nabla f_{\mathbf{x}_4,
    y_4}(\mathbf{w}) = (2, 0)\)，和 \(\nabla f_{\mathbf{x}_5, y_5}(\mathbf{w}) = (1,
    1)\)。'
- en: '**E8.4.2** Compute the softmax function \(\boldsymbol{\gamma}(\mathbf{z})\)
    for \(\mathbf{z} = (1, -2, 0, 3)\).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.2** 计算 \(\mathbf{z} = (1, -2, 0, 3)\) 的 softmax 函数 \(\boldsymbol{\gamma}(\mathbf{z})\)。'
- en: '**E8.4.3** Compute the Kullback-Leibler divergence between the probability
    distributions \(\mathbf{p} = (0.2, 0.3, 0.5)\) and \(\mathbf{q} = (0.1, 0.4, 0.5)\).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.3** 计算概率分布 \(\mathbf{p} = (0.2, 0.3, 0.5)\) 和 \(\mathbf{q} = (0.1, 0.4,
    0.5)\) 之间的 Kullback-Leibler 散度。'
- en: '**E8.4.4** In linear regression with a single feature, the loss function for
    a single sample \((x, y)\) is given by'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.4** 在具有单个特征的线性回归中，单个样本 \((x, y)\) 的损失函数由下式给出'
- en: \[ \ell(w, b; x, y) = (wx + b - y)^2. \]
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \ell(w, b; x, y) = (wx + b - y)^2. \]
- en: Compute the gradients \(\frac{\partial \ell}{\partial w}\) and \(\frac{\partial
    \ell}{\partial b}\).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度 \(\frac{\partial \ell}{\partial w}\) 和 \(\frac{\partial \ell}{\partial
    b}\)。
- en: '**E8.4.5** Suppose we have a dataset with three samples: \((x_1, y_1) = (2,
    3)\), \((x_2, y_2) = (-1, 0)\), and \((x_3, y_3) = (1, 2)\). We want to perform
    mini-batch SGD for linear regression with a batch size of 2\. If the first mini-batch
    randomly selected is \(B = \{1, 3\}\), compute the SGD update for the parameters
    \(w\) and \(b\), assuming a learning rate of \(\alpha = 0.1\). The model is initialized
    at \(w = 1\) and \(b = 0\).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.5** 假设我们有一个包含三个样本的数据集：\((x_1, y_1) = (2, 3)\)，\((x_2, y_2) = (-1, 0)\)，和
    \((x_3, y_3) = (1, 2)\)。我们想要对线性回归进行小批量随机梯度下降，批大小为 2。如果第一个随机选择的小批量是 \(B = \{1,
    3\}\)，假设学习率为 \(\alpha = 0.1\)，计算参数 \(w\) 和 \(b\) 的 SGD 更新。模型初始化为 \(w = 1\) 和 \(b
    = 0\)。'
- en: '**E8.4.6** For the linear regression problem with a single sample \((\mathbf{x},
    y) = ((1, 2), 3)\), compute the gradient of the loss function \(f(\mathbf{w})
    = (\mathbf{x}^T \mathbf{w} - y)^2\) at \(\mathbf{w} = (0, 0)\).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.6** 对于单个样本 \((\mathbf{x}, y) = ((1, 2), 3)\) 的线性回归问题，计算损失函数 \(f(\mathbf{w})
    = (\mathbf{x}^T \mathbf{w} - y)^2\) 在 \(\mathbf{w} = (0, 0)\) 处的梯度。'
- en: '**E8.4.7** Consider the logistic regression loss function for a single sample
    \((x, y)\) where \(x \in \mathbb{R}\) and \(y \in \{0, 1\}\):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.7** 考虑单个样本 \((x, y)\) 的逻辑回归损失函数，其中 \(x \in \mathbb{R}\) 且 \(y \in \{0,
    1\}\)：'
- en: \[ \ell(w; x, y) = -y \log(\sigma(wx)) - (1-y) \log(1 - \sigma(wx)), \]
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \ell(w; x, y) = -y \log(\sigma(wx)) - (1-y) \log(1 - \sigma(wx)), \]
- en: where \(\sigma(z) = \frac{1}{1 + e^{-z}}\) is the sigmoid function. Compute
    the gradient \(\nabla \ell(w; x, y)\) with respect to \(w\).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\sigma(z) = \frac{1}{1 + e^{-z}}\) 是 sigmoid 函数。计算关于 \(w\) 的梯度 \(\nabla
    \ell(w; x, y)\)。
- en: '**E8.4.8** Consider a multinomial logistic regression problem with three classes
    (\(K = 3\)). Given an input vector \(\mathbf{x} = (1, -1)\), and a weight matrix'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.8** 考虑一个有三个类别 (\(K = 3\)) 的多项式逻辑回归问题。给定输入向量 \(\mathbf{x} = (1, -1)\)
    和权重矩阵'
- en: \[\begin{split} W = \begin{pmatrix} 1 & 2 \\ -1 & 0 \\ 0 & 1 \end{pmatrix},
    \end{split}\]
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} W = \begin{pmatrix} 1 & 2 \\ -1 & 0 \\ 0 & 1 \end{pmatrix},
    \end{split}\]
- en: compute the softmax output \(\boldsymbol{\gamma}(W\mathbf{x})\).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 \(\boldsymbol{\gamma}(W\mathbf{x})\) 的 softmax 输出。
- en: '**E8.4.9** For the multinomial logistic regression problem with a single sample
    \((\mathbf{x}, \mathbf{y}) = ((1, 2), (0, 0, 1))\) and \(K = 3\) classes, compute
    the gradient of the loss function \(f(\mathbf{w}) = -\sum_{i=1}^K y_i \log \gamma_i(W\mathbf{x})\)
    at \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.9** 对于具有单个样本 \((\mathbf{x}, \mathbf{y}) = ((1, 2), (0, 0, 1))\) 和 \(K
    = 3\) 个类别的多项式逻辑回归问题，计算损失函数 \(f(\mathbf{w}) = -\sum_{i=1}^K y_i \log \gamma_i(W\mathbf{x})\)
    在 \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\) 处的梯度。'
- en: '**E8.4.10** For the linear regression problem with two samples \((\mathbf{x}_1,
    y_1) = ((1, 2), 3)\) and \((\mathbf{x}_2, y_2) = ((4, -1), 2)\), compute the full
    gradient at \(\mathbf{w} = (0, 0)\).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.10** 对于具有两个样本 \((\mathbf{x}_1, y_1) = ((1, 2), 3)\) 和 \((\mathbf{x}_2,
    y_2) = ((4, -1), 2)\) 的线性回归问题，计算 \(\mathbf{w} = (0, 0)\) 时的完整梯度。'
- en: '**E8.4.11** For the multinomial logistic regression problem with two samples
    \((\mathbf{x}_1, \mathbf{y}_1) = ((1, 2), (0, 0, 1))\) and \((\mathbf{x}_2, \mathbf{y}_2)
    = ((4, -1), (1, 0, 0))\), and \(K = 3\) classes, compute the full gradient at
    \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.11** 对于具有两个样本 \((\mathbf{x}_1, \mathbf{y}_1) = ((1, 2), (0, 0, 1))\)
    和 \((\mathbf{x}_2, \mathbf{y}_2) = ((4, -1), (1, 0, 0))\) 的多项式逻辑回归问题，以及 \(K =
    3\) 个类别，计算 \(W = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix}\) 时的完整梯度。'
- en: '**E8.4.12** In a binary classification problem, the logistic regression model
    predicts probabilities of 0.8 and 0.3 for two samples. If the true labels for
    these samples are 1 and 0, respectively, compute the average cross-entropy loss.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.12** 在一个二元分类问题中，逻辑回归模型预测了两个样本的概率为 0.8 和 0.3。如果这些样本的真实标签分别是 1 和 0，计算平均交叉熵损失。'
- en: '**E8.4.13** In a multi-class classification problem with four classes, a model
    predicts the following probability distribution for a sample: \((0.1, 0.2, 0.3,
    0.4)\). If the true label is the third class, what is the cross-entropy loss for
    this sample?'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.4.13** 在一个有四个类别的多类别分类问题中，一个模型预测了一个样本的概率分布：\((0.1, 0.2, 0.3, 0.4)\)。如果真实标签是第三个类别，那么这个样本的交叉熵损失是多少？'
- en: '**Section 8.5**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.5 节**'
- en: '**E8.5.1** Compute the sigmoid function \(\sigma(t)\) for the following values
    of \(t\): \(1, -1, 2\).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.1** 计算以下 \(t\) 值的 sigmoid 函数 \(\sigma(t)\)：\(1, -1, 2\).'
- en: '**E8.5.2** Compute the derivative of the sigmoid function \(\sigma''(t)\) for
    the following values of \(t\): \(1, -1, 2\).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.2** 计算以下 \(t\) 值的 sigmoid 函数的导数 \(\sigma''(t)\)：\(1, -1, 2\).'
- en: '**E8.5.3** Given the vector \(\mathbf{z} = (1, -1, 2)\), compute \(\bsigma(\mathbf{z})\)
    and \(\bsigma''(\mathbf{z})\).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.3** 给定向量 \(\mathbf{z} = (1, -1, 2)\)，计算 \(\bsigma(\mathbf{z})\) 和 \(\bsigma''(\mathbf{z})\).'
- en: '**E8.5.4** Given the matrix \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\)
    and the vector \(\mathbf{x} = (1, 2)\), compute \(\bsigma(W\mathbf{x})\).'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.4** 给定矩阵 \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\) 和向量 \(\mathbf{x}
    = (1, 2)\)，计算 \(\bsigma(W\mathbf{x})\).'
- en: '**E8.5.5** Given the matrix \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\)
    and the vector \(\mathbf{x} = (1, 2)\), compute the Jacobian matrix of \(\bsigma(W\mathbf{x})\).'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.5** 给定矩阵 \(W = \begin{pmatrix} 1 & -1 \\ 2 & 0 \end{pmatrix}\) 和向量 \(\mathbf{x}
    = (1, 2)\)，计算 \(\bsigma(W\mathbf{x})\) 的雅可比矩阵。'
- en: '**E8.5.6** Given the vectors \(\mathbf{y} = (0, 1)\) and \(\mathbf{z} = (0.3,
    0.7)\), compute the cross-entropy loss \(H(\mathbf{y}, \mathbf{z})\).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.6** 给定向量 \(\mathbf{y} = (0, 1)\) 和 \(\mathbf{z} = (0.3, 0.7)\)，计算交叉熵损失
    \(H(\mathbf{y}, \mathbf{z})\).'
- en: '**E8.5.7** Given the vectors \(\mathbf{y} = (0, 1)\) and \(\mathbf{z} = (0.3,
    0.7)\), compute the gradient of the cross-entropy loss \(\nabla H(\mathbf{y},
    \mathbf{z})\).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.7** 给定向量 \(\mathbf{y} = (0, 1)\) 和 \(\mathbf{z} = (0.3, 0.7)\)，计算交叉熵损失
    \(\nabla H(\mathbf{y}, \mathbf{z})\) 的梯度。'
- en: '**E8.5.8** Given the vectors \(\mathbf{w} = (1, 2, -1, 0)\) and \(\mathbf{z}
    = (1, 2)\), compute \(\mathbb{A}_2[\mathbf{w}]\) and \(\mathbb{B}_2[\mathbf{z}]\).'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**E8.5.8** 给定向量 \(\mathbf{w} = (1, 2, -1, 0)\) 和 \(\mathbf{z} = (1, 2)\)，计算
    \(\mathbb{A}_2[\mathbf{w}]\) 和 \(\mathbb{B}_2[\mathbf{z}]\)。'
- en: 8.6.2\. Problems[#](#problems "Link to this heading")
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6.2\. 问题[#](#problems "链接到这个标题")
- en: '**8.1** Consider the affine map'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 8.1 节** 考虑仿射映射'
- en: \[ \mathbf{f}(\mathbf{x}) = A \mathbf{x} + \mathbf{b}, \]
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{f}(\mathbf{x}) = A \mathbf{x} + \mathbf{b}, \]
- en: 'where \(A \in \mathbb{R}^{m \times d}\) and \(\mathbf{b} = (b_1, \ldots, b_m)
    \in \mathbb{R}^m\). Let \(S \subseteq \mathbb{R}^m\) be a convex set. Show that
    the following set is convex:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(A \in \mathbb{R}^{m \times d}\) 且 \(\mathbf{b} = (b_1, \ldots, b_m) \in
    \mathbb{R}^m\)。设 \(S \subseteq \mathbb{R}^m\) 是一个凸集。证明以下集合是凸的：
- en: \[ T = \left\{ \mathbf{x} \in \mathbb{R}^d \,:\, \mathbf{f}(\mathbf{x}) \in
    S \right\}. \]
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: \[ T = \left\{ \mathbf{x} \in \mathbb{R}^d \,:\, \mathbf{f}(\mathbf{x}) \in
    S \right\}. \]
- en: \(\lhd\)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.2** (Adapted from [Khu]) Consider the vector-valued function \(\mathbf{f}
    = (f_1, \ldots, f_d) : \mathbb{R}^d \to \mathbb{R}^d\) defined as'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.2** （改编自 [Khu]）考虑向量值函数 \(\mathbf{f} = (f_1, \ldots, f_d) : \mathbb{R}^d
    \to \mathbb{R}^d\)，定义为'
- en: \[ f_i(\mathbf{x}) = x_i^3, \]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: \[ f_i(\mathbf{x}) = x_i^3, \]
- en: for all \(\mathbf{x} \in \mathbb{R}^d\) and all \(i = 1, \ldots, d\).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(\mathbf{x} \in \mathbb{R}^d\) 和所有 \(i = 1, \ldots, d\)。
- en: a) Compute the Jacobian \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) for all \(\mathbf{x}\).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: a) 计算所有 \(\mathbf{x}\) 的雅可比矩阵 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\)。
- en: b) When is \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) invertible?
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: b) 当 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) 是可逆的吗？
- en: c) When is \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) positive semidefinite? \(\lhd\)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: c) 当 \(\mathbf{J}_\mathbf{f}(\mathbf{x})\) 是正定半定吗？\(\lhd\)
- en: '**8.3** Let \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) be a symmetric
    matrix.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.3** 设 \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) 是一个对称矩阵。'
- en: a) Let \(\mathbf{v} = (v_1, \ldots, v_n) \in \mathbb{R}^n\) be an eigenvector
    of \(A\) with eigenvalue \(\lambda\). Let \(v_{i}\) be the largest element of
    \(\mathbf{v}\) in absolute value, that is, \(i \in \arg\max_j |v_j|\). Define
    the vector \(\mathbf{w} = (w_1, \ldots, w_n)\) as
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\mathbf{v} = (v_1, \ldots, v_n) \in \mathbb{R}^n\) 是 \(A\) 的一个特征向量，其特征值为
    \(\lambda\)。设 \(v_{i}\) 是 \(\mathbf{v}\) 中绝对值最大的元素，即 \(i \in \arg\max_j |v_j|\)。定义向量
    \(\mathbf{w} = (w_1, \ldots, w_n)\) 如下
- en: \[ w_j = \frac{v_j}{v_{i}}, \qquad j=1, \ldots, n. \]
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: \[ w_j = \frac{v_j}{v_{i}}, \qquad j=1, \ldots, n. \]
- en: Show that
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 证明
- en: \[ \lambda - a_{i,i} = \sum_{j \neq i} a_{i,j} w_j. \]
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \lambda - a_{i,i} = \sum_{j \neq i} a_{i,j} w_j. \]
- en: b) Use (a) to show that, for any eigenvalue \(\lambda\) of \(A\), there is \(i\)
    such that
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使用 (a) 来证明，对于 \(A\) 的任何特征值 \(\lambda\)，存在 \(i\) 使得
- en: \[ |\lambda - a_{i,i}| \leq \sum_{j \neq i} |a_{i,j}|. \]
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: \[ |\lambda - a_{i,i}| \leq \sum_{j \neq i} |a_{i,j}|. \]
- en: \(\lhd\)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.4** A symmetric matrix \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times
    n}\) with nonnegative elements on its diagonal is said to be diagonally dominant
    if for all \(i\)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.4** 一个对称矩阵 \(A = (a_{i,j})_{i,j=1}^n \in \mathbb{R}^{n \times n}\) 如果其对角线上的元素非负，并且对于所有
    \(i\)'
- en: \[ a_{i,i} \geq \sum_{j \neq i} |a_{i,j}|, \]
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: \[ a_{i,i} \geq \sum_{j \neq i} |a_{i,j}|, \]
- en: that is, each diagonal element is greater or equal than the sum of the absolute
    values of the other elements in its row. Use Problem 8.3 to prove that such a
    matrix is positive semidefinite. \(\lhd\)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 即，每个对角元素都大于或等于其行中其他元素的绝对值之和。使用问题 8.3 来证明这样的矩阵是正定半定的。\(\lhd\)
- en: '**8.5** Consider multinomial logistic regression. Let'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.5** 考虑多项式逻辑回归。设'
- en: \[ R = I_{K \times K} \otimes \mathbf{x}^T, \]
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: \[ R = I_{K \times K} \otimes \mathbf{x}^T, \]
- en: and
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[ S = \mathrm{diag}\left( \bgamma \left( \mathbf{v} \right) \right) - \bgamma
    \left( \mathbf{v} \right) \, \bgamma \left( \mathbf{v} \right)^T \]
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: \[ S = \mathrm{diag}\left( \bgamma \left( \mathbf{v} \right) \right) - \bgamma
    \left( \mathbf{v} \right) \, \bgamma \left( \mathbf{v} \right)^T \]
- en: where
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[ \mathbf{v} = \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w}) \right). \]
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{v} = \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w}) \right). \]
- en: a) Show that
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明
- en: \[ \nabla f(\mathbf{w}) = \Gamma \left( \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w})
    \right) \right) \]
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(\mathbf{w}) = \Gamma \left( \bgamma \left( \bfg_0 (\mathbf{x}, \mathbf{w})
    \right) \right) \]
- en: where
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: \[ \Gamma (\mathbf{u}) = R (\mathbf{u} - \mathbf{y}). \]
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \Gamma (\mathbf{u}) = R (\mathbf{u} - \mathbf{y}). \]
- en: b) Use the *Chain Rule* to show that
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: b) 使用 **链式法则** 来证明
- en: \[ H_f (\mathbf{w}) = R^T S R. \]
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \[ H_f (\mathbf{w}) = R^T S R. \]
- en: c) Use (b) and the *Properties of the Kronecker Product* to show that
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用 (b) 和 **克罗内克积的性质** 来证明
- en: \[ H_f (\mathbf{w}) = \left( \mathrm{diag} \left( \bgamma \left( \mathcal{W}
    \mathbf{x} \right) \right) - \bgamma \left( \mathcal{W} \mathbf{x} \right) \,
    \bgamma \left( \mathcal{W} \mathbf{x} \right)^T \right) \otimes \mathbf{x} \mathbf{x}^T.
    \]
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: \[ H_f (\mathbf{w}) = \left( \mathrm{diag} \left( \bgamma \left( \mathcal{W}
    \mathbf{x} \right) \right) - \bgamma \left( \mathcal{W} \mathbf{x} \right) \,
    \bgamma \left( \mathcal{W} \mathbf{x} \right)^T \right) \otimes \mathbf{x} \mathbf{x}^T.
    \]
- en: \(\lhd\)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.6** Consider multinomial logistic regression. Use Problems 8.4 and 8.5
    to show that the objective function is convex. [*Hint:* It is enough to show that
    \(S\) (defined in Problem 8.5) is diagonally dominant. Why?] \(\lhd\)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.6** 考虑多项式逻辑回归。使用问题 8.4 和 8.5 来证明目标函数是凸的。[提示：只需证明 \(S\)（在问题 8.5 中定义）是对角占优的。为什么？]\(\lhd\)'
- en: '**8.7** Prove part a) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.7** 证明 *克罗内克积性质引理* 的部分 a)。\(\lhd\)'
- en: '**8.8** Prove part b) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.8** 证明 *克罗内克积性质引理* 的部分 b)。\(\lhd\)'
- en: '**8.9** Prove parts c) and d) of the *Kronecker Product Properties Lemma*.
    \(\lhd\)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.9** 证明 *克罗内克积性质引理* 的部分 c) 和 d)。\(\lhd\)'
- en: '**8.10** Prove part e) of the *Kronecker Product Properties Lemma*. \(\lhd\)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.10** 证明 *克罗内克积性质引理* 的部分 e)。\(\lhd\)'
- en: '**8.11** Let \(A\) and \(B\) be symmetric matrices of size \(n \times n\) and
    \(m \times m\) respectively.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.11** 设 \(A\) 和 \(B\) 分别是大小为 \(n \times n\) 和 \(m \times m\) 的对称矩阵。'
- en: a) Show that \(A \otimes B\) is symmetric. [*Hint:* Use Problem 8.10.]
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明 \(A \otimes B\) 是对称的。[提示：使用问题 8.10。]\(\lhd\)
- en: b) Compute the eigenvectors and eigenvalues of \(A \otimes B\) in terms of the
    eigenvectors and eigenvalues of \(A\) and \(B\). [*Hint:* Try the Kronecker products
    of eigenvectors of \(A\) and \(B\).]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: b) 用 \(A\) 和 \(B\) 的特征向量与特征值表示 \(A \otimes B\) 的特征向量与特征值。[提示：尝试 \(A\) 和 \(B\)
    的特征向量的克罗内克积。]
- en: c) Recall that the determinant of a symmetric matrix is the product of its eigenvalues.
    Show that
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: c) 回忆对称矩阵的行列式是其特征值的乘积。证明 \(\lhd\)
- en: \[ \mathrm{det}(A \otimes B) = \mathrm{det}(A)^n \,\mathrm{det}(B)^m. \]
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathrm{det}(A \otimes B) = \mathrm{det}(A)^n \,\mathrm{det}(B)^m. \]
- en: \(\lhd\)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.12** Compute \(\mathrm{tr}(A \otimes B)\) in terms of \(\mathrm{tr}(A)\)
    and \(\mathrm{tr}(B)\). Justify your answer. \(\lhd\)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.12** 用 \(\mathrm{tr}(A)\) 和 \(\mathrm{tr}(B)\) 表示 \(\mathrm{tr}(A \otimes
    B)\)。证明你的答案。 \(\lhd\)'
- en: '**8.13** a) Show that if \(D_1\) and \(D_2\) are square diagonal matrices,
    then so is \(D_1 \otimes D_2\).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.13** a) 证明如果 \(D_1\) 和 \(D_2\) 是方对角矩阵，那么 \(D_1 \otimes D_2\) 也是。\(\lhd\)'
- en: b) Show that if \(Q_1\) and \(Q_2\) have orthonormal columns, so does \(Q_1
    \otimes Q_2\). \(\lhd\)
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明如果 \(Q_1\) 和 \(Q_2\) 有正交列，那么 \(Q_1 \otimes Q_2\) 也有正交列。\(\lhd\)
- en: '**8.14** Let \(A_1 = U_1 \Sigma_1 V_1^T\) and \(A_2 = U_2 \Sigma_2 V_2^T\)
    be full SVDs of \(A_1, A_2 \in \mathbb{R}^{n \times n}\) respectively.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.14** 设 \(A_1 = U_1 \Sigma_1 V_1^T\) 和 \(A_2 = U_2 \Sigma_2 V_2^T\) 分别是
    \(A_1, A_2 \in \mathbb{R}^{n \times n}\) 的全奇异值分解。'
- en: a) Compute a full SVD of \(A_1 \otimes A_2\). [*Hint:* Use Problem 8.13.]
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: a) 计算 \(A_1 \otimes A_2\) 的完全奇异值分解。[提示：使用问题 8.13。]
- en: b) Show that the rank of \(A_1 \otimes A_2\) is \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\).
    \(\lhd\)
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明 \(A_1 \otimes A_2\) 的秩是 \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\)。\(\lhd\)
- en: '**8.15** Let \(P_1\) and \(P_2\) be transition matrices.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.15** 设 \(P_1\) 和 \(P_2\) 是转移矩阵。'
- en: a) Let \(\bpi_1\) and \(\bpi_2\) (as row vectors) be stationary distributions
    of \(P_1\) and \(P_2\) respectively. Show that \(\bpi_1 \otimes \bpi_2\) is a
    stationary distribution of \(P_1 \otimes P_2\).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\bpi_1\) 和 \(\bpi_2\)（作为行向量）分别是 \(P_1\) 和 \(P_2\) 的平稳分布。证明 \(\bpi_1 \otimes
    \bpi_2\) 是 \(P_1 \otimes P_2\) 的平稳分布。
- en: b) Assume that \(P_1\) and \(P_2\) are both irreducible and lazy. Show that
    the same holds for \(P_1 \otimes P_2\). \(\lhd\)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: b) 假设 \(P_1\) 和 \(P_2\) 都是不可约的且懒惰的。证明 \(P_1 \otimes P_2\) 也是这样。\(\lhd\)
- en: '**8.16** Let \(\mathbf{u}\) be a column vector and \(A, B\) be matrices of
    such size that one can form the matrix product \(AB\).'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.16** 设 \(\mathbf{u}\) 是一个列向量，\(A, B\) 是可以形成矩阵乘积 \(AB\) 的矩阵。'
- en: a) Let \(\mathbf{a}_1^T, \ldots, \mathbf{a}_n^T\) be the rows of \(A\). Prove
    that
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: a) 设 \(\mathbf{a}_1^T, \ldots, \mathbf{a}_n^T\) 是 \(A\) 的行。\(\lhd\)
- en: \[\begin{split} A \otimes \mathbf{u} = \begin{pmatrix} \mathbf{u} \mathbf{a}_1^T\\
    \vdots\\ \mathbf{u} \mathbf{a}_n^T \end{pmatrix}. \end{split}\]
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A \otimes \mathbf{u} = \begin{pmatrix} \mathbf{u} \mathbf{a}_1^T\\
    \vdots\\ \mathbf{u} \mathbf{a}_n^T \end{pmatrix}. \end{split}\]
- en: b) Prove part f) of the *Kronecker Product Properties Lemma*. \(\lhd\)
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明 *克罗内克积性质引理* 的部分 f)。\(\lhd\)
- en: '**8.17** Prove the *Composition of Continuous Functions Lemma*. \(\lhd\)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.17** 证明 *连续函数的复合引理*。\(\lhd\)'
- en: '**8.18** Consider the map \(X \mathbf{z}\) as a function of the entries of
    the matrix \(X \in \mathbb{R}^{n \times m}\). Specifically, for a fixed \(\mathbf{z}
    \in \mathbb{R}^m\), letting \((\mathbf{x}^{(i)})^T\) be the \(i\)-th row of \(X\)
    we define the function'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.18** 考虑映射 \(X \mathbf{z}\) 作为矩阵 \(X \in \mathbb{R}^{n \times m}\) 的元素的函数。具体来说，对于固定的
    \(\mathbf{z} \in \mathbb{R}^m\)，令 \((\mathbf{x}^{(i)})^T\) 为 \(X\) 的第 \(i\) 行，我们定义函数'
- en: \[\begin{split} \mathbf{f}(\mathbf{x}) = X \mathbf{z} = \begin{pmatrix} (\mathbf{x}^{(1)})^T
    \mathbf{z} \\ \vdots\\ (\mathbf{x}^{(n)})^T \mathbf{z} \end{pmatrix} \end{split}\]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{f}(\mathbf{x}) = X \mathbf{z} = \begin{pmatrix} (\mathbf{x}^{(1)})^T
    \mathbf{z} \\ \vdots\\ (\mathbf{x}^{(n)})^T \mathbf{z} \end{pmatrix} \end{split}\]
- en: where \(\mathbf{x} = \mathrm{vec}(X^T) = (\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)})\).
    Show that \(\mathbf{f}\) is linear in \(\mathbf{x}\), that is, \(\mathbf{f}(\mathbf{x}
    + \mathbf{x}') = \mathbf{f}(\mathbf{x}) + \mathbf{f}(\mathbf{x}')\).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\mathbf{x} = \mathrm{vec}(X^T) = (\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)})\)。证明
    \(\mathbf{f}\) 在 \(\mathbf{x}\) 上是线性的，即 \(\mathbf{f}(\mathbf{x} + \mathbf{x}')
    = \mathbf{f}(\mathbf{x}) + \mathbf{f}(\mathbf{x}')\)。
- en: \(\lhd\)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.19** Let \(f(x_1, x_2) = \sin(x_1^2 + x_2) + \cos(x_1 x_2)\). Compute the
    gradient of \(f\) using the *Chain Rule* by defining appropriate functions \(\mathbf{g}\)
    and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.19** 设 \(f(x_1, x_2) = \sin(x_1^2 + x_2) + \cos(x_1 x_2)\)。通过定义适当的函数 \(\mathbf{g}\)
    和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用**链式法则**求 \(f\) 的梯度。'
- en: \(\lhd\)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.20** Consider the function \(f(x_1, x_2, x_3) = \sqrt{x_1 + x_2^2 + \exp(x_3)}\).
    Find the gradient of \(f\) at the point \((1, 2, 0)\) using the *Chain Rule* by
    defining suitable functions \(\mathbf{g}\) and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.20** 考虑函数 \(f(x_1, x_2, x_3) = \sqrt{x_1 + x_2^2 + \exp(x_3)}\)。通过定义合适的函数
    \(\mathbf{g}\) 和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用**链式法则**求 \(f\) 在点 \((1,
    2, 0)\) 处的梯度。'
- en: \(\lhd\)
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.21** Consider the function \(f(x_1, x_2, x_3) = (x_1 + x_2^2)^3 + \sin(x_2
    x_3)\). Find the gradient of \(f\) using the *Chain Rule* by defining suitable
    functions \(\mathbf{g}\) and \(h\) such that \(f = h \circ \mathbf{g}\).'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.21** 考虑函数 \(f(x_1, x_2, x_3) = (x_1 + x_2^2)^3 + \sin(x_2 x_3)\)。通过定义合适的函数
    \(\mathbf{g}\) 和 \(h\) 使得 \(f = h \circ \mathbf{g}\)，使用**链式法则**求 \(f\) 的梯度。'
- en: \(\lhd\)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.22** For \(i=1, \ldots, n\), let \(f_i : D_i \to \mathbb{R}\), with \(D_i
    \subseteq \mathbb{R}\), be a continuously differentiable real-valued function
    of a single variable. Consider the vector-valued function \(\mathbf{f} : D_1 \times
    \cdots \times D_n \to \mathbb{R}^n\) defined as'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.22** 对于 \(i=1, \ldots, n\)，设 \(f_i : D_i \to \mathbb{R}\)，其中 \(D_i \subseteq
    \mathbb{R}\)，是一个关于单变量的连续可微实值函数。考虑定义在 \(D_1 \times \cdots \times D_n \to \mathbb{R}^n\)
    的向量值函数 \(\mathbf{f}\)：'
- en: \[ \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_n(\mathbf{x})) = (f_1(x_1),
    \ldots, f_n(x_n)). \]
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_n(\mathbf{x})) = (f_1(x_1),
    \ldots, f_n(x_n)). \]
- en: For \(\mathbf{x} = (x_1, \ldots, x_n)\) such that \(x_i\) is an interior point
    of \(D_i\) for all \(i\), compute the Jacobian \(J_{\mathbf{f}}(\mathbf{x})\).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 \(\mathbf{x} = (x_1, \ldots, x_n)\) 且 \(x_i\) 是 \(D_i\) 的内部点（对所有 \(i\)），计算
    \(J_{\mathbf{f}}(\mathbf{x})\)。
- en: \(\lhd\)
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.23** Let \(f\) be a real-valued function taking a matrix \(A = (a_{i,j})_{i,j}
    \in \mathbb{R}^{n \times n}\) as an input. Assume \(f\) is continuously differentiable
    in each entry of \(A\). Consider the following matrix derivative'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.23** 设 \(f\) 是一个以矩阵 \(A = (a_{i,j})_{i,j} \in \mathbb{R}^{n \times n}\)
    为输入的实值函数。假设 \(f\) 在 \(A\) 的每个元素上都是连续可微的。考虑以下矩阵导数'
- en: \[\begin{split} \frac{\partial f(A)}{\partial A} = \begin{pmatrix} \frac{\partial
    f(A)}{\partial a_{1,1}} & \cdots & \frac{\partial f(A)}{\partial a_{1,n}}\\ \vdots
    & \ddots & \vdots\\ \frac{\partial f(A)}{\partial a_{n,1}} & \cdots & \frac{\partial
    f(A)}{\partial a_{n,n}} \end{pmatrix}. \end{split}\]
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \frac{\partial f(A)}{\partial A} = \begin{pmatrix} \frac{\partial
    f(A)}{\partial a_{1,1}} & \cdots & \frac{\partial f(A)}{\partial a_{1,n}}\\ \vdots
    & \ddots & \vdots\\ \frac{\partial f(A)}{\partial a_{n,1}} & \cdots & \frac{\partial
    f(A)}{\partial a_{n,n}} \end{pmatrix}. \end{split}\]
- en: a) Show that, for any \(B \in \mathbb{R}^{n \times n}\),
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明，对于任意 \(B \in \mathbb{R}^{n \times n}\)，
- en: \[ \frac{\partial \,\mathrm{tr}(B^T A)}{\partial A} = B. \]
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \,\mathrm{tr}(B^T A)}{\partial A} = B. \]
- en: b) Show that, for any \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\),
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明，对于任意 \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\)，
- en: \[ \frac{\partial \,\mathbf{x}^T A \mathbf{y}}{\partial A} = \mathbf{x} \mathbf{y}^T.
    \]
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial \,\mathbf{x}^T A \mathbf{y}}{\partial A} = \mathbf{x} \mathbf{y}^T.
    \]
- en: \(\lhd\)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
- en: '**8.24** Let \(A = (a_{i,j})_{i \in [n], j \in [m]} \in \mathbb{R}^{n \times
    m}\) and \(B = (b_{i,j})_{i \in [p], j \in [q]} \in \mathbb{R}^{p \times q}\)
    be arbitrary matrices. Their Kronecker product, denoted \(A \otimes B \in \mathbb{R}^{np
    \times mq}\), is the following matrix in block form'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '**8.24** 设 \(A = (a_{i,j})_{i \in [n], j \in [m]} \in \mathbb{R}^{n \times
    m}\) 和 \(B = (b_{i,j})_{i \in [p], j \in [q]} \in \mathbb{R}^{p \times q}\) 是任意矩阵。它们的克罗内克积，记为
    \(A \otimes B \in \mathbb{R}^{np \times mq}\)，是以下分块形式的矩阵'
- en: \[\begin{split} A \otimes B = \begin{pmatrix} a_{1,1} B & \cdots & a_{1,m} B
    \\ \vdots & \ddots & \vdots \\ a_{n,1} B & \cdots & a_{n,m} B \end{pmatrix}. \end{split}\]
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A \otimes B = \begin{pmatrix} a_{1,1} B & \cdots & a_{1,m} B
    \\ \vdots & \ddots & \vdots \\ a_{n,1} B & \cdots & a_{n,m} B \end{pmatrix}. \end{split}\]
- en: 'The Kronecker product satisfies the following properties (which follow from
    block formulas, but which you do not have to prove): 1) if \(A, B, C, D\) are
    matrices of such size that one can form the matrix products \(AC\) and \(BD\),
    then \((A \otimes B)\,(C \otimes D) = (AC) \otimes (BD)\); 2) the transpose of
    \(A \otimes B\) is \((A \otimes B)^T = A^T \otimes B^T\).'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 克朗内克积满足以下性质（这些性质由分块公式得出，但不需要证明）：1) 如果 \(A, B, C, D\) 是可以形成矩阵乘积 \(AC\) 和 \(BD\)
    的矩阵，那么 \((A \otimes B)\,(C \otimes D) = (AC) \otimes (BD)\)；2) \(A \otimes B\)
    的转置是 \((A \otimes B)^T = A^T \otimes B^T\)。
- en: a) Show that if \(D_1\) and \(D_2\) are square diagonal matrices, then so is
    \(D_1 \otimes D_2\).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: a) 证明如果 \(D_1\) 和 \(D_2\) 是方对角矩阵，那么 \(D_1 \otimes D_2\) 也是。
- en: b) Show that if \(Q_1\) and \(Q_2\) have orthonormal columns, so does \(Q_1
    \otimes Q_2\).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: b) 证明如果 \(Q_1\) 和 \(Q_2\) 有正交归一列，那么 \(Q_1 \otimes Q_2\) 也有。
- en: c) Let \(A_1 = U_1 \Sigma_1 V_1^T\) and \(A_2 = U_2 \Sigma_2 V_2^T\) be full
    SVDs of \(A_1, A_2 \in \mathbb{R}^{n \times n}\) respectively. Compute a full
    SVD of \(A_1 \otimes A_2\).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: c) 设 \(A_1 = U_1 \Sigma_1 V_1^T\) 和 \(A_2 = U_2 \Sigma_2 V_2^T\) 分别是 \(A_1,
    A_2 \in \mathbb{R}^{n \times n}\) 的满奇异值分解。计算 \(A_1 \otimes A_2\) 的满奇异值分解。
- en: d) Let \(A_1\) and \(A_2\) be as in c). Show that the rank of \(A_1 \otimes
    A_2\) is \(\mathrm{rk}(A_1) \,\mathrm{rk}(A_2)\).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: d) 设 \(A_1\) 和 \(A_2\) 如 c) 所述。证明 \(A_1 \otimes A_2\) 的秩是 \(\mathrm{rk}(A_1)
    \,\mathrm{rk}(A_2)\)。
- en: \(\lhd\)
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: \(\lhd\)
