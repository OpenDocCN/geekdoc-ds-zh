- en: 'Chapter 6 Classification II: evaluation & tuning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 分类II：评估与调整
- en: 原文：[https://datasciencebook.ca/classification2.html](https://datasciencebook.ca/classification2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://datasciencebook.ca/classification2.html](https://datasciencebook.ca/classification2.html)'
- en: 6.1 Overview
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 概述
- en: This chapter continues the introduction to predictive modeling through classification.
    While the previous chapter covered training and data preprocessing, this chapter
    focuses on how to evaluate the performance of a classifier, as well as how to
    improve the classifier (where possible) to maximize its accuracy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章继续介绍通过分类进行预测建模。虽然上一章涵盖了训练和数据预处理，但本章重点介绍如何评估分类器的性能，以及如何（如果可能）改进分类器以最大化其准确率。
- en: 6.2 Chapter learning objectives
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 章节学习目标
- en: 'By the end of the chapter, readers will be able to do the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，读者将能够做到以下几点：
- en: Describe what training, validation, and test data sets are and how they are
    used in classification.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述训练集、验证集和测试集是什么，以及它们在分类中的应用。
- en: Split data into training, validation, and test data sets.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分为训练集、验证集和测试集。
- en: Describe what a random seed is and its importance in reproducible data analysis.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述随机种子是什么，以及它在可重复数据分析中的重要性。
- en: Set the random seed in R using the `set.seed` function.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`set.seed`函数在R中设置随机种子。
- en: Describe and interpret accuracy, precision, recall, and confusion matrices.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述并解释准确率、精确率、召回率和混淆矩阵。
- en: Evaluate classification accuracy, precision, and recall in R using a test set,
    a single validation set, and cross-validation.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用测试集、单个验证集和交叉验证在R中评估分类准确率、精确率和召回率。
- en: Produce a confusion matrix in R.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在R中生成混淆矩阵。
- en: Choose the number of neighbors in a K-nearest neighbors classifier by maximizing
    estimated cross-validation accuracy.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过最大化估计的交叉验证准确率来选择K最近邻分类器中的邻居数量。
- en: Describe underfitting and overfitting, and relate it to the number of neighbors
    in K-nearest neighbors classification.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述欠拟合和过拟合，并将其与K最近邻分类中的邻居数量联系起来。
- en: Describe the advantages and disadvantages of the K-nearest neighbors classification
    algorithm.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述K最近邻分类算法的优点和缺点。
- en: 6.3 Evaluating performance
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 评估性能
- en: 'Sometimes our classifier might make the wrong prediction. A classifier does
    not need to be right 100% of the time to be useful, though we don’t want the classifier
    to make too many wrong predictions. How do we measure how “good” our classifier
    is? Let’s revisit the [breast cancer images data](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
    ([Street, Wolberg, and Mangasarian 1993](#ref-streetbreastcancer)) and think about
    how our classifier will be used in practice. A biopsy will be performed on a *new*
    patient’s tumor, the resulting image will be analyzed, and the classifier will
    be asked to decide whether the tumor is benign or malignant. The key word here
    is *new*: our classifier is “good” if it provides accurate predictions on data
    *not seen during training*, as this implies that it has actually learned about
    the relationship between the predictor variables and response variable, as opposed
    to simply memorizing the labels of individual training data examples. But then,
    how can we evaluate our classifier without visiting the hospital to collect more
    tumor images?'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们的分类器可能会做出错误的预测。虽然我们不希望分类器做出太多的错误预测，但分类器不需要100%正确才能有用。我们如何衡量我们的分类器有多“好”？让我们回顾一下[威斯康星乳腺癌图像数据](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
    ([Street, Wolberg, 和 Mangasarian 1993](#ref-streetbreastcancer))，并思考我们的分类器在实际应用中会如何使用。对一位新患者的肿瘤将进行活检，生成的图像将被分析，分类器将被要求判断肿瘤是良性还是恶性。这里的关键词是“新”：如果我们的分类器能够在训练期间未见过的数据上提供准确的预测，那么它就是“好”的，因为这表明它实际上已经了解了预测变量和响应变量之间的关系，而不是仅仅记住单个训练数据示例的标签。但是，我们如何在不访问医院收集更多肿瘤图像的情况下评估我们的分类器呢？
- en: The trick is to split the data into a **training set** and **test set** (Figure
    [6.1](classification2.html#fig:06-training-test)) and use only the **training
    set** when building the classifier. Then, to evaluate the performance of the classifier,
    we first set aside the labels from the **test set**, and then use the classifier
    to predict the labels in the **test set**. If our predictions match the actual
    labels for the observations in the **test set**, then we have some confidence
    that our classifier might also accurately predict the class labels for new observations
    without known class labels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 诀窍是将数据分为一个**训练集**和一个**测试集**（图[6.1](classification2.html#fig:06-training-test)），并在构建分类器时仅使用**训练集**。然后，为了评估分类器的性能，我们首先将**测试集**中的标签留出，然后使用分类器预测**测试集**中的标签。如果我们的预测与**测试集**中观察到的实际标签相匹配，那么我们有信心认为我们的分类器也可能准确地预测没有已知类别标签的新观察结果。
- en: '**Note:** If there were a golden rule of machine learning, it might be this:
    *you cannot use the test data to build the model!* If you do, the model gets to
    “see” the test data in advance, making it look more accurate than it really is.
    Imagine how bad it would be to overestimate your classifier’s accuracy when predicting
    whether a patient’s tumor is malignant or benign!'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 如果机器学习有一个黄金法则，那可能就是：*你不能使用测试数据来构建模型!* 如果你这样做，模型会“看到”测试数据，使其看起来比实际情况更准确。想象一下，在预测患者肿瘤是恶性还是良性时，高估分类器的准确性会有多糟糕！'
- en: '![Splitting the data into training and testing sets.](../Images/a72ca7fbe8b2425ea65e5efa1152faa1.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![将数据分为训练集和测试集。](../Images/a72ca7fbe8b2425ea65e5efa1152faa1.png)'
- en: 'Figure 6.1: Splitting the data into training and testing sets.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：将数据分为训练集和测试集。
- en: How exactly can we assess how well our predictions match the actual labels for
    the observations in the test set? One way we can do this is to calculate the prediction
    **accuracy**. This is the fraction of examples for which the classifier made the
    correct prediction. To calculate this, we divide the number of correct predictions
    by the number of predictions made. The process for assessing if our predictions
    match the actual labels in the test set is illustrated in Figure [6.2](classification2.html#fig:06-ML-paradigm-test).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确切地评估我们的预测与测试集中观察到的实际标签的匹配程度呢？我们可以做的一件事是计算预测**准确性**。这是分类器做出正确预测的示例比例。为了计算这个值，我们将正确预测的数量除以做出的预测总数。评估我们的预测是否与测试集中的实际标签匹配的过程在图[6.2](classification2.html#fig:06-ML-paradigm-test)中得到了说明。
- en: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}}\]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}}\]
- en: '![Process for splitting the data and finding the prediction accuracy.](../Images/0dbe73aded32d905c79dd561aa410e35.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![分割数据并找到预测准确性的过程。](../Images/0dbe73aded32d905c79dd561aa410e35.png)'
- en: 'Figure 6.2: Process for splitting the data and finding the prediction accuracy.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：分割数据并找到预测准确性的过程。
- en: Accuracy is a convenient, general-purpose way to summarize the performance of
    a classifier with a single number. But prediction accuracy by itself does not
    tell the whole story. In particular, accuracy alone only tells us how often the
    classifier makes mistakes in general, but does not tell us anything about the
    *kinds* of mistakes the classifier makes. A more comprehensive view of performance
    can be obtained by additionally examining the **confusion matrix**. The confusion
    matrix shows how many test set labels of each type are predicted correctly and
    incorrectly, which gives us more detail about the kinds of mistakes the classifier
    tends to make. Table [6.1](classification2.html#tab:confusion-matrix) shows an
    example of what a confusion matrix might look like for the tumor image data with
    a test set of 65 observations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性是一个方便的、通用的方法，可以用一个数字来总结分类器的性能。但预测准确性本身并不能说明全部情况。特别是，仅凭准确性并不能告诉我们分类器通常犯错误的频率，也不能告诉我们分类器犯的**错误类型**。通过进一步检查**混淆矩阵**，我们可以获得更全面的性能视图。混淆矩阵显示了每种类型的测试集标签被正确和错误预测的数量，这为我们提供了关于分类器倾向于犯的**错误类型**的更多细节。表[6.1](classification2.html#tab:confusion-matrix)展示了对于有65个观察值的测试集的肿瘤图像数据，混淆矩阵可能看起来像什么。
- en: 'Table 6.1: An example confusion matrix for the tumor image data.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1：肿瘤图像数据的示例混淆矩阵。
- en: '|  | Actually Malignant | Actually Benign |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | 实际为恶性 | 实际为良性 |'
- en: '| --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Predicted Malignant** | 1 | 4 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **预测为恶性** | 1 | 4 |'
- en: '| **Predicted Benign** | 3 | 57 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **预测良性** | 3 | 57 |'
- en: 'In the example in Table [6.1](classification2.html#tab:confusion-matrix), we
    see that there was 1 malignant observation that was correctly classified as malignant
    (top left corner), and 57 benign observations that were correctly classified as
    benign (bottom right corner). However, we can also see that the classifier made
    some mistakes: it classified 3 malignant observations as benign, and 4 benign
    observations as malignant. The accuracy of this classifier is roughly 89%, given
    by the formula'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在表[6.1](classification2.html#tab:confusion-matrix)的例子中，我们看到有1个恶性观察被正确地分类为恶性（左上角），以及57个良性观察被正确地分类为良性（右下角）。然而，我们也可以看到分类器犯了一些错误：它将3个恶性观察错误地分类为良性，并将4个良性观察错误地分类为恶性。这个分类器的准确率大约为89%，由以下公式给出
- en: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}} = \frac{1+57}{1+57+4+3} = 0.892.\]
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}} = \frac{1+57}{1+57+4+3} = 0.892.\]
- en: But we can also see that the classifier only identified 1 out of 4 total malignant
    tumors; in other words, it misclassified 75% of the malignant cases present in
    the data set! In this example, misclassifying a malignant tumor is a potentially
    disastrous error, since it may lead to a patient who requires treatment not receiving
    it. Since we are particularly interested in identifying malignant cases, this
    classifier would likely be unacceptable even with an accuracy of 89%.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们也可以看到，分类器只识别出了4个总恶性肿瘤中的1个；换句话说，它错误地将数据集中75%的恶性病例分类了！在这个例子中，将一个恶性肿瘤错误分类为良性是一个可能带来灾难性错误的错误，因为它可能导致需要治疗的病人没有得到治疗。由于我们特别关注识别恶性病例，即使准确率达到89%，这个分类器也可能是不被接受的。
- en: 'Focusing more on one label than the other is common in classification problems.
    In such cases, we typically refer to the label we are more interested in identifying
    as the *positive* label, and the other as the *negative* label. In the tumor example,
    we would refer to malignant observations as *positive*, and benign observations
    as *negative*. We can then use the following terms to talk about the four kinds
    of prediction that the classifier can make, corresponding to the four entries
    in the confusion matrix:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，通常更关注一个标签而不是另一个标签。在这种情况下，我们通常将我们更感兴趣识别的标签称为**正**标签，而将另一个称为**负**标签。在肿瘤的例子中，我们将恶性观察称为**正**，将良性观察称为**负**。然后我们可以使用以下术语来讨论分类器可以做出的四种预测，对应于混淆矩阵中的四个条目：
- en: '**True Positive:** A malignant observation that was classified as malignant
    (top left in Table [6.1](classification2.html#tab:confusion-matrix)).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**：一个恶性观察被正确地分类为恶性（表[6.1](classification2.html#tab:confusion-matrix)的左上角）。'
- en: '**False Positive:** A benign observation that was classified as malignant (top
    right in Table [6.1](classification2.html#tab:confusion-matrix)).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**：一个良性观察被错误地分类为恶性（表[6.1](classification2.html#tab:confusion-matrix)的右上角）。'
- en: '**True Negative:** A benign observation that was classified as benign (bottom
    right in Table [6.1](classification2.html#tab:confusion-matrix)).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**：一个良性观察被正确地分类为良性（表[6.1](classification2.html#tab:confusion-matrix)的右下角）。'
- en: '**False Negative:** A malignant observation that was classified as benign (bottom
    left in Table [6.1](classification2.html#tab:confusion-matrix)).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**：一个恶性观察被错误地分类为良性（表[6.1](classification2.html#tab:confusion-matrix)的左下角）。'
- en: 'A perfect classifier would have zero false negatives and false positives (and
    therefore, 100% accuracy). However, classifiers in practice will almost always
    make some errors. So you should think about which kinds of error are most important
    in your application, and use the confusion matrix to quantify and report them.
    Two commonly used metrics that we can compute using the confusion matrix are the
    **precision** and **recall** of the classifier. These are often reported together
    with accuracy. *Precision* quantifies how many of the positive predictions the
    classifier made were actually positive. Intuitively, we would like a classifier
    to have a *high* precision: for a classifier with high precision, if the classifier
    reports that a new observation is positive, we can trust that the new observation
    is indeed positive. We can compute the precision of a classifier using the entries
    in the confusion matrix, with the formula'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一个完美的分类器将没有假阴性和假阳性（因此，准确率为100%）。然而，在实际应用中，分类器几乎总是会犯一些错误。因此，你应该考虑在你的应用中哪种类型的错误最重要，并使用混淆矩阵来量化并报告它们。我们可以使用混淆矩阵计算的两个常用指标是分类器的**精确度**和**召回率**。这些指标通常与准确率一起报告。*精确度*衡量分类器做出的正类预测中有多少实际上是正类。直观上，我们希望分类器具有*高*精确度：对于具有高精确度的分类器，如果分类器报告说一个新的观察结果是正类，我们可以相信这个新的观察结果确实是正类。我们可以使用混淆矩阵中的条目来计算分类器的精确度，公式如下
- en: \[\mathrm{precision} = \frac{\mathrm{number \; of \; correct \; positive \;
    predictions}}{\mathrm{total \; number \; of \; positive \; predictions}}.\]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{precision} = \frac{\mathrm{number \; of \; correct \; positive \;
    predictions}}{\mathrm{total \; number \; of \; positive \; predictions}}.\]
- en: '*Recall* quantifies how many of the positive observations in the test set were
    identified as positive. Intuitively, we would like a classifier to have a *high*
    recall: for a classifier with high recall, if there is a positive observation
    in the test data, we can trust that the classifier will find it. We can also compute
    the recall of the classifier using the entries in the confusion matrix, with the
    formula'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率*衡量测试集中被识别为正类的正类观察数量。直观上，我们希望分类器具有*高*召回率：对于具有高召回率的分类器，如果测试数据中存在正类观察，我们可以相信分类器会找到它。我们也可以使用混淆矩阵中的条目来计算分类器的召回率，公式如下'
- en: \[\mathrm{recall} = \frac{\mathrm{number \; of \; correct \; positive \; predictions}}{\mathrm{total
    \; number \; of \; positive \; test \; set \; observations}}.\]
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{recall} = \frac{\mathrm{number \; of \; correct \; positive \; predictions}}{\mathrm{total
    \; number \; of \; positive \; test \; set \; observations}}.\]
- en: In the example presented in Table [6.1](classification2.html#tab:confusion-matrix),
    we have that the precision and recall are
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在表[6.1](classification2.html#tab:confusion-matrix)中给出的示例中，我们得到精确度和召回率分别是
- en: \[\mathrm{precision} = \frac{1}{1+4} = 0.20, \quad \mathrm{recall} = \frac{1}{1+3}
    = 0.25.\]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{precision} = \frac{1}{1+4} = 0.20, \quad \mathrm{recall} = \frac{1}{1+3}
    = 0.25.\]
- en: 'So even with an accuracy of 89%, the precision and recall of the classifier
    were both relatively low. For this data analysis context, recall is particularly
    important: if someone has a malignant tumor, we certainly want to identify it.
    A recall of just 25% would likely be unacceptable!'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所以即使准确率达到89%，分类器的精确度和召回率仍然相对较低。在这个数据分析的背景下，召回率尤为重要：如果有人患有恶性肿瘤，我们当然希望能够识别出来。仅仅25%的召回率可能是不被接受的！
- en: '**Note:** It is difficult to achieve both high precision and high recall at
    the same time; models with high precision tend to have low recall and vice versa.
    As an example, we can easily make a classifier that has *perfect recall*: just
    *always* guess positive! This classifier will of course find every positive observation
    in the test set, but it will make lots of false positive predictions along the
    way and have low precision. Similarly, we can easily make a classifier that has
    *perfect precision*: *never* guess positive! This classifier will never incorrectly
    identify an obsevation as positive, but it will make a lot of false negative predictions
    along the way. In fact, this classifier will have 0% recall! Of course, most real
    classifiers fall somewhere in between these two extremes. But these examples serve
    to show that in settings where one of the classes is of interest (i.e., there
    is a *positive* label), there is a trade-off between precision and recall that
    one has to make when designing a classifier.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：**同时实现高精度和高召回率是困难的；高精度的模型往往召回率低，反之亦然。作为一个例子，我们可以轻松地制作一个具有**完美召回率**的分类器：**总是**猜测为正！这个分类器当然会找到测试集中的每一个正类观察值，但在过程中会做出很多错误的正类预测，并且精度低。同样，我们也可以轻松地制作一个具有**完美精度**的分类器：**永远**不猜测为正！这个分类器永远不会错误地将观察值识别为正类，但在过程中会做出很多错误的负类预测。实际上，这个分类器的召回率将是
    0%！当然，大多数真实世界的分类器都介于这两个极端之间。但这些例子有助于说明，在某个类别对结果有影响（即存在**正**标签）的情况下，在设计分类器时，必须在精度和召回率之间做出权衡。'
- en: 6.4 Randomness and seeds
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 随机性和种子
- en: Beginning in this chapter, our data analyses will often involve the use of *randomness*.
    We use randomness any time we need to make a decision in our analysis that needs
    to be fair, unbiased, and not influenced by human input. For example, in this
    chapter, we need to split a data set into a training set and test set to evaluate
    our classifier. We certainly do not want to choose how to split the data ourselves
    by hand, as we want to avoid accidentally influencing the result of the evaluation.
    So instead, we let R *randomly* split the data. In future chapters we will use
    randomness in many other ways, e.g., to help us select a small subset of data
    from a larger data set, to pick groupings of data, and more.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章开始，我们的数据分析将经常涉及使用**随机性**。我们在需要做出公平、无偏见且不受人类输入影响的分析决策时使用随机性。例如，在本章中，我们需要将数据集分成训练集和测试集来评估我们的分类器。我们当然不希望手动选择如何分割数据，因为我们想避免无意中影响评估结果。因此，我们让
    R **随机**分割数据。在未来的章节中，我们将以许多其他方式使用随机性，例如，帮助我们从一个较大的数据集中选择一小部分数据，选择数据分组，等等。
- en: 'However, the use of randomness runs counter to one of the main tenets of good
    data analysis practice: *reproducibility*. Recall that a reproducible analysis
    produces the same result each time it is run; if we include randomness in the
    analysis, would we not get a different result each time? The trick is that in
    R—and other programming languages—randomness is not actually random! Instead,
    R uses a *random number generator* that produces a sequence of numbers that are
    completely determined by a *seed value*. Once you set the seed value using the
    `set.seed` function, everything after that point may *look* random, but is actually
    totally reproducible. As long as you pick the same seed value, you get the same
    result!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随机性的使用与良好数据分析实践的主要原则之一——**可重复性**——相矛盾。回想一下，可重复的分析每次运行都会产生相同的结果；如果我们把随机性包含在分析中，我们不会每次都得到不同的结果吗？诀窍在于在
    R（以及其他编程语言）中，随机性实际上并不是随机的！相反，R 使用一个**随机数生成器**，它产生一个完全由**种子值**决定的数字序列。一旦你使用 `set.seed`
    函数设置了种子值，之后的所有操作可能看起来是随机的，但实际上是完全可重复的。只要选择相同的种子值，你就能得到相同的结果！
- en: Let’s use an example to investigate how seeds work in R. Say we want to randomly
    pick 10 numbers from 0 to 9 in R using the `sample` function, but we want it to
    be reproducible. Before using the sample function, we call `set.seed`, and pass
    it any integer as an argument. Here, we pass in the number `1`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来探究在 R 中种子是如何工作的。假设我们想在 R 中使用 `sample` 函数随机选择 0 到 9 之间的 10 个数字，但我们希望它是可重复的。在使用
    `sample` 函数之前，我们调用 `set.seed` 并传递任何整数作为参数。这里，我们传递了数字 `1`。
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can see that `random_numbers1` is a list of 10 numbers from 0 to 9 that,
    from all appearances, looks random. If we run the `sample` function again, we
    will get a fresh batch of 10 numbers that also look random.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，`random_numbers1` 是一个包含从 0 到 9 的 10 个数字的列表，从所有迹象来看，看起来是随机的。如果我们再次运行 `sample`
    函数，我们将得到一批看起来也是随机的 10 个新数字。
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If we want to force R to produce the same sequences of random numbers, we can
    simply call the `set.seed` function again with the same argument value.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想强制 R 产生相同的随机数字序列，我们可以简单地再次使用相同的参数值调用 `set.seed` 函数。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Notice that after setting the seed, we get the same two sequences of numbers
    in the same order. `random_numbers1` and `random_numbers1_again` produce the same
    sequence of numbers, and the same can be said about `random_numbers2` and `random_numbers2_again`.
    And if we choose a different value for the seed—say, 4235—we obtain a different
    sequence of random numbers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到在设置种子之后，我们以相同的顺序得到了相同的两个数字序列。`random_numbers1` 和 `random_numbers1_again`
    产生了相同的数字序列，对于 `random_numbers2` 和 `random_numbers2_again` 也是如此。如果我们为种子选择一个不同的值——比如说，4235——我们将得到一个不同的随机数字序列。
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In other words, even though the sequences of numbers that R is generating *look*
    random, they are totally determined when we set a seed value!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，尽管 R 生成的数字序列看起来是随机的，但当我们设置种子值时，它们是完全确定的！
- en: So what does this mean for data analysis? Well, `sample` is certainly not the
    only function that uses randomness in R. Many of the functions that we use in
    `tidymodels`, `tidyverse`, and beyond use randomness—some of them without even
    telling you about it. So at the beginning of every data analysis you do, right
    after loading packages, you should call the `set.seed` function and pass it an
    integer that you pick. Also note that when R starts up, it creates its own seed
    to use. So if you do not explicitly call the `set.seed` function in your code,
    your results will likely not be reproducible. And finally, be careful to set the
    seed *only once* at the beginning of a data analysis. Each time you set the seed,
    you are inserting your own human input, thereby influencing the analysis. If you
    use `set.seed` many times throughout your analysis, the randomness that R uses
    will not look as random as it should.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这对数据分析意味着什么呢？嗯，`sample` 当然不是在 R 中使用随机性的唯一函数。我们在 `tidymodels`、`tidyverse` 以及其他地方使用的许多函数都使用了随机性——其中一些甚至没有告诉你。因此，在每次数据分析的开始，在加载包之后，你应该调用
    `set.seed` 函数并传递你选择的整数。此外，请注意，当 R 启动时，它会创建自己的种子值来使用。所以，如果你在你的代码中明确没有调用 `set.seed`
    函数，你的结果可能无法重现。最后，务必在数据分析的开始处只设置一次种子。每次你设置种子，你都在插入你自己的主观输入，从而影响分析。如果你在分析过程中多次使用
    `set.seed`，R 使用的随机性看起来可能不会像它应该的那样随机。
- en: 'In summary: if you want your analysis to be reproducible, i.e., produce *the
    same result* each time you run it, make sure to use `set.seed` exactly once at
    the beginning of the analysis. Different argument values in `set.seed` lead to
    different patterns of randomness, but as long as you pick the same argument value
    your result will be the same. In the remainder of the textbook, we will set the
    seed once at the beginning of each chapter.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说：如果你想使你的分析可重现，即每次运行时都产生相同的结果，确保在分析开始时恰好使用一次 `set.seed`。`set.seed` 中的不同参数值会导致不同的随机模式，但只要你选择相同的参数值，你的结果就会相同。在本教材的剩余部分，我们将在每一章的开始处设置一次种子。
- en: 6.5 Evaluating performance with `tidymodels`
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 使用 `tidymodels` 评估性能
- en: Back to evaluating classifiers now! In R, we can use the `tidymodels` package
    not only to perform K-nearest neighbors classification, but also to assess how
    well our classification worked. Let’s work through an example of how to use tools
    from `tidymodels` to evaluate a classifier using the breast cancer data set from
    the previous chapter. We begin the analysis by loading the packages we require,
    reading in the breast cancer data, and then making a quick scatter plot visualization
    of tumor cell concavity versus smoothness colored by diagnosis in Figure [6.3](classification2.html#fig:06-precode).
    You will also notice that we set the random seed here at the beginning of the
    analysis using the `set.seed` function, as described in Section [6.4](classification2.html#randomseeds).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到评估分类器的话题！在R中，我们可以使用 `tidymodels` 包不仅执行K最近邻分类，还可以评估我们的分类效果如何。让我们通过一个例子来了解如何使用
    `tidymodels` 工具评估一个分类器，使用的是上一章中的乳腺癌数据集。我们开始分析，通过加载所需的包，读取乳腺癌数据，然后制作一个快速散点图可视化，展示肿瘤细胞凹凸度与平滑度按诊断着色，如图[6.3](classification2.html#fig:06-precode)。你也会注意到，我们在分析开始时使用
    `set.seed` 函数设置了随机种子，如第[6.4](classification2.html#randomseeds)节所述。
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Scatter plot of tumor cell concavity versus smoothness colored by diagnosis
    label.](../Images/b9241a2aad1243e56dd849a6da65a681.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![肿瘤细胞凹凸度与平滑度散点图，按诊断标签着色。](../Images/b9241a2aad1243e56dd849a6da65a681.png)'
- en: 'Figure 6.3: Scatter plot of tumor cell concavity versus smoothness colored
    by diagnosis label.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3：按诊断标签着色的肿瘤细胞凹凸度与平滑度散点图。
- en: 6.5.1 Create the train / test split
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.1 创建训练/测试拆分
- en: Once we have decided on a predictive question to answer and done some preliminary
    exploration, the very next thing to do is to split the data into the training
    and test sets. Typically, the training set is between 50% and 95% of the data,
    while the test set is the remaining 5% to 50%; the intuition is that you want
    to trade off between training an accurate model (by using a larger training data
    set) and getting an accurate evaluation of its performance (by using a larger
    test data set). Here, we will use 75% of the data for training, and 25% for testing.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定要回答一个预测问题并进行了初步的探索，接下来要做的事情就是将数据拆分为训练集和测试集。通常，训练集占数据量的50%到95%，而测试集则是剩余的5%到50%；这种直觉是，你希望在训练一个准确模型（通过使用更大的训练数据集）和获得对其性能的准确评估（通过使用更大的测试数据集）之间进行权衡。在这里，我们将使用75%的数据进行训练，25%的数据进行测试。
- en: The `initial_split` function from `tidymodels` handles the procedure of splitting
    the data for us. It also applies two very important steps when splitting to ensure
    that the accuracy estimates from the test data are reasonable. First, it **shuffles**
    the data before splitting, which ensures that any ordering present in the data
    does not influence the data that ends up in the training and testing sets. Second,
    it **stratifies** the data by the class label, to ensure that roughly the same
    proportion of each class ends up in both the training and testing sets. For example,
    in our data set, roughly 63% of the observations are from the benign class, and
    37% are from the malignant class, so `initial_split` ensures that roughly 63%
    of the training data are benign, 37% of the training data are malignant, and the
    same proportions exist in the testing data.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 `tidymodels` 的 `initial_split` 函数为我们处理了数据拆分的流程。在拆分数据时，它还应用了两个非常重要的步骤，以确保从测试数据中得到的准确度估计是合理的。首先，它在拆分之前对数据进行**洗牌**，这确保了数据中存在的任何顺序都不会影响最终进入训练集和测试集的数据。其次，它根据类别标签**分层**数据，以确保每个类别在大约相同的比例下出现在训练集和测试集中。例如，在我们的数据集中，大约63%的观测值来自良性类别，37%来自恶性类别，因此
    `initial_split` 确保大约63%的训练数据是良性的，37%的训练数据是恶性的，测试数据中也存在相同的比例。
- en: Let’s use the `initial_split` function to create the training and testing sets.
    We will specify that `prop = 0.75` so that 75% of our original data set ends up
    in the training set. We will also set the `strata` argument to the categorical
    label variable (here, `Class`) to ensure that the training and testing subsets
    contain the right proportions of each category of observation. The `training`
    and `testing` functions then extract the training and testing data sets into two
    separate data frames. Note that the `initial_split` function uses randomness,
    but since we set the seed earlier in the chapter, the split will be reproducible.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `initial_split` 函数来创建训练集和测试集。我们将指定 `prop = 0.75`，这样我们原始数据集的75%将最终进入训练集。我们还将设置
    `strata` 参数为分类标签变量（在这里，`Class`），以确保训练集和测试集包含每个观察类别的正确比例。然后 `training` 和 `testing`
    函数将训练集和测试数据集提取到两个单独的数据框中。请注意，`initial_split` 函数使用随机性，但由于我们在本章早期设置了种子，所以分割将是可重复的。
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can see from `glimpse` in the code above that the training set contains 426
    observations, while the test set contains 143 observations. This corresponds to
    a train / test split of 75% / 25%, as desired. Recall from Chapter [5](classification1.html#classification1)
    that we use the `glimpse` function to view data with a large number of columns,
    as it prints the data such that the columns go down the page (instead of across).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的代码中的 `glimpse` 可以看出，训练集包含426个观测值，而测试集包含143个观测值。这对应于75% / 25%的训练/测试分割，正如我们期望的那样。回想一下第[5](classification1.html#classification1)章，我们使用
    `glimpse` 函数来查看具有大量列的数据，因为它以列向下打印数据（而不是横跨页面）。
- en: We can use `group_by` and `summarize` to find the percentage of malignant and
    benign classes in `cancer_train` and we see about 63% of the training data are
    benign and 37% are malignant, indicating that our class proportions were roughly
    preserved when we split the data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `group_by` 和 `summarize` 来找到 `cancer_train` 中恶性和良性类别的百分比，我们看到大约63%的训练数据是良性的，37%是恶性的，这表明当我们分割数据时，我们的类别比例大致得到了保留。
- en: '[PRE18]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 6.5.2 Preprocess the data
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.2 预处理数据
- en: As we mentioned in the last chapter, K-nearest neighbors is sensitive to the
    scale of the predictors, so we should perform some preprocessing to standardize
    them. An additional consideration we need to take when doing this is that we should
    create the standardization preprocessor using **only the training data**. This
    ensures that our test data does not influence any aspect of our model training.
    Once we have created the standardization preprocessor, we can then apply it separately
    to both the training and test data sets.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中提到的，K近邻对预测因子的规模很敏感，因此我们应该进行一些预处理来标准化它们。在执行此操作时，我们需要考虑的另一个额外因素是，我们应该使用**仅**训练数据创建标准化预处理器。这确保了我们的测试数据不会影响模型训练的任何方面。一旦我们创建了标准化预处理器，我们就可以将其分别应用于训练集和测试数据集。
- en: Fortunately, the `recipe` framework from `tidymodels` helps us handle this properly.
    Below we construct and prepare the recipe using only the training data (due to
    `data = cancer_train` in the first line).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，`tidymodels` 的 `recipe` 框架帮助我们正确处理这个问题。下面我们仅使用训练数据（由于第一行中的 `data = cancer_train`）构建和准备这个配方。
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 6.5.3 Train the classifier
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.3 训练分类器
- en: Now that we have split our original data set into training and test sets, we
    can create our K-nearest neighbors classifier with only the training set using
    the technique we learned in the previous chapter. For now, we will just choose
    the number \(K\) of neighbors to be 3, and use concavity and smoothness as the
    predictors. As before we need to create a model specification, combine the model
    specification and recipe into a workflow, and then finally use `fit` with the
    training data `cancer_train` to build the classifier.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将原始数据集分为训练集和测试集，我们可以使用上一章学到的技术，仅使用训练集来创建我们的K近邻分类器。目前，我们只需选择邻居数 \(K\) 为3，并使用凹度和平滑度作为预测因子。和之前一样，我们需要创建一个模型规范，将模型规范和配方组合成一个工作流程，然后最终使用
    `fit` 函数和训练数据 `cancer_train` 来构建分类器。
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 6.5.4 Predict the labels in the test set
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.4 在测试集中预测标签
- en: Now that we have a K-nearest neighbors classifier object, we can use it to predict
    the class labels for our test set. We use the `bind_cols` to add the column of
    predictions to the original test data, creating the `cancer_test_predictions`
    data frame. The `Class` variable contains the actual diagnoses, while the `.pred_class`
    contains the predicted diagnoses from the classifier.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了K最近邻分类器对象，我们可以用它来预测测试集的类别标签。我们使用`bind_cols`将预测列添加到原始测试数据中，创建`cancer_test_predictions`数据框。`Class`变量包含实际诊断，而`.pred_class`包含分类器预测的诊断。
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 6.5.5 Evaluate performance
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.5 评估性能
- en: 'Finally, we can assess our classifier’s performance. First, we will examine
    accuracy. To do this we use the `metrics` function from `tidymodels`, specifying
    the `truth` and `estimate` arguments:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以评估我们的分类器性能。首先，我们将检查准确率。为此，我们使用`tidymodels`中的`metrics`函数，指定`truth`和`estimate`参数：
- en: '[PRE25]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the metrics data frame, we filtered the `.metric` column since we are interested
    in the `accuracy` row. Other entries involve other metrics that are beyond the
    scope of this book. Looking at the value of the `.estimate` variable shows that
    the estimated accuracy of the classifier on the test data was 85%. To compute
    the precision and recall, we can use the `precision` and `recall` functions from
    `tidymodels`. We first check the order of the labels in the `Class` variable using
    the `levels` function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在指标数据框中，我们过滤了`.metric`列，因为我们只对`accuracy`行感兴趣。其他条目涉及本书范围之外的其他指标。查看`.estimate`变量的值显示，分类器在测试数据上的估计准确率为85%。为了计算精确率和召回率，我们可以使用`tidymodels`中的`precision`和`recall`函数。我们首先使用`levels`函数检查`Class`变量中标签的顺序：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This shows that `"Malignant"` is the first level. Therefore we will set the
    `truth` and `estimate` arguments to `Class` and `.pred_class` as before, but also
    specify that the “positive” class corresponds to the first factor level via `event_level="first"`.
    If the labels were in the other order, we would instead use `event_level="second"`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明“Malignant”是第一级。因此，我们将`truth`和`estimate`参数设置为`Class`和`.pred_class`，就像之前一样，但还指定“阳性”类别对应于第一因子水平，通过`event_level="first"`。如果标签顺序相反，我们将使用`event_level="second"`。
- en: '[PRE29]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The output shows that the estimated precision and recall of the classifier on
    the test data was 77% and 87%, respectively. Finally, we can look at the *confusion
    matrix* for the classifier using the `conf_mat` function.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，分类器在测试数据上的估计精确率和召回率分别为77%和87%。最后，我们可以使用`conf_mat`函数查看分类器的*混淆矩阵*。
- en: '[PRE33]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The confusion matrix shows 46 observations were correctly predicted as malignant,
    and 76 were correctly predicted as benign. It also shows that the classifier made
    some mistakes; in particular, it classified 7 observations as benign when they
    were actually malignant, and 14 observations as malignant when they were actually
    benign. Using our formulas from earlier, we see that the accuracy, precision,
    and recall agree with what R reported.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示，46个观察值被正确预测为恶性，76个观察值被正确预测为良性。它还显示分类器犯了一些错误；特别是，它将7个观察值错误地分类为良性，而实际上它们是恶性的，还有14个观察值被错误地分类为恶性，而实际上它们是良性的。使用我们之前提到的公式，我们可以看到准确率、精确率和召回率与R报告的一致。
- en: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}} = \frac{46+76}{46+76+14+7} = 0.853\]
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{accuracy} = \frac{\mathrm{number \; of \; correct \; predictions}}{\mathrm{total
    \; number \; of \; predictions}} = \frac{46+76}{46+76+14+7} = 0.853\]
- en: \[\mathrm{precision} = \frac{\mathrm{number \; of \; correct \; positive \;
    predictions}}{\mathrm{total \; number \; of \; positive \; predictions}} = \frac{46}{46
    + 14} = 0.767\]
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{precision} = \frac{\mathrm{number \; of \; correct \; positive \;
    predictions}}{\mathrm{total \; number \; of \; positive \; predictions}} = \frac{46}{46
    + 14} = 0.767\]
- en: \[\mathrm{recall} = \frac{\mathrm{number \; of \; correct \; positive \; predictions}}{\mathrm{total
    \; number \; of \; positive \; test \; set \; observations}} = \frac{46}{46+7}
    = 0.868\]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathrm{recall} = \frac{\mathrm{number \; of \; correct \; positive \; predictions}}{\mathrm{total
    \; number \; of \; positive \; test \; set \; observations}} = \frac{46}{46+7}
    = 0.868\]
- en: 6.5.6 Critically analyze performance
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.6 临界性分析性能
- en: We now know that the classifier was 85% accurate on the test data set, and had
    a precision of 77% and a recall of 87%. That sounds pretty good! Wait, *is* it
    good? Or do we need something higher?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道，分类器在测试数据集上的准确率为85%，精确率为77%，召回率为87%。听起来相当不错！等等，*这是否真的很好？或者我们是否需要更高的准确率？
- en: 'In general, a *good* value for accuracy (as well as precision and recall, if
    applicable) depends on the application; you must critically analyze your accuracy
    in the context of the problem you are solving. For example, if we were building
    a classifier for a kind of tumor that is benign 99% of the time, a classifier
    with 99% accuracy is not terribly impressive (just always guess benign!). And
    beyond just accuracy, we need to consider the precision and recall: as mentioned
    earlier, the *kind* of mistake the classifier makes is important in many applications
    as well. In the previous example with 99% benign observations, it might be very
    bad for the classifier to predict “benign” when the actual class is “malignant”
    (a false negative), as this might result in a patient not receiving appropriate
    medical attention. In other words, in this context, we need the classifier to
    have a *high recall*. On the other hand, it might be less bad for the classifier
    to guess “malignant” when the actual class is “benign” (a false positive), as
    the patient will then likely see a doctor who can provide an expert diagnosis.
    In other words, we are fine with sacrificing some precision in the interest of
    achieving high recall. This is why it is important not only to look at accuracy,
    but also the confusion matrix.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，准确率（以及如果适用的话，精确率和召回率）的*良好*值取决于应用；你必须批判性地分析你在解决问题的背景下准确率。例如，如果我们正在构建一种良性99%的肿瘤分类器，那么一个准确率达到99%的分类器并不特别令人印象深刻（只需总是猜测良性！）。而且，除了准确率之外，我们还需要考虑精确率和召回率：如前所述，分类器所犯的错误类型在许多应用中也很重要。在之前的99%良性观察的例子中，如果分类器预测“良性”而实际类别是“恶性”（一个假阴性），这可能会导致患者没有获得适当的医疗关注。换句话说，在这种情况下，我们需要分类器有*高召回率*。另一方面，如果分类器在实际上为“良性”时猜测“恶性”（一个假阳性），那么患者可能会去看医生，医生可以提供专业的诊断。换句话说，我们可以在追求高召回率的同时牺牲一些精确率。这就是为什么不仅要看准确率，还要看混淆矩阵的重要性。
- en: 'However, there is always an easy baseline that you can compare to for any classification
    problem: the *majority classifier*. The majority classifier *always* guesses the
    majority class label from the training data, regardless of the predictor variables’
    values. It helps to give you a sense of scale when considering accuracies. If
    the majority classifier obtains a 90% accuracy on a problem, then you might hope
    for your K-nearest neighbors classifier to do better than that. If your classifier
    provides a significant improvement upon the majority classifier, this means that
    at least your method is extracting some useful information from your predictor
    variables. Be careful though: improving on the majority classifier does not *necessarily*
    mean the classifier is working well enough for your application.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于任何分类问题，你都可以有一个简单的基线进行比较：*多数分类器*。多数分类器*总是*从训练数据中猜测多数类标签，而不考虑预测变量的值。在考虑准确率时，这有助于你有一个量化的概念。如果多数分类器在某个问题上的准确率达到90%，那么你可能希望你的K最近邻分类器做得比这更好。如果你的分类器在多数分类器的基础上有显著的改进，这意味着至少你的方法从预测变量中提取了一些有用的信息。但要注意：改进多数分类器并不*必然*意味着分类器足够好，可以适用于你的应用。
- en: 'As an example, in the breast cancer data, recall the proportions of benign
    and malignant observations in the training data are as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在乳腺癌数据中，回想一下训练数据中良性观察和恶性观察的比例如下：
- en: '[PRE35]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Since the benign class represents the majority of the training data, the majority
    classifier would *always* predict that a new observation is benign. The estimated
    accuracy of the majority classifier is usually fairly close to the majority class
    proportion in the training data. In this case, we would suspect that the majority
    classifier will have an accuracy of around 63%. The K-nearest neighbors classifier
    we built does quite a bit better than this, with an accuracy of 85%. This means
    that from the perspective of accuracy, the K-nearest neighbors classifier improved
    quite a bit on the basic majority classifier. Hooray! But we still need to be
    cautious; in this application, it is likely very important not to misdiagnose
    any malignant tumors to avoid missing patients who actually need medical care.
    The confusion matrix above shows that the classifier does, indeed, misdiagnose
    a significant number of malignant tumors as benign (7 out of 53 malignant tumors,
    or 13%!). Therefore, even though the accuracy improved upon the majority classifier,
    our critical analysis suggests that this classifier may not have appropriate performance
    for the application.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由于良性类代表了大多数训练数据，多数分类器会*总是*预测新的观测结果是良性的。多数分类器的估计准确性通常与训练数据中多数类的比例相当接近。在这种情况下，我们会怀疑多数分类器的准确性大约为63%。我们构建的K近邻分类器比这做得好得多，准确率为85%。这意味着从准确性的角度来看，K近邻分类器在基本多数分类器的基础上有了相当大的改进。太好了！但我们仍然需要谨慎；在这个应用中，很可能非常重要，不要误诊任何恶性肿瘤，以避免遗漏真正需要医疗护理的患者。上面的混淆矩阵显示，分类器确实将相当数量的恶性肿瘤误诊为良性（53个恶性肿瘤中的7个，或13%）！因此，尽管准确性超过了多数分类器，但我们的批判性分析表明，这个分类器可能不适合该应用。
- en: 6.6 Tuning the classifier
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6 调整分类器
- en: The vast majority of predictive models in statistics and machine learning have
    *parameters*. A *parameter* is a number you have to pick in advance that determines
    some aspect of how the model behaves. For example, in the K-nearest neighbors
    classification algorithm, \(K\) is a parameter that we have to pick that determines
    how many neighbors participate in the class vote. By picking different values
    of \(K\), we create different classifiers that make different predictions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和机器学习中的大多数预测模型都有*参数*。一个*参数*是在事先必须选择的一个数字，它决定了模型行为的一些方面。例如，在K近邻分类算法中，\(K\)是一个我们必须选择的参数，它决定了有多少邻居参与类别投票。通过选择不同的\(K\)值，我们创建了不同的分类器，它们会做出不同的预测。
- en: 'So then, how do we pick the *best* value of \(K\), i.e., *tune* the model?
    And is it possible to make this selection in a principled way? In this book, we
    will focus on maximizing the accuracy of the classifier. Ideally, we want somehow
    to maximize the accuracy of our classifier on data *it hasn’t seen yet*. But we
    cannot use our test data set in the process of building our model. So we will
    play the same trick we did before when evaluating our classifier: we’ll split
    our *training data itself* into two subsets, use one to train the model, and then
    use the other to evaluate it. In this section, we will cover the details of this
    procedure, as well as how to use it to help you pick a good parameter value for
    your classifier.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何选择\(K\)的*最佳*值，即*调整*模型？并且是否有可能以原则性的方式做出这个选择？在这本书中，我们将专注于最大化分类器的准确性。理想情况下，我们希望以某种方式最大化我们的分类器在尚未见过的数据上的准确性。但我们不能在构建模型的过程中使用我们的测试数据集。因此，我们将再次使用我们在评估分类器时使用的相同技巧：我们将把我们的*训练数据本身*分成两个子集，使用一个来训练模型，然后使用另一个来评估它。在本节中，我们将详细介绍这个过程的细节，以及如何使用它来帮助你为你的分类器选择一个好的参数值。
- en: '**And remember:** don’t touch the test set during the tuning process. Tuning
    is a part of model training!'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**记住：**在调整过程中不要触碰测试集。调整是模型训练的一部分！'
- en: 6.6.1 Cross-validation
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.1 交叉验证
- en: The first step in choosing the parameter \(K\) is to be able to evaluate the
    classifier using only the training data. If this is possible, then we can compare
    the classifier’s performance for different values of \(K\)—and pick the best—using
    only the training data. As suggested at the beginning of this section, we will
    accomplish this by splitting the training data, training on one subset, and evaluating
    on the other. The subset of training data used for evaluation is often called
    the **validation set**.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 选择参数 \(K\) 的第一步是能够仅使用训练数据来评估分类器。如果这可行，那么我们可以仅使用训练数据来比较不同 \(K\) 值的分类器性能——并选择最佳——这样我们就能得到一个单一的分类器。正如本节开头所建议的，我们将通过分割训练数据，在一个子集上训练，在另一个子集上评估来实现这一点。用于评估的训练数据子集通常被称为**验证集**。
- en: There is, however, one key difference from the train/test split that we performed
    earlier. In particular, we were forced to make only a *single split* of the data.
    This is because at the end of the day, we have to produce a single classifier.
    If we had multiple different splits of the data into training and testing data,
    we would produce multiple different classifiers. But while we are tuning the classifier,
    we are free to create multiple classifiers based on multiple splits of the training
    data, evaluate them, and then choose a parameter value based on ***all*** of the
    different results. If we just split our overall training data *once*, our best
    parameter choice will depend strongly on whatever data was lucky enough to end
    up in the validation set. Perhaps using multiple different train/validation splits,
    we’ll get a better estimate of accuracy, which will lead to a better choice of
    the number of neighbors \(K\) for the overall set of training data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这与我们之前进行的训练/测试分割有一个关键的不同。具体来说，我们被迫只对数据进行一次**分割**。这是因为最终，我们必须生成一个单一的分类器。如果我们对数据进行多个不同的训练和测试数据分割，我们将生成多个不同的分类器。但在调整分类器时，我们可以自由地基于多个训练数据分割创建多个分类器，评估它们，然后根据**所有**不同的结果选择参数值。如果我们只对整体训练数据进行一次分割，我们最佳参数的选择将强烈依赖于最终幸运地进入验证集的数据。也许通过使用多个不同的训练/验证分割，我们可以得到更好的准确度估计，这将导致对整体训练数据集中邻居数量
    \(K\) 的更好选择。
- en: Let’s investigate this idea in R! In particular, we will generate five different
    train/validation splits of our overall training data, train five different K-nearest
    neighbors models, and evaluate their accuracy. We will start with just a single
    split.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 R 中研究这个想法！特别是，我们将生成五个不同的整体训练数据训练/验证分割，训练五个不同的 K 近邻模型，并评估它们的准确度。我们将从一个单一的分割开始。
- en: '[PRE37]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The accuracy estimate using this split is 86%. Now we repeat the above code
    4 more times, which generates 4 more splits. Therefore we get five different shuffles
    of the data, and therefore five different values for accuracy: 86.0%, 89.7%, 88.8%,
    86.0%, 86.9%. None of these values are necessarily “more correct” than any other;
    they’re just five estimates of the true, underlying accuracy of our classifier
    built using our overall training data. We can combine the estimates by taking
    their average (here 87%) to try to get a single assessment of our classifier’s
    accuracy; this has the effect of reducing the influence of any one (un)lucky validation
    set on the estimate.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个分割的准确度估计为 86%。现在我们重复上述代码 4 次更多，这将生成 4 个更多的分割。因此，我们得到五个不同的数据洗牌，因此得到五个不同的准确度值：86.0%，89.7%，88.8%，86.0%，86.9%。这些值中没有一个必然比其他任何值“更正确”；它们只是使用我们的整体训练数据构建的分类器的真实、潜在准确度的五个估计。我们可以通过取它们的平均值（这里为
    87%）来结合估计，以尝试得到对分类器准确度的单一评估；这会减少任何一个（不）幸运的验证集对估计的影响。
- en: In practice, we don’t use random splits, but rather use a more structured splitting
    procedure so that each observation in the data set is used in a validation set
    only a single time. The name for this strategy is **cross-validation**. In **cross-validation**,
    we split our **overall training data** into \(C\) evenly sized chunks. Then, iteratively
    use \(1\) chunk as the **validation set** and combine the remaining \(C-1\) chunks
    as the **training set**. This procedure is shown in Figure [6.4](classification2.html#fig:06-cv-image).
    Here, \(C=5\) different chunks of the data set are used, resulting in 5 different
    choices for the **validation set**; we call this *5-fold* cross-validation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们不使用随机分割，而是使用更结构化的分割过程，以确保数据集中的每个观察值只在一个验证集中使用一次。这种策略的名称是 **交叉验证**。在 **交叉验证**
    中，我们将 **整体训练数据** 分成 \(C\) 个大小均匀的块。然后，迭代地使用 \(1\) 个块作为 **验证集**，并将剩余的 \(C-1\) 个块作为
    **训练集**。这个过程在图 [6.4](classification2.html#fig:06-cv-image) 中显示。在此，使用 \(C=5\) 个不同的数据集块，产生了
    5 个不同的 **验证集** 选择；我们称之为 *5 折* 交叉验证。
- en: '![5-fold cross-validation.](../Images/ca8769a0ecedf5e72670f580cd0d4f87.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![5 折交叉验证。](../Images/ca8769a0ecedf5e72670f580cd0d4f87.png)'
- en: 'Figure 6.4: 5-fold cross-validation.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4：5 折交叉验证。
- en: 'To perform 5-fold cross-validation in R with `tidymodels`, we use another function:
    `vfold_cv`. This function splits our training data into `v` folds automatically.
    We set the `strata` argument to the categorical label variable (here, `Class`)
    to ensure that the training and validation subsets contain the right proportions
    of each category of observation.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 R 中使用 `tidymodels` 执行 5 折交叉验证，我们使用另一个函数：`vfold_cv`。此函数会自动将我们的训练数据分成 `v` 折。我们将
    `strata` 参数设置为分类标签变量（在此处为 `Class`），以确保训练集和验证集包含每个观察类别正确的比例。
- en: '[PRE39]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Then, when we create our data analysis workflow, we use the `fit_resamples`
    function instead of the `fit` function for training. This runs cross-validation
    on each train/validation split.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当我们创建我们的数据分析工作流程时，我们使用 `fit_resamples` 函数而不是 `fit` 函数进行训练。这将在每个训练/验证分割上运行交叉验证。
- en: '[PRE41]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `collect_metrics` function is used to aggregate the *mean* and *standard
    error* of the classifier’s validation accuracy across the folds. You will find
    results related to the accuracy in the row with `accuracy` listed under the `.metric`
    column. You should consider the mean (`mean`) to be the estimated accuracy, while
    the standard error (`std_err`) is a measure of how uncertain we are in the mean
    value. A detailed treatment of this is beyond the scope of this chapter; but roughly,
    if your estimated mean is 0.89 and standard error is 0.02, you can expect the
    *true* average accuracy of the classifier to be somewhere roughly between 87%
    and 91% (although it may fall outside this range). You may ignore the other columns
    in the metrics data frame, as they do not provide any additional insight. You
    can also ignore the entire second row with `roc_auc` in the `.metric` column,
    as it is beyond the scope of this book.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`collect_metrics` 函数用于聚合分类器验证准确率的均值和标准误差，该准确率是跨所有折叠的。你将在 `.metric` 列下 `accuracy`
    所在的行中找到与准确率相关的结果。你应该将均值（`mean`）视为估计的准确率，而标准误差（`std_err`）是我们对均值不确定性的度量。对此的详细讨论超出了本章的范围；但大致来说，如果你的估计均值是
    0.89，标准误差是 0.02，你可以预期分类器的 *真实* 平均准确率大约在 87% 到 91% 之间（尽管它可能超出这个范围）。你可以忽略指标数据框中的其他列，因为它们不会提供任何额外的见解。你也可以忽略
    `.metric` 列中带有 `roc_auc` 的整个第二行，因为它超出了本书的范围。'
- en: '[PRE43]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We can choose any number of folds, and typically the more we use the better
    our accuracy estimate will be (lower standard error). However, we are limited
    by computational power: the more folds we choose, the more computation it takes,
    and hence the more time it takes to run the analysis. So when you do cross-validation,
    you need to consider the size of the data, the speed of the algorithm (e.g., K-nearest
    neighbors), and the speed of your computer. In practice, this is a trial-and-error
    process, but typically \(C\) is chosen to be either 5 or 10\. Here we will try
    10-fold cross-validation to see if we get a lower standard error:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择任何数量的折数，通常使用的折数越多，我们的准确率估计将越好（标准误差越低）。然而，我们受限于计算能力：我们选择的折数越多，所需的计算就越多，因此运行分析所需的时间就越长。所以当你进行交叉验证时，你需要考虑数据的大小、算法的速度（例如，K
    近邻算法）以及你电脑的速度。在实践中，这是一个试错过程，但通常 \(C\) 被选择为 5 或 10。在这里，我们将尝试 10 折交叉验证，看看我们是否能得到更低的标准误差：
- en: '[PRE45]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In this case, using 10-fold instead of 5-fold cross validation did reduce the
    standard error, although by only an insignificant amount. In fact, due to the
    randomness in how the data are split, sometimes you might even end up with a *higher*
    standard error when increasing the number of folds! We can make the reduction
    in standard error more dramatic by increasing the number of folds by a large amount.
    In the following code we show the result when \(C = 50\); picking such a large
    number of folds often takes a long time to run in practice, so we usually stick
    to 5 or 10.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，使用 10 次交叉验证而不是 5 次交叉验证确实减少了标准误差，尽管减少的量并不显著。事实上，由于数据分割的随机性，有时你甚至可能会在增加折叠次数时得到更高的标准误差！我们可以通过大量增加折叠次数来使标准误差的减少更加显著。在下面的代码中，我们展示了当
    \(C = 50\) 时的结果；在实际应用中，选择如此大的折叠次数通常需要很长时间来运行，所以我们通常坚持使用 5 或 10。
- en: '[PRE47]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 6.6.2 Parameter value selection
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.2 参数值选择
- en: Using 5- and 10-fold cross-validation, we have estimated that the prediction
    accuracy of our classifier is somewhere around 89%. Whether that is good or not
    depends entirely on the downstream application of the data analysis. In the present
    situation, we are trying to predict a tumor diagnosis, with expensive, damaging
    chemo/radiation therapy or patient death as potential consequences of misprediction.
    Hence, we might like to do better than 89% for this application.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 5 次和 10 次交叉验证，我们估计我们的分类器的预测准确率大约在 89% 左右。这好不好完全取决于数据分析的下游应用。在当前情况下，我们正在尝试预测肿瘤诊断，误预测的潜在后果是昂贵的、破坏性的化疗/放疗或患者死亡。因此，我们可能希望在这个应用中做得比
    89% 更好。
- en: 'In order to improve our classifier, we have one choice of parameter: the number
    of neighbors, \(K\). Since cross-validation helps us evaluate the accuracy of
    our classifier, we can use cross-validation to calculate an accuracy for each
    value of \(K\) in a reasonable range, and then pick the value of \(K\) that gives
    us the best accuracy. The `tidymodels` package collection provides a very simple
    syntax for tuning models: each parameter in the model to be tuned should be specified
    as `tune()` in the model specification rather than given a particular value.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高我们的分类器，我们有一个参数选择：邻居数量，\(K\)。由于交叉验证帮助我们评估分类器的准确率，我们可以使用交叉验证来计算一个合理范围内的每个
    \(K\) 值的准确率，然后选择给我们最佳准确率的 \(K\) 值。`tidymodels` 包提供了一种非常简单的语法来调整模型：在模型规范中应指定要调整的每个模型参数为
    `tune()`，而不是给出一个特定的值。
- en: '[PRE49]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Then instead of using `fit` or `fit_resamples`, we will use the `tune_grid`
    function to fit the model for each value in a range of parameter values. In particular,
    we first create a data frame with a `neighbors` variable that contains the sequence
    of values of \(K\) to try; below we create the `k_vals` data frame with the `neighbors`
    variable containing values from 1 to 100 (stepping by 5) using the `seq` function.
    Then we pass that data frame to the `grid` argument of `tune_grid`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们不会使用 `fit` 或 `fit_resamples`，而是使用 `tune_grid` 函数为参数值范围内的每个值拟合模型。特别是，我们首先创建一个包含要尝试的
    \(K\) 值序列的 `neighbors` 变量的数据框；下面我们使用 `seq` 函数创建包含从 1 到 100（步长为 5）的值的 `k_vals`
    数据框，其中包含 `neighbors` 变量。然后我们将该数据框传递给 `tune_grid` 的 `grid` 参数。
- en: '[PRE50]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We can decide which number of neighbors is best by plotting the accuracy versus
    \(K\), as shown in Figure [6.5](classification2.html#fig:06-find-k).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过绘制准确率与 \(K\) 的关系图来决定最佳邻居数量，如图 [6.5](classification2.html#fig:06-find-k)
    所示。
- en: '[PRE52]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![Plot of estimated accuracy versus the number of neighbors.](../Images/187181752c567f8f19eb118bb7a37e5a.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![估计准确率与邻居数量的关系图](../Images/187181752c567f8f19eb118bb7a37e5a.png)'
- en: 'Figure 6.5: Plot of estimated accuracy versus the number of neighbors.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5：估计准确率与邻居数量的关系图。
- en: We can also obtain the number of neighbours with the highest accuracy programmatically
    by accessing the `neighbors` variable in the `accuracies` data frame where the
    `mean` variable is highest. Note that it is still useful to visualize the results
    as we did above since this provides additional information on how the model performance
    varies.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过访问 `accuracies` 数据框中的 `neighbors` 变量，并找到 `mean` 变量最高的位置，程序化地获得具有最高准确率的邻居数量。请注意，像上面那样可视化结果仍然很有用，因为这提供了关于模型性能如何变化的额外信息。
- en: '[PRE53]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Setting the number of neighbors to \(K =\) 36 provides the highest cross-validation
    accuracy estimate (89.89%). But there is no exact or perfect answer here; any
    selection from \(K = 30\) and \(60\) would be reasonably justified, as all of
    these differ in classifier accuracy by a small amount. Remember: the values you
    see on this plot are *estimates* of the true accuracy of our classifier. Although
    the \(K =\) 36 value is higher than the others on this plot, that doesn’t mean
    the classifier is actually more accurate with this parameter value! Generally,
    when selecting \(K\) (and other parameters for other predictive models), we are
    looking for a value where:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将邻居数量设置为 \(K =\) 36 提供了最高的交叉验证准确率估计（89.89%）。但这里没有确切或完美的答案；从 \(K = 30\) 到 \(60\)
    的任何选择都是合理有据的，因为所有这些在分类器准确率上的差异都很小。记住：你在这个图表上看到的值是**估计**我们分类器真实准确率的。尽管 \(K =\)
    36 的值比这个图表上的其他值都要高，但这并不意味着分类器实际上在这个参数值下更准确！一般来说，当我们选择 \(K\)（以及其他预测模型的参数）时，我们寻找的是这样一个值：
- en: we get roughly optimal accuracy, so that our model will likely be accurate;
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们得到了大致最优的准确率，因此我们的模型很可能会准确；
- en: changing the value to a nearby one (e.g., adding or subtracting a small number)
    doesn’t decrease accuracy too much, so that our choice is reliable in the presence
    of uncertainty;
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将值更改为附近的值（例如，添加或减去一个小数）并不会太多地降低准确率，因此我们的选择在存在不确定性的情况下是可靠的；
- en: the cost of training the model is not prohibitive (e.g., in our situation, if
    \(K\) is too large, predicting becomes expensive!).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型的花费并不巨大（例如，在我们的情况下，如果 \(K\) 太大，预测就会变得昂贵！）。
- en: We know that \(K =\) 36 provides the highest estimated accuracy. Further, Figure
    [6.5](classification2.html#fig:06-find-k) shows that the estimated accuracy changes
    by only a small amount if we increase or decrease \(K\) near \(K =\) 36. And finally,
    \(K =\) 36 does not create a prohibitively expensive computational cost of training.
    Considering these three points, we would indeed select \(K =\) 36 for the classifier.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道 \(K =\) 36 提供了最高的估计准确率。此外，图 [6.5](classification2.html#fig:06-find-k) 显示，如果我们增加或减少
    \(K\) 到 \(K =\) 36 附近，估计准确率的变化量很小。最后，\(K =\) 36 并不会产生过高的训练计算成本。考虑到这三点，我们确实会选择
    \(K =\) 36 作为分类器。
- en: 6.6.3 Under/Overfitting
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.3 欠拟合/过拟合
- en: To build a bit more intuition, what happens if we keep increasing the number
    of neighbors \(K\)? In fact, the accuracy actually starts to decrease! Let’s specify
    a much larger range of values of \(K\) to try in the `grid` argument of `tune_grid`.
    Figure [6.6](classification2.html#fig:06-lots-of-ks) shows a plot of estimated
    accuracy as we vary \(K\) from 1 to almost the number of observations in the training
    set.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强一点直观感受，如果我们不断增大邻居数量 \(K\) 会发生什么？实际上，准确率实际上开始下降！让我们指定一个更大的 \(K\) 值范围来尝试在
    `tune_grid` 的 `grid` 参数中。图 [6.6](classification2.html#fig:06-lots-of-ks) 展示了当我们从
    1 变化到几乎等于训练集观察数量时，估计准确率的图表。
- en: '[PRE55]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![Plot of accuracy estimate versus number of neighbors for many K values.](../Images/fa7150d63a14234970a34fd265ddcf26.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![多个 \(K\) 值下准确率估计与邻居数量的图表。](../Images/fa7150d63a14234970a34fd265ddcf26.png)'
- en: 'Figure 6.6: Plot of accuracy estimate versus number of neighbors for many K
    values.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6：多个 \(K\) 值下准确率估计与邻居数量的图表。
- en: '**Underfitting:** What is actually happening to our classifier that causes
    this? As we increase the number of neighbors, more and more of the training observations
    (and those that are farther and farther away from the point) get a “say” in what
    the class of a new observation is. This causes a sort of “averaging effect” to
    take place, making the boundary between where our classifier would predict a tumor
    to be malignant versus benign to smooth out and become *simpler.* If you take
    this to the extreme, setting \(K\) to the total training data set size, then the
    classifier will always predict the same label regardless of what the new observation
    looks like. In general, if the model *isn’t influenced enough* by the training
    data, it is said to **underfit** the data.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**欠拟合**：我们的分类器实际上发生了什么，导致了这种情况？随着邻居数量的增加，越来越多的训练观察值（以及那些离点越来越远的观察值）对新的观察值的类别有“发言权”。这导致了一种“平均效应”的发生，使得我们的分类器预测肿瘤为恶性或良性之间的边界变得平滑并变得更加*简单*。如果你将这一点推向极端，将
    \(K\) 设置为整个训练数据集的大小，那么分类器将始终预测相同的标签，而不管新的观察值看起来如何。一般来说，如果模型*对训练数据的影响不足*，则称模型**欠拟合**数据。'
- en: '**Overfitting:** In contrast, when we decrease the number of neighbors, each
    individual data point has a stronger and stronger vote regarding nearby points.
    Since the data themselves are noisy, this causes a more “jagged” boundary corresponding
    to a *less simple* model. If you take this case to the extreme, setting \(K =
    1\), then the classifier is essentially just matching each new observation to
    its closest neighbor in the training data set. This is just as problematic as
    the large \(K\) case, because the classifier becomes unreliable on new data: if
    we had a different training set, the predictions would be completely different.
    In general, if the model *is influenced too much* by the training data, it is
    said to **overfit** the data.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合**：相反，当我们减少邻居数量时，每个单独的数据点对附近点的投票越来越强。由于数据本身是嘈杂的，这导致了一个更“锯齿状”的边界，对应于一个**更简单**的模型。如果您将这种情况推向极端，设置\(K
    = 1\)，那么分类器本质上只是将每个新的观测值与其在训练数据集中的最近邻匹配。这与大\(K\)的情况一样有问题，因为分类器对新数据变得不可靠：如果我们有一个不同的训练集，预测将完全不同。一般来说，如果模型**过度依赖于**训练数据，我们说它**过拟合**了数据。'
- en: '![Effect of K in overfitting and underfitting.](../Images/5b11e12927f71fa5f8af3cdfc1cf233e.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![K在过拟合和欠拟合中的影响。](../Images/5b11e12927f71fa5f8af3cdfc1cf233e.png)'
- en: 'Figure 6.7: Effect of K in overfitting and underfitting.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7：K在过拟合和欠拟合中的影响。
- en: Both overfitting and underfitting are problematic and will lead to a model that
    does not generalize well to new data. When fitting a model, we need to strike
    a balance between the two. You can see these two effects in Figure [6.7](classification2.html#fig:06-decision-grid-K),
    which shows how the classifier changes as we set the number of neighbors \(K\)
    to 1, 7, 20, and 300.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合和欠拟合都存在问题，会导致模型对新数据的泛化能力不佳。在拟合模型时，我们需要在这两者之间找到一个平衡点。您可以在图[6.7](classification2.html#fig:06-decision-grid-K)中看到这两个效果，该图显示了当我们设置邻居数量\(K\)为1、7、20和300时，分类器是如何变化的。
- en: 6.6.4 Evaluating on the test set
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.4 在测试集上评估
- en: Now that we have tuned the K-NN classifier and set \(K =\) 36, we are done building
    the model and it is time to evaluate the quality of its predictions on the held
    out test data, as we did earlier in Section [6.5.5](classification2.html#eval-performance-cls2).
    We first need to retrain the K-NN classifier on the entire training data set using
    the selected number of neighbors.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经调整了K-NN分类器，并设置了\(K =\) 36，我们已经完成了模型的构建，现在是时候评估其预测在保留的测试数据上的质量了，正如我们在第[6.5.5](classification2.html#eval-performance-cls2)节中做的那样。我们首先需要使用所选的邻居数量在整个训练数据集上重新训练K-NN分类器。
- en: '[PRE56]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Then to make predictions and assess the estimated accuracy of the best model
    on the test data, we use the `predict` and `metrics` functions as we did earlier
    in the chapter. We can then pass those predictions to the `precision`, `recall`,
    and `conf_mat` functions to assess the estimated precision and recall, and print
    a confusion matrix.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然后为了对测试数据上最佳模型的估计准确性进行预测和评估，我们使用与本章早期相同的方法，使用`predict`和`metrics`函数。然后我们可以将这些预测传递给`precision`、`recall`和`conf_mat`函数，以评估估计的精确度和召回率，并打印出混淆矩阵。
- en: '[PRE58]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'At first glance, this is a bit surprising: the accuracy of the classifier has
    only changed a small amount despite tuning the number of neighbors! Our first
    model with \(K =\) 3 (before we knew how to tune) had an estimated accuracy of
    85%, while the tuned model with \(K =\) 36 had an estimated accuracy of 86%. Upon
    examining Figure [6.5](classification2.html#fig:06-find-k) again to see the cross
    validation accuracy estimates for a range of neighbors, this result becomes much
    less surprising. From 1 to around 96 neighbors, the cross validation accuracy
    estimate varies only by around 3%, with each estimate having a standard error
    around 1%. Since the cross-validation accuracy estimates the test set accuracy,
    the fact that the test set accuracy also doesn’t change much is expected. Also
    note that the \(K =\) 3 model had a precision precision of 77% and recall of 87%,
    while the tuned model had a precision of 80% and recall of 83%. Given that the
    recall decreased—remember, in this application, recall is critical to making sure
    we find all the patients with malignant tumors—the tuned model may actually be
    *less* preferred in this setting. In any case, it is important to think critically
    about the result of tuning. Models tuned to maximize accuracy are not necessarily
    better for a given application.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，这有点令人惊讶：尽管调整了邻居的数量，分类器的准确度只改变了一小部分！我们最初的模型（\(K =\) 3，在我们知道如何调整之前）的估计准确度为85%，而调整后的模型（\(K
    =\) 36）的估计准确度为86%。再次查看图[6.5](classification2.html#fig:06-find-k)以查看一系列邻居的交叉验证准确度估计，这个结果就不再那么令人惊讶了。从1到大约96个邻居，交叉验证准确度估计的变化只有大约3%，每个估计的标准误差约为1%。由于交叉验证准确度估计的是测试集准确度，因此测试集准确度变化不大是预期的。此外，注意\(K
    =\) 3的模型有77%的精确度和87%的召回率，而调整后的模型有80%的精确度和83%的召回率。鉴于召回率下降——记住，在这个应用中，召回率对于确保我们找到所有患有恶性肿瘤的患者至关重要——在这个设置中，调整后的模型实际上可能更不理想。无论如何，重要的是要批判性地思考调整的结果。调整以最大化准确度的模型不一定适用于特定的应用。
- en: 6.7 Summary
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 概述
- en: Classification algorithms use one or more quantitative variables to predict
    the value of another categorical variable. In particular, the K-nearest neighbors
    algorithm does this by first finding the \(K\) points in the training data nearest
    to the new observation, and then returning the majority class vote from those
    training observations. We can tune and evaluate a classifier by splitting the
    data randomly into a training and test data set. The training set is used to build
    the classifier, and we can tune the classifier (e.g., select the number of neighbors
    in K-NN) by maximizing estimated accuracy via cross-validation. After we have
    tuned the model we can use the test set to estimate its accuracy. The overall
    process is summarized in Figure [6.8](classification2.html#fig:06-overview).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 分类算法使用一个或多个定量变量来预测另一个分类变量的值。特别是，K最近邻算法通过首先找到训练数据中与新的观测值最近的\(K\)个点，然后从这些训练观测值中返回多数类投票来实现这一点。我们可以通过将数据随机分为训练集和测试集来调整和评估分类器。训练集用于构建分类器，我们可以通过交叉验证最大化估计的准确度来调整分类器（例如，选择K-NN中的邻居数量）。在调整好模型后，我们可以使用测试集来估计其准确度。整个过程总结在图[6.8](classification2.html#fig:06-overview)中。
- en: '![Overview of K-NN classification.](../Images/0f3a8f2920c2d3af45719849eba30930.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![K-NN分类概述](../Images/0f3a8f2920c2d3af45719849eba30930.png)'
- en: 'Figure 6.8: Overview of K-NN classification.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8：K-NN分类概述。
- en: 'The overall workflow for performing K-nearest neighbors classification using
    `tidymodels` is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`tidymodels`执行K最近邻分类的整体工作流程如下：
- en: Use the `initial_split` function to split the data into a training and test
    set. Set the `strata` argument to the class label variable. Put the test set aside
    for now.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`initial_split`函数将数据分为训练集和测试集。将`strata`参数设置为类别标签变量。现在暂时将测试集放在一边。
- en: Use the `vfold_cv` function to split up the training data for cross-validation.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`vfold_cv`函数将训练数据分割用于交叉验证。
- en: Create a `recipe` that specifies the class label and predictors, as well as
    preprocessing steps for all variables. Pass the training data as the `data` argument
    of the recipe.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`recipe`，指定类别标签和预测变量，以及所有变量的预处理步骤。将训练数据作为`recipe`的`data`参数传递。
- en: Create a `nearest_neighbors` model specification, with `neighbors = tune()`.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`nearest_neighbors`模型规范，其中`neighbors = tune()`。
- en: Add the recipe and model specification to a `workflow()`, and use the `tune_grid`
    function on the train/validation splits to estimate the classifier accuracy for
    a range of \(K\) values.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将配方和模型规范添加到`workflow()`中，并在训练/验证拆分上使用`tune_grid`函数来估计不同\(K\)值范围内的分类器准确度。
- en: Pick a value of \(K\) that yields a high accuracy estimate that doesn’t change
    much if you change \(K\) to a nearby value.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个\(K\)值，它产生高准确度估计，并且当\(K\)改变到附近的值时，估计不会变化太多。
- en: Make a new model specification for the best parameter value (i.e., \(K\)), and
    retrain the classifier using the `fit` function.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为最佳参数值（即\(K\)）创建一个新的模型规范，并使用`fit`函数重新训练分类器。
- en: Evaluate the estimated accuracy of the classifier on the test set using the
    `predict` function.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`predict`函数在测试集上评估分类器的估计准确度。
- en: In these last two chapters, we focused on the K-nearest neighbors algorithm,
    but there are many other methods we could have used to predict a categorical label.
    All algorithms have their strengths and weaknesses, and we summarize these for
    the K-NN here.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两章的最后，我们专注于K近邻算法，但我们可以使用许多其他方法来预测分类标签。所有算法都有其优点和缺点，我们在这里总结了K-NN的这些特点。
- en: '**Strengths:** K-nearest neighbors classification'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：** K近邻分类'
- en: is a simple, intuitive algorithm,
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是一个简单直观的算法，
- en: requires few assumptions about what the data must look like, and
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据必须看起来像什么几乎没有假设，
- en: works for binary (two-class) and multi-class (more than 2 classes) classification
    problems.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适用于二元（两类）和多类（多于两类）分类问题。
- en: '**Weaknesses:** K-nearest neighbors classification'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**弱点：** K近邻分类'
- en: becomes very slow as the training data gets larger,
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当训练数据量增大时变得非常慢，
- en: may not perform well with a large number of predictors, and
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能不会在大量预测变量的情况下表现良好，
- en: may not perform well when classes are imbalanced.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当类别不平衡时可能表现不佳，
- en: 6.8 Predictor variable selection
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.8 预测变量选择
- en: '**Note:** This section is not required reading for the remainder of the textbook.
    It is included for those readers interested in learning how irrelevant variables
    can influence the performance of a classifier, and how to pick a subset of useful
    variables to include as predictors.'
  id: totrans-222
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 本节不是教科书其余部分的要求阅读内容。它包括给那些对学习不相关变量如何影响分类器性能以及如何选择有用的变量子集作为预测变量感兴趣的读者。'
- en: Another potentially important part of tuning your classifier is to choose which
    variables from your data will be treated as predictor variables. Technically,
    you can choose anything from using a single predictor variable to using every
    variable in your data; the K-nearest neighbors algorithm accepts any number of
    predictors. However, it is **not** the case that using more predictors always
    yields better predictions! In fact, sometimes including irrelevant predictors
    can actually negatively affect classifier performance.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 调整你的分类器时，另一个可能重要的部分是选择你的数据中哪些变量将被视为预测变量。技术上，你可以从使用单个预测变量到使用数据中的每一个变量进行选择；K近邻算法接受任何数量的预测变量。然而，使用更多预测变量并不总是能带来更好的预测！实际上，有时包括不相关预测变量可能会实际上对分类器性能产生负面影响。
- en: 6.8.1 The effect of irrelevant predictors
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.8.1 不相关预测变量的影响
- en: Let’s take a look at an example where K-nearest neighbors performs worse when
    given more predictors to work with. In this example, we modified the breast cancer
    data to have only the `Smoothness`, `Concavity`, and `Perimeter` variables from
    the original data. Then, we added irrelevant variables that we created ourselves
    using a random number generator. The irrelevant variables each take a value of
    0 or 1 with equal probability for each observation, regardless of what the value
    `Class` variable takes. In other words, the irrelevant variables have no meaningful
    relationship with the `Class` variable.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子，其中K近邻算法在给定更多预测变量时表现更差。在这个例子中，我们将乳腺癌数据修改为仅包含原始数据中的`Smoothness`、`Concavity`和`Perimeter`变量。然后，我们添加了我们自己使用随机数生成器创建的不相关变量。这些不相关变量对于每个观测值，其值为0或1的概率相等，无论`Class`变量的值如何。换句话说，不相关变量与`Class`变量之间没有有意义的关联。
- en: '[PRE66]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Next, we build a sequence of K-NN classifiers that include `Smoothness`, `Concavity`,
    and `Perimeter` as predictor variables, but also increasingly many irrelevant
    variables. In particular, we create 6 data sets with 0, 5, 10, 15, 20, and 40
    irrelevant predictors. Then we build a model, tuned via 5-fold cross-validation,
    for each data set. Figure [6.9](classification2.html#fig:06-performance-irrelevant-features)
    shows the estimated cross-validation accuracy versus the number of irrelevant
    predictors. As we add more irrelevant predictor variables, the estimated accuracy
    of our classifier decreases. This is because the irrelevant variables add a random
    amount to the distance between each pair of observations; the more irrelevant
    variables there are, the more (random) influence they have, and the more they
    corrupt the set of nearest neighbors that vote on the class of the new observation
    to predict.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们构建了一系列包含`平滑度`、`凹度`和`周长`作为预测变量的K-NN分类器，同时也包含越来越多的无关变量。特别是，我们创建了包含0、5、10、15、20和40个无关预测因子的6个数据集。然后，我们为每个数据集构建了一个通过5折交叉验证调整的模型。图[6.9](classification2.html#fig:06-performance-irrelevant-features)显示了估计的交叉验证准确率与无关预测因子数量的关系。随着我们添加更多的无关预测变量，我们分类器的估计准确率下降。这是因为无关变量会给每对观测值之间的距离添加一个随机量；无关变量越多，它们的影响就越大，也就越容易破坏对新观测值进行类别预测的最近邻集。
- en: '![Effect of inclusion of irrelevant predictors.](../Images/e5f68f307c94bcbde59f3a8cfc654dab.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![包含无关预测因子的影响。](../Images/e5f68f307c94bcbde59f3a8cfc654dab.png)'
- en: 'Figure 6.9: Effect of inclusion of irrelevant predictors.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9：包含无关预测因子的影响。
- en: 'Although the accuracy decreases as expected, one surprising thing about Figure
    [6.9](classification2.html#fig:06-performance-irrelevant-features) is that it
    shows that the method still outperforms the baseline majority classifier (with
    about 63% accuracy) even with 40 irrelevant variables. How could that be? Figure
    [6.10](classification2.html#fig:06-neighbors-irrelevant-features) provides the
    answer: the tuning procedure for the K-nearest neighbors classifier combats the
    extra randomness from the irrelevant variables by increasing the number of neighbors.
    Of course, because of all the extra noise in the data from the irrelevant variables,
    the number of neighbors does not increase smoothly; but the general trend is increasing.
    Figure [6.11](classification2.html#fig:06-fixed-irrelevant-features) corroborates
    this evidence; if we fix the number of neighbors to \(K=3\), the accuracy falls
    off more quickly.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然准确率如预期的那样下降，但图[6.9](classification2.html#fig:06-performance-irrelevant-features)中一个令人惊讶的事情是它显示，即使在有40个无关变量的情况下，该方法仍然优于基线多数分类器（准确率约为63%）。这怎么可能呢？图[6.10](classification2.html#fig:06-neighbors-irrelevant-features)提供了答案：K-近邻分类器的调整过程通过增加邻居的数量来对抗无关变量带来的额外随机性。当然，由于无关变量带来的所有额外噪声，邻居的数量不会平滑地增加；但总体趋势是增加的。图[6.11](classification2.html#fig:06-fixed-irrelevant-features)证实了这一证据；如果我们把邻居的数量固定为\(K=3\)，准确率会更快地下降。
- en: '![Tuned number of neighbors for varying number of irrelevant predictors.](../Images/5bd989604db5567393c807a526dd2a53.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![不同数量无关预测因子下的调整邻居数量。](../Images/5bd989604db5567393c807a526dd2a53.png)'
- en: 'Figure 6.10: Tuned number of neighbors for varying number of irrelevant predictors.
    ![Accuracy versus number of irrelevant predictors for tuned and untuned number
    of neighbors.](../Images/fe1627bce54b1cedbe6b3a80c20440a5.png)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10：不同数量无关预测因子下的调整邻居数量。![调整和未调整邻居数量的准确率与无关预测因子数量之间的关系。](../Images/fe1627bce54b1cedbe6b3a80c20440a5.png)
- en: 'Figure 6.11: Accuracy versus number of irrelevant predictors for tuned and
    untuned number of neighbors.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11：调整和未调整邻居数量的准确率与无关预测因子数量之间的关系。
- en: 6.8.2 Finding a good subset of predictors
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.8.2 寻找一组好的预测变量子集
- en: So then, if it is not ideal to use all of our variables as predictors without
    consideration, how do we choose which variables we *should* use? A simple method
    is to rely on your scientific understanding of the data to tell you which variables
    are not likely to be useful predictors. For example, in the cancer data that we
    have been studying, the `ID` variable is just a unique identifier for the observation.
    As it is not related to any measured property of the cells, the `ID` variable
    should therefore not be used as a predictor. That is, of course, a very clear-cut
    case. But the decision for the remaining variables is less obvious, as all seem
    like reasonable candidates. It is not clear which subset of them will create the
    best classifier. One could use visualizations and other exploratory analyses to
    try to help understand which variables are potentially relevant, but this process
    is both time-consuming and error-prone when there are many variables to consider.
    Therefore we need a more systematic and programmatic way of choosing variables.
    This is a very difficult problem to solve in general, and there are a number of
    methods that have been developed that apply in particular cases of interest. Here
    we will discuss two basic selection methods as an introduction to the topic. See
    the additional resources at the end of this chapter to find out where you can
    learn more about variable selection, including more advanced methods.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果我们不考虑理想情况，使用所有变量作为预测因子，这显然是不理想的，我们应该如何选择我们**应该**使用的变量呢？一个简单的方法是依靠你对数据的科学理解来判断哪些变量不太可能是有用的预测因子。例如，在我们一直在研究的癌症数据中，`ID`变量只是观察的一个唯一标识符。由于它与细胞测量的任何属性无关，因此`ID`变量不应作为预测因子使用。当然，这是一个非常明确的情况。但剩余变量的选择则不那么明显，因为它们似乎都是合理的候选人。不清楚哪个子集将创建最佳的分类器。人们可以使用可视化和其他探索性分析来尝试帮助理解哪些变量可能是相关的，但这个过程在考虑许多变量时既耗时又容易出错。因此，我们需要一种更系统和程序化的方法来选择变量。在一般情况下，这是一个非常难以解决的问题，已经开发出许多适用于特定感兴趣情况的方法。在这里，我们将讨论两种基本选择方法，作为对这个主题的介绍。请参阅本章末尾的附加资源，以了解您可以在哪里了解更多关于变量选择的信息，包括更高级的方法。
- en: The first idea you might think of for a systematic way to select predictors
    is to try all possible subsets of predictors and then pick the set that results
    in the “best” classifier. This procedure is indeed a well-known variable selection
    method referred to as *best subset selection* ([Beale, Kendall, and Mann 1967](#ref-bealesubset);
    [Hocking and Leslie 1967](#ref-hockingsubset)). In particular, you
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想到的第一个用于系统选择预测因子的方法是尝试所有可能的预测因子子集，然后选择导致“最佳”分类器的集合。这种方法确实是一种众所周知的变量选择方法，被称为**最佳子集选择**（[Beale,
    Kendall, and Mann 1967](#ref-bealesubset); [Hocking and Leslie 1967](#ref-hockingsubset)）。特别是，你
- en: create a separate model for every possible subset of predictors,
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个可能的预测因子子集创建一个单独的模型。
- en: tune each one using cross-validation, and
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用交叉验证调整每一个，
- en: pick the subset of predictors that gives you the highest cross-validation accuracy.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择给出最高交叉验证准确率的预测因子子集。
- en: 'Best subset selection is applicable to any classification method (K-NN or otherwise).
    However, it becomes very slow when you have even a moderate number of predictors
    to choose from (say, around 10). This is because the number of possible predictor
    subsets grows very quickly with the number of predictors, and you have to train
    the model (itself a slow process!) for each one. For example, if we have 2 predictors—let’s
    call them A and B—then we have 3 variable sets to try: A alone, B alone, and finally
    A and B together. If we have 3 predictors—A, B, and C—then we have 7 to try: A,
    B, C, AB, BC, AC, and ABC. In general, the number of models we have to train for
    \(m\) predictors is \(2^m-1\); in other words, when we get to 10 predictors we
    have over *one thousand* models to train, and at 20 predictors we have over *one
    million* models to train! So although it is a simple method, best subset selection
    is usually too computationally expensive to use in practice.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳子集选择适用于任何分类方法（K-NN或其他）。然而，当你有相当数量的预测变量可供选择时（比如说，大约10个），它就会变得非常慢。这是因为可能的预测变量子集的数量会随着预测变量数量的增加而迅速增长，你必须为每一个子集训练模型（这本身就是一个缓慢的过程！）。例如，如果我们有2个预测变量——让我们称它们为A和B——那么我们有3个变量集要尝试：只有A，只有B，最后是A和B一起。如果我们有3个预测变量——A，B和C——那么我们有7个要尝试：A，B，C，AB，BC，AC和ABC。一般来说，我们需要为\(m\)个预测变量训练的模型数量是\(2^m-1\)；换句话说，当我们达到10个预测变量时，我们需要训练超过*一千*个模型，而当有20个预测变量时，我们需要训练超过*一百万*个模型！所以尽管这是一个简单的方法，但最佳子集选择通常在实践中的计算成本太高，难以使用。
- en: 'Another idea is to iteratively build up a model by adding one predictor variable
    at a time. This method—known as *forward selection* ([Eforymson 1966](#ref-forwardefroymson);
    [Draper and Smith 1966](#ref-forwarddraper))—is also widely applicable and fairly
    straightforward. It involves the following steps:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个想法是通过每次添加一个预测变量来迭代构建模型。这种方法——称为*前向选择*（[Eforymson 1966](#ref-forwardefroymson)；[Draper
    and Smith 1966](#ref-forwarddraper)）——也适用范围广泛，相当直接。它包括以下步骤：
- en: Start with a model having no predictors.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个没有预测变量的模型开始。
- en: 'Run the following 3 steps until you run out of predictors:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下3个步骤，直到没有预测变量为止：
- en: For each unused predictor, add it to the model to form a *candidate model*.
  id: totrans-245
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个未使用的预测变量，将其添加到模型中，形成一个*候选模型*。
- en: Tune all of the candidate models.
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整所有候选模型。
- en: Update the model to be the candidate model with the highest cross-validation
    accuracy.
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新模型，使其成为具有最高交叉验证精度的候选模型。
- en: Select the model that provides the best trade-off between accuracy and simplicity.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择在精度和简单性之间提供最佳权衡的模型。
- en: Say you have \(m\) total predictors to work with. In the first iteration, you
    have to make \(m\) candidate models, each with 1 predictor. Then in the second
    iteration, you have to make \(m-1\) candidate models, each with 2 predictors (the
    one you chose before and a new one). This pattern continues for as many iterations
    as you want. If you run the method all the way until you run out of predictors
    to choose, you will end up training \(\frac{1}{2}m(m+1)\) separate models. This
    is a *big* improvement from the \(2^m-1\) models that best subset selection requires
    you to train! For example, while best subset selection requires training over
    1000 candidate models with 10 predictors, forward selection requires training
    only 55 candidate models. Therefore we will continue the rest of this section
    using forward selection.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有\(m\)个总的预测变量可供使用。在第一次迭代中，你必须制作\(m\)个候选模型，每个模型有1个预测变量。然后在第二次迭代中，你必须制作\(m-1\)个候选模型，每个模型有2个预测变量（你之前选择的那个和一个新的）。这种模式会持续进行，直到你想要进行多少次迭代。如果你将这种方法一直运行到没有可供选择的预测变量为止，你最终将训练\(\frac{1}{2}m(m+1)\)个单独的模型。这比最佳子集选择要求的\(2^m-1\)个模型是一个巨大的改进！例如，最佳子集选择需要训练超过1000个候选模型，而前向选择只需要训练55个候选模型。因此，我们将继续使用前向选择来展开本节的其余部分。
- en: '**Note:** One word of caution before we move on. Every additional model that
    you train increases the likelihood that you will get unlucky and stumble on a
    model that has a high cross-validation accuracy estimate, but a low true accuracy
    on the test data and other future observations. Since forward selection involves
    training a lot of models, you run a fairly high risk of this happening. To keep
    this risk low, only use forward selection when you have a large amount of data
    and a relatively small total number of predictors. More advanced methods do not
    suffer from this problem as much; see the additional resources at the end of this
    chapter for where to learn more about advanced predictor selection methods.'
  id: totrans-250
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 在我们继续前进之前，有一个警告需要提醒。你训练的每一个额外模型都会增加你运气不佳并偶然发现一个交叉验证准确度估计很高，但在测试数据和未来观察中真实准确度却很低的风险。由于前向选择涉及训练大量模型，你发生这种情况的风险相当高。为了将这种风险降到最低，只有在你拥有大量数据并且预测因子总数相对较小的情况下才使用前向选择。更高级的方法受此问题的影响较小；关于更高级预测因子选择方法的更多信息，请参阅本章末尾的附加资源。'
- en: 6.8.3 Forward selection in R
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.8.3 R中的前向选择
- en: We now turn to implementing forward selection in R. Unfortunately there is no
    built-in way to do this using the `tidymodels` framework, so we will have to code
    it ourselves. First we will use the `select` function to extract a smaller set
    of predictors to work with in this illustrative example—`Smoothness`, `Concavity`,
    `Perimeter`, `Irrelevant1`, `Irrelevant2`, and `Irrelevant3`—as well as the `Class`
    variable as the label. We will also extract the column names for the full set
    of predictors.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们转向在R中实现前向选择。不幸的是，使用`tidymodels`框架没有内置的方法来做这件事，所以我们将不得不自己编写代码。首先，我们将使用`select`函数提取一个较小的预测因子集来在这个示例中使用——`Smoothness`、`Concavity`、`Perimeter`、`Irrelevant1`、`Irrelevant2`和`Irrelevant3`——以及`Class`变量作为标签。我们还将提取所有预测因子的列名。
- en: '[PRE68]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The key idea of the forward selection code is to use the `paste` function (which
    concatenates strings separated by spaces) to create a model formula for each subset
    of predictors for which we want to build a model. The `collapse` argument tells
    `paste` what to put between the items in the list; to make a formula, we need
    to put a `+` symbol between each variable. As an example, let’s make a model formula
    for all the predictors, which should output something like `Class ~ Smoothness
    + Concavity + Perimeter + Irrelevant1 + Irrelevant2 + Irrelevant3`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前向选择代码的关键思想是使用`paste`函数（它将用空格分隔的字符串连接起来）为我们要构建模型的每个预测因子子集创建一个模型公式。`collapse`参数告诉`paste`在列表项之间放置什么；为了创建一个公式，我们需要在变量之间放置一个`+`符号。作为一个例子，让我们为所有预测因子创建一个模型公式，它应该输出类似`Class
    ~ Smoothness + Concavity + Perimeter + Irrelevant1 + Irrelevant2 + Irrelevant3`的内容：
- en: '[PRE70]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Finally, we need to write some code that performs the task of sequentially
    finding the best predictor to add to the model. If you recall the end of the wrangling
    chapter, we mentioned that sometimes one needs more flexible forms of iteration
    than what we have used earlier, and in these cases one typically resorts to a
    *for loop*; see [the chapter on iteration](https://r4ds.had.co.nz/iteration.html)
    in *R for Data Science* ([Wickham and Grolemund 2016](#ref-wickham2016r)). Here
    we will use two for loops: one over increasing predictor set sizes (where you
    see `for (i in 1:length(names))` below), and another to check which predictor
    to add in each round (where you see `for (j in 1:length(names))` below). For each
    set of predictors to try, we construct a model formula, pass it into a `recipe`,
    build a `workflow` that tunes a K-NN classifier using 5-fold cross-validation,
    and finally records the estimated accuracy.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要编写一些代码来执行逐个寻找最佳预测因子添加到模型中的任务。如果你还记得整理章节的结尾，我们提到有时需要比我们之前使用的更灵活的迭代形式，在这些情况下，人们通常求助于一个*for循环*；请参阅*《R
    for Data Science》*中的[迭代章节](https://r4ds.had.co.nz/iteration.html)（Wickham和Grolemund
    2016）。在这里，我们将使用两个for循环：一个用于增加预测因子集的大小（下面可以看到`for (i in 1:length(names))`），另一个用于检查每一轮要添加哪个预测因子（下面可以看到`for
    (j in 1:length(names))`）。对于要尝试的每个预测因子集，我们构建一个模型公式，将其传递给一个`recipe`，构建一个使用5折交叉验证调整K-NN分类器的`workflow`，并最终记录估计的准确度。
- en: '[PRE72]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Interesting! The forward selection procedure first added the three meaningful
    variables `Perimeter`, `Concavity`, and `Smoothness`, followed by the irrelevant
    variables. Figure [6.12](classification2.html#fig:06-fwdsel-3) visualizes the
    accuracy versus the number of predictors in the model. You can see that as meaningful
    predictors are added, the estimated accuracy increases substantially; and as you
    add irrelevant variables, the accuracy either exhibits small fluctuations or decreases
    as the model attempts to tune the number of neighbors to account for the extra
    noise. In order to pick the right model from the sequence, you have to balance
    high accuracy and model simplicity (i.e., having fewer predictors and a lower
    chance of overfitting). The way to find that balance is to look for the *elbow*
    in Figure [6.12](classification2.html#fig:06-fwdsel-3), i.e., the place on the
    plot where the accuracy stops increasing dramatically and levels off or begins
    to decrease. The elbow in Figure [6.12](classification2.html#fig:06-fwdsel-3)
    appears to occur at the model with 3 predictors; after that point the accuracy
    levels off. So here the right trade-off of accuracy and number of predictors occurs
    with 3 variables: `Class ~ Perimeter + Concavity + Smoothness`. In other words,
    we have successfully removed irrelevant predictors from the model! It is always
    worth remembering, however, that what cross-validation gives you is an *estimate*
    of the true accuracy; you have to use your judgement when looking at this plot
    to decide where the elbow occurs, and whether adding a variable provides a meaningful
    increase in accuracy.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 好奇！前向选择过程首先添加了三个有意义的变量 `Perimeter`（周长）、`Concavity`（凹度）和 `Smoothness`（平滑度），然后是无关变量。图
    [6.12](classification2.html#fig:06-fwdsel-3) 可视化了模型中预测变量数量与准确率之间的关系。你可以看到，随着有意义的预测变量的添加，估计的准确率显著提高；而当你添加无关变量时，准确率要么表现出小幅波动，要么随着模型尝试调整邻居数量以解释额外的噪声而下降。为了从序列中挑选出合适的模型，你必须平衡高准确率和模型简单性（即拥有更少的预测变量和更低的过拟合风险）。找到这种平衡的方法是寻找图
    [6.12](classification2.html#fig:06-fwdsel-3) 中的 *肘部*，即图表上准确率停止急剧增加并趋于平稳或开始下降的位置。图
    [6.12](classification2.html#fig:06-fwdsel-3) 中的肘部似乎出现在具有 3 个预测变量的模型处；在此之后，准确率趋于平稳。因此，在这里，准确率和预测变量数量的最佳权衡发生在
    3 个变量上：`Class ~ Perimeter + Concavity + Smoothness`。换句话说，我们已经成功从模型中移除了无关的预测变量！然而，始终值得记住的是，交叉验证给你提供的是对真实准确率的
    *估计*；在查看此图表时，你必须运用你的判断力来决定肘部的位置，以及添加变量是否提供了有意义的准确率提升。
- en: '![Estimated accuracy versus the number of predictors for the sequence of models
    built using forward selection.](../Images/fd37471907f6190ab0e281d40a01674e.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![使用前向选择构建的模型序列的预测变量数量与估计准确率的关系图](../Images/fd37471907f6190ab0e281d40a01674e.png)'
- en: 'Figure 6.12: Estimated accuracy versus the number of predictors for the sequence
    of models built using forward selection.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12：使用前向选择构建的模型序列的预测变量数量与估计准确率的关系图
- en: '**Note:** Since the choice of which variables to include as predictors is part
    of tuning your classifier, you *cannot use your test data* for this process!'
  id: totrans-264
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 由于选择哪些变量作为预测变量是调整你的分类器的一部分，因此你 *不能使用你的测试数据* 进行此过程！'
- en: 6.9 Exercises
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.9 练习
- en: 'Practice exercises for the material covered in this chapter can be found in
    the accompanying [worksheets repository](https://worksheets.datasciencebook.ca)
    in the “Classification II: evaluation and tuning” row. You can launch an interactive
    version of the worksheet in your browser by clicking the “launch binder” button.
    You can also preview a non-interactive version of the worksheet by clicking “view
    worksheet.” If you instead decide to download the worksheet and run it on your
    own machine, make sure to follow the instructions for computer setup found in
    Chapter [13](setup.html#setup). This will ensure that the automated feedback and
    guidance that the worksheets provide will function as intended.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的练习可以在配套的 [worksheets 仓库](https://worksheets.datasciencebook.ca) 中找到，位于“分类
    II：评估和调整”行。你可以通过点击“launch binder”按钮在你的浏览器中启动工作表的交互式版本。你也可以通过点击“view worksheet”预览工作表的非交互式版本。如果你决定下载工作表并在自己的机器上运行它，请确保遵循第
    [13](setup.html#setup) 章中找到的计算机设置说明。这将确保工作表提供的自动反馈和指导按预期工作。
- en: 6.10 Additional resources
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.10 补充资源
- en: The [`tidymodels` website](https://tidymodels.org/packages) is an excellent
    reference for more details on, and advanced usage of, the functions and packages
    in the past two chapters. Aside from that, it also has a [nice beginner’s tutorial](https://www.tidymodels.org/start/)
    and [an extensive list of more advanced examples](https://www.tidymodels.org/learn/)
    that you can use to continue learning beyond the scope of this book. It’s worth
    noting that the `tidymodels` package does a lot more than just classification,
    and so the examples on the website similarly go beyond classification as well.
    In the next two chapters, you’ll learn about another kind of predictive modeling
    setting, so it might be worth visiting the website only after reading through
    those chapters.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`tidymodels` 网站](https://tidymodels.org/packages) 是了解前两章中函数和包的更多细节以及高级使用的优秀参考。除此之外，它还有一个[优秀的入门教程](https://www.tidymodels.org/start/)和[一个广泛的更高级示例列表](https://www.tidymodels.org/learn/)，你可以使用这些示例在本书范围之外继续学习。值得注意的是，`tidymodels`
    包不仅仅用于分类，因此网站上的示例也超出了分类的范围。在接下来的两章中，你将学习另一种预测建模设置，因此你可能只在这些章节阅读完毕后再访问该网站。'
- en: '*An Introduction to Statistical Learning* ([James et al. 2013](#ref-james2013introduction))
    provides a great next stop in the process of learning about classification. Chapter
    4 discusses additional basic techniques for classification that we do not cover,
    such as logistic regression, linear discriminant analysis, and naive Bayes. Chapter
    5 goes into much more detail about cross-validation. Chapters 8 and 9 cover decision
    trees and support vector machines, two very popular but more advanced classification
    methods. Finally, Chapter 6 covers a number of methods for selecting predictor
    variables. Note that while this book is still a very accessible introductory text,
    it requires a bit more mathematical background than we require.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《统计学习引论》* ([James 等人 2013](#ref-james2013introduction)) 在学习分类的过程中提供了一个很好的下一步。第四章讨论了分类的附加基本技术，这些技术我们没有涉及，例如逻辑回归、线性判别分析和朴素贝叶斯。第五章深入探讨了交叉验证。第八章和第九章涵盖了决策树和支持向量机，这两种非常流行但更高级的分类方法。最后，第六章介绍了选择预测变量的多种方法。请注意，尽管这本书仍然是一本非常易于理解的入门教材，但它比我们要求的数学背景要深一些。'
- en: References
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Beale, Evelyn Martin Lansdowne, Maurice George Kendall, and David Mann. 1967\.
    “The Discarding of Variables in Multivariate Analysis.” *Biometrika* 54 (3-4):
    357–66.Draper, Norman, and Harry Smith. 1966\. *Applied Regression Analysis*.
    Wiley.Eforymson, M. 1966\. “Stepwise Regression—a Backward and Forward Look.”
    In *Eastern Regional Meetings of the Institute of Mathematical Statistics*.Hocking,
    Ronald, and R. N. Leslie. 1967\. “Selection of the Best Subset in Regression Analysis.”
    *Technometrics* 9 (4): 531–40.James, Gareth, Daniela Witten, Trevor Hastie, and
    Robert Tibshirani. 2013\. *An Introduction to Statistical Learning*. 1st ed. Springer.
    [https://www.statlearning.com/](https://www.statlearning.com/).Street, William
    Nick, William Wolberg, and Olvi Mangasarian. 1993\. “Nuclear Feature Extraction
    for Breast Tumor Diagnosis.” In *International Symposium on Electronic Imaging:
    Science and Technology*.Wickham, Hadley, and Garrett Grolemund. 2016\. *R for
    Data Science: Import, Tidy, Transform, Visualize, and Model Data*. O’Reilly. [https://r4ds.had.co.nz/](https://r4ds.had.co.nz/).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 'Beale, Evelyn Martin Lansdowne, Maurice George Kendall, 和 David Mann. 1967.
    “多变量分析中变量的剔除。” *Biometrika* 54 (3-4): 357–66. Draper, Norman 和 Harry Smith. 1966.
    *应用回归分析*. Wiley. Eforymson, M. 1966. “逐步回归——回顾过去和未来。” 在 *数学统计学会东部区域会议* 中。Hocking,
    Ronald 和 R. N. Leslie. 1967. “回归分析中选择最佳子集。” *Technometrics* 9 (4): 531–40. James,
    Gareth, Daniela Witten, Trevor Hastie 和 Robert Tibshirani. 2013. *统计学习引论*. 第1版.
    Springer. [https://www.statlearning.com/](https://www.statlearning.com/). Street,
    William Nick, William Wolberg 和 Olvi Mangasarian. 1993. “用于乳腺肿瘤诊断的核特征提取。” 在 *国际电子成像：科学和技术研讨会*
    中。Wickham, Hadley 和 Garrett Grolemund. 2016. *R语言数据科学：导入、整理、转换、可视化和建模数据*. O’Reilly.
    [https://r4ds.had.co.nz/](https://r4ds.had.co.nz/).'
