- en: Memory-Level Parallelism
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存级并行性
- en: 原文：[https://en.algorithmica.org/hpc/cpu-cache/mlp/](https://en.algorithmica.org/hpc/cpu-cache/mlp/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/cpu-cache/mlp/](https://en.algorithmica.org/hpc/cpu-cache/mlp/)
- en: 'Memory requests can overlap in time: while you wait for a read request to complete,
    you can send a few others, which will be executed concurrently with it. This is
    the main reason why [linear iteration](../bandwidth) is so much faster than [pointer
    jumping](../latency): the CPU knows which memory locations it needs to fetch next
    and sends memory requests far ahead of time.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 内存请求可以在时间上重叠：当您等待读取请求完成时，您可以发送几个其他请求，这些请求将与它并发执行。这是为什么[线性迭代](../bandwidth)比[指针跳跃](../latency)快得多的主要原因：CPU知道它需要获取下一个内存位置，并且会提前发送内存请求。
- en: The number of concurrent memory operations is large but limited, and it is different
    for different types of memory. When designing algorithms and especially data structures,
    you may want to know this number, as it limits the amount of parallelism your
    computation can achieve.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 并发的内存操作数量很大但有限，并且对于不同类型的内存来说各不相同。在设计算法和特别是数据结构时，您可能想知道这个数字，因为它限制了您的计算可以实现的并行程度。
- en: 'To find this limit theoretically for a specific memory type, you can multiply
    its latency (time to fetch a cache line) by its bandwidth (number of cache lines
    fetched per second), which gives you the average number of memory operations in
    progress:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 要理论上找到特定内存类型的这个极限，您可以将其延迟（获取缓存行的耗时）乘以其带宽（每秒获取的缓存行数），这将给出平均内存操作数：
- en: '![](../Images/140f45accd593c65f4ed6d9695db7d77.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/140f45accd593c65f4ed6d9695db7d77.png)'
- en: The latency of the L1/L2 caches is small, so there is no need for a long pipeline
    of pending requests, but larger memory types can sustain up to 25-40 concurrent
    read operations.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: L1/L2缓存的延迟很小，因此不需要一个长的待处理请求管道，但较大的内存类型可以支持高达25-40个并发读取操作。
- en: '### [#](https://en.algorithmica.org/hpc/cpu-cache/mlp/#direct-experiment)Direct
    Experiment'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/cpu-cache/mlp/#direct-experiment)直接实验'
- en: 'Let’s try to measure available memory parallelism more directly by modifying
    our pointer chasing benchmark so that we loop around $D$ separate cycles in parallel
    instead of just one:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过修改我们的指针追踪基准测试来更直接地测量可用的内存并行性，这样我们就可以并行地循环$D$个不同的周期，而不是只循环一个：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Fixing the sum of the cycle lengths constant at a few select sizes and trying
    different $D$, we get slightly different results:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 将周期长度的总和固定在几个选定的大小，并尝试不同的$D$，我们得到略微不同的结果：
- en: '![](../Images/6d0a280245a088fb7de18b7aa488862e.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d0a280245a088fb7de18b7aa488862e.png)'
- en: 'The L2 cache run is limited by ~6 concurrent operations, as predicted, but
    larger memory types all max out between 13 and 17\. You can’t make use of more
    memory lanes as there is a conflict over logical registers. When the number of
    lanes is fewer than the number of registers, you can issue just one read instruction
    per lane:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如预测的那样，L2缓存的运行受到大约6个并发操作的限制，但较大的内存类型都在13到17之间达到最大值。由于逻辑寄存器存在冲突，您无法利用更多的内存通道。当通道数少于寄存器数时，您每条通道只能发出一个读取指令：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'But when it is over ~15, you have to use temporary memory storage:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但当超过15时，您必须使用临时内存存储：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You don’t always get to the maximum possible level of memory parallelism, but
    for most applications, a dozen concurrent requests are more than enough. [← Memory
    Sharing](https://en.algorithmica.org/hpc/cpu-cache/sharing/)[Prefetching →](https://en.algorithmica.org/hpc/cpu-cache/prefetching/)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您并不总是能达到最大可能的内存并行级别，但对于大多数应用来说，十二个并发请求已经足够多了。[←内存共享](https://en.algorithmica.org/hpc/cpu-cache/sharing/)[预取→](https://en.algorithmica.org/hpc/cpu-cache/prefetching/)
