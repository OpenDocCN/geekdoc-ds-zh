- en: 10  Store and share
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10  存储和共享
- en: 原文：[https://tellingstorieswithdata.com/10-store_and_share.html](https://tellingstorieswithdata.com/10-store_and_share.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://tellingstorieswithdata.com/10-store_and_share.html](https://tellingstorieswithdata.com/10-store_and_share.html)
- en: '[Preparation](./09-clean_and_prepare.html)'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[准备](./09-clean_and_prepare.html)'
- en: '[10  Store and share](./10-store_and_share.html)'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[10  存储和共享](./10-store_and_share.html)'
- en: '**Prerequisites**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**先决条件**'
- en: Read *Promoting Open Science Through Research Data Management*, ([Borghi and
    Van Gulick 2022](99-references.html#ref-Borghi2022Promoting))
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *通过研究数据管理促进开放科学* ([Borghi 和 Van Gulick 2022](99-references.html#ref-Borghi2022Promoting))
- en: Describes the state of data management, and some strategies for conducting research
    that is more reproducible.
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述了数据管理状态，以及进行更可重复研究的某些策略。
- en: Read *Data Management in Large-Scale Education Research*, ([Lewis 2024](99-references.html#ref-lewiscrystal))
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *大规模教育研究中的数据管理* ([Lewis 2024](99-references.html#ref-lewiscrystal))
- en: Focus on Chapter 2 “Research Data Management”, which provides an overview of
    data management concerns, workflow, and terminology.
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重点关注第二章“研究数据管理”，该章节概述了数据管理的关注点、工作流程和术语。
- en: Read *Transparent and reproducible social science research*, ([Christensen,
    Freese, and Miguel 2019](99-references.html#ref-christensen2019transparent))
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *透明和可重复的社会科学研究* ([Christensen, Freese, 和 Miguel 2019](99-references.html#ref-christensen2019transparent))
- en: Focus on Chapter 10 “Data Sharing”, which specifies ways to share data.
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重点关注第十章“数据共享”，该章节指定了共享数据的方式。
- en: Read *Datasheets for datasets*, ([Gebru et al. 2021](99-references.html#ref-gebru2021datasheets))
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *数据集的数据表* ([Gebru 等人 2021](99-references.html#ref-gebru2021datasheets))
- en: Introduces the idea of a datasheet.
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍了数据表的概念。
- en: 'Read *Data and its (dis)contents: A survey of dataset development and use in
    machine learning research*, ([Paullada et al. 2021](99-references.html#ref-Paullada2021))'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 *数据及其（不）内容：机器学习研究中的数据集开发和使用调查* ([Paullada 等人 2021](99-references.html#ref-Paullada2021))
- en: Details the state of data in machine learning.
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细说明了机器学习中数据的状态。
- en: '**Key concepts and skills**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键概念和技能**'
- en: The FAIR principles provide the foundation from which we consider data sharing
    and storage. These specify that data should be findable, accessible, interoperable,
    and reusable.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FAIR 原则为我们考虑数据共享和存储提供了基础。这些原则规定数据应该是可查找的、可访问的、可互操作的和可重用的。
- en: The most important step is the first one, and that is to get the data off our
    local computer, and to then make it accessible by others. After that, we build
    documentation, and datasheets, to make it easier for others to understand and
    use it. Finally, we ideally enable access without our involvement.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最重要的一步是第一步，那就是将数据从我们的本地计算机上移除，并使其对他人可访问。之后，我们建立文档和数据表，以便他人更容易理解和使用它。最后，我们理想情况下是在不涉及我们的情况下启用访问。
- en: At the same time as wanting to share our datasets as widely as possible, we
    should respect those whose information are contained in them. This means, for
    instance, protecting, to a reasonable extent, and informed by costs and benefits,
    personally identifying information through selective disclosure, hashing, data
    simulation, and differential privacy.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在尽可能广泛地共享我们的数据集的同时，我们应该尊重那些包含在其中的信息所有者。这意味着，例如，通过选择性披露、哈希、数据模拟和差分隐私，在合理的范围内保护个人识别信息，并考虑成本和收益。
- en: Finally, as our data get larger, approaches that were viable when they were
    smaller start to break down. We need to consider efficiency, and explore other
    approaches, formats, and languages.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，随着我们的数据量增大，当它们较小时可行的方案开始崩溃。我们需要考虑效率，并探索其他方法、格式和语言。
- en: '**Software and packages**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**软件和包**'
- en: Base R ([R Core Team 2024](99-references.html#ref-citeR))
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Base R ([R 核心团队 2024](99-references.html#ref-citeR))
- en: '`arrow` ([Richardson et al. 2023](99-references.html#ref-arrow))'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arrow` ([Richardson 等人 2023](99-references.html#ref-arrow))'
- en: '`devtools` ([Wickham et al. 2022](99-references.html#ref-citeDevtools))'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`devtools` ([Wickham 等人 2022](99-references.html#ref-citeDevtools))'
- en: '`diffpriv` ([Rubinstein and Alda 2017](99-references.html#ref-diffpriv))'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diffpriv` ([Rubinstein 和 Alda 2017](99-references.html#ref-diffpriv))'
- en: '`fs` ([Hester, Wickham, and Csárdi 2021](99-references.html#ref-fs))'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fs` ([Hester, Wickham, 和 Csárdi 2021](99-references.html#ref-fs))'
- en: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`janitor` ([Firke 2023](99-references.html#ref-janitor))'
- en: '`openssl` ([Ooms 2022](99-references.html#ref-openssl))'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openssl` ([Ooms 2022](99-references.html#ref-openssl))'
- en: '`tictoc` ([Izrailev 2022](99-references.html#ref-Izrailev2014))'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tictoc` ([Izrailev 2022](99-references.html#ref-Izrailev2014))'
- en: '`tidyverse` ([Wickham et al. 2019](99-references.html#ref-tidyverse))'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tidyverse` ([Wickham 等人 2019](99-references.html#ref-tidyverse))'
- en: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tinytable` ([Arel-Bundock 2024](99-references.html#ref-tinytable))'
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*## 10.1 Introduction'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*## 10.1 引言'
- en: After we have put together a dataset we must store it appropriately and enable
    easy retrieval both for ourselves and others. There is no completely agreed on
    approach, but there are best standards, and this is an evolving area of research
    ([Lewis 2024](99-references.html#ref-lewiscrystal)). Wicherts, Bakker, and Molenaar
    ([2011](99-references.html#ref-Wicherts2011)) found that a reluctance to share
    data was associated with research papers that had weaker evidence and more potential
    errors. While it is possible to be especially concerned about this—and entire
    careers and disciplines are based on the storage and retrieval of data—to a certain
    extent, the baseline is not onerous. If we can get our dataset off our own computer,
    then we are much of the way there. Further confirming that someone else can retrieve
    and use it, ideally without our involvement, puts us much further than most. Just
    achieving that for our data, models, and code meets the “bronze” standard of Heil
    et al. ([2021](99-references.html#ref-heil2021reproducibility)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们整理好数据集后，我们必须适当地存储它，并使自己和他人都能轻松检索。没有完全达成一致的方法，但有最佳标准，这是一个不断发展的研究领域([Lewis
    2024](99-references.html#ref-lewiscrystal))。Wicherts、Bakker和Molenaar([2011](99-references.html#ref-Wicherts2011))发现，不愿意分享数据与证据较弱、潜在错误更多的研究论文相关。虽然我们可能对此特别关心——整个职业和学科都基于数据的存储和检索——但在一定程度上，基础要求并不苛刻。如果我们能将数据集从自己的电脑上移除，那么我们就已经走得很远了。进一步确认其他人可以在不涉及我们的情况下检索和使用它，这将使我们比大多数人更进一步。仅仅为我们自己的数据、模型和代码实现这一点，就达到了Heil等人([2021](99-references.html#ref-heil2021reproducibility))所提出的“青铜”标准。
- en: 'The FAIR principles are useful when we come to think more formally about data
    sharing and management. This requires that datasets are ([Wilkinson et al. 2016](99-references.html#ref-wilkinson2016fair)):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: FAIR原则在正式思考数据共享和管理时非常有用。这要求数据集必须满足([Wilkinson et al. 2016](99-references.html#ref-wilkinson2016fair))：
- en: Findable. There is one, unchanging, identifier for the dataset and the dataset
    has high-quality descriptions and explanations.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可查找。数据集有一个唯一不变的标识符，并且数据集具有高质量的定义和解释。
- en: Accessible. Standardized approaches can be used to retrieve the data, and these
    are open and free, possibly with authentication, and their metadata persist even
    if the dataset is removed.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可访问。可以使用标准化的方法来检索数据，这些方法是公开和免费的，可能需要认证，并且即使数据集被删除，其元数据仍然持续存在。
- en: Interoperable. The dataset and its metadata use a broadly-applicable language
    and vocabulary.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可互操作。数据集及其元数据使用广泛适用的语言和词汇。
- en: Reusable. There are extensive descriptions of the dataset and the usage conditions
    are made clear along with provenance.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可重用。对数据集有详细的描述，并且使用条件和来源都得到了明确说明。
- en: One reason for the rise of data science is that humans are at the heart of it.
    And often the data that we are interested in directly concern humans. This means
    that there can be tension between sharing a dataset to facilitate reproducibility
    and maintaining privacy. Medicine developed approaches to this over a long time.
    And out of that we have seen the Health Insurance Portability and Accountability
    Act (HIPAA) in the US, the broader General Data Protection Regulation (GDPR) in
    Europe introduced in 2016, and the California Consumer Privacy Act (CCPA) introduced
    in 2018, among others.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学兴起的一个原因是人类是其核心。而且，我们感兴趣的数据通常直接与人类相关。这意味着在为了促进可重复性而共享数据集和维护隐私之间可能存在紧张关系。医学在长时间里发展了应对这一问题的方法。因此，我们看到了美国在2016年推出的更广泛的通用数据保护条例(GDPR)，以及2018年推出的加利福尼亚消费者隐私法案(CCPA)等。
- en: Our concerns in data science tend to be about personally identifying information.
    We have a variety of ways to protect especially private information, such as emails
    and home addresses. For instance, we can hash those variables. Sometimes we may
    simulate data and distribute that instead of sharing the actual dataset. More
    recently, approaches based on differential privacy are being implemented, for
    instance for the US census. The fundamental problem of data privacy is that increased
    privacy reduces the usefulness of a dataset. The trade-off means the appropriate
    decision is nuanced and depends on costs and benefits, and we should be especially
    concerned about differentiated effects on population minorities.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，我们的关注点往往集中在个人识别信息上。我们有各种方法来保护特别私人的信息，例如电子邮件和家庭地址。例如，我们可以对这些变量进行哈希处理。有时我们可能会模拟数据并分发这些数据而不是共享实际的数据集。最近，基于差分隐私的方法正在被实施，例如用于美国人口普查。数据隐私的基本问题是，隐私的增加会降低数据集的有用性。权衡意味着适当的决策是微妙的，并取决于成本和收益，我们应该特别关注对人口少数群体的差异化影响。
- en: Just because a dataset is FAIR, it is not necessarily an unbiased representation
    of the world. Further, it is not necessarily fair in the everyday way that word
    is used, i.e. impartial and honest ([Lima et al. 2022](99-references.html#ref-deLima2022)).
    FAIR reflects whether a dataset is appropriately available, not whether it is
    appropriate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 就算一个数据集是FAIR的，它也不一定是世界无偏见的代表。进一步说，它也不一定在日常用语中所说的公平，即公正和诚实（[Lima等人2022](99-references.html#ref-deLima2022)）。FAIR反映了一个数据集是否适当可用，而不是它是否适当。
- en: Finally, in this chapter we consider efficiency. As datasets and code bases
    get larger it becomes more difficult to deal with them, especially if we want
    them to be shared. We come to concerns around efficiency, not for its own sake,
    but to enable us to tell stories that could not otherwise be told. This might
    mean moving beyond CSV files to formats with other properties, or even using databases,
    such as Postgres, although even as we do so acknowledging that the simplicity
    of a CSV, as it is text-based which lends itself to human inspection, can be a
    useful feature.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在本章中，我们考虑效率。随着数据集和代码库的增大，处理它们变得更加困难，尤其是如果我们希望它们被共享时。我们开始关注效率，不是为了效率本身，而是为了能够讲述那些否则无法讲述的故事。这可能意味着超越CSV文件到具有其他属性的格式，甚至使用数据库，如Postgres，尽管如此，我们仍然承认CSV的简单性，作为基于文本的格式，它便于人类检查，可以是一个有用的特性。
- en: 10.2 Plan
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 计划
- en: The storage and retrieval of information is especially connected with libraries,
    in the traditional sense of a collection of books. These have existed since antiquity
    and have well-established protocols for deciding what information to store and
    what to discard, as well as information retrieval. One of the defining aspects
    of libraries is deliberate curation and organization. The use of a cataloging
    system ensures that books on similar topics are located close to each other, and
    there are typically also deliberate plans for ensuring the collection is up to
    date. This enables information storage and retrieval that is appropriate and efficient.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 信息存储和检索与图书馆（在传统意义上指书籍的集合）特别相关。这些图书馆自古代以来就存在，并且有成熟的协议来决定存储哪些信息以及丢弃哪些信息，以及信息检索。图书馆的一个定义特征是有意为之的收藏和组织。使用编目系统确保了相似主题的书籍彼此靠近，并且通常也有计划确保藏书保持最新。这使得信息存储和检索既适当又高效。
- en: Data science relies heavily on the internet when it comes to storage and retrieval.
    Vannevar Bush, the twentieth century engineer, defined a “memex” in 1945 as a
    device to store books, records, and communications in a way that supplements memory
    ([Bush 1945](99-references.html#ref-vannevarbush)). The key to it was the indexing,
    or linking together, of items. We see this concept echoed just four decades later
    in the proposal by Tim Berners-Lee for hypertext ([Berners-Lee 1989](99-references.html#ref-berners1989information)).
    This led to the World Wide Web and defines the way that resources are identified.
    They are then transported over the internet, using Hypertext Transfer Protocol
    (HTTP).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学在存储和检索方面高度依赖互联网。20世纪的工程师范内瓦·布什在1945年定义了一个“记忆扩展器”，作为一种存储书籍、记录和通信的设备，以补充记忆（[布什1945](99-references.html#ref-vannevarbush)）。其关键在于索引，即项目的链接。我们可以在四十年后的蒂姆·伯纳斯-李关于超文本的提案中看到这一概念的回响（[伯纳斯-李1989](99-references.html#ref-berners1989information)）。这导致了万维网的诞生，并定义了资源标识的方式。然后，它们通过超文本传输协议（HTTP）在互联网上传输。
- en: At its most fundamental, the internet is about storing and retrieving data.
    It is based on making various files on a computer available to others. When we
    consider the storage and retrieval of our datasets we want to especially contemplate
    for how long they should be stored and for whom ([Michener 2015](99-references.html#ref-michener2015ten)).
    For instance, if we want some dataset to be available for a decade, and widely
    available, then it becomes important to store it in open and persistent formats
    ([Hart et al. 2016](99-references.html#ref-hart2016ten)). But if we are just using
    a dataset as part of an intermediate step, and we have the original, unedited
    data and the scripts to create it, then it might be fine to not worry too much
    about such considerations. The evolution of physical storage media has similar
    complicated issues. For instance, datasets and recordings made on media such as
    wax cylinders, magnetic tapes, and proprietary optical disks, now have a variable
    ease of use.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的意义上，互联网是关于存储和检索数据。它基于使计算机上的各种文件对他人可用。当我们考虑我们数据集的存储和检索时，我们特别需要考虑它们应该存储多长时间以及为谁存储([Michener
    2015](99-references.html#ref-michener2015ten))。例如，如果我们希望某些数据集在十年内可用且广泛可用，那么将其存储在开放和持久格式的存储中就变得非常重要([Hart
    et al. 2016](99-references.html#ref-hart2016ten))。但如果我们只是将数据集作为中间步骤的一部分使用，并且我们有原始的、未编辑的数据以及创建它的脚本，那么可能不需要过于担心这些考虑。物理存储媒体的演变也有类似复杂的问题。例如，现在使用蜡筒、磁带和专有光学磁盘等媒体制作的数据集和录音，其使用便利性各不相同。
- en: Storing the original, unedited data is important and there are many cases where
    unedited data have revealed or hinted at fraud ([Simonsohn 2013](99-references.html#ref-simonsohn2013just)).
    Shared data also enhances the credibility of our work, by enabling others to verify
    it, and can lead to the generation of new knowledge as others use it to answer
    different questions ([Christensen, Freese, and Miguel 2019](99-references.html#ref-christensen2019transparent)).
    Christensen et al. ([2019](99-references.html#ref-christensen2019study)) suggest
    that research that shares its data may be more highly cited, although Tierney
    and Ram ([2021](99-references.html#ref-Tierney2021)) caution that widespread data
    sharing may require a cultural change.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 存储原始、未编辑的数据非常重要，有许多案例表明未编辑的数据揭示了或暗示了欺诈([Simonsohn 2013](99-references.html#ref-simonsohn2013just))。共享数据也增强了我们工作的可信度，因为它允许他人验证它，并且当他人用它来回答不同的问题时，可以导致新知识的产生([Christensen,
    Freese, and Miguel 2019](99-references.html#ref-christensen2019transparent))。Christensen等人([2019](99-references.html#ref-christensen2019study))建议共享数据的科研可能被引用得更多，尽管Tierney和Ram([2021](99-references.html#ref-Tierney2021))警告说，广泛的数据共享可能需要文化变革。
- en: We should try to invite scrutiny and make it as easy as possible to receive
    criticism. We should try to do this even when it is the difficult choice and results
    in discomfort because that is the only way to contribute to the stock of lasting
    knowledge. For instance, Piller ([2022](99-references.html#ref-pillerblots)) details
    potential fabrication in research about Alzheimer’s disease. In that case, one
    of the issues that researchers face when trying to understand whether the results
    are legitimate is a lack of access to unpublished images.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该努力接受审查，并尽可能使接受批评变得容易。即使在这是困难的选择并导致不适的情况下，我们也应该这样做，因为这是唯一能够为持久知识库做出贡献的方式。例如，Piller
    ([2022](99-references.html#ref-pillerblots)) 详细介绍了关于阿尔茨海默病研究中的潜在伪造。在这种情况下，研究人员在试图理解结果是否合法时面临的一个问题是无法访问未发表的照片。
- en: Data provenance is especially important. This refers to documenting “where a
    piece of data came from and the process by which it arrived in the database” ([Buneman,
    Khanna, and Wang-Chiew 2001, 316](99-references.html#ref-Buneman2001)). Documenting
    and saving the original, unedited dataset, using scripts to manipulate it to create
    the dataset that is analyzed, and sharing all of this—as recommended in this book—goes
    some way to achieving this. In some fields it is common for just a handful of
    databases to be used by many different teams, for instance, in genetics, the UK
    BioBank, and in the life sciences a cloud-based platform called ORCESTRA ([Mammoliti
    et al. 2021](99-references.html#ref-Mammoliti2021)) has been established to help.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来源特别重要。这指的是记录“数据来自哪里以及它是如何到达数据库的”过程（[Buneman, Khanna, and Wang-Chiew 2001,
    316](99-references.html#ref-Buneman2001)）。记录并保存原始的、未经编辑的数据集，使用脚本对其进行操作以创建分析所需的数据集，以及分享所有这些——正如本书所建议的——有助于实现这一点。在某些领域，只有少数数据库被许多不同的团队使用是很常见的，例如，在遗传学中，英国生物银行，以及在生命科学中，一个名为ORCESTRA的基于云的平台（[Mammoliti等人2021](99-references.html#ref-Mammoliti2021)）已经建立起来以帮助。
- en: 10.3 Share
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 分享
- en: 10.3.1 GitHub
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 GitHub
- en: The easiest place for us to get started with storing a dataset is GitHub because
    that is already built into our workflow. For instance, if we push a dataset to
    a public repository, then our dataset becomes available. One benefit of this is
    that if we have set up our workspace appropriately, then we likely store our original,
    unedited data and the tidy data, as well as the scripts that are needed to transform
    one to the other. We are most of the way to the “bronze” standard of Heil et al.
    ([2021](99-references.html#ref-heil2021reproducibility)) without changing anything.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们开始存储数据集来说，GitHub是最容易的地方，因为GitHub已经集成到我们的工作流程中。例如，如果我们将数据集推送到公共仓库，那么我们的数据集就会变得可用。这一好处在于，如果我们适当地设置了我们的工作区，那么我们很可能存储了原始的、未经编辑的数据以及整洁的数据，以及将一种数据转换为另一种数据所需的脚本。我们几乎已经达到了Heil等人所说的“青铜”标准（[2021](99-references.html#ref-heil2021reproducibility)），而无需做任何改变。
- en: As an example of how we have stored some data, we can access “raw_data.csv”
    from the [“starter_folder”](https://github.com/RohanAlexander/starter_folder).
    We navigate to the file in GitHub (“inputs” \(\rightarrow\) “data” \(\rightarrow\)
    “raw_data.csv”), and then click “Raw” ([Figure 10.1](#fig-githubraw)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们如何存储一些数据的例子，我们可以从[“starter_folder”](https://github.com/RohanAlexander/starter_folder)访问“raw_data.csv”。我们在GitHub中导航到该文件（“inputs”
    \(\rightarrow\) “data” \(\rightarrow\) “raw_data.csv”），然后点击“Raw”（[图10.1](#fig-githubraw)）。
- en: '![](../Images/233218987d1d470d0594eee7bad9da3f.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/233218987d1d470d0594eee7bad9da3f.png)'
- en: 'Figure 10.1: Getting the necessary link to be able to read a CSV from a GitHub
    repository'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：获取从GitHub仓库读取CSV文件所需的链接
- en: We can then add that URL as an argument to `read_csv()`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将该URL作为`read_csv()`函数的参数添加。
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*[PRE2]*  *While we can store and retrieve a dataset easily in this way, it
    lacks explanation, a formal dictionary, and aspects such as a license that would
    bring it closer to aligning with the FAIR principles. Another practical concern
    is that the maximum file size on GitHub is 100MB, although Git Large File Storage
    (LFS) can be used if needed. And a final concern, for some, is that GitHub is
    owned by Microsoft, a for-profit US technology firm.*  *### 10.3.2 R packages
    for data'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE2]*  *虽然我们可以通过这种方式轻松地存储和检索数据集，但它缺乏解释、正式的字典以及与FAIR原则更接近的方面，如许可证。另一个实际问题是，GitHub上的最大文件大小为100MB，尽管如果需要可以使用Git
    Large File Storage (LFS)。最后一个问题是，对于一些人来说，GitHub由微软拥有，这是一家盈利的美国科技公司。*  *### 10.3.2
    R包数据'
- en: To this point we have largely used R packages for their code, although we have
    seen a few that were focused on sharing data, for instance, `troopdata` and `babynames`
    in [Chapter 5](05-graphs_tables_maps.html). We can build a R package for our dataset
    and then add it to GitHub and potentially eventually CRAN. This will make it easy
    to store and retrieve because we can obtain the dataset by loading the package.
    In contrast to the CSV-based approach, it also means a dataset brings its documentation
    along with it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要使用R包的代码，尽管我们看到了一些专注于共享数据的包，例如，在第5章中提到的`troopdata`和`babynames`。我们可以为我们的数据集构建一个R包，然后将其添加到GitHub，最终可能添加到CRAN。这将使其存储和检索变得容易，因为我们可以通过加载包来获取数据集。与基于CSV的方法相比，这也意味着数据集会带来其文档。
- en: This will be the first R package that we build, and so we will jump over a number
    of steps. The key is to just try to get something working. In [Appendix G](26-deploy.html),
    we return to R packages and use them to deploy models. This gives us another chance
    to further develop experience with them.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是我们要构建的第一个R包，因此我们将跳过许多步骤。关键是尝试让某些东西工作。在[附录G](26-deploy.html)中，我们回到R包并使用它们来部署模型。这给了我们另一个机会来进一步发展对它们的经验。
- en: 'To get started, create a new package: “File” \(\rightarrow\) “New project”
    \(\rightarrow\) “New Directory” \(\rightarrow\) “R Package”. Give the package
    a name, such as “favcolordata” and select “Open in new session”. Create a new
    folder called “data”. We will simulate a dataset of people and their favorite
    colors to include in our R package.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，创建一个新的包：“文件” \(\rightarrow\) “新建项目” \(\rightarrow\) “新建目录” \(\rightarrow\)
    “R包”。给包起一个名字，例如“favcolordata”，并选择“在新会话中打开”。创建一个名为“data”的新文件夹。我们将模拟一个包含人们和他们最喜欢的颜色的数据集，并将其包含在我们的R包中。
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*To this point we have largely been using CSV files for our datasets. To include
    our data in this R package, we save our dataset in a different format, “.rda”,
    using `save()`.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*到目前为止，我们主要使用CSV文件作为我们的数据集。为了将我们的数据包含在这个R包中，我们使用`save()`将数据集保存为不同的格式，“.rda”。'
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Then we create a R file “data.R” in the “R” folder. This file will only contain
    documentation using `roxygen2` comments. These start with `#''`, and we follow
    the documentation for `troopdata` closely.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*然后我们在“R”文件夹中创建一个名为“data.R”的R文件。这个文件将只包含使用`roxygen2`注释的文档。这些注释以`#''`开头，并且我们紧密遵循`troopdata`的文档说明。'
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Finally, add a README that provides a summary of all of this for someone coming
    to the project for the first time. Examples of packages with excellent READMEs
    include [`ggplot2`](https://github.com/tidyverse/ggplot2#readme), [`pointblank`](https://github.com/rich-iannone/pointblank#readme),
    [`modelsummary`](https://github.com/vincentarelbundock/modelsummary#readme), and
    [`janitor`](https://github.com/sfirke/janitor#readme).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**最后，添加一个README文件，为第一次来这个项目的用户提供一个总结。具有优秀README文件的包示例包括[`ggplot2`](https://github.com/tidyverse/ggplot2#readme)、[`pointblank`](https://github.com/rich-iannone/pointblank#readme)、[`modelsummary`](https://github.com/vincentarelbundock/modelsummary#readme)和[`janitor`](https://github.com/sfirke/janitor#readme)。'
- en: We can now go to the “Build” tab and click “Install and Restart”. After this,
    the package “favcolordata”, will be loaded and the data can be accessed locally
    using “color_data”. If we were to push this package to GitHub, then anyone would
    be able to install the package using `devtools` and use our dataset. Indeed, the
    following should work.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以转到“构建”选项卡并点击“安装并重启”。之后，包“favcolordata”将被加载，数据可以通过“color_data”在本地访问。如果我们把这个包推送到GitHub，那么任何人都可以使用`devtools`安装这个包并使用我们的数据集。实际上，以下应该可以工作。
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*This has addressed many of the issues that we faced earlier. For instance,
    we have included a README and a data dictionary, of sorts, in terms of the descriptions
    that we added. But if we were to try to put this package onto CRAN, then we might
    face some issues. For instance, the maximum size of a package is 5MB and we would
    quickly come up against that. We have also largely forced users to use R. While
    there are benefits of that, we may like to be more language agnostic ([Tierney
    and Ram 2020](99-references.html#ref-tierney2020realistic)), especially if we
    are concerned about the FAIR principles.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*这已经解决了我们之前面临的一些问题。例如，我们已经包括了一个README和一个类似的数据字典，这些是通过我们添加的描述来实现的。但是，如果我们试图将这个包上传到CRAN，我们可能会遇到一些问题。例如，包的最大大小是5MB，我们很快就会遇到这个问题。我们还很大程度上强迫用户使用R。虽然这样做有一些好处，但我们可能希望更加语言无关（[Tierney和Ram
    2020](99-references.html#ref-tierney2020realistic)），特别是如果我们关心FAIR原则的话。'
- en: Wickham ([2022, chap. 8](99-references.html#ref-rpackages)) provides more information
    about including data in R packages.****  ***### 10.3.3 Depositing data
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Wickham ([2022, chap. 8](99-references.html#ref-rpackages))提供了更多关于在R包中包含数据的信息。
- en: While it is possible that a dataset will be cited if it is available through
    GitHub or a R package, this becomes more likely if the dataset is deposited somewhere.
    There are several reasons for this, but one is that it seems a bit more formal.
    Another is that it is associated with a DOI. [Zenodo](https://zenodo.org) and
    the [Open Science Framework](https://osf.io) (OSF) are two depositories that are
    commonly used. For instance, Carleton ([2021](99-references.html#ref-chris_carleton_2021_4550688))
    uses Zenodo to share the dataset and analysis supporting Carleton, Campbell, and
    Collard ([2021](99-references.html#ref-carleton2021reassessment)), Geuenich et
    al. ([2021b](99-references.html#ref-geuenich_michael_2021_5156049)) use Zenodo
    to share the dataset that underpins Geuenich et al. ([2021a](99-references.html#ref-geuenich2021automated)),
    and Katz and Alexander ([2023a](99-references.html#ref-katzhansard)) use Zenodo
    to share the dataset that underpins Katz and Alexander ([2023b](99-references.html#ref-katz2023digitization)).
    Similarly, Arel-Bundock et al. ([2022](99-references.html#ref-ryansnewpaper))
    use OSF to share code and data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然如果数据集通过 GitHub 或 R 包提供，它可能会被引用，但如果数据集被存放在某个地方，这种情况发生的可能性就更大了。这有几个原因，但其中之一是它看起来更正式。另一个原因是它与
    DOI 相关。[Zenodo](https://zenodo.org) 和 [开放科学框架](https://osf.io) (OSF) 是两个常用的存储库。例如，Carleton
    ([2021](99-references.html#ref-chris_carleton_2021_4550688)) 使用 Zenodo 来分享 Carleton,
    Campbell 和 Collard ([2021](99-references.html#ref-carleton2021reassessment)) 以及
    Geuenich 等人 ([2021b](99-references.html#ref-geuenich_michael_2021_5156049)) 支持的数据集，Geuenich
    等人 ([2021a](99-references.html#ref-geuenich2021automated)) 使用 Zenodo 来分享支撑他们的数据集，Katz
    和 Alexander ([2023a](99-references.html#ref-katzhansard)) 使用 Zenodo 来分享支撑 Katz
    和 Alexander ([2023b](99-references.html#ref-katz2023digitization)) 的数据集。类似地，Arel-Bundock
    等人 ([2022](99-references.html#ref-ryansnewpaper)) 使用 OSF 来分享代码和数据。
- en: Another option is to use a dataverse, such as the [Harvard Dataverse](https://dataverse.harvard.edu)
    or the [Australian Data Archive](https://ada.edu.au). This is a common requirement
    for journal publications. One nice aspect of this is that we can use `dataverse`
    to retrieve the dataset as part of a reproducible workflow. We have an example
    of this in [Chapter 13](13-ijaglm.html).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是使用数据仓库，例如 [哈佛数据仓库](https://dataverse.harvard.edu) 或 [澳大利亚数据档案](https://ada.edu.au)。这是期刊出版的一个常见要求。这个选择的优点之一是我们可以使用
    `数据仓库` 来检索作为可重复工作流程一部分的数据集。我们在 [第13章](13-ijaglm.html) 中有一个这样的例子。
- en: In general, these options are free and provide a DOI that can be useful for
    citation purposes. The use of data deposits such as these is a way to offload
    responsibility for the continued hosting of the dataset (which in this case is
    a good thing) and prevent the dataset from being lost. It also establishes a single
    point of truth, which should act to reduce errors ([Byrd et al. 2020](99-references.html#ref-byrd2020responsible)).
    Finally, it makes access to the dataset independent of the original researchers,
    and results in persistent metadata. That all being said, the viability of these
    options rests on their underlying institutions. For instance, Zenodo is operated
    by CERN and many dataverses are operated by universities. These institutions are
    subject to, as we all are, social and political forces.****  ***## 10.4 Data documentation
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些选项是免费的，并提供一个可用于引用的 DOI。使用这些数据存储库是将数据集持续托管的责任（在这种情况下是好事）转移出去，并防止数据集丢失的一种方式。它还建立了一个单一的真实点，这应该有助于减少错误
    ([Byrd 等人 2020](99-references.html#ref-byrd2020responsible))。最后，它使数据集的访问与原始研究人员无关，并导致持久元数据。话虽如此，这些选项的可行性取决于其背后的机构。例如，Zenodo
    由 CERN 运营，许多数据仓库由大学运营。这些机构，就像我们所有人一样，受到社会和政治力量的影响。
- en: Dataset documentation has long consisted of a data dictionary. This may be as
    straight-forward a list of the variables, a few sentences of description, and
    ideally a source. [The data dictionary of the ACS](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2016-2020.pdf),
    which was introduced in [Chapter 6](06-farm.html), is particularly comprehensive.
    And OSF provides [instructions](https://help.osf.io/article/217-how-to-make-a-data-dictionary)
    for how to make a data dictionary. Given the workflow advocated in this book,
    it might be worthwhile to actually begin putting together a data dictionary as
    part of the simulation step i.e. before even collecting the data. While it would
    need to be updated, it would be another opportunity to think deeply about the
    data situation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的文档长期以来一直由数据字典组成。这可能是一个简单的变量列表，几句话的描述，以及理想情况下一个来源。[美国社区调查（ACS）的数据字典](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2016-2020.pdf)，在第6章（06-farm.html）中介绍，特别全面。OSF提供了[如何制作数据字典的说明](https://help.osf.io/article/217-how-to-make-a-data-dictionary)。根据本书倡导的工作流程，在模拟步骤中实际开始整理数据字典可能是值得的，即在收集数据之前。虽然它需要更新，但这将是深入思考数据状况的另一个机会。
- en: Datasheets ([Gebru et al. 2021](99-references.html#ref-gebru2021datasheets))
    are an increasingly common addition to documentation. If we think of a data dictionary
    as a list of ingredients for a dataset, then we could think of a datasheet as
    basically a nutrition label for datasets. The process of creating them enables
    us to think more carefully about what we will feed our model. More importantly,
    they enable others to better understand what we fed our model. One important task
    is going back and putting together datasheets for datasets that are widely used.
    For instance, researchers went back and wrote a datasheet for “BookCorpus”, which
    is one of the most popular datasets in computer science, and they found that around
    30 per cent of the data were duplicated ([Bandy and Vincent 2021](99-references.html#ref-bandy2021addressing)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表（[Gebru等人2021](99-references.html#ref-gebru2021datasheets)）是文档中越来越常见的补充。如果我们把数据字典看作是数据集的成分列表，那么我们可以把数据表看作是数据集的基本营养标签。创建它们的过程使我们能够更仔细地思考我们将要喂给模型什么。更重要的是，它们使其他人更好地理解我们喂给模型什么。一个重要的任务是回头整理广泛使用的数据集的数据表。例如，研究人员回头为“BookCorpus”编写了数据表，这是计算机科学中最受欢迎的数据集之一，他们发现大约30%的数据是重复的（[Bandy和Vincent
    2021](99-references.html#ref-bandy2021addressing)）。
- en: '*Shoulders of giants* *Timnit Gebru is the founder of the Distributed Artificial
    Intelligence Research Institute (DAIR). After earning a PhD in Computer Science
    from Stanford University, Gebru joined Microsoft and then Google. In addition
    to Bandy and Vincent ([2021](99-references.html#ref-bandy2021addressing)), which
    introduced datasheets, one notable paper is Bender et al. ([2021](99-references.html#ref-Bender2021)),
    which discussed the dangers of language models being too large. She has made many
    other substantial contributions to fairness and accountability, especially Buolamwini
    and Gebru ([2018](99-references.html#ref-buolamwini2018gender)), which demonstrated
    racial bias in facial analysis algorithms.*  *Instead of telling us how unhealthy
    various foods are, a datasheet tells us things like:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*巨人的肩膀* *Timnit Gebru是分布式人工智能研究院（DAIR）的创始人。在斯坦福大学获得计算机科学博士学位后，Gebru加入了微软，然后是谷歌。除了Bandy和Vincent
    ([2021](99-references.html#ref-bandy2021addressing))，他们介绍了数据表，另一篇值得注意的论文是Bender等人([2021](99-references.html#ref-Bender2021))，讨论了语言模型过大的危险。她在公平性和问责制方面做出了许多其他重大贡献，特别是Buolamwini和Gebru
    ([2018](99-references.html#ref-buolamwini2018gender))，他们证明了面部分析算法中的种族偏见。* 数据表不像告诉我们各种食物有多不健康那样，而是告诉我们如下信息：'
- en: Who put the dataset together?
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁整理了数据集？
- en: Who paid for the dataset to be created?
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁支付了创建数据集的费用？
- en: How complete is the dataset? (Which is, of course, unanswerable, but detailing
    the ways in which it is known to be incomplete is valuable.)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的完整性如何？（当然，这是无法回答的，但详细说明其不完整的方式是有价值的。）
- en: Which variables are present, and, equally, not present, for particular observations?
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于特定的观测值，哪些变量是存在的，哪些是不存在的？
- en: Sometimes, a lot of work is done to create a datasheet. In that case, we may
    like to publish and share it on its own, for instance, Biderman, Bicheno, and
    Gao ([2022](99-references.html#ref-biderman2022datasheet)) and Bandy and Vincent
    ([2021](99-references.html#ref-bandy2021addressing)). But typically a datasheet
    might live in an appendix to the paper, for instance Zhang et al. ([2022](99-references.html#ref-zhang2022opt)),
    or be included in a file adjacent to the dataset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，为了创建数据表需要做大量的工作。在这种情况下，我们可能希望单独发布和分享它，例如，Biderman、Bicheno和Gao（[2022](99-references.html#ref-biderman2022datasheet)）和Bandy和Vincent（[2021](99-references.html#ref-bandy2021addressing)）。但通常情况下，数据表可能位于论文的附录中，例如张等人（[2022](99-references.html#ref-zhang2022opt)），或者包含在数据集相邻的文件中。
- en: When creating a datasheet for a dataset, especially a dataset that we did not
    put together ourselves, it is possible that the answer to some questions will
    simply be “Unknown”, but we should do what we can to minimize that. The datasheet
    template created by Gebru et al. ([2021](99-references.html#ref-gebru2021datasheets))
    is not the final word. It is possible to improve on it, and add additional detail
    sometimes. For instance, Miceli, Posada, and Yang ([2022](99-references.html#ref-Miceli2022))
    argue for the addition of questions to do with power relations.*  *## 10.5 Personally
    identifying information
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当为数据集创建数据表时，尤其是当我们没有自己组合的数据集时，某些问题的答案可能是简单的“未知”，但我们应该尽我们所能来最小化这种情况。Gebru等人创建的数据表模板（[2021](99-references.html#ref-gebru2021datasheets)）并不是最终的解决方案。我们可以在其基础上进行改进，并在某些情况下添加更多细节。例如，Miceli、Posada和Yang（[2022](99-references.html#ref-Miceli2022)）主张增加关于权力关系的问题。
- en: By way of background, Christensen, Freese, and Miguel ([2019, 180](99-references.html#ref-christensen2019transparent))
    define a variable as “confidential” if the researchers know who is associated
    with each observation, but the public version of the dataset removes this association.
    A variable is “anonymous” if even the researchers do not know.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作为背景，Christensen、Freese和Miguel（[2019, 180](99-references.html#ref-christensen2019transparent)）将变量定义为“机密”的，如果研究人员知道每个观察结果与谁相关联，但数据集的公共版本移除了这种关联。如果即使是研究人员也不知道，则变量是“匿名”的。
- en: 'Personally identifying information (PII) is that which enables us to link an
    observation in our dataset with an actual person. This is a significant concern
    in fields focused on data about people. Email addresses are often PII, as are
    names and addresses. While some variables may not be PII for many respondents,
    it could be PII for some. For instance, consider a survey that is representative
    of the population age distribution. There is not likely to be many respondents
    aged over 100, and so the variable age may then become PII. The same scenario
    applies to income, wealth, and many other variables. One response to this is for
    data to be censored, which was discussed in [Chapter 6](06-farm.html). For instance,
    we may record age between zero and 90, and then group everyone over that into
    “90+”. Another is to construct age-groups: “18-29”, “30-44”, \(\dots\). Notice
    that with both these solutions we have had to trade-off privacy and usefulness.
    More concerningly, a variable may be PII, not by itself, but when combined with
    another variable.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 个人识别信息（PII）是指那些使我们能够将数据集中的观察结果与实际个人关联起来的信息。这在关注人数据的领域中是一个重大的问题。电子邮件地址通常是PII，姓名和地址也是如此。虽然某些变量可能对许多受访者来说不是PII，但对于某些受访者来说可能是PII。例如，考虑一个代表人口年龄分布的调查。年龄超过100岁的受访者可能不会很多，因此变量年龄可能成为PII。同样的情况也适用于收入、财富以及许多其他变量。对此的一种应对方法是数据被屏蔽，这在第6章中已有讨论。例如，我们可能记录年龄在0到90岁之间，然后把超过这个年龄的人归入“90+”这一组。另一种方法是构建年龄组：“18-29”，“30-44”，等等。请注意，在这两种解决方案中，我们都不得不在隐私和实用性之间做出权衡。更令人担忧的是，一个变量可能本身不是PII，但与另一个变量结合时却可能是PII。
- en: Our primary concern should be with ensuring that the privacy of our dataset
    is appropriate, given the expectations of the reasonable person. This requires
    weighing costs and benefits. In national security settings there has been considerable
    concern about the over-classification of documents ([Lin 2014](99-references.html#ref-overclassification)).
    The reduced circulation of information because of this may result in unrealized
    benefits. To avoid this in data science, the test of the need to protect a dataset
    needs to be made by the reasonable person weighing up costs and benefits. It is
    easy, but incorrect, to argue that data should not be released unless it is perfectly
    anonymized. The fundamental problem of data privacy implies that such data would
    have limited utility. That approach, possibly motivated by the precautionary principle,
    would be too conservative and could cause considerable loss in terms of unrealized
    benefits.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要关注点应该是确保我们的数据集的隐私符合一个合理人的期望。这需要权衡成本和收益。在国家安全的背景下，人们已经对文件的过度分类（[Lin 2014](99-references.html#ref-overclassification)）表示了相当大的关注。由于这种原因导致的信息流通减少可能会导致未实现的利益。为了避免在数据科学中出现这种情况，需要由一个合理人权衡成本和收益来决定是否需要保护数据集。认为除非数据完全匿名化，否则不应发布数据的观点虽然容易，但却是错误的。数据隐私的基本问题意味着这样的数据将具有有限的效用。这种可能由预防原则激发的方法过于保守，可能会造成相当大的未实现利益的损失。
- en: Randomized response ([Greenberg et al. 1969](99-references.html#ref-randomizedresponse))
    is a clever way to enable anonymity without much overhead. Each respondent flips
    a coin before they answer a question but does not show the researcher the outcome
    of the coin flip. The respondent is instructed to respond truthfully to the question
    if the coin lands on heads, but to always give some particular (but still plausible)
    response if tails. The results of the other options can then be re-weighted to
    enable an estimate, without a researcher ever knowing the truth about any particular
    respondent. This is especially used in association with snowball sampling, discussed
    in [Chapter 6](06-farm.html). One issue with randomized response is that the resulting
    dataset can be only used to answer specific questions. This requires careful planning,
    and the dataset will be of less general value.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随机响应法（[Greenberg等人 1969](99-references.html#ref-randomizedresponse)）是一种在不增加太多开销的情况下实现匿名的好方法。每个受访者在回答问题之前都会掷硬币，但不会向研究人员展示硬币掷出的结果。受访者被指示如果硬币正面朝上，就诚实地回答问题，但如果硬币反面朝上，则始终给出一些特定（但仍合理）的答案。然后可以对其他选项的结果进行重新加权，以便进行估计，而研究人员永远不知道任何特定受访者的真实情况。这种方法特别与第6章中讨论的滚雪球抽样一起使用。随机响应法的一个问题是，由此产生的数据集只能用来回答特定的问题。这需要仔细规划，并且数据集将具有较低的一般价值。
- en: 'Zook et al. ([2017](99-references.html#ref-zook2017ten)) recommend considering
    whether data even need to be gathered in the first place. For instance, if a phone
    number is not absolutely required then it might be better to not ask for it, rather
    than need to worry about protecting it before data dissemination. GDPR and HIPAA
    are two legal structures that govern data in Europe, and the United States, respectively.
    Due to the influence of these regions, they have a significant effect outside
    those regions also. GDPR concerns data generally, while HIPAA is focused on healthcare.
    GDPR applies to all personal data, which is defined as:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Zook等人（[2017](99-references.html#ref-zook2017ten)）建议首先考虑是否真的需要收集数据。例如，如果电话号码不是绝对必需的，那么可能最好不要要求提供它，以免在数据传播前担心保护它。GDPR和HIPAA是分别在欧洲和美国管理数据的两个法律结构。由于这些地区的影响，它们对那些地区之外也有显著的影响。GDPR关注数据一般，而HIPAA则专注于医疗保健。GDPR适用于所有个人数据，其定义为：
- en: \(\dots\)any information relating to an identified or identifiable natural person
    (“data subject”); an identifiable natural person is one who can be identified,
    directly or indirectly, in particular by reference to an identifier such as a
    name, an identification number, location data, an online identifier or to one
    or more factors specific to the physical, physiological, genetic, mental, economic,
    cultural or social identity of that natural person;
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(\dots\)任何与已识别或可识别的自然人（“数据主体”）相关的信息；一个可识别的自然人是指可以通过直接或间接的方式，特别是通过参考如姓名、识别号码、位置数据、在线标识符或该自然人的物理、生理、遗传、心理、经济、文化或社会身份的特定因素来识别的人；
- en: ''
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Council of European Union ([2016](99-references.html#ref-gdpr)), Article 4,
    “Definitions”
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 欧洲联盟理事会 ([2016](99-references.html#ref-gdpr))，第4条，“定义”
- en: HIPAA refers to the privacy of medical records in the US and codifies the idea
    that the patient should have access to their medical records, and that only the
    patient should be able to authorize access to their medical records ([Annas 2003](99-references.html#ref-annas2003hipaa)).
    HIPAA only applies to certain entities. This means it sets a standard, but coverage
    is inconsistent. For instance, a person’s social media posts about their health
    would generally not be subject to it, nor would knowledge of a person’s location
    and how active they are, even though based on that information we may be able
    to get some idea of their health ([Cohen and Mello 2018](99-references.html#ref-Cohen2018)).
    Such data are hugely valuable ([Ross 2022](99-references.html#ref-ibmdataset)).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: HIPAA 指的是美国医疗记录的隐私，并规定了患者应有权访问其医疗记录，并且只有患者才能授权访问其医疗记录 ([Annas 2003](99-references.html#ref-annas2003hipaa))。HIPAA
    仅适用于某些实体。这意味着它设定了一个标准，但覆盖范围不一致。例如，一个人关于其健康状况的社交媒体帖子通常不受其影响，也不会涉及一个人的位置和活跃程度，尽管基于这些信息我们可能能够了解一些关于其健康状况的信息
    ([Cohen and Mello 2018](99-references.html#ref-Cohen2018))。此类数据价值巨大 ([Ross 2022](99-references.html#ref-ibmdataset))。
- en: There are a variety of ways of protecting PII, while still sharing some data,
    that we will now go through. We focus here initially on what we can do when the
    dataset is considered by itself, which is the main concern. But sometimes the
    combination of several variables, none of which are PII in and of themselves,
    can be PII. For instance, age is unlikely PII by itself, but age combined with
    city, education, and a few other variables could be. One concern is that re-identification
    could occur by combining datasets and this is a potential role for differential
    privacy.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在保护个人身份信息（PII）的同时共享一些数据的方法有很多，我们将在下面进行介绍。我们最初关注的是当数据集本身被考虑时我们能做什么，这是主要关注点。但有时几个变量的组合，这些变量本身不是PII，却可能是PII。例如，年龄本身可能不是PII，但年龄与城市、教育和其他几个变量的组合可能是。一个担忧是，通过组合数据集可能会发生重新识别，这是差分隐私的一个潜在作用。
- en: 10.5.1 Hashing
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 哈希
- en: A cryptographic hash is a one-way transformation, such that the same input always
    provides the same output, but given the output, it is not reasonably possible
    to obtain the input. For instance, a function that doubled its input always gives
    the same output, for the same input, but is also easy to reverse, so would not
    work well as a hash. In contrast, the modulo, which for a non-negative number
    is the remainder after division and can be implemented in R using `%%`, would
    be difficult to reverse.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 密码学哈希是一种单向变换，即相同的输入总是提供相同的输出，但给定输出，合理地获取输入是不可能的。例如，一个将输入翻倍的功能对于相同的输入总是给出相同的输出，但它也很容易逆转，所以不适合作为哈希使用。相比之下，取模运算（对于非负数是除法后的余数，可以在R中使用
    `%%` 实现）很难逆转。
- en: Knuth ([1998, 514](99-references.html#ref-knuth)) relates an interesting etymology
    for “hash”. He first defines “to hash” as relating to chop up or make a mess,
    and then explaining that hashing relates to scrambling the input and using this
    partial information to define the output. A collision is when different inputs
    map to the same output, and one feature of a good hashing algorithm is that collisions
    are reduced. As mentioned, one simple approach is to rely on the modulo operator.
    For instance, if we were interested in ten different groupings for the integers
    1 through to 10, then modulo would enable this. A better approach would be for
    the number of groupings to be a larger number, because this would reduce the number
    of values with the same hash outcome.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Knuth ([1998, 514](99-references.html#ref-knuth)) 提供了“哈希”一词的有趣词源。他首先将“哈希”定义为与切碎或弄乱相关，然后解释说哈希涉及打乱输入并使用这部分信息来定义输出。冲突是指不同的输入映射到相同的输出，一个好的哈希算法的一个特征是减少了冲突。正如所提到的，一个简单的方法是依赖于取模运算符。例如，如果我们对整数1到10的十个不同分组感兴趣，那么取模运算可以实现这一点。一个更好的方法是将分组数量设为一个更大的数字，因为这会减少具有相同哈希结果的数量。
- en: For instance, consider some information that we would like to keep private,
    such as names and ages of respondents.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一些我们希望保持私密的信息，如受访者的姓名和年龄。
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*[PRE8]*  *One option for the names would be to use a function that just took
    the first letter of each name. And one option for the ages would be to convert
    them to Roman numerals.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE8]*  *对于名字的一个选择是使用一个只取每个名字的第一个字母的函数。对于年龄的一个选择是将它们转换为罗马数字。'
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*[PRE10]*  *While the approach for the first variable, names, is good because
    the names cannot be backed out, the issue is that as the dataset grows there are
    likely to be lots of “collisions”—situations where different inputs, say “Rohan”
    and “Robert”, both get the same output, in this case “R”. It is the opposite situation
    for the approach for the second variable, ages. In this case, there will never
    be any collisions—“36” will be the only input that ever maps to “XXXVI”. However,
    it is easy to back out the actual data, for anyone who knows roman numerals.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE10]*  *对于第一个变量，名字，这种方法是好的，因为名字不能被反推出来，但问题是随着数据集的增长，很可能会出现很多“冲突”——即不同的输入，比如“Rohan”和“Robert”，都得到相同的输出，在这种情况下是“R”。对于第二个变量，年龄的方法，情况正好相反。在这种情况下，永远不会出现任何冲突——“36”将是唯一映射到“XXXVI”的输入。然而，对于任何知道罗马数字的人来说，反推实际数据是很容易的。'
- en: Rather than write our own hash functions, we can use cryptographic hash functions
    such as `md5()` from `openssl`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不必自己编写哈希函数，可以使用加密哈希函数，如来自`openssl`的`md5()`。
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*[PRE12]*  *We could share either of these transformed variables and be comfortable
    that it would be difficult for someone to use only that information to recover
    the names of our respondents. That is not to say that it is impossible. Knowledge
    of the key, which is the term given to the string used to encrypt the data, would
    allow someone to reverse this. If we made a mistake, such as accidentally pushing
    the original dataset to GitHub then they could be recovered. And it is likely
    that governments and some private companies can reverse the cryptographic hashes
    used here.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE12]*  *我们可以分享这些转换后的变量之一，并且可以放心，对于其他人来说，仅使用这些信息来恢复我们受访者的名字将是困难的。这并不是说这是不可能的。对于密钥的了解，即用于加密数据的字符串的术语，将允许某人反推这个。如果我们犯了错误，比如不小心将原始数据集推送到GitHub，那么它们可以被恢复。而且，政府和一些私营公司很可能会反推出这里使用的加密哈希。'
- en: One issue that remains is that anyone can take advantage of the key feature
    of hashes to back out the input. In particular, the same input always gets the
    same output. So they could test various options for inputs. For instance, they
    could themselves try to hash “Rohan”, and then noticing that the hash is the same
    as the one that we published in our dataset, know that data relates to that individual.
    We could try to keep our hashing approach secret, but that is difficult as there
    are only a few that are widely used. One approach is to add a salt that we keep
    secret. This slightly changes the input. For instance, we could add the salt “_is_a_person”
    to all our names and then hash that, although a large random number might be a
    better option. Provided the salt is not shared, then it would be difficult for
    most people to reverse our approach in that way.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个存在的问题是任何人都可以利用哈希的关键特性来反推出输入。特别是，相同的输入总是得到相同的输出。因此，他们可以测试各种输入选项。例如，他们可以自己尝试对“Rohan”进行哈希处理，然后注意到哈希值与我们在数据集中发布的哈希值相同，知道数据与该个人相关。我们可以尝试保持我们的哈希方法保密，但这很难，因为广泛使用的只有少数几种。一种方法是在输入中添加一个我们保密的盐。这稍微改变了输入。例如，我们可以将盐“_is_a_person”添加到我们所有的名字中，然后对它们进行哈希处理，尽管一个大的随机数可能是一个更好的选择。只要盐不被共享，那么大多数人就很难以这种方式反推出我们的方法。
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*[PRE14]****  ***### 10.5.2 Simulation'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE14]****  ***### 10.5.2 模拟'
- en: One common approach to deal with the issue of being unable to share the actual
    data that underpins an analysis, is to use data simulation. We have used data
    simulation throughout this book toward the start of the workflow to help us to
    think more deeply about our dataset. We can use data simulation again at the end,
    to ensure that others cannot access the actual dataset.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 处理无法共享支撑分析的实际数据的问题的一个常见方法是用数据模拟。我们在本书的整个工作流程的开始阶段使用了数据模拟，以帮助我们更深入地思考我们的数据集。我们可以在结束时再次使用数据模拟，以确保其他人无法访问实际的数据集。
- en: The approach is to understand the critical features of the dataset and the appropriate
    distribution. For instance, if our data were the ages of some population, then
    we may want to use the Poisson distribution and experiment with different parameters
    for the rate. Having simulated a dataset, we conduct our analysis using this simulated
    dataset and ensure that the results are broadly similar to when we use the real
    data. We can then release the simulated dataset along with our code.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法是理解数据集的关键特征和适当的分布。例如，如果我们的数据是某个人口的年龄，那么我们可能想使用泊松分布并尝试不同的速率参数。在模拟了一个数据集之后，我们使用这个模拟数据集进行分析，并确保结果与使用真实数据时大致相似。然后我们可以发布模拟数据集以及我们的代码。
- en: For more nuanced situations, Koenecke and Varian ([2020](99-references.html#ref-koenecke2020synthetic))
    recommend using the synthetic data vault ([Patki, Wedge, and Veeramachaneni 2016](99-references.html#ref-patki2016synthetic))
    and then the use of Generative Adversarial Networks, such as implemented by Athey
    et al. ([2021](99-references.html#ref-athey2021using)).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的情况，Koenecke 和 Varian ([2020](99-references.html#ref-koenecke2020synthetic))
    建议使用合成数据仓库 ([Patki, Wedge, 和 Veeramachaneni 2016](99-references.html#ref-patki2016synthetic))，然后使用生成对抗网络（GANs），例如
    Athey 等人 ([2021](99-references.html#ref-athey2021using)) 实现的。
- en: 10.5.3 Differential privacy
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.3 差分隐私
- en: Differential privacy is a mathematical definition of privacy ([Dwork and Roth
    2013, 6](99-references.html#ref-Dwork2013)). It is not just one algorithm, it
    is a definition that many algorithms satisfy. Further, there are many definitions
    of privacy, of which differential privacy is just one. The main issue it solves
    is that there are many datasets available. This means there is always the possibility
    that some combination of them could be used to identify respondents even if PII
    were removed from each of these individual datasets. For instance, experience
    with the Netflix prize found that augmenting the available dataset with data from
    IMBD resulted in better predictions, which points to why this would so commonly
    happen. Rather than needing to anticipate how various datasets could be combined
    to re-identify individuals and adjust variables to remove this possibility, a
    dataset that is created using a differentially private approach provides assurances
    that privacy will be maintained.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私是一种数学上的隐私定义 ([Dwork 和 Roth 2013, 6](99-references.html#ref-Dwork2013))。它不仅仅是一个算法，而是一个许多算法都满足的定义。此外，还有许多隐私定义，其中差分隐私只是其中之一。它主要解决的问题是有许多数据集可用。这意味着总有可能某些组合被用来识别受访者，即使从这些个别数据集中移除了个人识别信息（PII）。例如，Netflix
    奖的经验表明，将可用数据集与 IMBD 的数据相结合可以改善预测，这表明这种情况为什么会如此普遍。而不是需要预测各种数据集如何组合以重新识别个人并调整变量以消除这种可能性，使用差分隐私方法创建的数据集可以提供保证，即隐私将得到维护。
- en: '*Shoulders of giants* *Cynthia Dwork is the Gordon McKay Professor of Computer
    Science at Harvard University. After earning a PhD in Computer Science from Cornell
    University, she was a Post-Doctoral Research Fellow at MIT and then worked at
    IBM, Compaq, and Microsoft Research where she is a Distinguished Scientist. She
    joined Harvard in 2017\. One of her major contributions is differential privacy
    ([Dwork et al. 2006](99-references.html#ref-dwork2006calibrating)), which has
    become widely used.*  *To motivate the definition, consider a dataset of responses
    and PII that only has one person in it. The release of that dataset, as is, would
    perfectly identify them. At the other end of the scale, consider a dataset that
    does not contain a particular person. The release of that dataset could, in general,
    never be linked to them because they are not in it.[¹](#fn1) Differential privacy,
    then, is about the inclusion or exclusion of particular individuals in a dataset.
    An algorithm is differentially private if the inclusion or exclusion of any particular
    person in a dataset has at most some given factor of an effect on the probability
    of some output ([Oberski and Kreuter 2020](99-references.html#ref-Oberski2020Differential)).
    The fundamental problem of data privacy is that we cannot have completely anonymized
    data that remains useful ([Dwork and Roth 2013, 6](99-references.html#ref-Dwork2013)).
    Instead, we must trade-off utility and privacy.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*巨人的肩膀* *Cynthia Dwork是哈佛大学计算机科学系的Gordon McKay教授。在康奈尔大学获得计算机科学博士学位后，她成为了麻省理工学院的博士后研究员，然后在IBM、Compaq和微软研究工作，在那里她是杰出科学家。她于2017年加入哈佛大学。她的主要贡献之一是差分隐私([Dwork等人
    2006](99-references.html#ref-dwork2006calibrating))，这已经成为广泛使用的技术。*  *为了说明定义，考虑一个只包含一个人的响应和PII的数据集。该数据集的发布，按原样，可以完美地识别他们。在另一端，考虑一个不包含特定个人的数据集。通常情况下，该数据集的发布永远不会与他们联系起来，因为他们不在其中。[¹](#fn1)
    差分隐私，因此，是关于特定个人在数据集中包含或排除的问题。如果一个算法在数据集中包含或排除任何特定个人对某些输出概率的影响至多只有一些给定的因子，则该算法是差分隐私的([Oberski和Kreuter
    2020](99-references.html#ref-Oberski2020Differential))。数据隐私的基本问题是，我们无法拥有既完全匿名又保持有用的数据([Dwork和Roth
    2013, 6](99-references.html#ref-Dwork2013))。相反，我们必须在效用和隐私之间进行权衡。'
- en: A dataset is differentially private to different levels of privacy, based on
    how much it changes when one person’s results are included or excluded. This is
    the key parameter, because at the same time as deciding how much of an individual’s
    information we are prepared to give up, we are deciding how much random noise
    to add, which will impact our output. The choice of this level is a nuanced one
    and should involve consideration of the costs of undesired disclosures, compared
    with the benefits of additional research. For public data that will be released
    under differential privacy, the reasons for the decision should be public because
    of the costs that are being imposed. Indeed, Tang et al. ([2017](99-references.html#ref-differentialprivacyatapple))
    argue that even in the case of private companies that use differential privacy,
    such as Apple, users should have a choice about the level of privacy loss.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个数据集根据一个人结果包含或排除时变化的大小，对不同的隐私级别具有不同的隐私性。这是关键参数，因为在决定我们愿意放弃多少个人信息的同时，我们也在决定要添加多少随机噪声，这将影响我们的输出。这个级别的选择是一个微妙的选择，应该涉及对不希望泄露的成本与额外研究收益的比较。对于将在差分隐私下发布的公共数据，决策的原因应该是公开的，因为正在施加的成本。确实，Tang等人([2017](99-references.html#ref-differentialprivacyatapple))认为，即使在像苹果这样的使用差分隐私的私营公司的情况下，用户也应该有选择隐私损失级别的权利。
- en: Consider a situation in which a professor wants to release the average mark
    for a particular assignment. The professor wants to ensure that despite that information,
    no student can work out the grade that another student got. For instance, consider
    a small class with the following marks.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种情况，教授想要发布某个特定作业的平均分。教授希望确保即使有了这个信息，也没有学生能够计算出其他学生的分数。例如，考虑一个有以下分数的小班。
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*[PRE16]*  *The professor could announce the exact mean, for instance, “The
    mean for the first problem set was 50.5”. Theoretically, all-but-one student could
    let the others know their mark. It would then be possible for that group to determine
    the mark of the student who did not agree to make their mark public.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE16]*  *教授可以宣布确切的平均分，例如，“第一次作业的平均分是50.5”。理论上，除了一个学生外，其他所有学生都可以让其他人知道他们的分数。这样，这个小组就可以确定那个不同意公开分数的学生分数了。'
- en: A non-statistical approach would be for the professor to add the word “roughly”.
    For instance, the professor could say “The mean for the first problem set was
    roughly 50.5”. The students could attempt the same strategy, but they would never
    know with certainty. The professor could implement a more statistical approach
    to this by adding noise to the mean.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一种非统计方法教授可以添加“大致”这个词。例如，教授可以说“第一个问题集的平均值大致是50.5”。学生们可以尝试同样的策略，但他们永远不会确定。教授可以通过向平均值添加噪声来实施一种更统计的方法。
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*[PRE18]*  *The professor could then announce this modified mean. This would
    make the students’ plan more difficult. One thing to notice about that approach
    is that it would not work with persistent questioning. For instance, eventually
    the students would be able to back out the distribution of the noise that the
    professor added. One implication is that the professor would need to limit the
    number of queries they answered about the mean of the problem set.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE18]* *教授可以宣布这个修改后的平均值。这将使学生的计划更难。关于那种方法的一个要注意的事情是它不会与持续的提问一起工作。例如，最终学生们能够回溯出教授添加的噪声分布。一个影响是教授需要限制他们关于问题集平均值的查询数量。'
- en: A differentially private approach is a sophisticated version of this. We can
    implement it using `diffpriv`. This results in a mean that we could announce ([Table 10.1](#tbl-diffprivaexample)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私方法是这个方法的复杂版本。我们可以使用`diffpriv`来实现它。这导致了一个我们可以公告的平均值（[表10.1](#tbl-diffprivaexample)）。
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Table 10.1: Comparing the actual mean with a differentially private mean'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*表10.1：比较实际平均值与差分隐私平均值*'
- en: '| Actual mean | Announceable mean |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 实际平均值 | 可公告的平均值 |'
- en: '| --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 50.5 | 52.5 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 50.5 | 52.5 |'
- en: The implementation of differential privacy is a costs and benefits issue ([Hotz
    et al. 2022](99-references.html#ref-hotz2022balancing); [Kenny et al. 2023](99-references.html#ref-kennetal22)).
    Stronger privacy protection fundamentally must mean less information ([Bowen 2022,
    39](99-references.html#ref-clairemckaybowen)), and this differently affects various
    aspects of society. For instance, Suriyakumar et al. ([2021](99-references.html#ref-Suriyakumar2021))
    found that, in the context of health care, differentially private learning can
    result in models that are disproportionately affected by large demographic groups.
    A variant of differential privacy has recently been implemented by the US census.
    It may have a significant effect on redistricting ([Kenny et al. 2021](99-references.html#ref-kenny2021impact))
    and result in some publicly available data that are unusable in the social sciences
    ([Ruggles et al. 2019](99-references.html#ref-ruggles2019differential)).*******  ****##
    10.6 Data efficiency
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 差分隐私的实施是一个成本和收益问题（[Hotz等人2022](99-references.html#ref-hotz2022balancing)；[Kenny等人2023](99-references.html#ref-kennetal22)）。更强的隐私保护从根本上意味着更少的信息（[Bowen
    2022, 39](99-references.html#ref-clairemckaybowen)），并且这会不同地影响社会的各个方面。例如，Suriyakumar等人（[2021](99-references.html#ref-Suriyakumar2021)）发现，在医疗保健的背景下，差分隐私学习可能导致模型受到大型人口群体的不成比例的影响。美国人口普查最近实施了一种差分隐私的变体。它可能对重新划区有重大影响（[Kenny等人2021](99-references.html#ref-kenny2021impact)），并导致一些公开可用的数据在社会科学中无法使用（[Ruggles等人2019](99-references.html#ref-ruggles2019differential)）。*******
    ****
- en: For the most part, done is better than perfect, and unnecessary optimization
    is a waste of resources. However, at a certain point, we need to adapt new ways
    of dealing with data, especially as our datasets start to get larger. Here we
    discuss iterating through multiple files, and then turn to the use of Apache Arrow
    and parquet. Another natural step would be the use of SQL, which is covered in
    [Online Appendix C](22-sql_essentials.html).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，完成比完美更重要，不必要的优化是资源的浪费。然而，在某个时刻，我们需要适应新的数据处理方式，尤其是当我们的数据集开始变得更大时。在这里，我们讨论通过多个文件迭代，然后转向使用Apache
    Arrow和parquet。另一个自然的步骤是使用SQL，这在[在线附录C](22-sql_essentials.html)中有介绍。
- en: 10.6.1 Iteration
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.1 迭代
- en: There are several ways to become more efficient with our data, especially as
    it becomes larger. The first, and most obvious, is to break larger datasets into
    smaller pieces. For instance, if we have a dataset for a year, then we could break
    it into months, or even days. To enable this, we need a way of quickly reading
    in many different files.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以使我们的数据更高效，尤其是当数据变得更大时。首先，也是最明显的方法，是将较大的数据集分成更小的部分。例如，如果我们有一个一年的数据集，那么我们可以将其分成月份，甚至天数。为了实现这一点，我们需要一种快速读取许多不同文件的方法。
- en: The need to read in multiple files and combine them into the one tibble is a
    surprisingly common task. For instance, it may be that the data for a year, are
    saved into individual CSV files for each month. We can use `purrr` and `fs` to
    do this. To illustrate this situation we will simulate data from the exponential
    distribution using `rexp()`. Such data may reflect, say, comments on a social
    media platform, where the vast majority of comments are made by a tiny minority
    of users. We will use `dir_create()` from `fs` to create a folder, simulate monthly
    data, and save it. We will then illustrate reading it in.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 需要读取多个文件并将它们合并成一个tibble的任务出奇地常见。例如，可能一年的数据被保存为每个月份的单独CSV文件。我们可以使用`purrr`和`fs`来完成这项工作。为了说明这种情况，我们将使用`rexp()`模拟指数分布的数据。这样的数据可能反映了社交媒体平台上的评论，其中绝大多数评论是由少数用户发表的。我们将使用`fs`中的`dir_create()`来创建一个文件夹，模拟月度数据并保存它。然后我们将展示如何读取它。
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Having created our dataset with each month saved to a different CSV, we can
    now read it in. There are a variety of ways to do this. The first step is that
    we need to get a list of all the CSV files in the directory. We use the “glob”
    argument here to specify that we are interested only in the “.csv” files, and
    that could change to whatever files it is that we are interested in.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*在创建我们的数据集，每个月份都保存到不同的CSV文件后，我们现在可以读取它了。有各种方法可以做到这一点。第一步是我们需要获取目录中所有CSV文件的一个列表。在这里我们使用“glob”参数来指定我们只对“.csv”文件感兴趣，并且这可以改变为我们感兴趣的任何文件。'
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE22]'
- en: We can pass this list to `read_csv()` and it will read them in and combine them.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个列表传递给 `read_csv()`，然后它会读取它们并合并。
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE24]'
- en: It prints out the first ten days of April, because alphabetically April is the
    first month of the year and so that was the first CSV that was read.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 它会打印出四月的头十天，因为按字母顺序，四月是一年中的第一个月份，所以这是第一个被读取的CSV文件。
- en: This works well when we have CSV files, but we might not always have CSV files
    and so will need another way, and can use `map_dfr()` to do this. One nice aspect
    of this approach is that we can include the name of the file alongside the observation
    using “.id”. Here we specify that we would like that column to be called “file”,
    but it could be anything.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有CSV文件时，这工作得很好，但我们可能并不总是有CSV文件，因此需要另一种方法，并且可以使用 `map_dfr()` 来实现这一点。这种方法的一个优点是，我们可以使用“.id”将文件名与观测值一起包含。在这里我们指定我们希望该列被称为“file”，但它可以是任何名称。
- en: '[PRE25]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '*[PRE26]****  ***### 10.6.2 Apache Arrow'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE26]****  ***### 10.6.2 Apache Arrow'
- en: CSVs are commonly used without much thought in data science. And while CSVs
    are good because they have little overhead and can be manually inspected, this
    also means they are quite minimal. This can lead to issues, for instance class
    is not preserved, and file sizes can become large leading to storage and performance
    issues. There are various alternatives, including Apache Arrow, which stores data
    in columns rather than rows like CSV. We focus on the “.parquet” format from Apache
    Arrow. Like a CSV, parquet is an open standard. The R package, `arrow`, enables
    us to use this format. The use of parquet has the advantage of requiring little
    change from us while delivering significant benefits.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，CSV通常被不加思考地使用。虽然CSV很好，因为它们的开销很小，可以手动检查，但这也意味着它们非常简单。这可能导致问题，例如类信息没有被保留，文件大小可能变得很大，导致存储和性能问题。有各种替代方案，包括Apache
    Arrow，它将数据存储在列中而不是行中，就像CSV一样。我们专注于Apache Arrow的“ .parquet”格式。与CSV一样，parquet是一个开放标准。R包`arrow`使我们能够使用这种格式。使用parquet的优势在于，我们几乎不需要做出任何改变，同时带来显著的好处。
- en: '*Shoulders of giants* *Wes McKinney holds an undergraduate degree in theoretical
    mathematics from MIT. Starting in 2008, while working at AQR Capital Management,
    he developed the Python package, pandas, which has become a cornerstone of data
    science. He later wrote *Python for Data Analysis* ([McKinney [2011] 2022](99-references.html#ref-pythonfordataanalysis)).
    In 2016, with Hadley Wickham, he designed Feather, which was released in 2016\.
    He now works as CTO of Voltron Data, which focuses on the Apache Arrow project.*  *In
    particular, we focus on the benefit of using parquet for data storage, such as
    when we want to save a copy of an analysis dataset that we cleaned and prepared.
    Among other aspects, parquet brings two specific benefits, compared with CSV:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*巨人的肩膀* *Wes McKinney拥有麻省理工学院理论数学的学士学位。从2008年开始，在AQR Capital Management工作期间，他开发了Python包pandas，该包已成为数据科学的基础。他后来写了《Python
    for Data Analysis》([McKinney [2011] 2022](99-references.html#ref-pythonfordataanalysis))。2016年，他与Hadley
    Wickham一起设计了Feather，该工具于2016年发布。他现在在Voltron Data公司担任CTO，该公司专注于Apache Arrow项目。*  *特别是，我们关注使用Parquet进行数据存储的好处，例如当我们想要保存我们清理和准备的分析数据集的副本时。与其他方面相比，Parquet相对于CSV带来了两个具体的优势：**'
- en: the file sizes are typically smaller; and
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件大小通常更小；
- en: class is preserved because parquet attaches a schema, which makes dealing with,
    say, dates and factors considerably easier.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别信息被保留，因为Parquet附加了一个模式，这使得处理日期和因子等数据变得相当容易。
- en: Having loaded `arrow`, we can use parquet files in a similar way to CSV files.
    Anywhere in our code that we used `write_csv()` and `read_csv()` we could alternatively,
    or additionally, use `write_parquet()` and `read_parquet()`, respectively. The
    decision to use parquet needs to consider both costs and benefits, and it is an
    active area of development.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载了`arrow`之后，我们可以以类似CSV文件的方式使用Parquet文件。在我们的代码中，任何使用`write_csv()`和`read_csv()`的地方，我们都可以选择性地或附加地使用`write_parquet()`和`read_parquet()`，分别。使用Parquet的决定需要考虑成本和收益，并且这是一个活跃的开发领域。
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE28]'
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*[PRE30]**  **We can write a parquet file with `write_parquet()` and we can
    read a parquet with `read_parquet()`. We get significant reductions in file size
    when we compare the size of the same datasets saved in each format, especially
    as they get larger ([Table 10.2](#tbl-filesize)). The speed benefits of using
    parquet are most notable for larger datasets. It turns them from being impractical
    to being usable.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE30]**  **我们可以使用`write_parquet()`来写入Parquet文件，并使用`read_parquet()`来读取Parquet文件。当我们比较以每种格式保存的相同数据集的大小，尤其是当数据集变得更大时，我们会发现文件大小的显著减少（[表10.2](#tbl-filesize)）。使用Parquet的速度优势在处理大型数据集时最为明显。它将不切实际的数据集转变为可用的数据集。**'
- en: 'Table 10.2: Comparing the file sizes, and read and write times, of CSV and
    parquet as the file size increases'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2：随着文件大小的增加，比较CSV和Parquet的文件大小、读取和写入时间
- en: '| Number | CSV size | CSV write time (sec) | CSV read time (sec) | Parquet
    size | Parquet write time (sec) | Parquet read time (sec) |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 数量 | CSV大小 | CSV写入时间（秒） | CSV读取时间（秒） | Parquet大小 | Parquet写入时间（秒） | Parquet读取时间（秒）
    |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1e+02 | 3,102.72 | 0.01 | 0.26 | 2,713.6 | 0.01 | 0 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 1e+02 | 3,102.72 | 0.01 | 0.26 | 2,713.6 | 0.01 | 0 |'
- en: '| 1e+03 | 30,720 | 0.02 | 0.27 | 11,366.4 | 0.01 | 0 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 1e+03 | 30,720 | 0.02 | 0.27 | 11,366.4 | 0.01 | 0 |'
- en: '| 1e+04 | 307,415.04 | 0.02 | 0.3 | 101,969.92 | 0.01 | 0.01 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 1e+04 | 307,415.04 | 0.02 | 0.3 | 101,969.92 | 0.01 | 0.01 |'
- en: '| 1e+05 | 3,072,327.68 | 0.03 | 0.28 | 1,040,885.76 | 0.04 | 0.01 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 1e+05 | 3,072,327.68 | 0.03 | 0.28 | 1,040,885.76 | 0.04 | 0.01 |'
- en: '| 1e+06 | 30,712,791.04 | 0.15 | 0.58 | 8,566,865.92 | 0.22 | 0.05 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 1e+06 | 30,712,791.04 | 0.15 | 0.58 | 8,566,865.92 | 0.22 | 0.05 |'
- en: '| 1e+07 | 307,117,424.64 | 1 | 2.95 | 82,952,847.36 | 1.76 | 0.42 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 1e+07 | 307,117,424.64 | 1 | 2.95 | 82,952,847.36 | 1.76 | 0.42 |'
- en: '| 1e+08 | 3,070,901,616.64 | 7.65 | 32.89 | 827,137,720.32 | 16.12 | 4.85 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 1e+08 | 3,070,901,616.64 | 7.65 | 32.89 | 827,137,720.32 | 16.12 | 4.85 |'
- en: Crane, Hazlitt, and Arrow ([2023](99-references.html#ref-arrowcookbook)) provides
    further information about specific tasks, Navarro ([2022](99-references.html#ref-navarro2021getting))
    provides helpful examples of implementation, and Navarro, Keane, and Hazlitt ([2022](99-references.html#ref-navarroworkshop))
    provides an extensive set of materials. There is no settled consensus on whether
    parquet files should be used exclusively for dataset. But it is indisputable that
    the persistence of class alone provides a compelling reason for including them
    in addition to a CSV.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Crane, Hazlitt, 和 Arrow ([2023](99-references.html#ref-arrowcookbook)) 提供了关于特定任务的更多信息，Navarro
    ([2022](99-references.html#ref-navarro2021getting)) 提供了实施的有用示例，Navarro, Keane,
    和 Hazlitt ([2022](99-references.html#ref-navarroworkshop)) 提供了一套广泛的材料。关于是否应该仅使用parquet文件来存储数据集，没有达成共识。但不可否认的是，仅凭类的持久性就为包括它们提供了一个强有力的理由，除了CSV之外。
- en: We will use parquet more in the remainder of this book.******  ****## 10.7 Exercises
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，我们将更多地使用parquet格式。******  ****## 10.7 练习
- en: Practice
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: '*(Plan)* Consider the following scenario: *You work for a large news media
    company and focus on subscriber management. Over the course of a year most subscribers
    will never post a comment beneath a news article, but a few post an awful lot.*
    Please sketch what that dataset could look like and then sketch a graph that you
    could build to show all observations.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(计划)* 考虑以下场景：*你在一家大型新闻媒体公司工作，专注于订阅者管理。在一年中，大多数订阅者永远不会在新闻文章下发表评论，但少数人却会发表大量评论。*请描绘出这个数据集可能的样子，然后描绘出一个可以展示所有观察结果的图表。'
- en: '*(Simulate)* Please further consider the scenario described and simulate the
    situation. Carefully pick an appropriate distribution. Please include five tests
    based on the simulated data. Submit a link to a GitHub Gist that contains your
    code.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(模拟)* 请进一步考虑所描述的场景，并模拟这种情况。仔细选择一个合适的分布。请包括基于模拟数据的五个测试。提交一个包含你代码的GitHub Gist链接。'
- en: '*(Acquire)* Please describe one possible source of such a dataset.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(获取)* 请描述一个可能的数据集来源。'
- en: '*(Explore)* Please use `ggplot2` to build the graph that you sketched. Submit
    a link to a GitHub Gist that contains your code.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(探索)* 请使用 `ggplot2` 构建你绘制的图表。提交一个包含你代码的GitHub Gist链接。'
- en: '*(Communicate)* Please write two paragraphs about what you did.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*(沟通)* 请写两段关于你所做的事情的描述。'
- en: Quiz
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测验
- en: Following Wilkinson et al. ([2016](99-references.html#ref-wilkinson2016fair)),
    please discuss the FAIR principles in the context of a dataset that you are familiar
    with (begin with a one-paragraph summary of the dataset, then write one paragraph
    per principle).
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据 Wilkinson 等人 ([2016](99-references.html#ref-wilkinson2016fair))，请在一个你熟悉的数据集的背景下讨论FAIR原则（首先用一个段落总结数据集，然后针对每个原则写一个段落）。
- en: Please create a R package for a simulated dataset, push it to GitHub, and submit
    code to install the package (e.g. `devtools::install_github("RohanAlexander/favcolordata")`).
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请创建一个模拟数据集的R包，推送到GitHub，并提交安装包的代码（例如，`devtools::install_github("RohanAlexander/favcolordata")`）。
- en: 'According to Gebru et al. ([2021](99-references.html#ref-gebru2021datasheets)),
    a datasheet should document a dataset’s (please select all that apply):'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据 Gebru 等人 ([2021](99-references.html#ref-gebru2021datasheets))，数据表应该记录数据集的（请选择所有适用的）：
- en: composition.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 组成。
- en: recommended uses.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推荐用途。
- en: motivation.
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 动机。
- en: collection process.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集过程。
- en: Discuss, with the help of examples and references, whether a person’s name is
    PII (please write at least three paragraphs)?
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用例子和参考文献讨论一个人的名字是否是PII（请至少写三个段落）？
- en: Using `md5()` what is the hash of “Monica” (pick one)?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `md5()`，"Monica" 的哈希值是多少（选择一个）？
- en: 243f63354f4c1cc25d50f6269b844369
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 243f63354f4c1cc25d50f6269b844369
- en: 02df8936eee3d4d2568857ed530671b2
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 02df8936eee3d4d2568857ed530671b2
- en: 09084cc0cda34fd80bfa3cc0ae8fe3dc
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 09084cc0cda34fd80bfa3cc0ae8fe3dc
- en: 1b3840b0b70d91c17e70014c8537dbba
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1b3840b0b70d91c17e70014c8537dbba
- en: Please save the `penguins` data from from `palmerpenguins` as a CSV file and
    as a Parquet file. How big are they?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请将 `palmerpenguins` 中的 `penguins` 数据保存为CSV文件和Parquet文件。它们有多大？
- en: 12.5K; 6.04K
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 12.5K; 6.04K
- en: 14.9K; 6.04K
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 14.9K; 6.04K
- en: 14.9K; 5.02K
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 14.9K; 5.02K
- en: 12.5K; 5.02K
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 12.5K; 5.02K
- en: Class activities
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 课堂活动
- en: Use the [starter folder](https://github.com/RohanAlexander/starter_folder) and
    create a new repo. Add a link to the GitHub repo in the class’s shared Google
    Doc.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [starter folder](https://github.com/RohanAlexander/starter_folder) 创建一个新的仓库。在班级共享的Google文档中添加GitHub仓库的链接。
- en: Add the following code to a simulation R script, then lint it. What do you think
    about the recommendations?
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将以下代码添加到模拟R脚本中，然后进行代码审查。你对这些建议有什么看法？
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**   Simulate a dataset with ten million observations and at least five variables,
    one of which must be a date. Save it in both CSV and parquet formats. What is
    the file size difference?'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**   模拟一个包含一千万个观测值和至少五个变量的数据集，其中一个必须是日期。以 CSV 和 parquet 格式保存。文件大小差异是多少？'
- en: Discuss datasheets in the context of the dataset that you simulated.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您模拟的数据集的背景下讨论数据表。
- en: Pretend you were joining two datasets with `left_join()`. When joining datasets
    it is easy to accidentally duplicate or remove rows. Please add some tests that
    might put your mind at ease.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**   假设您正在使用 `left_join()` 连接两个数据集。在连接数据集时，很容易不小心重复或删除行。请添加一些可能让您放心的测试。'
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '**   Modify the following code to show why using “T” instead of “TRUE” should
    generally not be done (hint: assign “T” to “FALSE”)?'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**   修改以下代码以展示为什么通常不应该使用“T”而不是“TRUE”（提示：将“T”赋值为“FALSE”）？'
- en: '[PRE33]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*[PRE34]*  **   Working with the instructor, pick a chapter from Lewis ([2024](99-references.html#ref-lewiscrystal))
    and create a five-slide summary of the key take-aways from the chapter. Present
    to the class.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '*[PRE34]*  **   与指导老师一起，从 Lewis ([2024](99-references.html#ref-lewiscrystal))
    的书中选择一章，并创建一个五页的总结，总结本章的关键要点。向全班展示。'
- en: Working with the instructor, make a pull request that fixes some small aspect
    of a work-in-progress book.[²](#fn2) Options include:[³](#fn3) Lewis ([2024](99-references.html#ref-lewiscrystal))
    or Wickham, Çetinkaya-Rundel, and Grolemund ([[2016] 2023](99-references.html#ref-r4ds)).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**   与指导老师一起，提交一个修复正在进行的书籍某个小方面的拉取请求。[²](#fn2) 选项包括：[³](#fn3) Lewis ([2024](99-references.html#ref-lewiscrystal))
    或 Wickham, Çetinkaya-Rundel, 和 Grolemund ([[2016] 2023](99-references.html#ref-r4ds))。'
- en: Pretend that you are in a small class, and have some results from an assessment
    ([Table 10.3](#tbl-classmarks)). Use the code, but change the seed to generate
    your own dataset.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**   假设您在一个小班上课，并有一些评估结果（[表10.3](#tbl-classmarks)）。使用代码，但更改种子以生成您自己的数据集。'
- en: Hash, but do not salt, the names, and then exchange with another group. Can
    they work out what the names are?
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对姓名进行散列，但不加盐，然后与另一组交换。他们能否推断出这些姓名？
- en: Continuing with the results that you generated, please write code that simulates
    the dataset. You will need to decide which features are important and which are
    not. Note two interesting aspects of this and then share with the class.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续使用您生成的结果，请编写代码来模拟数据集。您需要决定哪些特征是重要的，哪些不是。注意这个问题的两个有趣方面，然后与全班分享。
- en: 'Continuing with the results that you generated, please: 1) work out the class
    mean, 2) remove the mark of one student, 3) provide the mean and the off-by-one
    dataset to another group. Can they work out the mark of the student who opted
    not to share?'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续使用您生成的结果，请：1）计算班级平均分，2）移除一名学生的标记，3）将平均分和偏移量数据集提供给另一组。他们能否推断出未分享的学生分数？
- en: Finally, please do the same exercise, but create a differentially private mean.
    What are they able to figure out now?
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，请进行同样的练习，但创建一个差分隐私平均数。现在他们能推断出什么？
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '*Table 10.3: Simulated students and their mark (out of 100) in a particular
    class paper'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '*表10.3：模拟学生及其在特定课程论文中的分数（满分100分）'
- en: '| Student | Mark |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 学生 | 分数 |'
- en: '| --- | --- |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Bertha | 37 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| Bertha | 37 |'
- en: '| Tyler | 32 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| Tyler | 32 |'
- en: '| Kevin | 48 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| Kevin | 48 |'
- en: '| Ryan | 39 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Ryan | 39 |'
- en: '| Robert | 34 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| Robert | 34 |'
- en: '| Jennifer | 52 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| Jennifer | 52 |'
- en: '| Donna | 48 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| Donna | 48 |'
- en: '| Karen | 43 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| Karen | 43 |'
- en: '| Emma | 61 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| Emma | 61 |'
- en: '| Arthur | 55 |****  ***### Task'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '| Arthur | 55 |'
- en: Please identify a dataset you consider interesting and important, that does
    not have a datasheet ([Gebru et al. 2021](99-references.html#ref-gebru2021datasheets)).
    As a reminder, datasheets accompany datasets and document “motivation, composition,
    collection process, recommended uses,” among other aspects. Please put together
    a datasheet for this dataset. You are welcome to use the template in the [starter
    folder](https://github.com/RohanAlexander/starter_folder).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请确定一个您认为有趣且重要的数据集，该数据集没有数据表（[Gebru 等人 2021](99-references.html#ref-gebru2021datasheets)）。提醒一下，数据表伴随数据集，并记录“动机、组成、收集过程、推荐用途”等方面的内容。请为这个数据集准备一个数据表。您可以使用[入门文件夹](https://github.com/RohanAlexander/starter_folder)中的模板。
- en: Use Quarto, and include an appropriate title, author, date, link to a GitHub
    repo, and citations to produce a draft. Following this, please pair with another
    student and exchange your written work. Update it based on their feedback, and
    be sure to acknowledge them by name in your paper. Submit a PDF.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Quarto，并包含一个合适的标题、作者、日期、指向 GitHub 仓库的链接以及引用来生成草稿。之后，请与另一位学生配对并交换你们的书面作品。根据他们的反馈进行更新，并确保在你们的论文中按名字提及他们。提交一个
    PDF 文件。
- en: Paper
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 论文
- en: At about this point the *Dysart* Paper from [Online Appendix F](25-papers.html)
    would be appropriate.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 大概在这个时候，[在线附录 F](25-papers.html) 中的 *Dysart* 论文是合适的。
- en: 'Annas, George. 2003\. “HIPAA Regulations: A New Era of Medical-Record Privacy?”
    *New England Journal of Medicine* 348 (15): 1486–90\. [https://doi.org/10.1056/NEJMlim035027](https://doi.org/10.1056/NEJMlim035027).Arel-Bundock,
    Vincent. 2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,”
    “Markdown,” “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Arel-Bundock,
    Vincent, Ryan Briggs, Hristos Doucouliagos, Marco Mendoza Aviña, and T. D. Stanley.
    2022\. “Quantitative Political Science Research Is Greatly Underpowered.” [https://osf.io/bzj9y/](https://osf.io/bzj9y/).Athey,
    Susan, Guido Imbens, Jonas Metzger, and Evan Munro. 2021\. “Using Wasserstein
    Generative Adversarial Networks for the Design of Monte Carlo Simulations.” *Journal
    of Econometrics*. [https://doi.org/10.1016/j.jeconom.2020.09.013](https://doi.org/10.1016/j.jeconom.2020.09.013).Bandy,
    John, and Nicholas Vincent. 2021\. “Addressing ‘Documentation Debt’ in Machine
    Learning: A Retrospective Datasheet for BookCorpus.” In *Proceedings of the Neural
    Information Processing Systems Track on Datasets and Benchmarks*, edited by J.
    Vanschoren and S. Yeung. Vol. 1\. [https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf).Bender,
    Emily, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021\.
    “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” In *Proceedings
    of the 2021 ACM Conference on Fairness, Accountability, and Transparency*. ACM.
    [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922).Berners-Lee,
    Timothy. 1989\. “Information Management: A Proposal.” [https://www.w3.org/History/1989/proposal.html](https://www.w3.org/History/1989/proposal.html).Biderman,
    Stella, Kieran Bicheno, and Leo Gao. 2022\. “Datasheet for the Pile.” [https://arxiv.org/abs/2201.07311](https://arxiv.org/abs/2201.07311).Borghi,
    John, and Ana Van Gulick. 2022\. “Promoting Open Science Through Research Data
    Management.” *Harvard Data Science Review* 4 (3). [https://doi.org/10.1162/99608f92.9497f68e](https://doi.org/10.1162/99608f92.9497f68e).Bowen,
    Claire McKay. 2022\. *Protecting Your Privacy in a Data-Driven World*. 1st ed.
    Chapman; Hall/CRC. [https://doi.org/10.1201/9781003122043](https://doi.org/10.1201/9781003122043).Buneman,
    Peter, Sanjeev Khanna, and Tan Wang-Chiew. 2001\. “Why and Where: A Characterization
    of Data Provenance.” In *Database Theory ICDT 2001*, 316–30\. Springer Berlin
    Heidelberg. [https://doi.org/10.1007/3-540-44503-x_20](https://doi.org/10.1007/3-540-44503-x_20).Buolamwini,
    Joy, and Timnit Gebru. 2018\. “Gender Shades: Intersectional Accuracy Disparities
    in Commercial Gender Classification.” In *Conference on Fairness, Accountability
    and Transparency*, 77–91.Bush, Vannevar. 1945\. “As We May Think.” *The Atlantic
    Monthly*, July. [https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/](https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/).Byrd,
    James Brian, Anna Greene, Deepashree Venkatesh Prasad, Xiaoqian Jiang, and Casey
    Greene. 2020\. “Responsible, Practical Genomic Data Sharing That Accelerates Research.”
    *Nature Reviews Genetics* 21 (10): 615–29\. [https://doi.org/10.1038/s41576-020-0257-5](https://doi.org/10.1038/s41576-020-0257-5).Carleton,
    Chris. 2021\. “wccarleton/conflict-europe: Acce.” Zenodo. [https://doi.org/10.5281/zenodo.4550688](https://doi.org/10.5281/zenodo.4550688).Carleton,
    Chris, Dave Campbell, and Mark Collard. 2021\. “A Reassessment of the Impact of
    Temperature Change on European Conflict During the Second Millennium CE Using
    a Bespoke Bayesian Time-Series Model.” *Climatic Change* 165 (1): 1–16\. [https://doi.org/10.1007/s10584-021-03022-2](https://doi.org/10.1007/s10584-021-03022-2).Christensen,
    Garret, Allan Dafoe, Edward Miguel, Don Moore, and Andrew Rose. 2019\. “A Study
    of the Impact of Data Sharing on Article Citations Using Journal Policies as a
    Natural Experiment.” *PLOS ONE* 14 (12): e0225883\. [https://doi.org/10.1371/journal.pone.0225883](https://doi.org/10.1371/journal.pone.0225883).Christensen,
    Garret, Jeremy Freese, and Edward Miguel. 2019\. *Transparent and Reproducible
    Social Science Research*. California: University of California Press.Cohen, Glenn,
    and Michelle Mello. 2018\. “HIPAA and Protecting Health Information in the 21st
    Century.” *JAMA* 320 (3): 231\. [https://doi.org/10.1001/jama.2018.5630](https://doi.org/10.1001/jama.2018.5630).Council
    of European Union. 2016\. “General Data Protection Regulation 2016/679.” [https://eur-lex.europa.eu/eli/reg/2016/679/oj](https://eur-lex.europa.eu/eli/reg/2016/679/oj).Crane,
    Nicola, Stephanie Hazlitt, and Apache Arrow. 2023\. *Apache Arrow R Cookbook*.
    [https://arrow.apache.org/cookbook/r/](https://arrow.apache.org/cookbook/r/).Dwork,
    Cynthia, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006\. “Calibrating Noise
    to Sensitivity in Private Data Analysis.” In *Theory of Cryptography Conference*,
    265–84\. Springer. [https://doi.org/10.1007/11681878_14](https://doi.org/10.1007/11681878_14).Dwork,
    Cynthia, and Aaron Roth. 2013\. “The Algorithmic Foundations of Differential Privacy.”
    *Foundations and Trends in Theoretical Computer Science* 9 (3-4): 211–407\. [https://doi.org/10.1561/0400000042](https://doi.org/10.1561/0400000042).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gebru,
    Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach,
    Hal Daumé III, and Kate Crawford. 2021\. “Datasheets for Datasets.” *Communications
    of the ACM* 64 (12): 86–92\. [https://doi.org/10.1145/3458723](https://doi.org/10.1145/3458723).Geuenich,
    Michael, Jinyu Hou, Sunyun Lee, Shanza Ayub, Hartland Jackson, and Kieran Campbell.
    2021a. “Automated Assignment of Cell Identity from Single-Cell Multiplexed Imaging
    and Proteomic Data.” *Cell Systems* 12 (12): 1173–86\. [https://doi.org/10.1016/j.cels.2021.08.012](https://doi.org/10.1016/j.cels.2021.08.012).———.
    2021b. “Replication Materials: "Automated Assignment of Cell Identity from Single-Cell
    Multiplexed Imaging and Proteomic Data".” [https://doi.org/10.5281/ZENODO.5156049](https://doi.org/10.5281/ZENODO.5156049).Greenberg,
    Bernard, Abdel-Latif Abul-Ela, Walt Simmons, and Daniel Horvitz. 1969\. “The Unrelated
    Question Randomized Response Model: Theoretical Framework.” *Journal of the American
    Statistical Association* 64 (326): 520–39\. [https://doi.org/10.1080/01621459.1969.10500991](https://doi.org/10.1080/01621459.1969.10500991).Hart,
    Edmund, Pauline Barmby, David LeBauer, François Michonneau, Sarah Mount, Patrick
    Mulrooney, Timothée Poisot, Kara Woo, Naupaka Zimmerman, and Jeffrey Hollister.
    2016\. “Ten Simple Rules for Digital Data Storage.” *PLOS Computational Biology*
    12 (10): e1005097\. [https://doi.org/10.1371/journal.pcbi.1005097](https://doi.org/10.1371/journal.pcbi.1005097).Heil,
    Benjamin, Michael Hoffman, Florian Markowetz, Su-In Lee, Casey Greene, and Stephanie
    Hicks. 2021\. “Reproducibility Standards for Machine Learning in the Life Sciences.”
    *Nature Methods* 18 (10): 1132–35\. [https://doi.org/10.1038/s41592-021-01256-7](https://doi.org/10.1038/s41592-021-01256-7).Hester,
    Jim, Hadley Wickham, and Gábor Csárdi. 2021\. *fs: Cross-Platform File System
    Operations Based on “libuv”*. [https://CRAN.R-project.org/package=fs](https://CRAN.R-project.org/package=fs).Hotz,
    Joseph, Christopher Bollinger, Tatiana Komarova, Charles Manski, Robert Moffitt,
    Denis Nekipelov, Aaron Sojourner, and Bruce Spencer. 2022\. “Balancing Data Privacy
    and Usability in the Federal Statistical System.” *Proceedings of the National
    Academy of Sciences* 119 (31): 1–10\. [https://doi.org/10.1073/pnas.2104906119](https://doi.org/10.1073/pnas.2104906119).Izrailev,
    Sergei. 2022\. *tictoc: Functions for Timing R Scripts, as Well as Implementations
    of “Stack” and “List” Structures*. [https://CRAN.R-project.org/package=tictoc](https://CRAN.R-project.org/package=tictoc).Katz,
    Lindsay, and Rohan Alexander. 2023a. “A new, comprehensive database of all proceedings
    of the Australian Parliamentary Debates (1998-2022).” Zenodo. [https://doi.org/10.5281/zenodo.7799678](https://doi.org/10.5281/zenodo.7799678).———.
    2023b. “Digitization of the Australian Parliamentary Debates, 1998–2022.” *Scientific
    Data* 10 (1): 1–14\. [https://doi.org/10.1038/s41597-023-02464-w](https://doi.org/10.1038/s41597-023-02464-w).Kenny,
    Christopher T., Shiro Kuriwaki, Cory McCartan, Evan T. R. Rosenman, Tyler Simko,
    and Kosuke Imai. 2021\. “The use of differential privacy for census data and its
    impact on redistricting: The case of the 2020 U.S. Census.” *Science Advances*
    7 (41). [https://doi.org/10.1126/sciadv.abk3283](https://doi.org/10.1126/sciadv.abk3283).———.
    2023\. “Comment: The Essential Role of Policy Evaluation for the 2020 Census Disclosure
    Avoidance System.” *Harvard Data Science Review*, no. Special Issue 2\. [https://doi.org/10.1162/99608f92.abc2c765](https://doi.org/10.1162/99608f92.abc2c765).Knuth,
    Donald. 1998\. *Art of Computer Programming, Volume 2: Seminumerical Algorithms*.
    2nd ed.Koenecke, Allison, and Hal Varian. 2020\. “Synthetic Data Generation for
    Economists.” [https://arxiv.org/abs/2011.01374](https://arxiv.org/abs/2011.01374).Lewis,
    Crystal. 2024\. *Data Management in Large-Scale Education Research*. 1st ed. Chapman;
    Hall/CRC. [https://datamgmtinedresearch.com/index.html](https://datamgmtinedresearch.com/index.html).Lima,
    Renato de, Oliver Phillips, Alvaro Duque, Sebastian Tello, Stuart Davies, Alexandre
    Adalardo de Oliveira, Sandra Muller, et al. 2022\. “Making Forest Data Fair and
    Open.” *Nature Ecology & Evolution* 6 (April): 656–58\. [https://doi.org/10.1038/s41559-022-01738-7](https://doi.org/10.1038/s41559-022-01738-7).Lin,
    Herbert. 2014\. “A Proposal to Reduce Government Overclassification of Information
    Related to National Security.” *Journal of National Security Law and Policy* 7:
    443–63.Mammoliti, Anthony, Petr Smirnov, Minoru Nakano, Zhaleh Safikhani, Christopher
    Eeles, Heewon Seo, Sisira Kadambat Nair, et al. 2021\. “Orchestrating and Sharing
    Large Multimodal Data for Transparent and Reproducible Research.” *Nature Communications*
    12 (1). [https://doi.org/10.1038/s41467-021-25974-w](https://doi.org/10.1038/s41467-021-25974-w).McKinney,
    Wes. (2011) 2022\. *Python for Data Analysis*. 3rd ed. [https://wesmckinney.com/book/](https://wesmckinney.com/book/).Miceli,
    Milagros, Julian Posada, and Tianling Yang. 2022\. “Studying up Machine Learning
    Data.” *Proceedings of the ACM on Human-Computer Interaction* 6 (January): 1–14\.
    [https://doi.org/10.1145/3492853](https://doi.org/10.1145/3492853).Michener, William.
    2015\. “Ten Simple Rules for Creating a Good Data Management Plan.” *PLOS Computational
    Biology* 11 (10): e1004525\. [https://doi.org/10.1371/journal.pcbi.1004525](https://doi.org/10.1371/journal.pcbi.1004525).Navarro,
    Danielle. 2022\. “Binding Apache Arrow to R,” January. [https://blog.djnavarro.net/posts/2022-01-18%5Fbinding-arrow-to-r/](https://blog.djnavarro.net/posts/2022-01-18%5Fbinding-arrow-to-r/).Navarro,
    Danielle, Jonathan Keane, and Stephanie Hazlitt. 2022\. “Larger-Than-Memory Data
    Workflows with Apache Arrow,” June. [https://arrow-user2022.netlify.app](https://arrow-user2022.netlify.app).Oberski,
    Daniel, and Frauke Kreuter. 2020\. “Differential Privacy and Social Science: An
    Urgent Puzzle.” *Harvard Data Science Review* 2 (1). [https://doi.org/10.1162/99608f92.63a22079](https://doi.org/10.1162/99608f92.63a22079).Ooms,
    Jeroen. 2022\. *openssl: Toolkit for Encryption, Signatures and Certificates Based
    on OpenSSL*. [https://CRAN.R-project.org/package=openssl](https://CRAN.R-project.org/package=openssl).Patki,
    Neha, Roy Wedge, and Kalyan Veeramachaneni. 2016\. “The Synthetic Data Vault.”
    In *2016 IEEE International Conference on Data Science and Advanced Analytics
    (DSAA)*, 399–410\. [https://doi.org/10.1109/DSAA.2016.49](https://doi.org/10.1109/DSAA.2016.49).Paullada,
    Amandalynne, Inioluwa Deborah Raji, Emily Bender, Emily Denton, and Alex Hanna.
    2021\. “Data and Its (Dis)contents: A Survey of Dataset Development and Use in
    Machine Learning Research.” *Patterns* 2 (11): 100336\. [https://doi.org/10.1016/j.patter.2021.100336](https://doi.org/10.1016/j.patter.2021.100336).Piller,
    Charles. 2022\. “Blots on a Field?” *Science* 377 (6604): 358–63\. [https://doi.org/10.1126/science.ade0209](https://doi.org/10.1126/science.ade0209).R
    Core Team. 2024\. *R: A Language and Environment for Statistical Computing*. Vienna,
    Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.R-project.org/).Richardson,
    Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane,
    Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2023\. *arrow: Integration
    to Apache Arrow*. [https://CRAN.R-project.org/package=arrow](https://CRAN.R-project.org/package=arrow).Ross,
    Casey. 2022\. “How a Decades-Old Database Became a Hugely Profitable Dossier on
    the Health of 270 Million Americans.” *Stat*, February. [https://www.statnews.com/2022/02/01/ibm-watson-health-marketscan-data/](https://www.statnews.com/2022/02/01/ibm-watson-health-marketscan-data/).Rubinstein,
    Benjamin, and Francesco Alda. 2017\. “Pain-Free Random Differential Privacy with
    Sensitivity Sampling.” In *34th International Conference on Machine Learning (ICML’2017)*.Ruggles,
    Steven, Catherine Fitch, Diana Magnuson, and Jonathan Schroeder. 2019\. “Differential
    Privacy and Census Data: Implications for Social and Economic Research.” *AEA
    Papers and Proceedings* 109 (May): 403–8\. [https://doi.org/10.1257/pandp.20191107](https://doi.org/10.1257/pandp.20191107).Simonsohn,
    Uri. 2013\. “Just Post It: The Lesson from Two Cases of Fabricated Data Detected
    by Statistics Alone.” *Psychological Science* 24 (10): 1875–88\. [https://doi.org/10.1177/0956797613480366](https://doi.org/10.1177/0956797613480366).Suriyakumar,
    Vinith, Nicolas Papernot, Anna Goldenberg, and Marzyeh Ghassemi. 2021\. “Chasing
    Your Long Tails.” In *Proceedings of the 2021 ACM Conference on Fairness, Accountability,
    and Transparency*. [https://doi.org/10.1145/3442188.3445934](https://doi.org/10.1145/3442188.3445934).Tang,
    Jun, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. 2017\.
    “Privacy Loss in Apple’s Implementation of Differential Privacy on MacOS 10.12.”
    arXiv. [https://doi.org/10.48550/arXiv.1709.02753](https://doi.org/10.48550/arXiv.1709.02753).Tierney,
    Nicholas, and Karthik Ram. 2020\. “A Realistic Guide to Making Data Available
    Alongside Code to Improve Reproducibility.” [https://arxiv.org/abs/2002.11626](https://arxiv.org/abs/2002.11626).———.
    2021\. “Common-Sense Approaches to Sharing Tabular Data Alongside Publication.”
    *Patterns* 2 (12): 100368\. [https://doi.org/10.1016/j.patter.2021.100368](https://doi.org/10.1016/j.patter.2021.100368).Wicherts,
    Jelte, Marjan Bakker, and Dylan Molenaar. 2011\. “Willingness to Share Research
    Data Is Related to the Strength of the Evidence and the Quality of Reporting of
    Statistical Results.” *PLOS ONE* 6 (11): e26828\. [https://doi.org/10.1371/journal.pone.0026828](https://doi.org/10.1371/journal.pone.0026828).Wickham,
    Hadley. 2022\. *R Packages*. 2nd ed. O’Reilly Media. [https://r-pkgs.org](https://r-pkgs.org).Wickham,
    Hadley, Mara Averick, Jenny Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain
    François, Garrett Grolemund, et al. 2019\. “Welcome to the Tidyverse.” *Journal
    of Open Source Software* 4 (43): 1686\. [https://doi.org/10.21105/joss.01686](https://doi.org/10.21105/joss.01686).Wickham,
    Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. (2016) 2023\. *R for Data
    Science*. 2nd ed. O’Reilly Media. [https://r4ds.hadley.nz](https://r4ds.hadley.nz).Wickham,
    Hadley, Jim Hester, Winston Chang, and Jenny Bryan. 2022\. *devtools: Tools to
    Make Developing R Packages Easier*. [https://CRAN.R-project.org/package=devtools](https://CRAN.R-project.org/package=devtools).Wilkinson,
    Mark, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton,
    Arie Baak, Niklas Blomberg, et al. 2016\. “The FAIR Guiding Principles for Scientific
    Data Management and Stewardship.” *Scientific Data* 3 (1): 1–9\. [https://doi.org/10.1038/sdata.2016.18](https://doi.org/10.1038/sdata.2016.18).Zhang,
    Susan, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher
    Dewan, et al. 2022\. “OPT: Open Pre-Trained Transformer Language Models.” arXiv.
    [https://doi.org/10.48550/arXiv.2205.01068](https://doi.org/10.48550/arXiv.2205.01068).Zook,
    Matthew, Solon Barocas, danah boyd, Kate Crawford, Emily Keller, Seeta Peña Gangadharan,
    Alyssa Goodman, et al. 2017\. “Ten Simple Rules for Responsible Big Data Research.”
    *PLOS Computational Biology* 13 (3): e1005399\. [https://doi.org/10.1371/journal.pcbi.1005399](https://doi.org/10.1371/journal.pcbi.1005399).***
    **** * *'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 'Annas, George. 2003\. “HIPAA Regulations: A New Era of Medical-Record Privacy?”
    *New England Journal of Medicine* 348 (15): 1486–90\. [https://doi.org/10.1056/NEJMlim035027](https://doi.org/10.1056/NEJMlim035027).Arel-Bundock,
    Vincent. 2024\. *tinytable: Simple and Configurable Tables in “HTML,” “LaTeX,”
    “Markdown,” “Word,” “PNG,” “PDF,” and “Typst” Formats*. [https://vincentarelbundock.github.io/tinytable/](https://vincentarelbundock.github.io/tinytable/).Arel-Bundock,
    Vincent, Ryan Briggs, Hristos Doucouliagos, Marco Mendoza Aviña, and T. D. Stanley.
    2022\. “Quantitative Political Science Research Is Greatly Underpowered.” [https://osf.io/bzj9y/](https://osf.io/bzj9y/).Athey,
    Susan, Guido Imbens, Jonas Metzger, and Evan Munro. 2021\. “Using Wasserstein
    Generative Adversarial Networks for the Design of Monte Carlo Simulations.” *Journal
    of Econometrics*. [https://doi.org/10.1016/j.jeconom.2020.09.013](https://doi.org/10.1016/j.jeconom.2020.09.013).Bandy,
    John, and Nicholas Vincent. 2021\. “Addressing ‘Documentation Debt’ in Machine
    Learning: A Retrospective Datasheet for BookCorpus.” In *Proceedings of the Neural
    Information Processing Systems Track on Datasets and Benchmarks*, edited by J.
    Vanschoren and S. Yeung. Vol. 1\. [https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf](https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf).Bender,
    Emily, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021\.
    “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” In *Proceedings
    of the 2021 ACM Conference on Fairness, Accountability, and Transparency*. ACM.
    [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922).Berners-Lee,
    Timothy. 1989\. “Information Management: A Proposal.” [https://www.w3.org/History/1989/proposal.html](https://www.w3.org/History/1989/proposal.html).Biderman,
    Stella, Kieran Bicheno, and Leo Gao. 2022\. “Datasheet for the Pile.” [https://arxiv.org/abs/2201.07311](https://arxiv.org/abs/2201.07311).Borghi,
    John, and Ana Van Gulick. 2022\. “Promoting Open Science Through Research Data
    Management.” *Harvard Data Science Review* 4 (3). [https://doi.org/10.1162/99608f92.9497f68e](https://doi.org/10.1162/99608f92.9497f68e).Bowen,
    Claire McKay. 2022\. *Protecting Your Privacy in a Data-Driven World*. 1st ed.
    Chapman; Hall/CRC. [https://doi.org/10.1201/9781003122043](https://doi.org/10.1201/9781003122043).Buneman,
    Peter, Sanjeev Khanna, and Tan Wang-Chiew. 2001\. “Why and Where: A Characterization
    of Data Provenance.” In *Database Theory ICDT 2001*, 316–30\. Springer. [https://doi.org/10.1007/3-540-44503-x_20](https://doi.org/10.1007/3-540-44503-x_20).Buolamwini,
    Joy, and Timnit Gebru. 2018\. “Gender Shades: Intersectional Accuracy Disparities
    in Commercial Gender Classification.” In *Conference on Fairness, Accountability
    and Transparency*, 77–91.Bush, Vannevar. 1945\. “As We May Think.” *The Atlantic
    Monthly*, July. [https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/](https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/).Byrd,
    James Brian, Anna Greene, Deepashree Venkatesh Prasad, Xiaoqian Jiang, and Casey
    Greene. 2020\. “Responsible, Practical Genomic Data Sharing That Accelerates Research.”
    *Nature Reviews Genetics* 21 (10): 615–29\. [https://doi.org/10.1038/s41576-020-0257-5](https://doi.org/10.1038/s41576-020-0257-5).Carleton,
    Chris. 2021\. “wccarleton/conflict-europe: Acce.” Zenodo. [https://doi.org/10.5281/zenodo.4550688](https://doi.org/10.5281/zenodo.4550688).Carleton,
    Chris, Dave Campbell, and Mark Collard. 2021\. “A Reassessment of the Impact of
    Temperature Change on European Conflict During the Second Millennium CE Using
    a Bespoke Bayesian Time-Series Model.” *Climatic Change* 165 (1): 1–16\. [https://doi.org/10.1007/s10584-021-03022-2](https://doi.org/10.1007/s10584-021-03022-2).Christensen,
    Garret, Allan Dafoe, Edward Miguel, Don Moore, and Andrew Rose. 2019\. “A Study
    of the Impact of Data Sharing on Article Citations Using Journal Policies as a
    Natural Experiment.” *PLOS ONE* 14 (12): e0225883\. [https://doi.org/10.1371/journal.pone.0225883](https://doi.org/10.1371/journal.pone.0225883).Christensen,
    Garret, Jeremy Freese, and Edward Miguel. 2019\. *Transparent and Reproducible
    Social Science Research*. California: University of California Press.Cohen, Glenn,
    and Michelle Mello. 2018\. “HIPAA and Protecting Health Information in the 21st
    Century.” *JAMA* 320 (3): 231\. [https://doi.org/10.1001/jama.2018.5630](https://doi.org/10.1001/jama.2018.5630).Council
    of European Union. 2016\. “General Data Protection Regulation 2016/679.” [https://eur-lex.europa.eu/eli/reg/2016/679/oj](https://eur-lex.europa.eu/eli/reg/2016/679/oj).Crane,
    Nicola, Stephanie Hazlitt, and Apache Arrow. 2023\. *Apache Arrow R Cookbook*.
    [https://arrow.apache.org/cookbook/r/](https://arrow.apache.org/cookbook/r/).Dwork,
    Cynthia, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006\. “Calibrating Noise
    to Sensitivity in Private Data Analysis.” In *Theory of Cryptography Conference*,
    265–84\. Springer. [https://doi.org/10.1007/11681878_14](https://doi.org/10.1007/11681878_14).Dwork,
    Cynthia, and Aaron Roth. 2013\. “The Algorithmic Foundations of Differential Privacy.”
    *Foundations and Trends in Theoretical Computer Science* 9 (3-4): 211–407\. [https://doi.org/10.1561/0400000042](https://doi.org/10.1561/0400000042).Firke,
    Sam. 2023\. *janitor: Simple Tools for Examining and Cleaning Dirty Data*. [https://CRAN.R-project.org/package=janitor](https://CRAN.R-project.org/package=janitor).Gebru,
    Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach,
    Hal Daumé III, and Kate Crawford. 2021\. “Datasheets for Datasets.” *Communications
    of the ACM* 64 (12): 86–92\. [https://doi.org/10.1145/3458723](https://doi.org/10.1145/3458723).Geuenich,
    Michael, Jinyu Hou, Sunyun Lee, Shanza Ayub, Hartland Jackson, and Kieran Campbell.
    2021a. “Automated Assignment of Cell Identity from Single-Cell Multiplexed Imaging
    and Proteomic Data.”'
- en: An interesting counterpoint is the recent use, by law enforcement, of DNA databases
    to find suspects. The suspect themselves might not be in the database, but the
    nature of DNA means that some related individuals can nonetheless still be identified.[↩︎](#fnref1)
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个有趣的对比是执法机构最近使用DNA数据库来寻找嫌疑人的情况。嫌疑人本人可能不在数据库中，但DNA的性质意味着一些相关个体仍然可以被识别。[↩︎](#fnref1)
- en: Closely supervise the students, and especially check the pull requests before
    they are made to ensure they are reasonable; we don’t want to annoy people. A
    good option might a fix to a couple of typos or similar.[↩︎](#fnref2)
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 严格监督学生，尤其是在他们提交之前检查拉取请求，以确保它们是合理的；我们不希望惹恼人们。一个不错的选择可能是修复几个错别字或类似问题。[↩︎](#fnref2)
- en: These will need to change each year.[↩︎](#fnref3)****************
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些内容每年都需要更新。[↩︎](#fnref3)****************
