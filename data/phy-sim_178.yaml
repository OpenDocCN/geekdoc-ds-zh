- en: Conjugate Gradient Method
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共轭梯度法
- en: 原文：[https://phys-sim-book.github.io/lec33.3-conjugate_gradient.html](https://phys-sim-book.github.io/lec33.3-conjugate_gradient.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://phys-sim-book.github.io/lec33.3-conjugate_gradient.html](https://phys-sim-book.github.io/lec33.3-conjugate_gradient.html)
- en: <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
- en: The Conjugate Gradient (CG) method is a powerful iterative algorithm for solving
    large, sparse linear systems of the form Ax=b, where A is symmetric positive definite
    (SPD). Unlike general iterative methods such as Jacobi and Gauss-Seidel, CG is
    specifically designed for SPD matrices and has become fundamental in scientific
    computing and numerical simulation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 共轭梯度（CG）法是一种强大的迭代算法，用于求解形式为 Ax=b 的大型稀疏线性系统，其中 A 是对称正定（SPD）。与雅可比和高斯-赛德尔等通用迭代方法不同，CG
    是专门为 SPD 矩阵设计的，并在科学计算和数值模拟中变得至关重要。
- en: '[Formulation as Quadratic Optimization](#formulation-as-quadratic-optimization)'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[作为二次优化的表述](#formulation-as-quadratic-optimization)'
- en: 'The conjugate gradient method can be elegantly understood as an optimization
    algorithm for minimizing the quadratic function: f(x)=21​xTAx−bTx,(34.3.1) where
    A is SPD. The unique global minimizer of f(x) is precisely the solution to Ax=b.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 共轭梯度法可以优雅地理解为最小化二次函数的优化算法：f(x)=21xTAx−bTx，（34.3.1）其中 A 是对称正定（SPD）。f(x) 的唯一全局最小值正是
    Ax=b 的解。
- en: The classical steepest descent method updates x along the negative gradient
    direction −∇f(x)=b−Ax, but this approach can suffer from slow convergence, particularly
    when A is ill-conditioned. The CG method overcomes this limitation by searching
    along a carefully chosen sequence of directions p(k) that are A-conjugate (or
    A-orthogonal), meaning p(i)TAp(j)=0 for i=j. This conjugacy property ensures
    that progress made along one direction is never undone by subsequent steps, and
    the minimization along each direction becomes independent of the others.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的梯度下降法沿着负梯度方向 −∇f(x)=b−Ax 更新 x，但这种方法可能会因为收敛速度慢而受到限制，尤其是在 A 是病态的情况下。CG 方法通过沿着精心选择的序列方向
    p(k) 搜索来克服这一限制，这些方向是 A-共轭的（或 A-正交的），意味着 p(i)TAp(j)=0 对于 i≠j。这种共轭性质确保了沿一个方向取得的进展不会被后续步骤所抵消，并且沿每个方向的最小化独立于其他方向。
- en: '[Line Search](#line-search)'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[线搜索](#line-search)'
- en: Given a sequence of conjugate directions p(0),p(1),p(2),…, the problem of minimizing
    the quadratic function reduces to finding optimal step sizes α(i) such that ∑i=0n−1​α(i)p(i)
    closely approximates the solution x∗.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一系列共轭方向 p(0),p(1),p(2),…，最小化二次函数的问题简化为寻找最优步长 α(i)，使得 ∑i=0n−1α(i)p(i) 紧密逼近解
    x∗。
- en: 'The most straightforward approach is **greedy line search**: starting from
    an initial point x(0), we select a search direction p(0) and then minimize f(x(0)+α(0)p(0))
    with respect to α(0). For quadratic functions, this optimization has a simple
    closed-form solution that avoids matrix inversion: α(0)=p(0)TAp(0)p(0)T(b−Ax(0))​.
    The intuition is clear: we start at x(0), choose a direction p(0), and move along
    this direction until the objective function is minimized. While this may not reach
    the global minimum in one step, it guarantees progress toward the optimal solution.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的方法是**贪婪线搜索**：从初始点 x(0) 开始，选择一个搜索方向 p(0)，然后最小化 f(x(0)+α(0)p(0)) 关于 α(0)。对于二次函数，这种优化有一个简单的闭式解，避免了矩阵求逆：α(0)=p(0)TAp(0)p(0)T(b−Ax(0))。直观上：我们从
    x(0) 开始，选择一个方向 p(0)，沿着这个方向移动，直到目标函数最小化。虽然这可能在一步内不会达到全局最小值，但它保证了向最优解的进步。
- en: 'This procedure is then repeated iteratively: at the new point x(1)=x(0)+α(0)p(0),
    we select the next direction p(1), compute the corresponding step size α(1), and
    continue.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后重复迭代这个过程：在新的点 x(1)=x(0)+α(0)p(0) 处，选择下一个方向 p(1)，计算相应的步长 α(1)，并继续。
- en: 'The general iteration process can be summarized as: α(i)x(i+1)r(i+1)​=p(i)TAp(i)p(i)Tr(i)​,=x(i)+α(i)p(i),=r(i)−α(i)Ap(i)​(34.3.2)
    where p(0),p(1),p(2),… are the search directions and r(i)=b−Ax(i) is the residual
    at step i. Note that the residual can be updated without recomputing Ax(i+1) from
    scratch: r(i+1)=b−Ax(i+1)=b−A(x(i)+α(i)p(i))=r(i)−α(i)Ap(i). In practice, when
    ∥r(i+1)∥ becomes sufficiently small (typically below a prescribed tolerance),
    the iteration process can be terminated early to achieve better computational
    efficiency.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通用迭代过程可以总结如下：α(i)x(i+1)r(i+1)=p(i)TAp(i)p(i)Tr(i)=x(i)+α(i)p(i)=r(i)−α(i)Ap(i)（34.3.2），其中p(0)，p(1)，p(2)，…是搜索方向，r(i)=b−Ax(i)是第i步的残差。请注意，残差可以更新，而无需从头开始重新计算Ax(i+1)：r(i+1)=b−Ax(i+1)=b−A(x(i)+α(i)p(i))=r(i)−α(i)Ap(i)。在实践中，当∥r(i+1)∥足够小（通常低于规定的容差）时，迭代过程可以提前终止，以实现更好的计算效率。
- en: '[Conjugate Directions](#conjugate-directions)'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[共轭方向](#conjugate-directions)'
- en: The choice of search directions is crucial for the method's performance. If
    the directions p(0),p(1),p(2),… are poorly chosen, convergence will be slow. In
    particular, gradient descent (which uses the steepest descent directions) exhibits
    slow convergence for ill-conditioned matrices A.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索方向的选择对于方法性能至关重要。如果方向p(0)，p(1)，p(2)，…选择不当，收敛将很慢。特别是，梯度下降（使用最速下降方向）对于条件不良的矩阵A表现出慢速收敛。
- en: 'In contrast, if we choose the directions to be mutually A-conjugate: p(i)TAp(j)=0,∀i=j,(34.3.3)
    the algorithm achieves remarkable efficiency: there is no "zigzagging" behavior,
    and we obtain the exact solution in at most n steps, where n is the dimension
    of the system:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相反，如果我们选择相互A-共轭的方向：p(i)TAp(j)=0，∀i≠j，（34.3.3）算法将实现显著的效率：没有“之字形”行为，并且我们最多在n步内获得精确解，其中n是系统的维度：
- en: Without loss of generality, assume x(0)=0 and set p(0) to be the initial residual.
    Since x(0)=0, the gradient at x(0) is Ax(0)−b=−b, so we set p(0)=b. The remaining
    directions will be constructed to be A-conjugate to all previous directions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不失一般性，假设x(0)=0并将p(0)设置为初始残差。由于x(0)=0，x(0)处的梯度是Ax(0)−b=−b，因此我们设置p(0)=b。剩余的方向将被构建为与所有先前的方向A-共轭。
- en: 'Let r(k) denote the residual at the k-th step: r(k)=b−Ax(k).(34.3.4) Note that
    r(k) equals the negative gradient of f at x(k), so standard gradient descent would
    move in the direction r(k).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 令r(k)表示第k步的残差：r(k)=b−Ax(k)。（34.3.4）注意，r(k)等于f在x(k)处的负梯度，因此标准梯度下降将沿着r(k)的方向移动。
- en: 'To construct conjugate directions, we require that each new search direction
    p(k) be built from the current residual r(k) while being A-conjugate to all previous
    search directions. We start with the negative gradient r(k) and orthogonalize
    it w.r.t. A against all previous search directions p(0),p(1),…,p(k−1) using the
    Gram–Schmidt process: p(k)=r(k)−i=0∑k−1​p(i)TAp(i)p(i)TAr(k)​p(i).(34.3.5)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建共轭方向，我们需要确保每个新的搜索方向p(k)都是从当前的残差r(k)构建的，同时与所有先前的搜索方向A-共轭。我们以负梯度r(k)开始，并使用Gram-Schmidt过程将其相对于A正交化，以对抗所有先前的搜索方向p(0)，p(1)，…，p(k−1)：p(k)=r(k)−i=0∑k−1p(i)TAp(i)p(i)TAr(k)p(i)。（34.3.5）
- en: '[Algorithmic Simplification](#algorithmic-simplification)'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[算法简化](#algorithmic-simplification)'
- en: The expressions above can be significantly simplified, leading to the elegant
    final form of the conjugate gradient algorithm. The key insight lies in proving
    two fundamental orthogonality relationships.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上述表达式可以显著简化，从而得到共轭梯度算法的优雅最终形式。关键洞察在于证明两个基本正交关系。
- en: '**Orthogonality Properties.** We first establish that the following orthogonality
    relations hold: p(i)Tr(j)=0,∀i<j,(34.3.6) r(i)Tr(j)=0,∀i=j.(34.3.7)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**正交性性质。**我们首先建立以下正交关系成立：p(i)Tr(j)=0，∀i<j，（34.3.6）r(i)Tr(j)=0，∀i≠j。（34.3.7）'
- en: '**Proof Sketch.** From the residual update formula (Equation [(34.3.4)](#eq:lec31:residual)),
    we can write recursively: rj​=r(j−1)−α(j−1)Ap(j−1)=r(i)−k=i∑j−1​α(k)Ap(k). Taking
    the dot product with p(i) on both sides: p(i)Tr(j)=p(i)Tr(i)−k=i∑j−1​αk​pi​TApk​.
    By the A-conjugacy property (Equation [(34.3.3)](#eq:lec31:A-conjugate)) and the
    step size formula α(i)=p(i)TAp(i)p(i)Tr(i)​, we can verify that p(i)Tr(j)=0 for
    i<j.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明概要。**从残差更新公式（方程式[(34.3.4)](#eq:lec31:residual)），我们可以递归地写出：rj=r(j−1)−α(j−1)Ap(j−1)=r(i)−k=i∑j−1α(k)Ap(k)。将p(i)与等式两边进行点积：p(i)Tr(j)=p(i)Tr(i)−k=i∑j−1αkpiTApk。通过A-共轭性质（方程式[(34.3.3)](#eq:lec31:A-conjugate)）和步长公式α(i)=p(i)TAp(i)p(i)Tr(i)，我们可以验证对于i<j，p(i)Tr(j)=0。'
- en: The second orthogonality relation r(i)Tr(j)=0 follows from the fact that each
    residual r(j) lies in the span of the search directions {p(0),p(1),…,p(j−1)} by
    construction, and these directions are built from previous residuals.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个正交关系r(i)^T r(j) = 0来源于每个残差r(j)按照构造位于搜索方向{p(0), p(1), …, p(j-1)}的范围内，而这些方向是由之前的残差构建的。
- en: '**Simplified Formulas.** Using these orthogonality properties, the conjugate
    direction formula (Equation [(34.3.5)](#eq:lec31:conjugate_direction)) simplifies
    dramatically. Since p(i)Tr(k)=0 for i<k, we have: p(k)Tr(k)=r(k)Tr(k).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**简化公式**。使用这些正交性质，共轭方向公式（方程[(34.3.5)](#eq:lec31:conjugate_direction)）大大简化。由于对于i<k，p(i)^T
    r(k) = 0，我们有：p(k)^T r(k) = r(k)^T r(k)。'
- en: 'This allows us to simplify the step size calculation: α(k)=p(k)TAp(k)r(k)Tr(k)​.(34.3.8)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许我们简化步长计算：α(k) = p(k)^T A p(k) r(k)^T r(k)。(34.3.8)
- en: 'For the conjugate direction update, we can show that only the most recent direction
    matters. Using the residual update formula and the orthogonality properties: p(k+1)​=r(k+1)−i=0∑k​p(i)TAp(i)p(i)TAr(k+1)​p(i)=r(k+1)−i=0∑k​p(i)TAp(i)r(k+1)TAp(i)​p(i)=r(k+1)−i=0∑k​α(i)p(i)TAp(i)r(k+1)T(r(i)−r(i+1))​p(i).​'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于共轭方向更新，我们可以证明只有最近的方向才是重要的。使用残差更新公式和正交性质：p(k+1) = r(k+1) - i=0∑k p(i)^T A p(i)
    p(i)^T A r(k+1) p(i) = r(k+1) - i=0∑k p(i)^T A r(k+1) T A p(i) p(i) = r(k+1) -
    i=0∑k α(i) p(i)^T A p(i) r(k+1)^T (r(i) - r(i+1)) p(i)。
- en: 'Applying the orthogonality relations (Equations [(34.3.7)](#eq:lec31:lemma2)
    and [(34.3.8)](#eq:lec31:simple_step_size)), this simplifies to: p(k+1)​=r(k+1)+i=0∑k​α(i)p(i)TAp(i)r(k+1)Tr(i+1)​p(i)=r(k+1)+i=0∑k​r(i)Tr(i)r(k+1)Tr(i+1)​p(i)=r(k+1)+r(k)Tr(k)r(k+1)Tr(k+1)​p(k).​'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 应用正交关系（方程[(34.3.7)](#eq:lec31:lemma2)和[(34.3.8)](#eq:lec31:simple_step_size)），这简化为：p(k+1)
    = r(k+1) + i=0∑k α(i) p(i)^T A p(i) r(k+1)^T r(i+1) p(i) = r(k+1) + i=0∑k r(i)^T
    r(i) r(k+1)^T r(i+1) p(i) = r(k+1) + r(k)^T r(k) r(k+1)^T r(k+1) p(k)。
- en: This remarkable simplification shows that we only need to retain the most recent
    search direction p(k) to compute the next one p(k+1).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种显著简化表明，我们只需要保留最近的搜索方向p(k)来计算下一个方向p(k+1)。
- en: '**Final Algorithm.** The simplified CG algorithm is summarized in [Algorithm
    34.3.1](#alg:lec31:cg):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**最终算法**。简化的共轭梯度算法总结在[算法34.3.1](#alg:lec31:cg)中：'
- en: '**Algorithm 34.3.1 (The Conjugate Gradient Method).** ![](../Images/bc2dc8215cbe71e4a5fbcb076232da21.png)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法34.3.1（共轭梯度法）**。![](../Images/bc2dc8215cbe71e4a5fbcb076232da21.png)'
- en: '[Preconditioning](#preconditioning)'
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[预条件化](#preconditioning)'
- en: The convergence rate of the conjugate gradient method is fundamentally determined
    by the condition number of matrix A. When A is ill-conditioned (i.e., has a large
    condition number), CG may converge slowly, requiring many iterations to reach
    acceptable accuracy.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 共轭梯度法的收敛速率从根本上取决于矩阵A的条件数。当A是病态的（即具有大的条件数）时，CG可能收敛缓慢，需要多次迭代才能达到可接受的精度。
- en: '**Preconditioning** is a crucial technique for accelerating convergence by
    transforming the original system into an equivalent one with more favorable spectral
    properties. The idea is to solve a modified system: M−1Ax=M−1b, where M is a carefully
    chosen **preconditioner** matrix that approximates A but is much easier to invert.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**预条件化**是一种通过将原始系统转换为具有更有利谱性质的等效系统来加速收敛的关键技术。其思想是解决一个修改后的系统：M^-1 A x = M^-1
    b，其中M是一个精心选择的**预条件器**矩阵，它近似A但更容易求逆。'
- en: A simple yet effective choice is the **diagonal (Jacobi) preconditioner**, where
    M=diag(A) contains only the diagonal entries of A. The preconditioned CG algorithm
    then solves the transformed system while maintaining the essential structure of
    the original algorithm.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单而有效的方法是**对角（雅可比）预条件器**，其中M=diag(A)只包含A的对角元素。预条件化的共轭梯度算法随后解决转换后的系统，同时保持原始算法的基本结构。
- en: In practice, preconditioning amounts to scaling the residuals at each iteration
    by M−1, which is computationally inexpensive when M is diagonal. The preconditioned
    CG algorithm follows the same iterative structure as standard CG, but operates
    on the preconditioned residuals, often achieving significantly faster convergence
    for ill-conditioned problems.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，预条件化相当于在每次迭代中将残差乘以M^-1，当M是对角矩阵时，这计算上并不昂贵。预条件化的共轭梯度算法遵循与标准CG相同的迭代结构，但操作在预条件化的残差上，通常对于病态问题能显著加快收敛速度。
