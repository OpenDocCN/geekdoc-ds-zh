- en: 3.8\. Online supplementary materials#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3.8\. 在线补充材料#
- en: 原文：[https://mmids-textbook.github.io/chap03_opt/supp/roch-mmids-opt-supp.html](https://mmids-textbook.github.io/chap03_opt/supp/roch-mmids-opt-supp.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap03_opt/supp/roch-mmids-opt-supp.html](https://mmids-textbook.github.io/chap03_opt/supp/roch-mmids-opt-supp.html)
- en: 3.8.1\. Quizzes, solutions, code, etc.[#](#quizzes-solutions-code-etc "Link
    to this heading")
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.8.1\. 测验、解答、代码等。[#](#quizzes-solutions-code-etc "链接到本标题")
- en: 3.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.1\. 仅代码[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中包含的代码的交互式Jupyter笔记本可以通过以下链接访问（推荐使用Google Colab）。鼓励您对其进行实验。一些建议的计算练习散布在其中。笔记本也可以作为幻灯片查看。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
- en: 3.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.2\. 自我评估测验[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以获取更广泛的自我评估测验的网络版本。
- en: '[Section 3.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.2节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
- en: '[Section 3.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.3节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
- en: '[Section 3.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.4节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
- en: '[Section 3.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.5节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
- en: '[Section 3.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.6节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
- en: 3.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章自动生成的测验可以通过以下链接访问（推荐使用Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
- en: 3.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.4\. 奇数编号预热练习的解答[#](#solutions-to-odd-numbered-warm-up-exercises "链接到本标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在Claude、Gemini和ChatGPT的帮助下)*'
- en: 'Answer and justification for E3.2.1:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.1的答案和解释：
- en: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
- en: 'At the point \((1, -1)\), we have:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((1, -1)\)，我们有：
- en: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
- en: 'Answer and justification for E3.2.3:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.3的答案和解释：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
- en: 'At the point \((\frac{\pi}{4}, \frac{\pi}{3})\), we have:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((\frac{\pi}{4}, \frac{\pi}{3})\) 处，我们有：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1}(\frac{\pi}{4}, \frac{\pi}{3})
    &= \cos(\frac{\pi}{4}) \cos(\frac{\pi}{3}) = \frac{\sqrt{2}}{2} \cdot \frac{1}{2}
    = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}(\frac{\pi}{4}, \frac{\pi}{3})
    &= -\sin(\frac{\pi}{4}) \sin(\frac{\pi}{3}) = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2}
    = -\frac{\sqrt{6}}{4}. \end{align*}\]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1}(\frac{\pi}{4}, \frac{\pi}{3})
    &= \cos(\frac{\pi}{4}) \cos(\frac{\pi}{3}) = \frac{\sqrt{2}}{2} \cdot \frac{1}{2}
    = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}(\frac{\pi}{4}, \frac{\pi}{3})
    &= -\sin(\frac{\pi}{4}) \sin(\frac{\pi}{3}) = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2}
    = -\frac{\sqrt{6}}{4}. \end{align*}\]
- en: 'Answer and justification for E3.2.5: The Hessian matrix of \(f(x_1, x_2)\)
    is:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.5 的答案和解释：函数 \(f(x_1, x_2)\) 的 Hessian 矩阵为：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
- en: 'At the point \((1, 2)\), we have:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((1, 2)\) 处，我们有：
- en: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
- en: We can see that \(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\), confirming the Symmetry of the Hessian
    Theorem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 \(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\)，这证实了 Hessian 矩阵对称定理。
- en: 'Answer and justification for E3.2.7:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.7 的答案和解释：
- en: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
- en: 'Answer and justification for E3.2.9: The Hessian matrix is given by:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.9 的答案和解释：Hessian 矩阵如下：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.11: \(\frac{\partial f}{\partial x} = 3x^2y^2
    - 2y^3\) and \(\frac{\partial f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\), obtained
    by differentiating \(f\) with respect to each variable while holding the other
    constant.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.11 的答案和解释：\(\frac{\partial f}{\partial x} = 3x^2y^2 - 2y^3\) 和 \(\frac{\partial
    f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\)，这是通过对 \(f\) 分别对每个变量求导，同时保持其他变量不变得到的。
- en: 'Answer and justification for E3.2.13: The Hessian matrix is given by'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.13 的答案和解释：Hessian 矩阵如下：
- en: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.15: \(\frac{\partial^2 q}{\partial x^2} =
    6x\) and \(\frac{\partial^2 q}{\partial y^2} = -6x\). Adding these gives \(6x
    - 6x = 0\), so \(q\) satisfies Laplace’s equation.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.15 的答案和解释：\(\frac{\partial^2 q}{\partial x^2} = 6x\) 和 \(\frac{\partial^2
    q}{\partial y^2} = -6x\)。将这两个结果相加得到 \(6x - 6x = 0\)，因此 \(q\) 满足拉普拉斯方程。
- en: 'Answer and justification for E3.2.17: By the chain rule, the rate of change
    of temperature experienced by the particle is'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.17 的答案和解释：根据链式法则，粒子经历的温度变化率为
- en: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
- en: We have \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) and \(\mathbf{c}'(t)
    = (2t, 3t^2)\). Evaluating at \(t = 1\) gives
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) 和 \(\mathbf{c}'(t)
    = (2t, 3t^2)\)。在 \(t = 1\) 处求值得到
- en: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
- en: 'Answer and justification for E3.2.19: \(\frac{d}{dt} f(\mathbf{g}(t)) = 2t
    \cos t - t^2 \sin t\). Justification: \(\nabla f = (y, x)\), and \(\mathbf{g}''(t)
    = (2t, -\sin t)\). Then, \(\frac{d}{dt} f(\mathbf{g}(t)) = \cos t \cdot 2t + t^2
    \cdot (-\sin t)\).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.2.19 的答案和解释：\(\frac{d}{dt} f(\mathbf{g}(t)) = 2t \cos t - t^2 \sin t\)。解释：\(\nabla
    f = (y, x)\)，且 \(\mathbf{g}'(t) = (2t, -\sin t)\)。因此，\(\frac{d}{dt} f(\mathbf{g}(t))
    = \cos t \cdot 2t + t^2 \cdot (-\sin t)\)。
- en: 'Answer and justification for E3.3.1: \(\nabla f(x_1, x_2) = (2x_1, 4x_2)\).
    Setting this equal to zero yields \(2x_1 = 0\) and \(4x_2 = 0\), which implies
    \(x_1 = 0\) and \(x_2 = 0\). Thus, the only point where \(\nabla f(x_1, x_2) =
    0\) is \((0, 0)\).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.1的答案和证明：\(\nabla f(x_1, x_2) = (2x_1, 4x_2)\)。将其设为零得到\(2x_1 = 0\)和\(4x_2
    = 0\)，这意味着\(x_1 = 0\)和\(x_2 = 0\)。因此，\(\nabla f(x_1, x_2) = 0\)的唯一点是\((0, 0)\)。
- en: 'Answer and justification for E3.3.3: The second directional derivative is given
    by \(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\). We have \(\mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 & 2 \\ 2 &
    2 \end{pmatrix}\). Thus,'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.3的答案和证明：二阶方向导数由\(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2}
    = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \mathbf{v}\)给出。我们有\(\mathbf{H}_f(x_1,
    x_2) = \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix}\)。因此，
- en: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
- en: 'Answer and justification for E3.3.5: The first-order necessary conditions are:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.5的答案和证明：一阶必要条件为：
- en: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
- en: 'Computing the gradients:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度：
- en: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
- en: 'From the first two equations, we have \(x_1 = x_2 = -\frac{\lambda}{2}\). Substituting
    into the third equation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从前两个方程中，我们得到\(x_1 = x_2 = -\frac{\lambda}{2}\)。将其代入第三个方程：
- en: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
- en: Thus, \(x_1 = x_2 = \frac{1}{2}\), and the only point satisfying the first-order
    necessary conditions is \((\frac{1}{2}, \frac{1}{2}, -1)\).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = x_2 = \frac{1}{2}\)，满足一阶必要条件的唯一点是\((\frac{1}{2}, \frac{1}{2}, -1)\)。
- en: 'Answer and justification for E3.3.7: The Lagrangian is \(L(x_1, x_2, x_3, \lambda)
    = x_1^2 + x_2^2 + x_3^2 + \lambda(x_1 + 2x_2 + 3x_3 - 6)\). The first-order necessary
    conditions are:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.7的答案和证明：拉格朗日函数为\(L(x_1, x_2, x_3, \lambda) = x_1^2 + x_2^2 + x_3^2 + \lambda(x_1
    + 2x_2 + 3x_3 - 6)\)。一阶必要条件为：
- en: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
- en: 'From the first three equations, we have \(x_1 = -\frac{\lambda}{2}\), \(x_2
    = -\lambda\), \(x_3 = -\frac{3\lambda}{2}\). Substituting into the fourth equation:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从前三个方程中，我们得到\(x_1 = -\frac{\lambda}{2}\)，\(x_2 = -\lambda\)，\(x_3 = -\frac{3\lambda}{2}\)。将其代入第四个方程：
- en: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
- en: Thus, \(x_1 = \frac{1}{2}\), \(x_2 = 1\), \(x_3 = \frac{3}{2}\), and the only
    point satisfying the first-order necessary conditions is \((\frac{1}{2}, 1, \frac{3}{2},
    -1)\).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = \frac{1}{2}\)，\(x_2 = 1\)，\(x_3 = \frac{3}{2}\)，满足一阶必要条件的唯一点是\((\frac{1}{2},
    1, \frac{3}{2}, -1)\)。
- en: 'Answer and justification for E3.3.9: The gradient of \(f\) is \(\nabla f(x_1,
    x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\). At the point \((1, 0)\), the gradient is
    \(\nabla f(1, 0) = (3, 0)\). The directional derivative of \(f\) at \((1, 0)\)
    in the direction \(\mathbf{v} = (1, 1)\) is \(\nabla f(1, 0)^T \mathbf{v} = (3,
    0)^T (1, 1) = 3\). Since this is positive, \(v\) is not a descent direction.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.9的答案和证明：函数\(f\)的梯度为\(\nabla f(x_1, x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\)。在点\((1,
    0)\)，梯度为\(\nabla f(1, 0) = (3, 0)\)。在\((1, 0)\)处沿方向\(\mathbf{v} = (1, 1)\)的函数\(f\)的方向导数为\(\nabla
    f(1, 0)^T \mathbf{v} = (3, 0)^T (1, 1) = 3\)。由于这是正的，因此\(v\)不是下降方向。
- en: 'Answer and justification for E3.3.11: The Hessian matrix of \(f\) is'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.11的答案和证明：函数\(f\)的Hessian矩阵为
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
- en: Therefore, the second directional derivative of \(f\) at \((0, 0)\) in the direction
    \(v = (1, 0)\) is \(\mathbf{v}^T \mathbf{H}_f(0, 0) \mathbf{v} = (1, 0) \begin{bmatrix}
    -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = -2\).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\)在\((0, 0)\)处的第二方向导数在方向\(v = (1, 0)\)上是\(\mathbf{v}^T \mathbf{H}_f(0,
    0) \mathbf{v} = (1, 0) \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix}
    1 \\ 0 \end{pmatrix} = -2\)。
- en: 'Answer and justification for E3.3.13: The Hessian matrix is'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.13的答案和证明：Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
- en: 'Justification: Compute the second partial derivatives:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 证明：计算二阶偏导数：
- en: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
- en: At \((1,1)\), these values are \(6\), \(6\), and \(-3\), respectively.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在\((1,1)\)处，这些值分别是\(6\)，\(6\)，和\(-3\)。
- en: 'Answer and justification for E3.4.1: The convex combination is:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.1的答案和证明：凸组合是：
- en: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
- en: 'Answer and justification for E3.4.3: \(S_1\) and \(S_2\) are halfspaces, which
    are convex sets. By the lemma in the text, the intersection of convex sets is
    also convex. Therefore, \(S_1 \cap S_2\) is a convex set.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.3的答案和证明：\(S_1\)和\(S_2\)是半空间，它们是凸集。根据文本中的引理，凸集的交集也是凸集。因此，\(S_1 \cap S_2\)是凸集。
- en: 'Answer and justification for E3.4.5: The function \(f\) is a quadratic function
    with \(P = 2\), \(q = 2\), and \(r = 1\). Since \(P > 0\), \(f\) is strictly convex.
    The unique global minimizer is found by setting the gradient to zero:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.5的答案和证明：函数\(f\)是一个二次函数，\(P = 2\)，\(q = 2\)，\(r = 1\)。由于\(P > 0\)，\(f\)是严格凸的。通过将梯度设为零找到唯一的全局最小值：
- en: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
- en: 'Answer and justification for E3.4.7: The Hessian matrix of \(f\) is:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.7的答案和证明：\(f\)的Hessian矩阵是：
- en: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
- en: 'For any \((x, y) \in \mathbb{R}^2\), we have:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任意的\((x, y) \in \mathbb{R}^2\)，我们有：
- en: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
- en: so \(f\) is strongly convex with \(m = 2\).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\)是具有\(m = 2\)的强凸函数。
- en: 'Answer and justification for E3.4.9: \(f\) is not convex. We have \(f''''(x)
    = 12x^2 - 4\), which is negative for \(x \in (-\frac{1}{\sqrt{3}}, \frac{1}{\sqrt{3}})\).
    Since the second derivative is not always nonnegative, \(f\) is not convex.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.9的答案和证明：\(f\)不是凸的。我们有\(f''(x) = 12x^2 - 4\)，对于\(x \in (-\frac{1}{\sqrt{3}},
    \frac{1}{\sqrt{3}})\)是负的。由于二阶导数不总是非负的，\(f\)不是凸的。
- en: 'Answer and justification for E3.4.11: \(f\) is strongly convex. We have \(f''''(x)
    = 2 > 0\), so \(f\) is 2-strongly convex.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.11的答案和证明：\(f\)是强凸的。我们有\(f''(x) = 2 > 0\)，所以\(f\)是2-强凸的。
- en: 'Answer and justification for E3.4.13: \(D\) is convex. To show this, let \((x_1,
    y_1), (x_2, y_2) \in D\) and \(\alpha \in (0, 1)\). We need to show that \((1
    - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\). Compute:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.13的答案和证明：\(D\)是凸集。为了证明这一点，令\((x_1, y_1), (x_2, y_2) \in D\)和\(\alpha \in
    (0, 1)\)。我们需要证明\((1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\)。计算：
- en: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
- en: Now,
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
- en: Hence, \(D\) is convex.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(D\)是凸集。
- en: 'Answer and justification for E3.4.15: \(D\) is not convex. For example, let
    \((x_1, y_1) = (2, \sqrt{3})\) and \((x_2, y_2) = (2, -\sqrt{3})\), both of which
    are in \(D\). For \(\alpha = \frac{1}{2}\),'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.15的答案和证明：\(D\)不是凸集。例如，令\((x_1, y_1) = (2, \sqrt{3})\)和\((x_2, y_2) = (2,
    -\sqrt{3})\)，它们都在\(D\)中。对于\(\alpha = \frac{1}{2}\)，
- en: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
- en: Now,
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
- en: 'Answer and justification for E3.5.1: The gradient is \(\nabla f(x, y) = (2x,
    8y)\). At \((1, 1)\), it is \((2, 8)\). The direction of steepest descent is \(-\nabla
    f(1, 1) = (-2, -8)\).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.1的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 8y)\)。在 \((1, 1)\) 处，它是 \((2, 8)\)。最速下降的方向是
    \(-\nabla f(1, 1) = (-2, -8)\)。
- en: 'Answer and justification for E3.5.3: \(\nabla f(x) = 3x^2 - 12x + 9\). At \(x_0
    = 0\), \(\nabla f(0) = 9\). The first iteration gives \(x_1 = x_0 - \alpha \nabla
    f(x_0) = 0 - 0.1 \cdot 9 = -0.9\). At \(x_1 = -0.9\), \(\nabla f(-0.9) = 3 \cdot
    (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43 + 10.8 + 9 = 22.23\). The second iteration
    gives \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot 22.23 = -3.123\).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.3的答案和解释：\(\nabla f(x) = 3x^2 - 12x + 9\)。在 \(x_0 = 0\) 处，\(\nabla f(0)
    = 9\)。第一次迭代给出 \(x_1 = x_0 - \alpha \nabla f(x_0) = 0 - 0.1 \cdot 9 = -0.9\)。在
    \(x_1 = -0.9\) 处，\(\nabla f(-0.9) = 3 \cdot (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43
    + 10.8 + 9 = 22.23\)。第二次迭代给出 \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot
    22.23 = -3.123\)。
- en: 'Answer and justification for E3.5.5: We have \(\nabla f(x) = 2x\), so \(\nabla
    f(2) = 4\). Thus, the gradient descent update is \(x_1 = x_0 - \alpha \nabla f(x_0)
    = 2 - 0.1 \cdot 4 = 1.6\).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.5的答案和解释：我们有 \(\nabla f(x) = 2x\)，所以 \(\nabla f(2) = 4\)。因此，梯度下降更新是 \(x_1
    = x_0 - \alpha \nabla f(x_0) = 2 - 0.1 \cdot 4 = 1.6\)。
- en: 'Answer and justification for E3.5.7: \(f''''(x) = 4\) for all \(x \in \mathbb{R}\).
    Therefore, \(f''''(x) \geq 4\) for all \(x \in \mathbb{R}\), which implies that
    \(f\) is \(4\)-strongly convex.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.7的答案和解释：对于所有 \(x \in \mathbb{R}\)，\(f''(x) = 4\)。因此，对于所有 \(x \in \mathbb{R}\)，\(f''(x)
    \geq 4\)，这意味着 \(f\) 是 \(4\)-强凸的。
- en: 'Answer and justification for E3.5.9: No. We have \(f''''(x) = 12x^2\), which
    can be arbitrarily large as \(x\) increases. Thus, there is no constant \(L\)
    such that \(-L \le f''''(x) \le L\) for all \(x \in \mathbb{R}\).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.9的答案和解释：不。我们有 \(f''(x) = 12x^2\)，随着 \(x\) 的增加，它可以任意大。因此，不存在常数 \(L\)，使得对于所有
    \(x \in \mathbb{R}\)，有 \(-L \le f''(x) \le L\)。
- en: 'Answer and justification for E3.5.11: We have \(f''''(x) = 2\) for all \(x
    \in \mathbb{R}\). Thus, we can take \(m = 2\), and we have \(f''''(x) \ge 2\)
    for all \(x \in \mathbb{R}\), which is the condition for \(m\)-strong convexity.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.11的答案和解释：对于所有 \(x \in \mathbb{R}\)，我们有 \(f''(x) = 2\)。因此，我们可以取 \(m = 2\)，并且对于所有
    \(x \in \mathbb{R}\)，我们有 \(f''(x) \ge 2\)，这是 \(m\)-强凸性的条件。
- en: 'Answer and justification for E3.5.13: The gradient is \(\nabla f(x, y) = (2x,
    2y)\). At \((1, 1)\), it is \((2, 2)\). The first update is \((0.8, 0.8)\). The
    gradient at \((0.8, 0.8)\) is \((1.6, 1.6)\). The second update is \((0.64, 0.64)\).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.13的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 2y)\)。在 \((1, 1)\) 处，它是 \((2, 2)\)。第一次更新是
    \((0.8, 0.8)\)。在 \((0.8, 0.8)\) 处的梯度是 \((1.6, 1.6)\)。第二次更新是 \((0.64, 0.64)\)。
- en: 'Answer and justification for E3.6.1: The log-odds is given by \(\log \frac{p}{1-p}
    = \log \frac{0.25}{0.75} = \log \frac{1}{3} = -\log 3\).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.1的答案和解释：对数几率由 \(\log \frac{p}{1-p} = \log \frac{0.25}{0.75} = \log \frac{1}{3}
    = -\log 3\) 给出。
- en: 'Answer and justification for E3.6.3:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.3的答案和解释：
- en: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
- en: 'Answer and justification for E3.6.5: By the quotient rule,'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.5的答案和解释：根据商规则，
- en: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
- en: 'Answer and justification for E3.6.7: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}) \approx 0.05\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x})
    \approx -0.73\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}) \approx 0.73\).
    Therefore,'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.7的答案和解释：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}) \approx
    0.05\)，\(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}) \approx -0.73\)，\(b_3
    - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}) \approx 0.73\)。因此，
- en: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
- en: 'Answer and justification for E3.6.9: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}^0) = 1 - \sigma(0) = 0.5\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T
    \mathbf{x}^0) = -0.5\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) =
    0.5\). Therefore,'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.9的答案和解释：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}^0) = 1 -
    \sigma(0) = 0.5\)，\(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}^0) = -0.5\)，\(b_3
    - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) = 0.5\)。因此，
- en: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
- en: 3.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.5\. 学习成果[#](#learning-outcomes "链接到这个标题")
- en: Define and calculate partial derivatives and gradients for functions of several
    variables.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义多个变量的函数的偏导数和梯度，并计算它们。
- en: Compute second-order partial derivatives and construct the Hessian matrix for
    twice continuously differentiable functions.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算二次连续可微函数的二阶偏导数并构建Hessian矩阵。
- en: Apply the Chain Rule to compute derivatives of composite functions of several
    variables.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用链式法则计算多个变量的复合函数的导数。
- en: State and prove the multivariable version of the Mean Value Theorem using the
    Chain Rule.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用链式法则表述并证明多元均值定理的多变量版本。
- en: Calculate gradients and Hessians for affine and quadratic functions of several
    variables.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算多个变量的仿射函数和二次函数的梯度和Hessian矩阵。
- en: Define global and local minimizers for unconstrained optimization problems.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无约束优化问题的全局和局部最小值。
- en: Derive the first-order necessary conditions for a local minimizer using the
    gradient.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用梯度推导局部最小值的一阶必要条件。
- en: Explain the concept of a descent direction and its relation to the gradient.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释下降方向的概念及其与梯度的关系。
- en: Explain the concept of directional derivatives and compute directional derivatives
    using the gradient.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释方向导数的概念，并使用梯度计算方向导数。
- en: State the second-order necessary and sufficient conditions for a local minimizer
    using the Hessian matrix.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵表述局部最小值的二阶必要和充分条件。
- en: Compute the gradient and Hessian matrix for a given multivariable function.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定多元函数的梯度和Hessian矩阵。
- en: Formulate optimization problems with equality constraints.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述具有等式约束的优化问题。
- en: Apply the method of Lagrange multipliers to derive the first-order necessary
    conditions for a constrained local minimizer.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用拉格朗日乘数法推导约束局部最小值的一阶必要条件。
- en: Verify the second-order sufficient conditions for a constrained local minimizer
    using the Hessian matrix and Lagrange multipliers.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵和拉格朗日乘数验证约束局部最小值的二阶充分条件。
- en: Analyze the regularity condition in the context of constrained optimization
    problems.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析约束优化问题中的正则性条件。
- en: Solve a constrained optimization problem by finding points that satisfy the
    first-order necessary conditions and checking the second-order sufficient conditions.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过找到满足一阶必要条件并检查二阶充分条件的点来解决约束优化问题。
- en: Define convex sets and convex functions, and provide examples of each.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义凸集和凸函数，并给出每个的例子。
- en: Identify operations that preserve convexity of sets and functions.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定保持集合和函数凸性的操作。
- en: Characterize convex functions using the first-order convexity condition based
    on the gradient.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于梯度的第一阶凸性条件来表征凸函数。
- en: Determine the convexity of a function using the second-order convexity condition
    based on the Hessian matrix.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于Hessian矩阵的二阶凸性条件确定函数的凸性。
- en: Explain the relationship between convexity and optimization, particularly how
    local minimizers of convex functions are also global minimizers.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释凸性与优化的关系，特别是凸函数的局部最小值也是全局最小值。
- en: State and prove the first-order optimality condition for convex functions on
    R^d and on convex sets.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述并证明在R^d和凸集上的凸函数的一阶最优性条件。
- en: Define strong convexity and its implications for the existence and uniqueness
    of global minimizers.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义强凸性及其对全局最小值存在性和唯一性的影响。
- en: Analyze the convexity and strong convexity of quadratic functions and least-squares
    objectives.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析二次函数和最小二乘目标函数的凸性和强凸性。
- en: Apply the concept of convexity to solve optimization problems, such as finding
    the projection of a point onto a convex set.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用凸性概念解决优化问题，例如找到点在凸集上的投影。
- en: Define gradient descent and explain its motivation as a numerical optimization
    method.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义梯度下降，并解释其作为数值优化方法的动机。
- en: Prove that the negative gradient is the steepest descent direction for a continuously
    differentiable function.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明负梯度是连续可微函数的最速下降方向。
- en: Analyze the convergence of gradient descent for smooth functions, proving that
    it produces a sequence of points with decreasing objective values and vanishing
    gradients.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析平滑函数的梯度下降收敛性，证明它产生了一系列具有递减目标值和消失梯度的点。
- en: Derive the convergence rate of gradient descent for smooth functions in terms
    of the number of iterations.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推导出梯度下降在平滑函数上的收敛率，以迭代次数来表示。
- en: Define strong convexity for twice continuously differentiable functions and
    relate it to the function value and gradient.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义二阶连续可微函数的强凸性，并将其与函数值和梯度联系起来。
- en: Prove faster convergence rates for gradient descent when applied to smooth and
    strongly convex functions, showing exponential convergence to the global minimum.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明当应用于平滑和强凸函数时，梯度下降具有更快的收敛率，并显示出指数收敛到全局最小值。
- en: Implement gradient descent in Python and apply it to simple examples to illustrate
    the theoretical convergence results.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中实现梯度下降，并将其应用于简单示例以说明理论收敛结果。
- en: Explain the role of the sigmoid function in transforming a linear function of
    features into a probability.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释sigmoid函数在将特征线性函数转换为概率中的作用。
- en: Derive the gradient and Hessian of the logistic regression objective function
    (cross-entropy loss).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推导逻辑回归目标函数（交叉熵损失）的梯度和Hessian矩阵。
- en: Prove that the logistic regression objective function is convex and smooth.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明逻辑回归目标函数是凸的和光滑的。
- en: Implement gradient descent to minimize the logistic regression objective function
    in Python.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中实现梯度下降以最小化逻辑回归目标函数。
- en: Apply logistic regression to real-world datasets.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将逻辑回归应用于实际数据集。
- en: \(\aleph\)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 3.8.2\. Additional sections[#](#additional-sections "Link to this heading")
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.8.2. 附加章节[#](#additional-sections "链接到本标题")
- en: '3.8.2.1\. Logistic regression: illustration of convergence result[#](#logistic-regression-illustration-of-convergence-result
    "Link to this heading")'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.1. 逻辑回归：收敛结果的展示[#](#logistic-regression-illustration-of-convergence-result
    "链接到本标题")
- en: We return to our proof of convergence for smooth functions using a special case
    of logistic regression. We first define the functions \(\hat{f}\), \(\mathcal{L}\)
    and \(\frac{\partial}{\partial x}\mathcal{L}\).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到平滑函数收敛性的证明，使用逻辑回归的特殊情况。我们首先定义函数\(\hat{f}\)，\(\mathcal{L}\)和\(\frac{\partial}{\partial
    x}\mathcal{L}\)。
- en: '[PRE0]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We illustrate GD on a random dataset.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在随机数据集上展示GD（梯度下降）。
- en: '[PRE1]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We plot the upper and lower bounds in the *Quadratic Bound for Smooth Functions*
    around \(x = x_0\). It turns out we can take \(L=1\) because all features are
    uniformly random between \(-1\) and \(1\). Observe that minimizing the upper quadratic
    bound leads to a decrease in \(\mathcal{L}\).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在\(x = x_0\)附近的*平滑函数的二次界限*中绘制上界和下界。结果是我们可以将\(L=1\)，因为所有特征在\(-1\)和\(1\)之间均匀随机。观察发现，最小化上界二次界限会导致\(\mathcal{L}\)的减少。
- en: '[PRE2]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
- en: '3.8.2.2\. Logistic regression: another dataset[#](#logistic-regression-another-dataset
    "Link to this heading")'
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.2. 逻辑回归：另一个数据集[#](#logistic-regression-another-dataset "链接到本标题")
- en: Recall that to run gradient descent, we first implement a function computing
    a descent update. It takes as input a function `grad_fn` computing the gradient
    itself, as well as a current iterate and a step size. We now also feed a dataset
    as additional input.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，为了运行梯度下降，我们首先实现一个计算下降更新的函数。该函数接受一个计算梯度的函数`grad_fn`作为输入，以及当前迭代和步长。现在我们还将数据集作为额外的输入。
- en: '[PRE3]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We analyze with a simple dataset from UC Berkeley’s [DS100](http://www.ds100.org)
    course. The file `lebron.csv` is available [here](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets).
    Quoting a previous version of the course’s textbook:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用UC Berkeley的[DS100](http://www.ds100.org)课程的一个简单数据集进行分析。文件`lebron.csv`可在[此处](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets)找到。引用课程教科书的前一个版本：
- en: In basketball, players score by shooting a ball through a hoop. One such player,
    LeBron James, is widely considered one of the best basketball players ever for
    his incredible ability to score. LeBron plays in the National Basketball Association
    (NBA), the United States’s premier basketball league. We’ve collected a dataset
    of all of LeBron’s attempts in the 2017 NBA Playoff Games using the NBA statistics
    website ([https://stats.nba.com/](https://stats.nba.com/)).
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在篮球中，球员通过将球投进篮筐来得分。勒布朗·詹姆斯就是这样一位球员，他因其惊人的得分能力而被广泛认为是史上最伟大的篮球运动员之一。勒布朗效力于美国最顶级的篮球联赛——国家篮球协会（NBA）。我们使用NBA统计网站（[https://stats.nba.com/](https://stats.nba.com/)）收集了2017年NBA季后赛中勒布朗的所有尝试数据集。
- en: We first load the data and look at its summary.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载数据并查看其摘要。
- en: '[PRE4]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 20170415 | 10 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 0 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 20170415 | 10 | IND | 驱动上篮 | 2分投篮 | 0 | 0 |'
- en: '| 1 | 20170415 | 11 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 20170415 | 11 | IND | 驱动上篮 | 2分投篮 | 0 | 1 |'
- en: '| 2 | 20170415 | 14 | IND | Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 20170415 | 14 | IND | 上篮 | 2分投篮 | 0 | 1 |'
- en: '| 3 | 20170415 | 15 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 20170415 | 15 | IND | 驱动上篮 | 2分投篮 | 0 | 1 |'
- en: '| 4 | 20170415 | 18 | IND | Alley Oop Dunk Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 20170415 | 18 | IND | 快攻扣篮 | 2分投篮 | 0 | 1 |'
- en: '[PRE5]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '|  | game_date | minute | shot_distance | shot_made |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | shot_distance | shot_made |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
- en: '| mean | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| mean | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
- en: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
- en: '| min | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| min | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
- en: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
- en: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
- en: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
- en: '| max | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| max | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
- en: The two columns we will be interested in are `shot_distance` (LeBron’s distance
    from the basket when the shot was attempted (ft)) and `shot_made` (0 if the shot
    missed, 1 if the shot went in). As the summary table above indicates, the average
    distance was `10.6953` and the frequency of shots made was `0.565104`. We extract
    those two columns and display them on a scatter plot.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注的两个列是 `shot_distance`（投篮时勒布朗距离篮筐的距离（英尺））和 `shot_made`（如果投篮未命中为0，如果投篮命中为1）。如上表所示，平均距离为
    `10.6953`，投篮命中的频率为 `0.565104`。我们提取这两个列，并在散点图上显示。
- en: '[PRE6]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
- en: As you can see, this kind of data is hard to vizualize because of the superposition
    of points with the same \(x\) and \(y\)-values. One trick is to jiggle the \(y\)’s
    a little bit by adding Gaussian noise. We do this next and plot again.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种数据由于具有相同 \(x\) 和 \(y\) 值的点重叠而难以可视化。一个技巧是通过添加高斯噪声稍微抖动 \(y\) 值。我们接下来这样做，并再次绘制。
- en: '[PRE7]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
- en: We apply GD to logistic regression. We first construct the data matrices \(A\)
    and \(\mathbf{b}\). To allow an affine function of the features, we add a column
    of \(1\)’s as we have done before.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将GD应用于逻辑回归。我们首先构建数据矩阵 \(A\) 和 \(\mathbf{b}\)。为了允许特征的一次函数，我们添加了一个列，就像之前做的那样。
- en: '[PRE8]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We run GD starting from \((0,0)\) with a step size computed from the smoothness
    of the objective as above.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 \((0,0)\) 开始运行GD，步长由上述目标函数的平滑度计算得出。
- en: '[PRE9]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally we plot the results.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们绘制结果。
- en: '[PRE13]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
- en: 3.8.1\. Quizzes, solutions, code, etc.[#](#quizzes-solutions-code-etc "Link
    to this heading")
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.8.1\. 测验、解答、代码等。[#](#quizzes-solutions-code-etc "链接到本标题")
- en: 3.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.1\. 仅代码[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码可以在以下位置找到交互式的Jupyter笔记本（推荐使用Google Colab）。鼓励您对其进行尝试。一些建议的计算练习散布在其中。笔记本也可以作为幻灯片查看。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
- en: 3.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.2\. 自我评估测验[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以获取更广泛的自我评估测验的网络版本。
- en: '[Section 3.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.2节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
- en: '[Section 3.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.3节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
- en: '[Section 3.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.4节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
- en: '[Section 3.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.5节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
- en: '[Section 3.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.6节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
- en: 3.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的自动生成的测验可以在此处访问（推荐使用Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
- en: 3.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.4\. 奇数编号预热练习的解答[#](#solutions-to-odd-numbered-warm-up-exercises "链接到本标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*(有Claude、Gemini和ChatGPT的帮助)*'
- en: 'Answer and justification for E3.2.1:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.1的答案和理由：
- en: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
- en: 'At the point \((1, -1)\), we have:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((1, -1)\)，我们有：
- en: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
- en: 'Answer and justification for E3.2.3:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.3的答案和理由：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
- en: 'At the point \((\frac{\pi}{4}, \frac{\pi}{3})\), we have:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((\frac{\pi}{4}, \frac{\pi}{3})\)，我们有：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1}(\frac{\pi}{4}, \frac{\pi}{3})
    &= \cos(\frac{\pi}{4}) \cos(\frac{\pi}{3}) = \frac{\sqrt{2}}{2} \cdot \frac{1}{2}
    = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}(\frac{\pi}{4}, \frac{\pi}{3})
    &= -\sin(\frac{\pi}{4}) \sin(\frac{\pi}{3}) = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2}
    = -\frac{\sqrt{6}}{4}. \end{align*}\]
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1}(\frac{\pi}{4}, \frac{\pi}{3})
    &= \cos(\frac{\pi}{4}) \cos(\frac{\pi}{3}) = \frac{\sqrt{2}}{2} \cdot \frac{1}{2}
    = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}(\frac{\pi}{4}, \frac{\pi}{3})
    &= -\sin(\frac{\pi}{4}) \sin(\frac{\pi}{3}) = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2}
    = -\frac{\sqrt{6}}{4}. \end{align*}\]
- en: 'Answer and justification for E3.2.5: The Hessian matrix of \(f(x_1, x_2)\)
    is:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.5的答案和解释：函数 \(f(x_1, x_2)\) 的Hessian矩阵为：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
- en: 'At the point \((1, 2)\), we have:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在点 \((1, 2)\) 处，我们有：
- en: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
- en: We can see that \(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\), confirming the Symmetry of the Hessian
    Theorem.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 \(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\)，这证实了Hessian矩阵对称定理。
- en: 'Answer and justification for E3.2.7:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.7的答案和解释：
- en: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
- en: 'Answer and justification for E3.2.9: The Hessian matrix is given by:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.9的答案和解释：Hessian矩阵由以下给出：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.11: \(\frac{\partial f}{\partial x} = 3x^2y^2
    - 2y^3\) and \(\frac{\partial f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\), obtained
    by differentiating \(f\) with respect to each variable while holding the other
    constant.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.11的答案和解释：通过对 \(f\) 分别对每个变量求导（保持其他变量不变），得到 \(\frac{\partial f}{\partial
    x} = 3x^2y^2 - 2y^3\) 和 \(\frac{\partial f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\)。
- en: 'Answer and justification for E3.2.13: The Hessian matrix is given by'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.13的答案和解释：Hessian矩阵由以下给出：
- en: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.15: \(\frac{\partial^2 q}{\partial x^2} =
    6x\) and \(\frac{\partial^2 q}{\partial y^2} = -6x\). Adding these gives \(6x
    - 6x = 0\), so \(q\) satisfies Laplace’s equation.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.15的答案和解释：\(\frac{\partial^2 q}{\partial x^2} = 6x\) 和 \(\frac{\partial^2
    q}{\partial y^2} = -6x\)。将这两个结果相加得到 \(6x - 6x = 0\)，因此 \(q\) 满足拉普拉斯方程。
- en: 'Answer and justification for E3.2.17: By the chain rule, the rate of change
    of temperature experienced by the particle is'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.17的答案和解释：根据链式法则，粒子所经历的温度变化率为
- en: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
- en: We have \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) and \(\mathbf{c}'(t)
    = (2t, 3t^2)\). Evaluating at \(t = 1\) gives
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) 和 \(\mathbf{c}'(t)
    = (2t, 3t^2)\)。在 \(t = 1\) 时计算得
- en: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
- en: 'Answer and justification for E3.2.19: \(\frac{d}{dt} f(\mathbf{g}(t)) = 2t
    \cos t - t^2 \sin t\). Justification: \(\nabla f = (y, x)\), and \(\mathbf{g}''(t)
    = (2t, -\sin t)\). Then, \(\frac{d}{dt} f(\mathbf{g}(t)) = \cos t \cdot 2t + t^2
    \cdot (-\sin t)\).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.19的答案和解释：\(\frac{d}{dt} f(\mathbf{g}(t)) = 2t \cos t - t^2 \sin t\)。解释：\(\nabla
    f = (y, x)\)，且 \(\mathbf{g}'(t) = (2t, -\sin t)\)。因此，\(\frac{d}{dt} f(\mathbf{g}(t))
    = \cos t \cdot 2t + t^2 \cdot (-\sin t)\)。
- en: 'Answer and justification for E3.3.1: \(\nabla f(x_1, x_2) = (2x_1, 4x_2)\).
    Setting this equal to zero yields \(2x_1 = 0\) and \(4x_2 = 0\), which implies
    \(x_1 = 0\) and \(x_2 = 0\). Thus, the only point where \(\nabla f(x_1, x_2) =
    0\) is \((0, 0)\).'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.1 的答案和解释：\(\nabla f(x_1, x_2) = (2x_1, 4x_2)\)。将其设为零得到 \(2x_1 = 0\) 和
    \(4x_2 = 0\)，这意味着 \(x_1 = 0\) 和 \(x_2 = 0\)。因此，唯一使 \(\nabla f(x_1, x_2) = 0\)
    的点是 \((0, 0)\)。
- en: 'Answer and justification for E3.3.3: The second directional derivative is given
    by \(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\). We have \(\mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 & 2 \\ 2 &
    2 \end{pmatrix}\). Thus,'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.3 的答案和解释：二阶偏导数由 \(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2}
    = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \mathbf{v}\) 给出。我们有 \(\mathbf{H}_f(x_1,
    x_2) = \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix}\)。因此，
- en: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
- en: 'Answer and justification for E3.3.5: The first-order necessary conditions are:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.5 的答案和解释：一阶必要条件是：
- en: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
- en: 'Computing the gradients:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度：
- en: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
- en: 'From the first two equations, we have \(x_1 = x_2 = -\frac{\lambda}{2}\). Substituting
    into the third equation:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 从前两个方程中，我们得到 \(x_1 = x_2 = -\frac{\lambda}{2}\)。将其代入第三个方程：
- en: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
- en: Thus, \(x_1 = x_2 = \frac{1}{2}\), and the only point satisfying the first-order
    necessary conditions is \((\frac{1}{2}, \frac{1}{2}, -1)\).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = x_2 = \frac{1}{2}\)，并且满足一阶必要条件的唯一点是 \((\frac{1}{2}, \frac{1}{2},
    -1)\)。
- en: 'Answer and justification for E3.3.7: The Lagrangian is \(L(x_1, x_2, x_3, \lambda)
    = x_1^2 + x_2^2 + x_3^2 + \lambda(x_1 + 2x_2 + 3x_3 - 6)\). The first-order necessary
    conditions are:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.7 的答案和解释：拉格朗日函数是 \(L(x_1, x_2, x_3, \lambda) = x_1^2 + x_2^2 + x_3^2
    + \lambda(x_1 + 2x_2 + 3x_3 - 6)\)。一阶必要条件是：
- en: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
- en: 'From the first three equations, we have \(x_1 = -\frac{\lambda}{2}\), \(x_2
    = -\lambda\), \(x_3 = -\frac{3\lambda}{2}\). Substituting into the fourth equation:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 从前三个方程中，我们得到 \(x_1 = -\frac{\lambda}{2}\)，\(x_2 = -\lambda\)，\(x_3 = -\frac{3\lambda}{2}\)。将这些值代入第四个方程：
- en: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
- en: Thus, \(x_1 = \frac{1}{2}\), \(x_2 = 1\), \(x_3 = \frac{3}{2}\), and the only
    point satisfying the first-order necessary conditions is \((\frac{1}{2}, 1, \frac{3}{2},
    -1)\).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = \frac{1}{2}\)，\(x_2 = 1\)，\(x_3 = \frac{3}{2}\)，并且满足一阶必要条件的唯一点是 \((\frac{1}{2},
    1, \frac{3}{2}, -1)\)。
- en: 'Answer and justification for E3.3.9: The gradient of \(f\) is \(\nabla f(x_1,
    x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\). At the point \((1, 0)\), the gradient is
    \(\nabla f(1, 0) = (3, 0)\). The directional derivative of \(f\) at \((1, 0)\)
    in the direction \(\mathbf{v} = (1, 1)\) is \(\nabla f(1, 0)^T \mathbf{v} = (3,
    0)^T (1, 1) = 3\). Since this is positive, \(v\) is not a descent direction.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.9 的答案和解释：函数 \(f\) 的梯度是 \(\nabla f(x_1, x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\)。在点
    \((1, 0)\) 处，梯度是 \(\nabla f(1, 0) = (3, 0)\)。在方向 \(\mathbf{v} = (1, 1)\) 上，函数
    \(f\) 在点 \((1, 0)\) 的方向导数是 \(\nabla f(1, 0)^T \mathbf{v} = (3, 0)^T (1, 1) = 3\)。由于这是正的，因此
    \(v\) 不是下降方向。
- en: 'Answer and justification for E3.3.11: The Hessian matrix of \(f\) is'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 对 E3.3.11 的答案和解释：函数 \(f\) 的Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
- en: Therefore, the second directional derivative of \(f\) at \((0, 0)\) in the direction
    \(v = (1, 0)\) is \(\mathbf{v}^T \mathbf{H}_f(0, 0) \mathbf{v} = (1, 0) \begin{bmatrix}
    -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = -2\).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\) 在 \((0, 0)\) 处沿方向 \(v = (1, 0)\) 的二阶方向导数是 \(\mathbf{v}^T \mathbf{H}_f(0,
    0) \mathbf{v} = (1, 0) \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix}
    1 \\ 0 \end{pmatrix} = -2\).
- en: 'Answer and justification for E3.3.13: The Hessian matrix is'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.13的答案和证明：Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
- en: 'Justification: Compute the second partial derivatives:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 证明：计算二阶偏导数：
- en: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
- en: At \((1,1)\), these values are \(6\), \(6\), and \(-3\), respectively.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在 \((1,1)\) 处，这些值分别是 \(6\)，\(6\) 和 \(-3\)。
- en: 'Answer and justification for E3.4.1: The convex combination is:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.1的答案和证明：凸组合是：
- en: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
- en: 'Answer and justification for E3.4.3: \(S_1\) and \(S_2\) are halfspaces, which
    are convex sets. By the lemma in the text, the intersection of convex sets is
    also convex. Therefore, \(S_1 \cap S_2\) is a convex set.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.3的答案和证明：\(S_1\) 和 \(S_2\) 是半空间，它们是凸集。根据文本中的引理，凸集的交集也是凸的。因此，\(S_1 \cap S_2\)
    是一个凸集。
- en: 'Answer and justification for E3.4.5: The function \(f\) is a quadratic function
    with \(P = 2\), \(q = 2\), and \(r = 1\). Since \(P > 0\), \(f\) is strictly convex.
    The unique global minimizer is found by setting the gradient to zero:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.5的答案和证明：函数 \(f\) 是一个二次函数，具有 \(P = 2\)，\(q = 2\)，和 \(r = 1\)。由于 \(P > 0\)，\(f\)
    是严格凸的。通过将梯度设为零找到唯一的全局最小值：
- en: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
- en: 'Answer and justification for E3.4.7: The Hessian matrix of \(f\) is:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.7的答案和证明：\(f\) 的Hessian矩阵是：
- en: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
- en: 'For any \((x, y) \in \mathbb{R}^2\), we have:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任意的 \((x, y) \in \mathbb{R}^2\)，我们有：
- en: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
- en: so \(f\) is strongly convex with \(m = 2\).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\) 是具有 \(m = 2\) 的强凸函数。
- en: 'Answer and justification for E3.4.9: \(f\) is not convex. We have \(f''''(x)
    = 12x^2 - 4\), which is negative for \(x \in (-\frac{1}{\sqrt{3}}, \frac{1}{\sqrt{3}})\).
    Since the second derivative is not always nonnegative, \(f\) is not convex.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.9的答案和证明：\(f\) 不是凸函数。我们有 \(f''(x) = 12x^2 - 4\)，对于 \(x \in (-\frac{1}{\sqrt{3}},
    \frac{1}{\sqrt{3}})\) 是负的。由于二阶导数不总是非负的，\(f\) 不是凸函数。
- en: 'Answer and justification for E3.4.11: \(f\) is strongly convex. We have \(f''''(x)
    = 2 > 0\), so \(f\) is 2-strongly convex.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.11的答案和证明：\(f\) 是强凸的。我们有 \(f''(x) = 2 > 0\)，所以 \(f\) 是2-强凸的。
- en: 'Answer and justification for E3.4.13: \(D\) is convex. To show this, let \((x_1,
    y_1), (x_2, y_2) \in D\) and \(\alpha \in (0, 1)\). We need to show that \((1
    - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\). Compute:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.13的答案和证明：\(D\) 是凸的。为了证明这一点，设 \((x_1, y_1), (x_2, y_2) \in D\) 和 \(\alpha
    \in (0, 1)\)。我们需要证明 \((1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\)。计算：
- en: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
- en: Now,
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
- en: Hence, \(D\) is convex.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(D\) 是凸的。
- en: 'Answer and justification for E3.4.15: \(D\) is not convex. For example, let
    \((x_1, y_1) = (2, \sqrt{3})\) and \((x_2, y_2) = (2, -\sqrt{3})\), both of which
    are in \(D\). For \(\alpha = \frac{1}{2}\),'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.15的答案和证明：\(D\) 不是凸的。例如，设 \((x_1, y_1) = (2, \sqrt{3})\) 和 \((x_2, y_2)
    = (2, -\sqrt{3})\)，它们都在 \(D\) 中。对于 \(\alpha = \frac{1}{2}\)，
- en: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
- en: Now,
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
- en: 'Answer and justification for E3.5.1: The gradient is \(\nabla f(x, y) = (2x,
    8y)\). At \((1, 1)\), it is \((2, 8)\). The direction of steepest descent is \(-\nabla
    f(1, 1) = (-2, -8)\).'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.1的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 8y)\)。在 \((1, 1)\) 处，它是 \((2, 8)\)。最速下降的方向是
    \(-\nabla f(1, 1) = (-2, -8)\)。
- en: 'Answer and justification for E3.5.3: \(\nabla f(x) = 3x^2 - 12x + 9\). At \(x_0
    = 0\), \(\nabla f(0) = 9\). The first iteration gives \(x_1 = x_0 - \alpha \nabla
    f(x_0) = 0 - 0.1 \cdot 9 = -0.9\). At \(x_1 = -0.9\), \(\nabla f(-0.9) = 3 \cdot
    (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43 + 10.8 + 9 = 22.23\). The second iteration
    gives \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot 22.23 = -3.123\).'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.3的答案和解释：\(\nabla f(x) = 3x^2 - 12x + 9\)。在 \(x_0 = 0\) 时，\(\nabla f(0)
    = 9\)。第一次迭代给出 \(x_1 = x_0 - \alpha \nabla f(x_0) = 0 - 0.1 \cdot 9 = -0.9\)。在
    \(x_1 = -0.9\) 时，\(\nabla f(-0.9) = 3 \cdot (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43
    + 10.8 + 9 = 22.23\)。第二次迭代给出 \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot
    22.23 = -3.123\)。
- en: 'Answer and justification for E3.5.5: We have \(\nabla f(x) = 2x\), so \(\nabla
    f(2) = 4\). Thus, the gradient descent update is \(x_1 = x_0 - \alpha \nabla f(x_0)
    = 2 - 0.1 \cdot 4 = 1.6\).'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.5的答案和解释：我们有 \(\nabla f(x) = 2x\)，所以 \(\nabla f(2) = 4\)。因此，梯度下降更新为 \(x_1
    = x_0 - \alpha \nabla f(x_0) = 2 - 0.1 \cdot 4 = 1.6\)。
- en: 'Answer and justification for E3.5.7: \(f''''(x) = 4\) for all \(x \in \mathbb{R}\).
    Therefore, \(f''''(x) \geq 4\) for all \(x \in \mathbb{R}\), which implies that
    \(f\) is \(4\)-strongly convex.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.7的答案和解释：对于所有 \(x \in \mathbb{R}\)，\(f''(x) = 4\)。因此，对于所有 \(x \in \mathbb{R}\)，\(f''(x)
    \geq 4\)，这意味着 \(f\) 是 \(4\)-强凸的。
- en: 'Answer and justification for E3.5.9: No. We have \(f''''(x) = 12x^2\), which
    can be arbitrarily large as \(x\) increases. Thus, there is no constant \(L\)
    such that \(-L \le f''''(x) \le L\) for all \(x \in \mathbb{R}\).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.9的答案和解释：不。我们有 \(f''(x) = 12x^2\)，随着 \(x\) 的增加，它可以变得任意大。因此，不存在常数 \(L\)，使得对于所有
    \(x \in \mathbb{R}\)，\(-L \le f''(x) \le L\)。
- en: 'Answer and justification for E3.5.11: We have \(f''''(x) = 2\) for all \(x
    \in \mathbb{R}\). Thus, we can take \(m = 2\), and we have \(f''''(x) \ge 2\)
    for all \(x \in \mathbb{R}\), which is the condition for \(m\)-strong convexity.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.11的答案和解释：对于所有 \(x \in \mathbb{R}\)，\(f''(x) = 2\)。因此，我们可以取 \(m = 2\)，并且对于所有
    \(x \in \mathbb{R}\)，\(f''(x) \ge 2\)，这是 \(m\)-强凸的条件。
- en: 'Answer and justification for E3.5.13: The gradient is \(\nabla f(x, y) = (2x,
    2y)\). At \((1, 1)\), it is \((2, 2)\). The first update is \((0.8, 0.8)\). The
    gradient at \((0.8, 0.8)\) is \((1.6, 1.6)\). The second update is \((0.64, 0.64)\).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.13的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 2y)\)。在 \((1, 1)\) 处，它是 \((2, 2)\)。第一次更新是
    \((0.8, 0.8)\)。在 \((0.8, 0.8)\) 处的梯度是 \((1.6, 1.6)\)。第二次更新是 \((0.64, 0.64)\)。
- en: 'Answer and justification for E3.6.1: The log-odds is given by \(\log \frac{p}{1-p}
    = \log \frac{0.25}{0.75} = \log \frac{1}{3} = -\log 3\).'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.1的答案和解释：对数几率由 \(\log \frac{p}{1-p} = \log \frac{0.25}{0.75} = \log \frac{1}{3}
    = -\log 3\) 给出。
- en: 'Answer and justification for E3.6.3:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.3的答案和解释：
- en: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
- en: 'Answer and justification for E3.6.5: By the quotient rule,'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.5的答案和解释：根据商规则，
- en: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
- en: 'Answer and justification for E3.6.7: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}) \approx 0.05\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x})
    \approx -0.73\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}) \approx 0.73\).
    Therefore,'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.7的答案和解释：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}) \approx
    0.05\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}) \approx -0.73\), \(b_3
    - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}) \approx 0.73\)。因此，
- en: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
- en: 'Answer and justification for E3.6.9: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}^0) = 1 - \sigma(0) = 0.5\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T
    \mathbf{x}^0) = -0.5\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) =
    0.5\). Therefore,'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.9的答案和解释：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}^0) = 1 -
    \sigma(0) = 0.5\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}^0) = -0.5\),
    \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) = 0.5\)。因此，
- en: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
- en: 3.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.5\. 学习成果[#](#learning-outcomes "链接到这个标题")
- en: Define and calculate partial derivatives and gradients for functions of several
    variables.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义并计算多个变量函数的偏导数和梯度。
- en: Compute second-order partial derivatives and construct the Hessian matrix for
    twice continuously differentiable functions.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算二次连续可微函数的二阶偏导数并构建Hessian矩阵。
- en: Apply the Chain Rule to compute derivatives of composite functions of several
    variables.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将链式法则应用于计算多个变量的复合函数的导数。
- en: State and prove the multivariable version of the Mean Value Theorem using the
    Chain Rule.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用链式法则陈述并证明多元函数的平均值定理。
- en: Calculate gradients and Hessians for affine and quadratic functions of several
    variables.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算多个变量的仿射函数和二次函数的梯度和Hessian矩阵。
- en: Define global and local minimizers for unconstrained optimization problems.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无约束优化问题的全局和局部最小值。
- en: Derive the first-order necessary conditions for a local minimizer using the
    gradient.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用梯度推导局部最小值的一阶必要条件。
- en: Explain the concept of a descent direction and its relation to the gradient.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释下降方向的概念及其与梯度的关系。
- en: Explain the concept of directional derivatives and compute directional derivatives
    using the gradient.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释方向导数的概念，并使用梯度计算方向导数。
- en: State the second-order necessary and sufficient conditions for a local minimizer
    using the Hessian matrix.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵陈述局部最小值的二阶必要和充分条件。
- en: Compute the gradient and Hessian matrix for a given multivariable function.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定多变量函数的梯度和Hessian矩阵。
- en: Formulate optimization problems with equality constraints.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表达具有等式约束的优化问题。
- en: Apply the method of Lagrange multipliers to derive the first-order necessary
    conditions for a constrained local minimizer.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用拉格朗日乘数法推导约束局部最小值的一阶必要条件。
- en: Verify the second-order sufficient conditions for a constrained local minimizer
    using the Hessian matrix and Lagrange multipliers.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵和拉格朗日乘数验证约束局部最小值的二阶充分条件。
- en: Analyze the regularity condition in the context of constrained optimization
    problems.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在约束优化问题的背景下分析正则性条件。
- en: Solve a constrained optimization problem by finding points that satisfy the
    first-order necessary conditions and checking the second-order sufficient conditions.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过找到满足一阶必要条件并检查二阶充分条件的点来解决约束优化问题。
- en: Define convex sets and convex functions, and provide examples of each.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义凸集和凸函数，并给出每个的例子。
- en: Identify operations that preserve convexity of sets and functions.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别保持集合和函数凸性的操作。
- en: Characterize convex functions using the first-order convexity condition based
    on the gradient.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于梯度定义凸函数的一阶凸性条件。
- en: Determine the convexity of a function using the second-order convexity condition
    based on the Hessian matrix.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于Hessian矩阵的二阶凸性条件确定函数的凸性。
- en: Explain the relationship between convexity and optimization, particularly how
    local minimizers of convex functions are also global minimizers.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释凸性与优化之间的关系，特别是凸函数的局部最小值也是全局最小值。
- en: State and prove the first-order optimality condition for convex functions on
    R^d and on convex sets.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈述并证明在R^d和凸集上的凸函数的一阶最优条件。
- en: Define strong convexity and its implications for the existence and uniqueness
    of global minimizers.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义强凸性及其对全局最小值存在性和唯一性的影响。
- en: Analyze the convexity and strong convexity of quadratic functions and least-squares
    objectives.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析二次函数和最小二乘目标函数的凸性和强凸性。
- en: Apply the concept of convexity to solve optimization problems, such as finding
    the projection of a point onto a convex set.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用凸性概念解决优化问题，例如找到点在凸集上的投影。
- en: Define gradient descent and explain its motivation as a numerical optimization
    method.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义梯度下降并解释其作为数值优化方法的动机。
- en: Prove that the negative gradient is the steepest descent direction for a continuously
    differentiable function.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明负梯度是连续可微函数的最速下降方向。
- en: Analyze the convergence of gradient descent for smooth functions, proving that
    it produces a sequence of points with decreasing objective values and vanishing
    gradients.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析平滑函数梯度下降的收敛性，证明它产生了一系列具有递减目标值和消失梯度的点。
- en: Derive the convergence rate of gradient descent for smooth functions in terms
    of the number of iterations.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以迭代次数为标准，推导出平滑函数梯度下降的收敛速度。
- en: Define strong convexity for twice continuously differentiable functions and
    relate it to the function value and gradient.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为二阶连续可微函数定义强凸性，并将其与函数值和梯度联系起来。
- en: Prove faster convergence rates for gradient descent when applied to smooth and
    strongly convex functions, showing exponential convergence to the global minimum.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明当梯度下降应用于平滑且强凸函数时，其收敛速度更快，并展示出指数级收敛到全局最小值。
- en: Implement gradient descent in Python and apply it to simple examples to illustrate
    the theoretical convergence results.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中实现梯度下降并将其应用于简单示例，以说明理论收敛结果。
- en: Explain the role of the sigmoid function in transforming a linear function of
    features into a probability.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释sigmoid函数在将特征线性函数转换为概率中的作用。
- en: Derive the gradient and Hessian of the logistic regression objective function
    (cross-entropy loss).
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推导逻辑回归目标函数（交叉熵损失）的梯度和Hessian矩阵。
- en: Prove that the logistic regression objective function is convex and smooth.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明逻辑回归目标函数是凸函数且光滑。
- en: Implement gradient descent to minimize the logistic regression objective function
    in Python.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中实现梯度下降以最小化逻辑回归目标函数。
- en: Apply logistic regression to real-world datasets.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将逻辑回归应用于实际数据集。
- en: \(\aleph\)
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 3.8.1.1\. Just the code[#](#just-the-code "Link to this heading")
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.1\. 仅代码[#](#just-the-code "链接到本标题")
- en: An interactive Jupyter notebook featuring the code in this chapter can be accessed
    below (Google Colab recommended). You are encouraged to tinker with it. Some suggested
    computational exercises are scattered throughout. The notebook is also available
    as a slideshow.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 以下可以访问一个包含本章代码的交互式 Jupyter 笔记本（推荐使用 Google Colab）。鼓励您对其进行实验。一些建议的计算练习散布在笔记本中。笔记本也可以作为幻灯片查看。
- en: '[Notebook](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb)
    ([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_opt_notebook.ipynb))'
- en: '[Slideshow](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_opt_notebook_slides.slides.html)'
- en: 3.8.1.2\. Self-assessment quizzes[#](#self-assessment-quizzes "Link to this
    heading")
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.2\. 自我评估测验[#](#self-assessment-quizzes "链接到本标题")
- en: A more extensive web version of the self-assessment quizzes is available by
    following the links below.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下链接可以访问更全面的自我评估测验的网页版本。
- en: '[Section 3.2](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.2节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_2.html)'
- en: '[Section 3.3](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.3节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_3.html)'
- en: '[Section 3.4](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.4节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_4.html)'
- en: '[Section 3.5](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.5节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_5.html)'
- en: '[Section 3.6](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3.6节](https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_3_6.html)'
- en: 3.8.1.3\. Auto-quizzes[#](#auto-quizzes "Link to this heading")
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.3\. 自动测验[#](#auto-quizzes "链接到本标题")
- en: Automatically generated quizzes for this chapter can be accessed here (Google
    Colab recommended).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 本章自动生成的测验可以在以下链接中访问（推荐使用 Google Colab）。
- en: '[Auto-quizzes](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([Open In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动测验](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb)
    ([在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-opt-autoquiz.ipynb))'
- en: 3.8.1.4\. Solutions to odd-numbered warm-up exercises[#](#solutions-to-odd-numbered-warm-up-exercises
    "Link to this heading")
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.4\. 奇数练习题的解答[#](#solutions-to-odd-numbered-warm-up-exercises "链接到这个标题")
- en: '*(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '*(在Claude、Gemini和ChatGPT的帮助下)*'
- en: 'Answer and justification for E3.2.1:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.1的答案和解释：
- en: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla f(x_1, x_2) &= \left(\frac{\partial f}{\partial x_1},
    \frac{\partial f}{\partial x_2}\right) \\ &= (6x_1 - 2x_2 - 5, -2x_1 + 8x_2 +
    2). \end{align*}\]
- en: 'At the point \((1, -1)\), we have:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在点\((1, -1)\)处，我们有：
- en: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(1, -1) = (6(1) - 2(-1) - 5, -2(1) + 8(-1) + 2) = (3, -8). \]
- en: 'Answer and justification for E3.2.3:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.3的答案和解释：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1} &= \cos(x_1) \cos(x_2), \\
    \frac{\partial f}{\partial x_2} &= -\sin(x_1) \sin(x_2). \end{align*}\]
- en: 'At the point \((\frac{\pi}{4}, \frac{\pi}{3})\), we have:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在点\((\frac{\pi}{4}, \frac{\pi}{3})\)处，我们有：
- en: \[\begin{align*} \frac{\partial f}{\partial x_1}(\frac{\pi}{4}, \frac{\pi}{3})
    &= \cos(\frac{\pi}{4}) \cos(\frac{\pi}{3}) = \frac{\sqrt{2}}{2} \cdot \frac{1}{2}
    = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}(\frac{\pi}{4}, \frac{\pi}{3})
    &= -\sin(\frac{\pi}{4}) \sin(\frac{\pi}{3}) = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2}
    = -\frac{\sqrt{6}}{4}. \end{align*}\]
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial f}{\partial x_1}\left(\frac{\pi}{4}, \frac{\pi}{3}\right)
    &= \cos\left(\frac{\pi}{4}\right) \cos\left(\frac{\pi}{3}\right) = \frac{\sqrt{2}}{2}
    \cdot \frac{1}{2} = \frac{\sqrt{2}}{4}, \\ \frac{\partial f}{\partial x_2}\left(\frac{\pi}{4},
    \frac{\pi}{3}\right) &= -\sin\left(\frac{\pi}{4}\right) \sin\left(\frac{\pi}{3}\right)
    = -\frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2} = -\frac{\sqrt{6}}{4}. \end{align*}\]
- en: 'Answer and justification for E3.2.5: The Hessian matrix of \(f(x_1, x_2)\)
    is:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.5的答案和解释：函数\(f(x_1, x_2)\)的Hessian矩阵为：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 6x_1 & 6x_2 \\ 6x_2
    & 6x_1 - 12x_2 \end{pmatrix}. \end{split}\]
- en: 'At the point \((1, 2)\), we have:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在点\((1, 2)\)处，我们有：
- en: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1, 2) = \begin{pmatrix} 6 & 12 \\ 12 & -18 \end{pmatrix}.
    \end{split}\]
- en: We can see that \(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\), confirming the Symmetry of the Hessian
    Theorem.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到\(\frac{\partial^2 f}{\partial x_1 \partial x_2}(1, 2) = \frac{\partial^2
    f}{\partial x_2 \partial x_1}(1, 2) = 12\)，这证实了Hessian矩阵对称定理。
- en: 'Answer and justification for E3.2.7:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.7的答案和解释：
- en: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial^2 f}{\partial x_1^2} &= 2 \sin(x_2), \\ \frac{\partial^2
    f}{\partial x_1 \partial x_2} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial
    x_2 \partial x_1} &= 2x_1 \cos(x_2), \\ \frac{\partial^2 f}{\partial x_2^2} &=
    -x_1^2 \sin(x_2). \end{align*}\]
- en: 'Answer and justification for E3.2.9: The Hessian matrix is given by:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.9的答案和解释：Hessian矩阵如下：
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2, x_3) = \begin{pmatrix} 2 & -2 & 4 \\
    -2 & 4 & -6 \\ 4 & -6 & 6 \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.11: \(\frac{\partial f}{\partial x} = 3x^2y^2
    - 2y^3\) and \(\frac{\partial f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\), obtained
    by differentiating \(f\) with respect to each variable while holding the other
    constant.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.11的答案和解释：通过对\(f\)分别对每个变量求导，同时保持其他变量不变，得到\(\frac{\partial f}{\partial x}
    = 3x^2y^2 - 2y^3\)和\(\frac{\partial f}{\partial y} = 2x^3y - 6xy^2 + 4y^3\)。
- en: 'Answer and justification for E3.2.13: The Hessian matrix is given by'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.13的答案和解释：Hessian矩阵如下
- en: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_g(x, y) = \begin{pmatrix} -\sin(x) \cos(y) & -\cos(x)
    \sin(y) \\ -\cos(x) \sin(y) & -\sin(x) \cos(y) \end{pmatrix}. \end{split}\]
- en: 'Answer and justification for E3.2.15: \(\frac{\partial^2 q}{\partial x^2} =
    6x\) and \(\frac{\partial^2 q}{\partial y^2} = -6x\). Adding these gives \(6x
    - 6x = 0\), so \(q\) satisfies Laplace’s equation.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.15 的答案和解释：\(\frac{\partial^2 q}{\partial x^2} = 6x\) 和 \(\frac{\partial^2
    q}{\partial y^2} = -6x\)。将它们相加得到 \(6x - 6x = 0\)，因此 \(q\) 满足拉普拉斯方程。
- en: 'Answer and justification for E3.2.17: By the chain rule, the rate of change
    of temperature experienced by the particle is'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.17 的答案和解释：根据链式法则，粒子经历的温度变化率为
- en: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(t)) = \nabla u(\mathbf{c}(t))^T \mathbf{c}'(t).
    \]
- en: We have \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) and \(\mathbf{c}'(t)
    = (2t, 3t^2)\). Evaluating at \(t = 1\) gives
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 \(\nabla u(x, y) = (-2xe^{-x^2 - y^2}, -2ye^{-x^2 - y^2})\) 和 \(\mathbf{c}'(t)
    = (2t, 3t^2)\)。在 \(t = 1\) 时计算得到
- en: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{d}{dt}u(\mathbf{c}(1)) = (-2e^{-2}, -2e^{-2})^T (2, 3) = -10e^{-2}.
    \]
- en: 'Answer and justification for E3.2.19: \(\frac{d}{dt} f(\mathbf{g}(t)) = 2t
    \cos t - t^2 \sin t\). Justification: \(\nabla f = (y, x)\), and \(\mathbf{g}''(t)
    = (2t, -\sin t)\). Then, \(\frac{d}{dt} f(\mathbf{g}(t)) = \cos t \cdot 2t + t^2
    \cdot (-\sin t)\).'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: E3.2.19 的答案和解释：\(\frac{d}{dt} f(\mathbf{g}(t)) = 2t \cos t - t^2 \sin t\). 解释：\(\nabla
    f = (y, x)\)，且 \(\mathbf{g}'(t) = (2t, -\sin t)\)。然后，\(\frac{d}{dt} f(\mathbf{g}(t))
    = \cos t \cdot 2t + t^2 \cdot (-\sin t)\)。
- en: 'Answer and justification for E3.3.1: \(\nabla f(x_1, x_2) = (2x_1, 4x_2)\).
    Setting this equal to zero yields \(2x_1 = 0\) and \(4x_2 = 0\), which implies
    \(x_1 = 0\) and \(x_2 = 0\). Thus, the only point where \(\nabla f(x_1, x_2) =
    0\) is \((0, 0)\).'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.1 的答案和解释：\(\nabla f(x_1, x_2) = (2x_1, 4x_2)\)。将其设置为等于零得到 \(2x_1 = 0\)
    和 \(4x_2 = 0\)，这意味着 \(x_1 = 0\) 和 \(x_2 = 0\)。因此，\(\nabla f(x_1, x_2) = 0\) 的唯一点是
    \((0, 0)\)。
- en: 'Answer and justification for E3.3.3: The second directional derivative is given
    by \(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2} = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0)
    \mathbf{v}\). We have \(\mathbf{H}_f(x_1, x_2) = \begin{pmatrix} 2 & 2 \\ 2 &
    2 \end{pmatrix}\). Thus,'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.3 的答案和解释：二阶方向导数由 \(\frac{\partial^2 f(\mathbf{x}_0)}{\partial \mathbf{v}^2}
    = \mathbf{v}^T \mathbf{H}_f(\mathbf{x}_0) \mathbf{v}\) 给出。我们有 \(\mathbf{H}_f(x_1,
    x_2) = \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix}\)。因此，
- en: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \frac{\partial^2 f(1, 1)}{\partial \mathbf{v}^2} = (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}})^T \begin{pmatrix} 2 & 2 \\ 2 & 2 \end{pmatrix} (\frac{1}{\sqrt{2}},
    \frac{1}{\sqrt{2}}) = \frac{1}{2}(2 + 2 + 2 + 2) = 4. \end{split}\]
- en: 'Answer and justification for E3.3.5: The first-order necessary conditions are:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.5 的答案和解释：一阶必要条件为：
- en: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla_{x_1, x_2} L(x_1, x_2, \lambda) &= 0, \\ h(x_1, x_2)
    &= 0. \end{align*}\]
- en: 'Computing the gradients:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度：
- en: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \frac{\partial L}{\partial x_1} &= 2x_1 + \lambda = 0, \\ \frac{\partial
    L}{\partial x_2} &= 2x_2 + \lambda = 0, \\ x_1 + x_2 &= 1. \end{align*}\]
- en: 'From the first two equations, we have \(x_1 = x_2 = -\frac{\lambda}{2}\). Substituting
    into the third equation:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 从前两个方程，我们得到 \(x_1 = x_2 = -\frac{\lambda}{2}\)。将其代入第三个方程：
- en: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - \frac{\lambda}{2} = 1 \implies \lambda = -1. \]
- en: Thus, \(x_1 = x_2 = \frac{1}{2}\), and the only point satisfying the first-order
    necessary conditions is \((\frac{1}{2}, \frac{1}{2}, -1)\).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = x_2 = \frac{1}{2}\)，唯一满足一阶必要条件的点是 \((\frac{1}{2}, \frac{1}{2}, -1)\)。
- en: 'Answer and justification for E3.3.7: The Lagrangian is \(L(x_1, x_2, x_3, \lambda)
    = x_1^2 + x_2^2 + x_3^2 + \lambda(x_1 + 2x_2 + 3x_3 - 6)\). The first-order necessary
    conditions are:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.7 的答案和解释：拉格朗日函数为 \(L(x_1, x_2, x_3, \lambda) = x_1^2 + x_2^2 + x_3^2 +
    \lambda(x_1 + 2x_2 + 3x_3 - 6)\)。一阶必要条件为：
- en: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} 2x_1 + \lambda &= 0, \\ 2x_2 + 2\lambda &= 0, \\ 2x_3 + 3\lambda
    &= 0, \\ x_1 + 2x_2 + 3x_3 &= 6. \end{align*}\]
- en: 'From the first three equations, we have \(x_1 = -\frac{\lambda}{2}\), \(x_2
    = -\lambda\), \(x_3 = -\frac{3\lambda}{2}\). Substituting into the fourth equation:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 从前三个方程，我们得到 \(x_1 = -\frac{\lambda}{2}\)，\(x_2 = -\lambda\)，\(x_3 = -\frac{3\lambda}{2}\)。将其代入第四个方程：
- en: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: \[ -\frac{\lambda}{2} - 2\lambda - \frac{9\lambda}{2} = 6 \implies -6\lambda
    = 6 \implies \lambda = -1. \]
- en: Thus, \(x_1 = \frac{1}{2}\), \(x_2 = 1\), \(x_3 = \frac{3}{2}\), and the only
    point satisfying the first-order necessary conditions is \((\frac{1}{2}, 1, \frac{3}{2},
    -1)\).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(x_1 = \frac{1}{2}\)，\(x_2 = 1\)，\(x_3 = \frac{3}{2}\)，并且唯一满足一阶必要条件的点是 \((\frac{1}{2},
    1, \frac{3}{2}, -1)\)。
- en: 'Answer and justification for E3.3.9: The gradient of \(f\) is \(\nabla f(x_1,
    x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\). At the point \((1, 0)\), the gradient is
    \(\nabla f(1, 0) = (3, 0)\). The directional derivative of \(f\) at \((1, 0)\)
    in the direction \(\mathbf{v} = (1, 1)\) is \(\nabla f(1, 0)^T \mathbf{v} = (3,
    0)^T (1, 1) = 3\). Since this is positive, \(v\) is not a descent direction.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.9的答案和证明：\(f\) 的梯度是 \(\nabla f(x_1, x_2) = (3x_1^2 - 3x_2^2, -6x_1x_2)\)。在点
    \((1, 0)\) 处，梯度是 \(\nabla f(1, 0) = (3, 0)\)。\(f\) 在 \((1, 0)\) 处沿 \(\mathbf{v}
    = (1, 1)\) 方向的方向导数是 \(\nabla f(1, 0)^T \mathbf{v} = (3, 0)^T (1, 1) = 3\)。由于这是正的，\(v\)
    不是下降方向。
- en: 'Answer and justification for E3.3.11: The Hessian matrix of \(f\) is'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.11的答案和证明：\(f\) 的Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(x_1, x_2) = \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix}.
    \end{split}\]
- en: Therefore, the second directional derivative of \(f\) at \((0, 0)\) in the direction
    \(v = (1, 0)\) is \(\mathbf{v}^T \mathbf{H}_f(0, 0) \mathbf{v} = (1, 0) \begin{bmatrix}
    -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = -2\).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\) 在 \((0, 0)\) 处沿 \(v = (1, 0)\) 方向的二阶方向导数是 \(\mathbf{v}^T \mathbf{H}_f(0,
    0) \mathbf{v} = (1, 0) \begin{bmatrix} -2 & 0 \\ 0 & -2 \end{bmatrix} \begin{pmatrix}
    1 \\ 0 \end{pmatrix} = -2\).
- en: 'Answer and justification for E3.3.13: The Hessian matrix is'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: E3.3.13的答案和证明：Hessian矩阵是
- en: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{H}_f(1,1) = \begin{pmatrix} 6 & -3 \\ -3 & 6 \end{pmatrix}.
    \end{split}\]
- en: 'Justification: Compute the second partial derivatives:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 证明：计算二阶偏导数：
- en: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{\partial^2 f}{\partial x^2} = 6x, \quad \frac{\partial^2 f}{\partial
    y^2} = 6y, \quad \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2
    f}{\partial y \partial x} = -3. \]
- en: At \((1,1)\), these values are \(6\), \(6\), and \(-3\), respectively.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在 \((1,1)\) 处，这些值分别是 \(6\)，\(6\)，和 \(-3\)。
- en: 'Answer and justification for E3.4.1: The convex combination is:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.1的答案和证明：凸组合是：
- en: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, 3) + \alpha(4, 5) = 0.7(2, 3) + 0.3(4, 5) = (0.7 \cdot 2
    + 0.3 \cdot 4, 0.7 \cdot 3 + 0.3 \cdot 5) = (2.6, 3.6). \]
- en: 'Answer and justification for E3.4.3: \(S_1\) and \(S_2\) are halfspaces, which
    are convex sets. By the lemma in the text, the intersection of convex sets is
    also convex. Therefore, \(S_1 \cap S_2\) is a convex set.'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.3的答案和证明：\(S_1\) 和 \(S_2\) 是半空间，它们是凸集。根据文本中的引理，凸集的交集也是凸集。因此，\(S_1 \cap S_2\)
    是一个凸集。
- en: 'Answer and justification for E3.4.5: The function \(f\) is a quadratic function
    with \(P = 2\), \(q = 2\), and \(r = 1\). Since \(P > 0\), \(f\) is strictly convex.
    The unique global minimizer is found by setting the gradient to zero:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.5的答案和证明：函数 \(f\) 是一个二次函数，\(P = 2\)，\(q = 2\)，\(r = 1\)。由于 \(P > 0\)，\(f\)
    是严格凸函数。通过将梯度设为零找到唯一的全局最小值：
- en: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla f(x) = 2x + 2 = 0 \implies x^* = -1. \]
- en: 'Answer and justification for E3.4.7: The Hessian matrix of \(f\) is:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.7的答案和证明：\(f\) 的Hessian矩阵是：
- en: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \nabla^2 f(x, y) = \begin{pmatrix} 2 & 0 \\ 0 & 4 \end{pmatrix}.
    \end{split}\]
- en: 'For any \((x, y) \in \mathbb{R}^2\), we have:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任意的 \((x, y) \in \mathbb{R}^2\)，我们有：
- en: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \nabla^2 f(x, y) \succeq 2I_{2 \times 2}, \]
- en: so \(f\) is strongly convex with \(m = 2\).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(f\) 是具有 \(m = 2\) 的强凸函数。
- en: 'Answer and justification for E3.4.9: \(f\) is not convex. We have \(f''''(x)
    = 12x^2 - 4\), which is negative for \(x \in (-\frac{1}{\sqrt{3}}, \frac{1}{\sqrt{3}})\).
    Since the second derivative is not always nonnegative, \(f\) is not convex.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.9的答案和证明：\(f\) 不是凸函数。我们有 \(f''(x) = 12x^2 - 4\)，对于 \(x \in (-\frac{1}{\sqrt{3}},
    \frac{1}{\sqrt{3}})\) 是负的。由于二阶导数不总是非负的，\(f\) 不是凸函数。
- en: 'Answer and justification for E3.4.11: \(f\) is strongly convex. We have \(f''''(x)
    = 2 > 0\), so \(f\) is 2-strongly convex.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.11的答案和证明：\(f\) 是强凸函数。我们有 \(f''(x) = 2 > 0\)，所以 \(f\) 是2-强凸函数。
- en: 'Answer and justification for E3.4.13: \(D\) is convex. To show this, let \((x_1,
    y_1), (x_2, y_2) \in D\) and \(\alpha \in (0, 1)\). We need to show that \((1
    - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\). Compute:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.13的答案和解释：\(D\) 是凸的。为了证明这一点，设 \((x_1, y_1), (x_2, y_2) \in D\) 且 \(\alpha
    \in (0, 1)\)。我们需要证明 \((1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) \in D\)。计算：
- en: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(x_1, y_1) + \alpha(x_2, y_2) = ((1 - \alpha)x_1 + \alpha x_2,
    (1 - \alpha)y_1 + \alpha y_2). \]
- en: Now,
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: \[ ((1 - \alpha)x_1 + \alpha x_2)^2 + ((1 - \alpha)y_1 + \alpha y_2)^2 < (1
    - \alpha)(x_1^2 + y_1^2) + \alpha(x_2^2 + y_2^2) < 4. \]
- en: Hence, \(D\) is convex.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，\(D\) 是凸的。
- en: 'Answer and justification for E3.4.15: \(D\) is not convex. For example, let
    \((x_1, y_1) = (2, \sqrt{3})\) and \((x_2, y_2) = (2, -\sqrt{3})\), both of which
    are in \(D\). For \(\alpha = \frac{1}{2}\),'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: E3.4.15的答案和解释：\(D\) 不是凸的。例如，设 \((x_1, y_1) = (2, \sqrt{3})\) 和 \((x_2, y_2)
    = (2, -\sqrt{3})\)，它们都在 \(D\) 中。对于 \(\alpha = \frac{1}{2}\)，
- en: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (1 - \alpha)(2, \sqrt{3}) + \alpha(2, -\sqrt{3}) = \left(2, 0\right). \]
- en: Now,
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，
- en: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \left(2\right)^2 - \left(0\right)^2 = 4 > 1. \]
- en: 'Answer and justification for E3.5.1: The gradient is \(\nabla f(x, y) = (2x,
    8y)\). At \((1, 1)\), it is \((2, 8)\). The direction of steepest descent is \(-\nabla
    f(1, 1) = (-2, -8)\).'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.1的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 8y)\)。在 \((1, 1)\) 处，它是 \((2, 8)\)。最速下降的方向是
    \(-\nabla f(1, 1) = (-2, -8)\)。
- en: 'Answer and justification for E3.5.3: \(\nabla f(x) = 3x^2 - 12x + 9\). At \(x_0
    = 0\), \(\nabla f(0) = 9\). The first iteration gives \(x_1 = x_0 - \alpha \nabla
    f(x_0) = 0 - 0.1 \cdot 9 = -0.9\). At \(x_1 = -0.9\), \(\nabla f(-0.9) = 3 \cdot
    (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43 + 10.8 + 9 = 22.23\). The second iteration
    gives \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot 22.23 = -3.123\).'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.3的答案和解释：\(\nabla f(x) = 3x^2 - 12x + 9\)。在 \(x_0 = 0\) 时，\(\nabla f(0)
    = 9\)。第一次迭代给出 \(x_1 = x_0 - \alpha \nabla f(x_0) = 0 - 0.1 \cdot 9 = -0.9\)。在
    \(x_1 = -0.9\) 时，\(\nabla f(-0.9) = 3 \cdot (-0.9)^2 - 12 \cdot (-0.9) + 9 = 2.43
    + 10.8 + 9 = 22.23\)。第二次迭代给出 \(x_2 = x_1 - \alpha \nabla f(x_1) = -0.9 - 0.1 \cdot
    22.23 = -3.123\)。
- en: 'Answer and justification for E3.5.5: We have \(\nabla f(x) = 2x\), so \(\nabla
    f(2) = 4\). Thus, the gradient descent update is \(x_1 = x_0 - \alpha \nabla f(x_0)
    = 2 - 0.1 \cdot 4 = 1.6\).'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.5的答案和解释：我们有 \(\nabla f(x) = 2x\)，所以 \(\nabla f(2) = 4\)。因此，梯度下降更新为 \(x_1
    = x_0 - \alpha \nabla f(x_0) = 2 - 0.1 \cdot 4 = 1.6\)。
- en: 'Answer and justification for E3.5.7: \(f''''(x) = 4\) for all \(x \in \mathbb{R}\).
    Therefore, \(f''''(x) \geq 4\) for all \(x \in \mathbb{R}\), which implies that
    \(f\) is \(4\)-strongly convex.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.7的答案和解释：对于所有 \(x \in \mathbb{R}\)，\(f''(x) = 4\)。因此，对于所有 \(x \in \mathbb{R}\)，\(f''(x)
    \geq 4\)，这意味着 \(f\) 是 \(4\)-强凸的。
- en: 'Answer and justification for E3.5.9: No. We have \(f''''(x) = 12x^2\), which
    can be arbitrarily large as \(x\) increases. Thus, there is no constant \(L\)
    such that \(-L \le f''''(x) \le L\) for all \(x \in \mathbb{R}\).'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.9的答案和解释：不是。我们有 \(f''(x) = 12x^2\)，随着 \(x\) 的增加，它可以任意大。因此，不存在常数 \(L\)，使得对于所有
    \(x \in \mathbb{R}\)，\(-L \le f''(x) \le L\)。
- en: 'Answer and justification for E3.5.11: We have \(f''''(x) = 2\) for all \(x
    \in \mathbb{R}\). Thus, we can take \(m = 2\), and we have \(f''''(x) \ge 2\)
    for all \(x \in \mathbb{R}\), which is the condition for \(m\)-strong convexity.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.11的答案和解释：对于所有 \(x \in \mathbb{R}\)，我们有 \(f''(x) = 2\)。因此，我们可以取 \(m = 2\)，并且对于所有
    \(x \in \mathbb{R}\)，\(f''(x) \ge 2\)，这是 \(m\)-强凸性的条件。
- en: 'Answer and justification for E3.5.13: The gradient is \(\nabla f(x, y) = (2x,
    2y)\). At \((1, 1)\), it is \((2, 2)\). The first update is \((0.8, 0.8)\). The
    gradient at \((0.8, 0.8)\) is \((1.6, 1.6)\). The second update is \((0.64, 0.64)\).'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: E3.5.13的答案和解释：梯度是 \(\nabla f(x, y) = (2x, 2y)\)。在 \((1, 1)\) 处，它是 \((2, 2)\)。第一次更新是
    \((0.8, 0.8)\)。在 \((0.8, 0.8)\) 处的梯度是 \((1.6, 1.6)\)。第二次更新是 \((0.64, 0.64)\)。
- en: 'Answer and justification for E3.6.1: The log-odds is given by \(\log \frac{p}{1-p}
    = \log \frac{0.25}{0.75} = \log \frac{1}{3} = -\log 3\).'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.1的答案和解释：对数似然由 \(\log \frac{p}{1-p} = \log \frac{0.25}{0.75} = \log \frac{1}{3}
    = -\log 3\) 给出。
- en: 'Answer and justification for E3.6.3:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.3的答案和解释：
- en: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \boldsymbol{\alpha}^T \mathbf{x} = (-0.2 \cdot 1) + (0.4 \cdot 3) = -0.2
    + 1.2 = 1.0 \]\[ p(\mathbf{x}; \boldsymbol{\alpha}) = \sigma(1.0) = \frac{1}{1
    + e^{-1}} \approx 0.731 \]
- en: 'Answer and justification for E3.6.5: By the quotient rule,'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: E3.6.5的答案和解释：根据商规则，
- en: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \sigma'(z) &= \frac{e^{-z}}{(1 + e^{-z})^2} = \frac{1}{1 +
    e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}} \\ &= \sigma(z) (1 - \sigma(z)). \end{align*}\]
- en: 'Answer and justification for E3.6.7: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}) \approx 0.05\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x})
    \approx -0.73\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}) \approx 0.73\).
    Therefore,'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 回答并证明E3.6.7：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}) \approx 0.05\)，\(b_2
    - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}) \approx -0.73\)，\(b_3 - \sigma(\boldsymbol{\alpha}_3^T
    \mathbf{x}) \approx 0.73\)。因此，
- en: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \nabla \ell(\mathbf{x}; A, b) &= -\frac{1}{3} \sum_{i=1}^3
    (b_i - \sigma(\boldsymbol{\alpha}_i^T \mathbf{x})) \boldsymbol{\alpha}_i \\ &\approx
    -\frac{1}{3} \{(0.05)(1, 2) + (-0.73)(-1, 1) + 0.73(0, -1)\}. \end{align*}\]
- en: 'Answer and justification for E3.6.9: We have \(b_1 - \sigma(\boldsymbol{\alpha}_1^T
    \mathbf{x}^0) = 1 - \sigma(0) = 0.5\), \(b_2 - \sigma(\boldsymbol{\alpha}_2^T
    \mathbf{x}^0) = -0.5\), \(b_3 - \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) =
    0.5\). Therefore,'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 回答并证明E3.6.9：我们有 \(b_1 - \sigma(\boldsymbol{\alpha}_1^T \mathbf{x}^0) = 1 - \sigma(0)
    = 0.5\)，\(b_2 - \sigma(\boldsymbol{\alpha}_2^T \mathbf{x}^0) = -0.5\)，\(b_3 -
    \sigma(\boldsymbol{\alpha}_3^T \mathbf{x}^0) = 0.5\)。因此，
- en: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathbf{x}^1 &= \mathbf{x}^0 - \beta \nabla \ell(\mathbf{x}^0;
    A, \mathbf{b}) \\ &= (0, 0) + \frac{0.1}{3} \{0.5(1, 2) + (-0.5)(-1, 1) + 0.5(0,
    -1)\} \\ &= (0.1, 0.05). \end{align*}\]
- en: 3.8.1.5\. Learning outcomes[#](#learning-outcomes "Link to this heading")
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.1.5\. 学习成果[#](#learning-outcomes "链接到这个标题")
- en: Define and calculate partial derivatives and gradients for functions of several
    variables.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义并计算多个变量函数的偏导数和梯度。
- en: Compute second-order partial derivatives and construct the Hessian matrix for
    twice continuously differentiable functions.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算二阶偏导数，并构建两次连续可微函数的Hessian矩阵。
- en: Apply the Chain Rule to compute derivatives of composite functions of several
    variables.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用链式法则计算多个变量复合函数的导数。
- en: State and prove the multivariable version of the Mean Value Theorem using the
    Chain Rule.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用链式法则陈述并证明多元版本的平均值定理。
- en: Calculate gradients and Hessians for affine and quadratic functions of several
    variables.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算多个变量的仿射函数和二次函数的梯度及Hessian矩阵。
- en: Define global and local minimizers for unconstrained optimization problems.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义无约束优化问题的全局和局部最小值。
- en: Derive the first-order necessary conditions for a local minimizer using the
    gradient.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用梯度推导局部最小值的一阶必要条件。
- en: Explain the concept of a descent direction and its relation to the gradient.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释下降方向的概念及其与梯度的关系。
- en: Explain the concept of directional derivatives and compute directional derivatives
    using the gradient.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释方向导数的概念，并使用梯度计算方向导数。
- en: State the second-order necessary and sufficient conditions for a local minimizer
    using the Hessian matrix.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵陈述局部最小值的二阶必要和充分条件。
- en: Compute the gradient and Hessian matrix for a given multivariable function.
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定多变量函数的梯度和Hessian矩阵。
- en: Formulate optimization problems with equality constraints.
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表达具有等式约束的优化问题。
- en: Apply the method of Lagrange multipliers to derive the first-order necessary
    conditions for a constrained local minimizer.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用拉格朗日乘数法推导约束局部最小值的一阶必要条件。
- en: Verify the second-order sufficient conditions for a constrained local minimizer
    using the Hessian matrix and Lagrange multipliers.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hessian矩阵和拉格朗日乘数验证约束局部最小值的二阶充分条件。
- en: Analyze the regularity condition in the context of constrained optimization
    problems.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在约束优化问题的背景下分析正则性条件。
- en: Solve a constrained optimization problem by finding points that satisfy the
    first-order necessary conditions and checking the second-order sufficient conditions.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过找到满足一阶必要条件并检查二阶充分条件的点来解决约束优化问题。
- en: Define convex sets and convex functions, and provide examples of each.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义凸集和凸函数，并给出每个的例子。
- en: Identify operations that preserve convexity of sets and functions.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别保持集合和函数凸性的操作。
- en: Characterize convex functions using the first-order convexity condition based
    on the gradient.
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于梯度的一阶凸性条件来描述凸函数。
- en: Determine the convexity of a function using the second-order convexity condition
    based on the Hessian matrix.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于Hessian矩阵的二次凸性条件确定函数的凸性。
- en: Explain the relationship between convexity and optimization, particularly how
    local minimizers of convex functions are also global minimizers.
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释凸性与优化之间的关系，特别是凸函数的局部最小值也是全局最小值。
- en: State and prove the first-order optimality condition for convex functions on
    R^d and on convex sets.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 R^d 和凸集上对凸函数陈述并证明一阶最优性条件。
- en: Define strong convexity and its implications for the existence and uniqueness
    of global minimizers.
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义强凸性及其对全局最小值存在性和唯一性的影响。
- en: Analyze the convexity and strong convexity of quadratic functions and least-squares
    objectives.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析二次函数和最小二乘目标函数的凸性和强凸性。
- en: Apply the concept of convexity to solve optimization problems, such as finding
    the projection of a point onto a convex set.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将凸性的概念应用于解决优化问题，例如找到点在凸集上的投影。
- en: Define gradient descent and explain its motivation as a numerical optimization
    method.
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义梯度下降并解释其作为数值优化方法的动机。
- en: Prove that the negative gradient is the steepest descent direction for a continuously
    differentiable function.
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明负梯度是连续可微函数的最速下降方向。
- en: Analyze the convergence of gradient descent for smooth functions, proving that
    it produces a sequence of points with decreasing objective values and vanishing
    gradients.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析光滑函数梯度下降的收敛性，证明它产生了一系列具有递减目标值和消失梯度的点。
- en: Derive the convergence rate of gradient descent for smooth functions in terms
    of the number of iterations.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以迭代次数为依据推导光滑函数梯度下降的收敛率。
- en: Define strong convexity for twice continuously differentiable functions and
    relate it to the function value and gradient.
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为两次连续可微函数定义强凸性并将其与函数值和梯度联系起来。
- en: Prove faster convergence rates for gradient descent when applied to smooth and
    strongly convex functions, showing exponential convergence to the global minimum.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明当应用于光滑和强凸函数时，梯度下降具有更快的收敛率，并显示出指数收敛到全局最小值。
- en: Implement gradient descent in Python and apply it to simple examples to illustrate
    the theoretical convergence results.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中实现梯度下降并将其应用于简单示例以说明理论收敛结果。
- en: Explain the role of the sigmoid function in transforming a linear function of
    features into a probability.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释sigmoid函数在将特征线性函数转换为概率中的作用。
- en: Derive the gradient and Hessian of the logistic regression objective function
    (cross-entropy loss).
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推导逻辑回归目标函数（交叉熵损失）的梯度和Hessian。
- en: Prove that the logistic regression objective function is convex and smooth.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明逻辑回归目标函数是凸的和光滑的。
- en: Implement gradient descent to minimize the logistic regression objective function
    in Python.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中实现梯度下降以最小化逻辑回归目标函数。
- en: Apply logistic regression to real-world datasets.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将逻辑回归应用于实际数据集。
- en: \(\aleph\)
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: \(\aleph\)
- en: 3.8.2\. Additional sections[#](#additional-sections "Link to this heading")
  id: totrans-480
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.8.2\. 其他部分[#](#additional-sections "链接到这个标题")
- en: '3.8.2.1\. Logistic regression: illustration of convergence result[#](#logistic-regression-illustration-of-convergence-result
    "Link to this heading")'
  id: totrans-481
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.1\. 逻辑回归：收敛结果的说明[#](#logistic-regression-illustration-of-convergence-result
    "链接到这个标题")
- en: We return to our proof of convergence for smooth functions using a special case
    of logistic regression. We first define the functions \(\hat{f}\), \(\mathcal{L}\)
    and \(\frac{\partial}{\partial x}\mathcal{L}\).
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到使用逻辑回归的特殊情况来证明光滑函数收敛性的证明。我们首先定义函数 \(\hat{f}\)，\(\mathcal{L}\) 和 \(\frac{\partial}{\partial
    x}\mathcal{L}\)。
- en: '[PRE14]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We illustrate GD on a random dataset.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在随机数据集上说明GD。
- en: '[PRE15]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We plot the upper and lower bounds in the *Quadratic Bound for Smooth Functions*
    around \(x = x_0\). It turns out we can take \(L=1\) because all features are
    uniformly random between \(-1\) and \(1\). Observe that minimizing the upper quadratic
    bound leads to a decrease in \(\mathcal{L}\).
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 \(x = x_0\) 附近的 *光滑函数的二次界限* 中绘制上界和下界。结果是我们可以将 \(L=1\)，因为所有特征在 \(-1\) 和 \(1\)
    之间均匀随机。观察最小化上界二次界限会导致 \(\mathcal{L}\) 的减少。
- en: '[PRE16]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
  id: totrans-488
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
- en: '3.8.2.2\. Logistic regression: another dataset[#](#logistic-regression-another-dataset
    "Link to this heading")'
  id: totrans-489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.2\. 逻辑回归：另一个数据集[#](#logistic-regression-another-dataset "链接到这个标题")
- en: Recall that to run gradient descent, we first implement a function computing
    a descent update. It takes as input a function `grad_fn` computing the gradient
    itself, as well as a current iterate and a step size. We now also feed a dataset
    as additional input.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，为了运行梯度下降，我们首先实现一个计算下降更新的函数。该函数接受一个计算梯度的函数 `grad_fn`、一个当前迭代和一个步长作为输入。我们现在还提供一个数据集作为额外的输入。
- en: '[PRE17]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We analyze with a simple dataset from UC Berkeley’s [DS100](http://www.ds100.org)
    course. The file `lebron.csv` is available [here](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets).
    Quoting a previous version of the course’s textbook:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用加州大学伯克利分校 [DS100](http://www.ds100.org) 课程的一个简单数据集进行分析。文件 `lebron.csv` 可在此处获取
    [here](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets)。引用课程教材的先前版本：
- en: In basketball, players score by shooting a ball through a hoop. One such player,
    LeBron James, is widely considered one of the best basketball players ever for
    his incredible ability to score. LeBron plays in the National Basketball Association
    (NBA), the United States’s premier basketball league. We’ve collected a dataset
    of all of LeBron’s attempts in the 2017 NBA Playoff Games using the NBA statistics
    website ([https://stats.nba.com/](https://stats.nba.com/)).
  id: totrans-493
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在篮球比赛中，球员通过将球投进篮筐来得分。其中一位球员，勒布朗·詹姆斯，因其惊人的得分能力而被广泛认为是史上最优秀的篮球运动员之一。勒布朗效力于美国最顶级的篮球联赛——美国职业篮球联赛（NBA）。我们使用NBA统计网站（[https://stats.nba.com/](https://stats.nba.com/)）收集了2017年NBA季后赛中勒布朗所有尝试的数据集。
- en: We first load the data and look at its summary.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载数据并查看其摘要。
- en: '[PRE18]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 20170415 | 10 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 0 |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 20170415 | 10 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 0 |'
- en: '| 1 | 20170415 | 11 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 20170415 | 11 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
- en: '| 2 | 20170415 | 14 | IND | Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 20170415 | 14 | IND | Layup Shot | 2PT Field Goal | 0 | 1 |'
- en: '| 3 | 20170415 | 15 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 20170415 | 15 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
- en: '| 4 | 20170415 | 18 | IND | Alley Oop Dunk Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 20170415 | 18 | IND | Alley Oop Dunk Shot | 2PT Field Goal | 0 | 1 |'
- en: '[PRE19]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '|  | game_date | minute | shot_distance | shot_made |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | shot_distance | shot_made |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
- en: '| mean | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
- en: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
- en: '| min | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| 最小值 | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
- en: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
- en: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
- en: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
- en: '| max | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
- en: The two columns we will be interested in are `shot_distance` (LeBron’s distance
    from the basket when the shot was attempted (ft)) and `shot_made` (0 if the shot
    missed, 1 if the shot went in). As the summary table above indicates, the average
    distance was `10.6953` and the frequency of shots made was `0.565104`. We extract
    those two columns and display them on a scatter plot.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注的两个列是 `shot_distance`（勒布朗在投篮时距离篮筐的距离（英尺））和 `shot_made`（如果投篮未命中则为0，如果投篮命中则为1）。如上表所示，平均距离为
    `10.6953`，投篮命中的频率为 `0.565104`。我们提取这两个列，并在散点图上显示。
- en: '[PRE20]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
- en: As you can see, this kind of data is hard to vizualize because of the superposition
    of points with the same \(x\) and \(y\)-values. One trick is to jiggle the \(y\)’s
    a little bit by adding Gaussian noise. We do this next and plot again.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种数据难以可视化，因为具有相同 \(x\) 和 \(y\) 值的点重叠在一起。一个技巧是通过添加高斯噪声稍微抖动 \(y\) 值。我们接下来这样做，并再次绘图。
- en: '[PRE21]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
- en: We apply GD to logistic regression. We first construct the data matrices \(A\)
    and \(\mathbf{b}\). To allow an affine function of the features, we add a column
    of \(1\)’s as we have done before.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将GD应用于逻辑回归。我们首先构建数据矩阵 \(A\) 和 \(\mathbf{b}\)。为了允许特征是仿射函数，我们添加了一个 \(1\) 的列，就像我们之前做的那样。
- en: '[PRE22]'
  id: totrans-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We run GD starting from \((0,0)\) with a step size computed from the smoothness
    of the objective as above.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 \((0,0)\) 开始运行GD，步长由上述目标函数的平滑度计算得出。
- en: '[PRE23]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Finally we plot the results.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们绘制结果图。
- en: '[PRE27]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
- en: '3.8.2.1\. Logistic regression: illustration of convergence result[#](#logistic-regression-illustration-of-convergence-result
    "Link to this heading")'
  id: totrans-530
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.1\. 逻辑回归：收敛结果的说明[#](#logistic-regression-illustration-of-convergence-result
    "链接到这个标题")
- en: We return to our proof of convergence for smooth functions using a special case
    of logistic regression. We first define the functions \(\hat{f}\), \(\mathcal{L}\)
    and \(\frac{\partial}{\partial x}\mathcal{L}\).
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到使用逻辑回归的特殊情况来证明平滑函数收敛性的证明。我们首先定义函数 \(\hat{f}\)，\(\mathcal{L}\) 和 \(\frac{\partial}{\partial
    x}\mathcal{L}\)。
- en: '[PRE28]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We illustrate GD on a random dataset.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在一个随机数据集上说明GD。
- en: '[PRE29]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We plot the upper and lower bounds in the *Quadratic Bound for Smooth Functions*
    around \(x = x_0\). It turns out we can take \(L=1\) because all features are
    uniformly random between \(-1\) and \(1\). Observe that minimizing the upper quadratic
    bound leads to a decrease in \(\mathcal{L}\).
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 \(x = x_0\) 附近的平滑函数的**二次边界**中绘制上下界。结果是我们可以将 \(L=1\)，因为所有特征都在 \(-1\) 和 \(1\)
    之间均匀随机。观察发现，最小化上二次边界会导致 \(\mathcal{L}\) 减小。
- en: '[PRE30]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
  id: totrans-537
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/324fe7586bd9a9025def6d4dad22a04d4771badbb9de6c87d2f507e57fba625f.png](../Images/097a341c91c4cf50443a8e9f81f433b8.png)'
- en: '3.8.2.2\. Logistic regression: another dataset[#](#logistic-regression-another-dataset
    "Link to this heading")'
  id: totrans-538
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8.2.2\. 逻辑回归：另一个数据集[#](#logistic-regression-another-dataset "链接到这个标题")
- en: Recall that to run gradient descent, we first implement a function computing
    a descent update. It takes as input a function `grad_fn` computing the gradient
    itself, as well as a current iterate and a step size. We now also feed a dataset
    as additional input.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，为了运行梯度下降，我们首先实现一个计算下降更新的函数。它接受一个计算梯度的函数 `grad_fn` 作为输入，以及当前迭代和步长。我们现在还提供一个数据集作为额外的输入。
- en: '[PRE31]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We analyze with a simple dataset from UC Berkeley’s [DS100](http://www.ds100.org)
    course. The file `lebron.csv` is available [here](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets).
    Quoting a previous version of the course’s textbook:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用加州大学伯克利分校[DS100](http://www.ds100.org)课程的一个简单数据集进行分析。文件 `lebron.csv` 可在[此处](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets)找到。引用课程教材的先前版本：
- en: In basketball, players score by shooting a ball through a hoop. One such player,
    LeBron James, is widely considered one of the best basketball players ever for
    his incredible ability to score. LeBron plays in the National Basketball Association
    (NBA), the United States’s premier basketball league. We’ve collected a dataset
    of all of LeBron’s attempts in the 2017 NBA Playoff Games using the NBA statistics
    website ([https://stats.nba.com/](https://stats.nba.com/)).
  id: totrans-542
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在篮球中，球员通过将球投进篮筐来得分。这样的球员，勒布朗·詹姆斯，因其惊人的得分能力而被广泛认为是史上最伟大的篮球运动员之一。勒布朗在美国最顶级的篮球联赛——NBA中打球。我们收集了2017年NBA季后赛中勒布朗所有尝试的数据集，数据来源于NBA统计网站([https://stats.nba.com/](https://stats.nba.com/))。
- en: We first load the data and look at its summary.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载数据并查看其摘要。
- en: '[PRE32]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | opponent | action_type | shot_type | shot_distance
    | shot_made |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 20170415 | 10 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 0 |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 20170415 | 10 | IND | 驱动上篮 | 2分投篮 | 0 | 0 |'
- en: '| 1 | 20170415 | 11 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 20170415 | 11 | IND | 驱动上篮 | 2分投篮 | 0 | 1 |'
- en: '| 2 | 20170415 | 14 | IND | Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 20170415 | 14 | IND | 上篮 | 2分投篮 | 0 | 1 |'
- en: '| 3 | 20170415 | 15 | IND | Driving Layup Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 20170415 | 15 | IND | 驱动上篮 | 2分投篮 | 0 | 1 |'
- en: '| 4 | 20170415 | 18 | IND | Alley Oop Dunk Shot | 2PT Field Goal | 0 | 1 |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 20170415 | 18 | IND | 转身扣篮 | 2分投篮 | 0 | 1 |'
- en: '[PRE33]'
  id: totrans-552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '|  | game_date | minute | shot_distance | shot_made |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '|  | game_date | minute | shot_distance | shot_made |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| count | 3.840000e+02 | 384.00000 | 384.000000 | 384.000000 |'
- en: '| mean | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| mean | 2.017052e+07 | 24.40625 | 10.695312 | 0.565104 |'
- en: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| std | 6.948501e+01 | 13.67304 | 10.547586 | 0.496390 |'
- en: '| min | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| min | 2.017042e+07 | 1.00000 | 0.000000 | 0.000000 |'
- en: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| 25% | 2.017050e+07 | 13.00000 | 1.000000 | 0.000000 |'
- en: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 2.017052e+07 | 25.00000 | 6.500000 | 1.000000 |'
- en: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| 75% | 2.017060e+07 | 35.00000 | 23.000000 | 1.000000 |'
- en: '| max | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| max | 2.017061e+07 | 48.00000 | 31.000000 | 1.000000 |'
- en: The two columns we will be interested in are `shot_distance` (LeBron’s distance
    from the basket when the shot was attempted (ft)) and `shot_made` (0 if the shot
    missed, 1 if the shot went in). As the summary table above indicates, the average
    distance was `10.6953` and the frequency of shots made was `0.565104`. We extract
    those two columns and display them on a scatter plot.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关注的两列是 `shot_distance`（投篮时勒布朗距离篮筐的距离（英尺））和 `shot_made`（如果投篮未中则为 0，如果投篮命中则为
    1）。如上表所示，平均距离为 `10.6953`，投篮命中的频率为 `0.565104`。我们提取这两列，并在散点图上显示。
- en: '[PRE34]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
  id: totrans-565
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/ccf5a77835e56e6a43556d4f958a46f41dcda89b707e8c6937654150eafed13d.png](../Images/3d7f7643b1fbf4e975e00b74d1d83929.png)'
- en: As you can see, this kind of data is hard to vizualize because of the superposition
    of points with the same \(x\) and \(y\)-values. One trick is to jiggle the \(y\)’s
    a little bit by adding Gaussian noise. We do this next and plot again.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种数据难以可视化，因为具有相同 \(x\) 和 \(y\) 值的点重叠在一起。一个技巧是通过添加高斯噪声稍微调整 \(y\) 值。我们接下来这样做，然后再次绘图。
- en: '[PRE35]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
  id: totrans-568
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/0108a98a440f644ac9feb81bb3700cbea2ffcdf8fa56a7d2f355b1d652ae7cff.png](../Images/8ed222a6929c72dd22f117b3334ede4e.png)'
- en: We apply GD to logistic regression. We first construct the data matrices \(A\)
    and \(\mathbf{b}\). To allow an affine function of the features, we add a column
    of \(1\)’s as we have done before.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 GD 应用到逻辑回归中。我们首先构建数据矩阵 \(A\) 和 \(\mathbf{b}\)。为了允许特征是仿射函数，我们添加了一个 \(1\)
    的列，就像之前做的那样。
- en: '[PRE36]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We run GD starting from \((0,0)\) with a step size computed from the smoothness
    of the objective as above.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 \((0,0)\) 开始运行 GD，步长由上述目标函数的平滑度计算得出。
- en: '[PRE37]'
  id: totrans-572
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-573
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-574
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Finally we plot the results.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制结果。
- en: '[PRE41]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
  id: totrans-578
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/e630ab57029ca45289fcf7e97e68879d9893d32390e62c3bf04d6b2295b8c0b2.png](../Images/b5fe636fb5ab3cb9e6e07cac190911dd.png)'
