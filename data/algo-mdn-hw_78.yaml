- en: Binary Search
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二分查找
- en: 原文：[https://en.algorithmica.org/hpc/data-structures/binary-search/](https://en.algorithmica.org/hpc/data-structures/binary-search/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/data-structures/binary-search/](https://en.algorithmica.org/hpc/data-structures/binary-search/)
- en: While improving the speed of user-facing applications is the end goal of performance
    engineering, people don’t really get excited over 5-10% improvements in some databases.
    Yes, this is what software engineers are paid for, but these types of optimizations
    tend to be too intricate and system-specific to be readily generalized to other
    software.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然提高面向用户的程序的速度是性能工程的目标，但人们对某些数据库中5-10%的性能提升并不感到兴奋。是的，这就是软件工程师的报酬，但这些类型的优化往往过于复杂和特定于系统，无法轻易推广到其他软件。
- en: 'Instead, the most fascinating showcases of performance engineering are multifold
    optimizations of textbook algorithms: the kinds that everybody knows and deemed
    so simple that it would never even occur to try to optimize them in the first
    place. These optimizations are simple and instructive and can very much be adopted
    elsewhere. And they are surprisingly not as rare as you’d think.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，性能工程中最迷人的展示是对教科书算法的多重优化：这类算法每个人都熟知，被认为如此简单，以至于根本不会想到去优化它们。这些优化简单且具有教育意义，可以在其他地方广泛应用。而且，它们并不像你想象的那样罕见。
- en: In this section, we focus on one such fundamental algorithm — *binary search*
    — and implement two of its variants that are, depending on the problem size, up
    to 4x faster than `std::lower_bound`, while being under just 15 lines of code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们关注这样一个基本算法——*二分查找*——并实现了其两种变体，这些变体在问题规模不同的情况下，比`std::lower_bound`快达4倍，同时代码行数仅为15行。
- en: The first algorithm achieves that by removing [branches](/hpc/pipelining/branching),
    and the second also optimizes the memory layout to achieve better [cache system](/hpc/cpu-cache)
    performance. This technically disqualifies it from being a drop-in replacement
    for `std::lower_bound` as it needs to permute the elements of the array before
    it can start answering queries — but I can’t recall a lot of scenarios where you
    obtain a sorted array but can’t afford to spend linear time on preprocessing.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个算法通过移除[分支](/hpc/pipelining/branching)来实现这一点，第二个算法还优化了内存布局以实现更好的[缓存系统](/hpc/cpu-cache)性能。从技术上讲，这使其不能作为`std::lower_bound`的直接替代品，因为它需要在开始回答查询之前对数组元素进行排列——但我无法回忆起很多你获得了排序数组但无法承担线性时间预处理成本的场景。
- en: 'The usual disclaimer: the CPU is a [Zen 2](https://www.7-cpu.com/cpu/Zen2.html),
    the RAM is a [DDR4-2666](/hpc/cpu-cache/), and the compiler we will be using by
    default is Clang 10\. The performance on your machine may be different, so I highly
    encourage to [go and test it](https://godbolt.org/z/14rd5Pnve) for yourself.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 常规免责声明：CPU是[Zen 2](https://www.7-cpu.com/cpu/Zen2.html)，RAM是[DDR4-2666](/hpc/cpu-cache/)，我们将默认使用Clang
    10编译器。你的机器上的性能可能会有所不同，所以我强烈建议你自己去[测试它](https://godbolt.org/z/14rd5Pnve)。
- en: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#binary-search)Binary
    Search'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#binary-search)二分查找'
- en: 'Here is the standard way of searching for the first element not less than `x`
    in a sorted array `t` of `n` integers that you can find in any introductory computer
    science textbook:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是任何计算机科学入门教科书中都可以找到的搜索排序数组`t`中第一个不小于`x`的元素的常规方法：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Find the middle element of the search range, compare it to `x`, shrink the range
    in half. Beautiful in its simplicity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 找到搜索范围的中点元素，将其与`x`比较，将范围缩小一半。其简单性令人赞叹。
- en: 'A similar approach is employed by `std::lower_bound`, except that it needs
    to be more generic to support containers with non-random-access iterators and
    thus uses the first element and the size of the search interval instead of the
    two of its ends. To this end, implementations from both [Clang](https://github.com/llvm-mirror/libcxx/blob/78d6a7767ed57b50122a161b91f59f19c9bd0d19/include/algorithm#L4169)
    and [GCC](https://github.com/gcc-mirror/gcc/blob/d9375e490072d1aae73a93949aa158fcd2a27018/libstdc%2B%2B-v3/include/bits/stl_algobase.h#L1023)
    use this metaprogramming monstrosity:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`std::lower_bound`采用类似的方法，但它需要更通用以支持具有非随机访问迭代器的容器，因此它使用搜索区间的第一个元素和大小，而不是其两个端点。为此，来自[Clang](https://github.com/llvm-mirror/libcxx/blob/78d6a7767ed57b50122a161b91f59f19c9bd0d19/include/algorithm#L4169)和[GCC](https://github.com/gcc-mirror/gcc/blob/d9375e490072d1aae73a93949aa158fcd2a27018/libstdc%2B%2B-v3/include/bits/stl_algobase.h#L1023)的实现都使用了这种元编程怪物：'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If the compiler is successful in removing the abstractions, it compiles to
    roughly the same machine code and yields roughly the same average latency, which
    [expectedly](/hpc/cpu-cache/latency) grows with the array size:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果编译器成功移除了抽象，它编译出的机器代码大致相同，并且平均延迟也大致相同，这[预期](/hpc/cpu-cache/latency)随着数组大小的增加而增长：
- en: '![](../Images/0d8b6b224cf1d3bc705727ef6612ae2a.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d8b6b224cf1d3bc705727ef6612ae2a.png)'
- en: Since most people don’t implement binary search by hand, we will use `std::lower_bound`
    from Clang as the baseline.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数人不会手动实现二分查找，我们将使用Clang中的`std::lower_bound`作为基准。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#the-bottleneck)The
    Bottleneck'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#the-bottleneck)瓶颈'
- en: Before jumping to the optimized implementations, let’s briefly discuss why binary
    search is slow in the first place.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳到优化实现之前，让我们简要讨论一下为什么二分查找一开始就慢。
- en: 'If you run `std::lower_bound` with [perf](/hpc/profiling/events), you’ll see
    that it spends most of its time on a [conditional jump](/hpc/architecture/loops)
    instruction:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用[perf](/hpc/profiling/events)运行`std::lower_bound`，你会看到它的大部分时间都花在一条[条件跳转](/hpc/architecture/loops)指令上：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This [pipeline stall](/hpc/) stops the search from progressing, and it is mainly
    caused by two [factors](/hpc/pipelining/hazards):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种[pipeline stall](/hpc/)阻止了搜索的进行，它主要是由两个[因素](/hpc/pipelining/hazards)引起的：
- en: We suffer a *control hazard* because we have a [branch](/hpc/pipelining/branching)
    that is impossible to predict (queries and keys are drawn independently at random),
    and the processor has to halt for 10-15 cycles to flush the pipeline and fill
    it back on each branch mispredict.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们遭受了*控制冒险*，因为我们有一个无法预测的[分支](/hpc/pipelining/branching)（查询和键是独立随机抽取的），处理器必须暂停10-15个周期来清空流水线和在每个分支预测错误时重新填充。
- en: We suffer a *data hazard* because we have to wait for the preceding comparison
    to complete, which in turn waits for one of its operands to be fetched from the
    memory — and it [may take](/hpc/cpu-cache/latency) anywhere between 0 and 300
    cycles, depending on where it is located.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们遭受了*数据冒险*，因为我们必须等待前面的比较完成，而这反过来又等待其操作数之一从内存中取出——这[可能需要](/hpc/cpu-cache/latency)0到300个周期，具体取决于它的位置。
- en: Now, let’s try to get rid of these obstacles one by one.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐一尝试消除这些障碍。
- en: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#removing-branches)Removing
    Branches'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#removing-branches)移除分支'
- en: 'We can replace branching with [predication](/hpc/pipelining/branchless). To
    make the task easier, we can adopt the STL approach and rewrite the loop using
    the first element and the size of the search interval (instead of its first and
    last element):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用[predication](/hpc/pipelining/branchless)来替换分支。为了使任务更容易，我们可以采用STL方法，并使用搜索间隔的第一个元素和大小（而不是其第一个和最后一个元素）重写循环：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note that, on each iteration, `len` is essentially just halved and then either
    floored or ceiled, depending on how the comparison went. This conditional update
    seems unnecessary; to avoid it, we can simply say that it’s always ceiled:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在每次迭代中，`len`实际上只是减半，然后根据比较结果进行向下取整或向上取整。这种条件更新看起来是不必要的；为了避免它，我们可以说它总是向上取整：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This way, we only need to update the first element of the search interval with
    a [conditional move](/hpc/pipelining/branchless/) and halve its size on each iteration:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们只需要在每个迭代中更新搜索间隔的第一个元素，并使用[条件移动](/hpc/pipelining/branchless/)将其大小减半：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that this loop is not always equivalent to the standard binary search.
    Since it always rounds *up* the size of the search interval, it accesses slightly
    different elements and may perform one comparison more than needed. Apart from
    simplifying computations on each iteration, it also makes the number of iterations
    constant if the array size is constant, removing branch mispredictions completely.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个循环并不总是等同于标准的二分查找。因为它总是向上取整搜索间隔的大小，所以它访问了稍微不同的元素，并且可能比所需的比较多一次。除了简化每次迭代的计算外，它还使得在数组大小恒定时迭代次数保持不变，从而完全消除了分支预测错误。
- en: 'As typical for predication, this trick is very fragile to compiler optimizations
    — depending on the compiler and how the function is invoked, it may still leave
    a branch or generate suboptimal code. It works fine on Clang 10, yielding a 2.5-3x
    improvement on small arrays:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如典型的predication一样，这个技巧对编译器优化非常脆弱——取决于编译器和函数的调用方式，它可能仍然留下分支或生成次优代码。它在Clang 10上运行良好，在小数组上提供了2.5-3倍的性能提升：
- en: '![](../Images/d1de0a9e2468bfe1337d27ec18713602.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/d1de0a9e2468bfe1337d27ec18713602.png)'
- en: 'One interesting detail is that it performs worse on large arrays. It seems
    weird: the total delay is dominated by the RAM latency, and since it does roughly
    the same memory accesses as the standard binary search, it should be roughly the
    same or even slightly better.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的细节是，它在大型数组上的性能更差。这似乎很奇怪：总延迟主要由RAM延迟主导，而且它做的内存访问与标准二分搜索大致相同，所以它应该是大致相同，甚至稍微好一些。
- en: The real question you need to ask is not why the branchless implementation is
    worse but why the branchy version is better. It happens because when you have
    branching, the CPU can [speculate](/hpc/pipelining/branching/) on one of the branches
    and start fetching either the left or the right key before it can even confirm
    that it is the right one — which effectively acts as implicit [prefetching](/hpc/cpu-cache/prefetching).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要问的真正问题不是为什么无分支实现更差，而是为什么分支版本更好。这是因为当你有分支时，CPU可以[推测](/hpc/pipelining/branching/)其中一个分支，并在确认它是正确的之前就开始获取左边的或右边的键——这实际上相当于隐式的[预取](/hpc/cpu-cache/prefetching)。
- en: 'For the branchless implementation, this doesn’t happen, as `cmov` is treated
    as every other instruction, and the branch predictor doesn’t try to peek into
    its operands to predict the future. To compensate for this, we can prefetch the
    data in software by explicitly requesting the left and right child key:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于无分支实现，这种情况不会发生，因为`cmov`被视为其他任何指令，分支预测器也不会试图窥视其操作数来预测未来。为了补偿这一点，我们可以通过显式请求左右子键来在软件中预取数据：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With prefetching, the performance on large arrays becomes roughly the same:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预取，在大数组上的性能大致相同：
- en: '![](../Images/daa69a5238a8e64bfaf7b75f8ce5111a.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/daa69a5238a8e64bfaf7b75f8ce5111a.png)'
- en: The graph still grows faster as the branchy version also prefetches “grandchildren,”
    “great-grandchildren,” and so on — although the usefulness of each new speculative
    read diminishes exponentially as the prediction is less and less likely to be
    correct.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随着分支版本也预取“孙子”、“曾孙”等，图仍然以更快的速度增长——尽管每次新的推测性读取的有用性随着预测越来越不可能正确而呈指数减少。
- en: In the branchless version, we could also fetch ahead by more than one layer,
    but the number of fetches we’d need also grows exponentially. Instead, we will
    try a different approach to optimize memory operations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在无分支版本中，我们也可以提前获取超过一层的数据，但所需的获取次数也会呈指数增长。相反，我们将尝试不同的方法来优化内存操作。
- en: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#optimizing-the-layout)Optimizing
    the Layout'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '## [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#optimizing-the-layout)优化布局'
- en: 'The memory requests we perform during binary search form a very specific access
    pattern:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分搜索过程中我们执行的内存请求形成了一种非常特定的访问模式：
- en: '![](../Images/ba0f19f678d02d700f8434f1b6859735.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ba0f19f678d02d700f8434f1b6859735.png)'
- en: How likely is it that the elements on each request are cached? How good is their
    [data locality](/hpc/external-memory/locality/)?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每次请求中的元素被缓存的几率有多大？它们的数据局部性如何？
- en: '*Spatial locality* seems to be okay for the last 3 to 4 requests that are likely
    to be on the same [cache line](/hpc/cpu-cache/cache-lines) — but all the previous
    requests require huge memory jumps.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*空间局部性*似乎对于最后3到4次请求来说是可行的，这些请求可能位于相同的[缓存行](/hpc/cpu-cache/cache-lines)上——但所有之前的请求都需要巨大的内存跳跃。'
- en: '*Temporal locality* seems to be okay for the first dozen or so requests — there
    aren’t that many different comparison sequences of this length, so we will be
    comparing against the same middle elements over and over, which are likely to
    be cached.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间局部性*似乎对于前十二次左右的请求来说是可行的——这个长度的不同比较序列并不多，所以我们将反复比较相同的中间元素，这些元素很可能是缓存的。'
- en: 'To illustrate how important the second type of cache sharing is, let’s try
    to pick the element we will compare to on each iteration randomly among the elements
    of the search interval, instead of the middle one:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明第二种类型的缓存共享有多么重要，让我们尝试在搜索区间的元素中随机选择我们将要比较的元素，而不是中间的元素：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Theoretically](#appendix-random-binary-search), this randomized binary search
    is expected to do 30-40% more comparisons than the normal one, but on a real computer,
    the running time goes ~6x on large arrays:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[理论上](#appendix-random-binary-search)，这种随机二分搜索预计要比正常搜索多进行30-40%的比较，但在实际计算机上，在大数组上的运行时间大约是6倍：'
- en: '![](../Images/3d703a992e5db0ba9b92db99c332f6ce.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/3d703a992e5db0ba9b92db99c332f6ce.png)'
- en: This isn’t just caused by the `rand()` call being slow. You can clearly see
    the point on the L2-L3 boundary where memory latency outweighs the random number
    generation and [modulo](/hpc/arithmetic/division). The performance degrades because
    all of the fetched elements are unlikely to be cached and not just some small
    suffix of them.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是仅仅因为`rand()`调用速度慢。你可以在L2-L3边界清楚地看到这一点，在那里内存延迟超过了随机数生成和[取模](/hpc/arithmetic/division)。性能下降是因为所有检索到的元素不太可能被缓存，而不仅仅是它们的一些小后缀。
- en: 'Another potential negative effect is that of [cache associativity](/hpc/cpu-cache/associativity).
    If the array size is a multiple of a large power of two, then the indices of these
    “hot” elements will also be divisible by some large powers of two and map to the
    same cache line, kicking each other out. For example, binary searching over arrays
    of size $2^{20}$ takes about ~360ns per query while searching over arrays of size
    $(2^{20} + 123)$ takes ~300ns — a 20% difference. There are [ways](https://en.wikipedia.org/wiki/Fibonacci_search_technique)
    to fix this problem, but to not get distracted from more pressing matters, we
    are just going to ignore it: all array sizes we use are in the form of $\lfloor
    1.17^k \rfloor$ for integer $k$ so that any cache side effects are unlikely.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个潜在的负面影响是[缓存关联性](/hpc/cpu-cache/associativity)。如果数组大小是某个大二的幂的倍数，那么这些“热”元素的索引也将是某些大二的幂的倍数，并将映射到相同的缓存行，相互踢出。例如，在大小为$2^{20}$的数组上进行二分搜索大约需要每个查询360ns，而在大小为$(2^{20}
    + 123)$的数组上进行搜索大约需要300ns——相差20%。有[方法](https://en.wikipedia.org/wiki/Fibonacci_search_technique)可以解决这个问题，但为了不分散对更紧迫问题的注意力，我们只是忽略它：我们使用的所有数组大小都是整数$k$的$\lfloor
    1.17^k \rfloor$的形式，这样任何缓存副作用都极不可能发生。
- en: The real problem with our memory layout is that it doesn’t make the most efficient
    use of temporal locality because it groups hot and cold elements together. For
    example, we likely store the element $\lfloor n/2 \rfloor$, which we request the
    first thing on each query, in the same cache line with $\lfloor n/2 \rfloor +
    1$, which we almost never request.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们内存布局的真正问题是它没有最有效地利用时间局部性，因为它将热元素和冷元素放在一起。例如，我们可能将请求的第一个元素$\lfloor n/2 \rfloor$存储在与$\lfloor
    n/2 \rfloor + 1$相同的缓存行中，而后者我们几乎从不请求。
- en: 'Here is the heatmap visualizing the expected frequency of comparisons for a
    31-element array:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是可视化31元素数组预期比较频率的热图：
- en: '![](../Images/97149b2f72e5c7dd2e42f068f661650a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97149b2f72e5c7dd2e42f068f661650a.png)'
- en: So, ideally, we’d want a memory layout where hot elements are grouped with hot
    elements, and cold elements are grouped with cold elements. And we can achieve
    this if we permute the array in a more cache-friendly way by renumbering them.
    The numeration we will use is actually half a millennium old, and chances are,
    you already know it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，理想情况下，我们希望有一个内存布局，其中热元素与热元素分组，冷元素与冷元素分组。我们可以通过重新编号数组以更缓存友好的方式来实现这一点。我们将使用的编号实际上有半个世纪的历史，而且你很可能已经知道了。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#eytzinger-layout)Eytzinger
    Layout'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '### [Eytzinger布局](https://en.algorithmica.org/hpc/data-structures/binary-search/#eytzinger-layout)'
- en: '**Michaël Eytzinger** is a 16th-century Austrian nobleman known for his work
    on genealogy, particularly for a system for numbering ancestors called *ahnentafel*
    (German for “ancestor table”).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**米夏埃尔·艾茨金格**是一位16世纪的奥地利贵族，因其在家谱研究方面的作品而闻名，尤其是他提出的被称为*ahnentafel*（德语意为“祖先表”）的祖先编号系统。'
- en: Ancestry mattered a lot back then, but writing down that data was expensive.
    *Ahnentafel* allows displaying a person’s genealogy compactly, without wasting
    extra space by drawing diagrams.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在那个时代，血统非常重要，但写下这些数据是昂贵的。*Ahnentafel*允许紧凑地显示一个人的家谱，而不会通过绘制图表浪费额外的空间。
- en: It lists a person’s direct ancestors in a fixed sequence of ascent. First, the
    person themselves is listed as number 1, and then, recursively, for each person
    numbered $k$, their father is listed as $2k$ and their mother as $(2k+1)$.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 它列出了一个固定顺序中的人的直接祖先。首先，这个人自己被列为编号1，然后，递归地，对于每个编号为$k$的人，他们的父亲被列为$2k$，他们的母亲被列为$(2k+1)$。
- en: 'Here is the example for [Paul I](https://en.wikipedia.org/wiki/Paul_I_of_Russia),
    the great-grandson of [Peter the Great](https://en.wikipedia.org/wiki/Peter_the_Great):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是[保罗一世](https://en.wikipedia.org/wiki/Paul_I_of_Russia)，彼得大帝的曾孙的例子：
- en: Paul I
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保罗一世
- en: Peter III (Paul’s father)
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 彼得三世（保罗的父亲）
- en: '[Catherine II](https://en.wikipedia.org/wiki/Catherine_the_Great) (Paul’s mother)'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[叶卡捷琳娜二世](https://en.wikipedia.org/wiki/Catherine_the_Great)（保罗的母亲）'
- en: Charles Frederick (Peter’s father, Paul’s paternal grandfather)
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查尔斯·弗雷德里克（彼得的父亲，保罗的父亲的祖父）
- en: Anna Petrovna (Peter’s mother, Paul’s paternal grandmother)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安娜·彼得罗夫娜（彼得的母亲，保罗的父亲的祖母）
- en: Christian August (Catherine’s father, Paul’s maternal grandfather)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克里斯蒂安·奥古斯特（凯瑟琳的父亲，保罗的母亲的祖父）
- en: Johanna Elisabeth (Catherine’s mother, Paul’s maternal grandmother)
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 约翰娜·伊丽莎白（凯瑟琳的母亲，保罗的母亲的祖母）
- en: Apart from being compact, it has some nice properties, like that all even-numbered
    persons are male and all odd-numbered (possibly except for 1) are female. One
    can also find the number of a particular ancestor only knowing the genders of
    their descendants. For example, Peter the Great’s bloodline is Paul I → Peter
    III → Anna Petrovna → Peter the Great, so his number should be $((1 \times 2)
    \times 2 + 1) \times 2 = 10$.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了紧凑之外，它还有一些很好的特性，比如所有偶数编号的人都是男性，所有奇数编号的（可能除了1）都是女性。一个人也可以只通过知道其后代的性别来找到特定祖先的编号。例如，彼得大帝的血脉是保罗一世
    → 彼得三世 → 安娜·彼得罗夫娜 → 彼得大帝，因此他的编号应该是 $((1 \times 2) \times 2 + 1) \times 2 = 10$。
- en: '**In computer science**, this enumeration has been widely used for implicit
    (pointer-free) implementations of heaps, segment trees, and other binary tree
    structures — where instead of names, it stores underlying array items.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**在计算机科学中**，这种枚举已被广泛用于堆、线段树和其他二叉树结构的隐式（无指针）实现——在这里，它存储的是底层数组项而不是名称。'
- en: 'Here is how this layout looks when applied to binary search:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何将这种布局应用于二分搜索的：
- en: '![](../Images/e9da87bd9fd823f9afa85785500ce7a4.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/e9da87bd9fd823f9afa85785500ce7a4.png)'
- en: Note that the tree is slightly imbalanced (because of the last layer is continuous)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到树略微不平衡（因为最后一层是连续的）
- en: 'When searching in this layout, we just need to start from the first element
    of the array, and then on each iteration jump to either $2 k$ or $(2k + 1)$, depending
    on how the comparison went:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种布局中搜索时，我们只需从数组的第一个元素开始，然后在每次迭代中根据比较结果跳转到 `2k` 或 `(2k + 1)`。
- en: '![](../Images/228f35b59f050f682d228f93babb8656.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/228f35b59f050f682d228f93babb8656.png)'
- en: You can immediately see how its temporal locality is better (and, in fact, theoretically
    optimal) as the elements closer to the root are closer to the beginning of the
    array and thus are more likely to be fetched from the cache.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以立即看出它的时空局部性更好（实际上，理论上是最优的），因为靠近根的元素更接近数组的开始部分，因此更有可能从缓存中获取。
- en: '![](../Images/d7f49b3b16fdf4021d6bf5a913e91021.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/d7f49b3b16fdf4021d6bf5a913e91021.png)'
- en: Another way to look at it is that we write every even-indexed element to the
    end of the new array, then write every even-indexed element of the remaining ones
    right before them, and so on, until we place the root as the first element.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看待它的方法是，我们将每个偶数索引的元素写入新数组的末尾，然后写入剩余元素中每个偶数索引的元素，紧随其后，依此类推，直到我们将根作为第一个元素放置。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#construction)Construction'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '### [构造](https://en.algorithmica.org/hpc/data-structures/binary-search/#construction)'
- en: 'To construct the Eytzinger array, we could do this even-odd [filtering](/hpc/simd/shuffling/#permutations-and-lookup-tables)
    $O(\log n)$ times — and, perhaps, this is the fastest approach — but for brevity,
    we will instead build it by traversing the original search tree:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建 Eytzinger 数组，我们可以进行这种偶数奇数 [过滤](/hpc/simd/shuffling/#permutations-and-lookup-tables)
    $O(\log n)$ 次——这可能是最快的方法——但为了简洁起见，我们将通过遍历原始搜索树来构建它。
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This function takes the current node number `k`, recursively writes out all
    elements to the left of the middle of the search interval, writes out the current
    element we’d compare against, and then recursively writes out all the elements
    on the right. It seems a bit complicated, but to convince yourself that it works,
    you only need three observations:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受当前节点编号 `k`，递归地写出搜索区间中间左侧的所有元素，然后写出我们要比较的当前元素，最后递归地写出右侧的所有元素。这看起来有点复杂，但为了让你相信它有效，你只需要三个观察点：
- en: It writes exactly `n` elements as we enter the body of `if` for each `k` from
    `1` to `n` just once.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个 `k` 从 `1` 到 `n`，它只会在 `if` 语句体中写入 `n` 个元素一次。
- en: It writes out sequential elements from the original array as it increments the
    `i` pointer each time.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在每次增加 `i` 指针时，按顺序从原始数组中写入连续元素。
- en: By the time we write the element at node `k`, we will have already written all
    the elements to its left (exactly `i`).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们写入节点 `k` 的元素时，我们已经在它的左侧写入了所有元素（正好是 `i`）。
- en: 'Despite being recursive, it is actually quite fast as all the memory reads
    are sequential, and the memory writes are only in $O(\log n)$ different memory
    blocks at a time. Maintaining the permutation is both logically and computationally
    harder to maintain though: adding an element to a sorted array only requires shifting
    a suffix of its elements one position to the right, while Eytzinger array practically
    needs to be rebuilt from scratch.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管是递归的，但实际上它非常快，因为所有的内存读取都是顺序的，而内存写入只发生在 $O(\log n)$ 个不同的内存块中。然而，维护排列在逻辑上和计算上都更难，因为向有序数组中添加一个元素只需要将其元素的一个后缀向右移动一个位置，而
    Eytzinger 数组实际上需要从头开始重建。
- en: 'Note that this traversal and the resulting permutation are not exactly equivalent
    to the “tree” of vanilla binary search: for example, the left child subtree may
    be larger than the right child subtree — up to twice as large — but it doesn’t
    matter much since both approaches result in the same $\lceil \log_2 n \rceil$
    tree depth.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种遍历和由此产生的排列并不完全等同于传统的二分搜索“树”：例如，左子树可能比右子树大——最多大两倍——但这并不重要，因为两种方法都导致了相同的
    $\lceil \log_2 n \rceil$ 树深度。
- en: Also note that the Eytzinger array is one-indexed — this will be important for
    performance later. You can put in the zeroth element the value that you want to
    be returned in the case when the lower bound doesn’t exist (similar to `a.end()`
    for `std::lower_bound`).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，Eytzinger 数组是从 1 开始计数的——这将在后续的性能中变得很重要。你可以将你想要在不存在下界的情况下返回的值放在零元素中（类似于
    `std::lower_bound` 的 `a.end()`）。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#search-implementation)Search
    Implementation'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#search-implementation)搜索实现'
- en: 'We can now descend this array using only indices: we just start with $k=1$
    and execute $k := 2k$ if we need to go left and $k := 2k + 1$ if we need to go
    right. We don’t even need to store and recalculate the search boundaries anymore.
    This simplicity also lets us avoid branching:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用索引来下降这个数组：我们只需从 $k=1$ 开始，如果需要向左移动，则执行 $k := 2k$，如果需要向右移动，则执行 $k := 2k
    + 1$。我们甚至不再需要存储和重新计算搜索边界。这种简单性还让我们避免了分支：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The only problem arises when we need to restore the index of the resulting
    element, as $k$ does not directly point to it. Consider this example (its corresponding
    tree is listed above):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的问题是当我们需要恢复结果元素的索引时，因为 $k$ 并不直接指向它。考虑这个例子（其对应的树如上所示）：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here we query the array of $[0, …, 9]$ for the lower bound of $x=3$. We compare
    it against $6$, $3$, $1$, and $2$, go left-left-right-right, and end up with $k
    = 19$, which isn’t even a valid array index.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们查询数组 $[0, …, 9]$ 以找到 $x=3$ 的下界。我们将其与 $6$、$3$、$1$ 和 $2$ 进行比较，向左左右右移动，最终得到
    $k = 19$，这甚至不是一个有效的数组索引。
- en: The trick is to notice that, unless the answer is the last element of the array,
    we compare $x$ against it at some point, and after we’ve learned that it is not
    less than $x$, we go left exactly once and then keep going right until we reach
    a leaf (because we will only be comparing $x$ against lesser elements). Therefore,
    to restore the answer, we just need to “cancel” some number of right turns and
    then one more.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧在于注意到，除非答案是数组的最后一个元素，否则我们会在某个时刻将 $x$ 与它进行比较，在我们得知它不小于 $x$ 之后，我们向左移动一次，然后继续向右移动直到我们到达一个叶子节点（因为我们只会将
    $x$ 与较小的元素进行比较）。因此，为了恢复答案，我们只需要“取消”一些向右的移动，然后再加上一次。
- en: 'This can be done in an elegant way by observing that the right turns are recorded
    in the binary representation of $k$ as 1-bits, and so we just need to find the
    number of trailing 1s in the binary representation and right-shift $k$ by exactly
    that number of bits plus one. To do this, we can invert the number (`~k`) and
    call the “find first set” instruction:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过观察 $k$ 的二进制表示中的右转被记录为 1 位来优雅地完成，所以我们只需要找到二进制表示中的尾随 1 的数量，并将 $k$ 向右移动正好那么多位加一。为此，我们可以反转这个数（`~k`）并调用“找到第一个设置”指令：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We run it, and… well, it doesn’t look *that* good:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行它，嗯，看起来并不那么好：
- en: '![](../Images/968d4f0e9353467d25cbc991c2c23c85.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/968d4f0e9353467d25cbc991c2c23c85.png)'
- en: 'The latency on smaller arrays is on par with the branchless binary search implementation
    — which isn’t surprising as it is just two lines of code — but it starts taking
    off much sooner. The reason is that the Eytzinger binary search doesn’t get the
    advantage of spatial locality: the last 3-4 elements we compare against are not
    in the same cache line anymore, and we have to fetch them separately.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在较小的数组上，延迟与无分支二分搜索实现相当——这并不令人惊讶，因为它只是两行代码——但它开始得要早得多。原因是Eytzinger二分搜索没有获得空间局部性的优势：我们比较的最后3-4个元素不再位于同一缓存行中，我们必须单独获取它们。
- en: If you think about it deeper, you might object that the improved temporal locality
    should compensate for that. Before, we were using only about $\frac{1}{16}$-th
    of the cache line to store one hot element, and now we are using all of it, so
    the effective cache size is larger by a factor of 16, which lets us cover $\log_2
    16 = 4$ more first requests.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更深入地思考，你可能会反对说，改进的时间局部性应该可以补偿这一点。在此之前，我们只使用了大约 $\frac{1}{16}$ 的缓存行来存储一个热元素，而现在我们使用了全部，所以有效缓存大小增加了16倍，这使得我们可以覆盖
    $\log_2 16 = 4$ 个更多的首次请求。
- en: But if you think about it more, you understand that this isn’t enough compensation.
    Caching the other 15 elements wasn’t completely useless, and also, the hardware
    prefetcher could fetch the neighboring cache lines of our requests. If this was
    one of our last requests, the rest of what we will be reading will probably be
    cached elements. So actually, the last 6-7 accesses are likely to be cached, not
    3-4.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你更深入地思考，你会理解这还不足以补偿。缓存其他15个元素并不是完全没有用，而且，硬件预取器可以预取我们请求的相邻缓存行。如果这是我们最后的请求之一，我们将要读取的其余部分可能都是缓存元素。所以实际上，最后6-7次访问很可能是缓存的，而不是3-4次。
- en: It seems like we did an overall stupid thing switching to this layout, but there
    is a way to make it worthwhile.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们切换到这种布局是一个整体上的愚蠢行为，但有一种方法可以使它变得有价值。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#prefetching)Prefetching'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#prefetching)预取'
- en: 'To hide the memory latency, we can use software prefetching similar to how
    we did for branchless binary search. But instead of issuing two separate prefetch
    instructions for the left and right child nodes, we can notice that they are neighbors
    in the Eytzinger array: one has index $2 k$ and the other $(2k + 1)$, so they
    are likely in the same cache line, and we can use just one instruction.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了隐藏内存延迟，我们可以使用类似于我们为无分支二分搜索所做的方式的软件预取。但不是为左子节点和右子节点发出两个单独的预取指令，我们可以注意到它们在Eytzinger数组中是邻居：一个的索引是
    $2 k$，另一个是 $(2k + 1)$，所以它们很可能位于同一缓存行中，我们可以只用一个指令。
- en: 'This observation extends to the grand-children of node $k$ — they are also
    stored sequentially:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这个观察结果也适用于节点 $k$ 的子节点——它们也是按顺序存储的：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Their cache line can also be fetched with one instruction. Interesting… what
    if we continue this, and instead of fetching direct children, we fetch ahead as
    many descendants as we can cramp into one cache line? That would be $\frac{64}{4}
    = 16$ elements, our great-great-grandchildren with indices from $16k$ to $(16k
    + 15)$.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的缓存行也可以用一个指令来获取。有趣……如果我们继续这样做，而不是获取直接子节点，而是尽可能多地预取一个缓存行中可以容纳的后代节点，那会是什么样子？这将会有
    $\frac{64}{4} = 16$ 个元素，我们的曾孙节点，索引从 $16k$ 到 $(16k + 15)$。
- en: Now, if we prefetch just one of these 16 elements, we will probably only get
    some but not all of them, as they may cross a cache line boundary. We can prefetch
    the first *and* the last element, but to get away with just one memory request,
    we need to notice that the index of the first element, $16k$, is divisible by
    $16$, so its memory address will be the base address of the array plus something
    divisible by $16 \cdot 4 = 64$, the cache line size. If the array were to begin
    on a cache line, then these $16$ great-great-grandchildren elements will be guaranteed
    to be on a single cache line, which is just what we needed.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们只预取这16个元素中的一个，我们可能只会得到一些而不是全部，因为它们可能跨越缓存行边界。我们可以预取第一个*和*最后一个元素，但要通过一个内存请求完成，我们需要注意到第一个元素索引
    $16k$ 可以被 $16$ 整除，所以它的内存地址将是数组的基本地址加上一个可以被 $16 \cdot 4 = 64$ 整除的值，这是缓存行的大小。如果数组从缓存行开始，那么这16个曾孙元素将保证位于单个缓存行中，这正是我们所需要的。
- en: 'Therefore, we only need to [align](/hpc/cpu-cache/alignment) the array:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们只需要[对齐](/hpc/cpu-cache/alignment)数组：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And then prefetch the element indexed $16 k$ on each iteration:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在每次迭代中预取索引为 $16 k$ 的元素：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The performance on large arrays improves 3-4x from the previous version and
    ~2x compared to `std::lower_bound`. Not bad for just two more lines of code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型数组上的性能比之前版本提高了3-4倍，比`std::lower_bound`提高了约2倍。仅仅增加两行代码就不错了：
- en: '![](../Images/03052e594c2dc64bc4d19a90ee17b8cb.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03052e594c2dc64bc4d19a90ee17b8cb.png)'
- en: Essentially, what we do here is hide the latency by prefetching four steps ahead
    and overlapping memory requests. Theoretically, if the compute didn’t matter,
    we would expect a ~4x speedup, but in reality, we get a somewhat more moderate
    speedup.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们在这里做的是通过预取四步并重叠内存请求来隐藏延迟。理论上，如果计算不重要，我们预计会有约4倍的速度提升，但现实中，我们得到的是一种更为适度的速度提升。
- en: 'We can also try to prefetch further than that four steps ahead, and we don’t
    even have to use more than one prefetch instruction for that: we can try to request
    only the first cache line and rely on the hardware to prefetch its neighbors.
    This trick may or may not improve actual performance — depends on the hardware:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试预取超过四步，而且我们甚至不必使用超过一个预取指令：我们可以尝试只请求第一行缓存，并依赖硬件来预取其邻居。这个技巧可能或可能不会提高实际性能——取决于硬件：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Also, note that the last few prefetch requests are actually not needed, and
    in fact, they may even be outside the memory region allocated for the program.
    On most modern CPUs, invalid prefetch instructions get converted into no-ops,
    so it isn’t a problem, but on some platforms, this may cause a slowdown, so it
    may make sense, for example, to split off the last ~4 iterations from the loop
    to try to remove them.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，最后几个预取请求实际上并不需要，实际上，它们甚至可能超出程序分配的内存区域。在大多数现代CPU上，无效的预取指令会被转换为空操作，所以这不是问题，但在某些平台上，这可能会导致速度降低，因此，例如，将最后约4次迭代从循环中分离出来以尝试移除它们可能是有意义的。
- en: This prefetching technique allows us to read up to four elements ahead, but
    it doesn’t really come for free — we are effectively trading off excess memory
    [bandwidth](/hpc/cpu-cache/bandwidth) for reduced [latency](/hpc/cpu-cache/latency).
    If you run more than one instance at a time on separate hardware threads or just
    any other memory-intensive computation in the background, it will significantly
    [affect](/hpc/cpu-cache/sharing) the benchmark performance.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这种预取技术使我们能够读取最多四个元素，但这并不是免费的——我们实际上是在用额外的内存[带宽](/hpc/cpu-cache/bandwidth)来换取减少的[延迟](/hpc/cpu-cache/latency)。如果你同时在不同的硬件线程上运行多个实例，或者在后台运行任何其他内存密集型计算，这将显著[影响](/hpc/cpu-cache/sharing)基准性能。
- en: But we can do better. Instead of fetching four cache lines at a time, we could
    fetch four times *fewer* cache lines. And in the [next section](../s-tree), we
    will explore the approach.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以做得更好。我们不必一次预取四行缓存，我们可以预取更少的四倍缓存行。在[下一节](../s-tree)中，我们将探讨这种方法。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#removing-the-last-branch)Removing
    the Last Branch'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '### [移除最后一个分支](https://en.algorithmica.org/hpc/data-structures/binary-search/#removing-the-last-branch)'
- en: 'Just one finishing touch: did you notice the bumpiness of the Eytzinger search?
    This isn’t random noise — let’s zoom in:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 只需一个收尾工作：你注意到Eytzinger搜索的颠簸吗？这并不是随机噪声——让我们放大看看：
- en: '![](../Images/98293c45b3cc644c79feae3d4ef2b8c9.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98293c45b3cc644c79feae3d4ef2b8c9.png)'
- en: The latency is ~10ns higher for the array sizes in the form of $1.5 \cdot 2^k$.
    These are mispredicted branches from the loop itself — the last branch, to be
    exact. When the array size is far from a power of two, it is hard to predict whether
    the loop will make $\lfloor \log_2 n \rfloor$ or $\lfloor \log_2 n \rfloor + 1$
    iterations, so we have a 50% chance to suffer exactly one branch mispredict.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于形式为$1.5 \cdot 2^k$的数组大小，延迟大约高10ns。这些是从循环本身预测错误的分支——确切地说，是最后一个分支。当数组大小远非2的幂时，很难预测循环将执行$\lfloor
    \log_2 n \rfloor$次或$\lfloor \log_2 n \rfloor + 1$次迭代，所以我们有50%的几率正好预测错误一次分支。
- en: 'One way to address it is to pad the array with infinities to the closest power
    of two, but this wastes memory. Instead, we get rid of that last branch by always
    executing a constant minimum number of iterations and then using predication to
    optionally make the last comparison against some dummy element — that is guaranteed
    to be less than $x$ so that its comparison will be canceled:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方法是使用无穷大填充数组到最接近的2的幂，但这会浪费内存。相反，我们通过始终执行一个固定的最小迭代次数，然后使用预测来可选地使最后一个比较与某个虚拟元素——这保证小于$x$，因此其比较将被取消：
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The graph is now smooth, and on small arrays, it is just a couple of cycles
    slower than the branchless binary search:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图现在变得平滑了，在小数组上，它比无分支的二分查找慢了仅仅几个周期：
- en: '![](../Images/361967de1a95a2729ca8023b6b8c060d.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/361967de1a95a2729ca8023b6b8c060d.png)'
- en: Interestingly, now GCC fails to replace the branch with `cmov`, but Clang doesn’t.
    1-1.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，现在 GCC 无法用 `cmov` 替换分支，但 Clang 不行。1-1。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#appendix-random-binary-search)Appendix:
    Random Binary Search'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '### [附录：随机二分查找](https://en.algorithmica.org/hpc/data-structures/binary-search/#appendix-random-binary-search)'
- en: By the way, finding the exact expected number of comparisons for random binary
    search is quite an interesting math problem in and of itself. Try solving it yourself
    first!
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，找到随机二分查找的确切期望比较次数本身就是一个相当有趣的数学问题。先自己试试解决它！
- en: 'The way to compute it *algorithmically* is through dynamic programming. If
    we denote $f_n$ as the expected number of comparisons to find a random lower bound
    on a search interval of size $n$, it can be calculated from the previous $f_n$
    by considering all the $(n - 1)$ possible splits:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 计算它的 *算法* 方法是通过动态规划。如果我们用 $f_n$ 表示在大小为 $n$ 的搜索区间中找到随机下界的期望比较次数，它可以通过考虑所有可能的
    $(n - 1)$ 个分割来从之前的 $f_n$ 计算得出：
- en: '$$ f_n = \sum_{l = 1}^{n - 1} \frac{1}{n-1} \cdot \left( f_l \cdot \frac{l}{n}
    + f_{n - l} \cdot \frac{n - l}{n} \right) + 1 $$ Directly applying this formula
    gives us an $O(n^2)$ algorithm, but we can optimize it by rearranging the sum
    like this: $$ \begin{aligned} f_n &= \sum_{i = 1}^{n - 1} \frac{ f_i \cdot i +
    f_{n - i} \cdot (n - i) }{ n \cdot (n - 1) } + 1 \\ &= \frac{2}{n \cdot (n - 1)}
    \cdot \sum_{i = 1}^{n - 1} f_i \cdot i + 1 \end{aligned} $$ To update $f_n$, we
    only need to calculate the sum of $f_i \cdot i$ for all $i < n$. To do that, let’s
    introduce two new variables: $$ g_n = f_n \cdot n, \;\; s_n = \sum_{i=1}^{n} g_n
    $$ Now they can be sequentially calculated as: $$ \begin{aligned} g_n &= f_n \cdot
    n = \frac{2}{n-1} \cdot \sum_{i = 1}^{n - 1} g_i + n = \frac{2}{n - 1} \cdot s_{n
    - 1} + n \\ s_n &= s_{n - 1} + g_n \end{aligned} $$ This way we get an $O(n)$
    algorithm, but we can do even better. Let’s substitute $g_n$ in the update formula
    for $s_n$: $$ \begin{aligned} s_n &= s_{n - 1} + \frac{2}{n - 1} \cdot s_{n -
    1} + n \\ &= (1 + \frac{2}{n - 1}) \cdot s_{n - 1} + n \\ &= \frac{n + 1}{n -
    1} \cdot s_{n - 1} + n \end{aligned} $$'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: $$ f_n = \sum_{l = 1}^{n - 1} \frac{1}{n-1} \cdot \left( f_l \cdot \frac{l}{n}
    + f_{n - l} \cdot \frac{n - l}{n} \right) + 1 $$ 直接应用这个公式会给我们一个 $O(n^2)$ 的算法，但我们可以通过重新排列求和来优化它：$$
    \begin{aligned} f_n &= \sum_{i = 1}^{n - 1} \frac{ f_i \cdot i + f_{n - i} \cdot
    (n - i) }{ n \cdot (n - 1) } + 1 \\ &= \frac{2}{n \cdot (n - 1)} \cdot \sum_{i
    = 1}^{n - 1} f_i \cdot i + 1 \end{aligned} $$ 要更新 $f_n$，我们只需要计算所有 $i < n$ 的 $f_i
    \cdot i$ 的和。为了做到这一点，让我们引入两个新变量：$$ g_n = f_n \cdot n, \;\; s_n = \sum_{i=1}^{n}
    g_n $$ 现在它们可以按顺序计算如下：$$ \begin{aligned} g_n &= f_n \cdot n = \frac{2}{n-1} \cdot
    \sum_{i = 1}^{n - 1} g_i + n = \frac{2}{n - 1} \cdot s_{n - 1} + n \\ s_n &= s_{n
    - 1} + g_n \end{aligned} $$ 这样我们得到一个 $O(n)$ 的算法，但我们还可以做得更好。让我们将 $g_n$ 代入 $s_n$
    的更新公式中：$$ \begin{aligned} s_n &= s_{n - 1} + \frac{2}{n - 1} \cdot s_{n - 1} +
    n \\ &= (1 + \frac{2}{n - 1}) \cdot s_{n - 1} + n \\ &= \frac{n + 1}{n - 1} \cdot
    s_{n - 1} + n \end{aligned} $$
- en: 'The next trick is more complicated. We define $r_n$ like this: $$ \begin{aligned}
    r_n &= \frac{s_n}{n} \\ &= \frac{1}{n} \cdot \left(\frac{n + 1}{n - 1} \cdot s_{n
    - 1} + n\right) \\ &= \frac{n + 1}{n} \cdot \frac{s_{n - 1}}{n - 1} + 1 \\ &=
    \left(1 + \frac{1}{n}\right) \cdot r_{n - 1} + 1 \end{aligned} $$ We can substitute
    it into the formula we got for $g_n$ before: $$ g_n = \frac{2}{n - 1} \cdot s_{n
    - 1} + n = 2 \cdot r_{n - 1} + n $$ Recalling that $g_n = f_n \cdot n$, we can
    express $r_{n - 1}$ using $f_n$: $$ f_n \cdot n = 2 \cdot r_{n - 1} + n \implies
    r_{n - 1} = \frac{(f_n - 1) \cdot n}{2} $$ Final step. We’ve just expressed $r_n$
    through $r_{n - 1}$ and $r_{n - 1}$ through $f_n$. This lets us express $f_{n
    + 1}$ through $f_n$: $$ \begin{aligned} &&\quad r_n &= \left(1 + \frac{1}{n}\right)
    \cdot r_{n - 1} + 1 \\ &\Rightarrow & \frac{(f_{n + 1} - 1) \cdot (n + 1)}{2}
    &= \left(1 + \frac{1}{n}\right) \cdot \frac{(f_n - 1) \cdot n}{2} + 1 \\ &&&=
    \frac{n + 1}{2} \cdot (f_n - 1) + 1 \\ &\Rightarrow & (f_{n + 1} - 1) &= (f_{n}
    - 1) + \frac{2}{n + 1} \\ &\Rightarrow &f_{n + 1} &= f_{n} + \frac{2}{n + 1} \\
    &\Rightarrow &f_{n} &= f_{n - 1} + \frac{2}{n} \\ &\Rightarrow &f_{n} &= \sum_{k
    = 2}^{n} \frac{2}{k} \end{aligned} $$'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个技巧更复杂。我们这样定义 $r_n$：$$ \begin{aligned} r_n &= \frac{s_n}{n} \\ &= \frac{1}{n}
    \cdot \left(\frac{n + 1}{n - 1} \cdot s_{n - 1} + n\right) \\ &= \frac{n + 1}{n}
    \cdot \frac{s_{n - 1}}{n - 1} + 1 \\ &= \left(1 + \frac{1}{n}\right) \cdot r_{n
    - 1} + 1 \end{aligned} $$ 我们可以将其代入之前得到的 $g_n$ 的公式：$$ g_n = \frac{2}{n - 1} \cdot
    s_{n - 1} + n = 2 \cdot r_{n - 1} + n $$ 回忆一下 $g_n = f_n \cdot n$，我们可以用 $f_n$
    来表示 $r_{n - 1}$：$$ f_n \cdot n = 2 \cdot r_{n - 1} + n \implies r_{n - 1} = \frac{(f_n
    - 1) \cdot n}{2} $$ 最后一步。我们刚刚用 $r_{n - 1}$ 和 $r_{n - 1}$ 通过 $f_n$ 表达了 $r_n$。这使得我们可以用
    $f_n$ 来表示 $f_{n + 1}$：$$ \begin{aligned} &&\quad r_n &= \left(1 + \frac{1}{n}\right)
    \cdot r_{n - 1} + 1 \\ &\Rightarrow & \frac{(f_{n + 1} - 1) \cdot (n + 1)}{2}
    &= \left(1 + \frac{1}{n}\right) \cdot \frac{(f_n - 1) \cdot n}{2} + 1 \\ &&&=
    \frac{n + 1}{2} \cdot (f_n - 1) + 1 \\ &\Rightarrow & (f_{n + 1} - 1) &= (f_{n}
    - 1) + \frac{2}{n + 1} \\ &\Rightarrow &f_{n + 1} &= f_{n} + \frac{2}{n + 1} \\
    &\Rightarrow &f_{n} &= f_{n - 1} + \frac{2}{n} \\ &\Rightarrow &f_{n} &= \sum_{k
    = 2}^{n} \frac{2}{k} \end{aligned} $$
- en: The last expression is double the [harmonic series](https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)),
    which is well known to approximate $\ln n$ as $n \to \infty$. Therefore, the random
    binary search will perform $\frac{2 \ln n}{\log_2 n} = 2 \ln 2 \approx 1.386$
    more comparisons compared to the normal one.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的表达式是调和级数的两倍，众所周知，当 $n \to \infty$ 时，它可以近似 $\ln n$。因此，随机二分搜索将比正常二分搜索多进行 $\frac{2
    \ln n}{\log_2 n} = 2 \ln 2 \approx 1.386$ 次比较。
- en: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#acknowledgements)Acknowledgements'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/data-structures/binary-search/#acknowledgements)致谢'
- en: The article is loosely based on “[Array Layouts for Comparison-Based Searching](https://arxiv.org/pdf/1509.05053.pdf)”
    by Paul-Virak Khuong and Pat Morin. It is 46 pages long and discusses these and
    many other (less successful) approaches in more detail. I highly recommend also
    checking it out — this is one of my favorite performance engineering papers.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 本文大致基于Paul-Virak Khuong和Pat Morin的论文“[基于比较的搜索的数组布局](https://arxiv.org/pdf/1509.05053.pdf)”。这篇论文有46页，详细讨论了这些以及其他许多（不太成功）的方法。我强烈推荐也看看它——这是我最喜欢的性能工程论文之一。
- en: Thanks to Marshall Lochbaum for [providing](https://github.com/algorithmica-org/algorithmica/issues/57)
    the proof for the random binary search. No way I could do it myself.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Marshall Lochbaum为随机二分搜索提供了[证明](https://github.com/algorithmica-org/algorithmica/issues/57)。我自己是不可能做到的。
- en: I also stole these lovely layout visualizations from some blog a long time ago,
    but I don’t remember the name of the blog and what license they had, and inverse
    image search doesn’t find them anymore. If you don’t sue me, thank you, whoever
    you are! [← ../Data Structures Case Studies](https://en.algorithmica.org/hpc/data-structures/)[Static
    B-Trees →](https://en.algorithmica.org/hpc/data-structures/s-tree/)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我很久以前也从某个博客上偷来了这些可爱的布局可视化，但我已经不记得博客的名字和它们有什么许可，反向图像搜索也不再能找到它们了。如果你不告我，谢谢你，无论你是谁！[←
    ../数据结构案例研究](https://en.algorithmica.org/hpc/data-structures/)[静态B-Trees →](https://en.algorithmica.org/hpc/data-structures/s-tree/)
