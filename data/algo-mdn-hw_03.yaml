- en: Programming Languages
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程语言
- en: 原文：[https://en.algorithmica.org/hpc/complexity/languages/](https://en.algorithmica.org/hpc/complexity/languages/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/complexity/languages/](https://en.algorithmica.org/hpc/complexity/languages/)
- en: If you are reading this book, then somewhere on your computer science journey
    you had a moment when you first started to care about the efficiency of your code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读这本书，那么在你的计算机科学之旅中，你一定有过一个时刻，你开始关心你代码的效率。
- en: 'Mine was in high school, when I realized that making websites and doing *useful*
    programming won’t get you into a university, and entered the exciting world of
    algorithmic programming olympiads. I was an okay programmer, especially for a
    highschooler, but I had never really wondered how much time it took for my code
    to execute before. But suddenly it started to matter: each problem now has a strict
    time limit. I started counting my operations. How many can you do in one second?'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我的经历是在高中时期，当我意识到制作网站和进行*有用的*编程并不能让你进入大学，于是进入了令人兴奋的算法编程奥林匹克竞赛的世界。我是一名不错的程序员，尤其是对于一个高中生来说，但我从未真正想过我的代码执行需要多少时间。但突然间，这开始变得很重要：每个问题现在都有一个严格的时间限制。我开始计算我的操作次数。一秒钟你能做多少？
- en: 'I didn’t know much about computer architecture to answer this question. But
    I also didn’t need the right answer — I needed a rule of thumb. My thought process
    was: “2-3GHz means 2 to 3 billion instructions executed every second, and in a
    simple loop that does something with array elements, I also need to increment
    loop counter, check end-of-loop condition, do array indexing and stuff like that,
    so let’s add room for 3-5 more instructions for every useful one” and ended up
    with using $5 \cdot 10^8$ as an estimate. None of these statements are true, but
    counting how many operations my algorithm needed and dividing it by this number
    was a good rule of thumb for my use case.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我对计算机架构的了解不多，无法回答这个问题。但我也并不需要正确的答案——我需要一个经验法则。我的思考过程是：“2-3GHz意味着每秒执行20到30亿条指令，在一个简单的循环中，我还需要增加循环计数器，检查循环结束条件，进行数组索引等操作，所以让我们为每个有用的操作增加3-5条指令的空间”最终我使用了$5
    \cdot 10^8$作为估算值。这些陈述都不正确，但计算我的算法需要多少操作，并将其除以这个数字，对于我的用例来说是一个很好的经验法则。
- en: The real answer, of course, is much more complicated and highly dependent on
    what kind of “operation” you have in mind. It can be as low as $10^7$ for things
    like [pointer chasing](/hpc/cpu-cache/latency) and as high as $10^{11}$ for [SIMD-accelerated](/hpc/simd)
    linear algebra. To demonstrate these striking differences, we will use the case
    study of matrix multiplication implemented in different languages — and dig deeper
    into how computers execute them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，真正的答案要复杂得多，并且高度依赖于你心中的“操作”类型。对于像[指针追踪](/hpc/cpu-cache/latency)这样的操作，它可能低至$10^7$，而对于[向量指令集加速](/hpc/simd)的线性代数，它可能高达$10^{11}$。为了展示这些显著的不同，我们将使用不同语言实现的矩阵乘法案例研究——并深入探讨计算机如何执行它们。
- en: '## [#](https://en.algorithmica.org/hpc/complexity/languages/#types-of-languages)Types
    of Languages'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '## [#](https://en.algorithmica.org/hpc/complexity/languages/#types-of-languages)语言类型'
- en: On the lowest level, computers execute *machine code* consisting of binary-encoded
    *instructions* which are used to control the CPU. They are specific, quirky, and
    require a great deal of intellectual effort to work with, so one of the first
    things people did after creating computers was create *programming languages*,
    which abstract away some details of how computers operate to simplify the process
    of programming.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在最低级别上，计算机执行由二进制编码的*指令*组成的*机器代码*，这些指令用于控制CPU。它们是特定的、古怪的，并且需要大量的智力努力才能与之合作，因此人们在创建计算机之后做的第一件事之一就是创建*编程语言*，这些语言抽象出计算机操作的一些细节，以简化编程过程。
- en: 'A programming language is fundamentally just an interface. Any program written
    in it is just a nicer higher-level representation which still at some point needs
    to be transformed into the machine code to be executed on the CPU — and there
    are several different means of doing that:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 编程语言本质上只是一个接口。用其编写的任何程序都只是更高级的、更优雅的表示形式，但最终仍需要在某些点上将其转换为CPU上执行的机器代码——并且有几种不同的方法可以做到这一点：
- en: 'From a programmer’s perspective, there are two types of languages: *compiled*,
    which pre-process before executing, and *interpreted*, which are executed during
    runtime using a separate program called *an interpreter*.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从程序员的视角来看，有两种类型的语言：*编译型*，在执行前进行预处理，和*解释型*，在运行时使用一个称为*解释器*的独立程序执行。
- en: 'From a computer’s perspective, there are also two types of languages: *native*,
    which directly execute machine code, and *managed*, which rely on some sort of
    *runtime* to do it.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从计算机的角度来看，也存在两种类型的语言：*原生*，它直接执行机器代码，和 *托管*，它依赖于某种 *运行时* 来执行。
- en: 'Since running machine code in an interpreter doesn’t make sense, this makes
    a total of three types of languages:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在解释器中运行机器代码没有意义，这总共形成了三种类型的语言：
- en: Interpreted languages, such as Python, JavaScript, or Ruby.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释型语言，例如 Python、JavaScript 或 Ruby。
- en: Compiled languages with a runtime, such as Java, C#, or Erlang (and languages
    that work on their VMs, such as Scala, F#, or Elixir).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有运行时的编译型语言，例如 Java、C# 或 Erlang（以及在其虚拟机上工作的语言，如 Scala、F# 或 Elixir）。
- en: Compiled native languages, such as C, Go, or Rust.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译型原生语言，例如 C、Go 或 Rust。
- en: 'There is no “right” way of executing computer programs: each approach has its
    own gains and drawbacks. Interpreters and virtual machines provide flexibility
    and enable some nice high-level programming features such as dynamic typing, run
    time code alteration, and automatic memory management, but these come with some
    unavoidable performance trade-offs, which we will now talk about.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 执行计算机程序没有“正确”的方式：每种方法都有其自身的优势和劣势。解释器和虚拟机提供了灵活性，并使一些高级编程特性成为可能，例如动态类型、运行时代码修改和自动内存管理，但这些都会带来一些不可避免的性能折衷，我们将在下面讨论。
- en: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#interpreted-languages)Interpreted
    languages'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#interpreted-languages)解释型语言'
- en: 'Here is an example of a by-definition $1024 \times 1024$ matrix multiplication
    in pure Python:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个纯 Python 中定义的 $1024 \times 1024$ 矩阵乘法的示例：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code runs in 630 seconds. That’s more than 10 minutes!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码运行了 630 秒。这超过了 10 分钟！
- en: Let’s try to put this number in perspective. The CPU that ran it has a clock
    frequency of 1.4GHz, meaning that it does $1.4 \cdot 10^9$ cycles per second,
    totaling to almost $10^{15}$ for the entire computation, and about 880 cycles
    per multiplication in the innermost loop.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试将这个数字放在一个合适的视角中。运行它的 CPU 的时钟频率为 1.4GHz，意味着它每秒执行 $1.4 \cdot 10^9$ 个周期，整个计算总共接近
    $10^{15}$ 个周期，最内层循环中大约每乘法执行 880 个周期。
- en: 'This is not surprising if you consider the things that Python needs to do to
    figure out what the programmer meant:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑到 Python 需要做什么来确定程序员的意思，这并不奇怪：
- en: it parses the expression `c[i][j] += a[i][k] * b[k][j]`;
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它解析表达式 `c[i][j] += a[i][k] * b[k][j]`；
- en: tries to figure out what `a`, `b`, and `c` are and looks up their names in a
    special hash table with type information;
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试确定 `a`、`b` 和 `c` 是什么，并在包含类型信息的特殊哈希表中查找它们的名称；
- en: understands that `a` is a list, fetches its `[]` operator, retrieves the pointer
    for `a[i]`, figures out it’s also a list, fetches its `[]` operator again, gets
    the pointer for `a[i][k]`, and then the element itself;
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 `a` 是一个列表，获取其 `[]` 操作符，检索 `a[i]` 的指针，发现它也是一个列表，再次获取其 `[]` 操作符，获取 `a[i][k]`
    的指针，然后是元素本身；
- en: looks up its type, figures out that it’s a `float`, and fetches the method implementing
    `*` operator;
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找其类型，确定它是一个 `float`，并获取实现 `*` 操作符的方法；
- en: does the same things for `b` and `c` and finally add-assigns the result to `c[i][j]`.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 `b` 和 `c` 执行相同的事情，最后将结果加赋给 `c[i][j]`。
- en: Granted, the interpreters of widely used languages such as Python are well-optimized,
    and they can skip through some of these steps on repeated execution of the same
    code. But still, some quite significant overhead is unavoidable due to the language
    design. If we get rid of all this type checking and pointer chasing, perhaps we
    can get cycles per multiplication ratio closer to 1, or whatever the “cost” of
    native multiplication is?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，广泛使用的语言（如 Python）的解释器已经进行了很好的优化，并且可以在重复执行相同代码时跳过一些步骤。但是，由于语言设计，一些相当显著的开销是不可避免的。如果我们去掉所有这些类型检查和指针追踪，也许我们可以将每乘法的周期比接近
    1，或者接近原生乘法的“成本”？
- en: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#managed-languages)Managed
    Languages'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#managed-languages)托管语言'
- en: 'The same matrix multiplication procedure, but implemented in Java:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前相同的矩阵乘法过程，但使用 Java 实现：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It now runs in 10 seconds, which amounts to roughly 13 CPU cycles per multiplication
    — 63 times faster than Python. Considering that we need to read elements of `b`
    non-sequentially from the memory, the running time is roughly what it is supposed
    to be.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在它运行需要10秒，相当于每次乘法大约13个CPU周期——比Python快63倍。考虑到我们需要从内存中非顺序地读取`b`的元素，运行时间大致符合预期。
- en: Java is a *compiled*, but not *native* language. The program first compiles
    to *bytecode*, which is then interpreted by a virtual machine (JVM). To achieve
    higher performance, frequently executed parts of the code, such as the innermost
    `for` loop, are compiled into the machine code during runtime and then executed
    with almost no overhead. This technique is called *just-in-time compilation*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Java是一种*编译型*，但不是*原生型*语言。程序首先编译成*字节码*，然后由虚拟机（JVM）进行解释。为了达到更高的性能，代码中经常执行的部分，例如最内层的`for`循环，在运行时被编译成机器码，然后几乎无开销地执行。这种技术被称为*即时编译*。
- en: JIT compilation is not a feature of the language itself, but of its implementation.
    There is also a JIT-compiled version of Python called [PyPy](https://www.pypy.org/),
    which needs about 12 seconds to execute the code above without any changes to
    it.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: JIT编译不是语言本身的功能，而是其实现的功能。还有一个名为[PyPy](https://www.pypy.org/)的Python JIT编译版本，它执行上述代码需要大约12秒，而且没有任何修改。
- en: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#compiled-languages)Compiled
    Languages'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#compiled-languages)编译型语言'
- en: 'Now it’s turn for C:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到C了：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It takes 9 seconds when you compile it with `gcc -O3`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用`gcc -O3`编译它，它需要9秒。
- en: It doesn’t seem like a huge improvement — the 1-3 second advantage over Java
    and PyPy can be attributed to the additional time of JIT-compilation — but we
    haven’t yet taken advantage of a far better C compiler ecosystem. If we add `-march=native`
    and `-ffast-math` flags, time suddenly goes down to 0.6 seconds!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来并不像是一个巨大的改进——Java和PyPy超过1-3秒的优势可以归因于JIT编译的额外时间——但我们还没有充分利用一个更好的C编译器生态系统。如果我们添加`-march=native`和`-ffast-math`标志，时间突然下降到0.6秒！
- en: What happened here is we [communicated to the compiler](/hpc/compilation/flags/)
    the exact model of the CPU we are running (`-march=native`) and gave it the freedom
    to rearrange [floating-point computations](/hpc/arithmetic/float) (`-ffast-math`),
    and so it took advantage of it and used [vectorization](/hpc/simd) to achieve
    this speedup.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生的事情是我们向编译器[传达了](/hpc/compilation/flags/)我们正在运行的CPU的确切模型(`-march=native`)，并给它自由去重新排列[浮点运算](/hpc/arithmetic/float)(`-ffast-math`)，因此它利用了这一点，并使用[向量化](/hpc/simd)来实现这个加速。
- en: It’s not like it is impossible to tune the JIT-compilers of PyPy and Java to
    achieve the same performance without significant changes to the source code, but
    it is certainly easier for languages that compile directly to native code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 并不是不可能调整PyPy和Java的JIT编译器以实现相同性能而不对源代码进行重大修改，但显然对于直接编译成原生代码的语言来说更容易。
- en: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#blas)BLAS'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#blas)BLAS'
- en: 'Finally, let’s take a look at what an expert-optimized implementation is capable
    of. We will test a widely-used optimized linear algebra library called [OpenBLAS](https://www.openblas.net/).
    The easiest way to use it is to go back to Python and just call it from `numpy`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看一个专家优化的实现能做什么。我们将测试一个广泛使用的优化线性代数库，称为[OpenBLAS](https://www.openblas.net/)。使用它的最简单方法是回到Python，并从`numpy`中调用它：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now it takes ~0.12 seconds: a ~5x speedup over the auto-vectorized C version
    and ~5250x speedup over our initial Python implementation!'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在它需要大约0.12秒：比自动向量化C版本快5倍，比我们最初的Python实现快5250倍！
- en: You don’t typically see such dramatic improvements. For now, we are not ready
    to tell you exactly how this is achieved. Implementations of dense matrix multiplication
    in OpenBLAS are typically [5000 lines of handwritten assembly](https://github.com/xianyi/OpenBLAS/blob/develop/kernel/x86_64/dgemm_kernel_16x2_haswell.S)
    tailored separately for *each* architecture. In later chapters, we will explain
    all the relevant techniques one by one, and then [return](/hpc/algorithms/matmul)
    to this example and develop our own BLAS-level implementation using just under
    40 lines of C.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常不会看到如此戏剧性的改进。目前，我们还没有准备好告诉你这是如何实现的。OpenBLAS中密集矩阵乘法的实现通常是针对*每个*架构定制的5000行手写汇编代码（[查看代码](https://github.com/xianyi/OpenBLAS/blob/develop/kernel/x86_64/dgemm_kernel_16x2_haswell.S)）。在后面的章节中，我们将逐一解释所有相关技术，然后[返回](/hpc/algorithms/matmul)到这个例子，并使用不到40行的C代码开发我们自己的BLAS级实现。
- en: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#takeaway)Takeaway'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/complexity/languages/#takeaway)总结'
- en: The key lesson here is that using a native, low-level language doesn’t necessarily
    give you performance; but it does give you *control* over performance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键教训是，使用本地、低级语言并不一定能带来性能；但它确实能让你对性能拥有*控制*。
- en: 'Complementary to the “N operations per second” simplification, many programmers
    also have a misconception that using different programming languages has some
    sort of multiplier on that number. Thinking this way and [comparing languages](https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html)
    in terms of performance doesn’t make much sense: programming languages are fundamentally
    just tools that take away *some* control over performance in exchange for convenient
    abstractions. Regardless of the execution environment, it is still largely a programmer’s
    job to use the opportunities that the hardware provides. [← Modern Hardware](https://en.algorithmica.org/hpc/complexity/hardware/)[../Computer
    Architecture →](https://en.algorithmica.org/hpc/architecture/)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与“每秒N次操作”的简化说法相辅相成，许多程序员也存在一种误解，认为使用不同的编程语言会在那个数字上产生某种乘数效应。以这种方式思考并将语言[比较](https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html)性能并不太有意义：编程语言本质上只是工具，它们以方便的抽象为代价，减少了*一些*对性能的控制。无论执行环境如何，程序员仍然主要需要利用硬件提供的机遇。[←现代硬件](https://en.algorithmica.org/hpc/complexity/hardware/)[→计算机架构](https://en.algorithmica.org/hpc/architecture/)
