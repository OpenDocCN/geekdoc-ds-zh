- en: Chapter 9 Input and Output
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 输入和输出
- en: 原文：[https://randpythonbook.netlify.app/input-and-output](https://randpythonbook.netlify.app/input-and-output)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://randpythonbook.netlify.app/input-and-output](https://randpythonbook.netlify.app/input-and-output)'
- en: 9.1 General Input Considerations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 一般输入考虑
- en: So far, this text has been favoring the creation of small pieces of data *within
    our scripts.* The avoidance of reading in data from an external file has been
    avoided primarily for pedagogical purposes. In general, one might have
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本文档一直倾向于在脚本中创建小块数据 *within our scripts.* 避免从外部文件读取数据主要是出于教学目的。一般来说，可能会
- en: data read in from a plain text file (e.g. `"my_data.csv"` or `"log_file.txt"`
    ),
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从纯文本文件（例如`"my_data.csv"`或`"log_file.txt"`）读取的数据，
- en: data read in from a database (e.g. MySQL, PostgreSQL, etc.), or
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据库（例如MySQL、PostgreSQL等）读取的数据，或
- en: data created in a script (either deterministically or randomly).
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在脚本中创建的数据（无论是确定性的还是随机的）。
- en: 'When discussing reading in data, this text mostly focuses on the first category.
    Here are the reasons for its doing so:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论读取数据时，本文档主要关注第一类。这样做的原因如下：
- en: text-files are more readily-available to students than databases,
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本文件比数据库更容易为学生所获取，
- en: teaching the second category requires teaching SQL, and that would introduce
    conceptual overlap, and
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 教授第二类需要教授SQL，这将引入概念上的重叠，
- en: the third category is programmatically self-explanatory.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三类是程序上自我解释的。
- en: 'The third reason does not imply data created by code is unimportant. For example,
    it is the most common approach to create data used in **simulation studies.**
    Authors writing statistical papers need to demonstrate that their techniques work
    on “nice” data: data simulated from a *known* data-generating process. In a simulation
    study, unlike in the “real-world,” you have access to the parameters generating
    your data, and you can examine data that might otherwise be unobserved or hidden.
    Further, with data from the real-world, there is no guarantee your model correctly
    matches the true model.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种原因并不意味着由代码创建的数据不重要。例如，它是创建用于 **模拟研究** 中数据最常见的方法。撰写统计论文的作者需要证明他们的技术可以在“良好”的数据上工作：从
    *已知* 的数据生成过程中模拟的数据。在模拟研究中，与“现实世界”不同，你可以访问生成你数据的参数，并检查可能无法观察或隐藏的数据。此外，从现实世界的数据中，无法保证你的模型正确地匹配了真实模型。
- en: Can your code/technique/algorithm, at the very least, obtain parameter estimates
    that are “in-line” with the parameters your code is using to simulate data? Are
    forecasts or predictions obtained by your method accurate? These kinds of questions
    can often only be answered by simulating fake data. Programmatically, simulating
    data like this largely involves calling functions that we have seen before (e.g. `rnorm()`
    in R or `np.random.choice()` in Python). This may or may not involve setting a
    pseudorandom number seed, first, for reproducibility.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你的代码/技术/算法，至少，能否获得与你的代码用于模拟数据的参数“一致”的参数估计？通过你的方法获得的预测或预测是否准确？这些问题通常只能通过模拟假数据来回答。程序上，模拟此类数据主要涉及调用我们之前见过的函数（例如R中的`rnorm()`或Python中的`np.random.choice()`）。这可能或可能不涉及首先设置伪随机数种子，以实现可重复性。
- en: Also, *benchmark data sets* are often readily available through specialized
    function calls.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*基准数据集* 通常可以通过专门的函数调用轻松获取。
- en: Even though this chapter is written to teach you how to read in files into R
    and Python, you should not expect that you will know how to read in *all* data
    sets after reading this section. For both R and Python, there are an enormous
    amount of functions, different functions have different return types, different
    functions are suited for different file types, many functions are spread across
    a plethora of third party libraries, and many of these functions have an enormous
    amount of arguments. You will probably not be able to memorize everything. In
    my very humble opinion, I doubt you should want to.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一章的目的是教你如何将文件读入R和Python，但你不应期望在阅读这一节后就能知道如何读取 *所有* 数据集。对于R和Python，都有大量的函数，不同的函数有不同的返回类型，不同的函数适用于不同的文件类型，许多函数散布在众多第三方库中，而且许多这些函数有大量的参数。你可能无法记住所有这些。以我非常谦卑的观点来看，我怀疑你是否有这样的愿望。
- en: Instead, **focus on developing your ability to identify and diagnose data input
    problems.** Reading in a data set correctly is often a process of trial-and-error.
    After attempting to read in a data set, always check the following items. Many
    of these points were previously mentioned in section @(data-frames-in-r). Some
    apply to reading in text data more than reading in structured data from a database,
    and vice versa.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，**专注于提高你识别和诊断数据输入问题的能力。** 正确读取数据集通常是一个试错的过程。在尝试读取数据集后，始终检查以下项目。其中许多点在前面提到的
    @(data-frames-in-r) 部分中已经提到。有些点比从数据库读取结构化数据读取文本数据更适用，反之亦然。
- en: Check that **the correct column *separator* was used, or the correct “fixed-width
    format” was expected.** If mistakes are made, data frame columns are going to
    be combined or split apart in weird ways, and often the wrong types are going
    to be used for pieces of data (e.g. `"2,3"` instead of `2` and `3`.) Also, watch
    out for when separators are found inside data elements or column names. For example,
    sometimes it’s unclear whether people’s names in the “last, first” format can
    be stored in one or two columns. Also, text data might surprise you with unexpected
    spaces or other whitespace is a common separator.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查**是否使用了正确的列分隔符，或者期望了正确的“固定宽度格式”。** 如果出错，数据框的列可能会以奇怪的方式合并或拆分，并且通常会对数据片段使用错误的数据类型（例如，“2,3”而不是
    `2` 和 `3`）。此外，注意分隔符是否出现在数据元素或列名称中。例如，有时不清楚以“last, first”格式存储的人名是否可以存储在一列或两列中。此外，文本数据可能会让你惊讶于意外的空格或其他空白字符作为分隔符。
- en: Check that **the column names were parsed and stored correctly.** Column names
    should not be stored as data in R/Python. Functions that read in data should not
    expect column names when they don’t exist in the actual file.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查**列名是否正确解析和存储。** 列名不应作为 R/Python 中的数据存储。读取数据的函数不应期望在文件中不存在列名时存在列名。
- en: Check that **empty space and metadata was ignored correctly.** Data descriptions
    are sometimes stored in the same file as the data itself, and that should be skipped
    over when it’s being read in. Empty space between column names and data shouldn’t
    be stored. This can occur at the beginning of the file, and even at the end of
    the file.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查**空格和元数据是否正确忽略。** 数据描述有时与数据本身存储在同一个文件中，在读取时应跳过。列名和数据之间的空格不应存储。这可能会出现在文件的开始处，甚至出现在文件的末尾。
- en: '**Check that type choice and recognition of special characters are performed
    correctly.** Are letters stored as strings or as something else such as an R `factor`?
    Are dates and times stored as a special date/time type, or as strings? Is missing
    data correctly identified? Sometimes data providers use outrageous numbers like
    \(-9999\) to represent missing data–don’t store that as a float or integer!'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检查类型选择和特殊字符的识别是否正确执行。** 字母是以字符串存储还是以其他方式存储，例如 R 的 `factor`？日期和时间是以特殊的日期/时间类型存储还是以字符串存储？缺失数据是否正确识别？有时数据提供者使用像
    \(-9999\) 这样的极端数字来表示缺失数据——不要将其存储为浮点数或整数！'
- en: '**Be ready to prompt R or Python to recognize a specific character encoding
    if you are reading in text data written in another language.** All text data has
    a character encoding, which is a mapping of numbers to characters. Any specific
    encoding will dictate what characters are recognizable in a program. If you try
    to read in data written in another language, the function you are using will likely
    complain about unrecognized characters. Fortunately, these errors and warnings
    are easily fixed by specifying a nondefault argument such as `encoding=` or `fileEncoding=`.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备好提示 R 或 Python 识别特定字符编码，如果你正在读取用其他语言编写的文本数据。** 所有文本数据都有字符编码，这是一种将数字映射到字符的映射。任何特定的编码都将决定程序中可识别的字符。如果你尝试读取用另一种语言编写的文本数据，你使用的函数可能会抱怨无法识别的字符。幸运的是，通过指定非默认参数，如
    `encoding=` 或 `fileEncoding=`，这些错误和警告很容易修复。'
- en: 'This is no small task. To make matters worse:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一项小任务。更糟糕的是：
- en: you can’t (or shouldn’t) edit the raw data to suit your needs, to make it easier
    to read in. You have to work with what you are given. If you were allowed to edit,
    say, a text file you downloaded onto your own machine, you shouldn’t–it will lead
    to code that doesn’t run anywhere else. Additionally, if you abuse write privileges
    on your company’s database, for example–that could be very dangerous as well.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能（或不应该）编辑原始数据以满足你的需求，使其更容易阅读。你必须处理你得到的数据。如果你被允许编辑，比如说，你下载到自己的机器上的文本文件，你不应该这样做——这会导致代码在其他任何地方都无法运行。此外，如果你滥用公司数据库的写权限，例如——这也可能非常危险。
- en: Data sets are often quite large, so manually checking each element is often
    impossible. In this situation you will have to resign yourself to checking the
    top and bottom of a data set, or maybe anticipate a specific place where problems
    are likely to appear.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集通常相当大，所以手动检查每个元素通常是不可能的。在这种情况下，你必须接受检查数据集的顶部和底部，或者可能预测一个可能出现问题的特定位置。
- en: 9.2 Reading in Text Files with R
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 使用 R 读取文本文件
- en: You’ve seen examples of `read.csv()` used earlier in the book, so it should
    not surprise you that this is one of the most common ways to read in data in R.
    Another important function is `read.table()`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本书中已经看到了 `read.csv()` 的示例，所以这不应该让你感到惊讶，这是在 R 中读取数据最常见的方法之一。另一个重要的函数是 `read.table()`。
- en: If you look at the source code for `read.csv()` (type the name of the function
    without parentheses into the console and press the `<Enter>` key), you will see
    it calls `read.table()`. The primary difference between these functions is default
    arguments. **Mind the default arguments.** Do not be completely averse to writing
    a long-line of code to read in a data set correctly. Or do, and choose the function
    with the best default arguments.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 `read.csv()` 的源代码（在控制台中输入函数名称（不带括号）并按 `<Enter>` 键），你会看到它调用了 `read.table()`。这两个函数的主要区别在于默认参数。**注意默认参数**。不要完全反对写一行长的代码来正确读取数据集。或者，如果你这样做，请选择具有最佳默认参数的函数。
- en: Consider the [“Challenger USA Space Shuttle O-Ring Data Set”](https://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring)
    from (Dua and Graff [2017](#ref-uci_data)). The first few rows of the raw text
    file[^(14)](#fn14) looks like this.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下来自（Dua 和 Graff [2017](#ref-uci_data)）的“Challenger USA Space Shuttle O-Ring
    数据集”（[“Challenger USA Space Shuttle O-Ring Data Set”](https://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring)）。原始文本文件的前几行[^(14)](#fn14)看起来像这样。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It does not use commas as separators, and there is no header information, so
    `read.csv()` used with its default arguments will produce an incorrect result.
    It will miss the first row by counting it as a column name, and store everything
    in one column with the wrong type.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 它不使用逗号作为分隔符，也没有标题信息，所以使用默认参数的 `read.csv()` 会产生错误的结果。它会将第一行误认为是列名，并将所有内容存储在一个错误的类型的列中。
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Specifying `header=FALSE` fixes the column name issue, but `sep = " "` does
    not fix the separator issue.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 指定 `header=FALSE` 解决了列名问题，但 `sep = " "` 并没有解决分隔符问题。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: One space is strictly one space. Some rows have two, though. This causes there
    to be two too many columns filled with `NA`s.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个空格严格是一个空格。尽管有些行有两个空格。这导致有两个多余的列填充了 `NA`。
- en: After digging into the documentation a bit further, you will notice that `""`
    works for “one or more spaces, tabs, newlines or carriage returns.” This is why
    `read.table()`, with its default arguments, works well.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步挖掘文档之后，你会注意到 `""` 对“一个或多个空格、制表符、换行符或回车符”有效。这就是为什么 `read.table()`（使用其默认参数）工作得很好。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This data set has columns whose widths are “fixed”, too. It is in “fixed width
    format” because any given column has all its elements take up a constant amount
    of characters. The third column has integers with two or three digits, but no
    matter what, each row has the same number of characters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的列宽度也是“固定”的。它处于“固定宽度格式”，因为任何给定列的所有元素都占用固定数量的字符。第三列包含两位或三位数的整数，但无论如何，每一行都有相同数量的字符。
- en: You may choose to exploit this and use a specialized function that reads in
    data in a fixed width format (e.g. `read.fwf()`). The frustrating thing about
    this approach, though, is that you have to specify what those widths are. This
    can be quite tedious, particularly if your data set has many columns and/or many
    rows. The upside though, is that the files can be a little bit smaller, because
    the data provider does not have to waste characters on separators.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择利用这一点并使用一个专门的功能来读取固定宽度的数据（例如`read.fwf()`）。然而，这种方法的一个令人沮丧的地方是，你必须指定这些宽度是什么。这可能会相当繁琐，尤其是如果你的数据集有很多列和/或很多行。然而，好处是文件可以稍微小一点，因为数据提供者不需要在分隔符上浪费字符。
- en: In the example below, we specify widths that include blank spaces to the left
    of the digits. On the other hand, if we specified `widths=c(2,2,4,4,1)`, which
    includes spaces to the *right* of digits, then columns would have been recognized
    as `character`s.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们指定了包含数字左侧空格的宽度。另一方面，如果我们指定`widths=c(2,2,4,4,1)`，这包括数字右侧的空格，那么列就会被识别为`字符`s。
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you need to read in some text data that does not possess a tabular structure,
    then you may need `readLines()`. This function will read in all of the text, separate
    each line into an element of a `character` `vector`, and will not make any attempt
    to parse lines into columns. Further processing can be accomplished using the
    techniques from section [3.9](/r-vectors-versus-numpy-arrays-and-pandas-series#an-introduction-to-regular-expressions).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要读取一些不具有表格结构的文本数据，那么你可能需要使用`readLines()`。这个函数将读取所有文本，将每一行分离成一个`字符`向量的元素，并且不会尝试将行解析为列。进一步的处理可以使用第[3.9](/r-vectors-versus-numpy-arrays-and-pandas-series#an-introduction-to-regular-expressions)节中的技术完成。
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Some of you may have had difficulty reading in the above data. This can happen
    if your machine’s default character encoding is different than mine. For instance,
    if your character encoding is [“GBK”](https://en.wikipedia.org/wiki/GBK_(character_encoding)),
    then you might get a warning message like “invalid input found on input connection.”
    This message means that your machine didn’t recognize some of the characters in
    the data set.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一些人在读取上面的数据时可能遇到了困难。这可能是因为你的机器的默认字符编码与我的不同。例如，如果你的字符编码是[“GBK”](https://en.wikipedia.org/wiki/GBK_(character_encoding))，那么你可能会收到一条警告信息，例如“在输入连接上找到无效输入。”这条信息意味着你的机器没有识别数据集中的一些字符。
- en: These errors are easy to fix, though, so don’t worry. Just specify an encoding
    argument in your function that reads in data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些错误很容易修复，所以不要担心。只需在读取数据的函数中指定一个编码参数即可。
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 9.3 Reading in Text Files with Pandas
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 使用Pandas读取文本文件
- en: A [wide variety of different file formats can be read in with Pandas.](https://pandas.pydata.org/pandas-docs/stable/reference/io.html)
    I will only mention a few functions here.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas可以读取多种不同的文件格式。[广泛的文件格式可以通过Pandas读取](https://pandas.pydata.org/pandas-docs/stable/reference/io.html)。在这里，我将只提及几个函数。
- en: Recall R has `read.table()` and `read.csv()`, and that they are very similar.
    In Pandas, [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)
    and [`pd.read_table()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html)
    have a lot in common, too. Their primary difference is the default column separator,
    as well.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 回想R中的`read.table()`和`read.csv()`，它们非常相似。在Pandas中，`pd.read_csv()`和`pd.read_table()`也有很多共同之处。它们的主要区别在于默认的列分隔符。
- en: Recall the O-Ring data from above. The columns are *not* separated by commas,
    so if we treat it as a comma-separated file, the resulting Pandas `DataFrame`
    is going to be missing all but one of its columns.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下上面的O-Ring数据。列之间没有用逗号分隔，所以如果我们将其视为逗号分隔的文件，结果中的Pandas `DataFrame`将丢失除一列之外的所有列。
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: By default, `pd.read_csv()` is expecting column labels, which is also a problem.
    Unlike R, though, the `header=` argument is not expected to be a Boolean. You
    will need to provide a `None`, instead. The separator needs to be just right,
    too.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`pd.read_csv()`期望列标签，这也是一个问题。与R不同，`header=`参数不需要是一个布尔值。你需要提供一个`None`。分隔符也需要恰到好处。
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Reading in fixed width files can be done in a way that is nearly identical to
    the way we did it in R. Here is an example.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以几乎与我们在R中做的方式读取固定宽度文件。以下是一个示例。
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you had chosen `widths=[2,2,4,4,1]`, instead, then the trailing whitespace
    will cause Pandas to recognize a `dtype` of `object`. The reason it is not recognized
    as a string is because strings can be of different length, and all string types
    specify a maximum length. If you want to enforce a maximum length, there may be
    some speed advantages. In the below example, we use [`d.astype()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html)
    to convert two columns’ types to [`pd.StringDtype`](https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas.StringDtype).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择了 `widths=[2,2,4,4,1]`，那么尾随空格将导致 Pandas 识别一个 `dtype` 为 `object`。它没有被识别为字符串的原因是字符串可以有不同长度，所有字符串类型都指定了最大长度。如果你想强制最大长度，可能会有一些速度优势。在下面的例子中，我们使用
    `d.astype()` 将两列的类型转换为 `pd.StringDtype`。
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Just like in R, you may run into an encoding issue with a file. For instance,
    the following will not work because the file contains Chinese characters. If you
    mostly work with UTF-8 files, you will receive a `UnicodeDecodeError` if you try
    to run the following code.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在 R 中一样，你可能会遇到文件编码问题。例如，以下代码将无法运行，因为文件包含中文字符。如果你主要处理 UTF-8 文件，当你尝试运行以下代码时，你会收到一个
    `UnicodeDecodeError`。
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: However, the error messages disappear when you specify `encoding="gbk"`.[^(15)](#fn15)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当你指定 `encoding="gbk"` 时，错误信息就会消失。[^(15)](#fn15)
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You may also read in unstructured, nontabular data with Python. Use the built-in
    [`open()`](https://docs.python.org/3/library/functions.html#open) function to
    open up a file in read mode, and then use `f.readlines()` to return a `list` of
    strings.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 Python 读取非结构化、非表格数据。使用内置的 `open()` 函数以读取模式打开一个文件，然后使用 `f.readlines()`
    返回一个字符串的 `list`。
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 9.4 Saving Data in R
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 在 R 中保存数据
- en: Storing data is important for saving your progress. For example, sometimes running
    a script that performs data cleaning can take a very long time. Saving your progress
    might free you from the responsibility of running that script many times.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 保存数据对于保存你的进度很重要。例如，有时运行执行数据清洗的脚本可能需要非常长的时间。保存你的进度可能会让你摆脱多次运行该脚本的责任。
- en: 'In R, there are many options for storing data. I will mention two: writing
    data out to a plain text file, and saving a serialized object.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中，有许多存储数据的选择。我将提到两个：将数据写入纯文本文件，以及保存序列化对象。
- en: 9.4.1 Writing Out Tabular Plain Text Data in R
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 在 R 中写入表格纯文本数据
- en: 'If you want to write out tabular data to a text file, use `write.table()` or
    `write.csv()`. There are two arguments that you must specify, at a minimum: the
    first argument is your R object (typically a `matrix` or `data.frame`), and the
    second argument is the file path on your hard drive.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要将表格数据写入文本文件，请使用 `write.table()` 或 `write.csv()`。至少有两个参数你必须指定：第一个参数是你的 R
    对象（通常是 `matrix` 或 `data.frame`），第二个参数是硬盘上的文件路径。
- en: Here is an example of writing out `d` to a file called `"oring_out.csv"`. I
    choose to include column names, but not row names. I also use commas to separate
    columns.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个将 `d` 写入名为 `"oring_out.csv"` 的文件的例子。我选择包含列名，但不包括行名。我还使用逗号分隔列。
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The above will not print anything to the R console, but we can use a text editor
    to take a look at the raw text file on our hard drive. Here are the first three
    rows.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码不会在 R 控制台中打印任何内容，但我们可以使用文本编辑器查看硬盘上的原始文本文件。以下是前三行。
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 9.4.2 Serialization in R
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 R 中的序列化
- en: Alternatively you may choose to store your data in a **serialized** form. With
    this approach, you are still saving your data in a more permanent way to your
    hard drive, but it is stored in format that’s usually more memory efficient.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以选择以**序列化**的形式存储你的数据。采用这种方法，你仍然以更永久的方式将数据保存到硬盘上，但它以通常更节省内存的格式存储。
- en: 'Recall that a common reason for writing out data is to save your progress.
    When you want to save your progress, it is important to ask yourself: “is it better
    to save my progress as a serialized object, or as a raw text file?”'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，写入数据的一个常见原因是保存你的进度。当你想要保存进度时，重要的是要问自己：“将我的进度保存为序列化对象，还是保存为原始文本文件更好？”
- en: When making this decision, consider *versatility.* On the one hand, raw text
    files are more versatile and can be used in more places. On the other hand, versatility
    is often bug prone.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在做出这个决定时，请考虑*多功能性*。一方面，原始文本文件更灵活，可以在更多地方使用。另一方面，多功能性往往容易出错。
- en: For example, suppose you want to save a cleaned up `data.frame`. Are you sure
    you will remember to store that column of strings as `character` and not a `factor`?
    Does any code that uses this `data.frame` require that this column be in this
    format?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想保存一个清理过的`data.frame`。你确定你会记得将那一列字符串存储为`character`而不是`factor`吗？使用此`data.frame`的任何代码是否需要这一列以这种格式存在？
- en: For instance, let’s save the object `d` in a file called `oring.rds`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们将对象`d`保存到名为`oring.rds`的文件中。
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: After it is saved with `saveRDS()`, we are free to delete the variable with
    `rm()`, because it can be read back in later on. To do this, call `readRDS()`.
    This is file has a special format that is recognized by R, so you will not need
    to worry about any of the usual struggles that occur when reading in data from
    a plain text file. Additionally, `.rds` files are typically smaller–`oring.rds`
    is only 248 bytes, while `"oring_out.csv"` is 332 bytes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`saveRDS()`保存后，我们可以自由地使用`rm()`删除变量，因为稍后可以再次读取。为此，请调用`readRDS()`。这个文件有一个R能识别的特殊格式，因此你不需要担心从纯文本文件读取数据时通常遇到的任何问题。此外，`.rds`文件通常更小——`oring.rds`只有248字节，而`"oring_out.csv"`是332字节。
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You can serialize multiple objects at once, too! Convention dictates that these
    files end with the `.RData` suffix. Save your entire global environment with `save()`
    or `save.image()`, and bring it back with `load()` or `attach()`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以一次序列化多个对象！惯例规定这些文件以`.RData`后缀结尾。使用`save()`或`save.image()`保存整个全局环境，然后使用`load()`或`attach()`恢复。
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 9.5 Saving Data in Python
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 Python中的数据保存
- en: 9.5.1 Writing Out Tabular Plain Text Data in Python
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 Python中写入表格纯文本数据
- en: You can write out tabular data with a variety of [`DataFrame` methods that are
    named `to_*()`.](https://pandas.pydata.org/pandas-docs/stable/reference/io.html#input-output).
    [`pd.DataFrame.to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv)
    has a lot of common with `write.csv()` in R. Below we write out `d` to a file
    called `oring_out2.csv`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用各种名为`to_*()`的`DataFrame`方法写出表格数据。[`to_*()`方法](https://pandas.pydata.org/pandas-docs/stable/reference/io.html#input-output)。`pd.DataFrame.to_csv()`与R中的`write.csv()`有很多相似之处。以下我们将`d`写入名为`oring_out2.csv`的文件。
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here is how the first few rows of that file looks in a text editor.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本编辑器中，该文件的几行如下所示。
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 9.5.2 Serialization in Python
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.2 Python中的序列化
- en: Serialization functionality is readily available in Python, just like it is
    in R. In Python, the [`pickle`](https://docs.python.org/3/library/pickle.html)
    and `cPickle` libraries are probably the most commonly used. Serializing objects
    with these libraries is known as *pickling* an object.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Python中序列化功能很容易获得，就像在R中一样。在Python中，`pickle`和`cPickle`库可能是最常用的。使用这些库序列化对象被称为*序列化*对象。
- en: Pandas has a [`.to_pickle()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)
    wrapper method attached to every `DataFrame`. Once the pickled object is saved,
    the file can be read back into Python with [`pd.read_pickle()`](https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html#pandas.read_pickle).
    These functions are extremely convenient, because they call all the required `pickle`
    code and hide a decent amount of complexity.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas为每个`DataFrame`附加了一个`.to_pickle()`包装方法。[`.to_pickle()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)。一旦保存了序列化对象，就可以使用`pd.read_pickle()`[`.read_pickle()`](https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html#pandas.read_pickle)将其读回到Python中。这些函数非常方便，因为它们调用所有必要的`pickle`代码，并隐藏了大量复杂性。
- en: Here is an example of writing out `d` and then reading the pickled object back
    in. In Python 3, the file suffix for pickled objects is usually `.pickle`, but
    there are many other choices.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例，展示了如何先写出`d`，然后读取回序列化的对象。在Python 3中，序列化对象的文件后缀通常是`.pickle`，但有许多其他选择。
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Unfortunately, `"oring.pickle"` is much larger (1,676 bytes) than the original
    text file `"o-ring-erosion-only.data"` (322 bytes). This is for two reasons. First,
    the original data set is small, so the overhead of pickling this object is relatively
    pronounced, and second, we are not taking advantage of any compression. If you
    use something like `d_is_back.to_pickle("data/oring.zip")` it will become smaller.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，`"oring.pickle"`比原始文本文件`"o-ring-erosion-only.data"`（322字节）大得多（1,676字节）。这是两个原因造成的。首先，原始数据集很小，因此序列化此对象的开销相对较大，其次，我们没有利用任何压缩。如果你使用类似`d_is_back.to_pickle("data/oring.zip")`的方法，它将变得更小。
- en: In Python, unlike in R, it is more difficult to serialize all of the objects
    you currently have in memory. It is possible, but it will likely require the use
    of a third-party library.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，与 R 不同，将当前内存中的所有对象序列化更为困难。虽然可能实现，但可能需要使用第三方库。
- en: 'Speaking of third-party code, there are many that provide alternative serialization
    solutions in both R and Python. I do not discuss any in this text. However, I
    will mention that some of them may provide combinations of the following: an increase
    in read and write speed, a decrease in required memory, improved security[^(16)](#fn16),
    improved human readability and interoperability between multiple programming languages.
    If any of these sound potentially beneficial, I encourage you to conduct further
    research.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到第三方代码，有许多提供 R 和 Python 中替代序列化解决方案的代码。在此文本中，我没有讨论任何一种。然而，我将提到其中一些可能提供以下组合：提高读写速度、减少所需内存、提高安全性[^(16)](#fn16)、提高人类可读性和多编程语言之间的互操作性。如果其中任何一项听起来可能有益，我鼓励您进行进一步的研究。
- en: 9.6 Exercises
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.6 练习
- en: 9.6.1 R Questions
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.6.1 R 问题
- en: Consider again the data set called `"gspc.csv"`, which contains daily open,
    high, low and close values for the S&P500 Index.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑名为 `"gspc.csv"` 的数据集，它包含 S&P500 指数的每日开盘价、最高价、最低价和收盘价。
- en: Read in this data set as a `data.frame`, and call it `myData`. Do not include
    the code that achieves this in your assignment submission.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此数据集作为 `data.frame` 读取，并命名为 `myData`。不要在作业提交中包含实现此功能的代码。
- en: Write out this object as `myData.rds`. After you are finished, remove `myData`
    from memory. Do not include the code that achieves this in your assignment submission.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此对象写入为 `myData.rds`。完成后，从内存中删除 `myData`。不要在作业提交中包含实现此功能的代码。
- en: Read in `myData.rds`, and store the variable as `financialData`. *Do* include
    the code that achieves this in your project submission. Make sure this code assumes
    that `myData.rds` is in the same folder as the code file `io_lab.R`.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `myData.rds`，并将变量存储为 `financialData`。*必须*在项目提交中包含实现此功能的代码。确保此代码假设 `myData.rds`
    与代码文件 `io_lab.R` 在同一文件夹中。
- en: 9.6.2 Python Questions
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.6.2 Python 问题
- en: We will use the `"Google.html"` data set mentioned in the chapter.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用章节中提到的 `"Google.html"` 数据集。
- en: Use `open()` to open the `"Google.html"` file. Store the output of the function
    as `my_file`.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `open()` 打开 `"Google.html"` 文件。将函数的输出存储为 `my_file`。
- en: Use the `.readlines()` method of the file to write the contents of the file
    as a `list` called `html_data`
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用文件的 `.readlines()` 方法将文件内容写入名为 `html_data` 的列表。
- en: Coerce the `list` to a `DataFrame` with one column called `html`
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `list` 强制转换为具有一个名为 `html` 的列的 `DataFrame`。
- en: 'Create a `Series` called `nchars_ineach` that stores the number of characters
    in each line of text. Hint: the [`Series.str` attribute has a lot of helpful methods](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#api-series-str).'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `nchars_ineach` 的 `Series`，用于存储文本每行的字符数。提示：`Series.str` 属性有很多有用的方法（[Series.str
    属性有很多有用的方法](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#api-series-str)）。
- en: Create an `int`-like variable called `num_div_tags` that holds the total number
    of times the phrase “`<div>`” appears in the file.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个类似于 `int` 的变量 `num_div_tags`，用于存储短语 “`<div>`” 在文件中出现的总次数。
- en: Consider the data set called `"gspc.csv"`, which contains daily open, high,
    low and close values for the S&P500 Index.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑名为 `"gspc.csv"` 的数据集，它包含 S&P500 指数的每日开盘价、最高价、最低价和收盘价。
- en: Read in this data set as a `DataFrame`, and call it `my_data`. Do not include
    the code that achieves this in your assignment submission.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此数据集作为 `DataFrame` 读取，并命名为 `my_data`。不要在作业提交中包含实现此功能的代码。
- en: Write out this object as `"my_data.pickle"`. After you are finished, remove
    `my_data` from memory. Do not include the code that achieves this in your assignment
    submission.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此对象写入为 `"my_data.pickle"`。完成后，从内存中删除 `my_data`。不要在作业提交中包含实现此功能的代码。
- en: Read in `"my_data.pickle"`, and store the variable as `financial_data`. *Do*
    include the code that achieves this in your project submission. Make sure this
    code assumes that `"my_data.pickle"` is in the same folder as the code file `io_lab.py`.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `"my_data.pickle"`，并将变量存储为 `financial_data`。*必须*在项目提交中包含实现此功能的代码。确保此代码假设
    `"my_data.pickle"` 与代码文件 `io_lab.py` 在同一文件夹中。
- en: References
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: Dua, Dheeru, and Casey Graff. 2017\. “UCI Machine Learning Repository.” University
    of California, Irvine, School of Information; Computer Sciences. [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Dua, Dheeru, 和 Casey Graff. 2017. “UCI机器学习仓库.” 加州大学欧文分校，信息学院；计算机科学系. [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
- en: '* * *'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Open raw text files with text editor programs, not with programs that perform
    any kind of processing. For instance, if you open it with Microsoft Excel, the
    appearance of the data will change, and important information helping you to read
    your data into R or Python will not be available to you.[↩](/input-and-output#fnref14)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用文本编辑程序打开原始文本文件，而不是使用执行任何类型处理的程序。例如，如果您用Microsoft Excel打开它，数据的外观将发生变化，而且重要的信息，帮助您将数据读入R或Python的信息将无法供您使用。[↑](/input-and-output#fnref14)
- en: A list of more options of encodings that are built into Python,are available
    [here.](https://docs.python.org/3/library/codecs.html#standard-encodings)[↩](/input-and-output#fnref15)
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python内置的编码选项列表[在此处](https://docs.python.org/3/library/codecs.html#standard-encodings)提供。[↑](/input-and-output#fnref15)
- en: The [documentation for `pickle`](https://docs.python.org/2/library/pickle.html)
    mentions that the library is “not secure against erroneous or maliciously constructed
    data” and recommends that you “[n]ever unpickle data received from an untrusted
    or unauthenticated source.”[↩](/input-and-output#fnref16)
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pickle`的[文档](https://docs.python.org/2/library/pickle.html)提到，该库“不针对错误或恶意构造的数据安全”，并建议您“[永远不要从不受信任或未经认证的来源反序列化数据。”][↑](/input-and-output#fnref16)'
