- en: '2.5\. Application: regression analysis#'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.5\. 应用：回归分析#
- en: 原文：[https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html](https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html](https://mmids-textbook.github.io/chap02_ls/05_regression/roch-mmids-ls-regression.html)
- en: We return to our motivating example, the regression problem, and apply the least
    squares approach.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到我们的动机示例，回归问题，并应用最小二乘法。
- en: 2.5.1\. Linear regression[#](#linear-regression "Link to this heading")
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5.1\. 线性回归[#](#linear-regression "链接到本标题")
- en: '**Linear regression** \(\idx{linear regression}\xdi\) We seek an affine function
    to fit input data points \(\{(\mathbf{x}_i, y_i)\}_{i=1}^n\), where \(\mathbf{x}_i
    = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\) and \(y_i \in \mathbb{R}\) for
    all \(i\). The common approach involves finding coefficients \(\beta_j\)’s that
    minimize the criterion'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性回归** \(\idx{linear regression}\xdi\) 我们寻求一个仿射函数来拟合输入数据点 \(\{(\mathbf{x}_i,
    y_i)\}_{i=1}^n\)，其中 \(\mathbf{x}_i = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\)
    且 \(y_i \in \mathbb{R}\) 对所有 \(i\) 都成立。常见的方法是找到系数 \(\beta_j\)，使得标准最小化'
- en: \[ \sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
    \]
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
    \]
- en: This is indeed a linear least squares problem.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个线性最小二乘问题。
- en: '![A regression line (with help from ChatGPT; code converted from (Source))](../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![回归线（得益于 ChatGPT；代码从（来源）转换而来）](../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png)'
- en: In matrix form, let
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以矩阵形式，设
- en: \[\begin{split} \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix},
    \quad\quad A = \begin{pmatrix} 1 & \mathbf{x}_1^T \\ 1 & \mathbf{x}_2^T \\ \vdots
    & \vdots \\ 1 & \mathbf{x}_n^T \end{pmatrix} \quad\text{and}\quad \boldsymbol{\beta}
    = \begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{pmatrix}. \end{split}\]
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix},
    \quad\quad A = \begin{pmatrix} 1 & \mathbf{x}_1^T \\ 1 & \mathbf{x}_2^T \\ \vdots
    & \vdots \\ 1 & \mathbf{x}_n^T \end{pmatrix} \quad\text{and}\quad \boldsymbol{\beta}
    = \begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{pmatrix}. \end{split}\]
- en: Then the problem is
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后问题变为
- en: \[ \min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} \|\mathbf{y} - A \boldsymbol{\beta}\|^2.
    \]
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} \|\mathbf{y} - A \boldsymbol{\beta}\|^2.
    \]
- en: We assume that the columns of \(A\) are linearly independent, which is often
    the case with real data (unless there is an algebraic relationship between some
    columns). The normal equations are then
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 \(A\) 的列线性无关，这在实际数据中通常是情况（除非某些列之间存在代数关系）。因此，正则方程如下
- en: \[ A^T A \boldsymbol{\beta} = A^T \mathbf{y}. \]
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A^T A \boldsymbol{\beta} = A^T \mathbf{y}. \]
- en: Let \(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\) be the
    unique solution of the system. It gives the vector of coefficients in our fitted
    model. We refer to
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 设 \(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\) 为该系统的唯一解。它给出了我们拟合模型中的系数向量。我们称之为
- en: \[ \hat{y}_i = \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
    \]
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_i = \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
    \]
- en: as the fitted values and to
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为拟合值，并到
- en: \[ r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n \]
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: \[ r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n \]
- en: as the residuals\(\idx{residuals}\xdi\). In vector form, we obtain \(\hat{\mathbf{y}}
    = (\hat{y}_1,\ldots,\hat{y}_n)\) and \(\mathbf{r} = (r_1,\ldots,r_n)\) as
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为残差\(\idx{residuals}\xdi\). 以向量形式，我们得到 \(\hat{\mathbf{y}} = (\hat{y}_1,\ldots,\hat{y}_n)\)
    和 \(\mathbf{r} = (r_1,\ldots,r_n)\) 如下
- en: \[ \hat{\mathbf{y}} = A \boldsymbol{\hat\beta} \quad \text{and} \quad \mathbf{r}
    = \mathbf{y} - \hat{\mathbf{y}}. \]
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\mathbf{y}} = A \boldsymbol{\hat\beta} \quad \text{and} \quad \mathbf{r}
    = \mathbf{y} - \hat{\mathbf{y}}. \]
- en: The residual sum of squares (RSS)\(\idx{residual sum of squares}\xdi\) is given
    by
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 残差平方和（RSS）\(\idx{residual sum of squares}\xdi\) 由以下给出
- en: \[ \sum_{i=1}^n r_i^2 = \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d
    \hat{\beta}_j x_{i,j}\right\}\right)^2 \]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n r_i^2 = \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d
    \hat{\beta}_j x_{i,j}\right\}\right)^2 \]
- en: or, in vector form,
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，以向量形式，
- en: \[ \|\mathbf{r}\|^2 = \|\mathbf{y} - \hat{\mathbf{y}}\|^2 = \|\mathbf{y} - A
    \boldsymbol{\hat\beta}\|^2. \]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \|\mathbf{r}\|^2 = \|\mathbf{y} - \hat{\mathbf{y}}\|^2 = \|\mathbf{y} - A
    \boldsymbol{\hat\beta}\|^2. \]
- en: '**NUMERICAL CORNER:** We test our least-squares method on simulated data. This
    has the advantage that we know the truth.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角:** 我们在我们的模拟数据上测试我们的最小二乘法。这有一个优点，即我们知道真实值。'
- en: Suppose the truth is a linear function of one variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设真实值是一个变量的线性函数。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png](../Images/2eef44a4747d0f6416d01155aadc0534.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png](../Images/2eef44a4747d0f6416d01155aadc0534.png)'
- en: A perfect straight line is little too easy. So let’s add some noise. That is,
    to each \(y_i\) we add an independent random variable \(\varepsilon_i\) with a
    standard Normal distribution (mean \(0\), variance \(1\)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一条完美的直线有点太简单了。所以让我们添加一些噪声。也就是说，对每个 \(y_i\) 我们添加一个具有标准正态分布（均值 \(0\)，方差 \(1\)）的独立随机变量
    \(\varepsilon_i\)。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png](../Images/0ea0617d403c0459cb176423ab08728a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png](../Images/0ea0617d403c0459cb176423ab08728a.png)'
- en: We form the matrix \(A\) and use our least-squares code to solve for \(\boldsymbol{\hat\beta}\).
    The function `ls_by_qr`, which we implemented previously, is in [mmids.py](https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py),
    which is available on the [GitHub of the book](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们形成矩阵 \(A\) 并使用我们的最小二乘法代码来求解 \(\boldsymbol{\hat\beta}\)。我们之前实现的函数 `ls_by_qr`
    在 [mmids.py](https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py)
    中，该文件可在书的 [GitHub](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main)
    上找到。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png](../Images/d879007a695e84bcc491f8d33559f076.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png](../Images/d879007a695e84bcc491f8d33559f076.png)'
- en: \(\unlhd\)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 2.5.2\. Polynomial regression (and overfitting)[#](#polynomial-regression-and-overfitting
    "Link to this heading")
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5.2\. 多项式回归（以及过拟合）[#](#多项式回归以及过拟合 "链接到这个标题")
- en: '**Beyond linearity** \(\idx{polynomial regression}\xdi\) The linear assumption
    is not as restrictive as it may first appear. The same approach can be extended
    straightforwardly to fit polynomials or more complicated combination of functions.
    For instance, suppose \(d=1\). To fit a second degree polynomial to the data \(\{(x_i,
    y_i)\}_{i=1}^n\), we add a column to the \(A\) matrix with the squares of the
    \(x_i\)’s. That is, we let'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**超越线性** \(\idx{多项式回归}\xdi\) 线性假设并不像最初看起来那么严格。同样的方法可以简单地扩展到拟合多项式或更复杂的函数组合。例如，假设
    \(d=1\)。为了将二次多项式拟合到数据 \(\{(x_i, y_i)\}_{i=1}^n\)，我们在 \(A\) 矩阵中添加一个列，包含 \(x_i\)
    的平方。也就是说，我们让'
- en: \[\begin{split} A = \begin{pmatrix} 1 & x_1 & x_1^2 \\ 1 & x_2 & x_2^2 \\ \vdots
    & \vdots & \vdots \\ 1 & x_n & x_n^2 \end{pmatrix}. \end{split}\]
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A = \begin{pmatrix} 1 & x_1 & x_1^2 \\ 1 & x_2 & x_2^2 \\ \vdots
    & \vdots & \vdots \\ 1 & x_n & x_n^2 \end{pmatrix}. \end{split}\]
- en: Then, we are indeed fitting a degree-two polynomial as follows
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们确实是在拟合以下二次多项式
- en: \[ (A \boldsymbol{\beta})_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2. \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (A \boldsymbol{\beta})_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2. \]
- en: The solution otherwise remains the same.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案保持不变。
- en: This idea of adding columns can also be used to model interactions between predictors.
    Suppose \(d=2\). Then we can consider the following \(A\) matrix, where the last
    column combines both predictors into their product,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种添加列的想法也可以用来建模预测变量之间的交互。假设 \(d=2\)。那么我们可以考虑以下 \(A\) 矩阵，其中最后一列将两个预测变量组合成它们的乘积，
- en: \[\begin{split} A = \begin{pmatrix} 1 & x_{11} & x_{12} & x_{11} x_{12} \\ 1
    & x_{21} & x_{22} & x_{21} x_{22} \\ \vdots & \vdots & \vdots & \vdots\\ 1 & x_{n1}
    & x_{n2} & x_{n1} x_{n2} \end{pmatrix}. \end{split}\]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A = \begin{pmatrix} 1 & x_{11} & x_{12} & x_{11} x_{12} \\ 1
    & x_{21} & x_{22} & x_{21} x_{22} \\ \vdots & \vdots & \vdots & \vdots\\ 1 & x_{n1}
    & x_{n2} & x_{n1} x_{n2} \end{pmatrix}. \end{split}\]
- en: '**NUMERICAL CORNER:** Suppose the truth is in fact a degree-two polynomial
    of one variable with Gaussian noise.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 假设真实情况实际上是一个一变量的二次多项式，带有高斯噪声。'
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png](../Images/9fde58544d9266d798debbcd18cf995a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png](../Images/9fde58544d9266d798debbcd18cf995a.png)'
- en: We form the matrix \(A\) and use our least-squares code to solve for \(\boldsymbol{\hat\beta}\).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们形成矩阵 \(A\) 并使用我们的最小二乘法代码来求解 \(\boldsymbol{\hat\beta}\)。
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="切换隐藏内容">显示代码单元格源代码 隐藏代码单元格源代码</summary>
- en: '[PRE8]</details> ![../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png](../Images/c79327531705ad13d8cb4943a270ee4e.png)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE8]</details> ![../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png](../Images/c79327531705ad13d8cb4943a270ee4e.png)'
- en: \(\unlhd\)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**Overfitting in polynomial regression** In adding more parameters, one must
    worry about [overfitting](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)\(\idx{overfitting}\xdi\).
    To quote Wikipedia:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**多项式回归中的过度拟合** 在添加更多参数时，必须担心 [过度拟合](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)\(\idx{overfitting}\xdi\)。引用维基百科：'
- en: In statistics, overfitting is “the production of an analysis that corresponds
    too closely or exactly to a particular set of data, and may therefore fail to
    fit additional data or predict future observations reliably”.[[1](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)]
    An overfitted model is a statistical model that contains more parameters than
    can be justified by the data.[[2](https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2)]
    The essence of overfitting is to have unknowingly extracted some of the residual
    variation (i.e. the noise) as if that variation represented underlying model structure.[[3](https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3)]
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在统计学中，过度拟合是“产生的一种分析结果与特定数据集过于接近或完全一致，因此可能无法拟合附加数据或可靠地预测未来观察结果”[[1](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)]。一个过度拟合的模型是一个包含比数据可以证明的更多参数的统计模型[[2](https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2)]。过度拟合的本质是无意中提取了一些残差变异（即噪声），好像这种变异代表了潜在模型结构[[3](https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3)]）
- en: '**NUMERICAL CORNER:** We return to the `Advertising` dataset from the [[ISLP]](https://www.statlearning.com/)
    textbook. We load the dataset again.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**: 我们回到 [[ISLP]](https://www.statlearning.com/) 教科书中的 `Advertising` 数据集。我们再次加载数据集。'
- en: '**Figure:** Pie chart (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**图**: 饼图 (*来源:* 使用 [Midjourney](https://www.midjourney.com/) 制作)'
- en: '![Predicting sales](../Images/a2936245bd692ef24ec32aa2c9836872.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![预测销售](../Images/a2936245bd692ef24ec32aa2c9836872.png)'
- en: \(\bowtie\)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bowtie\)
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We will focus for now on the TV budget. We form the matrix \(A\) and use our
    least-squares code to solve for \(\boldsymbol{\beta}\).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们将关注电视预算。我们形成矩阵 \(A\) 并使用我们的最小二乘法代码求解 \(\boldsymbol{\beta}\)。
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源代码
    隐藏代码单元格源代码</summary>
- en: '[PRE12]</details> ![../../_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png](../Images/bcffea330b988d225e11b92c7e85f38a.png)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE12] ![图片](../Images/bcffea330b988d225e11b92c7e85f38a.png)'
- en: A degree-two polynomial might be a better fit.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 二次多项式可能是一个更好的拟合。
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源代码
    隐藏代码单元格源代码</summary>
- en: '[PRE15]</details> ![../../_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png](../Images/6df89699e41e6a5486cb045e7360d476.png)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE15] ![图片](../Images/6df89699e41e6a5486cb045e7360d476.png)'
- en: The fit looks slightly better than the linear one. This is not entirely surprising
    though given that the linear model is a subset of the quadratic one. But, as we
    mentioned earlier, when adding more parameters we must now worry about overfitting
    the data. To illustrate, let’s see what happens with a degree-\(20\) polynomial
    fit.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个拟合看起来比线性拟合略好。但这并不完全令人惊讶，因为线性模型是二次模型的子集。但是，正如我们之前提到的，当我们添加更多参数时，我们必须担心数据过度拟合。为了说明，让我们看看
    \(20\) 次多项式拟合会发生什么。
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![../../_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png](../Images/8a6079d567365e38718954b97e0d5d59.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8a6079d567365e38718954b97e0d5d59.png)'
- en: The outcome now seems to vary wildly, seemingly driven by the randomness of
    the data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的结果似乎变化无常，似乎是由数据的随机性驱动的。
- en: '**CHAT & LEARN:** Ask your favorite AI chatbot about using cross-validation
    to choose a suitable degree. Ask for code and apply it to this dataset. ([Open
    In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb))
    \(\ddagger\)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**聊天与学习**: 向你喜欢的 AI 聊天机器人询问如何使用交叉验证来选择合适的度数。请求代码并将其应用于此数据集。([在 Colab 中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb))
    \(\ddagger\)'
- en: \(\unlhd\)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(有 Claude、Gemini 和 ChatGPT 的帮助)*'
- en: '**1** In linear regression, the goal is to find coefficients \(\beta_j\)’s
    that minimize which of the following criteria?'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 在线性回归中，目标是找到系数 \(\beta_j\)，以最小化以下哪个标准？'
- en: a) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)
- en: b) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)
- en: c) \(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)
- en: d) \(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)
- en: '**2** The normal equations for linear regression are:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 线性回归的正则方程如下：'
- en: a) \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)
- en: b) \(A A^T \boldsymbol{\beta} = A \mathbf{y}\)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(A A^T \boldsymbol{\beta} = A \mathbf{y}\)
- en: c) \(A^T A \boldsymbol{\beta} = A \mathbf{y}\)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(A^T A \boldsymbol{\beta} = A \mathbf{y}\)
- en: d) \(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)
- en: '**3** In the numerical example with a degree-20 polynomial fit, the fitted
    curve:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 在20次多项式拟合的数值示例中，拟合曲线：'
- en: a) Fits the data perfectly.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: a) 完美拟合数据。
- en: b) Fails to capture the overall trend in the data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: b) 无法捕捉数据的整体趋势。
- en: c) Captures the noise in the data as if it were the underlying structure.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: c) 将数据中的噪声视为潜在结构。
- en: d) Is a straight line.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: d) 是一条直线。
- en: '**4** What is the primary advantage of using simulated data to test the least
    squares method?'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 使用模拟数据测试最小二乘法的主要优势是什么？'
- en: a) Simulated data eliminates the need for real-world data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: a) 模拟数据消除了对现实世界数据的需求。
- en: b) Simulated data provides a perfect fit without noise.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: b) 模拟数据提供了无噪声的完美拟合。
- en: c) Simulated data allows us to know the ground truth.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: c) 模拟数据使我们能够了解真实情况。
- en: d) Simulated data reduces computational complexity.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: d) 模拟数据降低了计算复杂性。
- en: '**5** Which of the following best describes overfitting?'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪项最能描述过度拟合？'
- en: a) The model fits the training data well but generalizes poorly to new data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: a) 该模型对训练数据拟合良好，但泛化到新数据较差。
- en: b) The model fits both the training data and new data well.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: b) 模型对训练数据和新的数据都拟合良好。
- en: c) The model fits the training data poorly but generalizes well to new data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: c) 模型对训练数据拟合不良，但泛化到新数据良好。
- en: d) The model ignores random noise in the training data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: d) 模型忽略了训练数据中的随机噪声。
- en: 'Answer for 1: b. Justification: The text states that in linear regression,
    we seek to find coefficients \(\beta_j\)’s that minimize the criterion \(\sum_{i=1}^n
    (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 1题的答案：b. 理由：文本指出，在线性回归中，我们寻求找到系数 \(\beta_j\)，以最小化以下标准 \(\sum_{i=1}^n (y_i -
    \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)。
- en: 'Answer for 2: a. Justification: The text states, “The normal equations are
    then \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\).”'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 2题的答案：a. 理由：文本指出，“正则方程是 \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)。”
- en: 'Answer for 3: c. Justification: The text states that “The essence of overfitting
    is to have unknowingly extracted some of the residual variation (i.e., the noise)
    as if that variation represented underlying model structure.”'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 3题的答案：c. 理由：文本指出，“过度拟合的本质是无意中提取了一些残差变化（即噪声），好像这种变化代表了潜在模型结构。”
- en: 'Answer for 4: c. Justification: The text notes, “This has the advantage that
    we know the truth.”'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 4题的答案：c. 理由：文本指出，“这有一个优势，即我们知道真相。”
- en: 'Answer for 5: a. Justification: The text quotes Wikipedia: “An overfitted model
    is a statistical model that contains more parameters than can be justified by
    the data.”'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 5题的答案：a. 理由：文本引用维基百科：“过度拟合的模型是一个包含比数据可以证明的更多参数的统计模型。”
- en: 2.5.1\. Linear regression[#](#linear-regression "Link to this heading")
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5.1\. 线性回归[#](#linear-regression "链接到本标题")
- en: '**Linear regression** \(\idx{linear regression}\xdi\) We seek an affine function
    to fit input data points \(\{(\mathbf{x}_i, y_i)\}_{i=1}^n\), where \(\mathbf{x}_i
    = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\) and \(y_i \in \mathbb{R}\) for
    all \(i\). The common approach involves finding coefficients \(\beta_j\)’s that
    minimize the criterion'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性回归** \(\idx{linear regression}\xdi\) 我们寻求一个仿射函数来拟合输入数据点 \(\{(\mathbf{x}_i,
    y_i)\}_{i=1}^n\)，其中 \(\mathbf{x}_i = (x_{i,1}, \ldots, x_{i,d}) \in \mathbb{R}^d\)
    且 \(y_i \in \mathbb{R}\) 对所有 \(i\) 都成立。常见的方法是找到系数 \(\beta_j\)，以最小化以下标准'
- en: \[ \sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
    \]
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n \left(y_i - \left\{\beta_0 + \sum_{j=1}^d \beta_j x_{i,j}\right\}\right)^2.
    \]
- en: This is indeed a linear least squares problem.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个线性最小二乘问题。
- en: '![A regression line (with help from ChatGPT; code converted from (Source))](../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![A regression line (with help from ChatGPT; code converted from (Source))](../Images/1f7e102fbf9a1f59441b2ed46f3349a3.png)'
- en: In matrix form, let
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以矩阵形式，设
- en: \[\begin{split} \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix},
    \quad\quad A = \begin{pmatrix} 1 & \mathbf{x}_1^T \\ 1 & \mathbf{x}_2^T \\ \vdots
    & \vdots \\ 1 & \mathbf{x}_n^T \end{pmatrix} \quad\text{and}\quad \boldsymbol{\beta}
    = \begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{pmatrix}. \end{split}\]
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix},
    \quad\quad A = \begin{pmatrix} 1 & \mathbf{x}_1^T \\ 1 & \mathbf{x}_2^T \\ \vdots
    & \vdots \\ 1 & \mathbf{x}_n^T \end{pmatrix} \quad\text{and}\quad \boldsymbol{\beta}
    = \begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_d \end{pmatrix}. \end{split}\]
- en: Then the problem is
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，问题变为
- en: \[ \min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} \|\mathbf{y} - A \boldsymbol{\beta}\|^2.
    \]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{\boldsymbol{\beta} \in \mathbb{R}^{d+1}} \|\mathbf{y} - A \boldsymbol{\beta}\|^2.
    \]
- en: We assume that the columns of \(A\) are linearly independent, which is often
    the case with real data (unless there is an algebraic relationship between some
    columns). The normal equations are then
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 \(A\) 的列线性无关，这在真实数据中通常是情况（除非某些列之间存在代数关系）。因此，正则方程是
- en: \[ A^T A \boldsymbol{\beta} = A^T \mathbf{y}. \]
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A^T A \boldsymbol{\beta} = A^T \mathbf{y}. \]
- en: Let \(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\) be the
    unique solution of the system. It gives the vector of coefficients in our fitted
    model. We refer to
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 令 \(\boldsymbol{\hat\beta} = (\hat{\beta}_0,\ldots,\hat{\beta}_d)\) 为该系统的唯一解。它给出了我们拟合模型中的系数向量。我们称之为
- en: \[ \hat{y}_i = \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
    \]
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y}_i = \beta_0 + \sum_{j=1}^d \beta_j x_{i,j}, \quad i = 1,\ldots,n
    \]
- en: as the fitted values and to
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 作为拟合值，并且到
- en: \[ r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n \]
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \[ r_i = y_i - \hat{y}_i, \quad i = 1,\ldots,n \]
- en: as the residuals\(\idx{residuals}\xdi\). In vector form, we obtain \(\hat{\mathbf{y}}
    = (\hat{y}_1,\ldots,\hat{y}_n)\) and \(\mathbf{r} = (r_1,\ldots,r_n)\) as
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作为残差\(\idx{residuals}\xdi\)。以向量形式，我们得到 \(\hat{\mathbf{y}} = (\hat{y}_1,\ldots,\hat{y}_n)\)
    和 \(\mathbf{r} = (r_1,\ldots,r_n)\) 如下
- en: \[ \hat{\mathbf{y}} = A \boldsymbol{\hat\beta} \quad \text{and} \quad \mathbf{r}
    = \mathbf{y} - \hat{\mathbf{y}}. \]
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\mathbf{y}} = A \boldsymbol{\hat\beta} \quad \text{and} \quad \mathbf{r}
    = \mathbf{y} - \hat{\mathbf{y}}. \]
- en: The residual sum of squares (RSS)\(\idx{residual sum of squares}\xdi\) is given
    by
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 残差平方和（RSS）\(\idx{residual sum of squares}\xdi\) 由下式给出
- en: \[ \sum_{i=1}^n r_i^2 = \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d
    \hat{\beta}_j x_{i,j}\right\}\right)^2 \]
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^n r_i^2 = \sum_{i=1}^n \left(y_i - \left\{\hat{\beta}_0 + \sum_{j=1}^d
    \hat{\beta}_j x_{i,j}\right\}\right)^2 \]
- en: or, in vector form,
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，以向量形式，
- en: \[ \|\mathbf{r}\|^2 = \|\mathbf{y} - \hat{\mathbf{y}}\|^2 = \|\mathbf{y} - A
    \boldsymbol{\hat\beta}\|^2. \]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \|\mathbf{r}\|^2 = \|\mathbf{y} - \hat{\mathbf{y}}\|^2 = \|\mathbf{y} - A
    \boldsymbol{\hat\beta}\|^2. \]
- en: '**NUMERICAL CORNER:** We test our least-squares method on simulated data. This
    has the advantage that we know the truth.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落：** 我们在模拟数据上测试我们的最小二乘法。这有一个优点，即我们知道真相。'
- en: Suppose the truth is a linear function of one variable.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 假设真理是一个一元线性函数。
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png](../Images/2eef44a4747d0f6416d01155aadc0534.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/b7534b4829e85e0392d88cd63283feab5152d865592acc624d093ad239193eea.png](../Images/2eef44a4747d0f6416d01155aadc0534.png)'
- en: A perfect straight line is little too easy. So let’s add some noise. That is,
    to each \(y_i\) we add an independent random variable \(\varepsilon_i\) with a
    standard Normal distribution (mean \(0\), variance \(1\)).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 完美的直线过于简单。因此，让我们添加一些噪声。也就是说，对每个 \(y_i\) 我们添加一个具有标准正态分布（均值 \(0\)，方差 \(1\)）的独立随机变量
    \(\varepsilon_i\)。
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png](../Images/0ea0617d403c0459cb176423ab08728a.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/b5adb381b022a250bc499f92a2c124a2d277fd2ff3dba90ad87b99b3a8ee4a0a.png](../Images/0ea0617d403c0459cb176423ab08728a.png)'
- en: We form the matrix \(A\) and use our least-squares code to solve for \(\boldsymbol{\hat\beta}\).
    The function `ls_by_qr`, which we implemented previously, is in [mmids.py](https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py),
    which is available on the [GitHub of the book](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建矩阵 \(A\) 并使用我们的最小二乘法代码求解 \(\boldsymbol{\hat\beta}\)。之前我们实现的函数 `ls_by_qr`
    在 [mmids.py](https://raw.githubusercontent.com/MMiDS-textbook/MMiDS-textbook.github.io/main/utils/mmids.py)
    中，该文件可在[本书的GitHub仓库](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main)找到。
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e7e1f797d.png](../Images/d879007a695e84bcc491f8d33559f076.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/f3588b24516021d16ce7c2c1f232ecd770e8ed04ad3c889ad37d7d7e1f797d.png](../Images/d879007a695e84bcc491f8d33559f076.png)'
- en: \(\unlhd\)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: 2.5.2\. Polynomial regression (and overfitting)[#](#polynomial-regression-and-overfitting
    "Link to this heading")
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5.2\. 多项式回归（以及过拟合）[#](#polynomial-regression-and-overfitting "链接到本标题")
- en: '**Beyond linearity** \(\idx{polynomial regression}\xdi\) The linear assumption
    is not as restrictive as it may first appear. The same approach can be extended
    straightforwardly to fit polynomials or more complicated combination of functions.
    For instance, suppose \(d=1\). To fit a second degree polynomial to the data \(\{(x_i,
    y_i)\}_{i=1}^n\), we add a column to the \(A\) matrix with the squares of the
    \(x_i\)’s. That is, we let'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**超越线性** \(\idx{多项式回归}\xdi\) 线性假设并不像最初看起来那么严格。同样的方法可以简单地扩展到拟合多项式或更复杂的函数组合。例如，假设
    \(d=1\)。为了将二次多项式拟合到数据 \(\{(x_i, y_i)\}_{i=1}^n\)，我们在 \(A\) 矩阵中添加一个列，包含 \(x_i\)
    的平方。也就是说，我们让'
- en: \[\begin{split} A = \begin{pmatrix} 1 & x_1 & x_1^2 \\ 1 & x_2 & x_2^2 \\ \vdots
    & \vdots & \vdots \\ 1 & x_n & x_n^2 \end{pmatrix}. \end{split}\]
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A = \begin{pmatrix} 1 & x_1 & x_1^2 \\ 1 & x_2 & x_2^2 \\ \vdots
    & \vdots & \vdots \\ 1 & x_n & x_n^2 \end{pmatrix}. \end{split}\]
- en: Then, we are indeed fitting a degree-two polynomial as follows
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们确实在以下方式中拟合了一个二次多项式
- en: \[ (A \boldsymbol{\beta})_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2. \]
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: \[ (A \boldsymbol{\beta})_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2. \]
- en: The solution otherwise remains the same.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案否则保持不变。
- en: This idea of adding columns can also be used to model interactions between predictors.
    Suppose \(d=2\). Then we can consider the following \(A\) matrix, where the last
    column combines both predictors into their product,
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这种添加列的想法也可以用来建模预测变量之间的交互。假设 \(d=2\)。那么我们可以考虑以下 \(A\) 矩阵，其中最后一列将两个预测变量组合成它们的乘积，
- en: \[\begin{split} A = \begin{pmatrix} 1 & x_{11} & x_{12} & x_{11} x_{12} \\ 1
    & x_{21} & x_{22} & x_{21} x_{22} \\ \vdots & \vdots & \vdots & \vdots\\ 1 & x_{n1}
    & x_{n2} & x_{n1} x_{n2} \end{pmatrix}. \end{split}\]
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} A = \begin{pmatrix} 1 & x_{11} & x_{12} & x_{11} x_{12} \\ 1
    & x_{21} & x_{22} & x_{21} x_{22} \\ \vdots & \vdots & \vdots & \vdots\\ 1 & x_{n1}
    & x_{n2} & x_{n1} x_{n2} \end{pmatrix}. \end{split}\]
- en: '**NUMERICAL CORNER:** Suppose the truth is in fact a degree-two polynomial
    of one variable with Gaussian noise.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落**：假设真相实际上是一个变量的二次多项式，带有高斯噪声。'
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png](../Images/9fde58544d9266d798debbcd18cf995a.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/eadda9bff35f63929d01806e5b558ed3350db0b9cbc7efd1b446b52ddff4ae34.png](../Images/9fde58544d9266d798debbcd18cf995a.png)'
- en: We form the matrix \(A\) and use our least-squares code to solve for \(\boldsymbol{\hat\beta}\).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们形成矩阵 \(A\) 并使用我们的最小二乘法代码来求解 \(\boldsymbol{\hat\beta}\)。
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="切换隐藏内容">显示代码单元格源代码 隐藏代码单元格源代码</summary>
- en: '[PRE27]</details> ![../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png](../Images/c79327531705ad13d8cb4943a270ee4e.png)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE27]</details> ![../../_images/bbf5609a182e64df13441c79b85c74d9a49dbfbef9716ba956e2f13e70dea1d2.png](../Images/c79327531705ad13d8cb4943a270ee4e.png)'
- en: \(\unlhd\)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**Overfitting in polynomial regression** In adding more parameters, one must
    worry about [overfitting](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)\(\idx{overfitting}\xdi\).
    To quote Wikipedia:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**多项式回归中的过拟合** 在添加更多参数时，必须担心 [过拟合](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)\(\idx{过拟合}\xdi\)。引用维基百科的话：'
- en: In statistics, overfitting is “the production of an analysis that corresponds
    too closely or exactly to a particular set of data, and may therefore fail to
    fit additional data or predict future observations reliably”.[[1](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)]
    An overfitted model is a statistical model that contains more parameters than
    can be justified by the data.[[2](https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2)]
    The essence of overfitting is to have unknowingly extracted some of the residual
    variation (i.e. the noise) as if that variation represented underlying model structure.[[3](https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3)]
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在统计学中，过拟合是“分析结果与特定数据集过于接近或完全一致，因此可能无法拟合附加数据或可靠地预测未来观察结果”[[1](https://en.wikipedia.org/wiki/Overfitting#cite_note-1)]。一个过拟合的模型是一个包含比数据可以证明的更多参数的统计模型[[2](https://en.wikipedia.org/wiki/Overfitting#cite_note-CDS-2)]。过拟合的本质是在不知不觉中提取了一些残差变异（即噪声），好像这种变异代表了潜在模型结构[[3](https://en.wikipedia.org/wiki/Overfitting#cite_note-BA2002-3)]）
- en: '**NUMERICAL CORNER:** We return to the `Advertising` dataset from the [[ISLP]](https://www.statlearning.com/)
    textbook. We load the dataset again.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落**：我们回到 [[ISLP]](https://www.statlearning.com/) 教科书中的 `Advertising` 数据集。我们再次加载数据集。'
- en: '**Figure:** Pie chart (*Credit:* Made with [Midjourney](https://www.midjourney.com/))'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**图：饼图 (*来源：[Midjourney](https://www.midjourney.com/))**'
- en: '![Predicting sales](../Images/a2936245bd692ef24ec32aa2c9836872.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![预测销售](../Images/a2936245bd692ef24ec32aa2c9836872.png)'
- en: \(\bowtie\)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bowtie\)
- en: '[PRE28]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We will focus for now on the TV budget. We form the matrix \(A\) and use our
    least-squares code to solve for \(\boldsymbol{\beta}\).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将专注于电视预算。我们形成矩阵 \(A\) 并使用我们的最小二乘法代码来求解 \(\boldsymbol{\beta}\)。
- en: '[PRE29]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源
    隐藏代码单元格源</summary>
- en: '[PRE31]</details> ![../../_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png](../Images/bcffea330b988d225e11b92c7e85f38a.png)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE31]</details> ![../../_images/8f726a7109f0d9b61448ef49928a680ed907765437c981ee6e04aeb275693a52.png](../Images/bcffea330b988d225e11b92c7e85f38a.png)'
- en: A degree-two polynomial might be a better fit.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 二次多项式可能是一个更好的拟合。
- en: '[PRE32]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: <details class="hide above-input"><summary aria-label="Toggle hidden content">Show
    code cell source Hide code cell source</summary>
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="hide above-input"><summary aria-label="Toggle hidden content">显示代码单元格源
    隐藏代码单元格源</summary>
- en: '[PRE34]</details> ![../../_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png](../Images/6df89699e41e6a5486cb045e7360d476.png)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE34]</details> ![../../_images/bae314a4c6b951c24b56035f36157378a8272971c2861c45649e81183d6eb5ce.png](../Images/6df89699e41e6a5486cb045e7360d476.png)'
- en: The fit looks slightly better than the linear one. This is not entirely surprising
    though given that the linear model is a subset of the quadratic one. But, as we
    mentioned earlier, when adding more parameters we must now worry about overfitting
    the data. To illustrate, let’s see what happens with a degree-\(20\) polynomial
    fit.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合看起来比线性拟合略好。但这并不完全令人惊讶，因为线性模型是二次模型的一个子集。但是，正如我们之前提到的，当我们添加更多参数时，我们必须担心数据过拟合。为了说明这一点，让我们看看二次多项式拟合度数为
    \(20\) 时会发生什么。
- en: '[PRE35]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![../../_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png](../Images/8a6079d567365e38718954b97e0d5d59.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![../../_images/93ca62931e6172f1807be38a582a4ad5d64a7cd5553092a78c14a6ecc358c896.png](../Images/8a6079d567365e38718954b97e0d5d59.png)'
- en: The outcome now seems to vary wildly, seemingly driven by the randomness of
    the data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在似乎变化无常，似乎是由数据的随机性驱动的。
- en: '**CHAT & LEARN:** Ask your favorite AI chatbot about using cross-validation
    to choose a suitable degree. Ask for code and apply it to this dataset. ([Open
    In Colab](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb))
    \(\ddagger\)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN:** 向你喜欢的AI聊天机器人询问如何使用交叉验证来选择合适的度数。请求代码并将其应用于此数据集。（[在Colab中打开](https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_ls_notebook.ipynb))
    \(\ddagger\)'
- en: \(\unlhd\)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(由Claude、Gemini和ChatGPT协助)*'
- en: '**1** In linear regression, the goal is to find coefficients \(\beta_j\)’s
    that minimize which of the following criteria?'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 在线性回归中，目标是找到使以下哪个标准最小化的系数 \(\beta_j\)？'
- en: a) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})\)
- en: b) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\)
- en: c) \(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\sum_{i=1}^n (y_i - \{\beta_0 + \sum_{j=1}^d \beta_j x_{ij}\}^2)\)
- en: d) \(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\sum_{i=1}^n |y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij}|\)
- en: '**2** The normal equations for linear regression are:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 线性回归的正则方程如下：'
- en: a) \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)
- en: b) \(A A^T \boldsymbol{\beta} = A \mathbf{y}\)
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(A A^T \boldsymbol{\beta} = A \mathbf{y}\)
- en: c) \(A^T A \boldsymbol{\beta} = A \mathbf{y}\)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(A^T A \boldsymbol{\beta} = A \mathbf{y}\)
- en: d) \(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(A A^T \boldsymbol{\beta} = A^T \mathbf{y}\)
- en: '**3** In the numerical example with a degree-20 polynomial fit, the fitted
    curve:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 在度数为 \(20\) 的多项式拟合的数值示例中，拟合曲线：'
- en: a) Fits the data perfectly.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: a) 完美地拟合数据。
- en: b) Fails to capture the overall trend in the data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: b) 无法捕捉数据中的整体趋势。
- en: c) Captures the noise in the data as if it were the underlying structure.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: c) 将数据中的噪声捕捉得像潜在结构一样。
- en: d) Is a straight line.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: d) 是一条直线。
- en: '**4** What is the primary advantage of using simulated data to test the least
    squares method?'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 使用模拟数据测试最小二乘法的主要优势是什么？'
- en: a) Simulated data eliminates the need for real-world data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: a) 模拟数据消除了对真实世界数据的需求。
- en: b) Simulated data provides a perfect fit without noise.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: b) 模拟数据提供了无噪声的完美拟合。
- en: c) Simulated data allows us to know the ground truth.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: c) 模拟数据使我们能够知道真实情况。
- en: d) Simulated data reduces computational complexity.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: d) 模拟数据降低了计算复杂度。
- en: '**5** Which of the following best describes overfitting?'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪项最能描述过度拟合？'
- en: a) The model fits the training data well but generalizes poorly to new data.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: a) 模型很好地拟合了训练数据，但对新数据泛化能力较差。
- en: b) The model fits both the training data and new data well.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: b) 模型对训练数据和新的数据都拟合得很好。
- en: c) The model fits the training data poorly but generalizes well to new data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: c) 模型对训练数据拟合较差，但对新数据泛化能力较好。
- en: d) The model ignores random noise in the training data.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: d) 模型忽略了训练数据中的随机噪声。
- en: 'Answer for 1: b. Justification: The text states that in linear regression,
    we seek to find coefficients \(\beta_j\)’s that minimize the criterion \(\sum_{i=1}^n
    (y_i - \beta_0 - \sum_{j=1}^d \beta_j x_{ij})^2\).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 1题答案：b. 理由：文本指出，在线性回归中，我们寻求找到系数 \(\beta_j\)，使得准则 \(\sum_{i=1}^n (y_i - \beta_0
    - \sum_{j=1}^d \beta_j x_{ij})^2\) 最小化。
- en: 'Answer for 2: a. Justification: The text states, “The normal equations are
    then \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\).”'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 2题答案：a. 理由：文本指出，“然后正则方程是 \(A^T A \boldsymbol{\beta} = A^T \mathbf{y}\)。”
- en: 'Answer for 3: c. Justification: The text states that “The essence of overfitting
    is to have unknowingly extracted some of the residual variation (i.e., the noise)
    as if that variation represented underlying model structure.”'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 3题答案：c. 理由：文本指出，“过度拟合的本质是无意中提取了一些残留变异（即噪声），好像这种变异代表了潜在模型结构。”
- en: 'Answer for 4: c. Justification: The text notes, “This has the advantage that
    we know the truth.”'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 4题答案：c. 理由：文本指出，“这有一个优点，那就是我们知道真相。”
- en: 'Answer for 5: a. Justification: The text quotes Wikipedia: “An overfitted model
    is a statistical model that contains more parameters than can be justified by
    the data.”'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 5题答案：a. 理由：文本引用维基百科：“过度拟合的模型是一个包含比数据可以证明的更多参数的统计模型。”
