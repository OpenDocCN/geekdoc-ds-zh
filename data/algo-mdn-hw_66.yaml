- en: Moving Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据移动
- en: 原文：[https://en.algorithmica.org/hpc/simd/moving/](https://en.algorithmica.org/hpc/simd/moving/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://en.algorithmica.org/hpc/simd/moving/](https://en.algorithmica.org/hpc/simd/moving/)
- en: 'If you took some time to study [the reference](https://software.intel.com/sites/landingpage/IntrinsicsGuide),
    you may have noticed that there are essentially two major groups of vector operations:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您花了一些时间研究[参考资料](https://software.intel.com/sites/landingpage/IntrinsicsGuide)，您可能会注意到，本质上存在两组主要的向量操作：
- en: Instructions that perform some elementwise operation (`+`, `*`, `<`, `acos`,
    etc.).
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行某些逐元素操作（`+`、`*`、`<`、`acos`等）的指令。
- en: Instructions that load, store, mask, shuffle, and generally move data around.
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载、存储、掩码、洗牌以及通常移动数据的指令。
- en: While using the elementwise instructions is easy, the largest challenge with
    SIMD is getting the data in vector registers in the first place, with low enough
    overhead so that the whole endeavor is worthwhile.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用逐元素指令很简单，但SIMD最大的挑战是首先将数据放入向量寄存器中，并且开销足够低，以至于整个努力都是值得的。
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#aligned-loads-and-stores)Aligned
    Loads and Stores'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#aligned-loads-and-stores)对齐加载和存储'
- en: 'Operations of reading and writing the contents of a SIMD register into memory
    have two versions each: `load` / `loadu` and `store` / `storeu`. The letter “u”
    here stands for “unaligned.” The difference is that the former ones only work
    correctly when the read / written block fits inside a single [cache line](/hpc/cpu-cache/cache-lines)
    (and crash otherwise), while the latter work either way, but with a slight performance
    penalty if the block crosses a cache line.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 将SIMD寄存器的内容读取和写入内存的操作有两个版本：`load` / `loadu`和`store` / `storeu`。这里的“u”代表“未对齐”。区别在于前者只有在读取/写入的块适合单个[缓存行](/hpc/cpu-cache/cache-lines)时才能正确工作（否则会崩溃），而后者无论哪种方式都可以工作，但如果块跨越了缓存行，会有轻微的性能损失。
- en: 'Sometimes, especially when the “inner” operation is very lightweight, the performance
    difference becomes significant (at least because you need to fetch two cache lines
    instead of one). As an extreme example, this way of adding two arrays together:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，尤其是在“内部”操作非常轻量时，性能差异变得非常显著（至少因为您需要获取两条缓存行而不是一条）。作为一个极端的例子，这种将两个数组相加的方式：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '…is ~30% slower than its aligned version:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: …比其对齐版本慢约30%：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the first version, assuming that arrays `a`, `b` and `c` are all 64-byte
    *aligned* (the addresses of their first elements are divisible by 64, and so they
    start at the beginning of a cache line), roughly half of reads and writes will
    be “bad” because they cross a cache line boundary.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种版本中，假设数组`a`、`b`和`c`都是64字节对齐的（它们第一个元素地址能被64整除，因此它们从缓存行的开始处开始），大约一半的读取和写入将会是“坏”的，因为它们跨越了缓存行边界。
- en: Note that the performance difference is caused by the cache system and not by
    the instructions themselves. On most modern architectures, the `loadu` / `storeu`
    intrinsics should be equally as fast as `load` / `store` given that in both cases
    the blocks only span one cache line. The advantage of the latter is that they
    can act as free run time assertions that all reads and writes are aligned.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，性能差异是由缓存系统而不是指令本身引起的。在大多数现代架构上，如果块只跨越一个缓存行，`loadu` / `storeu`内联函数应该与`load`
    / `store`一样快。后者的优势是它们可以作为免费的运行时断言，确保所有读取和写入都是对齐的。
- en: 'This makes it important to properly [align](/hpc/cpu-cache/alignment) arrays
    and other data on allocation, and it is also one of the reasons why compilers
    can’t always [auto-vectorize](../auto-vectorization) efficiently. For most purposes,
    we only need to guarantee that any 32-byte SIMD block will not cross a cache line
    boundary, and we can specify this alignment with the `alignas` specifier:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得在分配时正确对齐数组和其它数据变得很重要，这也是编译器不能总是高效地进行[自动向量化](../auto-vectorization)的原因之一。对于大多数用途，我们只需要保证任何32字节SIMD块不会跨越缓存行边界，我们可以使用`alignas`指定符来指定这种对齐：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The [built-in vector types](../intrinsics) already have corresponding alignment
    requirements and assume aligned memory reads and writes — so you are always safe
    when allocating an array of `v8si`, but when converting it from `int*` you have
    to make sure it is aligned.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[内置向量类型](../intrinsics)已经具有相应的对齐要求，并假设对齐的内存读取和写入——所以当分配`v8si`数组时，您总是安全的，但当你从`int*`转换它时，你必须确保它是对齐的。'
- en: Similar to the scalar case, many arithmetic instructions take memory addresses
    as operands — [vector addition](../intrinsics) is an example — although you can’t
    explicitly use it as an intrinsic and have to rely on the compiler. There are
    also a few other instructions for reading a SIMD block from memory, notably the
    [non-temporal](/hpc/cpu-cache/bandwidth#bypassing-the-cache) load and store operations
    that don’t lift accessed data in the cache hierarchy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于标量情况，许多算术指令将内存地址作为操作数——[向量加法](../intrinsics)就是一个例子——尽管你不能显式地使用它作为内建函数，而必须依赖编译器。还有一些其他指令用于从内存中读取SIMD块，特别是[非临时](/hpc/cpu-cache/bandwidth#bypassing-the-cache)加载和存储操作，这些操作不会将访问的数据提升到缓存层次结构中。
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#register-aliasing)Register
    Aliasing'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#register-aliasing)寄存器别名'
- en: 'The first SIMD extension, MMX, started quite small. It only used 64-bit vectors,
    which were conveniently aliased to the mantissa part of a [80-bit float](/hpc/arithmetic/ieee-754)
    so that there is no need to introduce a separate set of registers. As the vector
    size grew with later extensions, the same [register aliasing](/hpc/architecture/assembly#instructions-and-registers)
    mechanism used in general-purpose registers was adopted for the vector registers
    to maintain backward compatibility: `xmm0` is the first half (128 bits) of `ymm0`,
    `xmm1` is the first half of `ymm1`, and so on.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一款SIMD扩展，MMX，开始时相当小。它只使用了64位向量，这些向量方便地别名为80位浮点数的尾数部分，因此不需要引入一组单独的寄存器。随着后续扩展中向量大小的增长，用于通用寄存器的相同[寄存器别名](/hpc/architecture/assembly#instructions-and-registers)机制被用于向量寄存器，以保持向后兼容性：`xmm0`是`ymm0`的第一个半部分（128位），`xmm1`是`ymm1`的第一个半部分，依此类推。
- en: This feature, combined with the fact that the vector registers are located in
    the FPU, makes moving data between them and the general-purpose registers slightly
    complicated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特性，加上向量寄存器位于FPU的事实，使得在它们和通用寄存器之间移动数据变得稍微复杂一些。
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#extract-and-insert)Extract
    and Insert'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#extract-and-insert)提取和插入'
- en: To *extract* a specific value from a vector, you can use `_mm256_extract_epi32`
    and similar intrinsics. It takes the index of the integer to be extracted as the
    second parameter and generates different instruction sequences depending on its
    value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要从向量中*提取*特定值，你可以使用`_mm256_extract_epi32`和类似的内建函数。它将需要提取的整数的索引作为第二个参数，并根据其值生成不同的指令序列。
- en: 'If you need to extract the first element, it generates the `vmovd` instruction
    (for `xmm0`, the first half of the vector):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要提取第一个元素，它会生成`vmovd`指令（对于`xmm0`，向量的第一个半部分）：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For other elements of an SSE vector, it generates possibly slightly slower
    `vpextrd`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SSE向量的其他元素，它生成可能稍微慢一点的`vpextrd`：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To extract anything from the second half of an AVX vector, it first has to extract
    that second half, and then the scalar itself. For example, here is how it extracts
    the last (eighth) element,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要从AVX向量的第二半部分提取任何内容，首先必须提取那个第二半部分，然后才是标量本身。例如，以下是提取最后一个（第八个）元素的方法，
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'There is a similar `_mm256_insert_epi32` intrinsic for overwriting specific
    elements:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个类似`_mm256_insert_epi32`的内建函数用于覆盖特定元素：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Takeaway: moving scalar data to and from vector registers is slow, especially
    when this isn’t the first element.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：将标量数据移动到和从向量寄存器中是慢的，尤其是在这不是第一个元素的情况下。
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#making-constants)Making
    Constants'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#making-constants)创建常数'
- en: 'If you need to populate not just one element but the entire vector, you can
    use the `_mm256_setr_epi32` intrinsic:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要填充的不仅仅是单个元素，而是整个向量，你可以使用`_mm256_setr_epi32`内建函数：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The “r” here stands for “reversed” — from [the CPU point of view](/hpc/arithmetic/integer#integer-types),
    not for humans. There is also the `_mm256_set_epi32` (without “r”) that fills
    the values from the opposite direction. Both are mostly used to create compile-time
    constants that are then fetched into the register with a block load. If your use
    case is filling a vector with zeros, use the `_mm256_setzero_si256` instead: it
    `xor`-s the register with itself.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的“r”代表“反向”——从[CPU的角度](/hpc/arithmetic/integer#integer-types)来看，而不是对人类来说。还有一个`_mm256_set_epi32`（没有“r”），它从相反方向填充值。这两个函数主要用于创建编译时常数，然后通过块加载将它们加载到寄存器中。如果你的用例是填充一个零向量，请使用`_mm256_setzero_si256`，它会将寄存器与自身进行`xor`操作。
- en: 'In built-in vector types, you can just use normal braced initialization:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在内置向量类型中，你可以直接使用正常的括号初始化：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#broadcast)Broadcast'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#broadcast)广播'
- en: 'Instead of modifying just one element, you can also *broadcast* a single value
    into all its positions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了修改单个元素之外，你还可以将单个值*广播*到所有位置：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is a frequently used operation, so you can also use a memory location:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常用的操作，因此你也可以使用一个内存位置：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When using built-in vector types, you can create a zero vector and add a scalar
    to it:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用内置向量类型时，你可以创建一个零向量并将其与一个标量相加：
- en: '[PRE11]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#mapping-to-arrays)Mapping
    to Arrays'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#mapping-to-arrays)映射到数组'
- en: 'If you want to avoid all this complexity, you can just dump the vector in memory
    and read its values back as scalars:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想避免所有这些复杂性，你只需将向量存储在内存中，并以标量的形式读取其值：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This may not be fast or technically legal (the C++ standard doesn’t specify
    what happens when you cast data like this), but it is simple, and I frequently
    use this code to print out the contents of a vector during debugging.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不会很快或技术上合法（C++标准没有指定当你这样转换数据时会发生什么），但它很简单，我经常使用这段代码在调试期间打印向量的内容。
- en: '### [#](https://en.algorithmica.org/hpc/simd/moving/#non-contiguous-load)Non-Contiguous
    Load'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '### [#](https://en.algorithmica.org/hpc/simd/moving/#non-contiguous-load)非连续加载'
- en: Later SIMD extensions added special “gather” and “scatter instructions that
    read/write data non-sequentially using arbitrary array indices. These don’t work
    8 times faster though and are usually limited by the memory rather than the CPU,
    but they are still helpful for certain applications such as sparse linear algebra.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 后续的SIMD扩展添加了特殊的“gather”和“scatter”指令，这些指令使用任意数组索引非顺序地读写数据。尽管它们不会快8倍，但通常受内存限制而不是CPU限制，但它们对于某些应用（如稀疏线性代数）仍然很有帮助。
- en: Gather is available since AVX2, and various scatter instructions are available
    since AVX512.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`gather`自AVX2以来可用，而各种`scatter`指令自AVX512以来可用。'
- en: '![](../Images/1a34046ab00a6375ab2bb5e5cef95a93.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a34046ab00a6375ab2bb5e5cef95a93.png)'
- en: 'Let’s see if they work faster than scalar reads. First, we create an array
    of size $N$ and $Q$ random read queries:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它们是否比标量读取更快。首先，我们创建一个大小为 $N$ 和 $Q$ 的随机读取查询数组：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the scalar code, we add the elements specified by the queries to a checksum
    one by one:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在标量代码中，我们逐个将查询指定的元素添加到校验和中：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And in the SIMD code, we use the `gather` instruction to do that for 8 different
    indexes in parallel:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在SIMD代码中，我们使用`gather`指令并行地对8个不同的索引进行操作：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'They perform roughly the same, except when the array fits into the L1 cache:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的性能大致相同，除非数组适合L1缓存：
- en: '![](../Images/aa064e69926e477a9b25997890fce027.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa064e69926e477a9b25997890fce027.png)'
- en: The purpose of `gather` and `scatter` is not to perform memory operations faster,
    but to get the data into registers to perform heavy computations on them. For
    anything costlier than just one addition, they are hugely favorable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`gather` 和 `scatter` 的目的不是使内存操作更快，而是将数据放入寄存器中，以便对它们进行大量计算。对于比仅仅一次加法更昂贵的操作，它们非常有优势。'
- en: The lack of (fast) gather and scatter instructions makes SIMD programming on
    CPUs very different from proper parallel computing environments that support independent
    memory access. You have to always engineer around it and employ various ways of
    organizing your data sequentially so that it be loaded into registers. [← Intrinsics
    and Vector Types](https://en.algorithmica.org/hpc/simd/intrinsics/)[Reductions
    →](https://en.algorithmica.org/hpc/simd/reduction/)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏（快速）`gather` 和 `scatter` 指令使得在CPU上使用SIMD编程与支持独立内存访问的正确并行计算环境大不相同。你必须始终围绕它进行设计，并采用各种方式组织你的数据，以便将其加载到寄存器中。[←
    内置函数和向量类型](https://en.algorithmica.org/hpc/simd/intrinsics/)[减少 →](https://en.algorithmica.org/hpc/simd/reduction/)
