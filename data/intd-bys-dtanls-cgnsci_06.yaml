- en: Chapter 1 Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章 简介
- en: 原文：[https://bruno.nicenboim.me/bayescogsci/ch-intro.html](https://bruno.nicenboim.me/bayescogsci/ch-intro.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://bruno.nicenboim.me/bayescogsci/ch-intro.html](https://bruno.nicenboim.me/bayescogsci/ch-intro.html)
- en: 'The central idea we will explore in this book is how to use Bayes’ theorem
    to quantify uncertainty about our belief regarding a scientific question of interest,
    given some data. Before we delve into the details of the underlying theory and
    its application, it is important to have some familiarity with the following topics:
    basic concepts of probability, the concept of random variables, probability distributions,
    and the concept of likelihood. Therefore, we will begin with these topics.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将探讨的核心思想是如何使用贝叶斯定理来量化我们对感兴趣的科学问题的信念的不确定性，给定一些数据。在我们深入探讨基础理论和其应用细节之前，了解以下主题是很重要的：概率的基本概念、随机变量的概念、概率分布和似然的概念。因此，我们将从这些主题开始。
- en: Some of these concepts might seem abstract at first, but they are very relevant
    for conducting a Bayesian analysis. When reading this book for the first time,
    it might be helpful to do a quick pass through this chapter and return to it as
    needed while progressing through the rest of the book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些概念一开始可能看起来很抽象，但它们对于进行贝叶斯分析非常相关。在第一次阅读这本书时，快速浏览本章并在阅读其他部分时根据需要返回本章可能会有所帮助。
- en: 1.1 Probability
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 概率
- en: Informally, we all understand what the term *probability* means. We routinely
    talk about things like the probability of it raining today. However, there are
    two distinct ways to think about probability. One can think of the probability
    of something happening with reference to the frequency with which it might occur
    in repeated observations. Such a conception of probability is easy to imagine
    in cases where something can, at least in principle, occur repeatedly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 非正式地说，我们都理解“概率”这个术语的含义。我们经常谈论诸如今天下雨的概率之类的事情。然而，思考概率有两种不同的方式。一个人可以参考某事可能发生的频率来考虑其发生的概率。这种概率的概念在某种事物至少在原则上可以重复发生的情况下很容易想象。
- en: An example would be obtaining a 6 when tossing a die again and again. However,
    this frequentist view of probability is difficult to justify when talking about
    one-of-a-kind things, such as earthquakes; here, probability is expressing our
    uncertainty about the earthquake happening.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子就是反复掷骰子得到6点。然而，当谈论独一无二的物体，如地震时，这种频率主义的概率观很难得到证明；在这里，概率是表达我们对地震发生的不确定性的理解。
- en: Both the frequency-based and the uncertain-belief perspective have their place
    in statistical inference, and depending on the situation, we are going to rely
    on both ways of thinking.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 频率基础和不确定信念视角在统计推断中都有其位置，并且根据具体情况，我们将依赖这两种思维方式。
- en: The statements below are not formal definitions of the axioms of probability
    theory; for more details (and more precise formulations), see Blitzstein and Hwang
    ([2014](#ref-blitzstein2014introduction)), Ross ([2002](#ref-RossProb)), Kerns
    ([2014](#ref-kerns2014introduction)), Resnick ([2019](#ref-resnick2019probability)),
    or Kolmogorov ([1933](#ref-kolmogorov2018foundations)) (among many other books).
    Keep in mind that different textbooks have slightly different ways of presenting
    the underlying structure of what constitutes a probability space (defined below).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的陈述并不是概率论公理的正式定义；更多细节（和更精确的表述）请参阅 Blitzstein 和 Hwang ([2014](#ref-blitzstein2014introduction))、Ross
    ([2002](#ref-RossProb))、Kerns ([2014](#ref-kerns2014introduction))、Resnick ([2019](#ref-resnick2019probability))
    或 Kolmogorov ([1933](#ref-kolmogorov2018foundations)) 等众多书籍）。请记住，不同的教科书在呈现概率空间（以下定义）的潜在结构方面略有不同。
- en: The probability of something happening is defined to be constrained in the way
    described below. A concrete example of “something happening” is an outcome–call
    it \(\omega\)–such as obtaining nine correct (\(c\)) answers and one incorrect
    (\(i\)) when we ask a subject \(10\) yes-no questions (say, about the meaning
    of a sentence). An example would be a sequence of correct (\(c\)) and incorrect
    (\(i\)) answers, such as \(iiiiciiiii\). Another possible outcome is \(cciicicici\).
    The outcomes are thus all possible sequences of correct and incorrect answers,
    and the sample space, \(\Omega\), is the set of all possible outcomes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 发生某事的概率被定义为受以下描述的方式约束。一个“发生某事”的具体例子是结果——称之为 \(\omega\)——例如在向受试者提出 \(10\) 个是非问题时（例如，关于句子含义的问题），得到九个正确（\(c\)）答案和一个错误（\(i\)）答案。一个例子是正确（\(c\)）和错误（\(i\)）答案的序列，例如
    \(iiiiciiiii\)。另一个可能的结果是 \(cciicicici\)。因此，结果就是所有可能的正确和错误答案的序列，样本空间 \(\Omega\)
    是所有可能结果的集合。
- en: Another important concept is events, \(E\), next; the event corresponding to
    obtaining one correct answer when \(10\) questions are asked, is the subset of
    outcomes \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,\ldots\}\); in other words, the
    event corresponding to obtaining one correct answer is a set containing \(10\)
    elements. Similarly, the event corresponding to obtaining nine correct answers
    when \(10\) questions are asked is the subset of outcomes \(\{ccccccccci,ccccccccic,\ldots
    \}\).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的概念是事件 \(E\)，接下来；当提出 \(10\) 个问题时，获得一个正确答案的事件是对应于结果子集 \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,\ldots\}\)；换句话说，获得一个正确答案的事件是一个包含
    \(10\) 个元素的集合。同样，当提出 \(10\) 个问题时，获得九个正确答案的事件是对应于结果子集 \(\{ccccccccci,ccccccccic,\ldots
    \}\)。
- en: 'When we conduct an experiment, if we get a particular outcome like \(ciiiiiiiii\),
    then we say that the event \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,\ldots\}\) occurred.
    A probability space involves two more key ingredients: A collection of subsets
    of \(\Omega\) denoted by \(F\) and called the *event space*;[¹](#fn1) and a real-valued
    function named \(P\) that assigns a number (a probability) to each set in \(F\).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行实验时，如果我们得到一个特定的结果，例如 \(ciiiiiiiii\)，那么我们就说事件 \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,\ldots\}\)
    发生了。一个概率空间涉及两个更关键的组成部分：由 \(F\) 表示的 \(\Omega\) 的子集集合，称为 *事件空间*；[¹](#fn1)；以及一个名为
    \(P\) 的实值函数，它将一个数字（一个概率）分配给 \(F\) 中的每个集合。
- en: Table [1.1](ch-intro.html#tab:probtab) summarizes the notation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1.1](ch-intro.html#tab:probtab) 总结了符号。
- en: 'TABLE 1.1: TABLE 1.2: Basic Probability Terminology for the 10-question example.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'TABLE 1.1: TABLE 1.2: 10 题例的基本概率术语。'
- en: '| Symbol | Name | Brief explanation | Example |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 名称 | 简要说明 | 示例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| \(\Omega\) | Sample space | The set of all possible outcomes | All possible
    sequences of correct (c) or incorrect (i) answers of length 10; that is \(2^{10}=1024\)
    sequences. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| \(\Omega\) | 样本空间 | 所有可能结果的集合 | 所有可能的长度为 10 的正确（c）或错误（i）答案的序列；即 \(2^{10}=1024\)
    个序列。 |'
- en: '| \(F\) | Event space | A collection of subsets of \(\Omega\) | All sequences
    with exactly 1 correct answer, or exactly 9 correct answers, etc. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| \(F\) | 事件空间 | \(\Omega\) 的子集集合 | 所有恰好有 1 个正确答案，或恰好有 9 个正确答案等的序列 |'
- en: '| \(P\) | Probability fun. | Assigns probabilities to events in \(F\) | If
    each question is answered correctly with probability \(\theta\), \(P(\{ciiiiiiiii\})
    = (1-\theta)^9\theta\). |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| \(P\) | 概率函数 | 将概率分配给 \(F\) 中的事件 | 如果每个问题以概率 \(\theta\) 正确回答，\(P(\{ciiiiiiiii\})
    = (1-\theta)^9\theta\)。 |'
- en: '| \(\omega\) | Outcome | An element of \(\Omega\) | The particular sequence
    \(ciiiiiiiii\). |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| \(\omega\) | 结果 | \(\Omega\) 的一个元素 | 特定的序列 \(ciiiiiiiii\)。 |'
- en: '| \(E\) | Event | A subset of \(\Omega\) | A collection of sequences \(\{ciiiiiiiii,
    iciiiiiiii, iiciiiiiii, \ldots\}\). |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| \(E\) | 事件 | \(\Omega\) 的子集 | 一系列序列 \(\{ciiiiiiiii, iciiiiiiii, iiciiiiiii,
    \ldots\}\)。 |'
- en: 'The probability axioms refer to the sample space \(\Omega\), event space \(F\),
    and probability \(P\) as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 概率公理涉及样本空间 \(\Omega\)、事件空间 \(F\) 和概率 \(P\)，如下所述：
- en: For every event \(E\) in the event space \(F\), the probability \(P(E)\) is
    a real number between \(0\) and \(1\).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于事件空间 \(F\) 中的每个事件 \(E\)，概率 \(P(E)\) 是介于 \(0\) 和 \(1\) 之间的实数。
- en: The event \(E=\Omega\) belongs to \(F\), and \(P(\Omega)=1\).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件 \(E=\Omega\) 属于 \(F\)，且 \(P(\Omega)=1\)。
- en: If the events \(A_1, A_2, A_3,...\) are mutually exclusive (in other words,
    if no two of these subsets of \(\Omega\) overlap), then the probability of the
    event “one of \(A_1\) or \(A_2\) or \(A_3\) or …” is given by the sum of the probability
    of \(A_1\) occurring, of \(A_2\) occurring, of \(A_3\) occurring, … (this sum
    could be finite or infinite).
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果事件 \(A_1, A_2, A_3,...\) 是互斥的（换句话说，如果这些 \(\Omega\) 的子集没有两个重叠），那么“\(A_1\) 或
    \(A_2\) 或 \(A_3\) 或 …”之一发生的事件的概率就是 \(A_1\) 发生的概率、\(A_2\) 发生的概率、\(A_3\) 发生的概率，……（这个和可能是有限的或无限的）。
- en: Together, the triplet \((\Omega, F, P)\) is called a *probability space*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一起，三元组 \((\Omega, F, P)\) 被称为**概率空间**。
- en: In the context of data analysis, we will talk about probability in the following
    way. Consider some data that we might have collected. This could be discrete \(0,1\)
    responses in a question-response accuracy task, or continuous measurements of
    reading times in milliseconds from an eyetracking study, or multi-category responses
    like “yes”, “no”, or “don’t know”, or electrical potentials on the microvolts
    scale.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析的背景下，我们将以下方式讨论概率。考虑我们可能收集的一些数据。这可能是在问题-响应准确度任务中的离散 \(0,1\) 响应，或从眼动研究中读取时间的毫秒级连续测量，或“是”、“否”或“不知道”等多类别响应，或微伏级上的电势。
- en: In any such case, we will say that the data are being generated from a *random
    variable*, which we will designate with a capital letter such as \(Y\).[²](#fn2)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何这样的情况下，我们都会说数据是从一个**随机变量**生成的，我们将用大写字母如 \(Y\) 来表示它。[²](#fn2)
- en: The actually observed outcome (a \(0,1\) response; reading time, a response
    like “yes”, “no”, “don’t know”, etc.) will be distinguished from the random variable
    that generated it by using lower case \(y\) for the observed outcome. We can call
    \(y\) an instance of \(Y\); every new observed outcome can be different due to
    random variability.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 实际观察到的结果（一个 \(0,1\) 响应；阅读时间，如“是”、“否”、“不知道”等）将通过使用小写 \(y\) 来区分生成它的随机变量。我们可以称
    \(y\) 为 \(Y\) 的一个实例；由于随机变异性，每个新的观察结果都可能不同。
- en: We can summarize the above informal concepts relating to random variables very
    compactly if we re-state them in mathematical form. A mathematical statement has
    the advantage not only of brevity but also of reducing (and hopefully eliminating)
    ambiguity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将与随机变量相关的上述非正式概念重新表述为数学形式，我们可以非常紧凑地总结它们。数学陈述的优点不仅在于简洁，而且在于减少（并希望消除）歧义。
- en: So, stating the definition of random variables formally (following Blitzstein
    and Hwang [2014](#ref-blitzstein2014introduction)), we define a random variable
    \(Y\) as a function from a sample space \(\Omega\) of possible outcomes \(\omega\)
    to the real number system:[³](#fn3)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，正式陈述随机变量的定义（遵循 Blitzstein 和 Hwang [2014](#ref-blitzstein2014introduction)），我们定义随机变量
    \(Y\) 为从可能结果样本空间 \(\Omega\) 到实数系统的函数：[³](#fn3)
- en: '\[\begin{equation} Y : \Omega \rightarrow \mathbb{R} \end{equation}\]'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\begin{equation} Y : \Omega \rightarrow \mathbb{R} \end{equation}\]'
- en: 'The random variable associates to each outcome \(\omega \in \Omega\) exactly
    one number \(Y(\omega) = y\). The number \(y\) is a variable that represents all
    the possible values that the random variable generates; these values are taken
    to belong to the support of the random variable \(Y\): \(y \in S_Y\).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量与 \(\Omega\) 中的每个结果 \(\omega\) 关联一个唯一的数字 \(Y(\omega) = y\)。数字 \(y\) 是一个变量，代表随机变量生成的所有可能值；这些值被认为是随机变量
    \(Y\) 的支撑集：\(y \in S_Y\)。
- en: In our running example of asking \(10\) questions and obtaining a correct or
    incorrect response in each of the \(10\) trials, \(Y(ciiiiiiiii) = 1\), \(Y(cciiiiiiii)
    = 2\), etc. We will say that the number of correct responses from a subject is
    generated from a random variable \(Y\). Because in our running example only discrete
    responses are possible (the number of correct responses can be \(0, 1, 2, \ldots,
    10\)), this is an example of a *discrete random variable*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们询问 \(10\) 个问题并从每个 \(10\) 次试验中获得正确或错误响应的运行示例中，\(Y(ciiiiiiiii) = 1\)，\(Y(cciiiiiiii)
    = 2\) 等。我们将说，从受试者那里得到的正确响应的数量是由随机变量 \(Y\) 生成的。因为在我们运行的示例中，只有离散响应是可能的（正确响应的数量可以是
    \(0, 1, 2, \ldots, 10\)），这是一个**离散随机变量**的例子。
- en: This particular random variable \(Y\) will be assumed to have a parameter \(\theta\)
    that represents the probability of producing a particular number of correct responses
    (as discussed below, you will see that the random variable in question is the
    binomial random variable). Given some observed data that is assumed to come from
    a particular distribution, typically our goal is to obtain an estimate of the
    (unknown) value of the parameter associated with that distribution. More generally,
    if there is more than one parameter involved in the distribution, then our goal
    is to obtain an estimate of these parameters.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的随机变量 \(Y\) 将被假定为具有一个参数 \(\theta\)，该参数代表产生特定数量正确反应的概率（如下文所述，你会看到所涉及的随机变量是二项式随机变量）。给定一些假设来自特定分布的观察数据，我们的目标通常是获得与该分布相关的（未知）参数值的估计。更普遍地，如果分布中涉及多个参数，那么我们的目标是获得这些参数的估计。
- en: 'Now, suppose that in our above example, the random variable \(Y\) gives us
    exactly one correct answer; this can be (somewhat sloppily) be written as \(Y=1\).
    The outcomes that could produce \(1\) are any of this set of ten possible outcomes:
    \(ciiiiiiiii\), \(iciiiiiiii\), \(iiciiiiiii\), \(iiiciiiiii\),…. The set \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,iiiciiiiii,...\}\)
    is an element of \(F\), so it is an event. The number \(y=1\) thus represents
    this event, and will have a probability of occurring associated with it; this
    is defined next.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设在我们上面的例子中，随机变量 \(Y\) 给出了恰好一个正确答案；这可以（有些草率地）写成 \(Y=1\)。产生 \(1\) 的结果可以是这组十个可能结果中的任何一个：\(ciiiiiiiii\)、\(iciiiiiiii\)、\(iiciiiiiii\)、\(iiiciiiiii\)、……。集合
    \(\{ciiiiiiiii,iciiiiiiii,iiciiiiiii,iiiciiiiii,...\}\) 是 \(F\) 的一个元素，因此它是一个事件。因此，\(y=1\)
    代表这个事件，并且将有一个与之相关的发生概率；这将在下一定义。
- en: A discrete random variable \(Y\) has associated with it a function called a
    *probability mass function* or PMF. This function, which is written \(p(y)\),
    gives us the probability of obtaining each of these \(11\) possible values (from
    0 correct responses to 10). We are using lower-case \(p(y)\) here to denote a
    function of \(y\). When we want to talk about the probability of observing \(y\),
    we will use \(P(y)\). In discrete random variables the value \(p(y)\) will be
    the same as \(P(y)\); but when we turn to continuous random variables, this equality
    will not hold.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个离散随机变量 \(Y\) 与一个称为**概率质量函数**或PMF的函数相关联。这个函数，写成 \(p(y)\)，给出了获得这 \(11\) 个可能值（从0个正确反应到10个）的概率。在这里我们使用小写
    \(p(y)\) 来表示 \(y\) 的函数。当我们想要谈论观察 \(y\) 的概率时，我们将使用 \(P(y)\)。在离散随机变量中，\(p(y)\) 的值将与
    \(P(y)\) 相同；但当我们转向连续随机变量时，这个等式将不再成立。
- en: We will write that this PMF \(p(y)\) depends on, or is conditional on, a particular
    fixed but unknown value for \(\theta\); the PMF will be written \(p(y|\theta)\).[⁴](#fn4)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将说明这个PMF \(p(y)\) 依赖于，或者是在一个特定的但未知的 \(\theta\) 值的条件下；PMF 将写成 \(p(y|\theta)\)。[⁴](#fn4)
- en: 'In frequentist approaches to data analysis, only the observed data \(y\) are
    used to draw inferences about \(\theta\). A typical question that we ask in the
    frequentist paradigm is: does \(\theta\) have a particular value \(\theta_0\)?
    One can obtain estimates of the unknown value of \(\theta\) from the observed
    data \(y\), and then draw inferences about how different–or more precisely how
    far away–this estimate is from the hypothesized \(\theta_0\). This is the essence
    of null hypothesis significance testing. The conclusions from such a procedure
    are framed in terms of either rejecting the hypothesis that \(\theta\) has value
    \(\theta_0\), or failing to reject this hypothesis. Here, rejecting the null hypothesis
    is the primary goal of the statistical hypothesis test.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在频率主义的数据分析方法中，仅使用观察到的数据 \(y\) 来推断 \(\theta\)。在频率主义范式下，我们通常会问这样一个问题：\(\theta\)
    是否具有特定的值 \(\theta_0\)？可以从观察数据 \(y\) 中获得 \(\theta\) 的未知值的估计，然后推断这个估计与假设的 \(\theta_0\)
    有多大不同——或者更精确地说，这个估计与 \(\theta_0\) 有多远。这就是零假设显著性检验的本质。这样的程序得出的结论是以拒绝 \(\theta\)
    具有值 \(\theta_0\) 的假设，或者未能拒绝这个假设的形式。在这里，拒绝零假设是统计假设检验的主要目标。
- en: Bayesian data analysis begins with a different question. What is common to the
    frequentist paradigm is the assumption that the data are generated from a random
    variable \(Y\) and that there is a function \(p(y|\theta)\) that depends on the
    parameter \(\theta\). Where the Bayesian approach diverges from the frequentist
    one is that an important goal is to express our uncertainty about \(\theta\).
    In other words, we treat the parameter \(\theta\) itself as a random variable,
    which means that we assign a probability distribution \(p(\theta)\) to this random
    variable. This distribution \(p(\theta)\) is called the *prior distribution* on
    \(\theta\); such a distribution could express our belief about the probability
    of correct responses, before we observe the data \(y\).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯数据分析从不同的问题开始。与频率派范式共同的是假设数据是从一个随机变量 \(Y\) 生成的，并且存在一个函数 \(p(y|\theta)\)，它依赖于参数
    \(\theta\)。贝叶斯方法与频率派方法的不同之处在于，一个重要的目标是表达我们对 \(\theta\) 的不确定性。换句话说，我们将参数 \(\theta\)
    本身视为一个随机变量，这意味着我们为这个随机变量分配一个概率分布 \(p(\theta)\)。这个分布 \(p(\theta)\) 被称为 \(\theta\)
    的 *先验分布*；这样的分布可以表达我们在观察数据 \(y\) 之前对正确响应概率的信念。
- en: In later chapters, we will spend some time trying to understand how such a prior
    distribution can be defined for a range of different research problems.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将花一些时间试图理解如何为不同研究问题定义这样的先验分布。
- en: 'Given such a prior distribution and some data \(y\), the end-product of a Bayesian
    data analysis is what is called the *posterior distribution* of the parameter
    (or parameters) given the data: \(p(\theta | y)\). This posterior distribution
    is the probability distribution of \(\theta\) after conditioning on \(y\), i.e.,
    after the data has been observed and is therefore known. All our statistical inference
    is based on this posterior distribution of \(\theta\); we can even carry out hypothesis
    tests that are analogous (but not identical) to the likelihood ratio based frequentist
    hypothesis tests.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这样的先验分布和一些数据 \(y\)，贝叶斯数据分析的最终结果是参数（或参数集）在给定数据 \(y\) 下的 *后验分布*：\(p(\theta |
    y)\)。这个后验分布是在对 \(y\) 进行条件化后的 \(\theta\) 的概率分布，即数据被观察并因此已知之后。我们所有的统计推断都是基于这个 \(\theta\)
    的后验分布；我们甚至可以进行类似于基于似然比频率派假设检验的假设检验。
- en: We already mentioned conditional probability above when discussing the probability
    of the data given some parameter \(\theta\), which we wrote as the PMF \(p(y|\theta)\).
    Conditional probability is an important concept in Bayesian data analysis, not
    least because it allows us to derive Bayes’ theorem. Let’s look at the definition
    of conditional probability next.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在讨论给定某些参数 \(\theta\) 的数据概率时已经提到了条件概率，我们将其写成 PMF \(p(y|\theta)\)。条件概率是贝叶斯数据分析中的一个重要概念，尤其是因为它允许我们推导出贝叶斯定理。接下来，让我们看看条件概率的定义。
- en: 1.2 Conditional probability
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 条件概率
- en: Suppose that \(A\) stands for some discrete event; an example would be “the
    streets are wet.” Suppose also that \(B\) stands for some other discrete event;
    an example is “it has been raining.” We can talk about the probability of the
    streets being wet given that it has been raining; or more generally, the probability
    of \(A\) given that \(B\) has happened.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 \(A\) 代表某个离散事件；一个例子是“街道湿了”。同样，假设 \(B\) 代表另一个离散事件；一个例子是“一直在下雨”。我们可以讨论在下雨的情况下街道湿的概率；或者更一般地，讨论在
    \(B\) 发生的情况下 \(A\) 的概率。
- en: This kind of statement is written as \(Prob(A|B)\) or more simply \(P(A|B)\).
    This is the conditional probability of \(A\) given \(B\). Conditional probability
    is defined as follows.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种陈述可以写成 \(Prob(A|B)\) 或更简单地 \(P(A|B)\)。这是在 \(B\) 的条件下 \(A\) 的条件概率。条件概率的定义如下。
- en: \[\begin{equation} P(A|B)= \frac{P(A,B)}{P(B)} \hbox{ where } P(B)>0 \end{equation}\]
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(A|B)= \frac{P(A,B)}{P(B)} \hbox{ 其中 } P(B)>0 \end{equation}\]
- en: 'The conditional probability of A given B is thus defined to be the joint probability
    of A and B, divided by the probability of B. We can rearrange the above equation
    so that we can talk about the joint probability of both events \(A\) and \(B\)
    happening. This joint probability can be computed by first taking \(P(B)\), the
    probability that event \(B\) (it has been raining) happens, and multiplying this
    by the probability that \(A\) happens conditional on \(B\), i.e., the probability
    that the streets are wet given it has been raining. This multiplication will give
    us \(P(A,B)\), the joint probability of \(A\) and \(B\), i.e., that it has been
    raining and that the streets are wet. We will write the above description as:
    \(P(A,B)=P(A|B)P(B)\).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，给定B的A的条件概率被定义为A和B的联合概率除以B的概率。我们可以重新排列上述方程，以便我们可以讨论事件A和B同时发生的联合概率。这个联合概率可以通过首先取\(P(B)\)，即事件B（下雨）发生的概率，然后乘以在B发生的条件下A发生的概率，即下雨时街道湿的概率。这个乘积将给出\(P(A,B)\)，即A和B的联合概率，即下雨且街道湿。我们将上述描述写为：\(P(A,B)=P(A|B)P(B)\)。
- en: 'Now, since the probability \(A\) and \(B\) happening is the same as the probability
    of \(B\) and \(A\) happening, i.e., since \(P(B,A)=P(A,B)\), we can equate the
    expansions of these two terms:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于A和B同时发生的概率与B和A同时发生的概率相同，即由于\(P(B,A)=P(A,B)\)，我们可以将这两个项的展开式相等。
- en: \[\begin{equation} P(A,B) = P(A|B) P(B) \hbox{ and } P(B,A) = P(B|A)P(A) \end{equation}\]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(A,B) = P(A|B) P(B) \hbox{ and } P(B,A) = P(B|A)P(A) \end{equation}\]
- en: 'Equating the two expansions, we get:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个展开式相等，我们得到：
- en: \[\begin{equation} P(A|B) P(B) = P(B|A)P(A) \end{equation}\]
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(A|B) P(B) = P(B|A)P(A) \end{equation}\]
- en: 'Dividing both sides by \(P(B)\):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 两边除以\(P(B)\)：
- en: \[\begin{equation} P(A|B)=\frac{P(B|A)P(A)}{P(B)} \end{equation}\]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(A|B)=\frac{P(B|A)P(A)}{P(B)} \end{equation}\]
- en: The above statement is Bayes’ rule, and is the basis for all the statistical
    inference we will do in this book.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 上述陈述是贝叶斯定理，是本书中我们将要做的所有统计推断的基础。
- en: 1.3 The law of total probability
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 全概率公式
- en: Related to the above discussion of conditional probability is the law of total
    probability. Suppose that we have \(A_1,\dots,A_n\) distinct events that are pairwise
    disjoint which together make up the entire sample space \(\Omega\); see Figure
    [1.1](ch-intro.html#fig:lotp). Then, \(P(B)\), the probability of \(B\) happening,
    will be the sum of the probabilities \(P(B\cap A_i)\), i.e., the sum of the joint
    probabilities of \(B\) and each \(A\) occurring (the symbol \(\cap\) is the “and”
    operator used in set theory). The use of \(\cap\) to represent joint probability
    is just an alternative notation to the one we used earlier (\(P(B,A_i)\)); you
    may see both notational variants in textbooks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述关于条件概率的讨论相关的是全概率公式。假设我们有一些互斥事件\(A_1,\dots,A_n\)，它们共同构成了整个样本空间\(\Omega\)；参见图[1.1](ch-intro.html#fig:lotp)。那么，\(P(B)\)，即B发生的概率，将是\(P(B\cap
    A_i)\)的概率之和，即B和每个A发生的联合概率（符号\(\cap\)是集合论中使用的“和”运算符）。使用\(\cap\)来表示联合概率只是我们之前使用的符号（\(P(B,A_i)\)）的另一种表示方法；你可能在教科书中看到这两种符号变体。
- en: 'Formally:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上：
- en: \[\begin{equation} P(B) = \sum_{i=1}^n P(B \cap A_i) \end{equation}\]
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(B) = \sum_{i=1}^n P(B \cap A_i) \end{equation}\]
- en: 'Because of the conditional probability rule, we can rewrite this as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于条件概率规则，我们可以将其重写为：
- en: \[\begin{equation} P(B) = \sum_{i=1}^n P(B | A_i) P(A_i) \end{equation}\]
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} P(B) = \sum_{i=1}^n P(B | A_i) P(A_i) \end{equation}\]
- en: Thus, the probability of \(B\) is the sum of the conditional probabilities \(P(B|A_i)\)
    weighted by the probability \(P(A_i)\). We will see the law of total probability
    in action below when we talk about *marginal likelihood*.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，B的概率是条件概率\(P(B|A_i)\)按概率\(P(A_i)\)加权的和。当我们讨论*marginal likelihood*时，你将在下面看到全概率公式的应用。
- en: '![An illustration of the law of total probability.](../Images/aede69bf5bc5a8c621df41cf917d212c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![全概率公式的插图](../Images/aede69bf5bc5a8c621df41cf917d212c.png)'
- en: 'FIGURE 1.1: An illustration of the law of total probability.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：全概率公式的插图。
- en: For now, this is all the probability theory we need to know!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这就是我们需要的所有概率论知识了！
- en: The next sections expand on the idea of a random variable, the probability distributions
    associated with the random variable, what it means to specify a prior distribution
    on a parameter, and how the prior and data can be used to derive the posterior
    distribution of \(\theta\).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将扩展随机变量的概念，与随机变量相关的概率分布，指定参数先验分布的含义，以及如何使用先验和数据进行 \(\theta\) 的后验分布推导。
- en: To make the discussion concrete, we will use an example of a discrete random
    variable, the binomial. After discussing this discrete random variable, we present
    another example, this time involving a continuous random variable, the normal
    random variable.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使讨论具体化，我们将使用一个离散随机变量的例子，即二项分布。在讨论这个离散随机变量之后，我们将提供另一个例子，这次涉及一个连续随机变量，即正态随机变量。
- en: 'The binomial and normal cases serve as the canonical examples that we will
    need in the initial stages of this book. We will introduce other random variables
    as needed: in particular, we will need the uniform and beta distributions. In
    other textbooks, you will encounter distributions like the Poisson, gamma, and
    the exponential. The most commonly used distributions and their properties are
    discussed in most textbooks on statistics (see Further Reading at the end of this
    chapter).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布和正态分布是我们在本书初期阶段需要的典型例子。根据需要，我们将介绍其他随机变量：特别是，我们需要均匀分布和贝塔分布。在其他教科书中，你将遇到泊松分布、伽马分布和对数正态分布。最常见的分布及其性质在大多数统计学教科书中都有讨论（参见本章末尾的进一步阅读）。
- en: '1.4 Discrete random variables: An example using the binomial distribution'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 离散随机变量：使用二项分布的例子
- en: 'Consider the following sentence:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下句子：
- en: '*“It’s raining, I’m going to take the ….”*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*“下雨了，我要带……”*'
- en: 'Suppose that our research goal is to estimate the probability, call it \(\theta\),
    of the word “umbrella” appearing in this sentence, versus any other word. If the
    sentence is completed with the word “umbrella”, we will refer to it as a success;
    any other completion will be referred to as a failure. This is an example of a
    binomial random variable: given \(n\) trials, there can be only two possible outcomes
    in each trial, a success or a failure, and there is some true unknown probability
    \(\theta\) of success that we want to estimate. When the number of trials \(n\)
    is one, the random variable is called a Bernoulli distribution. So the Bernoulli
    distribution is the binomial distribution with the number of trials \(n=1\).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的研究目标是估计单词“雨伞”出现在这个句子中的概率，称为 \(\theta\)，与任何其他单词相比。如果句子以单词“雨伞”结束，我们将称之为成功；任何其他完成方式将被视为失败。这是一个二项随机变量的例子：在
    \(n\) 次试验中，每次试验只有两种可能的结果，成功或失败，并且存在某个真实的未知成功概率 \(\theta\)，我们想要估计。当试验次数 \(n\) 为一时，随机变量被称为伯努利分布。因此，伯努利分布是试验次数
    \(n=1\) 的二项分布。
- en: One way to empirically estimate this probability of success is to carry out
    a *cloze task*. In a cloze task, subjects are asked to complete a fragment of
    the original sentence, such as “It’s raining, I’m going to take the …”. The predictability
    or cloze probability of “umbrella” is then calculated as the proportion of times
    that the target word “umbrella” was produced as an answer by subjects.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 估计成功概率的一种经验方法是进行 *完形填空任务*。在完形填空任务中，受试者被要求完成原始句子的一个片段，例如“下雨了，我要带……”。然后计算“雨伞”的可预测性或完形填空概率，作为受试者产生目标单词“雨伞”作为答案的比例。
- en: Assume for simplicity that \(10\) subjects are asked to complete the above sentence;
    each subject does this task only once. This gives us \(10\) independent trials
    that are either coded a success (“umbrella” was produced) or as a failure (some
    other word was produced). We can sum up the number of successes to calculate how
    many of the \(10\) trials had “umbrella” as a response. For example, if \(8\)
    instances of “umbrella” are produced in \(10\) trials, we would estimate the cloze
    probability of producing “umbrella” to be \(8/10\).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，假设有 \(10\) 个受试者被要求完成上述句子；每个受试者只完成一次任务。这给我们 \(10\) 个独立的试验，这些试验要么被编码为成功（产生了“雨伞”），要么被编码为失败（产生了其他单词）。我们可以总结成功次数来计算有多少次
    \(10\) 次试验以“雨伞”作为回应。例如，如果在 \(10\) 次试验中产生了 \(8\) 个“雨伞”实例，我们将估计产生“雨伞”的完形填空概率为 \(8/10\)。
- en: We can repeatedly generate simulated sequences of the number of successes in
    R (later on we will demonstrate how to generate such random sequences of simulated
    data). Here is a case where we carry out \(20\) experiments, and each experiment
    will have \(10\) trials.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 R 中反复生成成功次数的模拟序列（稍后我们将演示如何生成此类模拟数据的随机序列）。这里是一个我们进行 \(20\) 次实验的例子，每次实验将进行
    \(10\) 次试验。
- en: Before we look at the R code for generating such simulated data, some notational
    conventions are needed to avoid confusion. In the function we use below (`rbinom()`)
    for generating simulated data, `n` refers to the number of experiments, which
    in the R function’s terminology is the number of observations. By contrast, `size`
    is the number of trials. This means that in the example below, `n` refers to the
    number of experiments conducted; because in R-speak these are called observations,
    we are also going to adopt this terminology. So, if \(20\) experiments are done,
    each with \(10\) trials, we will say that we have \(20\) observations, each with
    \(10\) trials.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看生成此类模拟数据的 R 代码之前，需要一些符号约定以避免混淆。在我们下面使用的函数（`rbinom()`）中生成模拟数据时，`n` 指的是实验次数，在
    R 函数术语中是观察次数。相比之下，`size` 是试验次数。这意味着在下面的例子中，`n` 指的是进行的实验次数；因为在 R 术语中这些被称为观察，我们也将采用这种术语。因此，如果进行了
    \(20\) 次实验，每次实验 \(10\) 次试验，我们将说我们有 \(20\) 次观察，每次观察 \(10\) 次试验。
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The number of successes in each of the \(20\) simulated observations above is
    being generated by a discrete random variable \(Y\) with a probability distribution
    \(p(y|\theta)\) called the *binomial distribution*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 \(20\) 次模拟观察中每次成功次数是由一个离散随机变量 \(Y\) 生成的，其概率分布为 \(p(y|\theta)\)，称为**二项分布**。
- en: For discrete random variables such as the binomial, the probability distribution
    \(p(y|\theta)\) is called a probability mass function (PMF). The PMF defines the
    probability of each possible event. In the above example, with the number of trials
    \(\hbox{size}=10\), there are in principle \(11\) possible events that could produce
    \(y=0,1,2,...,10\) successes. Which of these is most probable depends on the parameter
    \(\theta\) in the binomial distribution that represents the probability of success.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二项分布等离散随机变量，概率分布 \(p(y|\theta)\) 被称为概率质量函数（PMF）。PMF 定义了每个可能事件的概率。在上面的例子中，试验次数
    \(\hbox{size}=10\)，原则上存在 \(11\) 种可能的事件，这些事件可能导致 \(y=0,1,2,...,10\) 次成功。其中哪种事件最可能发生取决于二项分布中的参数
    \(\theta\)，该参数代表成功的概率。
- en: The left-hand side plot in Figure [1.2](ch-intro.html#fig:binomplot) shows an
    example of a binomial PMF with \(10\) trials, with the parameter \(\theta\) fixed
    at \(0.5\). Setting \(\theta\) to \(0.5\) leads to a PMF where the most probable
    outcome is \(5\) successes out of \(10\). If we had set \(\theta\) to, say \(0.1\),
    then the most probable outcome would be \(1\) success out of \(10\); and if we
    had set \(\theta\) to \(0.9\), then the most probable outcome would be \(9\) successes
    out of \(10\).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1.2](ch-intro.html#fig:binomplot) 中左侧的图显示了 \(10\) 次试验的二项 PMF 的一个例子，其中参数 \(\theta\)
    固定为 \(0.5\)。将 \(\theta\) 设置为 \(0.5\) 导致最可能的输出是 \(10\) 次试验中的 \(5\) 次成功。如果我们把 \(\theta\)
    设置为，比如说 \(0.1\)，那么最可能的输出将是 \(10\) 次试验中的 \(1\) 次成功；如果我们把 \(\theta\) 设置为 \(0.9\)，那么最可能的输出将是
    \(10\) 次试验中的 \(9\) 次成功。
- en: '![Probability mass functions of a binomial distribution assuming 10 trials,
    with 50%, 10%, and 90% probability of success.](../Images/85fb0150182abed19ee71205f1fa4290.png)![Probability
    mass functions of a binomial distribution assuming 10 trials, with 50%, 10%, and
    90% probability of success.](../Images/ac61fb0cc13e47924b581a53fd97d10b.png)![Probability
    mass functions of a binomial distribution assuming 10 trials, with 50%, 10%, and
    90% probability of success.](../Images/ce283a3ebfdbd74525e310e006a6ff88.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![假设有 \(10\) 次试验的二项分布的概率质量函数，成功概率分别为 50%，10% 和 90%。](../Images/85fb0150182abed19ee71205f1fa4290.png)![假设有
    \(10\) 次试验的二项分布的概率质量函数，成功概率分别为 50%，10% 和 90%。](../Images/ac61fb0cc13e47924b581a53fd97d10b.png)![假设有
    \(10\) 次试验的二项分布的概率质量函数，成功概率分别为 50%，10% 和 90%。](../Images/ce283a3ebfdbd74525e310e006a6ff88.png)'
- en: 'FIGURE 1.2: Probability mass functions of a binomial distribution assuming
    10 trials, with 50%, 10%, and 90% probability of success.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：假设有 \(10\) 次试验的二项分布的概率质量函数，成功概率分别为 50%，10% 和 90%。
- en: The probability mass function for the binomial is written as follows. Here,
    it is again important to pay attention to the notation, as there is potential
    for confusion given the conventions in the `rbinom` function we saw earlier.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布的概率质量函数写作如下。在这里，再次需要注意符号，因为考虑到我们之前看到的 `rbinom` 函数中的约定，这里存在混淆的可能性。
- en: \[\begin{equation} \mathit{Binomial}(k|n,\theta) = \binom{n}{k} \theta^{k} (1-\theta)^{n-k}
    \end{equation}\]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \mathit{Binomial}(k|n,\theta) = \binom{n}{k} \theta^{k} (1-\theta)^{n-k}
    \end{equation}\]
- en: Here, \(n\) represents the total number of **trials**, and corresponds to `size`
    in the `rbinom` function; the confusion that can arise here is that in the `rbinom`
    function `n` is used to represent the number of observations (or the number of
    experiments). It is important to remember that in the definition of the probability
    mass function above, \(n\) represents the total number of trials in a single observation
    (or experiment).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，\(n\) 代表试验的总次数，对应于 `rbinom` 函数中的 `size`；这里可能出现的混淆是，在 `rbinom` 函数中，`n` 用于表示观察次数（或实验次数）。重要的是要记住，在上面的概率质量函数的定义中，`n`
    代表单个观察（或实验）中的试验总次数。
- en: 'The variable \(k\) the number of successes (this could range from \(0\) to
    \(10\) in our running example), and \(\theta\) the probability of success. The
    term \(\binom{n}{k}\), pronounced n-choose-k, represents the number of ways in
    which one can obtain \(k\) successes in an experiment with \(n\) trials. For example,
    \(1\) success out of \(10\) can occur in \(10\) possible ways: the very first
    observation could be a \(1\), or the second observation could be a \(1\), etc.
    The term \(\binom{n}{k}\) expands to \(\frac{n!}{k!(n-k)!}\). In R, it is computed
    using the function `choose(n,k)`, with \(n\) and \(k\) representing any real number
    (although of course, the `choose()` function only makes sense for positive integers).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 \(k\) 表示成功次数（在我们的例子中，这可能从 \(0\) 到 \(10\) 不等），而 \(\theta\) 表示成功的概率。术语 \(\binom{n}{k}\)，读作
    n-choose-k，表示在 \(n\) 次试验中取得 \(k\) 次成功的方式数量。例如，从 \(10\) 次试验中取得 \(1\) 次成功可以以 \(10\)
    种可能的方式发生：第一次观察可能是 \(1\)，或者第二次观察可能是 \(1\)，等等。术语 \(\binom{n}{k}\) 展开为 \(\frac{n!}{k!(n-k)!}\)。在
    R 中，它使用函数 `choose(n,k)` 计算，其中 \(n\) 和 \(k\) 代表任何实数（尽管当然，`choose()` 函数只对正整数有意义）。
- en: When we want to express the fact that the data is assumed to be generated from
    a binomial random variable, we will write \(Y \sim \mathit{Binomial}(n,\theta)\).
    If the data is generated from a random variable that has some other probability
    distribution \(f(\theta)\), we will write \(Y\sim f(\theta)\). In this book, we
    use \(f(\cdot)\) synonymously with \(p(\cdot)\) to represent a probability density/mass
    function.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要表达数据是从二项随机变量生成的这一事实时，我们将写作 \(Y \sim \mathit{Binomial}(n,\theta)\)。如果数据是从具有某种其他概率分布
    \(f(\theta)\) 的随机变量生成的，我们将写作 \(Y\sim f(\theta)\)。在这本书中，我们用 \(f(\cdot)\) 和 \(p(\cdot)\)
    同义地表示概率密度/质量函数。
- en: 1.4.1 The mean and variance of the binomial distribution
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 二项分布的均值和方差
- en: It is possible to analytically compute the mean (expectation) and variance of
    the PMF associated with the binomial random variable \(Y\).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 可以解析地计算与二项随机变量 \(Y\) 相关的概率质量函数的均值（期望）和方差。
- en: The expectation of a discrete random variable \(Y\) with probability mass function
    f(y), is defined as
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 具有概率质量函数 f(y) 的离散随机变量 \(Y\) 的期望值定义为
- en: \[\begin{equation} E[Y] = y_1 \cdot f(y_1) + \dots + y_n \cdot f(y_n) = \sum_{i=1}^n
    y_i \cdot f(y_i) \end{equation}\]
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} E[Y] = y_1 \cdot f(y_1) + \dots + y_n \cdot f(y_n) = \sum_{i=1}^n
    y_i \cdot f(y_i) \end{equation}\]
- en: 'As a simple example, suppose that we toss a fair coin once. The possible events
    are Tails (represented as \(y_1 = 0\)) and Heads (represented as \(y_2 = 1\)),
    each with equal probability, 0.5\. The expectation is:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为简单的例子，假设我们掷一枚公平的硬币一次。可能的事件是反面（表示为 \(y_1 = 0\)）和正面（表示为 \(y_2 = 1\)），每个事件发生的概率相等，为
    0.5。期望值是：
- en: \[\begin{equation} E[Y] = \sum_{i=1}^{2} y_i \cdot f(y_i) = 0\cdot 0.5 + 1\cdot
    0.5 = 0.5 \end{equation}\]
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} E[Y] = \sum_{i=1}^{2} y_i \cdot f(y_i) = 0\cdot 0.5 + 1\cdot
    0.5 = 0.5 \end{equation}\]
- en: The expectation has the interpretation that if we were to do the experiment
    a large number of times and calculate the sample mean of the observations, in
    the long run we would approach the value \(0.5\). Another way to look at the above
    definition is that the expectation gives us the weighted mean of the possible
    outcomes, weighted by the respective probabilities of each outcome.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的解释是，如果我们多次进行实验并计算观察值的样本均值，从长远来看，我们会接近 \(0.5\) 这个值。另一种看待上述定义的方式是，期望给出了可能结果的加权平均值，加权系数为每个结果的相应概率。
- en: Without getting into the details of how these are derived mathematically (Kerns
    [2014](#ref-kerns2014introduction)), we just state here that the mean of \(Y\)
    (the expectation \(E[Y]\)) and the variance of \(Y\) (written \(Var(Y)\)) of a
    binomial distribution with parameter \(\theta\) and \(n\) trials are \(E[Y] =
    n\theta\) and \(Var(Y) = n\theta (1-\theta)\), respectively.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们不深入探讨这些是如何从数学上推导出来的（参见 Kerns [2014](#ref-kerns2014introduction)），我们只是在这里声明，二项分布（参数为
    \(\theta\) 和 \(n\) 次试验）的期望 \(Y\)（期望 \(E[Y]\)）和方差 \(Y\)（记作 \(Var(Y)\)）分别是 \(E[Y]
    = n\theta\) 和 \(Var(Y) = n\theta (1-\theta)\)。
- en: In the binomial example above, \(n\) is a fixed number because we decide on
    the total number of trials before running the experiment. In the PMF, \(\binom{n}{k}
    \theta^{k} (1-\theta)^{n-k}\), \(\theta\) is also a fixed value; the only variable
    in a PMF is \(k\). In real experimental situations, we never know the true point
    value of \(\theta\). But \(\theta\) can be estimated from the data. From the observed
    data, we can compute the estimate of \(\theta\), \(\hat \theta=k/n\). The quantity
    \(\hat \theta\) is the observed proportion of successes, and is called the *maximum
    likelihood estimate* of the true (but unknown) parameter \(\theta\).[⁵](#fn5)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述二项分布的例子中，\(n\) 是一个固定的数字，因为我们决定在运行实验之前进行总试验次数。在概率质量函数 \(\binom{n}{k} \theta^{k}
    (1-\theta)^{n-k}\) 中，\(\theta\) 也是一个固定的值；在概率质量函数中，唯一可变的变量是 \(k\)。在现实实验中，我们永远不知道
    \(\theta\) 的真实点值。但 \(\theta\) 可以从数据中估计出来。从观察数据中，我们可以计算 \(\theta\) 的估计值，\(\hat
    \theta=k/n\)。量 \(\hat \theta\) 是观察到的成功比例，被称为对真实（但未知）参数 \(\theta\) 的 *最大似然估计*。[⁵](#fn5)
- en: What does the term “maximum likelihood estimate” mean? In order to understand
    this term, it is necessary to first understand what a likelihood function is.
    Recall that in the discussion above, the PMF \(p(k|n,\theta)\) assumes that \(\theta\)
    and \(n\) are fixed, and \(k\) will have some value between \(0\) and \(10\) when
    the experiment is repeated multiple times.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: “最大似然估计”这个术语是什么意思？为了理解这个术语，首先需要了解什么是似然函数。回想一下，在上面的讨论中，概率质量函数 \(p(k|n,\theta)\)
    假设 \(\theta\) 和 \(n\) 是固定的，当实验重复多次时，\(k\) 将在 \(0\) 到 \(10\) 之间取某个值。
- en: The *likelihood function* refers to the PMF \(p(k|n,\theta)\), treated as a
    function of \(\theta\). Once we have observed a particular value for \(k\), this
    value is now fixed, along with the number of trials \(n\). Once \(k\) and \(n\)
    are fixed, the function \(p(k|n,\theta)\) only depends on \(\theta\). Thus, the
    likelihood function is the same function as the PMF, but assumes that the data
    from the completed experiment is fixed and only the parameter \(\theta\) varies
    (from 0 to 1). The likelihood function is written \(\mathcal{L}(\theta| k,n)\),
    or simply \(\mathcal{L}(\theta)\).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: “似然函数”指的是概率质量函数 \(p(k|n,\theta)\)，将其视为 \(\theta\) 的函数。一旦观察到 \(k\) 的特定值，这个值现在就固定了，同时试验次数
    \(n\) 也固定了。一旦 \(k\) 和 \(n\) 固定，函数 \(p(k|n,\theta)\) 只依赖于 \(\theta\)。因此，似然函数与概率质量函数是同一个函数，但假设完成实验的数据是固定的，只有参数
    \(\theta\) 变化（从 0 到 1）。似然函数写作 \(\mathcal{L}(\theta| k,n)\)，或者简单地写作 \(\mathcal{L}(\theta)\)。
- en: 'For example, suppose that we have \(n=10\) trials, and observe \(k=7\) successes.
    The likelihood function is:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有 \(n=10\) 次试验，观察到 \(k=7\) 次成功。似然函数是：
- en: \[\begin{equation} \mathcal{L}(\theta|k=7,n=10)= \binom{10}{7} \theta^{7} (1-\theta)^{10-7}
    \end{equation}\]
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \mathcal{L}(\theta|k=7,n=10)= \binom{10}{7} \theta^{7} (1-\theta)^{10-7}
    \end{equation}\]
- en: If we now plot the likelihood function for all possible values of \(\theta\)
    ranging from \(0\) to \(1\), we get the plot shown in Figure [1.3](ch-intro.html#fig:binomlik-lawlargenos)(a).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在绘制从 \(0\) 到 \(1\) 的所有可能 \(\theta\) 值的似然函数，我们得到图 [1.3](ch-intro.html#fig:binomlik-lawlargenos)(a)
    所示的图表。
- en: '![(a) The likelihood function for 7 successes out of 10\. (b) The plot shows
    the estimate of the mean proportion of successes sampled from a binomial distribution
    with true probability of success 0.7, with increasing sample sizes. As the sample
    size increases, the estimate converges to  the true value of 0.7.](../Images/4672235f8c5649547c785db7690f93b1.png)![(a)
    The likelihood function for 7 successes out of 10\. (b) The plot shows the estimate
    of the mean proportion of successes sampled from a binomial distribution with
    true probability of success 0.7, with increasing sample sizes. As the sample size
    increases, the estimate converges to  the true value of 0.7.](../Images/50e97813d60611f2db612225e29be02e.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![（a）10次试验中7次成功的似然函数。（b）该图显示了从具有成功概率为0.7的二项分布中抽取的成功比例的均值估计，随着样本量的增加。随着样本量的增加，估计值收敛到0.7的真实值。](../Images/4672235f8c5649547c785db7690f93b1.png)![（a）10次试验中7次成功的似然函数。（b）该图显示了从具有成功概率为0.7的二项分布中抽取的成功比例的均值估计，随着样本量的增加。随着样本量的增加，估计值收敛到0.7的真实值。](../Images/50e97813d60611f2db612225e29be02e.png)'
- en: 'FIGURE 1.3: (a) The likelihood function for 7 successes out of 10\. (b) The
    plot shows the estimate of the mean proportion of successes sampled from a binomial
    distribution with true probability of success 0.7, with increasing sample sizes.
    As the sample size increases, the estimate converges to the true value of 0.7.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：（a）10次试验中7次成功的似然函数。（b）该图显示了从具有成功概率为0.7的二项分布中抽取的成功比例的均值估计，随着样本量的增加。随着样本量的增加，估计值收敛到0.7的真实值。
- en: 'What is important about this plot is that it shows that, given the data, the
    maximum point is at the point \(0.7\), which corresponds to the estimated mean
    using the formula shown above: \(k/n = 7/10\). Thus, the maximum likelihood estimate
    (MLE) gives us the most likely value that the parameter \(\theta\) has, given
    the data. In the binomial, the proportion of successes \(k/n\) can be shown to
    be the maximum likelihood estimate of the parameter \(\theta\) (e.g., see p. 339-340
    of Miller and Miller [2004](#ref-millermiller)).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图的重要之处在于，它表明，给定数据，最大值点在 \(0.7\) 处，这对应于使用上面显示的公式估计的均值：\(k/n = 7/10\)。因此，最大似然估计（MLE）给出了给定数据下参数
    \(\theta\) 最可能具有的值。在二项分布中，成功比例 \(k/n\) 可以被证明是参数 \(\theta\) 的最大似然估计（例如，参见 Miller
    和 Miller [2004](#ref-millermiller) 第 339-340 页）。
- en: 'A crucial point: the “most likely” value of the parameter is with respect to
    the data at hand. The goal is to estimate an unknown parameter value from the
    data. This estimated parameter value is chosen such that the probability (discrete
    case) or probability density (continuous case) of getting the sample values (i.e.,
    the data) is a maximum. This parameter value is the maximum likelihood estimate
    (MLE).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键点：参数的“最可能”值是相对于现有数据的。目标是根据数据估计一个未知参数值。这个估计的参数值被选择，使得得到样本值（即数据）的概率（离散情况）或概率密度（连续情况）是最大的。这个参数值就是最大似然估计（MLE）。
- en: This MLE from a particular sample of data need not invariably give us an accurate
    estimate of \(\theta\). For example, if we run our experiment with \(10\) trials
    and get \(1\) success out of \(10\), the MLE is \(0.10\). We could have just happened
    to observe only one success out of ten by chance, even if the true \(\theta\)
    were \(0.7\). If we were to repeatedly run the experiment with increasing sample
    sizes, as the sample size increases, the MLE would converge to the true value
    of the parameter. Figure [1.3](ch-intro.html#fig:binomlik-lawlargenos)(b) illustrates
    this point. The key point here is that with a smaller sample size, the MLE from
    a particular data set may or may not point to the true value.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从特定数据样本得到的MLE不一定总是给我们一个准确的\(\theta\)估计。例如，如果我们进行10次试验，10次中有1次成功，MLE是0.10。我们可能只是偶然观察到10次中只有1次成功，即使真实的\(\theta\)是0.7。如果我们反复进行实验，并随着样本量的增加，MLE会收敛到参数的真实值。图[1.3](ch-intro.html#fig:binomlik-lawlargenos)(b)说明了这一点。这里的关键点是，对于较小的样本量，特定数据集的MLE可能指向也可能不指向真实值。
- en: 1.4.2 What information does a probability distribution provide?
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.2 概率分布提供了哪些信息？
- en: 'In Bayesian data analysis, we will constantly be asking the question: what
    information does a probability distribution give us? In particular, we will treat
    each parameter \(\theta\) as a random variable; this will raise questions like:
    “what is the probability that the parameter \(\theta\) lies between two values
    \(a\) and \(b\)”; and “what is the range over which we can be 95% certain that
    the parameter lies”? In order to be able to answer questions like these, we need
    to know what information we can obtain once we have decided on a probability distribution
    that is assumed to have generated the data, and how to extract this information
    using R. We therefore discuss the different kinds of information we can obtain
    from a probability distribution. For now we focus only on the binomial random
    variable introduced above.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯数据分析中，我们将不断提出问题：概率分布给我们提供了哪些信息？特别是，我们将把每个参数 \(\theta\) 视为一个随机变量；这将引发像“参数
    \(\theta\) 落在两个值 \(a\) 和 \(b\) 之间的概率是多少”以及“我们可以在多大程度上有 95% 的把握说参数落在哪个范围内”等问题。为了能够回答这些问题，我们需要知道一旦我们决定了一个假设生成数据的概率分布，我们可以从中获得哪些信息，以及如何使用
    R 提取这些信息。因此，我们讨论了可以从概率分布中获得的不同类型的信息。现在我们只关注上面介绍的二项随机变量。
- en: 1.4.2.1 Compute the probability of a particular outcome (discrete case only)
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.2.1 计算特定结果的概率（仅适用于离散情况）
- en: 'The binomial distribution shown in Figure [1.2](ch-intro.html#fig:binomplot)
    already shows the probability of each possible event under a different value for
    \(\theta\). In R, there is a built-in function that allows us to calculate the
    probability of \(k\) successes out of \(n\), given a particular value of \(k\)
    (this number constitutes our data), the number of trials \(n\), and given a particular
    value of \(\theta\); this is the `dbinom()` function. For example, the probability
    of 5 successes out of 10 when \(\theta\) is \(0.5\) is (note: we are using \(k\)
    to represent the number of successes, but the `dbinom()` function below uses `x`
    instead):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1.2](ch-intro.html#fig:binomplot) 中显示的二项分布已经显示了在 \(\theta\) 不同值下每个可能事件的概率。在
    R 中，有一个内置函数允许我们计算在给定的 \(k\)（这个数字构成了我们的数据）、试验次数 \(n\) 和特定的 \(\theta\) 值下，\(k\)
    次成功的概率；这就是 `dbinom()` 函数。例如，当 \(\theta\) 为 \(0.5\) 时，10 次试验中 5 次成功的概率是（注意：我们用
    \(k\) 来表示成功的次数，但下面的 `dbinom()` 函数使用 `x` 代替）：
- en: '[PRE2]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The probabilities of success when \(\theta\) is \(0.1\) or \(0.9\) can be computed
    by replacing \(0.5\) above by each of these probabilities. One can just do this
    by giving `dbinom()` a vector of probabilities:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(\theta\) 为 \(0.1\) 或 \(0.9\) 时，成功的概率可以通过将上面的 \(0.5\) 替换为这些概率之一来计算。只需通过给
    `dbinom()` 函数提供一个概率向量即可完成此操作：
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The probability of a particular outcome like \(k=5\) successes is only computable
    in the discrete case. In the continuous case, the probability of obtaining a particular
    point value will always be zero (we discuss this when we turn to continuous probability
    distributions below).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 特定结果（如 \(k=5\) 次成功）的概率仅在离散情况下可计算。在连续情况下，获得特定点值的概率始终为零（我们将在下面讨论连续概率分布时讨论这一点）。
- en: 1.4.2.2 Compute the cumulative probability of k or less (more) than k successes
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.2.2 计算成功次数为 k 或更少（或更多）的累积概率
- en: 'Using the `dbinom()` function, we can compute the cumulative probability of
    obtaining 1 or less, 2 or less successes, etc. This is done through a simple summation
    procedure:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `dbinom()` 函数，我们可以计算获得 1 次或更少、2 次或更少成功等的累积概率。这是通过一个简单的求和过程完成的：
- en: '[PRE6]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Mathematically, we could write the above summation as:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，我们可以将上面的求和写成：
- en: \[\begin{equation} \sum_{k=0}^2 \binom{n}{k} \theta^{k} (1-\theta)^{n-k} \end{equation}\]
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \sum_{k=0}^2 \binom{n}{k} \theta^{k} (1-\theta)^{n-k} \end{equation}\]
- en: 'An alternative to the cumbersome addition in the R code above is this more
    compact statement, which is identical to the above mathematical expression:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 R 代码中的繁琐加法可以用这个更紧凑的语句来替代，它与上面的数学表达式相同：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'R has a built-in function called `pbinom()` that does this summation for us.
    If we want to know the probability of \(2\) or fewer than \(2\) successes as in
    the above example, we can write:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: R 有一个内置函数 `pbinom()`，它可以为我们完成这个求和。如果我们想知道像上面例子中那样 \(2\) 次或更少的成功概率，我们可以这样写：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The specification `lower.tail = TRUE` (the default value) ensures that the
    summation goes from \(2\) to numbers smaller than \(2\) (which lie in the lower
    tail of the distribution in Figure [1.2](ch-intro.html#fig:binomplot)). If we
    wanted to know what the probability is of obtaining \(3\) or more successes out
    of \(10\), we can set `lower.tail` to `FALSE`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 指定 `lower.tail = TRUE`（默认值）确保求和从 \(2\) 到小于 \(2\) 的数字（这些数字位于图 [1.2](ch-intro.html#fig:binomplot)
    中分布的下半部分）。如果我们想知道从 \(10\) 次实验中获得 \(3\) 次或更多成功的概率，可以将 `lower.tail` 设置为 `FALSE`：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The cumulative distribution function or CDF for a random variable \(Y\) is
    thus related to the corresponding probability mass/density function, and is written
    as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，随机变量 \(Y\) 的累积分布函数（CDF）与相应的概率质量/密度函数相关，并如下所示：
- en: \[\begin{equation} F_Y(a) = P(Y\leq a) \end{equation}\]
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} F_Y(a) = P(Y\leq a) \end{equation}\]
- en: The CDF can be plotted by computing the cumulative probabilities for any value
    \(k\) or less than \(k\), where \(k\) ranges from \(0\) to \(10\) in our running
    example. The CDF is shown in Figure [1.4](ch-intro.html#fig:binomcdf)(a).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 累计分布函数（CDF）可以通过计算任何值 \(k\) 或小于 \(k\) 的累积概率来绘制，在我们的运行示例中，\(k\) 的范围从 \(0\) 到 \(10\)。CDF
    在图 [1.4](ch-intro.html#fig:binomcdf)(a) 中显示。
- en: '![(a) Cumulative distribution function (CDF) of a binomial distribution with
    10 trials and a 50% probability of success. (b) Inverse CDF for the same binomial
    distribution.](../Images/ba03c97ade57cfc3f15adea5213ebe3c.png)![(a) Cumulative
    distribution function (CDF) of a binomial distribution with 10 trials and a 50%
    probability of success. (b) Inverse CDF for the same binomial distribution.](../Images/e427f6f09c6284103a61607ee276517d.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![(a) 具有十次试验和50%成功概率的二项分布的累积分布函数（CDF）。(b) 相同二项分布的逆CDF。](../Images/ba03c97ade57cfc3f15adea5213ebe3c.png)![(a)
    具有十次试验和50%成功概率的二项分布的累积分布函数（CDF）。(b) 相同二项分布的逆CDF。](../Images/e427f6f09c6284103a61607ee276517d.png)'
- en: 'FIGURE 1.4: (a) Cumulative distribution function (CDF) of a binomial distribution
    with 10 trials and a 50% probability of success. (b) Inverse CDF for the same
    binomial distribution.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.4: (a) 具有十次试验和50%成功概率的二项分布的累积分布函数（CDF）。(b) 相同二项分布的逆CDF。'
- en: 1.4.2.3 Compute the inverse of the cumulative distribution function (the quantile
    function)
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.2.3 计算累积分布函数的逆（分位数函数）
- en: We can also find out the value of the variable \(k\) (the quantile) such that
    the probability of obtaining \(k\) or less than \(k\) successes is some specific
    probability value \(p\). If we switch the x and y axes of Figure [1.4](ch-intro.html#fig:binomcdf)(a),
    we obtain another very useful function, the inverse of the CDF.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以找出变量 \(k\)（分位数）的值，使得获得 \(k\) 或小于 \(k\) 次成功的概率是某个特定的概率值 \(p\)。如果我们交换图 [1.4](ch-intro.html#fig:binomcdf)(a)
    的 x 轴和 y 轴，我们得到另一个非常有用的函数，即 CDF 的逆。
- en: 'The inverse of the CDF (known as the quantile function in R because it returns
    the quantile, the value \(k\)) is available in R as the function `qbinom()`. The
    usage is as follows: to find out what the value \(k\) of the outcome is such that
    the probability of obtaining \(k\) or less successes is \(0.37\), type:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: CDF 的逆（在 R 中称为分位数函数，因为它返回分位数，即值 \(k\)）在 R 中作为函数 `qbinom()` 提供。用法如下：要找出结果值 \(k\)
    的值，使得获得 \(k\) 或更少成功的概率为 \(0.37\)，请输入：
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: One can visualize the inverse CDF of the binomial as in Figure [1.4](ch-intro.html#fig:binomcdf)(b).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 可以像图 [1.4](ch-intro.html#fig:binomcdf)(b) 所示的那样可视化二项分布的逆CDF。
- en: 1.4.2.4 Generate simulated data from a \(\mathit{Binomial}(n,\theta)\) distribution
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.4.2.4 从 \(\mathit{Binomial}(n,\theta)\) 分布生成模拟数据
- en: 'We can generate simulated data from a binomial distribution by specifying the
    number of observations or experiments (`n`), the number of trials (`size`), and
    the probability of success \(\theta\). In R, we do this as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过指定观察次数或实验次数（`n`）、试验次数（`size`）和成功概率 \(\theta\) 来从二项分布生成模拟数据。在 R 中，我们这样做如下：
- en: '[PRE17]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The above code generates the number of successes in an experiment with \(10\)
    trials. Repeatedly run the above code; we will get different numbers of successes
    each time.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了 \(10\) 次试验的实验中的成功次数。重复运行上述代码；我们每次都会得到不同的成功次数。
- en: As mentioned earlier, if there is only one trial, then instead of the binomial
    distribution, we have a Bernoulli distribution. For example, if we have 10 experiments
    from a Bernoulli distribution, where the probability of success is 0.5, we can
    simulate data as follows using the function `rbern()` from the package `extraDistr`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，如果只有一次试验，那么我们就有伯努利分布，而不是二项分布。例如，如果我们有来自伯努利分布的10个实验，成功概率为0.5，我们可以使用`extraDistr`包中的`rbern()`函数模拟数据如下。
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The above kind of output can also be generated by using the `rbinom()` function:
    `rbinom(n = 10, size = 1, prob = 0.5)`. When the data are generated using the
    `rbinom()` function in this way, one can calculate the number of successes by
    just summing up the vector, or computing its mean and multiplying by the number
    of trials, here \(10\):'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的输出也可以通过使用`rbinom()`函数生成：`rbinom(n = 10, size = 1, prob = 0.5)`。当使用`rbinom()`函数以这种方式生成数据时，只需将向量求和即可计算成功次数，或者计算其均值并乘以试验次数，这里为\(10\)：
- en: '[PRE21]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '1.5 Continuous random variables: An example using the normal distribution'
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 连续随机变量：使用正态分布的示例
- en: 'We will now revisit the idea of the random variable using a continuous distribution.
    Imagine that we have a vector of reading time data \(y\) measured in milliseconds
    and coming from a normal distribution. The normal distribution is defined in terms
    of two parameters: the *location*, its mean value \(\mu\), which determines its
    center, and the *scale*, its standard deviation, \(\sigma\), which determines
    how much spread there is around this center point.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将重新审视使用连续分布的随机变量的概念。想象一下，我们有一个以毫秒为单位的阅读时间数据向量\(y\)，它来自正态分布。正态分布由两个参数定义：*位置*，其均值值\(\mu\)，它决定了其中心，以及*尺度*，其标准差\(\sigma\)，它决定了围绕这个中心点的分布程度。
- en: 'The probability density function (PDF) of the normal distribution is defined
    as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布的概率密度函数（PDF）定义为以下：
- en: \[\begin{equation} \mathit{Normal}(y|\mu,\sigma)=f(y)= \frac{1}{\sqrt{2\pi \sigma^2}}
    \exp \left(-\frac{(y-\mu)^2}{2\sigma^2} \right) \end{equation}\]
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \mathit{Normal}(y|\mu,\sigma)=f(y)= \frac{1}{\sqrt{2\pi \sigma^2}}
    \exp \left(-\frac{(y-\mu)^2}{2\sigma^2} \right) \end{equation}\]
- en: Here, \(\mu\) is some true, unknown mean, and \(\sigma^2\) is some true, unknown
    variance of the normal distribution that the reading times have been sampled from.
    There is a built-in function in R that computes the above function once we specify
    the mean \(\mu\) and the standard deviation \(\sigma\) (in R, this parameter is
    specified in terms of the standard deviation rather than the variance).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，\(\mu\)是某个真实、未知的均值，\(\sigma^2\)是正态分布的真实、未知方差，该分布是从阅读时间中抽取的。在R中有一个内置函数，一旦我们指定了均值\(\mu\)和标准差\(\sigma\)（在R中，此参数以标准差而不是方差的形式指定），就会计算上述函数。
- en: Figure [1.5](ch-intro.html#fig:normdistrn) visualizes the normal distribution
    for particular values of \(\mu\) and \(\sigma\), as a PDF (using `dnorm()`), a
    CDF (using `pnorm()`), and the inverse CDF (using `qnorm()`). It should be clear
    from the figure that these are three different ways of looking at the same information.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1.5](ch-intro.html#fig:normdistrn)可视化了特定\(\mu\)和\(\sigma\)值的正态分布，作为PDF（使用`dnorm()`）、CDF（使用`pnorm()`）和逆CDF（使用`qnorm()`）。从图中应该很明显，这些都是查看相同信息的三种不同方式。
- en: '![The PDF, CDF, and inverse CDF for the $\mathit{Normal}(\mu=500,\sigma=100)$.](../Images/5bac1e34ffeb93427c8908cab1507108.png)![The
    PDF, CDF, and inverse CDF for the $\mathit{Normal}(\mu=500,\sigma=100)$.](../Images/e6d98fdc84ace2a17a5c5cceec3e49ba.png)![The
    PDF, CDF, and inverse CDF for the $\mathit{Normal}(\mu=500,\sigma=100)$.](../Images/8143f0d6a1c0843a9841fee4700876bf.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![\(\mathit{Normal}(\mu=500,\sigma=100)\)的概率密度函数（PDF）、累积分布函数（CDF）和逆累积分布函数（inverse
    CDF）](../Images/5bac1e34ffeb93427c8908cab1507108.png)![\(\mathit{Normal}(\mu=500,\sigma=100)\)的概率密度函数（PDF）、累积分布函数（CDF）和逆累积分布函数（inverse
    CDF）](../Images/e6d98fdc84ace2a17a5c5cceec3e49ba.png)![\(\mathit{Normal}(\mu=500,\sigma=100)\)的概率密度函数（PDF）、累积分布函数（CDF）和逆累积分布函数（inverse
    CDF）](../Images/8143f0d6a1c0843a9841fee4700876bf.png)'
- en: 'FIGURE 1.5: The PDF, CDF, and inverse CDF for the \(\mathit{Normal}(\mu=500,\sigma=100)\).'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：\(\mathit{Normal}(\mu=500,\sigma=100)\)的概率密度函数（PDF）、累积分布函数（CDF）和逆累积分布函数（inverse
    CDF）。
- en: 'As in the discrete example, the PDF, CDF, and inverse of the CDF allow us to
    ask questions like:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 与离散示例类似，PDF、CDF和逆CDF允许我们提出如下问题：
- en: 'What is the probability of observing values between \(a\) and \(b\) from a
    normal distribution with mean \(\mu\) and standard deviation \(\sigma\)? Using
    the above example, we can ask what the probability is of observing values between
    \(200\) and \(700\) ms:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察到正态分布中\(a\)和\(b\)之间值的概率是多少？使用上述示例，我们可以询问观察到\(200\)到\(700\)毫秒之间值的概率是多少：
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The probability that the random variable takes any specific point value is zero.
    This is because the probability in a continuous probability distribution is the
    area under the curve, and the area at any point on the x-axis is always zero.
    The implication here is that it is only meaningful to ask about probabilities
    between two different point values; e.g., the probability that \(Y\) lies between
    \(a\) and \(b\), or \(P(a<Y<b)\). Notice that \(P(a<Y<b)\) is the same statement
    as \(P(a\leq Y\leq b)\). Of course, for any particular point value, the PDF itself
    does not return the value zero; but the value returned by the PDF is not the probability
    of that particular value occurring. It is the density of that particular value;
    and if the PDF is seen as a function of the parameters, it is the likelihood of
    that particular value.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量取任何特定点值的概率是零。这是因为连续概率分布中的概率是曲线下的面积，而x轴上任何点的面积总是零。这里的含义是，只有询问两个不同点值之间的概率才有意义；例如，\(Y\)位于\(a\)和\(b\)之间的概率，或\(P(a<Y<b)\)。请注意，\(P(a<Y<b)\)与\(P(a\leq
    Y\leq b)\)是相同的陈述。当然，对于任何特定的点值，PDF本身不会返回零值；但PDF返回的值不是该特定值发生的概率；它是该特定值的密度；如果将PDF视为参数的函数，它就是该特定值的似然。
- en: What is the quantile \(q\) such that the probability is \(p\) of observing that
    value \(q\) or a value more extreme than \(q\)? For example, we can work out the
    quantile \(q\) such that the probability of observing \(q\) or some value less
    than it is \(0.975\), in the \(\mathit{Normal}(500,100)\) distribution. Formally,
    we would write this as \(P(Y<a)\).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是最小分位数\(q\)，使得观察到该值\(q\)或比\(q\)更极端的值的概率是\(p\)？例如，我们可以计算出在\(\mathit{Normal}(500,100)\)分布中，观察到\(q\)或小于\(q\)的值的概率为\(0.975\)的最小分位数\(q\)。形式上，我们可以写成\(P(Y<a)\)。
- en: '[PRE29]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The above output says that the quantile value \(q\) such that \(Prob(X<q)=0.975\)
    is \(q=696\).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出表明，使得\(Prob(X<q)=0.975\)的分位数值\(q\)是\(q=696\)。
- en: 'Generate simulated data. Given a vector of \(n\) independent and identically
    distributed data \(y\), i.e., given that each data point is being generated independently
    from \(Y \sim \mathit{Normal}(\mu,\sigma)\) for some values of the parameters,
    the sample mean and standard deviation[⁶](#fn6) are:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模拟数据。给定一个由\(n\)个独立同分布数据\(y\)组成的向量，即每个数据点都是独立地从\(Y \sim \mathit{Normal}(\mu,\sigma)\)生成，对于某些参数值，样本均值和标准差[⁶](#fn6)是：
- en: \[\begin{equation} \bar{y} = \frac{\sum_{i=1}^n y_i}{n} \end{equation}\]
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \bar{y} = \frac{\sum_{i=1}^n y_i}{n} \end{equation}\]
- en: \[\begin{equation} sd(y) = \sqrt{\frac{\sum_{i=1}^n (y_i- \bar{y})^2}{n}} \end{equation}\]
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} sd(y) = \sqrt{\frac{\sum_{i=1}^n (y_i- \bar{y})^2}{n}} \end{equation}\]
- en: 'For example, we can generate \(10\) data points using the `rnorm()` function,
    and then use the simulated data to compute the mean and standard deviation:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以使用`rnorm()`函数生成10个数据点，然后使用模拟数据来计算均值和标准差：
- en: '[PRE31]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Again, the sample mean and sample standard deviation computed from a particular
    (simulated or real) data set need not necessarily be close to the true values
    of the respective parameters. Especially when sample size is small, one can end
    up with mis-estimates of the mean and standard deviation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，从特定的（模拟或真实）数据集中计算出的样本均值和样本标准差不一定接近相应参数的真实值。特别是当样本量较小时，可能会得到均值和标准差的误估计。
- en: 'Incidentally, simulated data can be used to generate all kinds of statistics.
    For example, we can compute the lower and upper quantiles such that 95% of the
    simulated data are contained within these quantiles:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 偶然的是，模拟数据可以用来生成各种统计数据。例如，我们可以计算下限和上限分位数，使得95%的模拟数据包含在这些分位数内：
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Later on, this function will be used to generate summary statistics once we
    have obtained samples of a parameter after we have fit a model using Stan/brms.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用Stan/brms拟合模型并获得了参数样本之后，这个函数将用于生成汇总统计量。
- en: '1.5.1 An important distinction: probability vs. density in a continuous random
    variable'
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 重要区分：连续随机变量中的概率与密度
- en: In continuous distributions like the normal discussed above, it is important
    to understand that the probability density function or PDF, \(p(y| \mu, \sigma)\)
    defines a mapping from the \(y\) values (the possible values that the data can
    have) to a quantity called the density of each possible value. We can see this
    function in action when we use `dnorm()` to compute, say, the density value corresponding
    to \(y=1\) and \(y=2\) in the standard normal distribution, that is, a normal
    distribution with a mean of zero and a standard deviation of one.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述讨论的连续分布，如正态分布中，理解概率密度函数或PDF，\(p(y| \mu, \sigma)\) 定义了从 \(y\) 值（数据可能具有的可能值）到称为每个可能值密度的数量的映射是很重要的。当我们使用
    `dnorm()` 来计算，比如说，标准正态分布中 \(y=1\) 和 \(y=2\) 对应的密度值时，我们可以看到这个函数的作用，即，一个均值为零，标准差为1的正态分布。
- en: '[PRE37]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: If the density at a particular point value like \(1\) is high compared to some
    other value (\(2\) in the above example) then this point value \(1\) has a higher
    likelihood than \(2\) in the standard normal distribution.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在特定点值（如 \(1\)）的密度相对于其他值（如上述例子中的 \(2\)）较高，那么这个点值 \(1\) 在标准正态分布中的可能性比 \(2\)
    更高。
- en: 'The quantity computed for the values \(1\) and \(2\) are *not* the probability
    of observing \(1\) or \(2\) in this distribution. As mentioned earlier, probability
    in a continuous distribution is defined as the area under the curve, and this
    area will always be zero at any point value (because there are infinitely many
    different possible values). If we want to know the probability of obtaining values
    between an upper and lower bound \(b\) and \(a\), i.e., \(P(a<Y<b)\) where these
    are two distinct values, we must use the cumulative distribution function or CDF:
    in R, for the normal distribution, this is the `pnorm()` function. For example,
    the probability of observing a value between \(+2\) and \(-2\) in a normal distribution
    with mean \(0\) and standard deviation \(1\) is:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于值 \(1\) 和 \(2\) 计算出的数量 **不是** 在此分布中观察到 \(1\) 或 \(2\) 的概率。如前所述，在连续分布中，概率被定义为曲线下的面积，而这个面积在任何点值处（因为存在无限多个不同的可能值）总是为零。如果我们想了解在上下界
    \(b\) 和 \(a\) 之间的值的概率，即 \(P(a<Y<b)\) 其中这些是两个不同的值，我们必须使用累积分布函数或CDF：在R中，对于正态分布，这是
    `pnorm()` 函数。例如，在均值为 \(0\) 和标准差为 \(1\) 的正态分布中观察到值在 \(+2\) 和 \(-2\) 之间的概率是：
- en: '[PRE41]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The situation is different in discrete random variables. These have a probability
    mass function (PMF) associated with them—an example is the binomial distribution
    that we saw earlier. There, the PMF maps the possible \(y\) values to the probabilities
    of those values occurring. That is why, in the binomial distribution, the probability
    of observing exactly \(2\) successes when sampling from a \(\mathit{Binomial}(n=10,\theta=0.5)\)
    can be computed using either `dbinom()` or `pbinom()`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在离散随机变量中，情况不同。它们与一个概率质量函数（PMF）相关联——一个例子是我们之前看到的二项分布。在那里，PMF 将可能的 \(y\) 值映射到这些值发生的概率。这就是为什么在二项分布中，从
    \(\mathit{Binomial}(n=10,\theta=0.5)\) 中采样时观察到恰好 \(2\) 个成功的概率可以使用 `dbinom()` 或
    `pbinom()` 来计算：
- en: '[PRE43]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In the second line of code above, we are computing the cumulative probability
    of observing two or less successes, minus the probability of observing one or
    less successes. This gives us the probability of observing exactly two successes.
    The `dbinom()` gives us this same information.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码的第二行中，我们正在计算观察到两个或更少成功的累积概率，减去观察到一个或更少成功的概率。这给出了观察到恰好两个成功的概率。`dbinom()`
    给出了相同的信息。
- en: 1.5.2 Truncating a normal distribution
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.2 截断正态分布
- en: 'In the above discussion, the support for the normal distribution ranges from
    minus infinity to plus infinity. One can define PDFs with a more limited support;
    an example would be a normal distribution whose PDF \(f(x)\) is such that the
    lower bound is truncated at \(0\) to allow only positive values. In such a case,
    the area under the range minus infinity to zero (\(\int_{-\infty}^0 f(x) \, \mathrm{d}x\))
    will be \(0\) because the range lies outside the support of the truncated normal
    distribution. Also, if one truncates the standard normal (\(\mathit{Normal}(0,1)\))
    at \(0\), in order to make the area between zero and plus infinity sum up to \(1\),
    we would have to multiply it by \(2\), because we just halved the area under the
    curve. More formally and more generally, we would have to multiply the truncated
    distribution \(f(x)\) by some factor \(k\) such that the following integral sums
    to \(1\):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述讨论中，正态分布的支持范围从负无穷大到正无穷大。可以定义支持范围更小的 PDF；一个例子是 PDF \(f(x)\) 为正态分布，其下限截断在 \(0\)
    处，只允许正值。在这种情况下，从负无穷大到零的范围下的面积（\(\int_{-\infty}^0 f(x) \, \mathrm{d}x\)) 将是 \(0\)，因为该范围位于截断正态分布的支持范围之外。此外，如果我们截断标准正态分布（\(\mathit{Normal}(0,1)\)）在
    \(0\) 处，为了使零到正无穷大的面积之和为 \(1\)，我们需要将其乘以 \(2\)，因为我们只将曲线下的面积减半。更正式和更普遍地说，我们需要将截断分布
    \(f(x)\) 乘以某个因子 \(k\)，使得以下积分之和为 \(1\)：
- en: \[\begin{equation} k \int_{0}^{\infty} f(x)\, \mathrm{d}x = 1 \tag{1.1} \end{equation}\]
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} k \int_{0}^{\infty} f(x)\, \mathrm{d}x = 1 \tag{1.1} \end{equation}\]
- en: 'Clearly, this factor is \(k = \frac{1}{\int_{0}^{\infty} f(x)\, \mathrm{d}x}\).
    For the standard normal, this integral is easy to compute using R; we just calculate
    the complement of the cumulative distribution (CCDF):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这个因子是 \(k = \frac{1}{\int_{0}^{\infty} f(x)\, \mathrm{d}x}\)。对于标准正态分布，使用
    R 计算这个积分很容易；我们只需计算累积分布函数（CCDF）的补数：
- en: '[PRE47]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The above calculation implies that \(k\) is indeed \(2\), as we informally argued
    (\(k = \frac{1}{0.5}=2\)).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 上述计算表明 \(k\) 确实是 \(2\)，正如我们非正式地论证的那样（\(k = \frac{1}{0.5}=2\)）。
- en: 'Also, if we had truncated the distribution at 0 to the right instead of the
    left (allowing only negative values), we would have to find the factor \(k\) in
    the same way as above, except that we would have to find \(k\) such that:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们截断分布的右侧而不是左侧在 \(0\) 处（只允许负值），我们也将以相同的方式找到因子 \(k\)，只是我们需要找到 \(k\) 使得：
- en: \[\begin{equation} k \int_{-\infty}^{0} f(x)\, \mathrm{d}x = 1 \end{equation}\]
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} k \int_{-\infty}^{0} f(x)\, \mathrm{d}x = 1 \end{equation}\]
- en: 'For the standard normal case, in R, this factor would require us to use the
    CDF:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标准正态情况，在 R 中，这个因子将要求我们使用累积分布函数（CDF）：
- en: '[PRE51]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Later in this book, we will be using such truncated distributions when doing
    Bayesian modeling, and when we use them, we will want to multiply the truncated
    distribution by the factor \(k\) to ensure that it is still a proper PDF whose
    area under the curve sums to \(1\). Truncated normal distributions are discussed
    in more detail in the online section [A.2](regression-models-with-brms---extended.html#app-truncation).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后面部分，我们将使用这样的截断分布来进行贝叶斯建模，当我们使用它们时，我们将想要将截断分布乘以因子 \(k\)，以确保它仍然是一个面积之和为 \(1\)
    的正确 PDF。截断正态分布的详细讨论可以在在线部分 [A.2](regression-models-with-brms---extended.html#app-truncation)
    中找到。
- en: 1.6 Bivariate and multivariate distributions
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 双变量和多变量分布
- en: So far, we have only discussed univariate distributions; these are distributions
    that involve only one variable. For example, when we talk about data generated
    from a Binomial distribution, or from a normal distribution, these are univariate
    distributions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了单变量分布；这些是只涉及一个变量的分布。例如，当我们谈论来自二项分布或正态分布的数据时，这些都是单变量分布。
- en: It is also possible to specify distributions with two or more dimensions. Some
    examples will make it clear what a bivariate (or more generally, multivariate)
    distribution is.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以指定具有两个或更多维度的分布。一些例子将清楚地说明什么是双变量分布（或更一般地说，多变量分布）。
- en: '1.6.1 Example 1: Discrete bivariate distributions'
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.1 示例 1：离散双变量分布
- en: Starting with the discrete case, consider the discrete bivariate distribution
    shown below. These are data from an experiment where, inter alia, in each trial
    a Likert acceptability rating and a question-response accuracy were recorded (the
    data are from a study by Laurinavichyute [2020](#ref-AnnaLphd), used with permission
    here). Load the data by loading the R package `bcogsci`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 从离散情况开始，考虑下面所示的离散双变量分布。这些数据来自一个实验，其中记录了每个试验的Likert可接受性评分和问题-回答准确性（数据来自Laurinavichyute
    [2020](#ref-AnnaLphd)的研究，在此处获得许可）。通过加载R包`bcogsci`来加载数据。
- en: '[PRE53]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Figure [1.6](ch-intro.html#fig:bivardiscrete) shows the *joint probability mass
    function* of two random variables X and Y. The random variable \(X\) consists
    of \(7\) possible values (this is the \(1-7\) Likert response scale), and the
    random variable \(Y\) is question-response accuracy, with \(0\) representing an
    incorrect response, and \(1\) representing a correct response. One can also display
    Figure [1.6](ch-intro.html#fig:bivardiscrete) as a table; see Table [1.3](ch-intro.html#tab:discbivariatetabular).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1.6](ch-intro.html#fig:bivardiscrete)显示了两个随机变量X和Y的**联合概率质量函数**。随机变量\(X\)包含\(7\)个可能的值（这是\(1-7\)的Likert响应量表），随机变量\(Y\)是问题-回答准确性，其中\(0\)代表错误响应，\(1\)代表正确响应。也可以将图[1.6](ch-intro.html#fig:bivardiscrete)以表格的形式显示；参见表[1.3](ch-intro.html#tab:discbivariatetabular)。
- en: '![Example of a discrete bivariate distribution. In these data, in every trial,
    two pieces of information were collected: Likert responses and yes-no question
    responses. The random variable X represents Likert scale responses on a scale
    of 1-7\. and the random variable Y represents 0, 1 (incorrect, correct) responses
    to comprehension questions.](../Images/cc8dc7e38402aabfee100812c77bc39b.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![离散双变量分布的示例。在这些数据中，在每次试验中，收集了两条信息：Likert响应和是/否问题响应。随机变量X代表1-7的Likert量表响应，随机变量Y代表对理解问题的0，1（错误，正确）响应。](../Images/cc8dc7e38402aabfee100812c77bc39b.png)'
- en: 'FIGURE 1.6: Example of a discrete bivariate distribution. In these data, in
    every trial, two pieces of information were collected: Likert responses and yes-no
    question responses. The random variable X represents Likert scale responses on
    a scale of 1-7\. and the random variable Y represents 0, 1 (incorrect, correct)
    responses to comprehension questions.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：离散双变量分布的示例。在这些数据中，在每次试验中，收集了两条信息：Likert响应和是/否问题响应。随机变量X代表1-7的Likert量表响应，随机变量Y代表对理解问题的0，1（错误，正确）响应。
- en: 'TABLE 1.3: The joint PMF for two random variables X and Y.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.3：两个随机变量X和Y的联合概率质量函数。
- en: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |'
- en: '| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |'
- en: '| \(y=0\) | \(0.018\) | \(0.023\) | \(0.04\) | \(0.043\) | \(0.063\) | \(0.049\)
    | \(0.055\) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| \(y=0\) | \(0.018\) | \(0.023\) | \(0.04\) | \(0.043\) | \(0.063\) | \(0.049\)
    | \(0.055\) |'
- en: '| \(y=1\) | \(0.031\) | \(0.053\) | \(0.086\) | \(0.096\) | \(0.147\) | \(0.153\)
    | \(0.142\) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| \(y=1\) | \(0.031\) | \(0.053\) | \(0.086\) | \(0.096\) | \(0.147\) | \(0.153\)
    | \(0.142\) |'
- en: 'For each possible pair of values of \(X\) and \(Y\), we have a joint probability
    \(p_{X,Y}(x,y)\). Given such a bivariate distribution, there are two useful quantities
    we can compute: the *marginal* distributions (\(p_{X}\) and \(p_Y\)), and the
    *conditional* distributions (\(p_{X|Y}\) and \(p_{Y|X}\)). Table [1.3](ch-intro.html#tab:discbivariatetabular)
    shows the joint probability mass function \(p_{X,Y}(x,y)\).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 对于\(X\)和\(Y\)的每一对可能值，我们都有一个联合概率\(p_{X,Y}(x,y)\)。给定这样的双变量分布，我们可以计算两个有用的量：**边缘**分布（\(p_X\)和\(p_Y\)），以及**条件**分布（\(p_{X|Y}\)和\(p_{Y|X}\)）。表[1.3](ch-intro.html#tab:discbivariatetabular)显示了联合概率质量函数\(p_{X,Y}(x,y)\)。
- en: 1.6.1.1 Marginal distributions
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.6.1.1 边缘分布
- en: The marginal distribution \(p_Y\) is defined as follows. \(S_{X}\) is the support
    of \(X\), i.e., all the possible values of \(X\).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘分布\(p_Y\)的定义如下。\(S_X\)是\(X\)的支持集，即\(X\)的所有可能值。
- en: \[\begin{equation} p_{Y}(y)=\sum_{x\in S_{X}}p_{X,Y}(x,y).\label{eq-marginal-pmf}
    \end{equation}\]
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p_{Y}(y)=\sum_{x\in S_{X}}p_{X,Y}(x,y).\label{eq-marginal-pmf}
    \end{equation}\]
- en: 'Similarly, the marginal distribution \(p_X\) is defined as:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，边缘分布\(p_X\)的定义如下：
- en: \[\begin{equation} p_{X}(x)=\sum_{y\in S_{Y}}p_{X,Y}(x,y).\label{eq-marginal-pmf2}
    \end{equation}\]
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p_{X}(x)=\sum_{y\in S_{Y}}p_{X,Y}(x,y).\label{eq-marginal-pmf2}
    \end{equation}\]
- en: \(p_Y\) is computed, by summing up the rows; and \(p_X\) by summing up the columns.
    We can see why this is called the marginal distribution; the result appears in
    the margins of the table. In the code below, the object `probs` contains bivariate
    PMF shown in Table [1.3](ch-intro.html#tab:discbivariatetabular).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \(p_Y\) 通过对行求和计算得出；\(p_X\) 通过对列求和计算得出。我们可以看到为什么这被称为边缘分布；结果出现在表格的边缘。在下面的代码中，对象
    `probs` 包含了表 [1.3](ch-intro.html#tab:discbivariatetabular) 中所示的二元概率质量函数。
- en: '[PRE54]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The marginal probabilities sum to \(1\), as they should. Table [1.4](ch-intro.html#tab:discbivariatetabularmarginal)
    shows the marginal probabilities.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘概率之和为 \(1\)，正如它们应该的那样。表 [1.4](ch-intro.html#tab:discbivariatetabularmarginal)
    展示了边缘概率。
- en: 'TABLE 1.4: The joint PMF for two random variables X and Y, along with the marginal
    distributions of X and Y.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.4：两个随机变量 X 和 Y 的联合概率质量函数，以及 X 和 Y 的边缘分布。
- en: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |
    \(P(Y)\) |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |
    \(P(Y)\) |'
- en: '| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |'
- en: '| \(y=0\) | \(0.018\) | \(0.023\) | \(0.04\) | \(0.043\) | \(0.063\) | \(0.049\)
    | \(0.055\) | \(0.291\) |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| \(y=0\) | \(0.018\) | \(0.023\) | \(0.04\) | \(0.043\) | \(0.063\) | \(0.049\)
    | \(0.055\) | \(0.291\) |'
- en: '| \(y=1\) | \(0.031\) | \(0.053\) | \(0.086\) | \(0.096\) | \(0.147\) | \(0.153\)
    | \(0.142\) | \(0.709\) |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| \(y=1\) | \(0.031\) | \(0.053\) | \(0.086\) | \(0.096\) | \(0.147\) | \(0.153\)
    | \(0.142\) | \(0.709\) |'
- en: '| \(P(X)\) | \(0.049\) | \(0.077\) | \(0.126\) | \(0.139\) | \(0.21\) | \(0.202\)
    | \(0.197\) |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| \(P(X)\) | \(0.049\) | \(0.077\) | \(0.126\) | \(0.139\) | \(0.21\) | \(0.202\)
    | \(0.197\) |  |'
- en: To compute the marginal distribution of \(X\), one is summing over all the \(Y\)’s;
    and to compute the marginal distribution of \(Y\), one sums over all the \(X\)’s.
    We say that we are *marginalizing out* the random variable that we are summing
    over. One can also visualize the two marginal distributions using barplots (Figure
    [1.7](ch-intro.html#fig:marginalbarplot)).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算 \(X\) 的边缘分布，需要对所有 \(Y\) 的值进行求和；要计算 \(Y\) 的边缘分布，需要对所有 \(X\) 的值进行求和。我们说我们在*边缘化*我们正在求和的随机变量。也可以使用条形图（图
    [1.7](ch-intro.html#fig:marginalbarplot)）来可视化这两个边缘分布。
- en: '![The marginal distributions of the random variables X and Y, presented as
    barplots.](../Images/7e3efb5fa3be802473e0145f8224ca00.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![随机变量 X 和 Y 的边缘分布，以条形图形式展示。](../Images/7e3efb5fa3be802473e0145f8224ca00.png)'
- en: 'FIGURE 1.7: The marginal distributions of the random variables X and Y, presented
    as barplots.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：随机变量 X 和 Y 的边缘分布，以条形图形式展示。
- en: 1.6.1.2 Conditional distributions
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.6.1.2 条件分布
- en: 'For computing conditional distributions, recall that conditional probability
    (see section [1.2](ch-intro.html#condprob)) is defined as:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 对于条件分布的计算，回忆一下，条件概率（见第 [1.2](ch-intro.html#condprob) 节）定义为：
- en: \[\begin{equation} p_{X\mid Y}(x\mid y) = \frac{p_{X,Y}(x,y)}{p_Y(y)} \end{equation}\]
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p_{X\mid Y}(x\mid y) = \frac{p_{X,Y}(x,y)}{p_Y(y)} \end{equation}\]
- en: and
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: \[\begin{equation} p_{Y\mid X}(y\mid x) = \frac{p_{X,Y}(x,y)}{p_X(x)} \end{equation}\]
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p_{Y\mid X}(y\mid x) = \frac{p_{X,Y}(x,y)}{p_X(x)} \end{equation}\]
- en: 'The conditional distribution of a random variable \(X\) given that \(Y=y\),
    where \(y\) is some specific (fixed) value, is:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 当 \(Y=y\) 时，随机变量 \(X\) 的条件分布是：
- en: \[\begin{equation} p_{X\mid Y} (x\mid y) = \frac{p_{X,Y}(x,y)}{p_Y(y)} \quad
    \hbox{provided } p_Y(y)=P(Y=y)>0 \end{equation}\]
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p_{X\mid Y} (x\mid y) = \frac{p_{X,Y}(x,y)}{p_Y(y)} \quad
    \hbox{provided } p_Y(y)=P(Y=y)>0 \end{equation}\]
- en: As an example, let’s consider how \(p_{X\mid Y}\) would be computed. The possible
    values of \(y\) are \(0,1\), and so we have to find the conditional distribution
    (defined above) for each of these values. That is, we have to find \(p_{X\mid
    Y}(x\mid y=0)\), and \(p_{X\mid Y}(x\mid y=1)\).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑如何计算 \(p_{X\mid Y}\)。\(y\) 的可能值为 \(0,1\)，因此我们需要为这些值中的每一个找到上述定义的条件分布。也就是说，我们需要找到
    \(p_{X\mid Y}(x\mid y=0)\) 和 \(p_{X\mid Y}(x\mid y=1)\)。
- en: Let’s do the calculation for \(p_{X\mid Y}(x\mid y=0)\).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来计算 \(p_{X\mid Y}(x\mid y=0)\)。
- en: \[\begin{equation} \begin{split} p_{X\mid Y} (1\mid 0) =& \frac{p_{X,Y}(1,0)}{p_Y(0)}\\
    =& \frac{0.018}{0.291}\\ =& 0.062 \end{split} \end{equation}\]
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{split} p_{X\mid Y} (1\mid 0) =& \frac{p_{X,Y}(1,0)}{p_Y(0)}\\
    =& \frac{0.018}{0.291}\\ =& 0.062 \end{split} \end{equation}\]
- en: This conditional probability value will occupy the cell \(X=1\), \(Y=0\) in
    Table [1.5](ch-intro.html#tab:discbivariatetabularconditional) summarizing the
    conditional probability distribution \(p_{X|Y}\). In this way, one can fill in
    the entire table, which will then represent the conditional distributions \(p_{X|Y=0}\)
    and \(p_{X|Y=1}\). The reader may want to take a few minutes to complete Table
    [1.5](ch-intro.html#tab:discbivariatetabularconditional). After the conditional
    probabilities have been computed, the rows should sum up to \(1\).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这个条件概率值将占据表 [1.5](ch-intro.html#tab:discbivariatetabularconditional) 中 \(X=1\)，\(Y=0\)
    的单元格，该表总结了条件概率分布 \(p_{X|Y}\)。通过这种方式，可以填写整个表格，该表格将代表条件分布 \(p_{X|Y=0}\) 和 \(p_{X|Y=1}\)。读者可能需要花几分钟时间完成表
    [1.5](ch-intro.html#tab:discbivariatetabularconditional)。在计算了条件概率之后，行应该加起来等于 \(1\)。
- en: 'TABLE 1.5: A table for listing conditional distributions of X given Y.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.5：列出给定 \(Y\) 的 \(X\) 条件分布的表格。
- en: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  | \(x=1\) | \(x=2\) | \(x=3\) | \(x=4\) | \(x=5\) | \(x=6\) | \(x=7\) |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| \(p_{X&#124;Y(x&#124;y=0)}\) | \(0.062\) |  |  |  |  |  |  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| \(p_{X\vert Y(x\vert y=0)}\) | \(0.062\) |  |  |  |  |  |  |'
- en: '| \(p_{X&#124;Y(x&#124;y=1)}\) |  |  |  |  |  |  |  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| \(p_{X\vert Y(x\vert y=1)}\) |  |  |  |  |  |  |  |'
- en: Similarly, one can construct a table that shows \(p_{Y|X}\).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，可以构建一个表格来显示 \(p_{Y|X}\)。
- en: 1.6.1.3 Covariance and correlation
  id: totrans-276
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.6.1.3 协方差和相关性
- en: Here, we briefly define the covariance and correlation of two discrete random
    variables. For detailed examples and discussion, see the references at the end
    of the chapter. Informally, if there is a high probability that large values of
    a random variable \(X\) are associated with large values of another random variable
    \(Y\), we will say that the covariance between the two random variable \(X\) and
    \(Y\), written \(Cov(X,Y)\), is positive.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们简要定义两个离散随机变量的协方差和相关性。对于详细示例和讨论，请参阅章节末尾的参考文献。非正式地说，如果随机变量 \(X\) 的较大值与另一个随机变量
    \(Y\) 的较大值相关联的概率很高，我们将说两个随机变量 \(X\) 和 \(Y\) 之间的协方差 \(Cov(X,Y)\) 是正的。
- en: The covariance of two (discrete) random variables \(X\) and \(Y\) is defined
    as follows. \(E[\cdot]\) refers to the expectation of a random variable.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 两个（离散）随机变量 \(X\) 和 \(Y\) 的协方差定义为以下。\(E[\cdot]\) 指的是随机变量的期望。
- en: \[\begin{equation} Cov(X,Y) = E[(X - E[X])(Y-E[Y])] \end{equation}\]
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} Cov(X,Y) = E[(X - E[X])(Y-E[Y])] \end{equation}\]
- en: 'It is possible to show that this is equivalent to:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明这是等价的：
- en: \[\begin{equation} Cov(X,Y) = E[XY] - E[X]E[Y] \end{equation}\]
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} Cov(X,Y) = E[XY] - E[X]E[Y] \end{equation}\]
- en: 'The expectation E[XY] is defined to be:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 期望 \(E[XY]\) 被定义为：
- en: \[\begin{equation} E[XY]=\sum_x \sum_y xy f_{X,Y}(x,y) \end{equation}\]
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} E[XY]=\sum_x \sum_y xy f_{X,Y}(x,y) \end{equation}\]
- en: 'If the standard deviations of the two random variables is \(\sigma_X\) and
    \(\sigma_Y\), the correlation between the two random variables, \(\rho_{XY}\),
    is defined as:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个随机变量的标准差分别为 \(\sigma_X\) 和 \(\sigma_Y\)，两个随机变量之间的相关系数 \(\rho_{XY}\) 定义为：
- en: \[\begin{equation} \rho_{XY} = \frac{Cov(X,Y)}{\sigma_X\sigma_Y} \end{equation}\]
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \rho_{XY} = \frac{Cov(X,Y)}{\sigma_X\sigma_Y} \end{equation}\]
- en: '1.6.2 Example 2: Continuous bivariate distributions'
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.2 示例 2：连续双变量分布
- en: Consider now the continuous bivariate case; this time, we will use simulated
    data. Consider two normal random variables \(X\) and \(Y\), each of which coming
    from, for example, a \(\mathit{Normal}(0,1)\) distribution, with some correlation
    \(\rho_{X,Y}\) between the two random variables.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑连续的双变量情况；这次，我们将使用模拟数据。考虑两个正态随机变量 \(X\) 和 \(Y\)，每个变量例如来自 \(\mathit{Normal}(0,1)\)
    分布，两个随机变量之间存在某种相关系数 \(\rho_{X,Y}\)。
- en: 'A bivariate distribution for two random variables \(X\) and \(Y\), each of
    which comes from a normal distribution, is expressed in terms of the means and
    standard deviations of each of the two distributions, and the correlation \(\rho_{XY}\)
    between them. The standard deviations and correlation in a bivariate distribution
    are expressed in a special form of a \(2\times 2\) matrix called a variance-covariance
    matrix \(\Sigma\). If \(\rho_{XY}\) is the correlation between the two random
    variables, and \(\sigma _{X}\) and \(\sigma _{Y}\) the respective standard deviations,
    the variance-covariance matrix is written as:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个随机变量 \(X\) 和 \(Y\) 的二元分布，每个变量都来自正态分布，可以用两个分布的均值和标准差以及它们之间的相关系数 \(\rho_{XY}\)
    来表示。二元分布中的标准差和相关系数以一个特殊的 \(2\times 2\) 矩阵形式表示，称为方差-协方差矩阵 \(\Sigma\)。如果 \(\rho_{XY}\)
    是两个随机变量之间的相关系数，而 \(\sigma _{X}\) 和 \(\sigma _{Y}\) 分别是各自的标准差，则方差-协方差矩阵表示为：
- en: \[\begin{equation}\label{eq:covmatfoundations} \Sigma = \begin{pmatrix} \sigma
    _{X}^2 & \rho_{XY}\sigma _{X}\sigma _{Y}\\ \rho_{XY}\sigma _{X}\sigma _{Y} & \sigma
    _{Y}^2\\ \end{pmatrix} \end{equation}\]
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation}\label{eq:covmatfoundations} \Sigma = \begin{pmatrix} \sigma
    _{X}^2 & \rho_{XY}\sigma _{X}\sigma _{Y}\\ \rho_{XY}\sigma _{X}\sigma _{Y} & \sigma
    _{Y}^2\\ \end{pmatrix} \end{equation}\]
- en: The off-diagonals of this matrix contain the covariance between \(X\) and \(Y\).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵的对角线包含 \(X\) 和 \(Y\) 之间的协方差。
- en: 'The joint distribution of \(X\) and \(Y\) is defined as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: \(X\) 和 \(Y\) 的联合分布定义如下：
- en: \[\begin{equation}\label{eq:jointpriordistfoundations} \begin{pmatrix} X \\
    Y \\ \end{pmatrix} \sim \mathcal{N}_2 \left( \begin{pmatrix} 0 \\ 0 \\ \end{pmatrix},
    \Sigma \right) \end{equation}\]
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation}\label{eq:jointpriordistfoundations} \begin{pmatrix} X \\
    Y \\ \end{pmatrix} \sim \mathcal{N}_2 \left( \begin{pmatrix} 0 \\ 0 \\ \end{pmatrix},
    \Sigma \right) \end{equation}\]
- en: The joint PDF is written with reference to the two variables \(f_{X,Y}(x,y)\).
    It has the property that the volume under the surface that is bounded by the density
    function sums to 1—this sum-to-1 property is the same idea that we encountered
    in the univariate cases (the normal and binomial distributions), except that we
    are talking about a bivariate distribution here, so we talk about the volume under
    the surface rather than the area under the curve.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 联合概率密度函数是以两个变量 \(f_{X,Y}(x,y)\) 为参考写成的。它具有这样一个性质：由密度函数所界定的表面下的体积总和为 1——这个总和为
    1 的性质与我们在一元情况中遇到的概念相同（正态分布和二项分布），只是在这里我们讨论的是二元分布，所以我们谈论的是表面下的体积而不是曲线下的面积。
- en: 'Formally, we would write the volume as a double integral: we are summing up
    the volume under the surface representing the joint density for \(X\) and \(Y\)
    (hence the two integrals).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，我们会将体积写成双重积分：我们在对代表 \(X\) 和 \(Y\) 联合密度的表面下的体积进行求和（因此有两个积分）。
- en: \[\begin{equation} \iint_{S_{X,Y}} f_{X,Y}(x,y)\, \mathrm{d}x \mathrm{d}y =
    1 \end{equation}\]
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \iint_{S_{X,Y}} f_{X,Y}(x,y)\, \mathrm{d}x \mathrm{d}y =
    1 \end{equation}\]
- en: Here, the terms \(\mathrm{d}x\) and \(\mathrm{d}y\) express the fact that we
    are summing up the volume under the surface.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，术语 \(\mathrm{d}x\) 和 \(\mathrm{d}y\) 表示我们在对表面下的体积进行求和。
- en: The joint CDF would be written as follows. The equation below gives us the probability
    of observing a value like \((u,v)\) or some value smaller than that (i.e., some
    \((u',v')\), such that \(u'<u\) and \(v'<v\)).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 联合累积分布函数可以写成以下形式。下面的方程给出了观察到一个像 \((u,v)\) 或更小的值（即某个 \((u',v')\)，使得 \(u'<u\)
    和 \(v'<v\)）的概率。
- en: \[\begin{equation} \begin{split} F_{X,Y}(u,v) =& P(X<u,Y<v)\\ =& \int_{-\infty}^u
    \int_{-\infty}^v f_{X,Y}(x,y)\, \mathrm{d}y \mathrm{d}x\\ \end{split} \end{equation}\]
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{split} F_{X,Y}(u,v) =& P(X<u,Y<v)\\ =& \int_{-\infty}^u
    \int_{-\infty}^v f_{X,Y}(x,y)\, \mathrm{d}y \mathrm{d}x\\ \end{split} \end{equation}\]
- en: 'Just as in the discrete case, the marginal distributions can be derived by
    marginalizing out the other random variable:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在离散情况下一样，可以通过对其他随机变量进行边缘化来推导边缘分布：
- en: \[\begin{equation} f_X(x) = \int_{S_Y} f_{X,Y}(x,y)\, \mathrm{d}y, \quad f_Y(y)
    = \int_{S_X} f_{X,Y}(x,y)\, \mathrm{d}x \end{equation}\]
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} f_X(x) = \int_{S_Y} f_{X,Y}(x,y)\, \mathrm{d}y, \quad f_Y(y)
    = \int_{S_X} f_{X,Y}(x,y)\, \mathrm{d}x \end{equation}\]
- en: Here, \(S_X\) and \(S_Y\) are the respective supports.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，\(S_X\) 和 \(S_Y\) 分别表示各自的支撑集。
- en: Here, the integral sign \(\int\) is the continuous equivalent of the summation
    sign \(\sum\) in the discrete case. Luckily, we will never have to compute such
    integrals ourselves; but it is important to appreciate how a marginal distribution
    arises from a bivariate distribution—by integrating out or marginalizing out the
    other random variable.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，积分符号 \(\int\) 是离散情况中求和符号 \(\sum\) 的连续等价物。幸运的是，我们永远不需要自己计算这样的积分；但是，理解从双变量分布中如何通过积分或边缘化来得到边缘分布是很重要的。
- en: A visualization will help. The figures below show a bivariate distribution with
    zero correlation (Figure [1.8](ch-intro.html#fig:zerocor)), a negative (Figure
    [1.9](ch-intro.html#fig:negcor)) and a positive correlation (Figure [1.10](ch-intro.html#fig:poscor)).
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化将有所帮助。下方的图示展示了具有零相关性的双变量分布（图[1.8](ch-intro.html#fig:zerocor)）、负相关（图[1.9](ch-intro.html#fig:negcor)）和正相关（图[1.10](ch-intro.html#fig:poscor)）。
- en: '![A bivariate normal distribution with zero correlation. Shown are four plots:
    the top-right plot shows the three-dimensional bivariate density, the top-left
    plot the contour plot of the distribution (seen from above). The lower plots show
    the cumulative distribution function from two views, as a three-dimensional plot
    and as a contour plot.](../Images/1026bd1de6b9f3832a5f7988cbd61f2d.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![具有零相关性的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。](../Images/1026bd1de6b9f3832a5f7988cbd61f2d.png)'
- en: 'FIGURE 1.8: A bivariate normal distribution with zero correlation. Shown are
    four plots: the top-right plot shows the three-dimensional bivariate density,
    the top-left plot the contour plot of the distribution (seen from above). The
    lower plots show the cumulative distribution function from two views, as a three-dimensional
    plot and as a contour plot. ![A bivariate normal distribution with a negative  correlation
    of -0.6\. Shown are four plots: the top-right plot shows the three-dimensional
    bivariate density, the top-left plot the contour plot of the distribution (seen
    from above). The lower plots show the cumulative distribution function from two
    views, as a three-dimensional plot and as a contour plot.](../Images/e0068cbd5c50b126d17d668d1c545ec1.png)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：具有零相关性的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。![具有-0.6负相关系数的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。](../Images/e0068cbd5c50b126d17d668d1c545ec1.png)
- en: 'FIGURE 1.9: A bivariate normal distribution with a negative correlation of
    -0.6\. Shown are four plots: the top-right plot shows the three-dimensional bivariate
    density, the top-left plot the contour plot of the distribution (seen from above).
    The lower plots show the cumulative distribution function from two views, as a
    three-dimensional plot and as a contour plot. ![A bivariate normal distribution
    with a positive  correlation of 0.6\. Shown are four plots: the top-right plot
    shows the three-dimensional bivariate density, the top-left plot the contour plot
    of the distribution (seen from above). The lower plots show the cumulative distribution
    function from two views, as a three-dimensional plot and as a contour plot.](../Images/df9861424d5a7ad0f0117e6c5544fada.png)'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9：具有-0.6负相关系数的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。![具有0.6正相关系数的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。](../Images/df9861424d5a7ad0f0117e6c5544fada.png)
- en: 'FIGURE 1.10: A bivariate normal distribution with a positive correlation of
    0.6\. Shown are four plots: the top-right plot shows the three-dimensional bivariate
    density, the top-left plot the contour plot of the distribution (seen from above).
    The lower plots show the cumulative distribution function from two views, as a
    three-dimensional plot and as a contour plot.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10：具有0.6正相关系数的双变量正态分布。展示了四个图：右上角的图展示了三维双变量密度，左上角的图展示了分布的轮廓图（从上方看）。下方的图展示了累积分布函数的两个视图，作为一个三维图和一个轮廓图。
- en: In this book, we will make use of such multivariate distributions a lot, and
    it will soon become important to know how to generate simulated bivariate or multivariate
    data that is correlated. So let’s look at that next.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将大量使用此类多元分布，并且很快就会知道如何生成相关的模拟双变量或多元数据变得很重要。所以让我们看看下一个。
- en: 1.6.3 Generate simulated bivariate (or multivariate) data
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.3 生成模拟的双变量（或多元）数据
- en: Suppose we want to generate \(100\) pairs of correlated continuous data, with
    correlation \(\rho=0.6\). The two random variables both have a normal PDF, and
    have mean \(0\), and standard deviations \(5\) and \(10\), respectively.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要生成100对相关连续数据，相关系数为\rho=0.6。这两个随机变量都具有正态概率密度函数，并且均值均为0，标准差分别为5和10。
- en: Here is how we would generate such data. First, define a variance-covariance
    matrix; then, use the multivariate analog of the `rnorm()` function, `mvrnorm()`,
    from the `MASS` package to generate \(100\) data points.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们生成此类数据的方法。首先，定义一个方差-协方差矩阵；然后，使用`MASS`包中的`rnorm()`函数的多变量类似物`mvrnorm()`生成100个数据点。
- en: '[PRE62]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Figure [1.11](ch-intro.html#fig:poscordata) confirms that the simulated data
    are positively correlated.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1.11](ch-intro.html#fig:poscordata)证实了模拟数据是正相关的。
- en: '![The relationship between two positively correlated random variables, generated
    by simulating data using the R function mvrnorm from the MASS library.](../Images/dedfc5e85e8afc84094a795f8ee1fa3c.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![使用MASS库中的R函数mvrnorm模拟数据生成的两个正相关性随机变量之间的关系](../Images/dedfc5e85e8afc84094a795f8ee1fa3c.png)'
- en: 'FIGURE 1.11: The relationship between two positively correlated random variables,
    generated by simulating data using the R function mvrnorm from the MASS library.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11：使用MASS库中的R函数mvrnorm模拟数据生成的两个正相关性随机变量之间的关系
- en: 1.6.4 Decomposing a variance-covariance matrix
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.4 分解方差-协方差矩阵
- en: 'One final useful fact about the variance-covariance matrix—one that we will
    need later—is that it can be decomposed into the component standard deviations
    and an underlying correlation matrix. For example, consider the matrix above:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 关于方差-协方差矩阵的一个最终有用的事实——我们稍后会用到的是，它可以分解为组成部分的标准差和潜在的相关矩阵。例如，考虑上面的矩阵：
- en: '[PRE64]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'One can decompose the matrix as follows. The matrix can be seen as the product
    of a diagonal matrix of the standard deviations and the correlation matrix:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵可以分解如下。该矩阵可以看作是标准差对角矩阵和相关性矩阵的乘积：
- en: \[\begin{equation} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix} \begin{pmatrix}
    1.0 & 0.6\\ 0.6 & 1.0\\ \end{pmatrix} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix}
    \end{equation}\]
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix} \begin{pmatrix}
    1.0 & 0.6\\ 0.6 & 1.0\\ \end{pmatrix} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix}
    \end{equation}\]
- en: One can reassemble the variance-covariance matrix by pre-multiplying and post-multiplying
    the correlation matrix with the diagonal matrix containing the standard deviations:[⁷](#fn7)
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将标准差对角矩阵与相关性矩阵进行前乘和后乘来重新组装方差-协方差矩阵：[⁷](#fn7)
- en: \[\begin{equation} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix} \begin{pmatrix}
    1.0 & 0.6\\ 0.6 & 1.0\\ \end{pmatrix} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix}
    = \begin{pmatrix} 25 & 30\\ 30 & 100\\ \end{pmatrix} \end{equation}\]
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix} \begin{pmatrix}
    1.0 & 0.6\\ 0.6 & 1.0\\ \end{pmatrix} \begin{pmatrix} 5 & 0\\ 0 & 10\\ \end{pmatrix}
    = \begin{pmatrix} 25 & 30\\ 30 & 100\\ \end{pmatrix} \end{equation}\]
- en: 'Using R (the symbol `%*%` is the matrix multiplication operator in R):'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 使用R（符号`%*%`是R中的矩阵乘法运算符）：
- en: '[PRE66]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: This decomposition and reassembly of the variance-covariance matrix will become
    important when we start building hierarchical models in Stan.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方差-协方差矩阵的分解和重新组装在我们开始使用Stan构建层次模型时将变得重要。
- en: '1.7 An important concept: The marginal likelihood (integrating out a parameter)'
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.7 一个重要概念：边缘似然（消去参数）
- en: Here, we introduce a concept that will turn up many times in this book. The
    concept we unpack here is called “integrating out a parameter.” We will need this
    when we encounter Bayes’ rule in the next chapter, and when we use Bayes factors
    later in the book (chapter [13](ch-bf.html#ch-bf)).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍一个将在本书中多次出现的概念。我们在这里展开的概念被称为“消去参数”。当我们遇到下一章中的贝叶斯规则，以及本书后面使用贝叶斯因子时（第[13](ch-bf.html#ch-bf)章），我们将需要这个概念。
- en: Integrating out a parameter refers to the following situation. The example used
    here discusses the binomial distribution, but the approach is generally applicable
    for any distribution.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 消去参数指的是以下情况。这里使用的例子讨论的是二项分布，但这种方法通常适用于任何分布。
- en: Suppose we have a binomial random variable \(Y\) with PMF \(p(Y)\). Suppose
    also that this PMF is defined in terms of parameter \(\theta\) that can have only
    three possible values, \(0.1, 0.5, 0.9\), each with equal probability. In other
    words, the probability that \(\theta\) is \(0.1, 0.5,\) or \(0.9\) is \(1/3\)
    each.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个二项随机变量 \(Y\)，其概率质量函数为 \(p(Y)\)。假设这个概率质量函数是用参数 \(\theta\) 定义的，\(\theta\)
    只能取三个可能的值，\(0.1, 0.5, 0.9\)，每个值都有相等的概率。换句话说，\(\theta\) 是 \(0.1, 0.5\) 或 \(0.9\)
    的概率都是 \(1/3\)。
- en: We stick with our earlier example of \(n=10\) trials and \(k=7\) successes.
    The likelihood function then is
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续使用之前的例子，即 \(n=10\) 次试验和 \(k=7\) 次成功。那么似然函数就是
- en: \[\begin{equation} p(k=7,n=10|\theta) = \binom{10}{7} \theta^7 (1-\theta)^{3}
    \end{equation}\]
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p(k=7,n=10|\theta) = \binom{10}{7} \theta^7 (1-\theta)^{3}
    \end{equation}\]
- en: 'There is a related concept of marginal likelihood, which we can write here
    as \(p(k=7,n=10)\). Marginal likelihood is the likelihood computed by “marginalizing”
    out the parameter \(\theta\): for each possible value that the parameter \(\theta\)
    can have, we compute the likelihood at that value and multiply that likelihood
    with the probability/density of that \(\theta\) value occurring. Then we sum up
    each of the products computed in this way. Mathematically, this means that we
    carry out the following operation.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个相关的边缘似然概念，我们可以将其写为 \(p(k=7,n=10)\)。边缘似然是通过“边缘化”参数 \(\theta\) 来计算的似然：对于参数
    \(\theta\) 可能的每个值，我们计算该值下的似然，并将该似然与 \(\theta\) 值发生的概率/密度相乘。然后我们将这种方式计算出的每个乘积相加。从数学上来说，这意味着我们执行以下操作。
- en: 'In our example, there are three possible values of \(\theta\), call them \(\theta_1=0.1\),
    \(\theta_2=0.5\), and \(\theta_3=0.9\). Each has probability \(1/3\); so \(p(\theta_1)=p(\theta_2)=p(\theta_3)=1/3\).
    Given this information, we can compute the marginal likelihood as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，\(\theta\) 有三个可能的值，我们可以称它们为 \(\theta_1=0.1\)，\(\theta_2=0.5\)，和 \(\theta_3=0.9\)。每个值都有
    \(1/3\) 的概率；所以 \(p(\theta_1)=p(\theta_2)=p(\theta_3)=1/3\)。有了这些信息，我们可以计算边缘似然如下：
- en: \[\begin{equation} \begin{split} p(k=7,n=10) =& \binom{10}{7} \theta_1^7 (1-\theta_1)^{3}
    \times p(\theta_1) \\ +& \binom{10}{7} \theta_2^7 (1-\theta_2)^{3}\times p(\theta_2)
    \\ +& \binom{10}{7} \theta_3^7 (1-\theta_3)^{3}\times p(\theta_3) \end{split}
    \end{equation}\]
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{split} p(k=7,n=10) =& \binom{10}{7} \theta_1^7 (1-\theta_1)^{3}
    \times p(\theta_1) \\ +& \binom{10}{7} \theta_2^7 (1-\theta_2)^{3}\times p(\theta_2)
    \\ +& \binom{10}{7} \theta_3^7 (1-\theta_3)^{3}\times p(\theta_3) \end{split}
    \end{equation}\]
- en: 'Writing the \(\theta\) values and their probabilities, we get:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 将 \(\theta\) 值及其概率写出，我们得到：
- en: \[\begin{equation} \begin{split} p(k=7,n=10) =& \binom{10}{7} 0.1^7 (1-0.1)^{3}
    \times \frac{1}{3} \\ +& \binom{10}{7} 0.5^7 (1-0.5)^{3}\times \frac{1}{3} \\
    +& \binom{10}{7} 0.9^7 (1-0.9)^{3}\times \frac{1}{3} \end{split} \end{equation}\]
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{split} p(k=7,n=10) =& \binom{10}{7} 0.1^7 (1-0.1)^{3}
    \times \frac{1}{3} \\ +& \binom{10}{7} 0.5^7 (1-0.5)^{3}\times \frac{1}{3} \\
    +& \binom{10}{7} 0.9^7 (1-0.9)^{3}\times \frac{1}{3} \end{split} \end{equation}\]
- en: 'Taking the common factors (\(\frac{1}{3}\) and \(\binom{10}{7}\)) out:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 提取公共因子 (\(\frac{1}{3}\) 和 \(\binom{10}{7}\))：
- en: \[\begin{equation} \begin{split} p(k=7,n=10) =& \frac{1}{3} \binom{10}{7} \big[
    0.1^7 (1-0.1)^{3} \\ +& 0.5^7 (1-0.5)^{3} \\ +& 0.9^7 (1-0.9)^{3} \big] \\ =&
    0.058 \end{split} \end{equation}\]
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} \begin{split} p(k=7,n=10) =& \frac{1}{3} \binom{10}{7} \big[
    0.1^7 (1-0.1)^{3} \\ +& 0.5^7 (1-0.5)^{3} \\ +& 0.9^7 (1-0.9)^{3} \big] \\ =&
    0.058 \end{split} \end{equation}\]
- en: Thus, a marginal likelihood is a kind of weighted sum of the likelihood, weighted
    by the possible values of the parameter.[⁸](#fn8)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，边缘似然是似然的一种加权求和，其权重由参数的可能值决定。[⁸](#fn8)
- en: The above example was contrived, because we stated that the parameter \(\theta\)
    has only three possible discrete values. Now consider the case where the parameter
    \(\theta\) can have all possible values between \(0\) and \(1\); every possible
    value is equally likely. Formally, what this means is that the possible values
    of \(\theta\) can be described in terms of the uniform distribution with lower
    bound \(0\) and upper bound \(1\) (for more details on this distribution, see
    section 5.2 in Blitzstein and Hwang [2014](#ref-blitzstein2014introduction)).
    This is a continuous distribution, and because the area under the distribution
    has to sum to \(1\), the density of every possible value of \(\theta\) is \(1\).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 上述例子是人为构造的，因为我们指出参数 \(\theta\) 只有三个可能的离散值。现在考虑参数 \(\theta\) 可以在 \(0\) 和 \(1\)
    之间取所有可能值的情形；每个可能值出现的概率是相等的。形式上，这意味着 \(\theta\) 的可能值可以用下限为 \(0\)、上限为 \(1\) 的均匀分布来描述（关于此分布的更多细节，请参阅
    Blitzstein 和 Hwang [2014](#ref-blitzstein2014introduction) 中的第 5.2 节）。这是一个连续分布，由于分布下的面积必须总和为
    \(1\)，因此 \(\theta\) 每个可能值的密度都是 \(1\)。
- en: 'In this example, the summation now has to be done over a continuous space \([0,1]\).
    The way this summation is expressed in mathematics is through the integral symbol:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，现在需要对连续空间 \([0,1]\) 进行求和。数学中表达这种求和的方式是通过积分符号：
- en: \[\begin{equation} p(k=7,n=10) = \int_0^1 \binom{10}{7} \theta^7 (1-\theta)^{3}\,
    p(\theta) d\theta \end{equation}\]
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p(k=7,n=10) = \int_0^1 \binom{10}{7} \theta^7 (1-\theta)^{3}\,
    p(\theta) d\theta \end{equation}\]
- en: 'Because \(p(\theta)=1\) for all \(\theta\) (in this particular case), we can
    just write:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 因为对于所有 \(\theta\)（在这个特定情况下），\(p(\theta)=1\)，所以我们只需写出：
- en: \[\begin{equation} p(k=7,n=10) = \int_0^1 \binom{10}{7} \theta^7 (1-\theta)^{3}\,
    d\theta \end{equation}\]
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{equation} p(k=7,n=10) = \int_0^1 \binom{10}{7} \theta^7 (1-\theta)^{3}\,
    d\theta \end{equation}\]
- en: 'This statement is computing something similar to what we computed above with
    the three discrete parameter values, except that the summation is being done over
    a continuous space ranging from 0 to 1\. We say that the parameter \(\theta\)
    has been integrated out, or marginalized. Integrating out a parameter will be
    a very common operation in this book, but we will never have to do the calculation
    ourselves. For the above case, we can compute the integral in R:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这个陈述计算的是与我们上面用三个离散参数值计算类似的东西，只是求和是在从 0 到 1 的连续空间上进行的。我们说参数 \(\theta\) 已经被积分掉，或者说是边缘化。在本书中，积分参数将是一个非常常见的操作，但我们永远不需要自己进行计算。对于上述情况，我们可以在
    R 中计算这个积分：
- en: '[PRE74]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The value that is output by the `integrate()` function above is the marginal
    likelihood.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 `integrate()` 函数输出的值是边缘似然。
- en: This completes our discussion of random variables and probability distributions.
    Next, we summarize what we have learned so far about univariate distributions.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们对随机变量和概率分布的讨论。接下来，我们将总结到目前为止关于单变量分布所学到的东西。
- en: 1.8 Summary of some useful R functions
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.8 一些有用的 R 函数摘要
- en: Table [1.6](ch-intro.html#tab:dpqrfunctions) summarizes the different functions
    relating to PMFs and PDFs, using the binomial and normal as examples.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1.6](ch-intro.html#tab:dpqrfunctions) 总结了与 PMFs 和 PDFs 相关的不同函数，以二项分布和正态分布为例。
- en: 'TABLE 1.6: Important R functions relating to random variables.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 'TABLE 1.6: 与随机变量相关的重要 R 函数。'
- en: '|  | Discrete | Continuous |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  | 离散 | 连续 |'
- en: '| --- | :-: | :-: |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| --- | :-: | :-: |'
- en: '| Example: | \(\mathit{Binomial}(y&#124;n,\theta)\) | \(\mathit{Norma}l(y&#124;\mu,\sigma)\)
    |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 示例 | \(\mathit{Binomial}(y|n,\theta)\) | \(\mathit{Normal}(y|\mu,\sigma)\)
    |'
- en: '| Likelihood function | `dbinom()` | `dnorm()` |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 似然函数 | `dbinom()` | `dnorm()` |'
- en: '| Prob Y=y | `dbinom()` | always 0 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 概率 Y=y | `dbinom()` | 总是 0 |'
- en: '| Prob \(Y\geq y, Y\leq y, y_1<Y<y_2\) | `pbinom()` | `pnorm()` |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 概率 \(Y\geq y, Y\leq y, y_1<Y<y_2\) | `pbinom()` | `pnorm()` |'
- en: '| Inverse CDF | `qbinom()` | `qnorm()` |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 反 CDF | `qbinom()` | `qnorm()` |'
- en: '| Generate simulated data | `rbinom()` | `rnorm()` |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 生成模拟数据 | `rbinom()` | `rnorm()` |'
- en: Later on, we will use other distributions, such as the uniform, beta, etc.,
    and each of these has their own set of `d-p-q-r` functions in R. One can look
    up these different distributions in, for example, Blitzstein and Hwang ([2014](#ref-blitzstein2014introduction)).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将使用其他分布，例如均匀分布、贝塔分布等，每个分布都有其自己的 `d-p-q-r` 函数集。例如，可以在 Blitzstein 和 Hwang
    ([2014](#ref-blitzstein2014introduction)) 中查找这些不同的分布。
- en: 1.9 Summary
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.9 摘要
- en: This chapter briefly reviewed some very basic concepts in probability theory,
    univariate discrete and continuous random variables, and bivariate distributions.
    An important set of functions we encountered are the d-p-q-r family of functions
    for different distributions; these are very useful for understanding the properties
    of commonly used distributions, visualizing distributions, and for simulating
    data. Distributions will play a central role in this book; for example, knowing
    how to visualize distributions will be important for deciding on prior distributions
    for parameters. Other important ideas we learned about were marginal and conditional
    probability, marginal likelihood, and how to define multivariate distributions;
    these concepts will play an important role in Bayesian statistics.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 本章简要回顾了概率论中的一些非常基本的概念，包括一元离散和连续随机变量以及双变量分布。我们遇到的一个重要函数集是针对不同分布的d-p-q-r函数族；这些函数对于理解常用分布的性质、可视化分布以及模拟数据非常有用。分布将在本书中扮演核心角色；例如，了解如何可视化分布对于确定参数的先验分布将非常重要。我们学到的其他重要概念包括边缘和条件概率、边缘似然以及如何定义多元分布；这些概念将在贝叶斯统计中发挥重要作用。
- en: 1.10 Further reading
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.10 进一步阅读
- en: 'An informal but useful discussion about probability appears in Spiegelhalter
    ([2024](#ref-spiegelhalter2024probability)). A quick review of the mathematical
    foundations needed for statistics is available in the short book by Fox ([2009](#ref-fox2009mathematical)),
    as well as Gill ([2006](#ref-gill2006essential)). A more comprehensive introduction
    to the mathematical background needed for advanced Bayesian modeling is Jordan
    and Smith ([2008](#ref-jordan2008mathematical)). Morin ([2016](#ref-morin2016probability))
    and Blitzstein and Hwang ([2014](#ref-blitzstein2014introduction)) are accessible
    introductions to probability theory. Ross ([2002](#ref-RossProb)) offers a more
    advanced treatment which discusses random variable theory and illustrates applications
    of probability theory. Some basic results about random variables are also discussed
    in the above-mentioned textbooks (for example, the expectation and variance of
    sums of random variables); some of these results will be needed in later chapters
    of the present book. A good formal introduction to mathematical statistics (covering
    classical frequentist theory) is Miller and Miller ([2004](#ref-millermiller)).
    The freely available book by Kerns ([2014](#ref-kerns2014introduction)) introduces
    frequentist and Bayesian statistics from the ground up in a very comprehensive
    and systematic manner; the source code for the book is available from [https://github.com/gjkerns/IPSUR](https://github.com/gjkerns/IPSUR).
    The open-access book, *Probability and Statistics: a simulation-based introduction*,
    by Bob Carpenter is also worth studying: [https://github.com/bob-carpenter/prob-stats](https://github.com/bob-carpenter/prob-stats).
    A thorough introduction to the matrix algebra needed for statistics, with examples
    using R, is provided in Fieller ([2016](#ref-fieller)). Commonly used probability
    distributions are presented in detail in Miller and Miller ([2004](#ref-millermiller)),
    Blitzstein and Hwang ([2014](#ref-blitzstein2014introduction)), and Ross ([2002](#ref-RossProb)).
    A useful reference for continuous univariate distributions is Johnson, Kotz, and
    Balakrishnan ([1995](#ref-johnson1995continuous)).'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spiegelhalter ([2024](#ref-spiegelhalter2024probability))的著作中有一篇关于概率的非正式但有用的讨论。关于统计学所需的数学基础，可以在Fox
    ([2009](#ref-fox2009mathematical))和Gill ([2006](#ref-gill2006essential))的简短书籍中找到，以及Jordan和Smith
    ([2008](#ref-jordan2008mathematical))对高级贝叶斯建模所需的数学背景的更全面介绍。Morin ([2016](#ref-morin2016probability))和Blitzstein与Hwang
    ([2014](#ref-blitzstein2014introduction))提供了概率理论的易于理解的入门介绍。Ross ([2002](#ref-RossProb))提供了更高级的处理方法，讨论了随机变量理论并展示了概率理论的应用。一些关于随机变量的基本结果也在上述教材中讨论（例如，随机变量和的期望和方差）；本书后面的章节中需要用到这些结果中的一些。Miller和Miller
    ([2004](#ref-millermiller))提供了对数学统计学的良好正式介绍（涵盖经典频率派理论）。Kerns ([2014](#ref-kerns2014introduction))的免费书籍从基础开始，以非常全面和系统的方式介绍了频率派和贝叶斯统计学；本书的源代码可在[https://github.com/gjkerns/IPSUR](https://github.com/gjkerns/IPSUR)找到。Bob
    Carpenter的开放获取书籍《概率与统计：基于模拟的介绍》也值得研究：[https://github.com/bob-carpenter/prob-stats](https://github.com/bob-carpenter/prob-stats)。Fieller
    ([2016](#ref-fieller))提供了对用于统计学的矩阵代数的彻底介绍，其中包含使用R的示例。Miller和Miller ([2004](#ref-millermiller))、Blitzstein和Hwang
    ([2014](#ref-blitzstein2014introduction))和Ross ([2002](#ref-RossProb))详细介绍了常用的概率分布。Johnson、Kotz和Balakrishnan
    ([1995](#ref-johnson1995continuous))提供了关于连续单变量分布的有用参考。
- en: References
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: Blitzstein, Joseph K., and Jessica Hwang. 2014\. *Introduction to Probability*.
    Chapman; Hall/CRC.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Blitzstein, Joseph K., and Jessica Hwang. 2014\. *《概率论入门》*. Chapman; Hall/CRC.
- en: 'Fieller, Nick. 2016\. *Basics of Matrix Algebra for Statistics with R*. Boca
    Raton, FL: CRC Press.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 'Fieller, Nick. 2016\. *《使用 R 的矩阵代数基础》*. Boca Raton, FL: CRC Press.'
- en: Fox, John. 2009\. *A Mathematical Primer for Social Statistics*. Vol. 159\.
    Sage.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: Fox, John. 2009\. *《社会统计的数学入门》*. Vol. 159\. Sage.
- en: Gill, Jeff. 2006\. *Essential Mathematics for Political and Social Research*.
    Cambridge University Press Cambridge.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: Gill, Jeff. 2006\. *《政治和社会研究的必要数学》*. Cambridge University Press Cambridge.
- en: Johnson, Norman L., Samuel Kotz, and Narayanaswamy Balakrishnan. 1995\. *Continuous
    Univariate Distributions, Volume 2*. Vol. 289\. John Wiley; Sons.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: Johnson, Norman L., Samuel Kotz, and Narayanaswamy Balakrishnan. 1995\. *《连续单变量分布，第二卷》*.
    Vol. 289\. John Wiley; Sons.
- en: 'Jordan, Dominic, and Peter Smith. 2008\. *Mathematical Techniques: An Introduction
    for the Engineering, Physical, and Mathematical Sciences*. Oxford University Press,
    Oxford.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: Jordan, Dominic, and Peter Smith. 2008\. *《工程、物理和数学科学的技术方法：导论》*. Oxford University
    Press, Oxford.
- en: Kerns, G. J. 2014\. *Introduction to Probability and Statistics Using R*. Second
    Edition.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: Kerns, G. J. 2014\. *《使用 R 的概率论与数理统计导论》*. 第二版.
- en: 'Kolmogorov, Andreı̆ Nikolaevich. 1933\. *Foundations of the Theory of Probability:
    Second English Edition*. Courier Dover Publications.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: Kolmogorov, Andreı̆ Nikolaevich. 1933\. *《概率论基础理论：第二英文版》*. Courier Dover Publications.
- en: Laurinavichyute, Anna. 2020\. “Similarity-Based Interference and Faulty Encoding
    Accounts of Sentence Processing.” Dissertation, University of Potsdam. [https://publishup.uni-potsdam.de/frontdoor/index/index/docId/50966](https://publishup.uni-potsdam.de/frontdoor/index/index/docId/50966).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: Laurinavichyute, Anna. 2020\. “基于相似性的干扰和句子处理的错误编码解释。” 博士学位论文，波茨坦大学. [https://publishup.uni-potsdam.de/frontdoor/index/index/docId/50966](https://publishup.uni-potsdam.de/frontdoor/index/index/docId/50966).
- en: 'Miller, I., and M. Miller. 2004\. *John E. Freund’s Mathematical Statistics
    with Applications*. Upper Saddle River, NJ: Prentice Hall.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 'Miller, I., and M. Miller. 2004\. *《约翰·E·弗雷德数学统计学应用》*. Upper Saddle River,
    NJ: Prentice Hall.'
- en: 'Morin, David J. 2016\. *Probability: For the Enthusiastic Beginner*. Createspace
    Independent Publishing Platform.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: Morin, David J. 2016\. *《概率论：为热情的初学者》*. Createspace Independent Publishing Platform.
- en: Resnick, Sidney. 2019\. *A Probability Path*. Springer.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: Resnick, Sidney. 2019\. *《概率论路径》*. Springer.
- en: Ross, Sheldon. 2002\. *A First Course in Probability*. Pearson Education.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Ross, Sheldon. 2002\. *《概率论入门》*. Pearson Education.
- en: 'Spiegelhalter, David J. 2024\. “Why Probability Probably Doesn’t Exist (but
    It Is Useful to Act Like It Does).” *Nature* 636 (8043): 560–63.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 'Spiegelhalter, David J. 2024\. “为什么概率可能不存在（但它有用地表现得像它存在）。” *《自然》* 636 (8043):
    560–63.'
- en: 'Steyer, Rolf, and Werner Nagel. 2017\. *Probability and Conditional Expectation:
    Fundamentals for the Empirical Sciences*. Vol. 5\. John Wiley & Sons.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: Steyer, Rolf, and Werner Nagel. 2017\. *《概率与条件期望：实证科学的基础》*. Vol. 5\. John Wiley
    & Sons.
- en: '* * *'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'When the sample space \(\Omega\) is finite, any subset of \(\Omega\) can be
    an event; in this case, the event space \(F\) is the collection of all possible
    subsets of \(\Omega\). In set theory, a set of all the subsets of another set
    is called a power set, and the number of subsets of any set with \(n\) elements
    is \(2^n\). For example, for a standard six-sided die, the sample space is the
    set \(\Omega=\{1,2,3,4,5,6\}\) and the event space \(F\) will contain \(2^6 =
    64\) sets: the empty set, six one-element sets, \(15\) two-element sets, \(20\)
    three-element sets, …, and one six-element set. Here are three assumptions we
    will always make about any event space: (a) Both the empty set and universal set
    (\(\Omega\)) belong to the event space \(F\); (b) if \(E\) is an event, then so
    is the complement of \(E\); and (c) for any list of events \(A_1, A_2,...\) (finite
    or infinite), the phrase “\(A_1\) or \(A_2\) or …” describes another event.[↩︎](ch-intro.html#fnref1)'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当样本空间 \(\Omega\) 是有限的，\(\Omega\) 的任何子集都可以是一个事件；在这种情况下，事件空间 \(F\) 是 \(\Omega\)
    所有可能子集的集合。在集合论中，一个集合的所有子集的集合被称为幂集，任何具有 \(n\) 个元素的集合的子集数量是 \(2^n\)。例如，对于一个标准的六面骰子，样本空间是集合
    \(\Omega=\{1,2,3,4,5,6\}\)，事件空间 \(F\) 将包含 \(2^6 = 64\) 个集合：空集，六个单元素集合，\(15\) 个双元素集合，\(20\)
    个三元素集合，……，以及一个六元素集合。以下是关于任何事件空间我们将始终做出的三个假设：(a) 空集和全集 (\(\Omega\)) 都属于事件空间 \(F\)；(b)
    如果 \(E\) 是一个事件，那么 \(E\) 的补集也是事件；(c) 对于任何事件列表 \(A_1, A_2,...\)（有限或无限），短语“\(A_1\)
    或 \(A_2\) 或……”描述了另一个事件。[↩︎](ch-intro.html#fnref1)
- en: Here, we use \(Y\), but we could have used any letter, such as \(X, Z,...\).
    Later on, in some situations we will use Greek letters like \(\theta, \mu, \sigma\)
    to represent a random variable.[↩︎](ch-intro.html#fnref2)
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们使用\(Y\)，但我们也可以使用任何其他字母，例如\(X, Z,...\)。稍后，在某些情况下，我们将使用希腊字母如\(\theta, \mu,
    \sigma\)来表示随机变量。[↩︎](ch-intro.html#fnref2)
- en: The actual formal definition of random variable is more complex, and it is based
    on measure theory. A more rigorous definition can be found in, for example, Steyer
    and Nagel ([2017](#ref-steyer2017probability)) and Resnick ([2019](#ref-resnick2019probability)).[↩︎](ch-intro.html#fnref3)
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机变量的实际形式定义更为复杂，它基于测度理论。更严谨的定义可以在例如Steyer和Nagel ([2017](#ref-steyer2017probability))
    和Resnick ([2019](#ref-resnick2019probability)) 的著作中找到。[↩︎](ch-intro.html#fnref3)
- en: 'A notational aside: In frequentist treatments, the PMF would usually be written
    \(p(y;\theta)\), i.e., with a semi-colon rather than the conditional distribution
    marked by the vertical bar. The semi-colon is intended to indicate that in the
    frequentist paradigm, the parameters are fixed point values; by contrast, in the
    Bayesian paradigm, parameters are random variables. This has the consequence that
    for the Bayesian, the distribution of \(y\), \(p(y)\) is really a conditional
    distribution, conditional on a random variable, here \(\theta\). For the frequentist,
    \(p(y)\) requires some point value for \(\theta\), but it cannot be a conditional
    distribution because \(\theta\) is not a random variable. We define conditional
    distributions later in this section.[↩︎](ch-intro.html#fnref4)'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顺便提一下，在频率论处理中，概率质量函数（PMF）通常写作\(p(y;\theta)\)，即使用分号而不是由竖线标记的条件分布。分号旨在表明，在频率论范式下，参数是固定的点值；相比之下，在贝叶斯范式下，参数是随机变量。这导致对于贝叶斯来说，\(y\)的分布\(p(y)\)实际上是一个条件分布，条件于一个随机变量，在这里是\(\theta\)。对于频率论者，\(p(y)\)需要为\(\theta\)提供一个点值，但由于\(\theta\)不是随机变量，因此它不能是一个条件分布。我们将在本节后面定义条件分布。[↩︎](ch-intro.html#fnref4)
- en: Looking ahead to the rest of the book, in the Bayesian approach, the parameter
    of interest, \(\theta\) in the present example, never has just a true unknown
    point value associated with it; instead, we use a probability distribution to
    express our belief about plausible values of the parameter. However, throughout
    this book, when generating simulated data, we will often use point values for
    parameters. These point values are adopted simply to evaluate the behavior of
    the model being investigated.[↩︎](ch-intro.html#fnref5)
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预览本书的其余部分，在贝叶斯方法中，感兴趣的参数，在本例中为\(\theta\)，并不只是与一个真实的未知点值相关联；相反，我们使用概率分布来表达我们对参数可能值的信念。然而，在本书的整个过程中，当我们生成模拟数据时，我们通常会使用参数的点值。这些点值仅用于评估正在研究模型的特性。[↩︎](ch-intro.html#fnref5)
- en: R will compute the standard deviation by dividing by \(n-1\), not \(n\); this
    is because dividing by \(n\) gives a biased estimate (chapter 10 of Miller and
    Miller [2004](#ref-millermiller)). This is not an important detail for our purposes,
    and in any case for large \(n\) it doesn’t really matter whether one divides by
    \(n\) or \(n-1\).[↩︎](ch-intro.html#fnref6)
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R将计算标准差时除以\(n-1\)，而不是\(n\)；这是因为除以\(n\)会得到一个有偏的估计（参见Miller和Miller [2004](#ref-millermiller)的第10章）。对我们来说，这不是一个重要的细节，而且在任何情况下，对于大的\(n\)，除以\(n\)或\(n-1\)实际上并没有太大区别。[↩︎](ch-intro.html#fnref6)
- en: 'There is a built-in convenience function, `sdcor2cov` in the `SIN` package
    that does this calculation, taking the vector of standard deviations (not the
    diagonal matrix) and the correlation matrix to yield the variance-covariance matrix:
    `sdcor2cov(stddev = sds, corr = corrmatrix)`.[↩︎](ch-intro.html#fnref7)'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`SIN`包中有一个内置的便利函数，`sdcor2cov`，用于执行此计算，它接受标准差向量（而非对角矩阵）和协方差矩阵来得到方差-协方差矩阵：`sdcor2cov(stddev
    = sds, corr = corrmatrix)`。[↩︎](ch-intro.html#fnref7)
- en: Where does the above formula come from? It falls out from the law of total probability
    discussed above.[↩︎](ch-intro.html#fnref8)
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述公式从何而来？它源自上面讨论的全概率定律。[↩︎](ch-intro.html#fnref8)
