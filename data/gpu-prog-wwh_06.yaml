- en: What problems fit to GPU?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适合 GPU 的问题有哪些？
- en: 原文：[https://enccs.github.io/gpu-programming/3-gpu-problems/](https://enccs.github.io/gpu-programming/3-gpu-problems/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://enccs.github.io/gpu-programming/3-gpu-problems/](https://enccs.github.io/gpu-programming/3-gpu-problems/)
- en: '*[GPU programming: why, when and how?](../)* **   What problems fit to GPU?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*[GPU 编程：为什么、何时以及如何？](../)* **   适合 GPU 的问题有哪些？'
- en: '[Edit on GitHub](https://github.com/ENCCS/gpu-programming/blob/main/content/3-gpu-problems.rst)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 GitHub 上编辑](https://github.com/ENCCS/gpu-programming/blob/main/content/3-gpu-problems.rst)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Questions
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: What are the strengths and weaknesses of GPUs?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 的优势和劣势是什么？
- en: What makes a particular problem suitable for GPU-porting?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么因素使特定问题适合 GPU 转移？
- en: Why are GPUs so ubiquitous in machine learning applications?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么 GPU 在机器学习应用中如此普遍？
- en: Objectives
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Get a feeling for the type of use cases that GPUs excel at.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感受 GPU 优秀于哪些用例类型。
- en: Instructor note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 教师备注
- en: 10 min teaching
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10 分钟教学
- en: 10 min exercises
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10 分钟练习
- en: What are GPUs good for?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 适合什么？
- en: 'Answer from [Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing)
    的回答：
- en: '*From a metaphorical point of view, the GPU can be seen as a person lying on
    a bed of nails. The person lying on top is the data and in the base of each nail
    there is a processor, so the nail is actually an arrow pointing from processor
    to memory. All nails are in a regular pattern, like a grid. If the body is well
    spread, it feels good (performance is good), if the body only touches some spots
    of the nail bed, then the pain is bad (bad performance).*'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**从比喻的角度来看，GPU 可以被看作是一个躺在钉床上的一个人。躺在上面的是数据，每个钉子的底部都有一个处理器，所以钉子实际上是从处理器指向内存的箭头。所有钉子都呈规则图案，就像一个网格。如果身体分布得很好，感觉会很好（性能良好），如果身体只接触钉床的一些点，那么疼痛就会很糟糕（性能差）。**'
- en: 'GPU computing is well-suited to problems that involve large amounts of data
    parallelism. Specifically, you can expect good performance on GPUs for:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 计算非常适合涉及大量数据并行的问题。具体来说，你可以在 GPU 上期待良好的性能，特别是对于：
- en: '**Large-scale matrix and vector operations**: Common in machine learning, scientific
    computing, and image processing.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大规模矩阵和向量运算**：在机器学习、科学计算和图像处理中很常见。'
- en: '**Fourier transforms**: Also common in machine learning, scientific computing,
    and image processing.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**傅里叶变换**：在机器学习、科学计算和图像处理中也很常见。'
- en: '**Monte Carlo simulations**: Used across finance, physics, and other fields
    to simulate complex systems.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蒙特卡洛模拟**：在金融、物理和其他领域用于模拟复杂系统。'
- en: '**Molecular dynamics simulations**: Used in chemistry, biochemistry and physics.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分子动力学模拟**：在化学、生物化学和物理学中使用。'
- en: '**Computational fluid dynamics**: Used in engineering, physics, and other fields.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算流体动力学**：在工程、物理和其他领域使用。'
- en: '**Convolutional neural networks** and **computer vision algorithms**.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**和**计算机视觉算法**。'
- en: '**Big data analytics**: Clustering, classification, regression, etc.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据分析**：聚类、分类、回归等。'
- en: '**Graphics rendering**: Original use-case for GPUs.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形渲染**：GPU 的原始用例。'
- en: What are GPUs not good for?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 不擅长什么？
- en: 'Not all programming problems can efficiently leverage the parallelism offered
    by GPUs. Some types of problems that do not fit well on a GPU include:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有编程问题都能有效地利用 GPU 提供的并行性。一些不适合 GPU 的问题类型包括：
- en: '**Sequential tasks**: Problems that require a series of dependent steps, where
    each step relies on the outcome of the previous step, are not well-suited for
    parallel processing. Examples include recursive algorithms, certain dynamic programming
    problems, and some graph traversal algorithms.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序任务**：需要一系列依赖步骤的问题，其中每个步骤依赖于前一个步骤的结果，不适合并行处理。例如，递归算法、某些动态规划问题以及一些图遍历算法。'
- en: '**Fine-grained branching**: GPUs perform best when the code being executed
    across different threads follows a similar control flow. When there is extensive
    branching (i.e., many `if` statements) within a kernel or algorithm, performance
    may suffer due to the divergence in execution paths among the GPU threads.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度分支**：当跨不同线程执行的代码遵循相似的控制流时，GPU 表现最佳。当内核或算法中有大量的分支（即许多 `if` 语句）时，由于 GPU
    线程执行路径的分歧，性能可能会受到影响。'
- en: '**Low arithmetic intensity**: GPUs excel at performing a large number of mathematical
    operations quickly. If a problem has low arithmetic intensity (i.e., a low ratio
    of arithmetic operations to memory accesses), the GPU may not be able to efficiently
    utilize its computational power, leading to underperformance.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低算术强度**：GPU擅长快速执行大量数学运算。如果问题具有低算术强度（即算术运算与内存访问的比率低），GPU可能无法有效地利用其计算能力，导致性能不佳。'
- en: '**Small data sets**: If the problem involves a small data set that does not
    require significant parallelism, using a GPU may not result in noticeable performance
    gains. In such cases, the overhead of transferring data between the CPU and GPU,
    and the time spent initializing the GPU, may outweigh any potential benefits.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小数据集**：如果问题涉及的小数据集不需要显著的并行处理，使用GPU可能不会带来明显的性能提升。在这种情况下，CPU和GPU之间传输数据以及初始化GPU所花费的时间可能会超过任何潜在的好处。'
- en: '**Limited parallelism**: Some algorithms have inherent limitations on the degree
    of parallelism that can be achieved. In these cases, using a GPU may not lead
    to significant performance improvements.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的并行性**：一些算法在可实现的并行度上存在固有的限制。在这些情况下，使用GPU可能不会导致显著的性能提升。'
- en: '**Memory-bound problems**: GPUs generally have less memory available compared
    to CPUs, and their memory bandwidth can be a limiting factor. If a problem requires
    a large amount of memory or involves memory-intensive operations, it may not be
    well-suited for a GPU.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存绑定问题**：与CPU相比，GPU通常可用的内存较少，其内存带宽可能成为限制因素。如果问题需要大量的内存或涉及内存密集型操作，它可能不适合GPU。'
- en: Examples of GPU acceleration
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU加速的示例
- en: To give a flavor of what type of performance gains we can achieve by porting
    a calculations to a GPU (if we’re lucky!), let’s look at a few case examples.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示将计算移植到GPU（如果我们幸运的话）可以实现的性能提升，让我们看看几个案例示例。
- en: Effect of array size
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数组大小的影响
- en: 'Consider the case of matrix multiplication in the Julia language:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑Julia语言中矩阵乘法的案例：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How much faster do you think the GPU version is compared to running on a single
    CPU core?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你认为GPU版本相比在单个CPU核心上运行要快多少？
- en: Julia automatically parallelises matrix multiplication over available CPU cores.
    Will the GPU version be faster than running on 64 cores?
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Julia会自动并行化矩阵乘法，以利用可用的CPU核心。GPU版本会比在64个核心上运行快吗？
- en: Does the size of the array affect how much the performance improves?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数组的尺寸会影响性能提升的多少吗？
- en: Solution
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Example results from running on LUMI (MI250X AMD GPU, 64-core AMD Trento CPUs):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在LUMI（MI250X AMD GPU，64核AMD Trento CPU）上运行的结果示例：
- en: GPU acceleration for matrix multiply in Julia
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Julia中矩阵乘法的GPU加速
- en: '| Matrix size | 1 CPU core | 64 CPU cores | 1 GPU | GPU speedup |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 矩阵大小 | 1 CPU核心 | 64 CPU核心 | 1 GPU | GPU加速比 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
- en: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
- en: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
- en: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
- en: Electronic structure calculations
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 电子结构计算
- en: '[VASP](https://www.vasp.at/) is a popular software package used for electronic
    structure calculations. The figures below show the speedup observed in a recent
    benchmark study on the [VASP Power Profiles on NVIDIA A100 GPUs](https://ieeexplore.ieee.org/document/10820603),
    which was conducted on the Perlmutter system at NERSC. An analysis of total energy
    usage demonstrated that VASP’s power usage varies significantly with different
    workloads, more so than with parallel concurrency. Additionally, power capping
    GPUs to 50% of their Thermal Design Power can be applied to most VASP workloads
    with less than a 10% performance loss.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[VASP](https://www.vasp.at/) 是一个流行的软件包，用于电子结构计算。下面的图示显示了在NERSC的Perlmutter系统上进行的最近基准测试研究
    [VASP在NVIDIA A100 GPU上的功率配置文件](https://ieeexplore.ieee.org/document/10820603)
    中观察到的加速效果，该研究展示了VASP的总能耗分析，表明VASP的功耗随着不同工作负载的变化而显著变化，比并行并发的变化更大。此外，将GPU的功耗限制在其热设计功耗的50%以下，可以应用于大多数VASP工作负载，而性能损失不到10%。'
- en: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
- en: Parallel efficiency of VASP on seven test cases representing diverse VASP production
    workloads and ensuring a comprehensive coverage of various code paths, elements,
    and problem sizes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: VASP在七个测试案例上的并行效率，这些测试案例代表了多样化的VASP生产工作负载，并确保对各种代码路径、元素和问题规模的全面覆盖。
- en: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
- en: '(Left) Power usage of seven representative VASP workloads. The horizontal axis
    shows number of nodes used, and vertical axis shows high power mode per node.
    (Right) Power consumed per GPU when running VASP under four different power caps:
    400 W (default), 300 W, 200 W, and 100 W. Horizontal axis shows power caps applied
    to GPUs, and vertical axis shows high power mode per GPU as a fraction of applied
    cap. The dashed horizontal line represents applied power cap. Each benchmark was
    run with a node count optimizing runtime while remaining above 70% parallel efficiency.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: （左）七个代表性VASP工作负载的功耗。水平轴表示使用的节点数，垂直轴表示每个节点的超高功率模式。 （右）在四种不同的功率限制下运行VASP时的GPU功耗：400
    W（默认）、300 W、200 W和100 W。水平轴表示施加到GPU上的功率限制，垂直轴表示每个GPU的超高功率模式占应用功率限制的比例。虚线水平线表示应用的功率限制。每个基准测试都是在优化运行时间的同时保持超过70%的并行效率的情况下运行的。
- en: Computational Chemistry
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算化学
- en: 'A great deal of computational resources are spent in Quantum Chemical calculations
    which involve the solution of the Hartree-Fock eigenvalue problem, which requires
    the diagonalization of the Fock matrix whose elements are given by:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子化学计算中投入了大量的计算资源，这些计算涉及哈特里-福克特征值问题的求解，这需要求解福克矩阵的对角化，其元素由以下给出：
- en: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
- en: 'The first term is related to the one electron contributions and the second
    term is related to the electron repulsion integrals (ERIs), in parenthesis, weighted
    by the by the density matrix \(D_{\gamma \delta}\). One of the most expensive
    parts in the solution of the Hartree-Fock equations is the processing (digestion)
    of the ERIs, one algorithm to do this task is as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项与单电子贡献相关，第二个项与电子排斥积分（ERIs）相关，括号内表示由密度矩阵 \(D_{\gamma \delta}\) 加权。在哈特里-福克方程的求解过程中，最昂贵的部分之一是处理（消化）ERIs，完成这一任务的算法如下：
- en: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
- en: Algorithm for processing ERIs [see [JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)
    for details]
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 处理ERIs的算法 [参见[JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)
    获取详细信息]
- en: This algorithm is suitable for GPUs as it involves many arithmetic operations.
    In addition to this, there are symmetries and properties of the integrals that
    could be used to rearrange the loops in an efficient manner that fit GPU architectures.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法适用于GPU，因为它涉及大量的算术运算。此外，还有积分的对称性和性质，可以用来以高效的方式重新排列循环，以适应GPU架构。
- en: Humanities
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人文学科
- en: A brief introduction into some of the work that is being done in the humanities
    that can benefit from utilizing GPUs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对人文学科中可以利用GPU进行的一些正在进行的工作的简要介绍。
- en: '**Language models and NLP (natural language processing)**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言模型和NLP（自然语言处理**）'
- en: With the recent popularity of ChatGPT, the use of language models has come into
    the mainstream, however such models have been used in the humanities many years
    already. One of the biggest goals of humanities researchers is working with textual
    data which has increased exponentially over recent years due to the rise in social
    media. Analyzing such textual data to gain insights into questions of sociology,
    linguistics and various other fields have become increasingly reliant on using
    language models. Along with language models, the need for GPU access has become
    essential.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT的近期流行，语言模型的使用已经进入主流，然而这些模型在多年前就已经被应用于人文学科。人文学者最大的目标之一是与近年来由于社交媒体的兴起而呈指数增长的文本数据合作。分析此类文本数据以深入了解社会学、语言学和其他领域的相关问题，越来越依赖于使用语言模型。随着语言模型的使用，对GPU访问的需求也变得至关重要。
- en: '**Archeology**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**考古学**'
- en: The field of archeology also makes use of GPUs in their 3D modelling and rendering
    work. The biggest problem with archeological sites is that once they are excavated,
    they are destroyed, so any researchers who aren’t present at the site, would lose
    valuable insights into how it looked when it was found. However, with recent developments
    in technology and accessibility to high-performance computing, they are able to
    generate extremely detailed renderings of the excavation sites which act as a
    way to preserve the site for future researchers to gain critical insights and
    contribute to the research.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 考古学领域也利用GPU进行3D建模和渲染工作。考古遗址的最大问题是，一旦被挖掘，它们就会被破坏，因此任何不在现场的研究人员都会失去对遗址发现时外观的宝贵洞察。然而，随着技术和高性能计算的可访问性最近的发展，他们能够生成极其详细的挖掘遗址渲染图，这可以作为保存遗址的一种方式，以便未来的研究人员获得关键的洞察并贡献于研究。
- en: '**Cognitive Science**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**认知科学**'
- en: Techniques such as Markov Chain Monte Carlo (MCMC) sampling have proven to be
    invaluable in studies that delve into human behavior or population dynamics. MCMC
    sampling allows researchers to simulate and analyze complex systems by iteratively
    sampling from a Markov chain, enabling the exploration of high-dimensional parameter
    spaces. This method is particularly useful when studying human behavior, as it
    can capture the inherent randomness and interdependencies that characterize social
    systems. By leveraging MCMC sampling, researchers can gain insights into various
    aspects of human behavior, such as decision-making, social interactions, and the
    spread of information or diseases within populations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如马尔可夫链蒙特卡洛（MCMC）采样等技术的证明在深入研究人类行为或种群动态的研究中非常有价值。MCMC采样允许研究人员通过迭代地从马尔可夫链中采样来模拟和分析复杂系统，从而探索高维参数空间。这种方法在研究人类行为时特别有用，因为它可以捕捉到表征社会系统的固有随机性和相互依赖性。通过利用MCMC采样，研究人员可以深入了解人类行为的各个方面，如决策、社会互动以及信息或疾病在人群中的传播。
- en: By offloading the computational workload to GPUs, researchers can experience
    substantial speedup in the execution of MCMC algorithms. This speedup allows for
    more extensive exploration of parameter spaces and facilitates the analysis of
    larger datasets, leading to more accurate and detailed insights into human behavior
    or population dynamics. Examples of studies done using these methods can be found
    at the [Center for Humanities Computing Aarhus](https://chc.au.dk/) (CHCAA) and
    [Interacting Minds Centre](https://interactingminds.au.dk/) (IMC) at Aarhus University.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将计算工作负载卸载到GPU，研究人员可以在MCMC算法的执行中体验到实质性的加速。这种加速允许更广泛地探索参数空间，并促进对更大数据集的分析，从而对人类行为或种群动态有更准确和详细的洞察。使用这些方法进行的案例研究可以在[人文计算中心奥尔胡斯](https://chc.au.dk/)（CHCAA）和[互动心智中心](https://interactingminds.au.dk/)（IMC）的[奥尔胡斯大学](https://chc.au.dk/)找到。
- en: Exercises
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Discussion
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论
- en: What type of problems have you used GPUs for?
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用GPU解决了哪些类型的问题？
- en: How large was the performance boost?
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能提升有多大？
- en: Good and bad use cases for GPU porting
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: GPU迁移的优缺点案例
- en: Which of the following computational tasks is likely to gain the least performance
    benefit from being ported to a GPU?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个计算任务在迁移到GPU后可能获得的最小性能提升？
- en: Training a large, deep neural network.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个大型、深度神经网络。
- en: Performing a Monte Carlo simulation with a large number of independent trials.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行大量独立试验的蒙特卡洛模拟。
- en: Executing an algorithm with heavy use of recursion and frequent branching.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行大量递归和频繁分支的算法。
- en: Processing a large image with a convolutional filter.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用卷积滤波器处理大型图像。
- en: Solution
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The right answer is option 3\. GPUs do not handle recursion and branching as
    effectively as more data-heavy algorithms.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是选项3。GPU在处理比数据更重的算法时，不如处理递归和分支有效。
- en: Keypoints
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs excel in processing tasks with high data parallelism, such as large-scale
    matrix operations, Fourier transforms, and big data analytics.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理具有高数据并行性的任务方面表现出色，例如大规模矩阵运算、傅里叶变换和大数据分析。
- en: GPUs struggle with sequential tasks, problems with extensive control flow divergence,
    low arithmetic intensity tasks, small data sets, and memory-bound problems. [Previous](../2-gpu-ecosystem/
    "The GPU hardware and software ecosystem") [Next](../4-gpu-concepts/ "GPU programming
    concepts")
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理顺序任务、具有广泛控制流发散的问题、低算术强度任务、小数据集和内存绑定问题方面存在困难。[上一页](../2-gpu-ecosystem/
    "GPU硬件和软件生态系统") [下一页](../4-gpu-concepts/ "GPU编程概念")
- en: '* * *'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: © Copyright 2023-2024, The contributors.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: © 版权所有 2023-2024，贡献者。
- en: Built with [Sphinx](https://www.sphinx-doc.org/) using a [theme](https://github.com/readthedocs/sphinx_rtd_theme)
    provided by [Read the Docs](https://readthedocs.org). Questions
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Sphinx](https://www.sphinx-doc.org/)构建，并采用[Read the Docs](https://readthedocs.org)提供的[主题](https://github.com/readthedocs/sphinx_rtd_theme)。
- en: What are the strengths and weaknesses of GPUs?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU的优缺点是什么？
- en: What makes a particular problem suitable for GPU-porting?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么使得特定问题适合GPU迁移？
- en: Why are GPUs so ubiquitous in machine learning applications?
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据分析**：聚类、分类、回归等。'
- en: Objectives
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Get a feeling for the type of use cases that GPUs excel at.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU计算非常适合涉及大量数据并行的问题。具体来说，你可以在GPU上期待良好的性能，尤其是在以下方面：
- en: Instructor note
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: 10 min teaching
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10分钟教学
- en: 10 min exercises
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自[Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing)的回答：
- en: What are GPUs good for?
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU擅长什么？
- en: 'Answer from [Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 感受GPU擅长用例的类型。
- en: '*From a metaphorical point of view, the GPU can be seen as a person lying on
    a bed of nails. The person lying on top is the data and in the base of each nail
    there is a processor, so the nail is actually an arrow pointing from processor
    to memory. All nails are in a regular pattern, like a grid. If the body is well
    spread, it feels good (performance is good), if the body only touches some spots
    of the nail bed, then the pain is bad (bad performance).*'
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*从比喻的角度来看，GPU可以被视为躺在钉床上的一个人。躺在上面的是数据，每个钉子的底部都有一个处理器，因此钉子实际上是从处理器指向内存的箭头。所有钉子都呈规则图案，就像一个网格。如果身体分布均匀，感觉良好（性能良好），如果身体只接触钉床的某些部位，那么疼痛就不好（性能差）。*'
- en: 'GPU computing is well-suited to problems that involve large amounts of data
    parallelism. Specifically, you can expect good performance on GPUs for:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有编程问题都能有效地利用GPU提供的并行性。不适合在GPU上运行的问题类型包括：
- en: '**Large-scale matrix and vector operations**: Common in machine learning, scientific
    computing, and image processing.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大规模矩阵和向量运算**：在机器学习、科学计算和图像处理中常见。'
- en: '**Fourier transforms**: Also common in machine learning, scientific computing,
    and image processing.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**傅里叶变换**：在机器学习、科学计算和图像处理中也常见。'
- en: '**Monte Carlo simulations**: Used across finance, physics, and other fields
    to simulate complex systems.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蒙特卡洛模拟**：在金融、物理和其他领域用于模拟复杂系统。'
- en: '**Molecular dynamics simulations**: Used in chemistry, biochemistry and physics.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分子动力学模拟**：用于化学、生物化学和物理学。'
- en: '**Computational fluid dynamics**: Used in engineering, physics, and other fields.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序任务**：需要一系列依赖步骤的问题，其中每个步骤依赖于前一个步骤的结果，不适合并行处理。例如，递归算法、某些动态规划问题以及一些图遍历算法。'
- en: '**Convolutional neural networks** and **computer vision algorithms**.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**和**计算机视觉算法**。'
- en: '**Big data analytics**: Clustering, classification, regression, etc.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教师备注
- en: '**Graphics rendering**: Original use-case for GPUs.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么GPU在机器学习应用中如此普遍？
- en: What are GPUs not good for?
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU不擅长什么？
- en: 'Not all programming problems can efficiently leverage the parallelism offered
    by GPUs. Some types of problems that do not fit well on a GPU include:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**图形渲染**：GPU的原始用例。'
- en: '**Sequential tasks**: Problems that require a series of dependent steps, where
    each step relies on the outcome of the previous step, are not well-suited for
    parallel processing. Examples include recursive algorithms, certain dynamic programming
    problems, and some graph traversal algorithms.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10分钟练习
- en: '**Fine-grained branching**: GPUs perform best when the code being executed
    across different threads follows a similar control flow. When there is extensive
    branching (i.e., many `if` statements) within a kernel or algorithm, performance
    may suffer due to the divergence in execution paths among the GPU threads.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度分支**：当跨不同线程执行的代码遵循相似的控制流时，GPU表现最佳。当内核或算法中有大量的分支（即许多`if`语句）时，由于GPU线程执行路径的分歧，性能可能会受到影响。'
- en: '**Low arithmetic intensity**: GPUs excel at performing a large number of mathematical
    operations quickly. If a problem has low arithmetic intensity (i.e., a low ratio
    of arithmetic operations to memory accesses), the GPU may not be able to efficiently
    utilize its computational power, leading to underperformance.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低算术强度**：GPU在快速执行大量数学运算方面表现出色。如果一个问题的算术强度低（即算术运算与内存访问的比率低），GPU可能无法有效地利用其计算能力，导致性能不佳。'
- en: '**Small data sets**: If the problem involves a small data set that does not
    require significant parallelism, using a GPU may not result in noticeable performance
    gains. In such cases, the overhead of transferring data between the CPU and GPU,
    and the time spent initializing the GPU, may outweigh any potential benefits.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小数据集**：如果一个问题涉及的小数据集不需要显著的并行性，使用GPU可能不会带来明显的性能提升。在这种情况下，CPU和GPU之间传输数据的开销以及初始化GPU所花费的时间可能会超过任何潜在的好处。'
- en: '**Limited parallelism**: Some algorithms have inherent limitations on the degree
    of parallelism that can be achieved. In these cases, using a GPU may not lead
    to significant performance improvements.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的并行性**：一些算法在可实现的并行度上存在固有的限制。在这些情况下，使用GPU可能不会导致显著的性能提升。'
- en: '**Memory-bound problems**: GPUs generally have less memory available compared
    to CPUs, and their memory bandwidth can be a limiting factor. If a problem requires
    a large amount of memory or involves memory-intensive operations, it may not be
    well-suited for a GPU.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存绑定问题**：与CPU相比，GPU通常可用的内存较少，其内存带宽可能成为限制因素。如果一个问题需要大量内存或涉及内存密集型操作，它可能不适合GPU。'
- en: Examples of GPU acceleration
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU加速的示例
- en: To give a flavor of what type of performance gains we can achieve by porting
    a calculations to a GPU (if we’re lucky!), let’s look at a few case examples.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示将计算移植到GPU（如果幸运的话）可以实现的性能提升，让我们看看几个案例示例。
- en: Effect of array size
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数组大小的影响
- en: 'Consider the case of matrix multiplication in the Julia language:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑Julia语言中矩阵乘法的例子：
- en: '[PRE1]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How much faster do you think the GPU version is compared to running on a single
    CPU core?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你认为GPU版本相比单核CPU运行要快多少？
- en: Julia automatically parallelises matrix multiplication over available CPU cores.
    Will the GPU version be faster than running on 64 cores?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Julia会自动并行化矩阵乘法，在可用的CPU核心上。GPU版本会比在64个核心上运行快吗？
- en: Does the size of the array affect how much the performance improves?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数组的大小会影响性能提升多少吗？
- en: Solution
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Example results from running on LUMI (MI250X AMD GPU, 64-core AMD Trento CPUs):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: LUMI（MI250X AMD GPU，64核AMD Trento CPU）运行示例结果：
- en: GPU acceleration for matrix multiply in Julia
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Julia中矩阵乘法的GPU加速
- en: '| Matrix size | 1 CPU core | 64 CPU cores | 1 GPU | GPU speedup |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 矩阵大小 | 1 CPU核心 | 64 CPU核心 | 1 GPU | GPU加速比 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
- en: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
- en: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
- en: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
- en: Electronic structure calculations
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 电子结构计算
- en: '[VASP](https://www.vasp.at/) is a popular software package used for electronic
    structure calculations. The figures below show the speedup observed in a recent
    benchmark study on the [VASP Power Profiles on NVIDIA A100 GPUs](https://ieeexplore.ieee.org/document/10820603),
    which was conducted on the Perlmutter system at NERSC. An analysis of total energy
    usage demonstrated that VASP’s power usage varies significantly with different
    workloads, more so than with parallel concurrency. Additionally, power capping
    GPUs to 50% of their Thermal Design Power can be applied to most VASP workloads
    with less than a 10% performance loss.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[VASP](https://www.vasp.at/) 是一个用于电子结构计算的流行软件包。下面的图示显示了在NERSC的Perlmutter系统上进行的[VASP在NVIDIA
    A100 GPU上的功率配置文件基准测试](https://ieeexplore.ieee.org/document/10820603)中观察到的加速效果。该分析展示了总能耗，表明VASP的功耗随着不同工作负载的变化而显著变化，比并行并发的变化更大。此外，将GPU的功耗限制在热设计功耗的50%以下，可以应用于大多数VASP工作负载，而性能损失不到10%。'
- en: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
- en: Parallel efficiency of VASP on seven test cases representing diverse VASP production
    workloads and ensuring a comprehensive coverage of various code paths, elements,
    and problem sizes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: VASP在七个代表不同VASP生产工作负载的测试案例上的并行效率，确保对各种代码路径、元素和问题规模的全面覆盖。
- en: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)]'
- en: '(Left) Power usage of seven representative VASP workloads. The horizontal axis
    shows number of nodes used, and vertical axis shows high power mode per node.
    (Right) Power consumed per GPU when running VASP under four different power caps:
    400 W (default), 300 W, 200 W, and 100 W. Horizontal axis shows power caps applied
    to GPUs, and vertical axis shows high power mode per GPU as a fraction of applied
    cap. The dashed horizontal line represents applied power cap. Each benchmark was
    run with a node count optimizing runtime while remaining above 70% parallel efficiency.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: （左）七个代表性VASP工作负载的功耗。水平轴表示使用的节点数，垂直轴表示每个节点的最大功率模式。 （右）在四种不同的功率限制下运行VASP时的功耗：400
    W（默认）、300 W、200 W和100 W。水平轴表示施加到GPU上的功率限制，垂直轴表示每个GPU的最大功率模式占应用功率限制的比例。虚线水平线表示应用的功率限制。每个基准测试都是在优化运行时间的同时，保持超过70%的并行效率的情况下运行的。
- en: Computational Chemistry
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算化学
- en: 'A great deal of computational resources are spent in Quantum Chemical calculations
    which involve the solution of the Hartree-Fock eigenvalue problem, which requires
    the diagonalization of the Fock matrix whose elements are given by:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子化学计算中，大量计算资源被用于解决哈特里-福克特征值问题，这需要求解福克矩阵的对角化，其元素由以下给出：
- en: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
- en: 'The first term is related to the one electron contributions and the second
    term is related to the electron repulsion integrals (ERIs), in parenthesis, weighted
    by the by the density matrix \(D_{\gamma \delta}\). One of the most expensive
    parts in the solution of the Hartree-Fock equations is the processing (digestion)
    of the ERIs, one algorithm to do this task is as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 第一项与单电子贡献相关，第二项与电子排斥积分（ERIs）相关（括号内），由密度矩阵 \(D_{\gamma \delta}\) 加权。在哈特里-福克方程的求解中，最昂贵的部分之一是ERIs的处理（消化），以下是一个执行此任务的算法：
- en: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
- en: Algorithm for processing ERIs [see [JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)
    for details]
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 处理ERIs的算法[详见[JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)获取详细信息]
- en: This algorithm is suitable for GPUs as it involves many arithmetic operations.
    In addition to this, there are symmetries and properties of the integrals that
    could be used to rearrange the loops in an efficient manner that fit GPU architectures.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法适合GPU，因为它涉及许多算术运算。此外，还有积分的对称性和性质，可以用来以高效的方式重新排列循环，以适应GPU架构。
- en: Humanities
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人文科学
- en: A brief introduction into some of the work that is being done in the humanities
    that can benefit from utilizing GPUs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 简要介绍一些可以利用GPU受益的人文领域正在进行的工作。
- en: '**Language models and NLP (natural language processing)**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言模型和NLP（自然语言处理**）'
- en: With the recent popularity of ChatGPT, the use of language models has come into
    the mainstream, however such models have been used in the humanities many years
    already. One of the biggest goals of humanities researchers is working with textual
    data which has increased exponentially over recent years due to the rise in social
    media. Analyzing such textual data to gain insights into questions of sociology,
    linguistics and various other fields have become increasingly reliant on using
    language models. Along with language models, the need for GPU access has become
    essential.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT的近期流行，语言模型的使用已经进入主流，然而这类模型在人文领域已经使用了多年。人文研究人员最大的目标之一是与近年来由于社交媒体的兴起而呈指数增长的文本数据合作。分析此类文本数据以深入了解社会学、语言学和其他领域的相关问题，越来越依赖于使用语言模型。随着语言模型的使用，对GPU访问的需求也变得至关重要。
- en: '**Archeology**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**考古学**'
- en: The field of archeology also makes use of GPUs in their 3D modelling and rendering
    work. The biggest problem with archeological sites is that once they are excavated,
    they are destroyed, so any researchers who aren’t present at the site, would lose
    valuable insights into how it looked when it was found. However, with recent developments
    in technology and accessibility to high-performance computing, they are able to
    generate extremely detailed renderings of the excavation sites which act as a
    way to preserve the site for future researchers to gain critical insights and
    contribute to the research.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 考古学领域也利用GPU进行3D建模和渲染工作。考古遗址的最大问题是，一旦被挖掘，它们就会被破坏，因此任何不在现场的研究人员都会失去对遗址发现时外观的宝贵洞察。然而，随着技术和高性能计算的可访问性最近的发展，他们能够生成极其详细的挖掘遗址渲染图，这可以作为保存遗址的一种方式，以便未来的研究人员获得关键的洞察并贡献于研究。
- en: '**Cognitive Science**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**认知科学**'
- en: Techniques such as Markov Chain Monte Carlo (MCMC) sampling have proven to be
    invaluable in studies that delve into human behavior or population dynamics. MCMC
    sampling allows researchers to simulate and analyze complex systems by iteratively
    sampling from a Markov chain, enabling the exploration of high-dimensional parameter
    spaces. This method is particularly useful when studying human behavior, as it
    can capture the inherent randomness and interdependencies that characterize social
    systems. By leveraging MCMC sampling, researchers can gain insights into various
    aspects of human behavior, such as decision-making, social interactions, and the
    spread of information or diseases within populations.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如马尔可夫链蒙特卡洛（MCMC）采样等技术的证明在深入研究人类行为或种群动态的研究中非常有价值。MCMC采样允许研究人员通过迭代地从马尔可夫链中采样来模拟和分析复杂系统，从而探索高维参数空间。这种方法在研究人类行为时特别有用，因为它可以捕捉到表征社会系统的固有随机性和相互依赖性。通过利用MCMC采样，研究人员可以深入了解人类行为的各个方面，如决策、社会互动以及信息或疾病在人群中的传播。
- en: By offloading the computational workload to GPUs, researchers can experience
    substantial speedup in the execution of MCMC algorithms. This speedup allows for
    more extensive exploration of parameter spaces and facilitates the analysis of
    larger datasets, leading to more accurate and detailed insights into human behavior
    or population dynamics. Examples of studies done using these methods can be found
    at the [Center for Humanities Computing Aarhus](https://chc.au.dk/) (CHCAA) and
    [Interacting Minds Centre](https://interactingminds.au.dk/) (IMC) at Aarhus University.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将计算工作负载卸载到GPU上，研究人员可以在MCMC算法的执行中体验到显著的加速。这种加速允许更广泛地探索参数空间，并促进对更大数据集的分析，从而对人类行为或种群动态有更准确和详细的洞察。使用这些方法进行的研究的例子可以在[人文计算中心奥尔胡斯](https://chc.au.dk/)（CHCAA）和[互动心智中心](https://interactingminds.au.dk/)（IMC）的奥尔胡斯大学找到。
- en: Exercises
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Discussion
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论
- en: What type of problems have you used GPUs for?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用GPU解决了哪些类型的问题？
- en: How large was the performance boost?
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能提升有多大？
- en: Good and bad use cases for GPU porting
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: GPU迁移的优缺点案例
- en: Which of the following computational tasks is likely to gain the least performance
    benefit from being ported to a GPU?
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个计算任务在迁移到GPU后可能获得的最小性能提升？
- en: Training a large, deep neural network.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练大型、深度神经网络。
- en: Performing a Monte Carlo simulation with a large number of independent trials.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用大量独立试验进行蒙特卡洛模拟。
- en: Executing an algorithm with heavy use of recursion and frequent branching.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行大量递归和频繁分支的算法。
- en: Processing a large image with a convolutional filter.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用卷积滤波器处理大型图像。
- en: Solution
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: The right answer is option 3\. GPUs do not handle recursion and branching as
    effectively as more data-heavy algorithms.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是选项3。GPU处理递归和分支不如数据密集型算法有效。
- en: Keypoints
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs excel in processing tasks with high data parallelism, such as large-scale
    matrix operations, Fourier transforms, and big data analytics.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理具有高数据并行性的任务方面表现出色，例如大规模矩阵运算、傅里叶变换和大数据分析。
- en: GPUs struggle with sequential tasks, problems with extensive control flow divergence,
    low arithmetic intensity tasks, small data sets, and memory-bound problems.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理顺序任务、存在大量控制流分支的问题、算术强度低的任务、小数据集和内存绑定问题方面存在困难。
- en: What are GPUs good for?
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU擅长做什么？
- en: 'Answer from [Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [Stack Exchange](https://scicomp.stackexchange.com/questions/943/what-kinds-of-problems-lend-themselves-well-to-gpu-computing)
    的回答：
- en: '*From a metaphorical point of view, the GPU can be seen as a person lying on
    a bed of nails. The person lying on top is the data and in the base of each nail
    there is a processor, so the nail is actually an arrow pointing from processor
    to memory. All nails are in a regular pattern, like a grid. If the body is well
    spread, it feels good (performance is good), if the body only touches some spots
    of the nail bed, then the pain is bad (bad performance).*'
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*从比喻的角度来看，GPU 可以被看作是一个躺在钉床上的一个人。躺在上面的是数据，每个钉子的底部都有一个处理器，所以钉子实际上是从处理器指向内存的箭头。所有的钉子都呈规则排列，就像一个网格。如果身体分布得很好，感觉会很好（性能良好），如果身体只接触钉床的某些部位，那么疼痛就会很糟糕（性能不佳）。*'
- en: 'GPU computing is well-suited to problems that involve large amounts of data
    parallelism. Specifically, you can expect good performance on GPUs for:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 计算非常适合涉及大量数据并行的问题。具体来说，你可以在 GPU 上期待良好的性能，特别是对于：
- en: '**Large-scale matrix and vector operations**: Common in machine learning, scientific
    computing, and image processing.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大规模矩阵和向量运算**：在机器学习、科学计算和图像处理中很常见。'
- en: '**Fourier transforms**: Also common in machine learning, scientific computing,
    and image processing.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**傅里叶变换**：在机器学习、科学计算和图像处理中也很常见。'
- en: '**Monte Carlo simulations**: Used across finance, physics, and other fields
    to simulate complex systems.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蒙特卡洛模拟**：在金融、物理和其他领域用于模拟复杂系统。'
- en: '**Molecular dynamics simulations**: Used in chemistry, biochemistry and physics.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分子动力学模拟**：在化学、生物化学和物理学中使用。'
- en: '**Computational fluid dynamics**: Used in engineering, physics, and other fields.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算流体动力学**：在工程、物理和其他领域使用。'
- en: '**Convolutional neural networks** and **computer vision algorithms**.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**和**计算机视觉算法**。'
- en: '**Big data analytics**: Clustering, classification, regression, etc.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据分析**：聚类、分类、回归等。'
- en: '**Graphics rendering**: Original use-case for GPUs.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形渲染**：GPU 的原始用例。'
- en: What are GPUs not good for?
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 不擅长什么？
- en: 'Not all programming problems can efficiently leverage the parallelism offered
    by GPUs. Some types of problems that do not fit well on a GPU include:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有编程问题都能有效地利用 GPU 提供的并行性。一些不适合 GPU 的问题类型包括：
- en: '**Sequential tasks**: Problems that require a series of dependent steps, where
    each step relies on the outcome of the previous step, are not well-suited for
    parallel processing. Examples include recursive algorithms, certain dynamic programming
    problems, and some graph traversal algorithms.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序任务**：需要一系列依赖步骤的问题，其中每个步骤依赖于前一个步骤的结果，不适合并行处理。例如，递归算法、某些动态规划问题和一些图遍历算法。'
- en: '**Fine-grained branching**: GPUs perform best when the code being executed
    across different threads follows a similar control flow. When there is extensive
    branching (i.e., many `if` statements) within a kernel or algorithm, performance
    may suffer due to the divergence in execution paths among the GPU threads.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度分支**：当跨不同线程执行的代码遵循相似的控制流时，GPU 表现最佳。当内核或算法中有广泛的分支（即许多 `if` 语句）时，由于 GPU
    线程执行路径的分歧，性能可能会受到影响。'
- en: '**Low arithmetic intensity**: GPUs excel at performing a large number of mathematical
    operations quickly. If a problem has low arithmetic intensity (i.e., a low ratio
    of arithmetic operations to memory accesses), the GPU may not be able to efficiently
    utilize its computational power, leading to underperformance.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低算术强度**：GPU 擅长快速执行大量数学运算。如果问题具有低算术强度（即算术运算与内存访问的比率低），GPU 可能无法有效地利用其计算能力，导致性能不佳。'
- en: '**Small data sets**: If the problem involves a small data set that does not
    require significant parallelism, using a GPU may not result in noticeable performance
    gains. In such cases, the overhead of transferring data between the CPU and GPU,
    and the time spent initializing the GPU, may outweigh any potential benefits.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小数据集**：如果问题涉及小数据集且不需要显著的并行性，使用 GPU 可能不会带来明显的性能提升。在这种情况下，CPU 和 GPU 之间传输数据的开销以及初始化
    GPU 的时间可能会超过任何潜在的好处。'
- en: '**Limited parallelism**: Some algorithms have inherent limitations on the degree
    of parallelism that can be achieved. In these cases, using a GPU may not lead
    to significant performance improvements.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的并行性**：一些算法在可实现的并行程度上有固有的限制。在这些情况下，使用 GPU 可能不会导致显著的性能提升。'
- en: '**Memory-bound problems**: GPUs generally have less memory available compared
    to CPUs, and their memory bandwidth can be a limiting factor. If a problem requires
    a large amount of memory or involves memory-intensive operations, it may not be
    well-suited for a GPU.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存受限问题**：与 CPU 相比，GPU 通常具有更少的内存可用，其内存带宽可能成为限制因素。如果一个问题需要大量的内存或涉及内存密集型操作，它可能不适合
    GPU。'
- en: Examples of GPU acceleration
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU 加速的例子
- en: To give a flavor of what type of performance gains we can achieve by porting
    a calculations to a GPU (if we’re lucky!), let’s look at a few case examples.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示将计算移植到 GPU 上可能获得的性能提升（如果幸运的话），让我们看看几个案例示例。
- en: Effect of array size
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数组大小的影响
- en: 'Consider the case of matrix multiplication in the Julia language:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑 Julia 语言中矩阵乘法的例子：
- en: '[PRE2]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How much faster do you think the GPU version is compared to running on a single
    CPU core?
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你认为 GPU 版本与单核 CPU 运行相比快多少？
- en: Julia automatically parallelises matrix multiplication over available CPU cores.
    Will the GPU version be faster than running on 64 cores?
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Julia 会自动并行化矩阵乘法，以利用可用的 CPU 核心。GPU 版本会比在 64 核上运行快吗？
- en: Does the size of the array affect how much the performance improves?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数组的大小是否会影响性能提升的程度？
- en: Solution
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Example results from running on LUMI (MI250X AMD GPU, 64-core AMD Trento CPUs):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LUMI（MI250X AMD GPU，64 核 AMD Trento CPU）上运行的结果示例：
- en: GPU acceleration for matrix multiply in Julia
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Julia 中矩阵乘法的 GPU 加速
- en: '| Matrix size | 1 CPU core | 64 CPU cores | 1 GPU | GPU speedup |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 矩阵大小 | 1 CPU 核心 | 64 CPU 核心 | 1 GPU | GPU 加速比 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| (512, 512) | 5.472 ms | 517.722 μs | 115.805 μs | ~47x / ~5x |'
- en: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| (1024, 1024) | 43.364 ms | 2.929 ms | 173.316 μs | ~250x / ~17x |'
- en: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| (2048, 2048) | 344.364 ms | 30.081 ms | 866.348 μs | ~400x / ~35x |'
- en: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| (4096, 4096) | 3.221 s | 159.563 ms | 5.910 ms | ~550x / ~27x |'
- en: Electronic structure calculations
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 电子结构计算
- en: '[VASP](https://www.vasp.at/) is a popular software package used for electronic
    structure calculations. The figures below show the speedup observed in a recent
    benchmark study on the [VASP Power Profiles on NVIDIA A100 GPUs](https://ieeexplore.ieee.org/document/10820603),
    which was conducted on the Perlmutter system at NERSC. An analysis of total energy
    usage demonstrated that VASP’s power usage varies significantly with different
    workloads, more so than with parallel concurrency. Additionally, power capping
    GPUs to 50% of their Thermal Design Power can be applied to most VASP workloads
    with less than a 10% performance loss.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[VASP](https://www.vasp.at/) 是一种流行的软件包，用于电子结构计算。下图展示了在 NERSC 的 Perlmutter 系统上进行的
    [VASP 在 NVIDIA A100 GPU 上的功率配置文件基准测试](https://ieeexplore.ieee.org/document/10820603)中观察到的加速效果，该测试涵盖了各种代码路径、元素和问题规模。分析总能耗表明，VASP
    的功耗随着不同工作负载的变化而显著变化，比并行并发的变化更大。此外，将 GPU 的功耗限制在其热设计功耗的 50% 可以应用于大多数 VASP 工作负载，而性能损失不到
    10%。'
- en: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
- en: Parallel efficiency of VASP on seven test cases representing diverse VASP production
    workloads and ensuring a comprehensive coverage of various code paths, elements,
    and problem sizes.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: VASP 在七个测试案例上的并行效率，这些测试案例代表了多样化的 VASP 生产工作负载，并确保了对各种代码路径、元素和问题规模的全面覆盖。
- en: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
- en: '(Left) Power usage of seven representative VASP workloads. The horizontal axis
    shows number of nodes used, and vertical axis shows high power mode per node.
    (Right) Power consumed per GPU when running VASP under four different power caps:
    400 W (default), 300 W, 200 W, and 100 W. Horizontal axis shows power caps applied
    to GPUs, and vertical axis shows high power mode per GPU as a fraction of applied
    cap. The dashed horizontal line represents applied power cap. Each benchmark was
    run with a node count optimizing runtime while remaining above 70% parallel efficiency.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: （左）七个代表性VASP工作负载的功耗。水平轴表示使用的节点数，垂直轴表示每个节点的最大功率模式。 （右）在四种不同的功率限制下运行VASP时的GPU功耗：400
    W（默认）、300 W、200 W和100 W。水平轴表示施加到GPU上的功率限制，垂直轴表示每个GPU的高功率模式占应用功率限制的比例。虚线水平线表示应用的功率限制。每个基准测试都是在优化运行时间的同时，保持超过70%的并行效率的情况下运行的节点数。
- en: Computational Chemistry
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算化学
- en: 'A great deal of computational resources are spent in Quantum Chemical calculations
    which involve the solution of the Hartree-Fock eigenvalue problem, which requires
    the diagonalization of the Fock matrix whose elements are given by:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子化学计算中，大量的计算资源被用于解决哈特里-福克特征值问题，这需要将福克矩阵对角化，其元素如下：
- en: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
- en: 'The first term is related to the one electron contributions and the second
    term is related to the electron repulsion integrals (ERIs), in parenthesis, weighted
    by the by the density matrix \(D_{\gamma \delta}\). One of the most expensive
    parts in the solution of the Hartree-Fock equations is the processing (digestion)
    of the ERIs, one algorithm to do this task is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项与单电子贡献相关，第二个项与电子排斥积分（ERIs）相关，括号内由密度矩阵 \(D_{\gamma \delta}\) 加权。在哈特里-福克方程的求解过程中，最昂贵的部分之一是处理（消化）ERIs，完成这一任务的算法如下：
- en: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
- en: Algorithm for processing ERIs [see [JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)
    for details]
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 处理ERIs的算法[详见[JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)的详细信息]
- en: This algorithm is suitable for GPUs as it involves many arithmetic operations.
    In addition to this, there are symmetries and properties of the integrals that
    could be used to rearrange the loops in an efficient manner that fit GPU architectures.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法适合GPU，因为它涉及许多算术运算。此外，积分的对称性和性质可以用来以高效的方式重新排列循环，以适应GPU架构。
- en: Humanities
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人文学科
- en: A brief introduction into some of the work that is being done in the humanities
    that can benefit from utilizing GPUs.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 对人文学科中可以利用GPU进行的一些研究工作的简要介绍。
- en: '**Language models and NLP (natural language processing)**'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言模型和NLP（自然语言处理**）'
- en: With the recent popularity of ChatGPT, the use of language models has come into
    the mainstream, however such models have been used in the humanities many years
    already. One of the biggest goals of humanities researchers is working with textual
    data which has increased exponentially over recent years due to the rise in social
    media. Analyzing such textual data to gain insights into questions of sociology,
    linguistics and various other fields have become increasingly reliant on using
    language models. Along with language models, the need for GPU access has become
    essential.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT的近期流行，语言模型的使用已经进入主流，然而这些模型在许多年前就已经被应用于人文学科。人文学者最大的目标之一是与近年来由于社交媒体的兴起而呈指数增长的文本数据合作。分析此类文本数据以获得对社会学、语言学以及各个其他领域问题的洞察，越来越依赖于使用语言模型。随着语言模型的使用，对GPU访问的需求也变得至关重要。
- en: '**Archeology**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**考古学**'
- en: The field of archeology also makes use of GPUs in their 3D modelling and rendering
    work. The biggest problem with archeological sites is that once they are excavated,
    they are destroyed, so any researchers who aren’t present at the site, would lose
    valuable insights into how it looked when it was found. However, with recent developments
    in technology and accessibility to high-performance computing, they are able to
    generate extremely detailed renderings of the excavation sites which act as a
    way to preserve the site for future researchers to gain critical insights and
    contribute to the research.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 考古学领域也利用 GPU 进行 3D 建模和渲染工作。考古遗址的最大问题是，一旦被挖掘，它们就会被破坏，因此任何不在现场的研究人员都会失去对遗址发现时外观的宝贵见解。然而，随着技术和高性能计算的可访问性最近的发展，他们能够生成极其详细的挖掘遗址渲染图，这可以作为保存遗址的一种方式，以便未来的研究人员获得关键见解并贡献于研究。
- en: '**Cognitive Science**'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '**认知科学**'
- en: Techniques such as Markov Chain Monte Carlo (MCMC) sampling have proven to be
    invaluable in studies that delve into human behavior or population dynamics. MCMC
    sampling allows researchers to simulate and analyze complex systems by iteratively
    sampling from a Markov chain, enabling the exploration of high-dimensional parameter
    spaces. This method is particularly useful when studying human behavior, as it
    can capture the inherent randomness and interdependencies that characterize social
    systems. By leveraging MCMC sampling, researchers can gain insights into various
    aspects of human behavior, such as decision-making, social interactions, and the
    spread of information or diseases within populations.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 像马尔可夫链蒙特卡洛（MCMC）采样这样的技术已被证明在深入研究人类行为或种群动态的研究中非常有价值。MCMC 采样允许研究人员通过迭代地从马尔可夫链中采样来模拟和分析复杂系统，从而探索高维参数空间。这种方法在研究人类行为时尤其有用，因为它可以捕捉到表征社会系统的固有随机性和相互依赖性。通过利用
    MCMC 采样，研究人员可以深入了解人类行为的各个方面，如决策、社会互动以及信息或疾病在人群中的传播。
- en: By offloading the computational workload to GPUs, researchers can experience
    substantial speedup in the execution of MCMC algorithms. This speedup allows for
    more extensive exploration of parameter spaces and facilitates the analysis of
    larger datasets, leading to more accurate and detailed insights into human behavior
    or population dynamics. Examples of studies done using these methods can be found
    at the [Center for Humanities Computing Aarhus](https://chc.au.dk/) (CHCAA) and
    [Interacting Minds Centre](https://interactingminds.au.dk/) (IMC) at Aarhus University.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将计算工作负载卸载到 GPU 上，研究人员可以在 MCMC 算法的执行中体验到显著的加速。这种加速允许更广泛地探索参数空间，并促进对更大数据集的分析，从而更准确、更详细地了解人类行为或种群动态。使用这些方法进行的案例研究可以在
    [Aarhus 大学的人文计算中心](https://chc.au.dk/)（CHCAA）和 [交互式心智中心](https://interactingminds.au.dk/)（IMC）找到。
- en: Electronic structure calculations
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 电子结构计算
- en: '[VASP](https://www.vasp.at/) is a popular software package used for electronic
    structure calculations. The figures below show the speedup observed in a recent
    benchmark study on the [VASP Power Profiles on NVIDIA A100 GPUs](https://ieeexplore.ieee.org/document/10820603),
    which was conducted on the Perlmutter system at NERSC. An analysis of total energy
    usage demonstrated that VASP’s power usage varies significantly with different
    workloads, more so than with parallel concurrency. Additionally, power capping
    GPUs to 50% of their Thermal Design Power can be applied to most VASP workloads
    with less than a 10% performance loss.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[VASP](https://www.vasp.at/) 是一种流行的软件包，用于电子结构计算。下方的图表展示了在最近的一项基准研究中的加速效果，该研究针对的是
    [NVIDIA A100 GPU 上的 VASP 功率配置文件](https://ieeexplore.ieee.org/document/10820603)，研究是在
    NERSC 的 Perlmutter 系统上进行的。对总能量使用的分析表明，VASP 的功耗随着不同工作负载的变化而显著不同，比并行并发的变化更大。此外，将
    GPU 的功耗限制在其热设计功耗的 50% 可以应用于大多数 VASP 工作负载，而性能损失不到 10%。'
- en: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_parallel_efficiency.png](../Images/0b6eaaa4ff02027d294385d1f2cbaf8a.png)'
- en: Parallel efficiency of VASP on seven test cases representing diverse VASP production
    workloads and ensuring a comprehensive coverage of various code paths, elements,
    and problem sizes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在代表多样化的 VASP 生产工作负载的七个测试案例中，VASP 的并行效率确保了对各种代码路径、元素和问题规模的全面覆盖。
- en: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/vasp_energy_consumption.jpg](../Images/6fa5e8533100766ad3399b8e454b4d19.png)'
- en: '(Left) Power usage of seven representative VASP workloads. The horizontal axis
    shows number of nodes used, and vertical axis shows high power mode per node.
    (Right) Power consumed per GPU when running VASP under four different power caps:
    400 W (default), 300 W, 200 W, and 100 W. Horizontal axis shows power caps applied
    to GPUs, and vertical axis shows high power mode per GPU as a fraction of applied
    cap. The dashed horizontal line represents applied power cap. Each benchmark was
    run with a node count optimizing runtime while remaining above 70% parallel efficiency.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: （左）七个代表性VASP工作负载的功耗。水平轴表示使用的节点数，垂直轴表示每个节点的峰值功率。 （右）在四种不同的功率限制下运行VASP时的GPU功耗：400
    W（默认）、300 W、200 W和100 W。水平轴表示施加到GPU上的功率限制，垂直轴表示每个GPU的峰值功率占应用功率限制的比例。虚线水平线表示应用的功率限制。每个基准测试都在优化运行时间的同时保持超过70%的并行效率。
- en: Computational Chemistry
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算化学
- en: 'A great deal of computational resources are spent in Quantum Chemical calculations
    which involve the solution of the Hartree-Fock eigenvalue problem, which requires
    the diagonalization of the Fock matrix whose elements are given by:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子化学计算中，大量的计算资源被用于解决哈特里-福克特征值问题，这需要将福克矩阵对角化，其元素由以下公式给出：
- en: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \[F_{\alpha \beta} = H^{\textrm{core}}_{\alpha \beta} + \sum_{\gamma \delta}D_{\gamma
    \delta} \left [ (\alpha \beta|\gamma \delta) - \frac{1}{2} (\alpha \delta|\gamma
    \beta) \right ],\]
- en: 'The first term is related to the one electron contributions and the second
    term is related to the electron repulsion integrals (ERIs), in parenthesis, weighted
    by the by the density matrix \(D_{\gamma \delta}\). One of the most expensive
    parts in the solution of the Hartree-Fock equations is the processing (digestion)
    of the ERIs, one algorithm to do this task is as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 第一项与单电子贡献相关，第二项与电子排斥积分（ERIs）相关，括号内由密度矩阵 \(D_{\gamma \delta}\) 加权。在解决哈特里-福克方程中，最昂贵的部分之一是处理（消化）ERIs，完成这一任务的算法如下：
- en: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/algorithms.svg](../Images/8315333e7eb919a0358c1a5aad382eaf.png)](../_images/algorithms.svg)'
- en: Algorithm for processing ERIs [see [JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)
    for details]
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 处理ERIs的算法[详情见[JCTC, 17, 7486, (2021)](https://doi.org/10.1021/acs.jctc.1c00720)]
- en: This algorithm is suitable for GPUs as it involves many arithmetic operations.
    In addition to this, there are symmetries and properties of the integrals that
    could be used to rearrange the loops in an efficient manner that fit GPU architectures.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法适合GPU，因为它涉及大量的算术运算。此外，积分的对称性和性质可以用来以高效的方式重新排列循环，以适应GPU架构。
- en: Humanities
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人文学科
- en: A brief introduction into some of the work that is being done in the humanities
    that can benefit from utilizing GPUs.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 简要介绍一些可以利用GPU进行的人文学科研究工作。
- en: '**Language models and NLP (natural language processing)**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言模型和NLP（自然语言处理**）'
- en: With the recent popularity of ChatGPT, the use of language models has come into
    the mainstream, however such models have been used in the humanities many years
    already. One of the biggest goals of humanities researchers is working with textual
    data which has increased exponentially over recent years due to the rise in social
    media. Analyzing such textual data to gain insights into questions of sociology,
    linguistics and various other fields have become increasingly reliant on using
    language models. Along with language models, the need for GPU access has become
    essential.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT的近期流行，语言模型的使用已经进入主流，然而这些模型在许多年前就已经被应用于人文学科。人文学科研究人员最大的目标之一是与近年来由于社交媒体的兴起而呈指数增长的文本数据合作。分析此类文本数据以获得对社会学、语言学以及各个其他领域的见解，越来越依赖于使用语言模型。与语言模型一样，对GPU访问的需求已成为必需。
- en: '**Archeology**'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**考古学**'
- en: The field of archeology also makes use of GPUs in their 3D modelling and rendering
    work. The biggest problem with archeological sites is that once they are excavated,
    they are destroyed, so any researchers who aren’t present at the site, would lose
    valuable insights into how it looked when it was found. However, with recent developments
    in technology and accessibility to high-performance computing, they are able to
    generate extremely detailed renderings of the excavation sites which act as a
    way to preserve the site for future researchers to gain critical insights and
    contribute to the research.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 考古学领域也利用GPU进行3D建模和渲染工作。考古遗址的最大问题是，一旦被挖掘，它们就会被破坏，因此任何不在现场的研究人员都会失去对遗址发现时外观的宝贵洞察。然而，随着技术和高性能计算的可访问性最近的发展，他们能够生成极其详细的挖掘遗址渲染图，这可以作为保存遗址的一种方式，以便未来的研究人员获得关键的洞察并贡献于研究。
- en: '**Cognitive Science**'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**认知科学**'
- en: Techniques such as Markov Chain Monte Carlo (MCMC) sampling have proven to be
    invaluable in studies that delve into human behavior or population dynamics. MCMC
    sampling allows researchers to simulate and analyze complex systems by iteratively
    sampling from a Markov chain, enabling the exploration of high-dimensional parameter
    spaces. This method is particularly useful when studying human behavior, as it
    can capture the inherent randomness and interdependencies that characterize social
    systems. By leveraging MCMC sampling, researchers can gain insights into various
    aspects of human behavior, such as decision-making, social interactions, and the
    spread of information or diseases within populations.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，马尔可夫链蒙特卡洛（MCMC）采样等技术已被证明在深入研究人类行为或种群动态的研究中非常有价值。MCMC采样允许研究人员通过迭代地从马尔可夫链中采样来模拟和分析复杂系统，从而探索高维参数空间。这种方法在研究人类行为时特别有用，因为它可以捕捉到表征社会系统的内在随机性和相互依赖性。通过利用MCMC采样，研究人员可以深入了解人类行为的各个方面，如决策、社会互动以及信息或疾病在人群中的传播。
- en: By offloading the computational workload to GPUs, researchers can experience
    substantial speedup in the execution of MCMC algorithms. This speedup allows for
    more extensive exploration of parameter spaces and facilitates the analysis of
    larger datasets, leading to more accurate and detailed insights into human behavior
    or population dynamics. Examples of studies done using these methods can be found
    at the [Center for Humanities Computing Aarhus](https://chc.au.dk/) (CHCAA) and
    [Interacting Minds Centre](https://interactingminds.au.dk/) (IMC) at Aarhus University.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将计算工作负载卸载到GPU上，研究人员可以在MCMC算法的执行中体验到显著的加速。这种加速使得对参数空间的更广泛探索成为可能，并促进了大数据集的分析，从而对人类行为或种群动态有了更准确和详细的洞察。使用这些方法进行的案例研究可以在[人文计算中心奥尔胡斯](https://chc.au.dk/)（CHCAA）和[互动心智中心](https://interactingminds.au.dk/)（IMC）的奥尔胡斯大学找到。
- en: Exercises
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Discussion
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论
- en: What type of problems have you used GPUs for?
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用GPU解决了哪些类型的问题？
- en: How large was the performance boost?
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能提升有多大？
- en: Good and bad use cases for GPU porting
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: GPU迁移的优缺点案例
- en: Which of the following computational tasks is likely to gain the least performance
    benefit from being ported to a GPU?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个计算任务在迁移到GPU后可能获得的最小性能提升？
- en: Training a large, deep neural network.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个大型、深度神经网络。
- en: Performing a Monte Carlo simulation with a large number of independent trials.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行具有大量独立试验的蒙特卡洛模拟。
- en: Executing an algorithm with heavy use of recursion and frequent branching.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行一个大量使用递归和频繁分支的算法。
- en: Processing a large image with a convolutional filter.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用卷积滤波器处理大型图像。
- en: Solution
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The right answer is option 3\. GPUs do not handle recursion and branching as
    effectively as more data-heavy algorithms.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是选项3。GPU在处理递归和分支方面不如数据密集型算法有效。
- en: Keypoints
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 重点
- en: GPUs excel in processing tasks with high data parallelism, such as large-scale
    matrix operations, Fourier transforms, and big data analytics.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理具有高数据并行性的任务方面表现出色，例如大规模矩阵运算、傅里叶变换和大数据分析。
- en: GPUs struggle with sequential tasks, problems with extensive control flow divergence,
    low arithmetic intensity tasks, small data sets, and memory-bound problems.*
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU在处理顺序任务、具有广泛控制流发散的问题、低算术强度任务、小数据集和内存绑定问题方面存在困难*。
