- en: 18.4Â Hashes, Sets, and Key-ValuesğŸ”—
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 18.4Â æ•£åˆ—ã€é›†åˆå’Œé”®å€¼ğŸ”—
- en: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/hash-set-kv.html](https://dcic-world.org/2025-08-27/hash-set-kv.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://dcic-world.org/2025-08-27/hash-set-kv.html](https://dcic-world.org/2025-08-27/hash-set-kv.html)
- en: '| Â Â Â Â [18.4.1Â A Hash Function for Strings](#%28part._hash-string%29) |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.1Â å­—ç¬¦ä¸²çš„æ•£åˆ—å‡½æ•°](#%28part._hash-string%29) |'
- en: '| Â Â Â Â [18.4.2Â Sets from Hashing](#%28part._.Sets_from_.Hashing%29) |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.2Â ä»æ•£åˆ—æ„å»ºé›†åˆ](#%28part._.Sets_from_.Hashing%29) |'
- en: '| Â Â Â Â [18.4.3Â Arrays](#%28part._.Arrays%29) |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.3Â æ•°ç»„](#%28part._.Arrays%29) |'
- en: '| Â Â Â Â [18.4.4Â Sets from Hashing and Arrays](#%28part._hash-tables%29) |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.4Â ä»æ•£åˆ—å’Œæ•°ç»„æ„å»ºé›†åˆ](#%28part._hash-tables%29) |'
- en: '| Â Â Â Â [18.4.5Â Collisions](#%28part._.Collisions%29) |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.5Â å†²çª](#%28part._.Collisions%29) |'
- en: '| Â Â Â Â [18.4.6Â Resolving Collisions](#%28part._.Resolving_.Collisions%29) |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.6Â è§£å†³å†²çª](#%28part._.Resolving_.Collisions%29) |'
- en: '| Â Â Â Â [18.4.7Â Complexity](#%28part._hash-comp%29) |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.7Â å¤æ‚åº¦](#%28part._hash-comp%29) |'
- en: '| Â Â Â Â [18.4.8Â Bloom Filters](#%28part._bloom-filters%29) |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.8Â å¸ƒéš†è¿‡æ»¤å™¨](#%28part._bloom-filters%29) |'
- en: '| Â Â Â Â [18.4.9Â Generalizing from Sets to Key-Values](#%28part._.Generalizing_from_.Sets_to_.Key-.Values%29)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '|Â Â Â Â [18.4.9Â ä»é›†åˆåˆ°é”®å€¼çš„ä¸€èˆ¬åŒ–](#%28part._.Generalizing_from_.Sets_to_.Key-.Values%29)
    |'
- en: 'We have seen several solutions to set membership [[Several Variations on Sets](part_sets.html)].
    In particular, trees [[Making Sets Grow on Trees](sets-from-trees.html)] gave
    us logarithmic complexity for insection and membership. Now we will see one more
    implementation of sets, with different complexity. To set this up, we assume you
    are familiar with the concept of hashing [[Converting Values to Ordered Values](orderability.html#%28part._hashing-values%29)],
    which we saw was useful for constructing search trees. Here, we will use it to
    construct sets in a very different way. We will then generalize sets to another
    important data structure: key-value repositories. But firstâ€¦'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†å‡ ç§è®¾ç½®æˆå‘˜å…³ç³»çš„è§£å†³æ–¹æ¡ˆ [[å‡ ç§é›†åˆçš„å˜ä½“](part_sets.html)]ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ ‘ [[åœ¨æ ‘ä¸Šæ„å»ºé›†åˆ](sets-from-trees.html)]
    ç»™æˆ‘ä»¬æä¾›äº†å¯¹äº¤å’Œæˆå‘˜å…³ç³»çš„å¯¹æ•°å¤æ‚åº¦ã€‚ç°åœ¨æˆ‘ä»¬å°†çœ‹åˆ°é›†åˆçš„å¦ä¸€ç§å®ç°ï¼Œå…·æœ‰ä¸åŒçš„å¤æ‚åº¦ã€‚ä¸ºäº†è®¾ç½®è¿™ä¸ªï¼Œæˆ‘ä»¬å‡è®¾ä½ ç†Ÿæ‚‰æ•£åˆ—çš„æ¦‚å¿µ [[å°†å€¼è½¬æ¢ä¸ºæœ‰åºå€¼](orderability.html#%28part._hashing-values%29)]ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å®ƒå¯¹äºæ„å»ºæœç´¢æ ‘æ˜¯æœ‰ç”¨çš„ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç”¨å®ƒä»¥éå¸¸ä¸åŒçš„æ–¹å¼æ„å»ºé›†åˆã€‚ç„¶åæˆ‘ä»¬å°†é›†åˆæ¨å¹¿åˆ°å¦ä¸€ä¸ªé‡è¦çš„æ•°æ®ç»“æ„ï¼šé”®å€¼å­˜å‚¨ã€‚ä½†é¦–å…ˆâ€¦
- en: 18.4.1Â A Hash Function for Strings[ğŸ”—](#(part._hash-string) "Link to here")
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.1Â å­—ç¬¦ä¸²çš„æ•£åˆ—å‡½æ•°[ğŸ”—](#(part._hash-string) "é“¾æ¥åˆ°æ­¤å¤„")
- en: As we have seen in [Converting Values to Ordered Values](orderability.html#%28part._hashing-values%29),
    we have multiple strategies for converting arbitrary values into numbers, which
    we will rely on here. Therefore, we could write this material around numbers alone.
    To make the examples more interesting, and to better illustrate some real-world
    issues, we will instead use strings. To hash them, we will use `hash-of`, defined
    there, which simply adds up a stringâ€™s code points.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨ [å°†å€¼è½¬æ¢ä¸ºæœ‰åºå€¼](orderability.html#%28part._hashing-values%29) ä¸­æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬æœ‰å¤šç§ç­–ç•¥å°†ä»»æ„å€¼è½¬æ¢ä¸ºæ•°å­—ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œä¾èµ–è¿™äº›ç­–ç•¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»…å›´ç»•æ•°å­—ç¼–å†™è¿™äº›ææ–™ã€‚ä¸ºäº†ä½¿ç¤ºä¾‹æ›´æœ‰è¶£ï¼Œå¹¶æ›´å¥½åœ°è¯´æ˜ä¸€äº›ç°å®ä¸–ç•Œçš„é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ”¹ç”¨å­—ç¬¦ä¸²ã€‚ä¸ºäº†æ•£åˆ—å®ƒä»¬ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é‚£é‡Œå®šä¹‰çš„
    `hash-of`ï¼Œå®ƒåªæ˜¯å°†å­—ç¬¦ä¸²çš„ä»£ç ç‚¹ç›¸åŠ ã€‚
- en: We use this function for multiple reasons. First, it is sufficient to illustrate
    some of the consequences of hashing. Second, in practice, when built-in hashing
    does not suffice, we do write (more complex versions of) functions like it. And
    finally, because itâ€™s all laid bare, itâ€™s easy for us to experiment with.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡ºäºå¤šä¸ªåŸå› ä½¿ç”¨è¿™ä¸ªå‡½æ•°ã€‚é¦–å…ˆï¼Œå®ƒè¶³ä»¥è¯´æ˜æ•£åˆ—çš„ä¸€äº›åæœã€‚å…¶æ¬¡ï¼Œåœ¨å®è·µä¸­ï¼Œå½“å†…ç½®æ•£åˆ—ä¸è¶³æ—¶ï¼Œæˆ‘ä»¬ç¡®å®ä¼šç¼–å†™ï¼ˆæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼‰è¿™æ ·çš„å‡½æ•°ã€‚æœ€åï¼Œå› ä¸ºæ‰€æœ‰å†…å®¹éƒ½æš´éœ²æ— é—ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾ˆå®¹æ˜“è¿›è¡Œå®éªŒã€‚
- en: 18.4.2Â Sets from Hashing[ğŸ”—](#(part._.Sets_from_.Hashing) "Link to here")
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.2Â ä»æ•£åˆ—æ„å»ºé›†åˆ[ğŸ”—](#(part._.Sets_from_.Hashing) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Suppose we are given a set of strings. We can hash each element of that set.
    Each string is now mapped to a number. Each of these numbers is a member of the
    set; every other number is not a member of this set.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå­—ç¬¦ä¸²é›†åˆã€‚æˆ‘ä»¬å¯ä»¥æ•£åˆ—è¯¥é›†åˆçš„æ¯ä¸ªå…ƒç´ ã€‚ç°åœ¨æ¯ä¸ªå­—ç¬¦ä¸²éƒ½æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚è¿™äº›æ•°å­—ä¸­çš„æ¯ä¸€ä¸ªéƒ½æ˜¯é›†åˆçš„æˆå‘˜ï¼›å…¶ä»–ä»»ä½•æ•°å­—éƒ½ä¸æ˜¯è¿™ä¸ªé›†åˆçš„æˆå‘˜ã€‚
- en: 'Therefore, a simple representation is to just store this list of numbers. For
    instance, we can store the list `[list: "Hello", "World!", "ğŸ´â€â˜ ï¸"] as [list: 500,
    553, 195692]`.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 'å› æ­¤ï¼Œä¸€ç§ç®€å•çš„è¡¨ç¤ºæ–¹æ³•å°±æ˜¯åªå­˜å‚¨è¿™ä¸ªæ•°å­—åˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆ—è¡¨ `[list: "Hello", "World!", "ğŸ´â€â˜ ï¸"]` å­˜å‚¨ä¸º
    `[list: 500, 553, 195692]`ã€‚'
- en: 'Unfortunately, this does not help very much. Insertion can be done in constant
    time, but checking membership requires us to traverse the entire list, which takes
    linear time in the worst case. Alternatively, maybe we have some clever scheme
    that involves sorting the list. But note:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¹¸çš„æ˜¯ï¼Œè¿™å¹¶æ²¡æœ‰å¤ªå¤§çš„å¸®åŠ©ã€‚æ’å…¥å¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…å®Œæˆï¼Œä½†æ£€æŸ¥æˆå‘˜èµ„æ ¼éœ€è¦æˆ‘ä»¬éå†æ•´ä¸ªåˆ—è¡¨ï¼Œåœ¨æœ€åçš„æƒ…å†µä¸‹è¿™éœ€è¦çº¿æ€§æ—¶é—´ã€‚æˆ–è€…ï¼Œä¹Ÿè®¸æˆ‘ä»¬æœ‰ä¸€äº›æ¶‰åŠæ’åºåˆ—è¡¨çš„å·§å¦™æ–¹æ¡ˆã€‚ä½†è¯·æ³¨æ„ï¼š
- en: inserting the element can now take as much as linear time; or,
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ’å…¥å…ƒç´ ç°åœ¨å¯èƒ½éœ€è¦çº¿æ€§æ—¶é—´ï¼›æˆ–è€…ï¼Œ
- en: we store the elements as a tree instead of a list, but then
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å…ƒç´ å­˜å‚¨ä¸ºæ ‘è€Œä¸æ˜¯åˆ—è¡¨ï¼Œä½†ç„¶å
- en: we have to make sure the tree is balanced, so
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»ç¡®ä¿æ ‘æ˜¯å¹³è¡¡çš„ï¼Œæ‰€ä»¥
- en: we will have essentially reconstructed the BBST.
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åŸºæœ¬ä¸Šé‡å»ºäº†BBSTã€‚
- en: In other words, we are recapitulating the discussion from [Representing Sets
    as Lists](sets-from-lists.html) and [Making Sets Grow on Trees](sets-from-trees.html).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æ­£åœ¨é‡è¿°[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)å’Œ[åœ¨æ ‘ä¸Šå¢é•¿é›†åˆ](sets-from-trees.html)ä¸­çš„è®¨è®ºã€‚
- en: 'Notice that the problem here is traversal: if we have to visit more than a
    constant number of elements, we have probably not improved anything over the BBST.
    So, given a hash, how can we perform only a constant amount of work? For that,
    lists and trees donâ€™t work: they both require at least some amount of (non-constant)
    traversal to get to an arbitrary element. Instead we need a different data structureâ€¦'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè¿™é‡Œçš„é—®é¢˜æ˜¯éå†ï¼šå¦‚æœæˆ‘ä»¬å¿…é¡»è®¿é—®è¶…è¿‡å¸¸æ•°æ•°é‡çš„å…ƒç´ ï¼Œæˆ‘ä»¬å¯èƒ½å¹¶æ²¡æœ‰æ¯”BBSTåšå¾—æ›´å¥½ã€‚æ‰€ä»¥ï¼Œç»™å®šä¸€ä¸ªå“ˆå¸Œå€¼ï¼Œæˆ‘ä»¬å¦‚ä½•åªåšå¸¸æ•°é‡çš„å·¥ä½œï¼Ÿä¸ºæ­¤ï¼Œåˆ—è¡¨å’Œæ ‘éƒ½ä¸é€‚ç”¨ï¼šå®ƒä»¬éƒ½éœ€è¦è‡³å°‘ä¸€äº›ï¼ˆéå¸¸æ•°ï¼‰éå†æ¥åˆ°è¾¾ä»»æ„å…ƒç´ ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸åŒçš„æ•°æ®ç»“æ„â€¦
- en: 18.4.3Â Arrays[ğŸ”—](#(part._.Arrays) "Link to here")
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.3Â æ•°ç»„[ğŸ”—](#(part._.Arrays) "é“¾æ¥è‡³æ­¤")
- en: Arrays are another linear data structure, like lists. There are two key differences
    between lists and arrays that reflect each oneâ€™s strength and weakness.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ç»„æ˜¯å¦ä¸€ç§çº¿æ€§æ•°æ®ç»“æ„ï¼Œå°±åƒåˆ—è¡¨ä¸€æ ·ã€‚åˆ—è¡¨å’Œæ•°ç»„ä¹‹é—´æœ‰ä¸¤ä¸ªå…³é”®çš„åŒºåˆ«ï¼Œåæ˜ äº†å„è‡ªçš„ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚
- en: The main benefit to arrays is that we can access any element in the array in
    constant time. This is in contrast to lists where, to get to the \(n\)th element,
    we have to first traverse the previous \(n-1\) elements (using successive `rest`s).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ç»„çš„ä¸»è¦ä¼˜ç‚¹æ˜¯æˆ‘ä»¬å¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…è®¿é—®æ•°ç»„ä¸­çš„ä»»ä½•å…ƒç´ ã€‚è¿™ä¸åˆ—è¡¨å½¢æˆå¯¹æ¯”ï¼Œåœ¨åˆ—è¡¨ä¸­ï¼Œä¸ºäº†åˆ°è¾¾ç¬¬\(n\)ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆéå†å‰é¢çš„\(n-1\)ä¸ªå…ƒç´ ï¼ˆä½¿ç”¨è¿ç»­çš„`rest`sï¼‰ã€‚
- en: However, this benefit comes at a cost. The reason arrays can support constant-time
    access is because the size of an array is fixed at creation time. Thus, while
    we can keep extending a list using link, we cannot grow the size of an array â€œin
    placeâ€; rather, we must make a new array and copy the entire arrayâ€™s content into
    the new array, which takes linear time. (We can do a better job of this by using
    [Halloween Analysis](amortized-analysis.html), but there is no real free ride.)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§å¥½å¤„æ˜¯ä»¥ä»£ä»·ä¸ºä»£ä»·çš„ã€‚æ•°ç»„å¯ä»¥æ”¯æŒå¸¸æ•°æ—¶é—´è®¿é—®çš„åŸå› æ˜¯æ•°ç»„çš„å°ºå¯¸åœ¨åˆ›å»ºæ—¶æ˜¯å›ºå®šçš„ã€‚å› æ­¤ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥é€šè¿‡é“¾æ¥æ¥æ‰©å±•åˆ—è¡¨ï¼Œä½†æˆ‘ä»¬ä¸èƒ½â€œå°±åœ°â€å¢é•¿æ•°ç»„çš„å°ºå¯¸ï¼›ç›¸åï¼Œæˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°ç»„ï¼Œå¹¶å°†æ•´ä¸ªæ•°ç»„çš„å†…å®¹å¤åˆ¶åˆ°æ–°æ•°ç»„ä¸­ï¼Œè¿™éœ€è¦çº¿æ€§æ—¶é—´ã€‚ï¼ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨[ä¸‡åœ£èŠ‚åˆ†æ](amortized-analysis.html)åšå¾—æ›´å¥½ï¼Œä½†è¿™å¹¶ä¸æ˜¯çœŸæ­£çš„å…è´¹ä¹‹æ—…ã€‚ï¼‰
- en: The arrays in Pyret are [documented here](https://www.pyret.org/docs/latest/arrays.html).
    While not necessary in principle, it is conventional to think of arrays as data
    structures that support mutation, and that is how we will use them here.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Pyretä¸­çš„æ•°ç»„åœ¨æ­¤å¤„[æ–‡æ¡£åŒ–](https://www.pyret.org/docs/latest/arrays.html)ã€‚è™½ç„¶åœ¨åŸåˆ™ä¸Šä¸æ˜¯å¿…è¦çš„ï¼Œä½†ä¼ ç»Ÿä¸Šè®¤ä¸ºæ•°ç»„æ˜¯æ”¯æŒå˜åŠ¨çš„æ•°æ®ç»“æ„ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¹Ÿå°†è¿™æ ·ä½¿ç”¨å®ƒä»¬ã€‚
- en: 18.4.4Â Sets from Hashing and Arrays[ğŸ”—](#(part._hash-tables) "Link to here")
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.4Â ä»å“ˆå¸Œè¡¨å’Œæ•°ç»„ç”Ÿæˆçš„é›†åˆ[ğŸ”—](#(part._hash-tables) "é“¾æ¥è‡³æ­¤")
- en: Okay, so now we have a strategy. When we want to insert a string into the set,
    we compute its hash, go to the corresponding location in the array, and record
    the presence of that string. If we want to check for membership, we similarly
    compute its hash and see whether the corresponding location has been set. Traditionally,
    each location in the array is called a bucket, and this data structure is called
    a hashtable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªç­–ç•¥ã€‚å½“æˆ‘ä»¬æƒ³è¦å°†ä¸€ä¸ªå­—ç¬¦ä¸²æ’å…¥åˆ°é›†åˆä¸­æ—¶ï¼Œæˆ‘ä»¬è®¡ç®—å…¶å“ˆå¸Œå€¼ï¼Œè½¬åˆ°æ•°ç»„ä¸­çš„ç›¸åº”ä½ç½®ï¼Œå¹¶è®°å½•è¯¥å­—ç¬¦ä¸²çš„å­˜åœ¨ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦æ£€æŸ¥æˆå‘˜èµ„æ ¼ï¼Œæˆ‘ä»¬åŒæ ·è®¡ç®—å…¶å“ˆå¸Œå€¼ï¼Œçœ‹çœ‹ç›¸åº”çš„ä½ç½®æ˜¯å¦å·²è¢«è®¾ç½®ã€‚ä¼ ç»Ÿä¸Šï¼Œæ•°ç»„ä¸­çš„æ¯ä¸ªä½ç½®è¢«ç§°ä¸ºæ¡¶ï¼Œè¿™ç§æ•°æ®ç»“æ„è¢«ç§°ä¸ºå“ˆå¸Œè¡¨ã€‚
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Observe that if this were to work, we would have constant time insertion and
    membership checking. Unfortunately, two things make this plan untenable in general.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå¦‚æœè¿™èƒ½èµ·ä½œç”¨ï¼Œæˆ‘ä»¬å°†æœ‰å¸¸æ•°æ—¶é—´çš„æ’å…¥å’Œæˆå‘˜èµ„æ ¼æ£€æŸ¥ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæœ‰ä¸¤ä»¶äº‹ä½¿å¾—è¿™ä¸ªè®¡åˆ’åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¸å¯è¡Œã€‚
- en: 18.4.5Â Collisions[ğŸ”—](#(part._.Collisions) "Link to here")
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.5Â å†²çª[ğŸ”—](#(part._.Collisions) "é“¾æ¥è‡³æ­¤")
- en: First, our choice of hash function. For the above scheme to work, two different
    strings have to map to two different locations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬çš„å“ˆå¸Œå‡½æ•°é€‰æ‹©ã€‚ä¸ºäº†ä½¿ä¸Šè¿°æ–¹æ¡ˆç”Ÿæ•ˆï¼Œä¸¤ä¸ªä¸åŒçš„å­—ç¬¦ä¸²å¿…é¡»æ˜ å°„åˆ°ä¸¤ä¸ªä¸åŒçš„ä½ç½®ã€‚
- en: Do Now!
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Do Now!
- en: ''
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is the above hash function invertible?
  id: totrans-38
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šè¿°å“ˆå¸Œå‡½æ•°å¯é€†å—ï¼Ÿ
- en: 'We just need to find two strings that have the same hash. Given the definition
    of `hash-of`, itâ€™s easy to see that any rearrangement of the letters produces
    the same hash:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€æ‰¾åˆ°ä¸¤ä¸ªå…·æœ‰ç›¸åŒå“ˆå¸Œå€¼çš„å­—ç¬¦ä¸²ã€‚æ ¹æ®`hash-of`çš„å®šä¹‰ï¼Œå¾ˆå®¹æ˜“çœ‹å‡ºä»»ä½•å­—æ¯çš„é‡æ–°æ’åˆ—éƒ½ä¼šäº§ç”Ÿç›¸åŒçš„å“ˆå¸Œå€¼ï¼š
- en: '|'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124;'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '[PRE1]'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '&#124;'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '|'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124;'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '[PRE3]'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '&#124;'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '|'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Similarly, this test suite passes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œè¿™ä¸ªæµ‹è¯•å¥—ä»¶ä¹Ÿé€šè¿‡äº†ï¼š
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When multiple values hash to the same location, we call this a hash collision.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¤šä¸ªå€¼å“ˆå¸Œåˆ°åŒä¸€ä½ç½®æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå“ˆå¸Œå†²çªã€‚
- en: 'Hash-collisions are problematic! With the above hash function, we get:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆå¸Œå†²çªæ˜¯æœ‰é—®é¢˜çš„ï¼ä½¿ç”¨ä¸Šè¿°å“ˆå¸Œå‡½æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: where two of these tests are desirable but the third is definitely not.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸¤ä¸ªæµ‹è¯•æ˜¯å¯å–çš„ï¼Œä½†ç¬¬ä¸‰ä¸ªåˆ™ç»å¯¹ä¸å¯å–ã€‚
- en: Note that collisions are virtually inevitable. If we have uniformly distributed
    data, then collisions show up sooner than we might expect.This follows from the
    reasoning behind what is known as the [birthday problem](http://en.wikipedia.org/wiki/Birthday_problem),
    commonly presented as how many people need to be in a room before the likelihood
    that two of them share a birthday exceeds some percentage. For the likelihood
    to exceed half we need just 23 people! Therefore, it is wise to prepare for the
    possibility of collisions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå†²çªå‡ ä¹æ˜¯ä¸å¯é¿å…çš„ã€‚å¦‚æœæˆ‘ä»¬æœ‰å‡åŒ€åˆ†å¸ƒçš„æ•°æ®ï¼Œé‚£ä¹ˆå†²çªçš„å‡ºç°ä¼šæ¯”æˆ‘ä»¬é¢„æœŸçš„è¦æ—©ã€‚è¿™æºäºæ‰€è°“çš„[ç”Ÿæ—¥é—®é¢˜](http://en.wikipedia.org/wiki/Birthday_problem)èƒŒåçš„æ¨ç†ï¼Œé€šå¸¸ä»¥åœ¨æˆ¿é—´é‡Œæœ‰å¤šå°‘äººä¹‹å‰ä¸¤äººå…±äº«ç”Ÿæ—¥çš„å¯èƒ½æ€§è¶…è¿‡æŸä¸ªç™¾åˆ†æ¯”æ¥å‘ˆç°ã€‚ä¸ºäº†ä½¿å¯èƒ½æ€§è¶…è¿‡ä¸€åŠï¼Œåªéœ€è¦23ä¸ªäººï¼å› æ­¤ï¼Œä¸ºå†²çªçš„å¯èƒ½æ€§åšå¥½å‡†å¤‡æ˜¯æ˜æ™ºçš„ã€‚
- en: The key is to know something about the distribution of hash values. For instance,
    if we knew our hash values are all multiples of 10, then using a table size of
    10 would be a terrible idea (because all elements would hash to the same bucket,
    turning our hash table into a list). In practice, it is common to use uncommon
    prime numbers as the table size, since a random value is unlikely to have it as
    a divisor. This does not yield a theoretical improvement (unless you can make
    certain assumptions about the input, or work through the math very carefully),
    but it works well in practice.In particular, since the typical hashing function
    uses memory addresses for objects on the heap, and on most systems these addresses
    are multiples of 4, using a prime like 31 is often a fairly good bet.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®æ˜¯è¦äº†è§£å“ˆå¸Œå€¼çš„åˆ†å¸ƒæƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬çš„å“ˆå¸Œå€¼éƒ½æ˜¯10çš„å€æ•°ï¼Œé‚£ä¹ˆä½¿ç”¨å¤§å°ä¸º10çš„è¡¨å°†æ˜¯ä¸€ä¸ªç³Ÿç³•çš„ä¸»æ„ï¼ˆå› ä¸ºæ‰€æœ‰å…ƒç´ éƒ½ä¼šå“ˆå¸Œåˆ°åŒä¸€ä¸ªæ¡¶ï¼Œå°†æˆ‘ä»¬çš„å“ˆå¸Œè¡¨å˜æˆä¸€ä¸ªåˆ—è¡¨ï¼‰ã€‚åœ¨å®è·µä¸­ï¼Œé€šå¸¸ä½¿ç”¨ä¸å¸¸è§çš„ç´ æ•°ä½œä¸ºè¡¨çš„å¤§å°ï¼Œå› ä¸ºéšæœºå€¼ä¸å¤ªå¯èƒ½æˆä¸ºå®ƒçš„é™¤æ•°ã€‚è¿™å¹¶ä¸å¸¦æ¥ç†è®ºä¸Šçš„æ”¹è¿›ï¼ˆé™¤éä½ å¯ä»¥å¯¹è¾“å…¥åšå‡ºæŸäº›å‡è®¾ï¼Œæˆ–è€…éå¸¸ä»”ç»†åœ°å¤„ç†æ•°å­¦ï¼‰ï¼Œä½†åœ¨å®è·µä¸­æ•ˆæœå¾ˆå¥½ã€‚ç‰¹åˆ«æ˜¯ï¼Œç”±äºå…¸å‹çš„å“ˆå¸Œå‡½æ•°ä½¿ç”¨å †ä¸Šå¯¹è±¡çš„å†…å­˜åœ°å€ï¼Œè€Œåœ¨å¤§å¤šæ•°ç³»ç»Ÿä¸­è¿™äº›åœ°å€æ˜¯4çš„å€æ•°ï¼Œä½¿ç”¨31è¿™æ ·çš„ç´ æ•°é€šå¸¸æ˜¯ä¸€ä¸ªç›¸å½“å¥½çš„é€‰æ‹©ã€‚
- en: While collisions are probabilistic, and depend on the choice of hash function,
    we have an even more fundamental and unavoidable reason for collisions. We have
    to store an array of the largest possible hash size. However, not only can hash
    values be very large (try to run `insert("ğŸ´â€â˜ ï¸")` and see what happens), there
    isnâ€™t even an a priori limit to the size of a hash. This fundamentally flies in
    the face of arrays, which must have a fixed size.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å†²çªæ˜¯æ¦‚ç‡æ€§çš„ï¼Œå¹¶ä¸”å–å†³äºå“ˆå¸Œå‡½æ•°çš„é€‰æ‹©ï¼Œä½†æˆ‘ä»¬æœ‰ä¸€ä¸ªæ›´åŸºæœ¬ä¸”ä¸å¯é¿å…çš„å†²çªåŸå› ã€‚æˆ‘ä»¬å¿…é¡»å­˜å‚¨ä¸€ä¸ªæœ€å¤§å¯èƒ½å“ˆå¸Œå¤§å°çš„æ•°ç»„ã€‚ç„¶è€Œï¼Œå“ˆå¸Œå€¼å¯ä»¥éå¸¸å¤§ï¼ˆå°è¯•è¿è¡Œ`insert("ğŸ´â€â˜ ï¸")`å¹¶çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆï¼‰ï¼Œç”šè‡³å“ˆå¸Œçš„å¤§å°ä¹Ÿæ²¡æœ‰å…ˆéªŒçš„é™åˆ¶ã€‚è¿™ä»æ ¹æœ¬ä¸Šä¸æ•°ç»„ç›¸çŸ›ç›¾ï¼Œæ•°ç»„å¿…é¡»æœ‰å›ºå®šçš„å¤§å°ã€‚
- en: 'To handle arbitrarily large values, we:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¤„ç†ä»»æ„å¤§çš„æ•°å€¼ï¼Œæˆ‘ä»¬ï¼š
- en: use an array size that is reasonable given our memory constraints
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç¬¦åˆæˆ‘ä»¬å†…å­˜é™åˆ¶çš„åˆç†å¤§å°çš„æ•°ç»„
- en: use the remainder of the hash relative to the arrayâ€™s size to find the bucket
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å“ˆå¸Œç›¸å¯¹äºæ•°ç»„å¤§å°çš„ä½™æ•°æ¥æ‰¾åˆ°æ¡¶
- en: 'That is:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£å°±æ˜¯ï¼š
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This addresses the second problem: we can also store the pirate flag:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è§£å†³äº†ç¬¬äºŒä¸ªé—®é¢˜ï¼šæˆ‘ä»¬è¿˜å¯ä»¥å­˜å‚¨æµ·ç›—æ——å¸œï¼š
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Observe, however, we have simply created yet another source of collisions:
    the remainder computation. If we have 10 buckets, then the hashes 5, 15, 25, 35,
    â€¦ all refer to the same bucket. Thus, there are two sources of collision, and
    we have to deal with them both.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬åªæ˜¯åˆåˆ›é€ äº†ä¸€ä¸ªå†²çªçš„æ¥æºï¼šä½™æ•°è®¡ç®—ã€‚å¦‚æœæˆ‘ä»¬æœ‰10ä¸ªæ¡¶ï¼Œé‚£ä¹ˆå“ˆå¸Œå€¼5ã€15ã€25ã€35ã€â€¦â€¦éƒ½æŒ‡å‘åŒä¸€ä¸ªæ¡¶ã€‚å› æ­¤ï¼Œæœ‰ä¸¤ä¸ªå†²çªæ¥æºï¼Œæˆ‘ä»¬å¿…é¡»å¤„ç†å®ƒä»¬ã€‚
- en: 18.4.6Â Resolving Collisions[ğŸ”—](#(part._.Resolving_.Collisions) "Link to here")
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.6Â è§£å†³å†²çª[ğŸ”—](#(part._.Resolving_.Collisions) "é“¾æ¥è‡³æ­¤")
- en: Surprisingly or disappointingly, we have a very simple solution to the collision
    problems. Each bucket is not a single Boolean value, but rather a list of the
    actual values that hashed to that bucket. Then, we just check for membership in
    that list.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å¤–åœ°æˆ–ä»¤äººå¤±æœ›çš„æ˜¯ï¼Œæˆ‘ä»¬å¯¹å†²çªé—®é¢˜æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„è§£å†³æ–¹æ¡ˆã€‚æ¯ä¸ªæ¡¶ä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„å¸ƒå°”å€¼ï¼Œè€Œæ˜¯ä¸€ç³»åˆ—å®é™…å€¼ï¼Œè¿™äº›å€¼è¢«å“ˆå¸Œåˆ°è¯¥æ¡¶ã€‚ç„¶åï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥è¯¥åˆ—è¡¨ä¸­çš„æˆå‘˜èµ„æ ¼å³å¯ã€‚
- en: 'First, we will abstract over finding the bucket number in `insert` and `is-in`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†å¯¹`insert`å’Œ`is-in`ä¸­æ‰¾åˆ°çš„æ¡¶å·è¿›è¡ŒæŠ½è±¡ï¼š
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we change what is held in each bucket: not a Boolean, but rather a list
    of the actual strings:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ”¹å˜æ¯ä¸ªæ¡¶ä¸­å­˜å‚¨çš„å†…å®¹ï¼šä¸å†æ˜¯å¸ƒå°”å€¼ï¼Œè€Œæ˜¯ä¸€ç³»åˆ—å®é™…å­—ç¬¦ä¸²ï¼š
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we can write the more nuanced membership checker:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç¼–å†™æ›´ç»†è‡´çš„æˆå‘˜æ£€æŸ¥å™¨ï¼š
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Similarly, when inserting, we first make sure the element isnâ€™t already there
    (to avoid the complexity problems caused by having duplicates), and only then
    insert it:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œåœ¨æ’å…¥æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®ä¿å…ƒç´ å°šæœªå­˜åœ¨ï¼ˆä»¥é¿å…ç”±é‡å¤é¡¹å¼•èµ·çš„å¤æ‚æ€§é—®é¢˜ï¼‰ï¼Œç„¶åæ‰æ’å…¥å®ƒï¼š
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now our tests pass as intended:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„æµ‹è¯•æŒ‰é¢„æœŸé€šè¿‡ï¼š
- en: '[PRE13]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 18.4.7Â Complexity[ğŸ”—](#(part._hash-comp) "Link to here")
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.7Â å¤æ‚æ€§[ğŸ”—](#(part._hash-comp) "é“¾æ¥è‡³æ­¤")
- en: 'Now we have yet another working implementation for (some primitives of) sets.
    The use of arrays supposedly enables us to get constant-time complexity. Yet we
    should feel at least some discomfort. After all, the constant time applied when
    the arrays contained only Boolean values. However, that solution was weak in two
    ways: it could not handle hash-collisions by non-invertible hash functions, and
    it required potentially enormous arrays. If we relaxed either assumption, the
    implementation was simply wrong, in that it was easily fooled by values that caused
    collisions either through hashing or through computing the remainder.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬åˆæœ‰äº†ä¸€ä¸ªï¼ˆä¸€äº›åŸè¯­ï¼‰é›†åˆçš„å·¥ä½œå®ç°ã€‚æ•°ç»„çš„ç”¨æ³•æ®è¯´ä½¿æˆ‘ä»¬èƒ½å¤Ÿè·å¾—å¸¸æ•°æ—¶é—´å¤æ‚åº¦ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è‡³å°‘åº”è¯¥æ„Ÿåˆ°ä¸€äº›ä¸é€‚ã€‚æ¯•ç«Ÿï¼Œå½“æ•°ç»„åªåŒ…å«å¸ƒå°”å€¼æ—¶ï¼Œåº”ç”¨çš„æ˜¯å¸¸æ•°æ—¶é—´ã€‚ç„¶è€Œï¼Œè¯¥è§£å†³æ–¹æ¡ˆæœ‰ä¸¤ä¸ªå¼±ç‚¹ï¼šå®ƒæ— æ³•é€šè¿‡ä¸å¯é€†çš„å“ˆå¸Œå‡½æ•°å¤„ç†å“ˆå¸Œå†²çªï¼Œå¹¶ä¸”éœ€è¦å¯èƒ½å·¨å¤§çš„æ•°ç»„ã€‚å¦‚æœæˆ‘ä»¬æ”¾å®½ä»»ä½•ä¸€ä¸ªå‡è®¾ï¼Œå®ç°å°±ç®€å•åœ°é”™è¯¯ï¼Œå› ä¸ºå®ƒå¾ˆå®¹æ˜“è¢«é€šè¿‡å“ˆå¸Œæˆ–è®¡ç®—ä½™æ•°å¼•èµ·çš„å†²çªå€¼æ¬ºéª—ã€‚
- en: 'The solution we have shown above is called hash chaining, where â€œchainâ€ refers
    to the list stored in each bucket. The benefit of hash-chaining is that insertion
    can still be constant-time: it takes a constant amount of time to find a bucket,
    and inserting can be as cheap as link. Of course, this assumes that we donâ€™t mind
    duplicates; otherwise we will pay the same price we saw earlier in [Representing
    Sets as Lists](sets-from-lists.html). But lookup takes time linear in the size
    of the bucket (which, with duplicates, could be arbitrarily larger relative to
    the number of distinct elements). And even if we check for duplicates, we run
    the risk that most or even all the elements could end up in the same bucket (e.g.,
    suppose the elements are `"Where"`, `"Weird"`, `"Wired"`, `"Whine"`). In that
    case, our sophisticated implementation reduces to the list-based representation
    and its complexity!'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸Šé¢å±•ç¤ºçš„è§£å†³æ–¹æ¡ˆè¢«ç§°ä¸ºå“ˆå¸Œé“¾è¡¨ï¼Œå…¶ä¸­â€œé“¾â€æŒ‡çš„æ˜¯æ¯ä¸ªæ¡¶ä¸­å­˜å‚¨çš„åˆ—è¡¨ã€‚å“ˆå¸Œé“¾è¡¨çš„ä¼˜ç‚¹æ˜¯æ’å…¥ä»ç„¶å¯ä»¥æ˜¯å¸¸æ•°æ—¶é—´ï¼šæŸ¥æ‰¾æ¡¶éœ€è¦å¸¸æ•°æ—¶é—´ï¼Œæ’å…¥å¯ä»¥åƒé“¾æ¥ä¸€æ ·ä¾¿å®œã€‚å½“ç„¶ï¼Œè¿™å‡è®¾æˆ‘ä»¬ä¸ä»‹æ„é‡å¤é¡¹ï¼›å¦åˆ™ï¼Œæˆ‘ä»¬å°†ä»˜å‡ºæˆ‘ä»¬åœ¨[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)ä¸­çœ‹åˆ°çš„ç›¸åŒä»£ä»·ã€‚ä½†æ˜¯æŸ¥æ‰¾çš„æ—¶é—´ä¸æ¡¶çš„å¤§å°æˆçº¿æ€§å…³ç³»ï¼ˆè€ƒè™‘åˆ°é‡å¤é¡¹ï¼Œè¿™å¯èƒ½ä¸ä¸åŒå…ƒç´ çš„æ•°é‡ä¸æˆæ¯”ä¾‹åœ°ä»»æ„å¤§ï¼‰ã€‚å³ä½¿æˆ‘ä»¬æ£€æŸ¥é‡å¤é¡¹ï¼Œæˆ‘ä»¬ä¹Ÿå­˜åœ¨é£é™©ï¼Œå³å¤§å¤šæ•°ç”šè‡³æ‰€æœ‰å…ƒç´ æœ€ç»ˆå¯èƒ½éƒ½è½åœ¨åŒä¸€ä¸ªæ¡¶ä¸­ï¼ˆä¾‹å¦‚ï¼Œå‡è®¾å…ƒç´ æ˜¯
    `"Where"`ï¼Œ`"Weird"`ï¼Œ`"Wired"`ï¼Œ`"Whine"`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¤æ‚çš„å®ç°ç®€åŒ–ä¸ºåŸºäºåˆ—è¡¨çš„è¡¨ç¤ºåŠå…¶å¤æ‚åº¦ï¼
- en: Thereâ€™s an additional subtlety here. When we check membership of the string
    in the list of strings, we have to consider the cost of comparing each pair of
    strings. In the worst case, that is proportional to the length of the shorter
    string. Usually this is bounded by a small constant, but one can imagine settings
    where this is not guaranteed to be true. However, this same cost has to be borne
    by all set implementations; it is not a new complexity introduced here.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªé¢å¤–çš„ç»†å¾®ä¹‹å¤„ã€‚å½“æˆ‘ä»¬æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åœ¨å­—ç¬¦ä¸²åˆ—è¡¨ä¸­æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘æ¯”è¾ƒæ¯ä¸€å¯¹å­—ç¬¦ä¸²çš„æˆæœ¬ã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸è¾ƒçŸ­å­—ç¬¦ä¸²çš„é•¿åº¦æˆæ¯”ä¾‹ã€‚é€šå¸¸è¿™è¢«é™åˆ¶åœ¨ä¸€ä¸ªå°çš„å¸¸æ•°èŒƒå›´å†…ï¼Œä½†å¯ä»¥æƒ³è±¡å‡ºä¸€äº›è®¾ç½®ï¼Œå…¶ä¸­è¿™å¹¶ä¸ä¿è¯æ€»æ˜¯æˆç«‹ã€‚ç„¶è€Œï¼Œè¿™ç§ç›¸åŒçš„æˆæœ¬å¿…é¡»ç”±æ‰€æœ‰é›†åˆå®ç°æ‰¿æ‹…ï¼›è¿™ä¸æ˜¯åœ¨è¿™é‡Œå¼•å…¥çš„æ–°å¤æ‚æ€§ã€‚
- en: Thus, in theory, hash-based sets can support insertion and membership in as
    little as constant time, and (ignoring the cost of string comparisons) as much
    as linear time, where â€œlinearâ€ has the same caveats about duplicates as the list-based
    representation. In many casesâ€”<wbr>depending on the nature of the data and parameters
    set for the arrayâ€”<wbr>they can be much closer to constant time. As a result,
    they tend to be very popular in practice.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä»ç†è®ºä¸Šè®²ï¼ŒåŸºäºå“ˆå¸Œçš„é›†åˆå¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…æ”¯æŒæ’å…¥å’Œæˆå‘˜èµ„æ ¼ï¼Œå¹¶ä¸”ï¼ˆå¿½ç•¥å­—ç¬¦ä¸²æ¯”è¾ƒçš„æˆæœ¬ï¼‰æœ€å¤šçº¿æ€§æ—¶é—´ï¼Œå…¶ä¸­â€œçº¿æ€§â€å…·æœ‰ä¸åŸºäºåˆ—è¡¨è¡¨ç¤ºç›¸åŒçš„å…³äºé‡å¤é¡¹çš„è­¦å‘Šã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹â€”â€”<wbr>å–å†³äºæ•°æ®çš„æ€§è´¨å’Œä¸ºæ•°ç»„è®¾ç½®çš„å‚æ•°â€”â€”<wbr>å®ƒä»¬å¯ä»¥æ›´æ¥è¿‘å¸¸æ•°æ—¶é—´ã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨å®è·µä¸­é€šå¸¸éå¸¸å—æ¬¢è¿ã€‚
- en: 18.4.8Â Bloom Filters[ğŸ”—](#(part._bloom-filters) "Link to here")
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.8Â å¸ƒéš†è¿‡æ»¤å™¨[ğŸ”—](#(part._bloom-filters) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Another way to improve the space and time complexity is to relax the properties
    we expect of the operations. Right now, set membership gives perfect answers,
    in that it answers `true` exactly when the element being checked was previously
    inserted into the set. But suppose weâ€™re in a setting where we can accept a more
    relaxed notion of correctness, where membership tests can â€œlieâ€ slightly in one
    direction or the other (but not both, because that makes the representation almost
    useless). Specifically, letâ€™s say that â€œno means noâ€ (i.e., if the set representation
    says the element isnâ€™t present, it really isnâ€™t) but â€œyes sometimes means noâ€
    (i.e., if the set representation says an element is present, sometimes it might
    not be). In short, if the set says the element isnâ€™t in it, this should be guaranteed;
    but if the set says the element is present, it may not be. In the latter case,
    we either need some otherâ€”<wbr>more expensiveâ€”<wbr>technique to determine truth,
    or we might just not care.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æé«˜ç©ºé—´å’Œæ—¶é—´å¤æ‚æ€§çš„å¦ä¸€ç§æ–¹æ³•æ˜¯æ”¾å®½æˆ‘ä»¬å¯¹æ“ä½œæœŸæœ›çš„æ€§è´¨ã€‚ç›®å‰ï¼Œé›†åˆæˆå‘˜èµ„æ ¼ç»™å‡ºå®Œç¾çš„ç­”æ¡ˆï¼Œå³å½“æ£€æŸ¥çš„å…ƒç´ ä¹‹å‰è¢«æ’å…¥åˆ°é›†åˆä¸­æ—¶ï¼Œå®ƒæ­£å¥½å›ç­”`true`ã€‚ä½†å‡è®¾æˆ‘ä»¬å¤„äºå¯ä»¥æ¥å—æ›´å®½æ¾çš„æ­£ç¡®æ€§æ¦‚å¿µçš„ç¯å¢ƒä¸­ï¼Œå…¶ä¸­æˆå‘˜èµ„æ ¼æµ‹è¯•å¯ä»¥ç¨å¾®â€œè¯´è°â€ä¸€ä¸ªæ–¹å‘æˆ–å¦ä¸€ä¸ªæ–¹å‘ï¼ˆä½†ä¸èƒ½ä¸¤è€…éƒ½è¿™æ ·åšï¼Œå› ä¸ºè¿™ä¼šä½¿è¡¨ç¤ºå‡ ä¹æ— ç”¨ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œè®©æˆ‘ä»¬è¯´â€œæ²¡æœ‰å°±æ˜¯æ²¡æœ‰â€ï¼ˆå³ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºè¯´å…ƒç´ ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆå®ƒç¡®å®ä¸å­˜åœ¨ï¼‰ä½†â€œæœ‰æ—¶è¯´æ˜¯å°±æ˜¯ä¸æ˜¯â€ï¼ˆå³ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºè¯´å…ƒç´ å­˜åœ¨ï¼Œæœ‰æ—¶å®ƒå¯èƒ½ä¸å­˜åœ¨ï¼‰ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºå…ƒç´ ä¸åœ¨å…¶ä¸­ï¼Œè¿™åº”è¯¥æ˜¯æœ‰ä¿è¯çš„ï¼›ä½†å¦‚æœé›†åˆè¡¨ç¤ºå…ƒç´ å­˜åœ¨ï¼Œå®ƒå¯èƒ½ä¸å­˜åœ¨ã€‚åœ¨åä¸€ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ä¸€äº›å…¶ä»–â€”â€”<wbr>æ›´æ˜‚è´µâ€”â€”<wbr>çš„æŠ€æœ¯æ¥ç¡®å®šçœŸå®æ€§ï¼Œæˆ–è€…æˆ‘ä»¬å¯èƒ½æ ¹æœ¬ä¸åœ¨ä¹ã€‚
- en: Where is such a data structure of use? Suppose we are building a Web site that
    uses password-based authentication. Because many passwords have been leaked in
    well-publicized breaches, it is safe to assume that hackers have them and will
    guess them. As a result, we want to not allow users to select any of these as
    passwords. We could use a hash-table to reject precisely the known leaked passwords.
    But for efficiency, we could use this imperfect hash instead. If it says â€œnoâ€,
    then we allow the user to use that password. But if it says â€œyesâ€, then either
    they are using a password that has been leaked, or they have an entirely different
    password that, purely by accident, has the same hash value, but no matter; we
    can just disallow that password as well.A related use is for filtering out malicious
    Web sites. The URL shortening system, bitly, [uses it for this purpose](http://word.bitly.com/post/28558800777/dablooms-an-open-source-scalable-counting-bloom).
    Itâ€™s also used by ad networks; hereâ€™s a [talk](https://youtu.be/T3Bt9Tn6P5c?si=t8U33orccRCgkSw0&t=1277)
    (the segment from about 20m to about 45m) about that. But sometimes, a Bloom filter
    is overkill, as this Cloudflare blog post [discusses](https://blog.cloudflare.com/when-bloom-filters-dont-bloom/)â€¦
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·çš„æ•°æ®ç»“æ„åœ¨å“ªé‡Œæœ‰ç”¨ï¼Ÿå‡è®¾æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªä½¿ç”¨åŸºäºå¯†ç çš„è®¤è¯çš„ç½‘ç«™ã€‚ç”±äºè®¸å¤šå¯†ç å·²ç»åœ¨å…¬å¼€çš„æ³„éœ²äº‹ä»¶ä¸­æ³„éœ²ï¼Œå¯ä»¥å®‰å…¨åœ°å‡è®¾é»‘å®¢æ‹¥æœ‰å®ƒä»¬å¹¶ä¼šçŒœæµ‹å®ƒä»¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸å…è®¸ç”¨æˆ·é€‰æ‹©è¿™äº›å¯†ç ä¸­çš„ä»»ä½•ä¸€ä¸ªã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å“ˆå¸Œè¡¨æ¥æ‹’ç»å·²çŸ¥æ³„éœ²çš„å¯†ç ã€‚ä½†ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªä¸å®Œç¾çš„å“ˆå¸Œã€‚å¦‚æœå®ƒè¯´â€œæ²¡æœ‰â€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å…è®¸ç”¨æˆ·ä½¿ç”¨é‚£ä¸ªå¯†ç ã€‚ä½†å¦‚æœå®ƒè¯´â€œæ˜¯â€ï¼Œé‚£ä¹ˆä»–ä»¬å¯èƒ½æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªå·²ç»æ³„éœ²çš„å¯†ç ï¼Œæˆ–è€…ä»–ä»¬æœ‰ä¸€ä¸ªå®Œå…¨ä¸åŒçš„å¯†ç ï¼Œçº¯ç²¹æ˜¯å¶ç„¶åœ°å…·æœ‰ç›¸åŒçš„å“ˆå¸Œå€¼ï¼Œä½†æ²¡å…³ç³»ï¼›æˆ‘ä»¬ä¹Ÿå¯ä»¥ç¦æ­¢é‚£ä¸ªå¯†ç ã€‚ç›¸å…³ç”¨é€”æ˜¯ç”¨äºè¿‡æ»¤æ‰æ¶æ„ç½‘ç«™ã€‚URLç¼©çŸ­ç³»ç»Ÿbitly[ç”¨äºæ­¤ç›®çš„](http://word.bitly.com/post/28558800777/dablooms-an-open-source-scalable-counting-bloom)ã€‚å®ƒä¹Ÿè¢«å¹¿å‘Šç½‘ç»œä½¿ç”¨ï¼›è¿™é‡Œæœ‰ä¸€ä¸ª[æ¼”è®²](https://youtu.be/T3Bt9Tn6P5c?si=t8U33orccRCgkSw0&t=1277)ï¼ˆä»å¤§çº¦20åˆ†é’Ÿåˆ°å¤§çº¦45åˆ†é’Ÿçš„æ®µè½ï¼‰å…³äºè¿™ä¸ªè¯é¢˜ã€‚ä½†æœ‰æ—¶ï¼Œå¸ƒéš†è¿‡æ»¤å™¨å¯èƒ½è¿‡äºå†—ä½™ï¼Œæ­£å¦‚è¿™ç¯‡Cloudflareåšå®¢æ–‡ç« [è®¨è®ºçš„](https://blog.cloudflare.com/when-bloom-filters-dont-bloom/)â€¦â€¦
- en: 'Another example is in updating databases or memory stores. Suppose we have
    a database of records, which we update frequently. It is often more efficient
    to maintain a journal of changes: i.e., a list that sequentially records all the
    changes that have occurred. At some interval (say overnight), the journal is â€œflushedâ€,
    meaning all these changes are applied to the database proper. But that means every
    read operation has become highly inefficient, because it has to check the entire
    journal first (for updates) before accessing the database. Again, here we can
    use this faulty notion of a hash table: if the hash of the record locator says
    â€œnoâ€, then the record certainly hasnâ€™t been modified and we go directly to the
    database; if it says â€œyesâ€ then we have to check the journal.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªä¾‹å­æ˜¯åœ¨æ›´æ–°æ•°æ®åº“æˆ–å†…å­˜å­˜å‚¨æ—¶ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç»å¸¸æ›´æ–°çš„è®°å½•æ•°æ®åº“ã€‚ç»´æŠ¤ä¸€ä¸ªå˜åŒ–æ—¥å¿—é€šå¸¸æ›´æœ‰æ•ˆï¼šå³ï¼Œä¸€ä¸ªæŒ‰é¡ºåºè®°å½•æ‰€æœ‰å·²å‘ç”Ÿå˜åŒ–çš„åˆ—è¡¨ã€‚åœ¨æŸä¸ªé—´éš”ï¼ˆæ¯”å¦‚å¤œé—´ï¼‰ï¼Œæ—¥å¿—è¢«â€œåˆ·æ–°â€ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰è¿™äº›å˜åŒ–éƒ½åº”ç”¨åˆ°æ•°æ®åº“æœ¬èº«ã€‚ä½†è¿™æ„å‘³ç€æ¯ä¸ªè¯»å–æ“ä½œéƒ½å˜å¾—éå¸¸ä½æ•ˆï¼Œå› ä¸ºå®ƒå¿…é¡»é¦–å…ˆæ£€æŸ¥æ•´ä¸ªæ—¥å¿—ï¼ˆä»¥æŸ¥æ‰¾æ›´æ–°ï¼‰ç„¶åå†è®¿é—®æ•°æ®åº“ã€‚å†æ¬¡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªæœ‰ç¼ºé™·çš„å“ˆå¸Œè¡¨æ¦‚å¿µï¼šå¦‚æœè®°å½•å®šä½å™¨çš„å“ˆå¸Œå€¼è¯´â€œæ²¡æœ‰â€ï¼Œé‚£ä¹ˆè®°å½•è‚¯å®šæ²¡æœ‰è¢«ä¿®æ”¹ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è®¿é—®æ•°æ®åº“ï¼›å¦‚æœå®ƒè¯´â€œæœ‰â€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¿…é¡»æ£€æŸ¥æ—¥å¿—ã€‚
- en: We have already seen a simple example implementation of this idea earlier, when
    we used a single array, with modular arithmetic, to represent the set. When an
    element was not present in the array, we knew for a fact that it was definitely
    not present. When the array indicated an element was present, we couldnâ€™t be sure
    that what was present was the exact value we were looking for. To get around this
    uncertainty, we used chaining.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰å·²ç»çœ‹åˆ°äº†è¿™ä¸ªæƒ³æ³•çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹å®ç°ï¼Œå½“æ—¶æˆ‘ä»¬ä½¿ç”¨å•ä¸ªæ•°ç»„ï¼Œé€šè¿‡æ¨¡è¿ç®—æ¥è¡¨ç¤ºé›†åˆã€‚å½“ä¸€ä¸ªå…ƒç´ ä¸åœ¨æ•°ç»„ä¸­æ—¶ï¼Œæˆ‘ä»¬çŸ¥é“å®ƒè‚¯å®šä¸åœ¨ã€‚å½“æ•°ç»„æŒ‡ç¤ºä¸€ä¸ªå…ƒç´ å­˜åœ¨æ—¶ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šå­˜åœ¨çš„ç¡®å®æ˜¯æˆ‘ä»¬è¦æ‰¾çš„ç¡®åˆ‡å€¼ã€‚ä¸ºäº†å…‹æœè¿™ç§ä¸ç¡®å®šæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é“¾å¼æ“ä½œã€‚
- en: However, there is something else we could have done. Chaining costs both space
    (to store all the actual values) and time (to look through all the values). Suppose,
    instead, a bucket is only a Boolean value. This results in a slightly useful,
    but potentially very inaccurate, data structure; furthermore, it exhibits correlated
    failure tied to the modulus.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åšå…¶ä»–äº‹æƒ…ã€‚é“¾å¼æ“ä½œæ—¢æ¶ˆè€—ç©ºé—´ï¼ˆç”¨äºå­˜å‚¨æ‰€æœ‰å®é™…å€¼ï¼‰ä¹Ÿæ¶ˆè€—æ—¶é—´ï¼ˆç”¨äºéå†æ‰€æœ‰å€¼ï¼‰ã€‚å‡è®¾ï¼Œç›¸åï¼Œæ¡¶åªæ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ã€‚è¿™ä¼šå¯¼è‡´ä¸€ä¸ªç¨å¾®æœ‰ç”¨ä½†å¯èƒ½éå¸¸ä¸å‡†ç¡®çš„æ•°æ®ç»“æ„ï¼›æ­¤å¤–ï¼Œå®ƒè¿˜è¡¨ç°å‡ºä¸æ¨¡æ•°ç›¸å…³çš„æ•…éšœã€‚
- en: But suppose we have not only one array, but several! When an element is added
    to the set, it is added to each array; when checking for membership, every array
    is consulted. The set only answers affirmatively to membership if all the arrays
    do so.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å‡è®¾æˆ‘ä»¬ä¸ä»…æœ‰å•ä¸ªæ•°ç»„ï¼Œè€Œæ˜¯æœ‰å¤šä¸ªæ•°ç»„ï¼å½“å…ƒç´ è¢«æ·»åŠ åˆ°é›†åˆä¸­æ—¶ï¼Œå®ƒä¼šè¢«æ·»åŠ åˆ°æ¯ä¸ªæ•°ç»„ä¸­ï¼›åœ¨æ£€æŸ¥æˆå‘˜èµ„æ ¼æ—¶ï¼Œä¼šå’¨è¯¢æ¯ä¸ªæ•°ç»„ã€‚åªæœ‰å½“æ‰€æœ‰æ•°ç»„éƒ½ç¡®è®¤æ—¶ï¼Œé›†åˆæ‰ä¼šè‚¯å®šåœ°å›ç­”æˆå‘˜èµ„æ ¼ã€‚
- en: 'Naturally, using multiple arrays offers absolutely no advantage if the arrays
    are all the same size: since both insertion and lookup are deterministic, all
    will yield the same answer. However, there is a simple antidote to this: use different
    array sizes. In particular, by using array sizes that are relatively prime to
    one another, we minimize the odds of a clash (only hashes that are the product
    of all the array sizes will fool the array).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶åœ°ï¼Œå¦‚æœæ‰€æœ‰æ•°ç»„çš„å¤§å°éƒ½ç›¸åŒï¼Œä½¿ç”¨å¤šä¸ªæ•°ç»„ç»å¯¹æ²¡æœ‰ä¼˜åŠ¿ï¼šå› ä¸ºæ’å…¥å’ŒæŸ¥æ‰¾éƒ½æ˜¯ç¡®å®šæ€§çš„ï¼Œæ‰€ä»¥æ‰€æœ‰æ“ä½œéƒ½ä¼šå¾—å‡ºç›¸åŒçš„ç­”æ¡ˆã€‚ç„¶è€Œï¼Œæœ‰ä¸€ç§ç®€å•çš„å¯¹ç­–ï¼šä½¿ç”¨ä¸åŒçš„æ•°ç»„å¤§å°ã€‚ç‰¹åˆ«æ˜¯ï¼Œé€šè¿‡ä½¿ç”¨å½¼æ­¤äº’è´¨çš„æ•°ç»„å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥æœ€å°åŒ–å†²çªçš„æ¦‚ç‡ï¼ˆåªæœ‰æ‰€æœ‰æ•°ç»„å¤§å°çš„ä¹˜ç§¯çš„å“ˆå¸Œå€¼æ‰èƒ½æ¬ºéª—æ•°ç»„ï¼‰ã€‚
- en: This data structure, called a Bloom Filter, is a probabilistic data structure.
    Unlike our earlier set data structure, this one is not guaranteed to always give
    the right answer; but contrary to the [â˜› space-time tradeoff](glossary.html#%28elem._glossary-space-time._tradeoff%29),
    we save both space and time by changing the problem slightly to accept incorrect
    answers. If we know something about the distribution of hash values, and we have
    some acceptable bound of error, we can design hash table sizes so that with high
    probability, the Bloom Filter will lie within the acceptable error bounds.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ç§°ä¸ºå¸ƒéš†è¿‡æ»¤å™¨ï¼ˆBloom Filterï¼‰çš„æ•°æ®ç»“æ„æ˜¯ä¸€ä¸ªæ¦‚ç‡æ•°æ®ç»“æ„ã€‚ä¸æˆ‘ä»¬çš„æ—©æœŸé›†åˆæ•°æ®ç»“æ„ä¸åŒï¼Œè¿™ä¸ªç»“æ„å¹¶ä¸ä¿è¯æ€»æ˜¯ç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼›ä½†ä¸[â˜›ç©ºé—´-æ—¶é—´æƒè¡¡](glossary.html#%28elem._glossary-space-time._tradeoff%29)ç›¸åï¼Œæˆ‘ä»¬é€šè¿‡ç¨å¾®æ”¹å˜é—®é¢˜ä»¥æ¥å—é”™è¯¯ç­”æ¡ˆï¼Œä»è€ŒèŠ‚çœäº†ç©ºé—´å’Œæ—¶é—´ã€‚å¦‚æœæˆ‘ä»¬äº†è§£å“ˆå¸Œå€¼çš„åˆ†å¸ƒï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰å¯æ¥å—çš„é”™è¯¯ç•Œé™ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡å“ˆå¸Œè¡¨çš„å¤§å°ï¼Œä½¿å¾—å¸ƒéš†è¿‡æ»¤å™¨ä»¥é«˜æ¦‚ç‡ä½äºå¯æ¥å—çš„é”™è¯¯ç•Œé™å†…ã€‚
- en: 18.4.9Â Generalizing from Sets to Key-Values[ğŸ”—](#(part._.Generalizing_from_.Sets_to_.Key-.Values)
    "Link to here")
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.9 ä»é›†åˆåˆ°é”®å€¼å¯¹çš„æ³›åŒ–[ğŸ”—](#(part._.Generalizing_from_.Sets_to_.Key-.Values) "é“¾æ¥è‡³æ­¤")
- en: 'Above, we focused on sets: that is, a string effectively mapped to a Boolean
    value, indicating whether it was present or not. However, there are many settings
    where it is valuable to associate one value with another. For instance, given
    an identity number we might want to pull up a personâ€™s records; given a computerâ€™s
    name, we might want to retrieve its routing information; given a starâ€™s catalog
    entry, we might want its astronomical information. This kind of data structure
    is so ubiquitous that it has several names, some of which are more general and
    some implying specific implementations: key-value store, associative array, hash
    map, dictionary, etc.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯é›†åˆï¼šä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ªå­—ç¬¦ä¸²å®é™…ä¸Šæ˜ å°„åˆ°ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºå®ƒæ˜¯å¦å­˜åœ¨ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šè®¾ç½®ä¸­ï¼Œå°†ä¸€ä¸ªå€¼ä¸å¦ä¸€ä¸ªå€¼å…³è”æ˜¯æœ‰ä»·å€¼çš„ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªèº«ä»½å·ç ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ£€ç´¢ä¸€ä¸ªäººçš„è®°å½•ï¼›ç»™å®šä¸€ä¸ªè®¡ç®—æœºçš„åç§°ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ£€ç´¢å…¶è·¯ç”±ä¿¡æ¯ï¼›ç»™å®šä¸€é¢—æ˜Ÿçš„ç›®å½•æ¡ç›®ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦å…¶å¤©æ–‡å­¦ä¿¡æ¯ã€‚è¿™ç§æ•°æ®ç»“æ„å¦‚æ­¤æ™®éï¼Œä»¥è‡³äºå®ƒæœ‰å‡ ä¸ªåç§°ï¼Œå…¶ä¸­ä¸€äº›æ›´é€šç”¨ï¼Œä¸€äº›æš—ç¤ºç‰¹å®šçš„å®ç°ï¼šé”®å€¼å­˜å‚¨ã€å…³è”æ•°ç»„ã€å“ˆå¸Œè¡¨ã€å­—å…¸ç­‰ã€‚
- en: In general, the names â€œkey-valueâ€ and â€œdictionaryâ€ are useful because they suggest
    a behavioral interface. In contrast, associative array implies the use of arrays,
    and hash table suggests the use of an array (and of hashing). In fact, real systems
    use a variety of implementation strategies, including balanced binary search trees.
    The names â€œkey-valueâ€ and â€œdictionaryâ€ avoid commitment to a particular implementation.
    Here, too, â€œdictionaryâ€ evokes a common mental image of unique words that map
    to descriptions. The term â€œkey valueâ€ is even more technically useful because
    keys are meant to all be distinct (i.e., no two different key-value pairs can
    have the same key; alternatively, one key can map to only one value). This makes
    sense because we view this as a generalization of sets, so the keys are the set
    elements, which must necessarily have no duplicates; the values take the place
    of the Boolean.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œâ€œé”®å€¼â€å’Œâ€œå­—å…¸â€è¿™ä¸¤ä¸ªåç§°æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒä»¬æš—ç¤ºäº†ä¸€ä¸ªè¡Œä¸ºæ¥å£ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œâ€œå…³è”æ•°ç»„â€æš—ç¤ºäº†æ•°ç»„çš„ç”¨æ³•ï¼Œâ€œå“ˆå¸Œè¡¨â€æš—ç¤ºäº†æ•°ç»„çš„ç”¨æ³•ï¼ˆä»¥åŠå“ˆå¸Œï¼‰ã€‚å®é™…ä¸Šï¼ŒçœŸå®ç³»ç»Ÿä½¿ç”¨å„ç§å®ç°ç­–ç•¥ï¼ŒåŒ…æ‹¬å¹³è¡¡çš„äºŒå‰æœç´¢æ ‘ã€‚åç§°â€œé”®å€¼â€å’Œâ€œå­—å…¸â€é¿å…äº†å¯¹äºç‰¹å®šå®ç°çš„æ‰¿è¯ºã€‚åœ¨è¿™é‡Œï¼Œâ€œå­—å…¸â€ä¹Ÿå”¤èµ·äº†å¯¹å”¯ä¸€å•è¯æ˜ å°„åˆ°æè¿°çš„å¸¸è§å¿ƒç†å›¾åƒã€‚æœ¯è¯­â€œé”®å€¼â€ç”šè‡³æ›´æœ‰æŠ€æœ¯ä¸Šçš„å®ç”¨æ€§ï¼Œå› ä¸ºé”®éƒ½æ„å‘³ç€æ˜¯ä¸åŒçš„ï¼ˆå³ï¼Œä¸¤ä¸ªä¸åŒçš„é”®å€¼å¯¹ä¸èƒ½æœ‰ç›¸åŒçš„é”®ï¼›æˆ–è€…ï¼Œä¸€ä¸ªé”®åªèƒ½æ˜ å°„åˆ°ä¸€ä¸ªå€¼ï¼‰ã€‚è¿™å¾ˆæœ‰æ„ä¹‰ï¼Œå› ä¸ºæˆ‘ä»¬å°†å…¶è§†ä¸ºé›†åˆçš„æ¨å¹¿ï¼Œæ‰€ä»¥é”®æ˜¯é›†åˆå…ƒç´ ï¼Œå®ƒä»¬å¿…ç„¶æ²¡æœ‰é‡å¤ï¼›å€¼å–ä»£äº†å¸ƒå°”å€¼ã€‚
- en: 'To extend our set representation to handle a dictionary or key-value store,
    we need to make a few changes. First, we introduce the key-value representation:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æˆ‘ä»¬çš„é›†åˆè¡¨ç¤ºæ‰©å±•åˆ°å¤„ç†å­—å…¸æˆ–é”®å€¼å­˜å‚¨ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›ä¿®æ”¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥é”®å€¼è¡¨ç¤ºï¼š
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Each bucket is still an empty list, but we understand it to be a list of key-value
    pairs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¡¶ä»ç„¶æ˜¯ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œä½†æˆ‘ä»¬å°†å…¶ç†è§£ä¸ºé”®å€¼å¯¹çš„åˆ—è¡¨ã€‚
- en: Previously, we only had `is-in` to check whether an element was present in a
    set or not. That element is now the key, and we could have a similar function
    to check whether the key is present. However, we rarely want to know just that;
    in fact, because we already know the key, we usually want the associated value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰ï¼Œæˆ‘ä»¬åªæœ‰`is-in`æ¥æ£€æŸ¥ä¸€ä¸ªå…ƒç´ æ˜¯å¦å­˜åœ¨äºé›†åˆä¸­ã€‚ç°åœ¨ï¼Œè¿™ä¸ªå…ƒç´ æ˜¯é”®ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªç±»ä¼¼çš„åŠŸèƒ½æ¥æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¾ˆå°‘åªæƒ³çŸ¥é“è¿™ä¸€ç‚¹ï¼›äº‹å®ä¸Šï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»çŸ¥é“äº†é”®ï¼Œæˆ‘ä»¬é€šå¸¸æƒ³è¦å…³è”çš„å€¼ã€‚
- en: Therefore, we can just have this one function:We use Pyretâ€™s naming convention
    of `-now` to indicate that this result might change later.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦è¿™ä¸€ä¸ªåŠŸèƒ½ï¼šæˆ‘ä»¬ä½¿ç”¨Pyretçš„å‘½åçº¦å®š`-now`æ¥è¡¨ç¤ºè¿™ä¸ªç»“æœå¯èƒ½ä¼šç¨åæ”¹å˜ã€‚
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Of course, `getkv-now` may fail: the key may not be present. That is, it has
    become a partial function [[Partial Domains](partial-domains.html)]. We therefore
    have all the usual strategies for dealing with partial functions. Here, for simplicity
    we choose to return an error if the key is not present, but all the other strategies
    we discuss for handling partiality are valid (and often better in a robust implementation).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œ`getkv-now`å¯èƒ½ä¼šå¤±è´¥ï¼šé”®å¯èƒ½ä¸å­˜åœ¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå·²ç»æˆä¸ºä¸€ä¸ªéƒ¨åˆ†å‡½æ•° [[éƒ¨åˆ†åŸŸ](partial-domains.html)]ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ‰æ‰€æœ‰å¤„ç†éƒ¨åˆ†å‡½æ•°çš„å¸¸è§„ç­–ç•¥ã€‚åœ¨è¿™é‡Œï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨é”®ä¸å­˜åœ¨æ—¶è¿”å›ä¸€ä¸ªé”™è¯¯ï¼Œä½†æˆ‘ä»¬è®¨è®ºçš„æ‰€æœ‰å…¶ä»–å¤„ç†éƒ¨åˆ†æ€§çš„ç­–ç•¥éƒ½æ˜¯æœ‰æ•ˆçš„ï¼ˆå¹¶ä¸”åœ¨å¥å£®çš„å®ç°ä¸­é€šå¸¸æ›´å¥½ï¼‰ã€‚
- en: 'Similarly, we have:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This is the generalization of `insert`. However, `insert` had no reason to
    return an error: inserting an element twice was harmless. However, because keys
    must now be associated with only one value, insertion has to check whether the
    key is already present, and signal an error otherwise. In short, it is also partial.This
    is not partial due to a mathematical reason, but rather because of state: the
    same key may have been inserted previously.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ `insert` çš„ä¸€èˆ¬åŒ–ã€‚ç„¶è€Œï¼Œ`insert` æ²¡æœ‰ç†ç”±è¿”å›é”™è¯¯ï¼šæ’å…¥å…ƒç´ ä¸¤æ¬¡æ˜¯æ— å®³çš„ã€‚ä½†æ˜¯ï¼Œç”±äºé”®ç°åœ¨å¿…é¡»ä¸ä»…ä¸€ä¸ªå€¼ç›¸å…³è”ï¼Œæ’å…¥å¿…é¡»æ£€æŸ¥é”®æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦åˆ™å‘å‡ºé”™è¯¯ä¿¡å·ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå®ƒä¹Ÿæ˜¯éƒ¨åˆ†çš„ã€‚è¿™ä¸æ˜¯ç”±äºæ•°å­¦åŸå› è€Œéƒ¨åˆ†ï¼Œè€Œæ˜¯å› ä¸ºçŠ¶æ€ï¼šåŒä¸€ä¸ªé”®å¯èƒ½ä¹‹å‰å·²ç»è¢«æ’å…¥ã€‚
- en: 'Once we have agreed on this interface, getting a value is a natural extension
    of checking for membership:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬åŒæ„äº†è¿™ä¸ªæ¥å£ï¼Œè·å–å€¼å°±æ˜¯æ£€æŸ¥æˆå‘˜èµ„æ ¼çš„è‡ªç„¶æ‰©å±•ï¼š
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Having found the index, we look in the bucket for whether any key-value pair
    has the desired key. If it does, then we return the corresponding value. Otherwise,
    we error.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ç´¢å¼•åï¼Œæˆ‘ä»¬åœ¨æ¡¶ä¸­æŸ¥æ‰¾æ˜¯å¦æœ‰ä»»ä½•é”®å€¼å¯¹å…·æœ‰æ‰€éœ€çš„é”®ã€‚å¦‚æœæœ‰ï¼Œåˆ™è¿”å›ç›¸åº”çš„å€¼ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬æŠ¥é”™ã€‚
- en: 'Inserting a key-value pair similarly generalizes adding an element to the set:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å°†é”®å€¼å¯¹æ’å…¥åŒæ ·æ¨å¹¿åˆ°å‘é›†åˆæ·»åŠ å…ƒç´ ï¼š
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Once again, we check the bucket for whether the key is already present. If it
    is, we choose to halt with an error. Otherwise, we make the key-value pair and
    link it to the existing bucket contents, and modify the array to refer to the
    new list.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡æ£€æŸ¥æ¡¶ä¸­æ˜¯å¦å·²ç»å­˜åœ¨è¯¥é”®ã€‚å¦‚æœå­˜åœ¨ï¼Œæˆ‘ä»¬é€‰æ‹©é”™è¯¯åœæ­¢ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬åˆ›å»ºé”®å€¼å¯¹å¹¶å°†å…¶é“¾æ¥åˆ°ç°æœ‰çš„æ¡¶å†…å®¹ï¼Œå¹¶ä¿®æ”¹æ•°ç»„ä»¥å¼•ç”¨æ–°çš„åˆ—è¡¨ã€‚
- en: Exercise
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do the above pair of functions do all the necessary error-checking?
  id: totrans-120
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„è¿™å¯¹å‡½æ•°æ˜¯å¦è¿›è¡Œäº†æ‰€æœ‰å¿…è¦çš„é”™è¯¯æ£€æŸ¥ï¼Ÿ
- en: Exercise
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Above, `setkv-now` raises an error if a key already has a name associated with
    it. A natural variation is to instead override the associated value, so that the
    new value is now associated with that key. Modify the implementation to do that
    instead, and make sure you test it thoroughly! Note that you may need to modify
    the `KV` datatype also.
  id: totrans-123
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢ï¼Œ`setkv-now` å¦‚æœä¸€ä¸ªé”®å·²ç»ä¸ä¸€ä¸ªåç§°ç›¸å…³è”ï¼Œåˆ™ä¼šå¼•å‘é”™è¯¯ã€‚ä¸€ä¸ªè‡ªç„¶çš„å˜ä½“æ˜¯è¦†ç›–å…³è”çš„å€¼ï¼Œä½¿å¾—æ–°çš„å€¼ç°åœ¨ä¸è¯¥é”®ç›¸å…³è”ã€‚ä¿®æ”¹å®ç°ä»¥æ‰§è¡Œæ­¤æ“ä½œï¼Œå¹¶ç¡®ä¿æ‚¨å½»åº•æµ‹è¯•å®ƒï¼è¯·æ³¨æ„ï¼Œæ‚¨å¯èƒ½è¿˜éœ€è¦ä¿®æ”¹
    `KV` æ•°æ®ç±»å‹ã€‚
- en: 'This concludes our brief tour of sets (yet again!) and key-value stores or
    dictionaries. We have chosen to implement both using arrays, which required us
    to employ hashes. For more on string dictionaries, see the [Pyret documentation](https://www.pyret.org/docs/latest/string-dict.html).
    Observe that Pyret offers two kinds of dictionaries: one mutable (like we have
    shown here) and one (the default) functional.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å†æ¬¡ç»“æŸäº†æˆ‘ä»¬å¯¹é›†åˆï¼ˆä»¥åŠé”®å€¼å­˜å‚¨æˆ–å­—å…¸ï¼‰çš„ç®€è¦æ¸¸è§ˆã€‚æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨æ•°ç»„æ¥å®ç°ä¸¤è€…ï¼Œè¿™è¦æ±‚æˆ‘ä»¬ä½¿ç”¨å“ˆå¸Œã€‚æœ‰å…³å­—ç¬¦ä¸²å­—å…¸çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [Pyret
    æ–‡æ¡£](https://www.pyret.org/docs/latest/string-dict.html)ã€‚è¯·æ³¨æ„ï¼ŒPyret æä¾›ä¸¤ç§ç±»å‹çš„å­—å…¸ï¼šä¸€ç§å¯å˜ï¼ˆå¦‚æˆ‘ä»¬åœ¨æ­¤å¤„æ‰€ç¤ºï¼‰å’Œä¸€ç§ï¼ˆé»˜è®¤ï¼‰å‡½æ•°å¼ã€‚
- en: 18.4.1Â A Hash Function for Strings[ğŸ”—](#(part._hash-string) "Link to here")
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.1 å­—ç¬¦ä¸²å“ˆå¸Œå‡½æ•°[ğŸ”—](#(part._hash-string) "é“¾æ¥åˆ°æ­¤å¤„")
- en: As we have seen in [Converting Values to Ordered Values](orderability.html#%28part._hashing-values%29),
    we have multiple strategies for converting arbitrary values into numbers, which
    we will rely on here. Therefore, we could write this material around numbers alone.
    To make the examples more interesting, and to better illustrate some real-world
    issues, we will instead use strings. To hash them, we will use `hash-of`, defined
    there, which simply adds up a stringâ€™s code points.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨[å°†å€¼è½¬æ¢ä¸ºæœ‰åºå€¼](orderability.html#%28part._hashing-values%29)ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬æœ‰å¤šç§ç­–ç•¥å°†ä»»æ„å€¼è½¬æ¢ä¸ºæ•°å­—ï¼Œæˆ‘ä»¬å°†ä¾èµ–äºæ­¤ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»…å›´ç»•æ•°å­—ç¼–å†™è¿™äº›ææ–™ã€‚ä¸ºäº†ä½¿ç¤ºä¾‹æ›´æœ‰è¶£ï¼Œå¹¶æ›´å¥½åœ°è¯´æ˜ä¸€äº›ç°å®ä¸–ç•Œçš„é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å­—ç¬¦ä¸²ã€‚ä¸ºäº†å¯¹å®ƒä»¬è¿›è¡Œå“ˆå¸Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é‚£é‡Œå®šä¹‰çš„
    `hash-of`ï¼Œå®ƒåªæ˜¯å°†å­—ç¬¦ä¸²çš„ä»£ç ç‚¹ç›¸åŠ ã€‚
- en: We use this function for multiple reasons. First, it is sufficient to illustrate
    some of the consequences of hashing. Second, in practice, when built-in hashing
    does not suffice, we do write (more complex versions of) functions like it. And
    finally, because itâ€™s all laid bare, itâ€™s easy for us to experiment with.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡ºäºå¤šä¸ªåŸå› ä½¿ç”¨è¿™ä¸ªå‡½æ•°ã€‚é¦–å…ˆï¼Œå®ƒè¶³ä»¥è¯´æ˜ä¸€äº›å“ˆå¸Œçš„åæœã€‚å…¶æ¬¡ï¼Œåœ¨å®è·µä¸­ï¼Œå½“å†…ç½®å“ˆå¸Œä¸è¶³æ—¶ï¼Œæˆ‘ä»¬ç¡®å®ç¼–å†™äº†ï¼ˆæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼‰è¿™æ ·çš„å‡½æ•°ã€‚æœ€åï¼Œå› ä¸ºæ‰€æœ‰å†…å®¹éƒ½æš´éœ²å‡ºæ¥ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“è¿›è¡Œå®éªŒã€‚
- en: 18.4.2Â Sets from Hashing[ğŸ”—](#(part._.Sets_from_.Hashing) "Link to here")
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.2 ä»å“ˆå¸Œä¸­åˆ›å»ºé›†åˆ[ğŸ”—](#(part._.Sets_from_.Hashing) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Suppose we are given a set of strings. We can hash each element of that set.
    Each string is now mapped to a number. Each of these numbers is a member of the
    set; every other number is not a member of this set.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå­—ç¬¦ä¸²é›†åˆã€‚æˆ‘ä»¬å¯ä»¥å¯¹é›†åˆä¸­çš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå“ˆå¸Œå¤„ç†ã€‚ç°åœ¨æ¯ä¸ªå­—ç¬¦ä¸²éƒ½æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ã€‚è¿™äº›æ•°å­—ä¸­çš„æ¯ä¸€ä¸ªéƒ½æ˜¯é›†åˆçš„æˆå‘˜ï¼›å…¶ä»–ä»»ä½•æ•°å­—éƒ½ä¸æ˜¯è¿™ä¸ªé›†åˆçš„æˆå‘˜ã€‚
- en: 'Therefore, a simple representation is to just store this list of numbers. For
    instance, we can store the list `[list: "Hello", "World!", "ğŸ´â€â˜ ï¸"] as [list: 500,
    553, 195692]`.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 'å› æ­¤ï¼Œä¸€ç§ç®€å•çš„è¡¨ç¤ºæ–¹æ³•å°±æ˜¯åªå­˜å‚¨è¿™ä¸ªæ•°å­—åˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆ—è¡¨ `[list: "Hello", "World!", "ğŸ´â€â˜ ï¸"]` å­˜å‚¨ä¸º
    `[list: 500, 553, 195692]`ã€‚'
- en: 'Unfortunately, this does not help very much. Insertion can be done in constant
    time, but checking membership requires us to traverse the entire list, which takes
    linear time in the worst case. Alternatively, maybe we have some clever scheme
    that involves sorting the list. But note:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¹¸çš„æ˜¯ï¼Œè¿™å¹¶æ²¡æœ‰å¤ªå¤§çš„å¸®åŠ©ã€‚æ’å…¥å¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…å®Œæˆï¼Œä½†æ£€æŸ¥æˆå‘˜èµ„æ ¼éœ€è¦æˆ‘ä»¬éå†æ•´ä¸ªåˆ—è¡¨ï¼Œåœ¨æœ€åçš„æƒ…å†µä¸‹éœ€è¦çº¿æ€§æ—¶é—´ã€‚æˆ–è€…ï¼Œä¹Ÿè®¸æˆ‘ä»¬æœ‰ä¸€äº›æ¶‰åŠæ’åºåˆ—è¡¨çš„å·§å¦™æ–¹æ¡ˆã€‚ä½†è¯·æ³¨æ„ï¼š
- en: inserting the element can now take as much as linear time; or,
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ’å…¥å…ƒç´ ç°åœ¨å¯èƒ½éœ€è¦çº¿æ€§æ—¶é—´ï¼›æˆ–è€…ï¼Œ
- en: we store the elements as a tree instead of a list, but then
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å…ƒç´ å­˜å‚¨ä¸ºæ ‘è€Œä¸æ˜¯åˆ—è¡¨ï¼Œä½†è¿™æ ·
- en: we have to make sure the tree is balanced, so
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»ç¡®ä¿æ ‘æ˜¯å¹³è¡¡çš„ï¼Œæ‰€ä»¥
- en: we will have essentially reconstructed the BBST.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®é™…ä¸Šå·²ç»é‡å»ºäº†äºŒå‰æœç´¢æ ‘ï¼ˆBBSTï¼‰ã€‚
- en: In other words, we are recapitulating the discussion from [Representing Sets
    as Lists](sets-from-lists.html) and [Making Sets Grow on Trees](sets-from-trees.html).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æ­£åœ¨å›é¡¾[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)å’Œ[åœ¨æ ‘ä¸Šæ„å»ºé›†åˆ](sets-from-trees.html)çš„è®¨è®ºã€‚
- en: 'Notice that the problem here is traversal: if we have to visit more than a
    constant number of elements, we have probably not improved anything over the BBST.
    So, given a hash, how can we perform only a constant amount of work? For that,
    lists and trees donâ€™t work: they both require at least some amount of (non-constant)
    traversal to get to an arbitrary element. Instead we need a different data structureâ€¦'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè¿™é‡Œçš„é—®é¢˜æ˜¯éå†ï¼šå¦‚æœæˆ‘ä»¬å¿…é¡»è®¿é—®è¶…è¿‡å¸¸æ•°ä¸ªå…ƒç´ ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯èƒ½å¹¶æ²¡æœ‰æ¯” BBST æœ‰æ‰€æ”¹è¿›ã€‚æ‰€ä»¥ï¼Œç»™å®šä¸€ä¸ªå“ˆå¸Œå€¼ï¼Œæˆ‘ä»¬å¦‚ä½•åªåšå¸¸æ•°é‡çš„å·¥ä½œï¼Ÿä¸ºæ­¤ï¼Œåˆ—è¡¨å’Œæ ‘éƒ½ä¸é€‚ç”¨ï¼šå®ƒä»¬éƒ½éœ€è¦è‡³å°‘ä¸€äº›ï¼ˆéå¸¸æ•°ï¼‰éå†æ¥åˆ°è¾¾ä»»æ„å…ƒç´ ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸åŒçš„æ•°æ®ç»“æ„â€¦
- en: 18.4.3Â Arrays[ğŸ”—](#(part._.Arrays) "Link to here")
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.3 æ•°ç»„[ğŸ”—](#(part._.Arrays) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Arrays are another linear data structure, like lists. There are two key differences
    between lists and arrays that reflect each oneâ€™s strength and weakness.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ç»„æ˜¯å¦ä¸€ç§çº¿æ€§æ•°æ®ç»“æ„ï¼Œå°±åƒåˆ—è¡¨ä¸€æ ·ã€‚åˆ—è¡¨å’Œæ•°ç»„ä¹‹é—´æœ‰ä¸¤ä¸ªå…³é”®çš„åŒºåˆ«ï¼Œåæ˜ äº†å„è‡ªçš„ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚
- en: The main benefit to arrays is that we can access any element in the array in
    constant time. This is in contrast to lists where, to get to the \(n\)th element,
    we have to first traverse the previous \(n-1\) elements (using successive `rest`s).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ç»„çš„ä¸»è¦å¥½å¤„æ˜¯æˆ‘ä»¬å¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…è®¿é—®æ•°ç»„ä¸­çš„ä»»ä½•å…ƒç´ ã€‚è¿™ä¸åˆ—è¡¨å½¢æˆå¯¹æ¯”ï¼Œåœ¨åˆ—è¡¨ä¸­ï¼Œè¦åˆ°è¾¾ç¬¬ \(n\) ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆéå†å‰é¢çš„ \(n-1\)
    ä¸ªå…ƒç´ ï¼ˆä½¿ç”¨è¿ç»­çš„ `rest`ï¼‰ã€‚
- en: However, this benefit comes at a cost. The reason arrays can support constant-time
    access is because the size of an array is fixed at creation time. Thus, while
    we can keep extending a list using link, we cannot grow the size of an array â€œin
    placeâ€; rather, we must make a new array and copy the entire arrayâ€™s content into
    the new array, which takes linear time. (We can do a better job of this by using
    [Halloween Analysis](amortized-analysis.html), but there is no real free ride.)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§å¥½å¤„æ˜¯æœ‰ä»£ä»·çš„ã€‚æ•°ç»„èƒ½å¤Ÿæ”¯æŒå¸¸æ•°æ—¶é—´è®¿é—®çš„åŸå› æ˜¯æ•°ç»„çš„å°ºå¯¸åœ¨åˆ›å»ºæ—¶æ˜¯å›ºå®šçš„ã€‚å› æ­¤ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥é€šè¿‡é“¾æ¥æ¥æ‰©å±•åˆ—è¡¨ï¼Œä½†æˆ‘ä»¬ä¸èƒ½â€œå°±åœ°â€å¢é•¿æ•°ç»„çš„å°ºå¯¸ï¼›ç›¸åï¼Œæˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°ç»„ï¼Œå¹¶å°†æ•´ä¸ªæ•°ç»„çš„å†…å®¹å¤åˆ¶åˆ°æ–°æ•°ç»„ä¸­ï¼Œè¿™éœ€è¦çº¿æ€§æ—¶é—´ã€‚ï¼ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨[ä¸‡åœ£èŠ‚åˆ†æ](amortized-analysis.html)åšå¾—æ›´å¥½ï¼Œä½†è¿™å¹¶ä¸æ˜¯çœŸæ­£çš„å…è´¹ä¹‹æ—…ã€‚ï¼‰
- en: The arrays in Pyret are [documented here](https://www.pyret.org/docs/latest/arrays.html).
    While not necessary in principle, it is conventional to think of arrays as data
    structures that support mutation, and that is how we will use them here.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Pyret ä¸­çš„æ•°ç»„åœ¨[è¿™é‡Œ](https://www.pyret.org/docs/latest/arrays.html)æœ‰æ–‡æ¡£è¯´æ˜ã€‚è™½ç„¶åœ¨åŸåˆ™ä¸Šä¸æ˜¯å¿…è¦çš„ï¼Œä½†ä¼ ç»Ÿä¸Šè®¤ä¸ºæ•°ç»„æ˜¯æ”¯æŒå˜åŠ¨çš„æ•°æ®ç»“æ„ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¹Ÿå°†è¿™æ ·ä½¿ç”¨å®ƒä»¬ã€‚
- en: 18.4.4Â Sets from Hashing and Arrays[ğŸ”—](#(part._hash-tables) "Link to here")
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.4 ä»å“ˆå¸Œå’Œæ•°ç»„æ„å»ºé›†åˆ[ğŸ”—](#(part._hash-tables) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Okay, so now we have a strategy. When we want to insert a string into the set,
    we compute its hash, go to the corresponding location in the array, and record
    the presence of that string. If we want to check for membership, we similarly
    compute its hash and see whether the corresponding location has been set. Traditionally,
    each location in the array is called a bucket, and this data structure is called
    a hashtable.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªç­–ç•¥ã€‚å½“æˆ‘ä»¬æƒ³è¦å°†ä¸€ä¸ªå­—ç¬¦ä¸²æ’å…¥åˆ°é›†åˆä¸­æ—¶ï¼Œæˆ‘ä»¬è®¡ç®—å…¶å“ˆå¸Œå€¼ï¼Œå‰å¾€æ•°ç»„ä¸­çš„ç›¸åº”ä½ç½®ï¼Œå¹¶è®°å½•è¯¥å­—ç¬¦ä¸²çš„å­˜åœ¨ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦æ£€æŸ¥æˆå‘˜èµ„æ ¼ï¼Œæˆ‘ä»¬åŒæ ·è®¡ç®—å…¶å“ˆå¸Œå€¼ï¼Œçœ‹çœ‹ç›¸åº”çš„ä½ç½®æ˜¯å¦å·²è¢«è®¾ç½®ã€‚ä¼ ç»Ÿä¸Šï¼Œæ•°ç»„ä¸­çš„æ¯ä¸ªä½ç½®è¢«ç§°ä¸ºæ¡¶ï¼Œè¿™ç§æ•°æ®ç»“æ„è¢«ç§°ä¸ºå“ˆå¸Œè¡¨ã€‚
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Observe that if this were to work, we would have constant time insertion and
    membership checking. Unfortunately, two things make this plan untenable in general.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿåˆ°ï¼Œå¦‚æœè¿™èƒ½è¡Œå¾—é€šï¼Œæˆ‘ä»¬å°†æœ‰æ’å®šæ—¶é—´çš„æ’å…¥å’Œæˆå‘˜èµ„æ ¼æ£€æŸ¥ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæœ‰ä¸¤ä»¶äº‹ä½¿å¾—è¿™ä¸ªè®¡åˆ’åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ä¸å¯è¡Œã€‚
- en: 18.4.5Â Collisions[ğŸ”—](#(part._.Collisions) "Link to here")
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.5Â å†²çª[ğŸ”—](#(part._.Collisions) "é“¾æ¥è‡³æ­¤")
- en: First, our choice of hash function. For the above scheme to work, two different
    strings have to map to two different locations.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬çš„å“ˆå¸Œå‡½æ•°é€‰æ‹©ã€‚ä¸ºäº†ä½¿ä¸Šè¿°æ–¹æ¡ˆç”Ÿæ•ˆï¼Œä¸¤ä¸ªä¸åŒçš„å­—ç¬¦ä¸²å¿…é¡»æ˜ å°„åˆ°ä¸¤ä¸ªä¸åŒçš„ä½ç½®ã€‚
- en: Do Now!
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç°åœ¨è¡ŒåŠ¨ï¼
- en: ''
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is the above hash function invertible?
  id: totrans-151
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„å“ˆå¸Œå‡½æ•°å¯é€†å—ï¼Ÿ
- en: 'We just need to find two strings that have the same hash. Given the definition
    of `hash-of`, itâ€™s easy to see that any rearrangement of the letters produces
    the same hash:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªéœ€è¦æ‰¾åˆ°ä¸¤ä¸ªå…·æœ‰ç›¸åŒå“ˆå¸Œå€¼çš„å­—ç¬¦ä¸²ã€‚æ ¹æ®`hash-of`çš„å®šä¹‰ï¼Œå¾ˆå®¹æ˜“çœ‹å‡ºä»»ä½•å­—æ¯çš„é‡æ–°æ’åˆ—éƒ½ä¼šäº§ç”Ÿç›¸åŒçš„å“ˆå¸Œå€¼ï¼š
- en: '|'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124;'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '[PRE20]'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '&#124;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '|'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '|'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124;'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '[PRE22]'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '&#124;'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;'
- en: '|'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE23]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '|'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Similarly, this test suite passes:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œè¿™ä¸ªæµ‹è¯•å¥—ä»¶é€šè¿‡ï¼š
- en: '[PRE24]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: When multiple values hash to the same location, we call this a hash collision.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¤šä¸ªå€¼å“ˆå¸Œåˆ°åŒä¸€ä½ç½®æ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå“ˆå¸Œå†²çªã€‚
- en: 'Hash-collisions are problematic! With the above hash function, we get:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆå¸Œå†²çªæ˜¯æœ‰é—®é¢˜çš„ï¼ä½¿ç”¨ä¸Šè¿°å“ˆå¸Œå‡½æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: where two of these tests are desirable but the third is definitely not.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸¤ä¸ªæµ‹è¯•æ˜¯å¯å–çš„ï¼Œä½†ç¬¬ä¸‰ä¸ªåˆ™ç»å¯¹ä¸å¯å–ã€‚
- en: Note that collisions are virtually inevitable. If we have uniformly distributed
    data, then collisions show up sooner than we might expect.This follows from the
    reasoning behind what is known as the [birthday problem](http://en.wikipedia.org/wiki/Birthday_problem),
    commonly presented as how many people need to be in a room before the likelihood
    that two of them share a birthday exceeds some percentage. For the likelihood
    to exceed half we need just 23 people! Therefore, it is wise to prepare for the
    possibility of collisions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå†²çªå‡ ä¹æ˜¯ä¸å¯é¿å…çš„ã€‚å¦‚æœæˆ‘ä»¬æœ‰å‡åŒ€åˆ†å¸ƒçš„æ•°æ®ï¼Œé‚£ä¹ˆå†²çªçš„å‡ºç°ä¼šæ¯”æˆ‘ä»¬é¢„æœŸçš„è¦æ—©ã€‚è¿™æºäºæ‰€è°“çš„[ç”Ÿæ—¥é—®é¢˜](http://en.wikipedia.org/wiki/Birthday_problem)èƒŒåçš„æ¨ç†ï¼Œé€šå¸¸ä»¥åœ¨æˆ¿é—´é‡Œæœ‰å¤šå°‘äººä¹‹å‰ï¼Œä¸¤äººå…±äº«ç”Ÿæ—¥çš„å¯èƒ½æ€§è¶…è¿‡æŸä¸ªç™¾åˆ†æ¯”çš„ä¾‹å­æ¥å±•ç¤ºã€‚ä¸ºäº†ä½¿å¯èƒ½æ€§è¶…è¿‡ä¸€åŠï¼Œåªéœ€è¦23ä¸ªäººï¼å› æ­¤ï¼Œä¸ºå†²çªçš„å¯èƒ½æ€§åšå¥½å‡†å¤‡æ˜¯æ˜æ™ºçš„ã€‚
- en: The key is to know something about the distribution of hash values. For instance,
    if we knew our hash values are all multiples of 10, then using a table size of
    10 would be a terrible idea (because all elements would hash to the same bucket,
    turning our hash table into a list). In practice, it is common to use uncommon
    prime numbers as the table size, since a random value is unlikely to have it as
    a divisor. This does not yield a theoretical improvement (unless you can make
    certain assumptions about the input, or work through the math very carefully),
    but it works well in practice.In particular, since the typical hashing function
    uses memory addresses for objects on the heap, and on most systems these addresses
    are multiples of 4, using a prime like 31 is often a fairly good bet.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®æ˜¯è¦äº†è§£å“ˆå¸Œå€¼çš„åˆ†å¸ƒæƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬çš„å“ˆå¸Œå€¼éƒ½æ˜¯10çš„å€æ•°ï¼Œé‚£ä¹ˆä½¿ç”¨å¤§å°ä¸º10çš„è¡¨å°†æ˜¯ä¸€ä¸ªç³Ÿç³•çš„ä¸»æ„ï¼ˆå› ä¸ºæ‰€æœ‰å…ƒç´ éƒ½ä¼šå“ˆå¸Œåˆ°åŒä¸€ä¸ªæ¡¶ä¸­ï¼Œå°†æˆ‘ä»¬çš„å“ˆå¸Œè¡¨å˜æˆä¸€ä¸ªåˆ—è¡¨ï¼‰ã€‚åœ¨å®è·µä¸­ï¼Œé€šå¸¸ä½¿ç”¨ä¸å¸¸è§çš„è´¨æ•°ä½œä¸ºè¡¨çš„å¤§å°ï¼Œå› ä¸ºéšæœºå€¼ä¸å¤ªå¯èƒ½æˆä¸ºå…¶é™¤æ•°ã€‚è¿™å¹¶ä¸å¸¦æ¥ç†è®ºä¸Šçš„æ”¹è¿›ï¼ˆé™¤éä½ å¯ä»¥å¯¹è¾“å…¥åšå‡ºæŸäº›å‡è®¾ï¼Œæˆ–è€…éå¸¸ä»”ç»†åœ°å¤„ç†æ•°å­¦é—®é¢˜ï¼‰ï¼Œä½†åœ¨å®è·µä¸­æ•ˆæœå¾ˆå¥½ã€‚ç‰¹åˆ«æ˜¯ï¼Œç”±äºå…¸å‹çš„å“ˆå¸Œå‡½æ•°ä½¿ç”¨å †ä¸Šå¯¹è±¡çš„å†…å­˜åœ°å€ï¼Œè€Œåœ¨å¤§å¤šæ•°ç³»ç»Ÿä¸­è¿™äº›åœ°å€æ˜¯4çš„å€æ•°ï¼Œä½¿ç”¨31è¿™æ ·çš„è´¨æ•°é€šå¸¸æ˜¯ä¸€ä¸ªç›¸å½“å¥½çš„é€‰æ‹©ã€‚
- en: While collisions are probabilistic, and depend on the choice of hash function,
    we have an even more fundamental and unavoidable reason for collisions. We have
    to store an array of the largest possible hash size. However, not only can hash
    values be very large (try to run `insert("ğŸ´â€â˜ ï¸")` and see what happens), there
    isnâ€™t even an a priori limit to the size of a hash. This fundamentally flies in
    the face of arrays, which must have a fixed size.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å†²çªæ˜¯æ¦‚ç‡æ€§çš„ï¼Œå¹¶ä¸”ä¾èµ–äºå“ˆå¸Œå‡½æ•°çš„é€‰æ‹©ï¼Œä½†æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªæ›´åŸºæœ¬ä¸”ä¸å¯é¿å…çš„å†²çªåŸå› ã€‚æˆ‘ä»¬å¿…é¡»å­˜å‚¨ä¸€ä¸ªå¯èƒ½çš„æœ€å¤§å“ˆå¸Œå¤§å°çš„æ•°ç»„ã€‚ç„¶è€Œï¼Œå“ˆå¸Œå€¼å¯ä»¥éå¸¸å¤§ï¼ˆå°è¯•è¿è¡Œ`insert("ğŸ´â€â˜ ï¸")`å¹¶çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆï¼‰ï¼Œç”šè‡³å“ˆå¸Œçš„å¤§å°ä¹Ÿæ²¡æœ‰å…ˆéªŒçš„é™åˆ¶ã€‚è¿™ä»æ ¹æœ¬ä¸Šä¸æ•°ç»„ç›¸çŸ›ç›¾ï¼Œå› ä¸ºæ•°ç»„å¿…é¡»æœ‰å›ºå®šçš„å¤§å°ã€‚
- en: 'To handle arbitrarily large values, we:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¤„ç†ä»»æ„å¤§çš„å€¼ï¼Œæˆ‘ä»¬ï¼š
- en: use an array size that is reasonable given our memory constraints
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è€ƒè™‘åˆ°æˆ‘ä»¬çš„å†…å­˜é™åˆ¶çš„åˆç†å¤§å°çš„æ•°ç»„
- en: use the remainder of the hash relative to the arrayâ€™s size to find the bucket
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å“ˆå¸Œç›¸å¯¹äºæ•°ç»„å¤§å°çš„ä½™æ•°æ¥æŸ¥æ‰¾æ¡¶
- en: 'That is:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£å°±æ˜¯ï¼š
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This addresses the second problem: we can also store the pirate flag:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è§£å†³äº†ç¬¬äºŒä¸ªé—®é¢˜ï¼šæˆ‘ä»¬è¿˜å¯ä»¥å­˜å‚¨æµ·ç›—æ——å¸œï¼š
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Observe, however, we have simply created yet another source of collisions:
    the remainder computation. If we have 10 buckets, then the hashes 5, 15, 25, 35,
    â€¦ all refer to the same bucket. Thus, there are two sources of collision, and
    we have to deal with them both.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬åªæ˜¯åˆåˆ›é€ äº†ä¸€ä¸ªå†²çªçš„æ¥æºï¼šä½™æ•°è®¡ç®—ã€‚å¦‚æœæˆ‘ä»¬æœ‰10ä¸ªæ¡¶ï¼Œé‚£ä¹ˆå“ˆå¸Œå€¼5ã€15ã€25ã€35ã€â€¦â€¦éƒ½æŒ‡å‘åŒä¸€ä¸ªæ¡¶ã€‚å› æ­¤ï¼Œæœ‰ä¸¤ä¸ªå†²çªæ¥æºï¼Œæˆ‘ä»¬å¿…é¡»å¤„ç†å®ƒä»¬ä¸¤ä¸ªã€‚
- en: 18.4.6Â Resolving Collisions[ğŸ”—](#(part._.Resolving_.Collisions) "Link to here")
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.6 è§£å†³å†²çª[ğŸ”—](#(part._.Resolving_.Collisions) "é“¾æ¥è‡³æ­¤")
- en: Surprisingly or disappointingly, we have a very simple solution to the collision
    problems. Each bucket is not a single Boolean value, but rather a list of the
    actual values that hashed to that bucket. Then, we just check for membership in
    that list.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: æƒŠè®¶æˆ–å¤±æœ›çš„æ˜¯ï¼Œæˆ‘ä»¬å¯¹å†²çªé—®é¢˜æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„è§£å†³æ–¹æ¡ˆã€‚æ¯ä¸ªæ¡¶ä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„å¸ƒå°”å€¼ï¼Œè€Œæ˜¯ä¸€ç³»åˆ—å®é™…å€¼ï¼Œè¿™äº›å€¼è¢«å“ˆå¸Œåˆ°è¯¥æ¡¶ã€‚ç„¶åï¼Œæˆ‘ä»¬åªéœ€æ£€æŸ¥è¯¥åˆ—è¡¨ä¸­çš„æˆå‘˜èµ„æ ¼ã€‚
- en: 'First, we will abstract over finding the bucket number in `insert` and `is-in`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†æŠ½è±¡åœ°å¤„ç†åœ¨`insert`å’Œ`is-in`ä¸­æŸ¥æ‰¾æ¡¶å·çš„é—®é¢˜ï¼š
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we change what is held in each bucket: not a Boolean, but rather a list
    of the actual strings:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ”¹å˜æ¯ä¸ªæ¡¶ä¸­å­˜å‚¨çš„å†…å®¹ï¼šä¸æ˜¯å¸ƒå°”å€¼ï¼Œè€Œæ˜¯ä¸€ç³»åˆ—å®é™…çš„å­—ç¬¦ä¸²ï¼š
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we can write the more nuanced membership checker:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç¼–å†™æ›´ç»†è‡´çš„æˆå‘˜æ£€æŸ¥å™¨ï¼š
- en: '[PRE30]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Similarly, when inserting, we first make sure the element isnâ€™t already there
    (to avoid the complexity problems caused by having duplicates), and only then
    insert it:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œåœ¨æ’å…¥æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®ä¿å…ƒç´ ä¸åœ¨é‚£é‡Œï¼ˆä»¥é¿å…é‡å¤å¼•èµ·çš„å¤æ‚æ€§é—®é¢˜ï¼‰ï¼Œç„¶åæ‰æ’å…¥ï¼š
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now our tests pass as intended:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„æµ‹è¯•æŒ‰é¢„æœŸé€šè¿‡ï¼š
- en: '[PRE32]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 18.4.7Â Complexity[ğŸ”—](#(part._hash-comp) "Link to here")
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.7 å¤æ‚åº¦[ğŸ”—](#(part._hash-comp) "é“¾æ¥è‡³æ­¤")
- en: 'Now we have yet another working implementation for (some primitives of) sets.
    The use of arrays supposedly enables us to get constant-time complexity. Yet we
    should feel at least some discomfort. After all, the constant time applied when
    the arrays contained only Boolean values. However, that solution was weak in two
    ways: it could not handle hash-collisions by non-invertible hash functions, and
    it required potentially enormous arrays. If we relaxed either assumption, the
    implementation was simply wrong, in that it was easily fooled by values that caused
    collisions either through hashing or through computing the remainder.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬åˆæœ‰äº†ä¸€ä¸ªï¼ˆæŸäº›åŸå§‹çš„ï¼‰é›†åˆçš„å·¥ä½œå®ç°ã€‚ä½¿ç”¨æ•°ç»„æ®è¯´å¯ä»¥ä½¿æˆ‘ä»¬è·å¾—å¸¸æ•°æ—¶é—´å¤æ‚åº¦ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è‡³å°‘åº”è¯¥æ„Ÿåˆ°ä¸€äº›ä¸é€‚ã€‚æ¯•ç«Ÿï¼Œå½“æ•°ç»„åªåŒ…å«å¸ƒå°”å€¼æ—¶ï¼Œåº”ç”¨çš„æ˜¯å¸¸æ•°æ—¶é—´ã€‚ç„¶è€Œï¼Œé‚£ä¸ªè§£å†³æ–¹æ¡ˆæœ‰ä¸¤ä¸ªå¼±ç‚¹ï¼šå®ƒä¸èƒ½é€šè¿‡ä¸å¯é€†çš„å“ˆå¸Œå‡½æ•°å¤„ç†å“ˆå¸Œå†²çªï¼Œå¹¶ä¸”éœ€è¦å¯èƒ½å·¨å¤§çš„æ•°ç»„ã€‚å¦‚æœæˆ‘ä»¬æ”¾å®½ä»»ä½•ä¸€ä¸ªå‡è®¾ï¼Œå®ç°å°±ç®€å•åœ°é”™è¯¯äº†ï¼Œå› ä¸ºå®ƒå¾ˆå®¹æ˜“è¢«é€šè¿‡å“ˆå¸Œæˆ–è®¡ç®—ä½™æ•°å¼•èµ·çš„å†²çªå€¼æ¬ºéª—ã€‚
- en: 'The solution we have shown above is called hash chaining, where â€œchainâ€ refers
    to the list stored in each bucket. The benefit of hash-chaining is that insertion
    can still be constant-time: it takes a constant amount of time to find a bucket,
    and inserting can be as cheap as link. Of course, this assumes that we donâ€™t mind
    duplicates; otherwise we will pay the same price we saw earlier in [Representing
    Sets as Lists](sets-from-lists.html). But lookup takes time linear in the size
    of the bucket (which, with duplicates, could be arbitrarily larger relative to
    the number of distinct elements). And even if we check for duplicates, we run
    the risk that most or even all the elements could end up in the same bucket (e.g.,
    suppose the elements are `"Where"`, `"Weird"`, `"Wired"`, `"Whine"`). In that
    case, our sophisticated implementation reduces to the list-based representation
    and its complexity!'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸Šé¢å±•ç¤ºçš„è§£å†³æ–¹æ¡ˆè¢«ç§°ä¸ºå“ˆå¸Œé“¾ï¼Œå…¶ä¸­â€œé“¾â€æŒ‡çš„æ˜¯æ¯ä¸ªæ¡¶ä¸­å­˜å‚¨çš„åˆ—è¡¨ã€‚å“ˆå¸Œé“¾çš„å¥½å¤„æ˜¯æ’å…¥ä»ç„¶å¯ä»¥æ˜¯å¸¸æ•°æ—¶é—´ï¼šæ‰¾åˆ°æ¡¶éœ€è¦å¸¸æ•°æ—¶é—´ï¼Œæ’å…¥å¯ä»¥åƒé“¾æ¥ä¸€æ ·ä¾¿å®œã€‚å½“ç„¶ï¼Œè¿™å‡è®¾æˆ‘ä»¬ä¸ä»‹æ„é‡å¤é¡¹ï¼›å¦åˆ™ï¼Œæˆ‘ä»¬å°†ä»˜å‡ºæˆ‘ä»¬åœ¨[å°†é›†åˆè¡¨ç¤ºä¸ºåˆ—è¡¨](sets-from-lists.html)ä¸­çœ‹åˆ°çš„ç›¸åŒä»£ä»·ã€‚ä½†æ˜¯æŸ¥æ‰¾çš„æ—¶é—´ä¸æ¡¶çš„å¤§å°æˆçº¿æ€§å…³ç³»ï¼ˆè€ƒè™‘åˆ°é‡å¤é¡¹ï¼Œè¿™å¯èƒ½ä¸ä¸åŒå…ƒç´ çš„æ•°é‡ä¸æˆæ¯”ä¾‹åœ°å¤§ï¼‰ã€‚å³ä½¿æˆ‘ä»¬æ£€æŸ¥é‡å¤é¡¹ï¼Œæˆ‘ä»¬ä¹Ÿé¢ä¸´å¤§å¤šæ•°ç”šè‡³æ‰€æœ‰å…ƒç´ æœ€ç»ˆéƒ½è½å…¥åŒä¸€ä¸ªæ¡¶çš„é£é™©ï¼ˆä¾‹å¦‚ï¼Œå‡è®¾å…ƒç´ æ˜¯`"Where"`ã€`"Weird"`ã€`"Wired"`ã€`"Whine"`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¤æ‚çš„å®ç°ç®€åŒ–ä¸ºåŸºäºåˆ—è¡¨çš„è¡¨ç¤ºåŠå…¶å¤æ‚æ€§ï¼
- en: Thereâ€™s an additional subtlety here. When we check membership of the string
    in the list of strings, we have to consider the cost of comparing each pair of
    strings. In the worst case, that is proportional to the length of the shorter
    string. Usually this is bounded by a small constant, but one can imagine settings
    where this is not guaranteed to be true. However, this same cost has to be borne
    by all set implementations; it is not a new complexity introduced here.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„å¾®å¦™ä¹‹å¤„ã€‚å½“æˆ‘ä»¬æ£€æŸ¥å­—ç¬¦ä¸²åœ¨å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æˆå‘˜èµ„æ ¼æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘æ¯”è¾ƒæ¯ä¸€å¯¹å­—ç¬¦ä¸²çš„æˆæœ¬ã€‚åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸è¾ƒçŸ­å­—ç¬¦ä¸²çš„é•¿åº¦æˆæ¯”ä¾‹ã€‚é€šå¸¸è¿™è¢«é™åˆ¶åœ¨ä¸€ä¸ªå°çš„å¸¸æ•°å†…ï¼Œä½†å¯ä»¥æƒ³è±¡å‡ºè¿™ç§æˆæœ¬ä¸ä¿è¯æ€»æ˜¯æˆç«‹çš„ç¯å¢ƒã€‚ç„¶è€Œï¼Œæ‰€æœ‰é›†åˆå®ç°éƒ½å¿…é¡»æ‰¿æ‹…è¿™ç§ç›¸åŒçš„æˆæœ¬ï¼›è¿™ä¸æ˜¯è¿™é‡Œå¼•å…¥çš„æ–°å¤æ‚æ€§ã€‚
- en: Thus, in theory, hash-based sets can support insertion and membership in as
    little as constant time, and (ignoring the cost of string comparisons) as much
    as linear time, where â€œlinearâ€ has the same caveats about duplicates as the list-based
    representation. In many casesâ€”<wbr>depending on the nature of the data and parameters
    set for the arrayâ€”<wbr>they can be much closer to constant time. As a result,
    they tend to be very popular in practice.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä»ç†è®ºä¸Šè®²ï¼ŒåŸºäºå“ˆå¸Œçš„é›†åˆå¯ä»¥åœ¨å¸¸æ•°æ—¶é—´å†…æ”¯æŒæ’å…¥å’Œæˆå‘˜èµ„æ ¼ï¼Œå¹¶ä¸”ï¼ˆå¿½ç•¥å­—ç¬¦ä¸²æ¯”è¾ƒçš„æˆæœ¬ï¼‰æœ€å¤šçº¿æ€§æ—¶é—´ï¼Œå…¶ä¸­â€œçº¿æ€§â€å…·æœ‰ä¸åŸºäºåˆ—è¡¨è¡¨ç¤ºç›¸åŒçš„å…³äºé‡å¤é¡¹çš„è­¦å‘Šã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹â€”â€”<wbr>å–å†³äºæ•°æ®çš„æ€§è´¨å’Œä¸ºæ•°ç»„è®¾ç½®çš„å‚æ•°â€”â€”<wbr>å®ƒä»¬å¯ä»¥æ›´æ¥è¿‘å¸¸æ•°æ—¶é—´ã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨å®è·µä¸­é€šå¸¸éå¸¸å—æ¬¢è¿ã€‚
- en: 18.4.8Â Bloom Filters[ğŸ”—](#(part._bloom-filters) "Link to here")
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.8 å¸ƒéš†è¿‡æ»¤å™¨[ğŸ”—](#(part._bloom-filters) "é“¾æ¥åˆ°æ­¤å¤„")
- en: Another way to improve the space and time complexity is to relax the properties
    we expect of the operations. Right now, set membership gives perfect answers,
    in that it answers `true` exactly when the element being checked was previously
    inserted into the set. But suppose weâ€™re in a setting where we can accept a more
    relaxed notion of correctness, where membership tests can â€œlieâ€ slightly in one
    direction or the other (but not both, because that makes the representation almost
    useless). Specifically, letâ€™s say that â€œno means noâ€ (i.e., if the set representation
    says the element isnâ€™t present, it really isnâ€™t) but â€œyes sometimes means noâ€
    (i.e., if the set representation says an element is present, sometimes it might
    not be). In short, if the set says the element isnâ€™t in it, this should be guaranteed;
    but if the set says the element is present, it may not be. In the latter case,
    we either need some otherâ€”<wbr>more expensiveâ€”<wbr>technique to determine truth,
    or we might just not care.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: æé«˜ç©ºé—´å’Œæ—¶é—´å¤æ‚æ€§çš„å¦ä¸€ç§æ–¹æ³•æ˜¯æ”¾å®½æˆ‘ä»¬å¯¹æ“ä½œæ‰€æœŸæœ›çš„æ€§è´¨ã€‚ç›®å‰ï¼Œé›†åˆæˆå‘˜èµ„æ ¼ç»™å‡ºå®Œç¾çš„ç­”æ¡ˆï¼Œå³å½“è¢«æ£€æŸ¥çš„å…ƒç´ ä¹‹å‰å·²æ’å…¥é›†åˆæ—¶ï¼Œå®ƒæ­£å¥½å›ç­”`true`ã€‚ä½†å‡è®¾æˆ‘ä»¬å¤„äºå¯ä»¥æ¥å—æ›´å®½æ¾çš„æ­£ç¡®æ€§æ¦‚å¿µçš„ç¯å¢ƒä¸­ï¼Œå…¶ä¸­æˆå‘˜èµ„æ ¼æµ‹è¯•å¯ä»¥â€œè¯´è°â€ç¨å¾®åå‘ä¸€ä¸ªæ–¹å‘æˆ–å¦ä¸€ä¸ªæ–¹å‘ï¼ˆä½†ä¸èƒ½ä¸¤è€…éƒ½åå‘ï¼Œå› ä¸ºè¿™ä¼šä½¿è¡¨ç¤ºå‡ ä¹æ— ç”¨ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œè®©æˆ‘ä»¬è¯´â€œæ²¡æœ‰å°±æ˜¯æ²¡æœ‰â€ï¼ˆå³ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºè¯´å…ƒç´ ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆå®ƒç¡®å®ä¸å­˜åœ¨ï¼‰ä½†â€œæœ‰æ—¶è¯´æ˜¯å°±æ˜¯ä¸æ˜¯â€ï¼ˆå³ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºè¯´å…ƒç´ å­˜åœ¨ï¼Œæœ‰æ—¶å®ƒå¯èƒ½ä¸å­˜åœ¨ï¼‰ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå¦‚æœé›†åˆè¡¨ç¤ºå…ƒç´ ä¸åœ¨å…¶ä¸­ï¼Œè¿™åº”è¯¥æ˜¯æœ‰ä¿è¯çš„ï¼›ä½†å¦‚æœé›†åˆè¡¨ç¤ºå…ƒç´ å­˜åœ¨ï¼Œå®ƒå¯èƒ½ä¸å­˜åœ¨ã€‚åœ¨åä¸€ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ä¸€äº›å…¶ä»–â€”â€”<wbr>æ›´æ˜‚è´µâ€”â€”<wbr>çš„æŠ€æœ¯æ¥ç¡®å®šçœŸå®æ€§ï¼Œæˆ–è€…æˆ‘ä»¬å¯èƒ½æ ¹æœ¬ä¸åœ¨ä¹ã€‚
- en: Where is such a data structure of use? Suppose we are building a Web site that
    uses password-based authentication. Because many passwords have been leaked in
    well-publicized breaches, it is safe to assume that hackers have them and will
    guess them. As a result, we want to not allow users to select any of these as
    passwords. We could use a hash-table to reject precisely the known leaked passwords.
    But for efficiency, we could use this imperfect hash instead. If it says â€œnoâ€,
    then we allow the user to use that password. But if it says â€œyesâ€, then either
    they are using a password that has been leaked, or they have an entirely different
    password that, purely by accident, has the same hash value, but no matter; we
    can just disallow that password as well.A related use is for filtering out malicious
    Web sites. The URL shortening system, bitly, [uses it for this purpose](http://word.bitly.com/post/28558800777/dablooms-an-open-source-scalable-counting-bloom).
    Itâ€™s also used by ad networks; hereâ€™s a [talk](https://youtu.be/T3Bt9Tn6P5c?si=t8U33orccRCgkSw0&t=1277)
    (the segment from about 20m to about 45m) about that. But sometimes, a Bloom filter
    is overkill, as this Cloudflare blog post [discusses](https://blog.cloudflare.com/when-bloom-filters-dont-bloom/)â€¦
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·çš„æ•°æ®ç»“æ„åœ¨å“ªé‡Œæœ‰ç”¨å‘¢ï¼Ÿå‡è®¾æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªä½¿ç”¨åŸºäºå¯†ç çš„è®¤è¯çš„ç½‘ç«™ã€‚ç”±äºè®¸å¤šå¯†ç å·²ç»åœ¨å…¬å¼€çš„æ³„éœ²äº‹ä»¶ä¸­æ³„éœ²ï¼Œæˆ‘ä»¬å¯ä»¥åˆç†åœ°å‡è®¾é»‘å®¢æ‹¥æœ‰å®ƒä»¬å¹¶ä¼šå°è¯•çŒœæµ‹å®ƒä»¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸å…è®¸ç”¨æˆ·é€‰æ‹©è¿™äº›å¯†ç ä¸­çš„ä»»ä½•ä¸€ä¸ªã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å“ˆå¸Œè¡¨æ¥æ‹’ç»æ‰€æœ‰å·²çŸ¥çš„æ³„éœ²å¯†ç ã€‚ä½†ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªä¸å®Œç¾çš„å“ˆå¸Œã€‚å¦‚æœå®ƒè¯´â€œæ²¡æœ‰â€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å…è®¸ç”¨æˆ·ä½¿ç”¨é‚£ä¸ªå¯†ç ã€‚ä½†å¦‚æœå®ƒè¯´â€œæœ‰â€ï¼Œé‚£ä¹ˆä»–ä»¬è¦ä¹ˆæ­£åœ¨ä½¿ç”¨ä¸€ä¸ªå·²ç»è¢«æ³„éœ²çš„å¯†ç ï¼Œè¦ä¹ˆä»–ä»¬æœ‰ä¸€ä¸ªå®Œå…¨ä¸åŒçš„å¯†ç ï¼Œçº¯ç²¹æ˜¯å¶ç„¶åœ°å…·æœ‰ç›¸åŒçš„å“ˆå¸Œå€¼ï¼›ä½†æ— è®ºå¦‚ä½•ï¼›æˆ‘ä»¬ä¹Ÿå¯ä»¥æ‹’ç»é‚£ä¸ªå¯†ç ã€‚ç›¸å…³çš„ç”¨é€”æ˜¯ç”¨äºè¿‡æ»¤æ‰æ¶æ„ç½‘ç«™ã€‚URLç¼©çŸ­ç³»ç»Ÿbitly[å°±ç”¨äºè¿™ä¸ªç›®çš„](http://word.bitly.com/post/28558800777/dablooms-an-open-source-scalable-counting-bloom)ã€‚å¹¿å‘Šç½‘ç»œä¹Ÿä½¿ç”¨å®ƒï¼›è¿™é‡Œæœ‰ä¸€ä¸ª[æ¼”è®²](https://youtu.be/T3Bt9Tn6P5c?si=t8U33orccRCgkSw0&t=1277)ï¼ˆä»å¤§çº¦20åˆ†é’Ÿåˆ°å¤§çº¦45åˆ†é’Ÿçš„æ®µè½ï¼‰å…³äºè¿™ä¸ªè¯é¢˜ã€‚ä½†æœ‰æ—¶ï¼Œå¸ƒéš†è¿‡æ»¤å™¨è¿‡äºå¼ºå¤§ï¼Œå°±åƒè¿™ç¯‡Cloudflareåšå®¢æ–‡ç« [è®¨è®ºçš„](https://blog.cloudflare.com/when-bloom-filters-dont-bloom/)é‚£æ ·â€¦â€¦
- en: 'Another example is in updating databases or memory stores. Suppose we have
    a database of records, which we update frequently. It is often more efficient
    to maintain a journal of changes: i.e., a list that sequentially records all the
    changes that have occurred. At some interval (say overnight), the journal is â€œflushedâ€,
    meaning all these changes are applied to the database proper. But that means every
    read operation has become highly inefficient, because it has to check the entire
    journal first (for updates) before accessing the database. Again, here we can
    use this faulty notion of a hash table: if the hash of the record locator says
    â€œnoâ€, then the record certainly hasnâ€™t been modified and we go directly to the
    database; if it says â€œyesâ€ then we have to check the journal.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªä¾‹å­æ˜¯åœ¨æ›´æ–°æ•°æ®åº“æˆ–å†…å­˜å­˜å‚¨ä¸­ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç»å¸¸æ›´æ–°çš„è®°å½•æ•°æ®åº“ã€‚é€šå¸¸ï¼Œç»´æŠ¤ä¸€ä¸ªå˜åŒ–æ—¥å¿—ä¼šæ›´æœ‰æ•ˆç‡ï¼šå³ï¼Œä¸€ä¸ªæŒ‰é¡ºåºè®°å½•æ‰€æœ‰å·²å‘ç”Ÿå˜åŒ–çš„åˆ—è¡¨ã€‚åœ¨æŸä¸ªæ—¶é—´é—´éš”ï¼ˆæ¯”å¦‚å¤œé—´ï¼‰ï¼Œæ—¥å¿—ä¼šè¢«â€œåˆ·æ–°â€ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰è¿™äº›å˜åŒ–éƒ½ä¼šåº”ç”¨åˆ°æ•°æ®åº“æœ¬èº«ã€‚ä½†è¿™ä¹Ÿæ„å‘³ç€æ¯æ¬¡è¯»å–æ“ä½œéƒ½å˜å¾—éå¸¸ä½æ•ˆï¼Œå› ä¸ºå®ƒå¿…é¡»é¦–å…ˆæ£€æŸ¥æ•´ä¸ªæ—¥å¿—ï¼ˆä»¥æŸ¥æ‰¾æ›´æ–°ï¼‰ç„¶åå†è®¿é—®æ•°æ®åº“ã€‚å†æ¬¡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªæœ‰ç¼ºé™·çš„å“ˆå¸Œè¡¨æ¦‚å¿µï¼šå¦‚æœè®°å½•å®šä½å™¨çš„å“ˆå¸Œå€¼è¯´â€œæ²¡æœ‰â€ï¼Œé‚£ä¹ˆè®°å½•è‚¯å®šæ²¡æœ‰è¢«ä¿®æ”¹ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è®¿é—®æ•°æ®åº“ï¼›å¦‚æœå®ƒè¯´â€œæœ‰â€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¿…é¡»æ£€æŸ¥æ—¥å¿—ã€‚
- en: We have already seen a simple example implementation of this idea earlier, when
    we used a single array, with modular arithmetic, to represent the set. When an
    element was not present in the array, we knew for a fact that it was definitely
    not present. When the array indicated an element was present, we couldnâ€™t be sure
    that what was present was the exact value we were looking for. To get around this
    uncertainty, we used chaining.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰å·²ç»çœ‹åˆ°äº†è¿™ä¸ªæƒ³æ³•çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹å®ç°ï¼Œå½“æ—¶æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå•ä¸€çš„æ•°ç»„ï¼Œé€šè¿‡æ¨¡è¿ç®—æ¥è¡¨ç¤ºé›†åˆã€‚å½“ä¸€ä¸ªå…ƒç´ ä¸åœ¨æ•°ç»„ä¸­æ—¶ï¼Œæˆ‘ä»¬çŸ¥é“å®ƒè‚¯å®šä¸åœ¨ã€‚å½“æ•°ç»„æŒ‡ç¤ºä¸€ä¸ªå…ƒç´ å­˜åœ¨æ—¶ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šå­˜åœ¨çš„ç¡®å®æ˜¯æˆ‘ä»¬è¦æ‰¾çš„ç¡®åˆ‡å€¼ã€‚ä¸ºäº†å…‹æœè¿™ç§ä¸ç¡®å®šæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é“¾å¼å­˜å‚¨ã€‚
- en: However, there is something else we could have done. Chaining costs both space
    (to store all the actual values) and time (to look through all the values). Suppose,
    instead, a bucket is only a Boolean value. This results in a slightly useful,
    but potentially very inaccurate, data structure; furthermore, it exhibits correlated
    failure tied to the modulus.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åšå…¶ä»–äº‹æƒ…ã€‚é“¾å¼å­˜å‚¨æ—¢æ¶ˆè€—ç©ºé—´ï¼ˆç”¨äºå­˜å‚¨æ‰€æœ‰å®é™…å€¼ï¼‰ä¹Ÿæ¶ˆè€—æ—¶é—´ï¼ˆç”¨äºæŸ¥æ‰¾æ‰€æœ‰å€¼ï¼‰ã€‚å‡è®¾ï¼Œç›¸åï¼Œæ¡¶åªæ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ã€‚è¿™ä¼šå¯¼è‡´ä¸€ä¸ªç¨å¾®æœ‰ç”¨ä½†å¯èƒ½éå¸¸ä¸å‡†ç¡®çš„æ•°æ®ç»“æ„ï¼›æ­¤å¤–ï¼Œå®ƒè¿˜è¡¨ç°å‡ºä¸æ¨¡æ•°ç›¸å…³çš„æ•…éšœã€‚
- en: But suppose we have not only one array, but several! When an element is added
    to the set, it is added to each array; when checking for membership, every array
    is consulted. The set only answers affirmatively to membership if all the arrays
    do so.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å‡è®¾æˆ‘ä»¬ä¸ä»…ä»…æœ‰ä¸€ä¸ªæ•°ç»„ï¼Œè€Œæ˜¯æœ‰å¤šä¸ªæ•°ç»„ï¼å½“ä¸€ä¸ªå…ƒç´ è¢«æ·»åŠ åˆ°é›†åˆä¸­æ—¶ï¼Œå®ƒä¼šè¢«æ·»åŠ åˆ°æ¯ä¸ªæ•°ç»„ä¸­ï¼›åœ¨æ£€æŸ¥æˆå‘˜èµ„æ ¼æ—¶ï¼Œä¼šå’¨è¯¢æ¯ä¸ªæ•°ç»„ã€‚åªæœ‰å½“æ‰€æœ‰æ•°ç»„éƒ½ç¡®è®¤æ—¶ï¼Œé›†åˆæ‰ä¼šè‚¯å®šåœ°å›ç­”æˆå‘˜èµ„æ ¼ã€‚
- en: 'Naturally, using multiple arrays offers absolutely no advantage if the arrays
    are all the same size: since both insertion and lookup are deterministic, all
    will yield the same answer. However, there is a simple antidote to this: use different
    array sizes. In particular, by using array sizes that are relatively prime to
    one another, we minimize the odds of a clash (only hashes that are the product
    of all the array sizes will fool the array).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶åœ°ï¼Œå¦‚æœæ‰€æœ‰æ•°ç»„çš„å¤§å°éƒ½ç›¸åŒï¼Œä½¿ç”¨å¤šä¸ªæ•°ç»„ç»å¯¹æ²¡æœ‰ä¼˜åŠ¿ï¼šå› ä¸ºæ’å…¥å’ŒæŸ¥æ‰¾éƒ½æ˜¯ç¡®å®šæ€§çš„ï¼Œæ‰€ä»¥æ‰€æœ‰æ“ä½œéƒ½ä¼šå¾—åˆ°ç›¸åŒçš„ç­”æ¡ˆã€‚ç„¶è€Œï¼Œæœ‰ä¸€ç§ç®€å•çš„å¯¹ç­–ï¼šä½¿ç”¨ä¸åŒå¤§å°çš„æ•°ç»„ã€‚ç‰¹åˆ«æ˜¯ï¼Œé€šè¿‡ä½¿ç”¨å½¼æ­¤äº’è´¨çš„æ•°ç»„å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥æœ€å°åŒ–å†²çªçš„æ¦‚ç‡ï¼ˆåªæœ‰æ‰€æœ‰æ•°ç»„å¤§å°çš„ä¹˜ç§¯çš„å“ˆå¸Œå€¼æ‰èƒ½æ¬ºéª—æ•°ç»„ï¼‰ã€‚
- en: This data structure, called a Bloom Filter, is a probabilistic data structure.
    Unlike our earlier set data structure, this one is not guaranteed to always give
    the right answer; but contrary to the [â˜› space-time tradeoff](glossary.html#%28elem._glossary-space-time._tradeoff%29),
    we save both space and time by changing the problem slightly to accept incorrect
    answers. If we know something about the distribution of hash values, and we have
    some acceptable bound of error, we can design hash table sizes so that with high
    probability, the Bloom Filter will lie within the acceptable error bounds.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ç§°ä¸ºå¸ƒéš†è¿‡æ»¤å™¨ï¼ˆBloom Filterï¼‰çš„æ•°æ®ç»“æ„æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ã€‚ä¸æˆ‘ä»¬çš„æ—©æœŸé›†åˆæ•°æ®ç»“æ„ä¸åŒï¼Œå®ƒä¸èƒ½ä¿è¯æ€»æ˜¯ç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼›ä½†ä¸[â˜›æ—¶ç©ºæƒè¡¡](glossary.html#%28elem._glossary-space-time._tradeoff%29)ç›¸åï¼Œæˆ‘ä»¬é€šè¿‡ç¨å¾®æ”¹å˜é—®é¢˜ä»¥æ¥å—é”™è¯¯ç­”æ¡ˆï¼Œä»è€ŒèŠ‚çœäº†ç©ºé—´å’Œæ—¶é—´ã€‚å¦‚æœæˆ‘ä»¬äº†è§£å“ˆå¸Œå€¼çš„åˆ†å¸ƒï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰å¯æ¥å—çš„é”™è¯¯ç•Œé™ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡å‡ºå“ˆå¸Œè¡¨çš„å¤§å°ï¼Œä½¿å¾—å¸ƒéš†è¿‡æ»¤å™¨æœ‰å¾ˆé«˜çš„æ¦‚ç‡åœ¨å¯æ¥å—çš„é”™è¯¯ç•Œé™å†…ã€‚
- en: 18.4.9Â Generalizing from Sets to Key-Values[ğŸ”—](#(part._.Generalizing_from_.Sets_to_.Key-.Values)
    "Link to here")
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.4.9 ä»é›†åˆåˆ°é”®å€¼å¯¹çš„æ¨å¹¿[ğŸ”—](#(part._.Generalizing_from_.Sets_to_.Key-.Values) "é“¾æ¥è‡³æ­¤")
- en: 'Above, we focused on sets: that is, a string effectively mapped to a Boolean
    value, indicating whether it was present or not. However, there are many settings
    where it is valuable to associate one value with another. For instance, given
    an identity number we might want to pull up a personâ€™s records; given a computerâ€™s
    name, we might want to retrieve its routing information; given a starâ€™s catalog
    entry, we might want its astronomical information. This kind of data structure
    is so ubiquitous that it has several names, some of which are more general and
    some implying specific implementations: key-value store, associative array, hash
    map, dictionary, etc.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢ï¼Œæˆ‘ä»¬å…³æ³¨äº†é›†åˆï¼šå³ï¼Œä¸€ä¸ªå­—ç¬¦ä¸²æœ‰æ•ˆåœ°æ˜ å°„åˆ°ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºå®ƒæ˜¯å¦å­˜åœ¨ã€‚ç„¶è€Œï¼Œæœ‰è®¸å¤šæƒ…å†µä¸‹å°†ä¸€ä¸ªå€¼ä¸å¦ä¸€ä¸ªå€¼å…³è”æ˜¯æœ‰ä»·å€¼çš„ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªèº«ä»½å·ç ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ£€ç´¢ä¸€ä¸ªäººçš„è®°å½•ï¼›ç»™å®šä¸€ä¸ªè®¡ç®—æœºçš„åç§°ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ£€ç´¢å…¶è·¯ç”±ä¿¡æ¯ï¼›ç»™å®šä¸€é¢—æ˜Ÿçš„ç›®å½•æ¡ç›®ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦å…¶å¤©æ–‡å­¦ä¿¡æ¯ã€‚è¿™ç§æ•°æ®ç»“æ„å¦‚æ­¤æ™®éï¼Œä»¥è‡³äºå®ƒæœ‰å‡ ä¸ªåç§°ï¼Œå…¶ä¸­ä¸€äº›æ›´é€šç”¨ï¼Œä¸€äº›æš—ç¤ºäº†ç‰¹å®šçš„å®ç°ï¼šé”®å€¼å­˜å‚¨ã€å…³è”æ•°ç»„ã€å“ˆå¸Œè¡¨ã€å­—å…¸ç­‰ã€‚
- en: In general, the names â€œkey-valueâ€ and â€œdictionaryâ€ are useful because they suggest
    a behavioral interface. In contrast, associative array implies the use of arrays,
    and hash table suggests the use of an array (and of hashing). In fact, real systems
    use a variety of implementation strategies, including balanced binary search trees.
    The names â€œkey-valueâ€ and â€œdictionaryâ€ avoid commitment to a particular implementation.
    Here, too, â€œdictionaryâ€ evokes a common mental image of unique words that map
    to descriptions. The term â€œkey valueâ€ is even more technically useful because
    keys are meant to all be distinct (i.e., no two different key-value pairs can
    have the same key; alternatively, one key can map to only one value). This makes
    sense because we view this as a generalization of sets, so the keys are the set
    elements, which must necessarily have no duplicates; the values take the place
    of the Boolean.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œâ€œé”®å€¼â€å’Œâ€œå­—å…¸â€è¿™ä¸¤ä¸ªåç§°æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒä»¬æš—ç¤ºäº†ä¸€ä¸ªè¡Œä¸ºæ¥å£ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œâ€œå…³è”æ•°ç»„â€æš—ç¤ºäº†ä½¿ç”¨æ•°ç»„ï¼Œè€Œâ€œå“ˆå¸Œè¡¨â€æš—ç¤ºäº†ä½¿ç”¨æ•°ç»„ï¼ˆä»¥åŠå“ˆå¸Œï¼‰ã€‚å®é™…ä¸Šï¼ŒçœŸå®ç³»ç»Ÿä½¿ç”¨å„ç§å®ç°ç­–ç•¥ï¼ŒåŒ…æ‹¬å¹³è¡¡äºŒå‰æœç´¢æ ‘ã€‚åç§°â€œé”®å€¼â€å’Œâ€œå­—å…¸â€é¿å…äº†å¯¹äºç‰¹å®šå®ç°çš„æ‰¿è¯ºã€‚åœ¨è¿™é‡Œï¼Œâ€œå­—å…¸â€å”¤èµ·äº†å¯¹å”¯ä¸€å•è¯æ˜ å°„åˆ°æè¿°çš„å¸¸è§å¿ƒç†å›¾åƒã€‚æœ¯è¯­â€œé”®å€¼â€åœ¨æŠ€æœ¯ä¸Šæ›´åŠ æœ‰ç”¨ï¼Œå› ä¸ºé”®æ„å‘³ç€å®ƒä»¬éƒ½æ˜¯ä¸åŒçš„ï¼ˆå³ï¼Œä¸¤ä¸ªä¸åŒçš„é”®å€¼å¯¹ä¸èƒ½æœ‰ç›¸åŒçš„é”®ï¼›æˆ–è€…ï¼Œä¸€ä¸ªé”®åªèƒ½æ˜ å°„åˆ°ä¸€ä¸ªå€¼ï¼‰ã€‚è¿™å¾ˆæœ‰æ„ä¹‰ï¼Œå› ä¸ºæˆ‘ä»¬å°†å…¶è§†ä¸ºé›†åˆçš„æ¨å¹¿ï¼Œå› æ­¤é”®æ˜¯é›†åˆå…ƒç´ ï¼Œå®ƒä»¬å¿…ç„¶æ²¡æœ‰é‡å¤ï¼›å€¼å–ä»£äº†å¸ƒå°”å€¼ã€‚
- en: 'To extend our set representation to handle a dictionary or key-value store,
    we need to make a few changes. First, we introduce the key-value representation:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æˆ‘ä»¬çš„é›†åˆè¡¨ç¤ºæ‰©å±•åˆ°å¤„ç†å­—å…¸æˆ–é”®å€¼å­˜å‚¨ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›ä¿®æ”¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥é”®å€¼è¡¨ç¤ºï¼š
- en: '[PRE33]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Each bucket is still an empty list, but we understand it to be a list of key-value
    pairs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¡¶ä»ç„¶æ˜¯ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œä½†æˆ‘ä»¬ç†è§£å®ƒæ˜¯ä¸€ä¸ªé”®å€¼å¯¹çš„åˆ—è¡¨ã€‚
- en: Previously, we only had `is-in` to check whether an element was present in a
    set or not. That element is now the key, and we could have a similar function
    to check whether the key is present. However, we rarely want to know just that;
    in fact, because we already know the key, we usually want the associated value.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥å‰ï¼Œæˆ‘ä»¬åªæœ‰ `is-in` æ¥æ£€æŸ¥ä¸€ä¸ªå…ƒç´ æ˜¯å¦å­˜åœ¨äºé›†åˆä¸­ã€‚ç°åœ¨è¿™ä¸ªå…ƒç´ æ˜¯é”®ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªç±»ä¼¼çš„åŠŸèƒ½æ¥æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¾ˆå°‘åªæƒ³çŸ¥é“è¿™ä¸€ç‚¹ï¼›äº‹å®ä¸Šï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»çŸ¥é“äº†é”®ï¼Œæˆ‘ä»¬é€šå¸¸æƒ³è¦å…³è”çš„å€¼ã€‚
- en: Therefore, we can just have this one function:We use Pyretâ€™s naming convention
    of `-now` to indicate that this result might change later.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦è¿™ä¸€ä¸ªå‡½æ•°ï¼šæˆ‘ä»¬ä½¿ç”¨ Pyret çš„å‘½åçº¦å®š `-now` æ¥è¡¨ç¤ºè¿™ä¸ªç»“æœå¯èƒ½ä¼šç¨åæ”¹å˜ã€‚
- en: '[PRE34]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Of course, `getkv-now` may fail: the key may not be present. That is, it has
    become a partial function [[Partial Domains](partial-domains.html)]. We therefore
    have all the usual strategies for dealing with partial functions. Here, for simplicity
    we choose to return an error if the key is not present, but all the other strategies
    we discuss for handling partiality are valid (and often better in a robust implementation).'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œ`getkv-now` å¯èƒ½ä¼šå¤±è´¥ï¼šé”®å¯èƒ½ä¸å­˜åœ¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå·²ç»å˜æˆäº†ä¸€ä¸ªéƒ¨åˆ†å‡½æ•° [[éƒ¨åˆ†åŸŸ](partial-domains.html)]ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ‰äº†å¤„ç†éƒ¨åˆ†å‡½æ•°çš„æ‰€æœ‰å¸¸ç”¨ç­–ç•¥ã€‚åœ¨è¿™é‡Œï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨é”®ä¸å­˜åœ¨æ—¶è¿”å›ä¸€ä¸ªé”™è¯¯ï¼Œä½†æ‰€æœ‰æˆ‘ä»¬è®¨è®ºçš„ç”¨äºå¤„ç†éƒ¨åˆ†æ€§çš„å…¶ä»–ç­–ç•¥éƒ½æ˜¯æœ‰æ•ˆçš„ï¼ˆå¹¶ä¸”åœ¨å¥å£®çš„å®ç°ä¸­é€šå¸¸æ›´å¥½ï¼‰ã€‚
- en: 'Similarly, we have:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '[PRE35]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This is the generalization of `insert`. However, `insert` had no reason to
    return an error: inserting an element twice was harmless. However, because keys
    must now be associated with only one value, insertion has to check whether the
    key is already present, and signal an error otherwise. In short, it is also partial.This
    is not partial due to a mathematical reason, but rather because of state: the
    same key may have been inserted previously.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ `insert` çš„ä¸€èˆ¬åŒ–ã€‚ç„¶è€Œï¼Œ`insert` æ²¡æœ‰ç†ç”±è¿”å›é”™è¯¯ï¼šæ’å…¥å…ƒç´ ä¸¤æ¬¡æ˜¯æ— å®³çš„ã€‚ä½†æ˜¯ï¼Œå› ä¸ºé”®ç°åœ¨å¿…é¡»ä¸ä»…ä¸€ä¸ªå€¼å…³è”ï¼Œæ‰€ä»¥æ’å…¥å¿…é¡»æ£€æŸ¥é”®æ˜¯å¦å·²å­˜åœ¨ï¼Œå¹¶åœ¨ä¸å­˜åœ¨æ—¶å‘å‡ºé”™è¯¯ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå®ƒä¹Ÿæ˜¯éƒ¨åˆ†å‡½æ•°ã€‚è¿™ä¸æ˜¯ç”±äºæ•°å­¦åŸå› è€Œæ˜¯ç”±äºçŠ¶æ€ï¼šåŒä¸€ä¸ªé”®å¯èƒ½ä¹‹å‰å·²ç»è¢«æ’å…¥è¿‡ã€‚
- en: 'Once we have agreed on this interface, getting a value is a natural extension
    of checking for membership:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬åŒæ„äº†è¿™ä¸ªæ¥å£ï¼Œè·å–å€¼å°±æ˜¯æ£€æŸ¥æˆå‘˜èµ„æ ¼çš„è‡ªç„¶æ‰©å±•ï¼š
- en: '[PRE36]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Having found the index, we look in the bucket for whether any key-value pair
    has the desired key. If it does, then we return the corresponding value. Otherwise,
    we error.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ç´¢å¼•åï¼Œæˆ‘ä»¬åœ¨æ¡¶ä¸­æŸ¥æ‰¾æ˜¯å¦æœ‰ä»»ä½•é”®å€¼å¯¹å…·æœ‰æ‰€éœ€é”®ã€‚å¦‚æœæœ‰ï¼Œåˆ™è¿”å›ç›¸åº”çš„å€¼ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬è¿”å›é”™è¯¯ã€‚
- en: 'Inserting a key-value pair similarly generalizes adding an element to the set:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ç±»ä¼¼çš„æ–¹å¼ï¼Œæ’å…¥é”®å€¼å¯¹å¯ä»¥æ¨å¹¿åˆ°å‘é›†åˆä¸­æ·»åŠ å…ƒç´ ï¼š
- en: '[PRE37]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Once again, we check the bucket for whether the key is already present. If it
    is, we choose to halt with an error. Otherwise, we make the key-value pair and
    link it to the existing bucket contents, and modify the array to refer to the
    new list.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œæˆ‘ä»¬æ£€æŸ¥æ¡¶ä»¥ç¡®å®šé”®æ˜¯å¦å·²ç»å­˜åœ¨ã€‚å¦‚æœå­˜åœ¨ï¼Œæˆ‘ä»¬é€‰æ‹©åœæ­¢å¹¶è¿”å›ä¸€ä¸ªé”™è¯¯ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬åˆ›å»ºé”®å€¼å¯¹å¹¶å°†å…¶é“¾æ¥åˆ°ç°æœ‰çš„æ¡¶å†…å®¹ï¼Œå¹¶ä¿®æ”¹æ•°ç»„ä»¥å¼•ç”¨æ–°çš„åˆ—è¡¨ã€‚
- en: Exercise
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Do the above pair of functions do all the necessary error-checking?
  id: totrans-233
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„è¿™å¯¹å‡½æ•°æ˜¯å¦è¿›è¡Œäº†æ‰€æœ‰å¿…è¦çš„é”™è¯¯æ£€æŸ¥ï¼Ÿ
- en: Exercise
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 
- en: ''
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Above, `setkv-now` raises an error if a key already has a name associated with
    it. A natural variation is to instead override the associated value, so that the
    new value is now associated with that key. Modify the implementation to do that
    instead, and make sure you test it thoroughly! Note that you may need to modify
    the `KV` datatype also.
  id: totrans-236
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢ï¼Œ`setkv-now` å¦‚æœé”®å·²ç»å…³è”äº†åç§°ï¼Œåˆ™ä¼šå¼•å‘é”™è¯¯ã€‚ä¸€ä¸ªè‡ªç„¶çš„å˜ä½“æ˜¯è¦†ç›–å…³è”çš„å€¼ï¼Œä½¿æ–°å€¼ç°åœ¨ä¸è¯¥é”®å…³è”ã€‚ä¿®æ”¹å®ç°ä»¥æ‰§è¡Œæ­¤æ“ä½œï¼Œå¹¶ç¡®ä¿å½»åº•æµ‹è¯•å®ƒï¼è¯·æ³¨æ„ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¿®æ”¹
    `KV` æ•°æ®ç±»å‹ã€‚
- en: 'This concludes our brief tour of sets (yet again!) and key-value stores or
    dictionaries. We have chosen to implement both using arrays, which required us
    to employ hashes. For more on string dictionaries, see the [Pyret documentation](https://www.pyret.org/docs/latest/string-dict.html).
    Observe that Pyret offers two kinds of dictionaries: one mutable (like we have
    shown here) and one (the default) functional.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å†æ¬¡ç»“æŸäº†æˆ‘ä»¬å¯¹é›†åˆï¼ˆä»¥åŠé”®å€¼å­˜å‚¨æˆ–å­—å…¸ï¼‰çš„ç®€è¦æ¸¸è§ˆã€‚æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨æ•°ç»„æ¥å®ç°å®ƒä»¬ï¼Œè¿™è¦æ±‚æˆ‘ä»¬ä½¿ç”¨å“ˆå¸Œã€‚æœ‰å…³å­—ç¬¦ä¸²å­—å…¸çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[Pyretæ–‡æ¡£](https://www.pyret.org/docs/latest/string-dict.html)ã€‚è¯·æ³¨æ„ï¼ŒPyretæä¾›äº†ä¸¤ç§ç±»å‹çš„å­—å…¸ï¼šä¸€ç§å¯å˜ï¼ˆå°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œæ‰€å±•ç¤ºçš„ï¼‰å’Œä¸€ç§ï¼ˆé»˜è®¤çš„ï¼‰å‡½æ•°å¼ã€‚
