- en: '6.3\. Modeling more complex dependencies 1: using conditional independence#'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6.3\. 建模更复杂的依赖关系 1：使用条件独立性#
- en: 原文：[https://mmids-textbook.github.io/chap06_prob/03_joint/roch-mmids-prob-joint.html](https://mmids-textbook.github.io/chap06_prob/03_joint/roch-mmids-prob-joint.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://mmids-textbook.github.io/chap06_prob/03_joint/roch-mmids-prob-joint.html](https://mmids-textbook.github.io/chap06_prob/03_joint/roch-mmids-prob-joint.html)
- en: 'In this section, we discuss the first of two standard techniques for constructing
    joint distributions from simpler building blocks: (1) imposing conditional independence
    relations and (2) marginalizing out an unobserved random variable. Combining them
    produces a large class of models known as probabilistic graphical models, which
    we do not discuss in generality. As before, we make our rigorous derivations in
    the finite support case, but these can be adapted to the continuous or hybrid
    cases.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论从更简单的构建块构建联合分布的两个标准技术中的第一个：1) 施加条件独立性关系和2) 对未观察到的随机变量进行边缘化。将它们结合起来产生了一类称为概率图模型的模型，我们在这里不进行一般性讨论。像以前一样，我们在有限支持情况下进行严格的推导，但这些可以适应连续或混合情况。
- en: 6.3.1\. Review of conditioning[#](#review-of-conditioning "Link to this heading")
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.1\. 条件概率回顾[#](#review-of-conditioning "链接到这个标题")
- en: We first review the concept of conditioning, which generally plays a key role
    in probabilistic modeling and reasoning.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先回顾条件概念，这在概率建模和推理中通常起着关键作用。
- en: '**Conditional probability** We start with events. Throughout, we work on a
    fixed probability space \((\Omega, \mathcal{F}, \P)\), which we assume is discrete,
    i.e., the number of elements in \(\Omega\) is countable.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件概率** 我们从事件开始。在整个过程中，我们都在一个固定的概率空间 \((\Omega, \mathcal{F}, \P)\) 上工作，我们假设它是离散的，即
    \(\Omega\) 中元素的数量是可数的。'
- en: '**DEFINITION** **(Conditional Probability)** \(\idx{conditional probability}\xdi\)
    Let \(A\) and \(B\) be two events with \(\mathbb{P}[B] > 0\). The conditional
    probability of \(A\) given \(B\) is defined as'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(条件概率)** \(\idx{条件概率}\xdi\) 设 \(A\) 和 \(B\) 是两个事件，且 \(\mathbb{P}[B]
    > 0\)。\(B\) 条件下 \(A\) 的条件概率定义为'
- en: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]}. \]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]}. \]
- en: \(\natural\)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: 'The intuitive interpretation goes something like this: knowing that event \(B\)
    has occurred, the updated probability of observing \(A\) is the probability of
    its restriction to \(B\) properly normalized to reflect that outcomes outside
    \(B\) have updated probability \(0\).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 直观解释大致如下：知道事件 \(B\) 已经发生，观察 \(A\) 的更新概率是其限制在 \(B\) 上的概率，适当归一化以反映 \(B\) 外的输出已更新概率为
    \(0\)。
- en: Conditional probabilities generally behave like “unconditional” probabilities.
    (See for instance Problems 6.8, 7.1, and 7.9.)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率通常像“无条件”概率一样表现。例如，参见问题 6.8、7.1 和 7.9。
- en: Independence can be characterized in terms of conditional probability. In words,
    \(A\) and \(B\) are independent if conditioning on one of them having taken place
    does not change the probability of the other occurring.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性可以用条件概率来描述。用词来说，如果对其中一个事件的发生进行条件化不会改变另一个事件发生的概率，则 \(A\) 和 \(B\) 是独立的。
- en: '**LEMMA** Let \(A\) and \(B\) be two events of positive probability. Then \(A\)
    and \(B\) are independent, which we will denote as \(A \indep B\), if and only
    if \(\P[A|B] = \P[A]\) and \(\P[B|A] = \P[B]\). \(\flat\)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 设 \(A\) 和 \(B\) 是两个概率大于零的事件。如果 \(A\) 和 \(B\) 是独立的，我们将表示为 \(A \indep
    B\)，当且仅当 \(\P[A|B] = \P[A]\) 且 \(\P[B|A] = \P[B]\)。\(\flat\)'
- en: '*Proof:* If \(A\) and \(B\) are independent, then \(\P[A \cap B] = \P[A] \P[B]\)
    which implies'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**证明**：如果 \(A\) 和 \(B\) 是独立的，那么 \(\P[A \cap B] = \P[A] \P[B]\)，这意味着'
- en: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \P[B]}{\P[B]} = \P[A].
    \]
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \P[B]}{\P[B]} = \P[A].
    \]
- en: In the other direction,
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在相反的方向上，
- en: \[ \P[A] = \P[A|B] = \frac{\P[A \cap B]}{\P[B]} \]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A] = \P[A|B] = \frac{\P[A \cap B]}{\P[B]} \]
- en: implies \(\P[A \cap B] = \P[A]\P[B]\) after rearranging. \(\square\)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 经过重新排列后，意味着 \(\P[A \cap B] = \P[A]\P[B]\)。\(\square\)
- en: The conditional probability is often used in three fundamental ways, which we
    recall next. Proofs can be found in most probability textbooks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率通常以三种基本方式使用，我们接下来回顾。证明可以在大多数概率教科书中找到。
- en: '**Multiplication Rule:** \(\idx{multiplication rule}\xdi\) For any collection
    of events \(A_1,\ldots,A_r\),'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**乘法法则** \(\idx{乘法法则}\xdi\) 对于任何事件集合 \(A_1,\ldots,A_r\)，'
- en: \[ \P\left[\cap_{i=1}^r A_i\right] = \prod_{i=1}^r \P\left[A_i \,\middle|\,
    \cap_{j=1}^{i-1} A_j \right]. \]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P\left[\cap_{i=1}^r A_i\right] = \prod_{i=1}^r \P\left[A_i \,\middle|\,
    \cap_{j=1}^{i-1} A_j \right]. \]
- en: '**Law of Total Probability:** \(\idx{law of total probability}\xdi\) For any
    event \(B\) and any [partition](https://en.wikipedia.org/wiki/Partition_of_a_set#Definition_and_Notation)\(\idx{partition}\xdi\)
    \(A_1,\ldots,A_r\) of \(\Omega\),'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全概率公式：** \(\idx{全概率公式}\xdi\) 对于任何事件 \(B\) 和任何 \(\Omega\) 的划分\(\idx{划分}\xdi\)
    \(A_1,\ldots,A_r\)，'
- en: \[ \P[B] = \sum_{i=1}^r \P[B|A_i] \P[A_i]. \]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[B] = \sum_{i=1}^r \P[B|A_i] \P[A_i]. \]
- en: '**Bayes’ Rule:** \(\idx{Bayes'' yule}\xdi\) For any events \(A\) and \(B\)
    with positive probability,'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯定理：** \(\idx{贝叶斯定理}\xdi\) 对于任何具有正概率的事件 \(A\) 和 \(B\)，'
- en: \[ \P[A|B] = \frac{\P[B|A]\P[A]}{\P[B]}. \]
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[B|A]\P[A]}{\P[B]}. \]
- en: It is implicit that all formulas above hold provided all conditional probabilities
    are well-defined.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，上述所有公式在所有条件概率都定义良好时都成立。
- en: '**Conditioning on a random variable** Conditional probabilities extend naturally
    to random variables. If \(X\) is a discrete random variable, we let \(p_X\) be
    its probability mass function and \(\S_X\) be its support, that is, the set of
    values where it has positive probability. Then we can for instance condition on
    the event \(\{X = x\}\) for any \(x \in \S_X\).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**对随机变量的条件化** 条件概率自然地扩展到随机变量。如果 \(X\) 是一个离散随机变量，我们让 \(p_X\) 是它的概率质量函数，\(\S_X\)
    是它的支撑集，即它具有正概率的值的集合。然后我们可以对事件 \(\{X = x\}\) 进行条件化，对于任何 \(x \in \S_X\)。'
- en: We define next the conditional probability mass function.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来定义条件概率质量函数。
- en: '**DEFINITION** **(Conditional Probability Mass Function)** Let \(X\) and \(Y\)
    be discrete random variables with joint probability mass function \(p_{X, Y}\)
    and marginals \(p_X\) and \(p_Y\). The conditional probability mass function\(\idx{conditional
    probability mass function}\xdi\) of \(X\) given \(Y\) is defined as'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（条件概率质量函数）** 设 \(X\) 和 \(Y\) 是具有联合概率质量函数 \(p_{X, Y}\) 和边缘 \(p_X\)
    和 \(p_Y\) 的离散随机变量。给定 \(Y\) 的 \(X\) 的条件概率质量函数\(\idx{条件概率质量函数}\xdi\) 定义为'
- en: \[ p_{X|Y}(x|y) := P[X=x|Y=y] = \frac{p_{X,Y}(x,y)}{p_Y(y)} \]
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p_{X|Y}(x|y) := P[X=x|Y=y] = \frac{p_{X,Y}(x,y)}{p_Y(y)} \]
- en: which is defined for all \(x \in \S_X\) and \(y \in \S_Y\). \(\natural\)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在所有 \(x \in \S_X\) 和 \(y \in \S_Y\) 上定义的。 \(\natural\)
- en: The conditional expectation can then be defined in a natural way as the expectation
    over the conditional probability mass function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 条件期望可以自然地定义为条件概率质量函数的期望。
- en: '**DEFINITION** **(Conditional Expectation)** \(\idx{conditional expectation}\xdi\)
    Let \(X\) and \(Y\) be discrete random variables where \(X\) takes real values
    and has a finite mean. The conditional expectation of \(X\) given \(Y = y\) is
    given by'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（条件期望）** \(\idx{条件期望}\xdi\) 设 \(X\) 和 \(Y\) 是离散随机变量，其中 \(X\) 取实数值且具有有限均值。当
    \(Y = y\) 时，\(X\) 的条件期望由以下公式给出'
- en: \[ \E[X|Y=y] = \sum_{x \in \S_X} x\, p_{X|Y}(x|y). \]
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[X|Y=y] = \sum_{x \in \S_X} x\, p_{X|Y}(x|y). \]
- en: \(\natural\)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: More generally, for a function \(f\) over the range of \(X\), we can define
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，对于 \(X\) 的值域上的函数 \(f\)，我们可以定义
- en: \[ \E[f(X)|Y=y] = \sum_{x \in \S_X} f(x)\, p_{X|Y}(x|y). \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[f(X)|Y=y] = \sum_{x \in \S_X} f(x)\, p_{X|Y}(x|y). \]
- en: 'We mention one useful formula: the *Law of Total Expectation*\(\idx{law of
    total expectation}\xdi\), the expectation version of the *Law of Total Probability*.
    It reads'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到一个有用的公式：*全期望公式*\(\idx{全期望公式}\xdi\)，它是全概率公式的期望版本。它读作
- en: \[ \E[f(X)] = \sum_{y \in \S_Y} \E[f(X)|Y=y] \,p_Y(y). \]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[f(X)] = \sum_{y \in \S_Y} \E[f(X)|Y=y] \,p_Y(y). \]
- en: '**Conditional expectation as least-squares estimator** Thinking of \(\E[X|Y=y]\)
    as a function of \(y\) leads to a fundamental characterization of the conditional
    expectation.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件期望作为最小二乘估计器** 将 \(\E[X|Y=y]\) 视为 \(y\) 的函数，导致条件期望的一个基本特征。'
- en: '**THEOREM** Let \(X\) and \(Y\) be discrete random variables where \(X\) takes
    real values and has a finite variance. Then the conditional expectation \(h(y)
    = \E[X|Y=y]\) minimizes the least squares criterion'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** 设 \(X\) 和 \(Y\) 是离散随机变量，其中 \(X\) 取实数值且具有有限方差。那么条件期望 \(h(y) = \E[X|Y=y]\)
    最小化最小二乘准则'
- en: \[ \min_{h} \E\left[(X - h(Y))^2\right] \]
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{h} \E\left[(X - h(Y))^2\right] \]
- en: where the minimum is over all real-valued functions of \(y\). \(\sharp\)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中最小值是在所有 \(y\) 的实值函数上取的。 \(\sharp\)
- en: '*Proof:* Think of \(h(y)\) as a vector \(\mathbf{h} = (h_y)_{y \in \S_Y}\),
    indexed by \(\S_Y\) (which is countable by assumption), with \(h_y = h(y) \in
    \mathbb{R}\). Then'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 将 \(h(y)\) 视为一个向量 \(\mathbf{h} = (h_y)_{y \in \S_Y}\)，由 \(\S_Y\)（根据假设是可数的）索引，其中
    \(h_y = h(y) \in \mathbb{R}\)。然后'
- en: \[\begin{align*} \mathcal{L}(\mathbf{h}) &=\E\left[(X - h(Y))^2\right]\\ &=
    \sum_{x\in \S_X} \sum_{y \in \S_Y} (x - h_y)^2 p_{X,Y}(x,y)\\ &= \sum_{y \in \S_Y}
    \left[\sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\right]. \end{align*}\]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathcal{L}(\mathbf{h}) &=\E\left[(X - h(Y))^2\right]\\ &=
    \sum_{x\in \S_X} \sum_{y \in \S_Y} (x - h_y)^2 p_{X,Y}(x,y)\\ &= \sum_{y \in \S_Y}
    \left[\sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\right]. \end{align*}\]
- en: Expanding the sum in the square brackets (which we denote by \(q_y\) and think
    of as a function of \(h_y\)) gives
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 将方括号内的和式展开（我们用 \(q_y\) 表示，并把它看作是 \(h_y\) 的函数）得到
- en: \[\begin{align*} q_y(h_y) &:= \sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\\ &=
    \sum_{x\in \S_X} [x^2 - 2 x h_y + h_y^2] \,p_{X,Y}(x,y)\\ &= \left\{\sum_{x\in
    \S_X} x^2 p_{X,Y}(x,y)\right\} + \left\{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)\right\}
    h_y + \left\{p_Y(y)\right\} h_y^2. \end{align*}\]
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} q_y(h_y) &:= \sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\\ &=
    \sum_{x\in \S_X} [x^2 - 2 x h_y + h_y^2] \,p_{X,Y}(x,y)\\ &= \left\{\sum_{x\in
    \S_X} x^2 p_{X,Y}(x,y)\right\} + \left\{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)\right\}
    h_y + \left\{p_Y(y)\right\} h_y^2. \end{align*}\]
- en: By the *Miminizing a Quadratic Function Lemma*, the unique global minimum of
    \(q_y(h_y)\) - provided \(p_Y(y) > 0\) - is attained at
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最小化二次函数引理，\(q_y(h_y)\) 的唯一全局最小值（假设 \(p_Y(y) > 0\)）在以下位置取得
- en: \[ h_y = - \frac{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)}{2 p_Y(y)}. \]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_y = - \frac{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)}{2 p_Y(y)}. \]
- en: After rearranging, we get
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 重新排列后，我们得到
- en: \[ h_y = \sum_{x\in \S_X} x \frac{p_{X,Y}(x,y)}{p_Y(y)} = \sum_{x\in \S_X} x
    p_{X|Y}(x|y) = \E[X|Y=y] \]
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_y = \sum_{x\in \S_X} x \frac{p_{X,Y}(x,y)}{p_Y(y)} = \sum_{x\in \S_X} x
    p_{X|Y}(x|y) = \E[X|Y=y] \]
- en: as claimed. \(\square\)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称。 \(\square\)
- en: '**Conditional independence** Next, we discuss conditional independence. We
    begin with the formal definition.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件独立性** 接下来，我们讨论条件独立性。我们首先给出其形式定义。'
- en: '**DEFINITION** **(Conditional Independence)** \(\idx{conditional independence}\xdi\)
    Let \(A, B, C\) be events such that \(\P[C] > 0\). Then \(A\) and \(B\) are conditionally
    independent given \(C\), denoted \(A \indep B | C\), if'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（条件独立性）** \(\idx{conditional independence}\xdi\) 设 \(A, B, C\) 是满足
    \(\P[C] > 0\) 的事件。那么 \(A\) 和 \(B\) 在给定 \(C\) 的条件下是条件独立的，记作 \(A \indep B | C\)，如果'
- en: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C]. \]
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C]. \]
- en: \(\natural\)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: 'In words, quoting [Wikipedia](https://en.wikipedia.org/wiki/Conditional_independence):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 用话来说，引用 [维基百科](https://en.wikipedia.org/wiki/Conditional_independence)：
- en: \(A\) and \(B\) are conditionally independent given \(C\) if and only if, given
    knowledge that \(C\) occurs, knowledge of whether \(A\) occurs provides no information
    on the likelihood of \(B\) occurring, and knowledge of whether \(B\) occurs provides
    no information on the likelihood of \(A\) occurring.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(A\) 和 \(B\) 在给定 \(C\) 的条件下是条件独立的，当且仅当，在知道 \(C\) 发生的条件下，\(A\) 发生的知识不会提供关于 \(B\)
    发生可能性的信息，同样，\(B\) 发生的知识也不会提供关于 \(A\) 发生可能性的信息。
- en: In general, conditionally independent events are not (unconditionally) independent.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，条件独立的事件不是（无条件）独立的。
- en: '**EXAMPLE:** Imagine I have two six-sided dice. Die 1 has faces \(\{1,3,5,7,9,11\}\)
    and die 2 has faces \(\{2, 4, 6, 8, 10, 12\}\). Suppose I perform the following
    experiment: I pick one of the two dice uniformly at random, and then I roll that
    die twice. Let \(X_1\) and \(X_2\) be the outcomes of the rolls. Consider the
    events \(A = \{X_1 = 1\}\), \(B = \{X_2 = 2\}\), and \(C = \{\text{die 1 is picked}\}\).
    The events \(A\) and \(B\) are clearly dependent: if \(A\) occurs, then I know
    that die 1 was picked, and hence \(B\) cannot occur. Knowledge of one event provides
    information about the likelihood of the other event occurring. Formally, by the
    law of total probability,'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：** 假设我有两个六面的骰子。骰子1的面是 \(\{1,3,5,7,9,11\}\)，骰子2的面是 \(\{2, 4, 6, 8, 10,
    12\}\)。假设我进行以下实验：我随机均匀地选择两个骰子中的一个，然后掷这个骰子两次。设 \(X_1\) 和 \(X_2\) 为掷骰子的结果。考虑事件 \(A
    = \{X_1 = 1\}\)，\(B = \{X_2 = 2\}\)，和 \(C = \{\text{选择骰子1}\}\)。事件 \(A\) 和 \(B\)
    显然是相关的：如果 \(A\) 发生，那么我知道选择了骰子1，因此 \(B\) 不能发生。一个事件的知识提供了关于另一个事件发生可能性的信息。根据全概率定律，'
- en: \[ \P[A] = \P[A|C]\P[C] + \P[A|C^c]\P[C^c] = \frac{1}{6}\frac{1}{2} + 0 \frac{1}{2}
    = \frac{1}{12}. \]
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A] = \P[A|C]\P[C] + \P[A|C^c]\P[C^c] = \frac{1}{6}\frac{1}{2} + 0 \frac{1}{2}
    = \frac{1}{12}. \]
- en: Similarly \(\P[B] = \frac{1}{12}\). Yet \(\P[A \cap B] = 0 \neq \frac{1}{12}
    \frac{1}{12}\).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 同样 \(\P[B] = \frac{1}{12}\)。然而 \(\P[A \cap B] = 0 \neq \frac{1}{12} \frac{1}{12}\)。
- en: 'On the other hand, we claim that \(A\) and \(B\) are conditionally independent
    given \(C\). Again this is intuitively clear: once I pick a die, the two rolls
    are independent. For a given die choice, knowledge of one roll provides no information
    about the likelihood of the other roll. Note that the phrase “for a given die
    choice” is critical in the last statement. Formally, by our experiment, we have
    \(\P[A|C] = 1/6\), \(\P[B|C] = 0\) and \(\P[A \cap B|C] = 0\). So indeed'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们声称在 \(C\) 的条件下 \(A\) 和 \(B\) 是条件独立的。这从直观上很清楚：一旦我选择了一个骰子，两次投掷是独立的。对于给定的骰子选择，一次投掷的知识不会提供关于另一次投掷可能性的任何信息。注意，在最后一条陈述中，“对于给定的骰子选择”这个短语是关键的。正式来说，通过我们的实验，我们有
    \(\P[A|C] = 1/6\)，\(\P[B|C] = 0\) 和 \(\P[A \cap B|C] = 0\)。所以确实
- en: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C] \]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C] \]
- en: as claimed. \(\lhd\)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所声称的。\(\lhd\)
- en: Conditional independence is naturally extended to random vectors.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 条件独立性自然扩展到随机向量。
- en: '**DEFINITION** **(Conditional Independence of Random Vectors)** Let \(\bX,
    \bY, \bW\) be discrete random vectors. Then \(\bX\) and \(\bY\) are said to be
    conditionally independent given \(\bW\), denoted \(\bX \indep \bY | \bW\), if
    for all \(\bx \in \S_\bX\), \(\by \in \S_\bY\) and \(\bw \in \S_\bW\)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（随机向量的条件独立性）** 设 \(\bX, \bY, \bW\) 为离散随机向量。那么当给定 \(\bW\) 时，\(\bX\)
    和 \(\bY\) 被称为条件独立，记为 \(\bX \indep \bY | \bW\)，如果对于所有 \(\bx \in \S_\bX\)，\(\by
    \in \S_\bY\) 和 \(\bw \in \S_\bW\)'
- en: \[ \P[\bX = \bx, \bY = \by|\bW = \bw] = \P[\bX = \bx |\bW = \bw] \,\P[\bY =
    \by|\bW = \bw]. \]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[\bX = \bx, \bY = \by|\bW = \bw] = \P[\bX = \bx |\bW = \bw] \,\P[\bY =
    \by|\bW = \bw]. \]
- en: \(\natural\)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: An important consequence is that we can drop the conditioning by the independent
    variable.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的后果是我们可以省略独立变量的条件。
- en: '**LEMMA** **(Role of Independence)** \(\idx{role of independence lemma}\xdi\)
    Let \(\bX, \bY, \bW\) be discrete random vectors such that \(\bX \indep \bY |
    \bW\). For all \(\bx \in \S_\bX\), \(\by \in \S_\bY\) and \(\bw \in \S_\bW\),'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **（独立性的作用）** \(\idx{role of independence lemma}\xdi\) 设 \(\bX, \bY,
    \bW\) 为离散随机向量，使得 \(\bX \indep \bY | \bW\)。对于所有 \(\bx \in \S_\bX\)，\(\by \in \S_\bY\)
    和 \(\bw \in \S_\bW\)，'
- en: \[ \P[\bX = \bx | \bY=\by, \bW=\bw] = \P[\bX = \bx | \bW = \bw]. \]
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[\bX = \bx | \bY=\by, \bW=\bw] = \P[\bX = \bx | \bW = \bw]. \]
- en: \(\flat\)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof:* In a previous exercise, we showed that \(A \indep B | C\) implies
    \(\P[A | B\cap C] = \P[A | C]\). That implies the claim. \(\square\)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 在之前的练习中，我们证明了 \(A \indep B | C\) 蕴含 \(\P[A | B\cap C] = \P[A | C]\)。这蕴含了所声称的。\(\square\)'
- en: '**CHAT & LEARN** The concept of conditional independence is closely related
    to the concept of d-separation in probabilistic graphical models. Ask your favorite
    AI chatbot to explain d-separation. \(\ddagger\)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**交流与学习** 条件独立性的概念与概率图模型中的 d-separation 概念密切相关。请你的喜欢的 AI 聊天机器人解释 d-separation。\(\ddagger\)'
- en: 6.3.2\. The basic configurations[#](#the-basic-configurations "Link to this
    heading")
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.2\. 基本配置[#](#the-basic-configurations "链接到本标题")
- en: A powerful approach for constructing complex probability distributions is the
    use of conditional independence. The case of three random variables exemplifies
    key probabilistic relationships. By the product rule, we can write
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 构建复杂概率分布的一个强大方法是使用条件独立性。三个随机变量的情况可以说明关键的概率关系。根据乘法规则，我们可以写出
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x, Y=y]. \]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x, Y=y]. \]
- en: 'This is conveniently represented through a digraph where the vertices are the
    variables. Recall that an arrow \((i,j)\), from \(i\) to \(j\), indicates that
    \(i\) is a parent of \(j\) and that \(j\) is a child of \(i\). Let \(\pa(i)\)
    be the set of parents of \(i\). The digraph \(G = (V, E)\) below encodes the following
    sampling scheme, referred as ancestral sampling:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过一个有向图方便地表示，其中顶点是变量。回想一下，一个从 \(i\) 到 \(j\) 的箭头 \((i,j)\) 表示 \(i\) 是 \(j\)
    的父节点，而 \(j\) 是 \(i\) 的子节点。设 \(\pa(i)\) 为 \(i\) 的父节点集合。下面的有向图 \(G = (V, E)\) 编码了以下采样方案，称为祖先采样：
- en: First we pick \(X\) according to its marginal \(\P[X=x]\). Note that \(X\) has
    no parent in \(G\).
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们根据其边缘概率 \(\P[X=x]\) 选择 \(X\)。注意 \(X\) 在 \(G\) 中没有父节点。
- en: Second we pick \(Y\) according to the conditional probability distribution (CPD)
    \(\P[Y=y|X=x]\). Note that \(X\) is the only parent of \(Y\).
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二步，我们根据条件概率分布（CPD）\(\P[Y=y|X=x]\) 选择 \(Y\)。注意 \(X\) 是 \(Y\) 唯一的父节点。
- en: Finally we pick \(Z\) according to the CPD \(\P[Z=z|X=x, Y=y]\). Note that the
    parents of \(Z\) are \(X\) and \(Y\).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们根据条件概率分布 \(\P[Z=z|X=x, Y=y]\) 选择 \(Z\)。注意 \(Z\) 的父节点是 \(X\) 和 \(Y\)。
- en: '![The full case](../Images/b73cb01c1b1f5d32087884467af21283.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![完整案例](../Images/b73cb01c1b1f5d32087884467af21283.png)'
- en: The graph above is acyclic, that is, it has no directed cycle. The variables
    \(X, Y, Z\) are in [topological order](https://en.wikipedia.org/wiki/Topological_sorting)\(\idx{topological
    order}\xdi\), that is, all edges \((i,j)\) are such that \(i\) comes before \(j\)
    in that order.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图是无环的，也就是说，它没有有向循环。变量 \(X, Y, Z\) 是 [拓扑排序](https://en.wikipedia.org/wiki/Topological_sorting)\(\idx{topological
    order}\xdi\)，也就是说，所有边 \((i,j)\) 都满足 \(i\) 在该顺序中先于 \(j\)。
- en: The same joint distribution can be represented by a different digraph if the
    product rule is used in a different order. For instance,
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用不同的顺序应用乘法规则，相同的联合分布可以用不同的有向图表示。例如，
- en: \[ \P[X=x, Y=y, Z=z] = \P[Z=z] \,\P[Y=y|Z=z] \,\P[X=x | Z=z, Y=y] \]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[Z=z] \,\P[Y=y|Z=z] \,\P[X=x | Z=z, Y=y] \]
- en: is represented by the following digraph. A topological order this time is \(Z,
    Y, X\).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如此表示的以下有向图。这次拓扑排序是 \(Z, Y, X\)。
- en: '![Another full case](../Images/ed39c216e1efdc59d602be7c9e2c744a.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![另一个完整案例](../Images/ed39c216e1efdc59d602be7c9e2c744a.png)'
- en: '**The fork** \(\idx{fork}\xdi\) Removing edges in the first graph above encodes
    conditional independence relations. For instance, removing the edge from \(Y\)
    to \(Z\) gives the following graph, known as a fork. We denote this configuration
    as \(Y \leftarrow X \rightarrow Z\).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**分支** \(\idx{fork}\xdi\) 在上面的第一个图中移除边表示条件独立性关系。例如，移除从 \(Y\) 到 \(Z\) 的边得到以下图，称为分支。我们用
    \(Y \leftarrow X \rightarrow Z\) 表示这种配置。'
- en: '![The fork](../Images/77cb78740ee4952c17900d2626c7ad2a.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![分支](../Images/77cb78740ee4952c17900d2626c7ad2a.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布可以简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]. \]
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]. \]
- en: So, in this case, what has changed is that the CPD of \(Z\) does not depend
    on the value of \(Y\). From the *Role of Independence* lemma, this corresponds
    to assuming the conditional independence \(Z \indep Y|X\). Indeed, we can check
    that claim directly from the joint distribution
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，变化的是 \(Z\) 的 CPD 不依赖于 \(Y\) 的值。根据 *独立性角色* 公理，这对应于假设条件独立性 \(Z \indep
    Y|X\)。实际上，我们可以直接从联合分布中验证这个说法
- en: \[\begin{align*} \P[Y= y, Z=z|X=x] &= \frac{\P[X=x, Y= y, Z=z]}{\P[X=x]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]}{\P[X=x]}\\ &= \P[Y=y|X=x] \,\P[Z=z
    | X=x] \end{align*}\]
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[Y= y, Z=z|X=x] &= \frac{\P[X=x, Y= y, Z=z]}{\P[X=x]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]}{\P[X=x]}\\ &= \P[Y=y|X=x] \,\P[Z=z
    | X=x] \end{align*}\]
- en: as claimed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如所述。
- en: '**The chain** \(\idx{chain}\xdi\) Removing the edge from \(X\) to \(Z\) gives
    the following graph, known as a chain (or pipe). We denote this configuration
    as \(X \rightarrow Y \rightarrow Z\).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**链** \(\idx{chain}\xdi\) 移除从 \(X\) 到 \(Z\) 的边得到以下图，称为链（或管道）。我们用 \(X \rightarrow
    Y \rightarrow Z\) 表示这种配置。'
- en: '![The chain](../Images/5bfd7c9b4911ca0e5931761d25c8457e.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![链](../Images/5bfd7c9b4911ca0e5931761d25c8457e.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布可以简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]. \]
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]. \]
- en: In this case, what has changed is that the CPD of \(Z\) does not depend on the
    value of \(X\). Compare that to the fork. The corresponding conditional independence
    relation is \(Z \indep X|Y\). Indeed, we can check that claim directly
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，变化的是 \(Z\) 的条件概率分布（CPD）不依赖于 \(X\) 的值。与分支结构相比，相应的条件独立性关系是 \(Z \indep X|Y\)。实际上，我们可以直接验证这个说法。
- en: \[\begin{align*} \P[X= x, Z=z|Y=y] &= \frac{\P[X=x, Y= y, Z=z]}{\P[Y=y]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]} \end{align*}\]
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[X= x, Z=z|Y=y] &= \frac{\P[X=x, Y= y, Z=z]}{\P[Y=y]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]} \end{align*}\]
- en: Now we have to use *Bayes’ Rule* to get
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须使用 *贝叶斯定理* 来得到
- en: \[\begin{align*} &= \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]}\\
    &= \frac{\P[Y=y|X=x]\,\P[X=x]}{\P[Y=y]} \P[Z=z | Y=y]\\ &= \P[X=x|Y=y] \,\P[Z=z
    | Y=y] \end{align*}\]
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &= \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]}\\
    &= \frac{\P[Y=y|X=x]\,\P[X=x]}{\P[Y=y]} \P[Z=z | Y=y]\\ &= \P[X=x|Y=y] \,\P[Z=z
    | Y=y] \end{align*}\]
- en: as claimed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如所述。
- en: For any \(x, y, z\) where the joint probability is positive, we can re-write
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何联合概率为正的 \(x, y, z\)，我们可以重新写
- en: \[\begin{align*} &\P[X=x, Y=y, Z=z]\\ &= \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]\\
    &= \P[Y=y] \,\P[X=x|Y=y] \,\P[Z=z | Y=y], \end{align*}\]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\P[X=x, Y=y, Z=z]\\ &= \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]\\
    &= \P[Y=y] \,\P[X=x|Y=y] \,\P[Z=z | Y=y], \end{align*}\]
- en: where we used that
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了以下事实
- en: \[ \P[X=x, Y=y] = \P[X=x] \,\P[Y=y|X=x] = \P[Y=y] \,\P[X=x|Y=y] \]
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y] = \P[X=x] \,\P[Y=y|X=x] = \P[Y=y] \,\P[X=x|Y=y] \]
- en: by definition of the conditional probability. In other words, we have shown
    that the chain \(X \rightarrow Y \rightarrow Z\) is in fact equivalent to the
    fork \(X \leftarrow Y \rightarrow Z\). In particular, they both correspond to
    assuming the conditional independence relation \(Z \indep X|Y\), although they
    capture a different way to sample the joint distribution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 根据条件概率的定义。换句话说，我们已经证明了链 \(X \rightarrow Y \rightarrow Z\) 实际上等同于分叉 \(X \leftarrow
    Y \rightarrow Z\)。特别是，它们都对应于假设条件独立性关系 \(Z \indep X|Y\)，尽管它们捕获了采样联合分布的不同方式。
- en: '**The collider** \(\idx{collider}\xdi\) Removing the edge from \(X\) to \(Y\)
    gives the following graph, known as a collider. We denote this configuration as
    \(X \rightarrow Z \leftarrow Y\).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**碰撞节点** \(\idx{collider}\xdi\) 从 \(X\) 到 \(Y\) 移除边得到以下图，称为碰撞节点。我们用 \(X \rightarrow
    Z \leftarrow Y\) 表示这种配置。'
- en: '![The collider](../Images/a4600775ea580d4809bd8b11895a447d.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![碰撞节点](../Images/a4600775ea580d4809bd8b11895a447d.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]. \]
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]. \]
- en: In this case, what has changed is that the CPD of \(Y\) does not depend on the
    value of \(X\). Compare that to the fork and the chain. This time we have \(X
    \indep Y\). Indeed, we can check that claim directly
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，发生变化的是 \(Y\) 的CPD不依赖于 \(X\) 的值。与分叉和链进行比较。这次我们有 \(X \indep Y\)。确实，我们可以直接检查这个说法
- en: \[\begin{align*} \P[X= x, Y=y] &= \sum_{z \in \S_z} \P[X=x, Y=y, Z=z]\\ &= \sum_{z
    \in \S_z} \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]\\ &= \P[X=x] \,\P[Y=y] \end{align*}\]
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[X= x, Y=y] &= \sum_{z \in \S_z} \P[X=x, Y=y, Z=z]\\ &= \sum_{z
    \in \S_z} \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]\\ &= \P[X=x] \,\P[Y=y] \end{align*}\]
- en: as claimed. In particular, the collider cannot be reframed as a chain or fork
    as its underlying assumption is stronger.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称的。特别是，碰撞节点不能被重新构造成链或分叉，因为其基本假设更强。
- en: Perhaps counter-intuitively, conditioning on \(Z\) makes \(X\) and \(Y\) dependent
    in general. This is known as explaining away or Berkson’s Paradox.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 可能出人意料的是，对 \(Z\) 进行条件化通常会使 \(X\) 和 \(Y\) 依赖。这被称为解释或伯克森悖论。
- en: '6.3.3\. Example: Naive Bayes[#](#example-naive-bayes "Link to this heading")'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.3\. 示例：朴素贝叶斯\[#](#example-naive-bayes "链接到这个标题")
- en: The model-based justification we gave for logistic regression in the subsection
    on generalized linear models used a so-called [discriminative approach](https://en.wikipedia.org/wiki/Discriminative_model)\(\idx{discriminative
    model}\xdi\), where the conditional distribution of the target \(y\) given the
    features \(\mathbf{x}\) is specified – but not the full distribution of the data
    \((\mathbf{x}, y)\). Here we give an example of the [generative approach](https://en.wikipedia.org/wiki/Generative_model)\(\idx{generative
    model}\xdi\), which models the full distribution. For a discussion of the benefits
    and drawbacks of each approach, see for example [here](https://en.wikipedia.org/wiki/Discriminative_model#Contrast_with_generative_model).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在广义线性模型小节中为逻辑回归提供的基于模型的论证使用了所谓的[判别方法](https://en.wikipedia.org/wiki/Discriminative_model)\(\idx{判别模型}\xdi\)，其中指定了目标
    \(y\) 在特征 \(\mathbf{x}\) 给定下的条件分布——但不是数据的完整分布 \((\mathbf{x}, y)\)。这里我们给出一个[生成方法](https://en.wikipedia.org/wiki/Generative_model)\(\idx{生成模型}\xdi\)的例子，它模型化了完整分布。关于每种方法的优缺点讨论，例如请参阅[这里](https://en.wikipedia.org/wiki/Discriminative_model#Contrast_with_generative_model)。
- en: The Naive Bayes\(\idx{Naive Bayes}\xdi\) model is a simple discrete model for
    supervised learning. It is useful for document classification for instance, and
    we will use that terminology here to be concrete. We assume that a document has
    a single topic \(C\) from a list \(\mathcal{C} = \{1, \ldots, K\}\) with probability
    distribution \(\pi_k = \P[C = k]\). There is a vocabulary of size \(M\) and we
    record the presence or absence of a word \(m\) in the document with a Bernoulli
    variable \(X_m \in \{0,1\}\), where \(p_{k,m} = \P[X_m = 1|C = k]\). We denote
    by \(\bX = (X_1, \ldots, X_M)\) the corresponding vector.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯\(\idx{朴素贝叶斯}\xdi\)模型是监督学习的一个简单离散模型。它在文档分类中很有用，例如，我们将使用这个术语来具体说明。我们假设一个文档有一个来自列表
    \(\mathcal{C} = \{1, \ldots, K\}\) 的单个主题 \(C\)，其概率分布为 \(\pi_k = \P[C = k]\)。存在一个大小为
    \(M\) 的词汇表，我们用伯努利变量 \(X_m \in \{0,1\}\) 记录文档中单词 \(m\) 的存在或不存在，其中 \(p_{k,m} = \P[X_m
    = 1|C = k]\)。我们用 \(\bX = (X_1, \ldots, X_M)\) 表示相应的向量。
- en: 'The conditional independence assumption comes next: we assume that, given a
    topic \(C\), the word occurrences are independent. That is,'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 条件独立性假设接下来：我们假设，给定一个主题 \(C\)，单词出现是独立的。也就是说，
- en: \[\begin{align*} \P[\bX = \bx|C=k] &= \prod_{m=1}^M \P[X_m = x_m|C = k]\\ &=
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[\bX = \bx|C=k] &= \prod_{m=1}^M \P[X_m = x_m|C = k]\\ &=
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
- en: Finally, the joint distribution is
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，联合分布是
- en: \[\begin{align*} \P[C = k, \bX = \bx] &= \P[\bX = \bx|C=k] \,\P[C=k]\\ &= \pi_k
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[C = k, \bX = \bx] &= \P[\bX = \bx|C=k] \,\P[C=k]\\ &= \pi_k
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
- en: Graphically, this is similar to a fork with \(C\) at its center and \(M\) prongs
    for the \(X_m\)s. This is represented using the so-called plate notation. The
    box with the \(M\) in the corner below indicates that \(X_m\) is repeated \(M\)
    times, all copies being conditionally independent given \(C\).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 从图形上看，这类似于一个以 \(C\) 为中心，\(M\) 个叉臂的叉。这使用所谓的板符号表示。下面角上的带有 \(M\) 的方框表示 \(X_m\)
    被重复 \(M\) 次，所有副本在给定 \(C\) 的条件下都是条件独立的。
- en: '![Naives Bayes](../Images/1e486313a3d40a4fea7001344a53121b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯](../Images/1e486313a3d40a4fea7001344a53121b.png)'
- en: '**Model fitting** Before using the model for prediction, one must first fit
    the model from training data \(\{\bx_i, c_i\}_{i=1}^n\). In this case, it means
    estimating the unknown parameters \(\bpi\) and \(\{\bp_k\}_{k=1}^K\), where \(\bp_k
    = (p_{k,1},\ldots, p_{k,M})\). For each \(k, m\) let'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型拟合** 在使用模型进行预测之前，必须首先从训练数据 \(\{\bx_i, c_i\}_{i=1}^n\) 中拟合模型。在这种情况下，这意味着估计未知参数
    \(\bpi\) 和 \(\{\bp_k\}_{k=1}^K\)，其中 \(\bp_k = (p_{k,1},\ldots, p_{k,M})\)。对于每个
    \(k, m\)，让'
- en: \[ N_{k,m} = \sum_{i=1}^n \mathbf{1}_{\{c_i = k\}} x_{i,m}, \quad N_{k} = \sum_{i=1}^n
    \mathbf{1}_{\{c_i = k\}}. \]
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: \[ N_{k,m} = \sum_{i=1}^n \mathbf{1}_{\{c_i = k\}} x_{i,m}, \quad N_{k} = \sum_{i=1}^n
    \mathbf{1}_{\{c_i = k\}}. \]
- en: We use maximum likelihood estimation which, recall, entails finding the parameters
    that maximize the probability of observing the data
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用最大似然估计，回想起来，这涉及到找到最大化观察数据概率的参数
- en: \[ \mathcal{L}(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = \prod_{i=1}^n \pi_{c_i} \prod_{m=1}^M
    p_{c_i, m}^{x_{i,m}} (1-p_{c_i, m})^{1-x_{i,m}}. \]
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = \prod_{i=1}^n \pi_{c_i} \prod_{m=1}^M
    p_{c_i, m}^{x_{i,m}} (1-p_{c_i, m})^{1-x_{i,m}}. \]
- en: Here, as usual, we assume that the samples are independent and identically distributed.
    We take a logarithm to turn the products into sums and consider the negative log-likelihood
    (NLL)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，像往常一样，我们假设样本是独立同分布的。我们取对数将乘积转换为和，并考虑负对数似然（NLL）
- en: \[\begin{align*} & L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\})\\ &\quad = - \sum_{i=1}^n
    \log \pi_{c_i} - \sum_{i=1}^n \sum_{m=1}^M [x_{i,m} \log p_{c_{i}, m} + (1-x_{i,m})
    \log (1-p_{c_i, m})]\\ &\quad = - \sum_{k=1}^K N_k \log \pi_k - \sum_{k=1}^K \sum_{m=1}^M
    [N_{k,m} \log p_{k,m} + (N_k-N_{k,m}) \log (1-p_{k,m})]. \end{align*}\]
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} & L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\})\\ &\quad = - \sum_{i=1}^n
    \log \pi_{c_i} - \sum_{i=1}^n \sum_{m=1}^M [x_{i,m} \log p_{c_{i}, m} + (1-x_{i,m})
    \log (1-p_{c_i, m})]\\ &\quad = - \sum_{k=1}^K N_k \log \pi_k - \sum_{k=1}^K \sum_{m=1}^M
    [N_{k,m} \log p_{k,m} + (N_k-N_{k,m}) \log (1-p_{k,m})]. \end{align*}\]
- en: The NLL can be broken up naturally into several terms that depend on different
    sets of parameters – and therefore can be optimized separately. First, there is
    a term that depends only on the \(\pi_k\)’s
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: NLL 可以自然地分解为依赖于不同参数集的几个项——因此可以分别优化。首先，有一个只依赖于 \(\pi_k\) 的项
- en: \[ J_0(\bpi; \{\bx_i, c_i\}) = - \sum_{k=1}^K N_k \log \pi_k. \]
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J_0(\bpi; \{\bx_i, c_i\}) = - \sum_{k=1}^K N_k \log \pi_k. \]
- en: The rest of the sum can be further split into \(KM\) terms, each depending only
    on \(p_{km}\) for a fixed \(k\) and m
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的和可以进一步拆分为 \(KM\) 项，每一项只依赖于固定 \(k\) 和 \(m\) 的 \(p_{km}\)
- en: \[ J_{k,m}(p_{k,m}; \{\bx_i, c_i\}) = - N_{k,m} \log p_{k,m} - (N_k-N_{k,m})
    \log (1-p_{k,m}). \]
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J_{k,m}(p_{k,m}; \{\bx_i, c_i\}) = - N_{k,m} \log p_{k,m} - (N_k-N_{k,m})
    \log (1-p_{k,m}). \]
- en: So
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 所以
- en: \[ L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = J_0(\bpi; \{\bx_i, c_i\}) + \sum_{k=1}^K
    \sum_{m=1}^M J_{k,m}(p_{k,m}; \{\bx_i, c_i\}). \]
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = J_0(\bpi; \{\bx_i, c_i\}) + \sum_{k=1}^K
    \sum_{m=1}^M J_{k,m}(p_{k,m}; \{\bx_i, c_i\}). \]
- en: We minimize these terms separately. We assume that \(N_k > 0\) for all \(k\).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分别最小化这些项。我们假设对于所有 \(k\)，\(N_k > 0\)。
- en: 'We use a special case of maximum likelihood estimation, which we previously
    worked out in an example, where we consider the space of all probability distributions
    over a finite set. The maximum likelihood estimator in that case is given by the
    empirical frequencies. Notice that minimizing \(J_0(\bpi; \{\bx_i, c_i\})\) is
    precisely of this form: we observe \(N_k\) samples from class \(k\) and we seek
    the maximum likelihood estimator of, \(\pi_k\), the probability of observing \(k\).
    Hence the solution is simply'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用最大似然估计的特殊情况，我们之前在示例中已经解决过，其中我们考虑了有限集上所有概率分布的空间。在这种情况下，最大似然估计量由经验频率给出。请注意，最小化
    \(J_0(\bpi; \{\bx_i, c_i\})\) 正是这种形式：我们观察到来自类别 \(k\) 的 \(N_k\) 个样本，并寻求 \(\pi_k\)
    的最大似然估计量，即观察到 \(k\) 的概率。因此，解决方案很简单
- en: \[ \hat{\pi}_k = \frac{N_k}{N}, \]
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\pi}_k = \frac{N_k}{N}, \]
- en: for all \(k\). Similarly, for each \(k\), \(m\), \(J_{k,m}\) is of that form
    as well. Here the states correspond to word \(m\) being present or absent in a
    document of class \(k\), and we observe \(N_{k,m}\) documents of type \(k\) where
    the word \(m\) is present. So the solution is
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(k\)。同样，对于每个 \(k\) 和 \(m\)，\(J_{k,m}\) 也具有相同的形式。在这里，状态对应于类别 \(k\) 的文档中单词
    \(m\) 的存在或不存在，我们观察到 \(N_{k,m}\) 个类型为 \(k\) 的文档，其中单词 \(m\) 存在。因此，解决方案是
- en: \[ \hat{p}_{k,m} = \frac{N_{k,m}}{N_k} \]
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{p}_{k,m} = \frac{N_{k,m}}{N_k} \]
- en: for all \(k, m\).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(k, m\)。
- en: '**Prediction** To predict the class of a new document, it is natural to maximize
    over \(k\) the probability that \(\{C=k\}\) given \(\{\bX = \bx\}\). By Bayes’
    rule,'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测** 要预测新文档的类别，自然是在 \(k\) 上最大化给定 \(\{\bX = \bx\}\) 的 \(\{C=k\}\) 的概率。根据贝叶斯定理，'
- en: \[\begin{align*} \P[C=k | \bX = \bx] &= \frac{\P[C = k, \bX = \bx]}{\P[\bX =
    \bx]}\\ &= \frac{\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}} {\sum_{k'=1}^K
    \pi_{k'} \prod_{m=1}^M p_{k',m}^{x_m} (1-p_{k',m})^{1-x_m}}. \end{align*}\]
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[C=k | \bX = \bx] &= \frac{\P[C = k, \bX = \bx]}{\P[\bX =
    \bx]}\\ &= \frac{\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}} {\sum_{k'=1}^K
    \pi_{k'} \prod_{m=1}^M p_{k',m}^{x_m} (1-p_{k',m})^{1-x_m}}. \end{align*}\]
- en: As the denominator does not in fact depend on \(k\), maximizing \(\P[C=k | \bX
    = \bx]\) boils down to maximizing the numerator \(\pi_k \prod_{m=1}^M p_{k,m}^{x_m}
    (1-p_{k,m})^{1-x_m}\), which is straighforward to compute. As we did previously,
    we take a negative logarithm – which has some numerical advantages – and we refer
    to it as the *score*
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分母实际上不依赖于 \(k\)，最大化 \(\P[C=k | \bX = \bx]\) 简化为最大化分子 \(\pi_k \prod_{m=1}^M
    p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\)，这是很容易计算的。像之前一样，我们取负对数——这有一些数值优势——并将其称为 *得分*
- en: \[\begin{align*} &- \log\left(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\right)\\
    &\qquad = -\log\pi_k - \sum_{m=1}^M [x_m \log p_{k,m} + (1-x_m) \log (1-p_{k,m})].
    \end{align*}\]
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &- \log\left(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\right)\\
    &\qquad = -\log\pi_k - \sum_{m=1}^M [x_m \log p_{k,m} + (1-x_m) \log (1-p_{k,m})].
    \end{align*}\]
- en: More specifically, taking a negative logarithm turns out to be a good idea here
    because computing a product of probabilities can produce very small numbers that,
    when they fall beneath machine precision, are approximated by zero. This is called
    [underflow](https://en.wikipedia.org/wiki/Arithmetic_underflow)\(\idx{underflow}\xdi\).
    By taking a negative logarithm, these probabilities are transformed into positive
    numbers of reasonable magnitude and the product becomes of sum of these. Moreover,
    because this transformation is monotone, we can use the transformed values directly
    to compute the optimal score, which is our ultimate goal in the prediction step.
    Since the parameters are unknown, we use \(\hat{\pi}_k\) and \(\hat{p}_{k,m}\)
    in place of \(\pi_k\) and \(p_{k,m}\).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，取负对数在这里是一个好主意，因为计算概率的乘积可能会产生非常小的数字，当它们低于机器精度时，会被近似为零。这被称为 [下溢](https://en.wikipedia.org/wiki/Arithmetic_underflow)\(\idx{underflow}\xdi\)。通过取负对数，这些概率被转换成合理大小的正数，乘积变成了这些数的和。此外，因为这种转换是单调的，我们可以直接使用转换后的值来计算最优得分，这是我们预测步骤中的最终目标。由于参数是未知的，我们用
    \(\hat{\pi}_k\) 和 \(\hat{p}_{k,m}\) 来代替 \(\pi_k\) 和 \(p_{k,m}\)。
- en: '**CHAT & LEARN** Ask your favorite AI chatbot for more information on the issue
    of underflow, and its cousin overflow\(\idx{overflow}\xdi\), in particular in
    the context of multiypling probabilities. \(\ddagger\)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 向您最喜欢的 AI 聊天机器人询问有关下溢（underflow）及其表亲上溢（overflow\(\idx{overflow}\xdi\)）问题的更多信息，特别是在乘以概率的上下文中。\(\ddagger\)'
- en: While maximum likehood estimation has [desirable theoretical properties](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties),
    it does suffer from [overfitting](https://towardsdatascience.com/parameter-inference-maximum-aposteriori-estimate-49f3cd98267a).
    If for instance a particular word \(m\) does not occur in any training document,
    then the probability of observing a new document that happens to contain that
    word is estimated to be \(0\) for any class (i.e., \(\hat{p}_{k,m} = 0\) for all
    \(k\) so that \(\hat \pi_k \prod_{m=1}^M \hat{p}_{k,m}^{x_m} (1-\hat{p}_{k,m})^{1-x_m}
    = 0\) for all \(k\) ) and the maximization problem above is not well-defined.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然最大似然估计具有[理想的理论特性](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties)，但它确实存在[过拟合](https://towardsdatascience.com/parameter-inference-maximum-aposteriori-estimate-49f3cd98267a)的问题。例如，如果一个特定的词\(m\)在任何训练文档中都没有出现，那么观察到包含该词的新文档的概率被估计为任何类别的\(0\)（即，对于所有\(k\)，\(\hat{p}_{k,m}
    = 0\)，因此\(\hat \pi_k \prod_{m=1}^M \hat{p}_{k,m}^{x_m} (1-\hat{p}_{k,m})^{1-x_m}
    = 0\)对于所有\(k\)）并且上述最大化问题没有很好地定义。
- en: One approach to deal with this is [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)\(\idx{Laplace
    smoothing}\xdi\)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这个问题的一个方法是对数平滑（[Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)\(\idx{Laplace
    smoothing}\xdi\)）。
- en: \[ \bar{\pi}_k = \frac{N_k + \alpha}{N + K \alpha}, \quad \bar{p}_{k,m} = \frac{N_{k,m}
    + \beta}{N_k + 2 \beta} \]
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{\pi}_k = \frac{N_k + \alpha}{N + K \alpha}, \quad \bar{p}_{k,m} = \frac{N_{k,m}
    + \beta}{N_k + 2 \beta} \]
- en: where \(\alpha, \beta > 0\), which can be justified using a Bayesian or regularization
    perspective.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(\alpha, \beta > 0\)，这可以通过贝叶斯或正则化视角来证明。
- en: We implement the Naive Bayes model with Laplace smoothing.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了带有Laplace平滑的朴素贝叶斯模型。
- en: We encode the data into a table, where the rows are the classes and the columns
    are the features. The entries are the corresponding \(N_{k,m}\)s. In addition
    we provide the vector \((N_k)_k\).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据编码到表中，其中行是类别，列是特征。条目是对应的\(N_{k,m}\)。此外，我们还提供了向量\((N_k)_k\)。
- en: '[PRE0]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using `N_k[:, np.newaxis]` reshapes the one-dimensional array `N_k` into a two-dimensional
    column vector. For example, if `N_k` has a shape of \((K,)\), then `N_k[:, np.newaxis]`
    changes its shape to \((K, 1)\). This allows the division in the expression
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`N_k[:, np.newaxis]`将一维数组`N_k`重塑为二维列向量。例如，如果`N_k`的形状为\((K,)\)，那么`N_k[:, np.newaxis]`将其形状更改为\((K,
    1)\)。这允许在表达式中进行除法。
- en: '[PRE1]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: to work correctly with [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html),
    ensuring that each element in a row of `N_km` is divided by the corresponding
    value in `N_k`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确地与[广播](https://numpy.org/doc/stable/user/basics.broadcasting.html)一起工作，确保`N_km`的每一行元素都除以`N_k`中相应的值。
- en: The next function computes the negative logarithm of \(\pi_k \prod_{m=1}^M p_{k,m}^{x_m}
    (1-p_{k,m})^{1-x_m}\), that is, the score of \(k\), and outputs a \(k\) achieving
    the minimum score.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数计算\(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\)的负对数，即\(k\)的得分，并输出一个得分最低的\(k\)。
- en: '[PRE2]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**NUMERICAL CORNER:** We use a simple example from [Stack Overflow](https://stackoverflow.com/questions/10059594/):'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角落:** 我们使用[Stack Overflow](https://stackoverflow.com/questions/10059594/)的一个简单示例：'
- en: '**Example:** Let’s say we have data on 1000 pieces of fruit. They happen to
    be Banana, Orange or some Other Fruit. We know 3 characteristics about each fruit:
    whether it is long, whether it is sweet, and if its color is yellow[, as displayed
    in the table below].'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**示例:** 假设我们有关于1000件水果的数据。它们可能是香蕉、橙子或其他水果。我们知道每件水果的3个特征：它是否长，是否甜，以及它的颜色是否为黄色[如下表所示]。'
- en: '| Fruit | Long | Sweet | Yellow | Total |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 水果 | 长的 | 甜的 | 黄色的 | 总计 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Banana | 400 | 350 | 450 | 500 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 香蕉 | 400 | 350 | 450 | 500 |'
- en: '| Orange | 0 | 150 | 300 | 300 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 橙子 | 0 | 150 | 300 | 300 |'
- en: '| Other | 100 | 150 | 50 | 200 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | 100 | 150 | 50 | 200 |'
- en: '| Total | 500 | 650 | 800 | 1000 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 500 | 650 | 800 | 1000 |'
- en: '[PRE3]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We run `nb_fit_table` on our simple dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的简单数据集上运行`nb_fit_table`。
- en: '[PRE4]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Continuing on with our previous example:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们之前的例子：
- en: Let’s say that we are given the properties of an unknown fruit, and asked to
    classify it. We are told that the fruit is Long, Sweet and Yellow. Is it a Banana?
    Is it an Orange? Or Is it some Other Fruit?
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们被给出了一个未知水果的特性，并要求对其进行分类。我们被告知该水果是长的、甜的和黄色的。它是香蕉吗？它是橙子吗？还是它是其他水果？
- en: We run `nb_predict` on our dataset with the additional fruit from the quote
    above.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在包含上述引用中提到的额外水果的数据集上运行`nb_predict`。
- en: '[PRE8]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: \(\unlhd\)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**CHAT & LEARN** Laplace smoothing is a special case of a more general technique
    known as Bayesian parameter estimation. Ask your favorite AI chatbot to explain
    Bayesian parameter estimation and how it relates to maximum likelihood estimation
    and Laplace smoothing. \(\ddagger\)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 拉普拉斯平滑是更一般技术，即贝叶斯参数估计的一个特例。请你的最爱AI聊天机器人解释贝叶斯参数估计以及它与最大似然估计和拉普拉斯平滑的关系。
    \(\ddagger\)'
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(由克莱德、双子星和ChatGPT协助)*'
- en: '**1** Which of the following statements is **not** true about conditional probabilities?'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 以下哪个关于条件概率的陈述是不正确的？'
- en: a) \(\mathbb{P}[A|B] = \frac{\mathbb{P}[A \cap B]}{\mathbb{P}[B]}\) for events
    \(A\) and \(B\) with \(\mathbb{P}[B] > 0\).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: a) 对于事件 \(A\) 和 \(B\)，当 \(\mathbb{P}[B] > 0\) 时，有 \(\mathbb{P}[A|B] = \frac{\mathbb{P}[A
    \cap B]}{\mathbb{P}[B]}\)。
- en: b) If \(A\) and \(B\) are independent, then \(\mathbb{P}[A|B] = \mathbb{P}[A]\).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: b) 如果 \(A\) 和 \(B\) 是独立的，那么 \(\mathbb{P}[A|B] = \mathbb{P}[A]\)。
- en: c) Conditional probabilities can be used to express the multiplication rule
    and the law of total probability.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: c) 条件概率可以用来表达乘法规则和全概率公式。
- en: d) \(\mathbb{P}[A|B] = \mathbb{P}[B|A]\) for any events \(A\) and \(B\).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对于任何事件 \(A\) 和 \(B\)，有 \(\mathbb{P}[A|B] = \mathbb{P}[B|A]\)。
- en: '**2** Which of the following is the correct mathematical expression for the
    conditional independence of events \(A\) and \(B\) given event \(C\), denoted
    as \(A \perp\!\!\!\perp B \mid C\)?'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 以下哪个是事件 \(A\) 和 \(B\) 在事件 \(C\) 条件下的条件独立性（记作 \(A \perp\!\!\!\perp B \mid
    C\)）的正确数学表达式？'
- en: a) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] + \mathbb{P}[B \mid
    C]\)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] + \mathbb{P}[B \mid
    C]\)
- en: b) \(\mathbb{P}[A \cup B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\mathbb{P}[A \cup B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
- en: c) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
- en: d) \(\mathbb{P}[A \mid B \cap C] = \mathbb{P}[A \mid C]\)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\mathbb{P}[A \mid B \cap C] = \mathbb{P}[A \mid C]\)
- en: '**3** In the fork configuration \(Y \leftarrow X \rightarrow Z\), which of
    the following conditional independence relations always holds?'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 在分叉配置 \(Y \leftarrow X \rightarrow Z\) 中，以下哪个条件独立性关系始终成立？'
- en: a) \(X \perp\!\!\!\perp Y \mid Z\)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(X \perp\!\!\!\perp Y \mid Z\)
- en: b) \(Y \perp\!\!\!\perp Z \mid X\)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(Y \perp\!\!\!\perp Z \mid X\)
- en: c) \(X \perp\!\!\!\perp Z \mid Y\)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(X \perp\!\!\!\perp Z \mid Y\)
- en: d) \(Y \perp\!\!\!\perp Z\)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(Y \perp\!\!\!\perp Z\)
- en: '**4** In the collider configuration \(X \rightarrow Z \leftarrow Y\), which
    of the following conditional independence relations always holds?'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 在碰撞配置 \(X \rightarrow Z \leftarrow Y\) 中，以下哪个条件独立性关系始终成立？'
- en: a) \(X \perp\!\!\!\perp Y \mid Z\)
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(X \perp\!\!\!\perp Y \mid Z\)
- en: b) \(Y \perp\!\!\!\perp Z \mid X\)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(Y \perp\!\!\!\perp Z \mid X\)
- en: c) \(X \perp\!\!\!\perp Z \mid Y\)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(X \perp\!\!\!\perp Z \mid Y\)
- en: d) \(X \perp\!\!\!\perp Y\)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(X \perp\!\!\!\perp Y\)
- en: '**5** Which of the following best describes the graphical representation of
    the Naive Bayes model for document classification?'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪个最好地描述了文档分类的朴素贝叶斯模型的图形表示？'
- en: a) A chain with the topic variable at the center and word variables as the links.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: a) 以主题变量为中心，以单词变量为链环的链。
- en: b) A collider with the topic variable at the center and word variables as the
    parents.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: b) 以主题变量为中心的碰撞器，以单词变量为父变量。
- en: c) A fork with the topic variable at the center and word variables as the prongs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: c) 以主题变量为中心，以单词变量为枝条的叉形。
- en: d) A complete graph with edges between all pairs of variables.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: d) 包含所有变量对边的完整图。
- en: 'Answer for 1: d. Justification: In general, \(\mathbb{P}[A|B] \neq \mathbb{P}[B|A]\).
    Bayes’ rule provides the correct relationship between these two conditional probabilities.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 1的答案：d. 理由：一般来说，\(\mathbb{P}[A|B] \neq \mathbb{P}[B|A]\)。贝叶斯定理提供了这两个条件概率之间的正确关系。
- en: 'Answer for 2: c. Justification: The text states, “Then \(A\) and \(B\) are
    conditionally independent given \(C\), denoted \(A \perp\!\!\!\perp B \mid C\),
    if \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\).”'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 2的答案：c. 理由：文本中提到，“然后 \(A\) 和 \(B\) 在 \(C\) 的条件下是条件独立的，记作 \(A \perp\!\!\!\perp
    B \mid C\)，如果 \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B
    \mid C]\)。”
- en: 'Answer for 3: b. Justification: The text states, “Removing the edge from \(Y\)
    to \(Z\) gives the following graph, known as a fork. We denote this configuration
    as \(Y \leftarrow X \rightarrow Z\). […] The corresponding conditional independence
    relation is \(Z \perp\!\!\!\perp Y \mid X\).”'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 答案 3：b. 证明：文本中提到，“从 \(Y\) 到 \(Z\) 移除边后得到以下图，称为分叉。我们用 \(Y \leftarrow X \rightarrow
    Z\) 表示这种配置。[...] 相应的条件独立性关系是 \(Z \perp\!\!\!\perp Y \mid X\)。”
- en: 'Answer for 4: d. Justification: The text states, “Removing the edge from \(X\)
    to \(Y\) gives the following graph, known as a collider. We denote this configuration
    as \(X \rightarrow Z \leftarrow Y\). […] This time we have \(X \perp\!\!\!\perp
    Y\).”'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 答案 4：d. 证明：文本中提到，“从 \(X\) 到 \(Y\) 移除边后得到以下图，称为碰撞器。我们用 \(X \rightarrow Z \leftarrow
    Y\) 表示这种配置。[...] 这次我们有 \(X \perp\!\!\!\perp Y\)。”
- en: 'Answer for 5: c. Justification: The text states, “Graphically, this is similar
    to a fork with \(C\) at its center and \(M\) prongs for the \(X_m\)s.”'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 答案 5：c. 证明：文本中提到，“从图形上看，这与以 \(C\) 为中心、\(M\) 为 \(X_m\) 的支点的分叉相似。”
- en: 6.3.1\. Review of conditioning[#](#review-of-conditioning "Link to this heading")
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.1\. 条件化回顾[#](#review-of-conditioning "链接到这个标题")
- en: We first review the concept of conditioning, which generally plays a key role
    in probabilistic modeling and reasoning.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先回顾条件化的概念，这在概率建模和推理中通常起着关键作用。
- en: '**Conditional probability** We start with events. Throughout, we work on a
    fixed probability space \((\Omega, \mathcal{F}, \P)\), which we assume is discrete,
    i.e., the number of elements in \(\Omega\) is countable.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件概率** 我们从事件开始。在整个过程中，我们在一个固定的概率空间 \((\Omega, \mathcal{F}, \P)\) 上工作，我们假设它是离散的，即
    \(\Omega\) 中元素的数量是可数的。'
- en: '**DEFINITION** **(Conditional Probability)** \(\idx{conditional probability}\xdi\)
    Let \(A\) and \(B\) be two events with \(\mathbb{P}[B] > 0\). The conditional
    probability of \(A\) given \(B\) is defined as'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（条件概率）** \(\idx{conditional probability}\xdi\) 设 \(A\) 和 \(B\) 是两个事件，且
    \(\mathbb{P}[B] > 0\)。\(B\) 给定 \(A\) 的条件概率定义为'
- en: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]}. \]
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]}. \]
- en: \(\natural\)
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: 'The intuitive interpretation goes something like this: knowing that event \(B\)
    has occurred, the updated probability of observing \(A\) is the probability of
    its restriction to \(B\) properly normalized to reflect that outcomes outside
    \(B\) have updated probability \(0\).'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 直观的解释大致如下：知道事件 \(B\) 已经发生，观察 \(A\) 的更新概率是其限制在 \(B\) 上的概率，并且适当地归一化以反映 \(B\) 之外的结果更新概率为
    \(0\)。
- en: Conditional probabilities generally behave like “unconditional” probabilities.
    (See for instance Problems 6.8, 7.1, and 7.9.)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率通常表现得像“无条件”概率。（例如，参见问题 6.8、7.1 和 7.9。）
- en: Independence can be characterized in terms of conditional probability. In words,
    \(A\) and \(B\) are independent if conditioning on one of them having taken place
    does not change the probability of the other occurring.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性可以用条件概率来描述。换句话说，如果基于其中一个事件已经发生来条件化，不会改变另一个事件发生的概率，那么 \(A\) 和 \(B\) 是独立的。
- en: '**LEMMA** Let \(A\) and \(B\) be two events of positive probability. Then \(A\)
    and \(B\) are independent, which we will denote as \(A \indep B\), if and only
    if \(\P[A|B] = \P[A]\) and \(\P[B|A] = \P[B]\). \(\flat\)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** 设 \(A\) 和 \(B\) 是两个概率大于零的事件。那么 \(A\) 和 \(B\) 是独立的，我们将其表示为 \(A \indep
    B\)，当且仅当 \(\P[A|B] = \P[A]\) 和 \(\P[B|A] = \P[B]\)。 \(\flat\)'
- en: '*Proof:* If \(A\) and \(B\) are independent, then \(\P[A \cap B] = \P[A] \P[B]\)
    which implies'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：* 如果 \(A\) 和 \(B\) 是独立的，那么 \(\P[A \cap B] = \P[A] \P[B]\)，这表明'
- en: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \P[B]}{\P[B]} = \P[A].
    \]
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \P[B]}{\P[B]} = \P[A].
    \]
- en: In the other direction,
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在相反的方向，
- en: \[ \P[A] = \P[A|B] = \frac{\P[A \cap B]}{\P[B]} \]
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A] = \P[A|B] = \frac{\P[A \cap B]}{\P[B]} \]
- en: implies \(\P[A \cap B] = \P[A]\P[B]\) after rearranging. \(\square\)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 经过重新排列后，意味着 \(\P[A \cap B] = \P[A]\P[B]\)。 \(\square\)
- en: The conditional probability is often used in three fundamental ways, which we
    recall next. Proofs can be found in most probability textbooks.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率通常以三种基本方式使用，我们将在下面回忆。证明可以在大多数概率教科书中找到。
- en: '**Multiplication Rule:** \(\idx{multiplication rule}\xdi\) For any collection
    of events \(A_1,\ldots,A_r\),'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**乘法法则：** \(\idx{multiplication rule}\xdi\) 对于任何事件集合 \(A_1,\ldots,A_r\)，'
- en: \[ \P\left[\cap_{i=1}^r A_i\right] = \prod_{i=1}^r \P\left[A_i \,\middle|\,
    \cap_{j=1}^{i-1} A_j \right]. \]
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P\left[\cap_{i=1}^r A_i\right] = \prod_{i=1}^r \P\left[A_i \,\middle|\,
    \cap_{j=1}^{i-1} A_j \right]. \]
- en: '**Law of Total Probability:** \(\idx{law of total probability}\xdi\) For any
    event \(B\) and any [partition](https://en.wikipedia.org/wiki/Partition_of_a_set#Definition_and_Notation)\(\idx{partition}\xdi\)
    \(A_1,\ldots,A_r\) of \(\Omega\),'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全概率公式:** \(\idx{全概率公式}\xdi\) 对于任何事件 \(B\) 和任何 \(\Omega\) 的划分 \(\idx{划分}\xdi\)
    \(A_1,\ldots,A_r\)，'
- en: \[ \P[B] = \sum_{i=1}^r \P[B|A_i] \P[A_i]. \]
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[B] = \sum_{i=1}^r \P[B|A_i] \P[A_i]. \]
- en: '**Bayes’ Rule:** \(\idx{Bayes'' yule}\xdi\) For any events \(A\) and \(B\)
    with positive probability,'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯定理:** \(\idx{贝叶斯定理}\xdi\) 对于任何具有正概率的事件 \(A\) 和 \(B\)，'
- en: \[ \P[A|B] = \frac{\P[B|A]\P[A]}{\P[B]}. \]
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A|B] = \frac{\P[B|A]\P[A]}{\P[B]}. \]
- en: It is implicit that all formulas above hold provided all conditional probabilities
    are well-defined.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，上述所有公式在所有条件概率都定义良好的情况下成立。
- en: '**Conditioning on a random variable** Conditional probabilities extend naturally
    to random variables. If \(X\) is a discrete random variable, we let \(p_X\) be
    its probability mass function and \(\S_X\) be its support, that is, the set of
    values where it has positive probability. Then we can for instance condition on
    the event \(\{X = x\}\) for any \(x \in \S_X\).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**对随机变量的条件化** 条件概率自然地扩展到随机变量。如果 \(X\) 是一个离散随机变量，我们让 \(p_X\) 是它的概率质量函数，\(\S_X\)
    是它的支撑集，即它具有正概率的值的集合。然后我们可以对任何 \(x \in \S_X\) 的事件 \(\{X = x\}\) 进行条件化。'
- en: We define next the conditional probability mass function.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来定义条件概率质量函数。
- en: '**DEFINITION** **(Conditional Probability Mass Function)** Let \(X\) and \(Y\)
    be discrete random variables with joint probability mass function \(p_{X, Y}\)
    and marginals \(p_X\) and \(p_Y\). The conditional probability mass function\(\idx{conditional
    probability mass function}\xdi\) of \(X\) given \(Y\) is defined as'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(条件概率质量函数)** 设 \(X\) 和 \(Y\) 是具有联合概率质量函数 \(p_{X, Y}\) 和边缘 \(p_X\)
    和 \(p_Y\) 的离散随机变量。\(X\) 给定 \(Y\) 的条件概率质量函数\(\idx{条件概率质量函数}\xdi\) 定义为'
- en: \[ p_{X|Y}(x|y) := P[X=x|Y=y] = \frac{p_{X,Y}(x,y)}{p_Y(y)} \]
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p_{X|Y}(x|y) := P[X=x|Y=y] = \frac{p_{X,Y}(x,y)}{p_Y(y)} \]
- en: which is defined for all \(x \in \S_X\) and \(y \in \S_Y\). \(\natural\)
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 该公式适用于所有 \(x \in \S_X\) 和 \(y \in \S_Y\)。\(\natural\)
- en: The conditional expectation can then be defined in a natural way as the expectation
    over the conditional probability mass function.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，条件期望可以自然地定义为条件概率质量函数的期望。
- en: '**DEFINITION** **(Conditional Expectation)** \(\idx{conditional expectation}\xdi\)
    Let \(X\) and \(Y\) be discrete random variables where \(X\) takes real values
    and has a finite mean. The conditional expectation of \(X\) given \(Y = y\) is
    given by'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(条件期望)** \(\idx{条件期望}\xdi\) 设 \(X\) 和 \(Y\) 是离散随机变量，其中 \(X\) 取实数值且具有有限均值。给定
    \(Y = y\) 的 \(X\) 的条件期望由'
- en: \[ \E[X|Y=y] = \sum_{x \in \S_X} x\, p_{X|Y}(x|y). \]
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[X|Y=y] = \sum_{x \in \S_X} x\, p_{X|Y}(x|y). \]
- en: \(\natural\)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: More generally, for a function \(f\) over the range of \(X\), we can define
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，对于 \(X\) 的值域上的函数 \(f\)，我们可以定义
- en: \[ \E[f(X)|Y=y] = \sum_{x \in \S_X} f(x)\, p_{X|Y}(x|y). \]
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[f(X)|Y=y] = \sum_{x \in \S_X} f(x)\, p_{X|Y}(x|y). \]
- en: 'We mention one useful formula: the *Law of Total Expectation*\(\idx{law of
    total expectation}\xdi\), the expectation version of the *Law of Total Probability*.
    It reads'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到一个有用的公式：**全期望公式**\(\idx{全期望公式}\xdi\)，它是**全概率公式**的期望版本。它读作
- en: \[ \E[f(X)] = \sum_{y \in \S_Y} \E[f(X)|Y=y] \,p_Y(y). \]
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \E[f(X)] = \sum_{y \in \S_Y} \E[f(X)|Y=y] \,p_Y(y). \]
- en: '**Conditional expectation as least-squares estimator** Thinking of \(\E[X|Y=y]\)
    as a function of \(y\) leads to a fundamental characterization of the conditional
    expectation.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件期望作为最小二乘估计器** 将 \(\E[X|Y=y]\) 视为 \(y\) 的函数，导致条件期望的一个基本特征描述。'
- en: '**THEOREM** Let \(X\) and \(Y\) be discrete random variables where \(X\) takes
    real values and has a finite variance. Then the conditional expectation \(h(y)
    = \E[X|Y=y]\) minimizes the least squares criterion'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**定理** 设 \(X\) 和 \(Y\) 是离散随机变量，其中 \(X\) 取实数值且具有有限方差。那么条件期望 \(h(y) = \E[X|Y=y]\)
    最小化最小二乘准则'
- en: \[ \min_{h} \E\left[(X - h(Y))^2\right] \]
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \min_{h} \E\left[(X - h(Y))^2\right] \]
- en: where the minimum is over all real-valued functions of \(y\). \(\sharp\)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 其中最小值是在所有 \(y\) 的实值函数上取的。\(\sharp\)
- en: '*Proof:* Think of \(h(y)\) as a vector \(\mathbf{h} = (h_y)_{y \in \S_Y}\),
    indexed by \(\S_Y\) (which is countable by assumption), with \(h_y = h(y) \in
    \mathbb{R}\). Then'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明:* 将 \(h(y)\) 视为一个向量 \(\mathbf{h} = (h_y)_{y \in \S_Y}\)，由 \(\S_Y\) （根据假设是可数的）索引，其中
    \(h_y = h(y) \in \mathbb{R}\)。然后'
- en: \[\begin{align*} \mathcal{L}(\mathbf{h}) &=\E\left[(X - h(Y))^2\right]\\ &=
    \sum_{x\in \S_X} \sum_{y \in \S_Y} (x - h_y)^2 p_{X,Y}(x,y)\\ &= \sum_{y \in \S_Y}
    \left[\sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\right]. \end{align*}\]
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \mathcal{L}(\mathbf{h}) &=\E\left[(X - h(Y))^2\right]\\ &=
    \sum_{x\in \S_X} \sum_{y \in \S_Y} (x - h_y)^2 p_{X,Y}(x,y)\\ &= \sum_{y \in \S_Y}
    \left[\sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\right]. \end{align*}\]
- en: Expanding the sum in the square brackets (which we denote by \(q_y\) and think
    of as a function of \(h_y\)) gives
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 展开方括号中的和（我们将其表示为 \(q_y\) 并将其视为 \(h_y\) 的函数）给出
- en: \[\begin{align*} q_y(h_y) &:= \sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\\ &=
    \sum_{x\in \S_X} [x^2 - 2 x h_y + h_y^2] \,p_{X,Y}(x,y)\\ &= \left\{\sum_{x\in
    \S_X} x^2 p_{X,Y}(x,y)\right\} + \left\{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)\right\}
    h_y + \left\{p_Y(y)\right\} h_y^2. \end{align*}\]
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} q_y(h_y) &:= \sum_{x\in \S_X} (x - h_y)^2 p_{X,Y}(x,y)\\ &=
    \sum_{x\in \S_X} [x^2 - 2 x h_y + h_y^2] \,p_{X,Y}(x,y)\\ &= \left\{\sum_{x\in
    \S_X} x^2 p_{X,Y}(x,y)\right\} + \left\{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)\right\}
    h_y + \left\{p_Y(y)\right\} h_y^2. \end{align*}\]
- en: By the *Miminizing a Quadratic Function Lemma*, the unique global minimum of
    \(q_y(h_y)\) - provided \(p_Y(y) > 0\) - is attained at
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最小化二次函数引理，在 \(p_Y(y) > 0\) 的条件下，\(q_y(h_y)\) 的唯一全局最小值在
- en: \[ h_y = - \frac{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)}{2 p_Y(y)}. \]
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_y = - \frac{- 2 \sum_{x\in \S_X} x p_{X,Y}(x,y)}{2 p_Y(y)}. \]
- en: After rearranging, we get
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 重新排列后，我们得到
- en: \[ h_y = \sum_{x\in \S_X} x \frac{p_{X,Y}(x,y)}{p_Y(y)} = \sum_{x\in \S_X} x
    p_{X|Y}(x|y) = \E[X|Y=y] \]
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: \[ h_y = \sum_{x\in \S_X} x \frac{p_{X,Y}(x,y)}{p_Y(y)} = \sum_{x\in \S_X} x
    p_{X|Y}(x|y) = \E[X|Y=y] \]
- en: as claimed. \(\square\)
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称。 \(\square\)
- en: '**Conditional independence** Next, we discuss conditional independence. We
    begin with the formal definition.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件独立性** 接下来，我们讨论条件独立性。我们首先从其形式定义开始。'
- en: '**DEFINITION** **(Conditional Independence)** \(\idx{conditional independence}\xdi\)
    Let \(A, B, C\) be events such that \(\P[C] > 0\). Then \(A\) and \(B\) are conditionally
    independent given \(C\), denoted \(A \indep B | C\), if'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **（条件独立性）** \(\idx{条件独立性}\xdi\) 设 \(A, B, C\) 为事件，且 \(\P[C] > 0\)。那么
    \(A\) 和 \(B\) 在给定 \(C\) 的条件下是条件独立的，表示为 \(A \indep B | C\)，如果'
- en: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C]. \]
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C]. \]
- en: \(\natural\)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: 'In words, quoting [Wikipedia](https://en.wikipedia.org/wiki/Conditional_independence):'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '用文字来说，引用 [维基百科](https://en.wikipedia.org/wiki/Conditional_independence):'
- en: \(A\) and \(B\) are conditionally independent given \(C\) if and only if, given
    knowledge that \(C\) occurs, knowledge of whether \(A\) occurs provides no information
    on the likelihood of \(B\) occurring, and knowledge of whether \(B\) occurs provides
    no information on the likelihood of \(A\) occurring.
  id: totrans-268
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(A\) 和 \(B\) 在给定 \(C\) 的条件下是条件独立的，当且仅当，在知道 \(C\) 发生的条件下，\(A\) 发生的知识不会提供关于 \(B\)
    发生可能性的信息，反之亦然。
- en: In general, conditionally independent events are not (unconditionally) independent.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，条件独立事件不是（无条件）独立的。
- en: '**EXAMPLE:** Imagine I have two six-sided dice. Die 1 has faces \(\{1,3,5,7,9,11\}\)
    and die 2 has faces \(\{2, 4, 6, 8, 10, 12\}\). Suppose I perform the following
    experiment: I pick one of the two dice uniformly at random, and then I roll that
    die twice. Let \(X_1\) and \(X_2\) be the outcomes of the rolls. Consider the
    events \(A = \{X_1 = 1\}\), \(B = \{X_2 = 2\}\), and \(C = \{\text{die 1 is picked}\}\).
    The events \(A\) and \(B\) are clearly dependent: if \(A\) occurs, then I know
    that die 1 was picked, and hence \(B\) cannot occur. Knowledge of one event provides
    information about the likelihood of the other event occurring. Formally, by the
    law of total probability,'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**：想象我有两个六面的骰子。骰子1的面是 \(\{1,3,5,7,9,11\}\)，骰子2的面是 \(\{2, 4, 6, 8, 10, 12\}\)。假设我进行以下实验：我随机选择两个骰子中的一个，然后掷两次。设
    \(X_1\) 和 \(X_2\) 为掷出的结果。考虑事件 \(A = \{X_1 = 1\}\)，\(B = \{X_2 = 2\}\)，和 \(C =
    \{\text{选择骰子1}\}\)。事件 \(A\) 和 \(B\) 显然是相关的：如果 \(A\) 发生，那么我知道选择了骰子1，因此 \(B\) 不能发生。一个事件的知识提供了关于另一个事件发生可能性的信息。形式上，根据全概率定律，'
- en: \[ \P[A] = \P[A|C]\P[C] + \P[A|C^c]\P[C^c] = \frac{1}{6}\frac{1}{2} + 0 \frac{1}{2}
    = \frac{1}{12}. \]
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A] = \P[A|C]\P[C] + \P[A|C^c]\P[C^c] = \frac{1}{6}\frac{1}{2} + 0 \frac{1}{2}
    = \frac{1}{12}. \]
- en: Similarly \(\P[B] = \frac{1}{12}\). Yet \(\P[A \cap B] = 0 \neq \frac{1}{12}
    \frac{1}{12}\).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地 \(\P[B] = \frac{1}{12}\)。然而 \(\P[A \cap B] = 0 \neq \frac{1}{12} \frac{1}{12}\)。
- en: 'On the other hand, we claim that \(A\) and \(B\) are conditionally independent
    given \(C\). Again this is intuitively clear: once I pick a die, the two rolls
    are independent. For a given die choice, knowledge of one roll provides no information
    about the likelihood of the other roll. Note that the phrase “for a given die
    choice” is critical in the last statement. Formally, by our experiment, we have
    \(\P[A|C] = 1/6\), \(\P[B|C] = 0\) and \(\P[A \cap B|C] = 0\). So indeed'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们断言，在给定 \(C\) 的条件下，\(A\) 和 \(B\) 是条件独立的。这从直观上很清楚：一旦我选择了一个骰子，两次投掷是独立的。对于给定的骰子选择，一次投掷的知识不会提供关于另一次投掷可能性的任何信息。注意，在最后一条陈述中，“对于给定的骰子选择”这个短语是关键的。根据我们的实验，我们有
    \(\P[A|C] = 1/6\)，\(\P[B|C] = 0\) 和 \(\P[A \cap B|C] = 0\)。因此，确实
- en: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C] \]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[A \cap B| C] = \P[A|C] \,\P[B|C] \]
- en: as claimed. \(\lhd\)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称。\(\lhd\)
- en: Conditional independence is naturally extended to random vectors.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 条件独立性自然扩展到随机向量。
- en: '**DEFINITION** **(Conditional Independence of Random Vectors)** Let \(\bX,
    \bY, \bW\) be discrete random vectors. Then \(\bX\) and \(\bY\) are said to be
    conditionally independent given \(\bW\), denoted \(\bX \indep \bY | \bW\), if
    for all \(\bx \in \S_\bX\), \(\by \in \S_\bY\) and \(\bw \in \S_\bW\)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** **(随机向量的条件独立性)** 设 \(\bX, \bY, \bW\) 是离散随机向量。如果对于所有 \(\bx \in \S_\bX\)，\(\by
    \in \S_\bY\) 和 \(\bw \in \S_\bW\)，'
- en: \[ \P[\bX = \bx, \bY = \by|\bW = \bw] = \P[\bX = \bx |\bW = \bw] \,\P[\bY =
    \by|\bW = \bw]. \]
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[\bX = \bx, \bY = \by|\bW = \bw] = \P[\bX = \bx |\bW = \bw] \,\P[\bY =
    \by|\bW = \bw]. \]
- en: \(\natural\)
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: \(\natural\)
- en: An important consequence is that we can drop the conditioning by the independent
    variable.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的后果是我们可以省略独立变量的条件。
- en: '**LEMMA** **(Role of Independence)** \(\idx{role of independence lemma}\xdi\)
    Let \(\bX, \bY, \bW\) be discrete random vectors such that \(\bX \indep \bY |
    \bW\). For all \(\bx \in \S_\bX\), \(\by \in \S_\bY\) and \(\bw \in \S_\bW\),'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**引理** **(独立性的作用)** \(\idx{独立性的作用引理}\xdi\) 设 \(\bX, \bY, \bW\) 是离散随机向量，使得 \(\bX
    \indep \bY | \bW\)。对于所有 \(\bx \in \S_\bX\)，\(\by \in \S_\bY\) 和 \(\bw \in \S_\bW\)，'
- en: \[ \P[\bX = \bx | \bY=\by, \bW=\bw] = \P[\bX = \bx | \bW = \bw]. \]
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[\bX = \bx | \bY=\by, \bW=\bw] = \P[\bX = \bx | \bW = \bw]. \]
- en: \(\flat\)
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: \(\flat\)
- en: '*Proof:* In a previous exercise, we showed that \(A \indep B | C\) implies
    \(\P[A | B\cap C] = \P[A | C]\). That implies the claim. \(\square\)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明* 在之前的练习中，我们证明了 \(A \indep B | C\) 蕴含 \(\P[A | B\cap C] = \P[A | C]\)。这证明了我们的断言。\(\square\)'
- en: '**CHAT & LEARN** The concept of conditional independence is closely related
    to the concept of d-separation in probabilistic graphical models. Ask your favorite
    AI chatbot to explain d-separation. \(\ddagger\)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 条件独立性的概念与概率图模型中的 d-separation 概念密切相关。请你的喜欢的 AI 聊天机器人解释 d-separation。\(\ddagger\)'
- en: 6.3.2\. The basic configurations[#](#the-basic-configurations "Link to this
    heading")
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.2\. 基本配置[#](#the-basic-configurations "链接到这个标题")
- en: A powerful approach for constructing complex probability distributions is the
    use of conditional independence. The case of three random variables exemplifies
    key probabilistic relationships. By the product rule, we can write
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 构建复杂概率分布的一个强大方法是使用条件独立性。三个随机变量的情况可以说明关键的概率关系。根据乘法法则，我们可以写出
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x, Y=y]. \]
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x, Y=y]. \]
- en: 'This is conveniently represented through a digraph where the vertices are the
    variables. Recall that an arrow \((i,j)\), from \(i\) to \(j\), indicates that
    \(i\) is a parent of \(j\) and that \(j\) is a child of \(i\). Let \(\pa(i)\)
    be the set of parents of \(i\). The digraph \(G = (V, E)\) below encodes the following
    sampling scheme, referred as ancestral sampling:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过一个有向图方便地表示，其中顶点是变量。回想一下，从 \(i\) 到 \(j\) 的箭头 \((i,j)\) 表示 \(i\) 是 \(j\)
    的父节点，而 \(j\) 是 \(i\) 的子节点。设 \(\pa(i)\) 为 \(i\) 的父节点集合。下面的有向图 \(G = (V, E)\) 编码了以下采样方案，称为祖先采样：
- en: First we pick \(X\) according to its marginal \(\P[X=x]\). Note that \(X\) has
    no parent in \(G\).
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们根据其边缘概率分布 \(\P[X=x]\) 选择 \(X\)。注意 \(X\) 在 \(G\) 中没有父节点。
- en: Second we pick \(Y\) according to the conditional probability distribution (CPD)
    \(\P[Y=y|X=x]\). Note that \(X\) is the only parent of \(Y\).
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二步，我们根据条件概率分布 (CPD) \(\P[Y=y|X=x]\) 选择 \(Y\)。注意 \(X\) 是 \(Y\) 的唯一父节点。
- en: Finally we pick \(Z\) according to the CPD \(\P[Z=z|X=x, Y=y]\). Note that the
    parents of \(Z\) are \(X\) and \(Y\).
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后我们根据条件概率分布 \(\P[Z=z|X=x, Y=y]\) 选择 \(Z\)。注意 \(Z\) 的父节点是 \(X\) 和 \(Y\)。
- en: '![The full case](../Images/b73cb01c1b1f5d32087884467af21283.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![完整案例](../Images/b73cb01c1b1f5d32087884467af21283.png)'
- en: The graph above is acyclic, that is, it has no directed cycle. The variables
    \(X, Y, Z\) are in [topological order](https://en.wikipedia.org/wiki/Topological_sorting)\(\idx{topological
    order}\xdi\), that is, all edges \((i,j)\) are such that \(i\) comes before \(j\)
    in that order.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图是无环的，也就是说，它没有有向循环。变量 \(X, Y, Z\) 按照拓扑顺序排列（[拓扑排序](https://en.wikipedia.org/wiki/Topological_sorting)\(\idx{拓扑排序}\xdi\)），也就是说，所有边
    \((i,j)\) 都满足 \(i\) 在该顺序中先于 \(j\)。
- en: The same joint distribution can be represented by a different digraph if the
    product rule is used in a different order. For instance,
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用不同的顺序应用乘法规则，相同的联合分布可以用不同的有向图表示。例如，
- en: \[ \P[X=x, Y=y, Z=z] = \P[Z=z] \,\P[Y=y|Z=z] \,\P[X=x | Z=z, Y=y] \]
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[Z=z] \,\P[Y=y|Z=z] \,\P[X=x | Z=z, Y=y] \]
- en: is represented by the following digraph. A topological order this time is \(Z,
    Y, X\).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 表示为以下有向图。这次拓扑顺序是 \(Z, Y, X\)。
- en: '![Another full case](../Images/ed39c216e1efdc59d602be7c9e2c744a.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![另一个完整案例](../Images/ed39c216e1efdc59d602be7c9e2c744a.png)'
- en: '**The fork** \(\idx{fork}\xdi\) Removing edges in the first graph above encodes
    conditional independence relations. For instance, removing the edge from \(Y\)
    to \(Z\) gives the following graph, known as a fork. We denote this configuration
    as \(Y \leftarrow X \rightarrow Z\).'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**分叉** \(\idx{分叉}\xdi\) 在上面的第一个图中移除边编码了条件独立性关系。例如，移除从 \(Y\) 到 \(Z\) 的边得到以下图，称为分叉。我们用
    \(Y \leftarrow X \rightarrow Z\) 表示这种配置。'
- en: '![The fork](../Images/77cb78740ee4952c17900d2626c7ad2a.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![分叉](../Images/77cb78740ee4952c17900d2626c7ad2a.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布可以简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]. \]
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]. \]
- en: So, in this case, what has changed is that the CPD of \(Z\) does not depend
    on the value of \(Y\). From the *Role of Independence* lemma, this corresponds
    to assuming the conditional independence \(Z \indep Y|X\). Indeed, we can check
    that claim directly from the joint distribution
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，变化的是 \(Z\) 的条件概率表（CPD）不依赖于 \(Y\) 的值。根据 *独立性的作用* 公理，这对应于假设条件独立性 \(Z
    \indep Y|X\)。确实，我们可以直接从联合分布中验证这一说法
- en: \[\begin{align*} \P[Y= y, Z=z|X=x] &= \frac{\P[X=x, Y= y, Z=z]}{\P[X=x]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]}{\P[X=x]}\\ &= \P[Y=y|X=x] \,\P[Z=z
    | X=x] \end{align*}\]
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[Y= y, Z=z|X=x] &= \frac{\P[X=x, Y= y, Z=z]}{\P[X=x]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | X=x]}{\P[X=x]}\\ &= \P[Y=y|X=x] \,\P[Z=z
    | X=x] \end{align*}\]
- en: as claimed.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称的。
- en: '**The chain** \(\idx{chain}\xdi\) Removing the edge from \(X\) to \(Z\) gives
    the following graph, known as a chain (or pipe). We denote this configuration
    as \(X \rightarrow Y \rightarrow Z\).'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '**链** \(\idx{链}\xdi\) 从 \(X\) 到 \(Z\) 移除边得到以下图，称为链（或管道）。我们用 \(X \rightarrow
    Y \rightarrow Z\) 表示这种配置。'
- en: '![The chain](../Images/5bfd7c9b4911ca0e5931761d25c8457e.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![链](../Images/5bfd7c9b4911ca0e5931761d25c8457e.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布可以简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]. \]
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]. \]
- en: In this case, what has changed is that the CPD of \(Z\) does not depend on the
    value of \(X\). Compare that to the fork. The corresponding conditional independence
    relation is \(Z \indep X|Y\). Indeed, we can check that claim directly
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，变化的是 \(Z\) 的条件概率表（CPD）不依赖于 \(X\) 的值。与分叉进行比较。相应的条件独立性关系是 \(Z \indep X|Y\)。确实，我们可以直接从联合分布中验证这一说法
- en: \[\begin{align*} \P[X= x, Z=z|Y=y] &= \frac{\P[X=x, Y= y, Z=z]}{\P[Y=y]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]} \end{align*}\]
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[X= x, Z=z|Y=y] &= \frac{\P[X=x, Y= y, Z=z]}{\P[Y=y]}\\ &=
    \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]} \end{align*}\]
- en: Now we have to use *Bayes’ Rule* to get
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须使用 *贝叶斯定理* 来得到
- en: \[\begin{align*} &= \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]}\\
    &= \frac{\P[Y=y|X=x]\,\P[X=x]}{\P[Y=y]} \P[Z=z | Y=y]\\ &= \P[X=x|Y=y] \,\P[Z=z
    | Y=y] \end{align*}\]
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &= \frac{\P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]}{\P[Y=y]}\\
    &= \frac{\P[Y=y|X=x]\,\P[X=x]}{\P[Y=y]} \P[Z=z | Y=y]\\ &= \P[X=x|Y=y] \,\P[Z=z
    | Y=y] \end{align*}\]
- en: as claimed.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称的。
- en: For any \(x, y, z\) where the joint probability is positive, we can re-write
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何 \(x, y, z\)，其中联合概率为正，我们可以重新写为
- en: \[\begin{align*} &\P[X=x, Y=y, Z=z]\\ &= \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]\\
    &= \P[Y=y] \,\P[X=x|Y=y] \,\P[Z=z | Y=y], \end{align*}\]
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &\P[X=x, Y=y, Z=z]\\ &= \P[X=x] \,\P[Y=y|X=x] \,\P[Z=z | Y=y]\\
    &= \P[Y=y] \,\P[X=x|Y=y] \,\P[Z=z | Y=y], \end{align*}\]
- en: where we used that
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们使用了
- en: \[ \P[X=x, Y=y] = \P[X=x] \,\P[Y=y|X=x] = \P[Y=y] \,\P[X=x|Y=y] \]
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y] = \P[X=x] \,\P[Y=y|X=x] = \P[Y=y] \,\P[X=x|Y=y] \]
- en: by definition of the conditional probability. In other words, we have shown
    that the chain \(X \rightarrow Y \rightarrow Z\) is in fact equivalent to the
    fork \(X \leftarrow Y \rightarrow Z\). In particular, they both correspond to
    assuming the conditional independence relation \(Z \indep X|Y\), although they
    capture a different way to sample the joint distribution.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 根据条件概率的定义。换句话说，我们已经表明链 \(X \rightarrow Y \rightarrow Z\) 实际上等同于分支 \(X \leftarrow
    Y \rightarrow Z\)。特别是，它们都对应于假设条件独立性关系 \(Z \indep X|Y\)，尽管它们捕获了采样联合分布的不同方式。
- en: '**The collider** \(\idx{collider}\xdi\) Removing the edge from \(X\) to \(Y\)
    gives the following graph, known as a collider. We denote this configuration as
    \(X \rightarrow Z \leftarrow Y\).'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**碰撞器** \(\idx{碰撞器}\xdi\) 从 \(X\) 到 \(Y\) 移除边得到以下图，称为碰撞器。我们用 \(X \rightarrow
    Z \leftarrow Y\) 表示这种配置。'
- en: '![The collider](../Images/a4600775ea580d4809bd8b11895a447d.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![碰撞器](../Images/a4600775ea580d4809bd8b11895a447d.png)'
- en: 'The joint distribution simplifies as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布可以简化如下：
- en: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]. \]
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \P[X=x, Y=y, Z=z] = \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]. \]
- en: In this case, what has changed is that the CPD of \(Y\) does not depend on the
    value of \(X\). Compare that to the fork and the chain. This time we have \(X
    \indep Y\). Indeed, we can check that claim directly
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，变化的是 \(Y\) 的条件概率表（CPD）不依赖于 \(X\) 的值。将其与分支和链进行比较。这次我们有 \(X \indep Y\)。确实，我们可以直接验证这个说法
- en: \[\begin{align*} \P[X= x, Y=y] &= \sum_{z \in \S_z} \P[X=x, Y=y, Z=z]\\ &= \sum_{z
    \in \S_z} \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]\\ &= \P[X=x] \,\P[Y=y] \end{align*}\]
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[X= x, Y=y] &= \sum_{z \in \S_z} \P[X=x, Y=y, Z=z]\\ &= \sum_{z
    \in \S_z} \P[X=x] \,\P[Y=y] \,\P[Z=z | X=x, Y=y]\\ &= \P[X=x] \,\P[Y=y] \end{align*}\]
- en: as claimed. In particular, the collider cannot be reframed as a chain or fork
    as its underlying assumption is stronger.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 如所声称的。特别是，碰撞器不能被重新构造成链或分支，因为其基本假设更强。
- en: Perhaps counter-intuitively, conditioning on \(Z\) makes \(X\) and \(Y\) dependent
    in general. This is known as explaining away or Berkson’s Paradox.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 可能出人意料的是，对 \(Z\) 进行条件化通常会使 \(X\) 和 \(Y\) 依赖。这被称为解释消除或伯克森悖论。
- en: '6.3.3\. Example: Naive Bayes[#](#example-naive-bayes "Link to this heading")'
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3.3\. 示例：朴素贝叶斯[#](#example-naive-bayes "链接到这个标题")
- en: The model-based justification we gave for logistic regression in the subsection
    on generalized linear models used a so-called [discriminative approach](https://en.wikipedia.org/wiki/Discriminative_model)\(\idx{discriminative
    model}\xdi\), where the conditional distribution of the target \(y\) given the
    features \(\mathbf{x}\) is specified – but not the full distribution of the data
    \((\mathbf{x}, y)\). Here we give an example of the [generative approach](https://en.wikipedia.org/wiki/Generative_model)\(\idx{generative
    model}\xdi\), which models the full distribution. For a discussion of the benefits
    and drawbacks of each approach, see for example [here](https://en.wikipedia.org/wiki/Discriminative_model#Contrast_with_generative_model).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在广义线性模型的子节中为逻辑回归提供的基于模型的论证使用了所谓的[判别方法](https://en.wikipedia.org/wiki/Discriminative_model)\(\idx{判别模型}\xdi\)，其中指定了目标
    \(y\) 在特征 \(\mathbf{x}\) 给定下的条件分布——但不是数据的完整分布 \((\mathbf{x}, y)\)。这里我们给出了[生成方法](https://en.wikipedia.org/wiki/Generative_model)\(\idx{生成模型}\xdi\)的例子，它模型化了完整分布。关于每种方法的优缺点讨论，例如，请参阅[这里](https://en.wikipedia.org/wiki/Discriminative_model#Contrast_with_generative_model)。
- en: The Naive Bayes\(\idx{Naive Bayes}\xdi\) model is a simple discrete model for
    supervised learning. It is useful for document classification for instance, and
    we will use that terminology here to be concrete. We assume that a document has
    a single topic \(C\) from a list \(\mathcal{C} = \{1, \ldots, K\}\) with probability
    distribution \(\pi_k = \P[C = k]\). There is a vocabulary of size \(M\) and we
    record the presence or absence of a word \(m\) in the document with a Bernoulli
    variable \(X_m \in \{0,1\}\), where \(p_{k,m} = \P[X_m = 1|C = k]\). We denote
    by \(\bX = (X_1, \ldots, X_M)\) the corresponding vector.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 基于朴素贝叶斯\(\idx{朴素贝叶斯}\xdi\)模型是一个简单的监督学习离散模型。它在文档分类中很有用，例如，我们将使用这个术语来具体说明。我们假设一个文档有一个单一的主题
    \(C\)，来自列表 \(\mathcal{C} = \{1, \ldots, K\}\)，其概率分布为 \(\pi_k = \P[C = k]\)。存在一个大小为
    \(M\) 的词汇表，我们使用伯努利变量 \(X_m \in \{0,1\}\) 记录文档中单词 \(m\) 的存在或不存在，其中 \(p_{k,m} =
    \P[X_m = 1|C = k]\)。我们用 \(\bX = (X_1, \ldots, X_M)\) 表示相应的向量。
- en: 'The conditional independence assumption comes next: we assume that, given a
    topic \(C\), the word occurrences are independent. That is,'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是条件独立性假设：我们假设，给定一个主题 \(C\)，单词出现是独立的。也就是说，
- en: \[\begin{align*} \P[\bX = \bx|C=k] &= \prod_{m=1}^M \P[X_m = x_m|C = k]\\ &=
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[\bX = \bx|C=k] &= \prod_{m=1}^M \P[X_m = x_m|C = k]\\ &=
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
- en: Finally, the joint distribution is
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，联合分布是
- en: \[\begin{align*} \P[C = k, \bX = \bx] &= \P[\bX = \bx|C=k] \,\P[C=k]\\ &= \pi_k
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[C = k, \bX = \bx] &= \P[\bX = \bx|C=k] \,\P[C=k]\\ &= \pi_k
    \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}. \end{align*}\]
- en: Graphically, this is similar to a fork with \(C\) at its center and \(M\) prongs
    for the \(X_m\)s. This is represented using the so-called plate notation. The
    box with the \(M\) in the corner below indicates that \(X_m\) is repeated \(M\)
    times, all copies being conditionally independent given \(C\).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图形上，这类似于一个以 \(C\) 为中心、\(M\) 个叉状支的叉子。这使用所谓的板符号表示。下面角上的带有 \(M\) 的框表示 \(X_m\) 被重复
    \(M\) 次，所有副本在给定 \(C\) 的条件下都是条件独立的。
- en: '![Naives Bayes](../Images/1e486313a3d40a4fea7001344a53121b.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯](../Images/1e486313a3d40a4fea7001344a53121b.png)'
- en: '**Model fitting** Before using the model for prediction, one must first fit
    the model from training data \(\{\bx_i, c_i\}_{i=1}^n\). In this case, it means
    estimating the unknown parameters \(\bpi\) and \(\{\bp_k\}_{k=1}^K\), where \(\bp_k
    = (p_{k,1},\ldots, p_{k,M})\). For each \(k, m\) let'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型拟合** 在使用模型进行预测之前，必须首先从训练数据 \(\{\bx_i, c_i\}_{i=1}^n\) 中拟合模型。在这种情况下，这意味着估计未知参数
    \(\bpi\) 和 \(\{\bp_k\}_{k=1}^K\)，其中 \(\bp_k = (p_{k,1},\ldots, p_{k,M})\)。对于每个
    \(k, m\)，让'
- en: \[ N_{k,m} = \sum_{i=1}^n \mathbf{1}_{\{c_i = k\}} x_{i,m}, \quad N_{k} = \sum_{i=1}^n
    \mathbf{1}_{\{c_i = k\}}. \]
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: \[ N_{k,m} = \sum_{i=1}^n \mathbf{1}_{\{c_i = k\}} x_{i,m}, \quad N_{k} = \sum_{i=1}^n
    \mathbf{1}_{\{c_i = k\}}. \]
- en: We use maximum likelihood estimation which, recall, entails finding the parameters
    that maximize the probability of observing the data
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用最大似然估计，回想一下，这涉及到找到最大化观察数据概率的参数
- en: \[ \mathcal{L}(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = \prod_{i=1}^n \pi_{c_i} \prod_{m=1}^M
    p_{c_i, m}^{x_{i,m}} (1-p_{c_i, m})^{1-x_{i,m}}. \]
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mathcal{L}(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = \prod_{i=1}^n \pi_{c_i} \prod_{m=1}^M
    p_{c_i, m}^{x_{i,m}} (1-p_{c_i, m})^{1-x_{i,m}}. \]
- en: Here, as usual, we assume that the samples are independent and identically distributed.
    We take a logarithm to turn the products into sums and consider the negative log-likelihood
    (NLL)
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，像往常一样，我们假设样本是独立同分布的。我们取对数将乘积转换为和，并考虑负对数似然（NLL）
- en: \[\begin{align*} & L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\})\\ &\quad = - \sum_{i=1}^n
    \log \pi_{c_i} - \sum_{i=1}^n \sum_{m=1}^M [x_{i,m} \log p_{c_{i}, m} + (1-x_{i,m})
    \log (1-p_{c_i, m})]\\ &\quad = - \sum_{k=1}^K N_k \log \pi_k - \sum_{k=1}^K \sum_{m=1}^M
    [N_{k,m} \log p_{k,m} + (N_k-N_{k,m}) \log (1-p_{k,m})]. \end{align*}\]
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} & L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\})\\ &\quad = - \sum_{i=1}^n
    \log \pi_{c_i} - \sum_{i=1}^n \sum_{m=1}^M [x_{i,m} \log p_{c_{i}, m} + (1-x_{i,m})
    \log (1-p_{c_i, m})]\\ &\quad = - \sum_{k=1}^K N_k \log \pi_k - \sum_{k=1}^K \sum_{m=1}^M
    [N_{k,m} \log p_{k,m} + (N_k-N_{k,m}) \log (1-p_{k,m})]. \end{align*}\]
- en: The NLL can be broken up naturally into several terms that depend on different
    sets of parameters – and therefore can be optimized separately. First, there is
    a term that depends only on the \(\pi_k\)’s
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: NLL 可以自然地分解为几个依赖于不同参数集的项——因此可以分别优化。首先，有一个只依赖于 \(\pi_k\) 的项
- en: \[ J_0(\bpi; \{\bx_i, c_i\}) = - \sum_{k=1}^K N_k \log \pi_k. \]
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J_0(\bpi; \{\bx_i, c_i\}) = - \sum_{k=1}^K N_k \log \pi_k. \]
- en: The rest of the sum can be further split into \(KM\) terms, each depending only
    on \(p_{km}\) for a fixed \(k\) and m
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的和可以进一步分解为 \(KM\) 项，每项只依赖于固定 \(k\) 和 \(m\) 的 \(p_{km}\)
- en: \[ J_{k,m}(p_{k,m}; \{\bx_i, c_i\}) = - N_{k,m} \log p_{k,m} - (N_k-N_{k,m})
    \log (1-p_{k,m}). \]
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: \[ J_{k,m}(p_{k,m}; \{\bx_i, c_i\}) = - N_{k,m} \log p_{k,m} - (N_k-N_{k,m})
    \log (1-p_{k,m}). \]
- en: So
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 所以
- en: \[ L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = J_0(\bpi; \{\bx_i, c_i\}) + \sum_{k=1}^K
    \sum_{m=1}^M J_{k,m}(p_{k,m}; \{\bx_i, c_i\}). \]
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: \[ L_n(\bpi, \{\bp_k\}; \{\bx_i, c_i\}) = J_0(\bpi; \{\bx_i, c_i\}) + \sum_{k=1}^K
    \sum_{m=1}^M J_{k,m}(p_{k,m}; \{\bx_i, c_i\}). \]
- en: We minimize these terms separately. We assume that \(N_k > 0\) for all \(k\).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分别最小化这些项。我们假设对于所有 \(k\)，\(N_k > 0\)。
- en: 'We use a special case of maximum likelihood estimation, which we previously
    worked out in an example, where we consider the space of all probability distributions
    over a finite set. The maximum likelihood estimator in that case is given by the
    empirical frequencies. Notice that minimizing \(J_0(\bpi; \{\bx_i, c_i\})\) is
    precisely of this form: we observe \(N_k\) samples from class \(k\) and we seek
    the maximum likelihood estimator of, \(\pi_k\), the probability of observing \(k\).
    Hence the solution is simply'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用最大似然估计的特殊情况，我们之前在示例中已经解决了这个问题，其中我们考虑了有限集上所有概率分布的空间。在这种情况下，最大似然估计量由经验频率给出。请注意，最小化
    \(J_0(\bpi; \{\bx_i, c_i\})\) 正是这种形式：我们观察到来自类别 \(k\) 的 \(N_k\) 个样本，我们寻求 \(\pi_k\)
    的最大似然估计，即观察到 \(k\) 的概率。因此，解决方案很简单
- en: \[ \hat{\pi}_k = \frac{N_k}{N}, \]
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\pi}_k = \frac{N_k}{N}, \]
- en: for all \(k\). Similarly, for each \(k\), \(m\), \(J_{k,m}\) is of that form
    as well. Here the states correspond to word \(m\) being present or absent in a
    document of class \(k\), and we observe \(N_{k,m}\) documents of type \(k\) where
    the word \(m\) is present. So the solution is
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(k\)。同样，对于每个 \(k\)，\(m\)，\(J_{k,m}\) 也是这种形式。在这里，状态对应于类别 \(k\) 的文档中单词 \(m\)
    的存在或不存在，我们观察到 \(k\) 类型的 \(N_{k,m}\) 个文档，其中单词 \(m\) 存在。因此，解决方案是
- en: \[ \hat{p}_{k,m} = \frac{N_{k,m}}{N_k} \]
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{p}_{k,m} = \frac{N_{k,m}}{N_k} \]
- en: for all \(k, m\).
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 \(k, m\)。
- en: '**Prediction** To predict the class of a new document, it is natural to maximize
    over \(k\) the probability that \(\{C=k\}\) given \(\{\bX = \bx\}\). By Bayes’
    rule,'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测** 要预测新文档的类别，自然是在 \(k\) 上最大化给定 \(\{\bX = \bx\}\) 的 \(\{C=k\}\) 的概率。根据贝叶斯定理，'
- en: \[\begin{align*} \P[C=k | \bX = \bx] &= \frac{\P[C = k, \bX = \bx]}{\P[\bX =
    \bx]}\\ &= \frac{\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}} {\sum_{k'=1}^K
    \pi_{k'} \prod_{m=1}^M p_{k',m}^{x_m} (1-p_{k',m})^{1-x_m}}. \end{align*}\]
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} \P[C=k | \bX = \bx] &= \frac{\P[C = k, \bX = \bx]}{\P[\bX =
    \bx]}\\ &= \frac{\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}} {\sum_{k'=1}^K
    \pi_{k'} \prod_{m=1}^M p_{k',m}^{x_m} (1-p_{k',m})^{1-x_m}}. \end{align*}\]
- en: As the denominator does not in fact depend on \(k\), maximizing \(\P[C=k | \bX
    = \bx]\) boils down to maximizing the numerator \(\pi_k \prod_{m=1}^M p_{k,m}^{x_m}
    (1-p_{k,m})^{1-x_m}\), which is straighforward to compute. As we did previously,
    we take a negative logarithm – which has some numerical advantages – and we refer
    to it as the *score*
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分母实际上不依赖于 \(k\)，最大化 \(\P[C=k | \bX = \bx]\) 简化为最大化分子 \(\pi_k \prod_{m=1}^M
    p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\)，这是容易计算的。正如我们之前所做的那样，我们取负对数——这有一些数值优势——并将其称为
    *得分*
- en: \[\begin{align*} &- \log\left(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\right)\\
    &\qquad = -\log\pi_k - \sum_{m=1}^M [x_m \log p_{k,m} + (1-x_m) \log (1-p_{k,m})].
    \end{align*}\]
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} &- \log\left(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\right)\\
    &\qquad = -\log\pi_k - \sum_{m=1}^M [x_m \log p_{k,m} + (1-x_m) \log (1-p_{k,m})].
    \end{align*}\]
- en: More specifically, taking a negative logarithm turns out to be a good idea here
    because computing a product of probabilities can produce very small numbers that,
    when they fall beneath machine precision, are approximated by zero. This is called
    [underflow](https://en.wikipedia.org/wiki/Arithmetic_underflow)\(\idx{underflow}\xdi\).
    By taking a negative logarithm, these probabilities are transformed into positive
    numbers of reasonable magnitude and the product becomes of sum of these. Moreover,
    because this transformation is monotone, we can use the transformed values directly
    to compute the optimal score, which is our ultimate goal in the prediction step.
    Since the parameters are unknown, we use \(\hat{\pi}_k\) and \(\hat{p}_{k,m}\)
    in place of \(\pi_k\) and \(p_{k,m}\).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，取负对数在这里是一个好主意，因为计算概率的乘积可能会产生非常小的数字，当它们低于机器精度时，会被近似为零。这被称为[下溢](https://en.wikipedia.org/wiki/Arithmetic_underflow)\(\idx{underflow}\xdi\)。通过取负对数，这些概率被转换成合理大小的正数，而乘积变成了这些数的和。此外，因为这种转换是单调的，我们可以直接使用转换后的值来计算最优得分，这是我们预测步骤中的最终目标。由于参数是未知的，我们用
    \(\hat{\pi}_k\) 和 \(\hat{p}_{k,m}\) 来代替 \(\pi_k\) 和 \(p_{k,m}\)。
- en: '**CHAT & LEARN** Ask your favorite AI chatbot for more information on the issue
    of underflow, and its cousin overflow\(\idx{overflow}\xdi\), in particular in
    the context of multiypling probabilities. \(\ddagger\)'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 向您喜欢的AI聊天机器人询问有关下溢问题及其表亲溢出\(\idx{overflow}\xdi\)的信息，特别是在乘以概率的上下文中。\(\ddagger\)'
- en: While maximum likehood estimation has [desirable theoretical properties](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties),
    it does suffer from [overfitting](https://towardsdatascience.com/parameter-inference-maximum-aposteriori-estimate-49f3cd98267a).
    If for instance a particular word \(m\) does not occur in any training document,
    then the probability of observing a new document that happens to contain that
    word is estimated to be \(0\) for any class (i.e., \(\hat{p}_{k,m} = 0\) for all
    \(k\) so that \(\hat \pi_k \prod_{m=1}^M \hat{p}_{k,m}^{x_m} (1-\hat{p}_{k,m})^{1-x_m}
    = 0\) for all \(k\) ) and the maximization problem above is not well-defined.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然最大似然估计具有 [理想的理论特性](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Properties)，但它确实存在
    [过拟合](https://towardsdatascience.com/parameter-inference-maximum-aposteriori-estimate-49f3cd98267a)
    的问题。例如，如果某个特定的词 \(m\) 在任何训练文档中都没有出现，那么观察到包含该词的新文档的概率被估计为任何类别的 \(0\)（即，对于所有 \(k\)，\(\hat{p}_{k,m}
    = 0\)，因此 \(\hat \pi_k \prod_{m=1}^M \hat{p}_{k,m}^{x_m} (1-\hat{p}_{k,m})^{1-x_m}
    = 0\) 对于所有 \(k\)）并且上述最大化问题没有很好地定义。
- en: One approach to deal with this is [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)\(\idx{Laplace
    smoothing}\xdi\)
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这种问题的一种方法是 [拉普拉斯平滑](https://en.wikipedia.org/wiki/Additive_smoothing)\(\idx{Laplace
    smoothing}\xdi\)。
- en: \[ \bar{\pi}_k = \frac{N_k + \alpha}{N + K \alpha}, \quad \bar{p}_{k,m} = \frac{N_{k,m}
    + \beta}{N_k + 2 \beta} \]
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{\pi}_k = \frac{N_k + \alpha}{N + K \alpha}, \quad \bar{p}_{k,m} = \frac{N_{k,m}
    + \beta}{N_k + 2 \beta} \]
- en: where \(\alpha, \beta > 0\), which can be justified using a Bayesian or regularization
    perspective.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\alpha, \beta > 0\)，这可以通过贝叶斯或正则化视角来证明。
- en: We implement the Naive Bayes model with Laplace smoothing.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用拉普拉斯平滑实现朴素贝叶斯模型。
- en: We encode the data into a table, where the rows are the classes and the columns
    are the features. The entries are the corresponding \(N_{k,m}\)s. In addition
    we provide the vector \((N_k)_k\).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据编码到一个表格中，其中行是类别，列是特征。条目是对应的 \(N_{k,m}\) 值。此外，我们还提供了向量 \((N_k)_k\)。
- en: '[PRE10]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Using `N_k[:, np.newaxis]` reshapes the one-dimensional array `N_k` into a two-dimensional
    column vector. For example, if `N_k` has a shape of \((K,)\), then `N_k[:, np.newaxis]`
    changes its shape to \((K, 1)\). This allows the division in the expression
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `N_k[:, np.newaxis]` 将一维数组 `N_k` 转换为二维列向量。例如，如果 `N_k` 的形状为 \((K,)\)，那么 `N_k[:,
    np.newaxis]` 将其形状更改为 \((K, 1)\)。这允许在表达式中进行除法，确保 `N_km` 每行的每个元素都除以 `N_k` 中相应的值。
- en: '[PRE11]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: to work correctly with [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html),
    ensuring that each element in a row of `N_km` is divided by the corresponding
    value in `N_k`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确使用 [广播](https://numpy.org/doc/stable/user/basics.broadcasting.html)，确保 `N_km`
    每行的每个元素都除以 `N_k` 中相应的值。
- en: The next function computes the negative logarithm of \(\pi_k \prod_{m=1}^M p_{k,m}^{x_m}
    (1-p_{k,m})^{1-x_m}\), that is, the score of \(k\), and outputs a \(k\) achieving
    the minimum score.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数计算 \(\pi_k \prod_{m=1}^M p_{k,m}^{x_m} (1-p_{k,m})^{1-x_m}\) 的负对数，即 \(k\)
    的得分，并输出一个得分最低的 \(k\)。
- en: '[PRE12]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**NUMERICAL CORNER:** We use a simple example from [Stack Overflow](https://stackoverflow.com/questions/10059594/):'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值角**：我们使用 [Stack Overflow](https://stackoverflow.com/questions/10059594/)
    中的一个简单例子：'
- en: '**Example:** Let’s say we have data on 1000 pieces of fruit. They happen to
    be Banana, Orange or some Other Fruit. We know 3 characteristics about each fruit:
    whether it is long, whether it is sweet, and if its color is yellow[, as displayed
    in the table below].'
  id: totrans-374
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**示例**：假设我们有关于 1000 件水果的数据。它们可能是香蕉、橙子或其他某种水果。我们知道每件水果的 3 个特征：它是否是长形的，是否是甜的，以及它的颜色是否是黄色的[如下表所示]。'
- en: '| Fruit | Long | Sweet | Yellow | Total |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 水果 | 长形 | 甜 | 黄色 | 总计 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Banana | 400 | 350 | 450 | 500 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| 香蕉 | 400 | 350 | 450 | 500 |'
- en: '| Orange | 0 | 150 | 300 | 300 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| 橙子 | 0 | 150 | 300 | 300 |'
- en: '| Other | 100 | 150 | 50 | 200 |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | 100 | 150 | 50 | 200 |'
- en: '| Total | 500 | 650 | 800 | 1000 |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 500 | 650 | 800 | 1000 |'
- en: '[PRE13]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We run `nb_fit_table` on our simple dataset.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的简单数据集上运行 `nb_fit_table`。
- en: '[PRE14]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Continuing on with our previous example:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们之前的例子：
- en: Let’s say that we are given the properties of an unknown fruit, and asked to
    classify it. We are told that the fruit is Long, Sweet and Yellow. Is it a Banana?
    Is it an Orange? Or Is it some Other Fruit?
  id: totrans-388
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们被给出了一个未知水果的性质，并要求对其进行分类。我们被告知这个水果是长形的、甜的和黄色的。它是香蕉吗？它是橙子吗？还是它是其他某种水果？
- en: We run `nb_predict` on our dataset with the additional fruit from the quote
    above.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的数据集上运行 `nb_predict`，并添加了上面引用的额外水果。
- en: '[PRE18]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: \(\unlhd\)
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: \(\unlhd\)
- en: '**CHAT & LEARN** Laplace smoothing is a special case of a more general technique
    known as Bayesian parameter estimation. Ask your favorite AI chatbot to explain
    Bayesian parameter estimation and how it relates to maximum likelihood estimation
    and Laplace smoothing. \(\ddagger\)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**CHAT & LEARN** 拉普拉斯平滑是更一般技术（贝叶斯参数估计）的一种特殊情况。请你的AI聊天机器人解释贝叶斯参数估计以及它与最大似然估计和拉普拉斯平滑的关系。
    \(\ddagger\)'
- en: '***Self-assessment quiz*** *(with help from Claude, Gemini, and ChatGPT)*'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我评估测验*** *(由Claude, Gemini和ChatGPT协助)*'
- en: '**1** Which of the following statements is **not** true about conditional probabilities?'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '**1** 以下哪个关于条件概率的陈述是不正确的？'
- en: a) \(\mathbb{P}[A|B] = \frac{\mathbb{P}[A \cap B]}{\mathbb{P}[B]}\) for events
    \(A\) and \(B\) with \(\mathbb{P}[B] > 0\).
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\mathbb{P}[A|B] = \frac{\mathbb{P}[A \cap B]}{\mathbb{P}[B]}\) 对于事件 \(A\)
    和 \(B\)，其中 \(\mathbb{P}[B] > 0\).
- en: b) If \(A\) and \(B\) are independent, then \(\mathbb{P}[A|B] = \mathbb{P}[A]\).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: b) 如果 \(A\) 和 \(B\) 是独立的，那么 \(\mathbb{P}[A|B] = \mathbb{P}[A]\).
- en: c) Conditional probabilities can be used to express the multiplication rule
    and the law of total probability.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: c) 条件概率可以用来表达乘法规则和全概率定律。
- en: d) \(\mathbb{P}[A|B] = \mathbb{P}[B|A]\) for any events \(A\) and \(B\).
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\mathbb{P}[A|B] = \mathbb{P}[B|A]\) 对于任何事件 \(A\) 和 \(B\).
- en: '**2** Which of the following is the correct mathematical expression for the
    conditional independence of events \(A\) and \(B\) given event \(C\), denoted
    as \(A \perp\!\!\!\perp B \mid C\)?'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '**2** 以下哪个是事件 \(A\) 和 \(B\) 在事件 \(C\) 条件下的条件独立性（表示为 \(A \perp\!\!\!\perp B
    \mid C\)）的正确数学表达式？'
- en: a) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] + \mathbb{P}[B \mid
    C]\)
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] + \mathbb{P}[B \mid
    C]\)
- en: b) \(\mathbb{P}[A \cup B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(\mathbb{P}[A \cup B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
- en: c) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\)
- en: d) \(\mathbb{P}[A \mid B \cap C] = \mathbb{P}[A \mid C]\)
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(\mathbb{P}[A \mid B \cap C] = \mathbb{P}[A \mid C]\)
- en: '**3** In the fork configuration \(Y \leftarrow X \rightarrow Z\), which of
    the following conditional independence relations always holds?'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '**3** 在 \(Y \leftarrow X \rightarrow Z\) 的叉配置中，以下哪个条件独立性关系始终成立？'
- en: a) \(X \perp\!\!\!\perp Y \mid Z\)
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(X \perp\!\!\!\perp Y \mid Z\)
- en: b) \(Y \perp\!\!\!\perp Z \mid X\)
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(Y \perp\!\!\!\perp Z \mid X\)
- en: c) \(X \perp\!\!\!\perp Z \mid Y\)
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(X \perp\!\!\!\perp Z \mid Y\)
- en: d) \(Y \perp\!\!\!\perp Z\)
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(Y \perp\!\!\!\perp Z\)
- en: '**4** In the collider configuration \(X \rightarrow Z \leftarrow Y\), which
    of the following conditional independence relations always holds?'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '**4** 在 \(X \rightarrow Z \leftarrow Y\) 的碰撞配置中，以下哪个条件独立性关系始终成立？'
- en: a) \(X \perp\!\!\!\perp Y \mid Z\)
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: a) \(X \perp\!\!\!\perp Y \mid Z\)
- en: b) \(Y \perp\!\!\!\perp Z \mid X\)
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: b) \(Y \perp\!\!\!\perp Z \mid X\)
- en: c) \(X \perp\!\!\!\perp Z \mid Y\)
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: c) \(X \perp\!\!\!\perp Z \mid Y\)
- en: d) \(X \perp\!\!\!\perp Y\)
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: d) \(X \perp\!\!\!\perp Y\)
- en: '**5** Which of the following best describes the graphical representation of
    the Naive Bayes model for document classification?'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '**5** 以下哪个最好地描述了文档分类的朴素贝叶斯模型的图形表示？'
- en: a) A chain with the topic variable at the center and word variables as the links.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: a) 以主题变量为中心，以单词变量为链环的链。
- en: b) A collider with the topic variable at the center and word variables as the
    parents.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: b) 以主题变量为中心，以单词变量为父变量的碰撞。
- en: c) A fork with the topic variable at the center and word variables as the prongs.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: c) 以主题变量为中心，以单词变量为叉尖的叉。
- en: d) A complete graph with edges between all pairs of variables.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: d) 一个包含所有变量对边的完整图。
- en: 'Answer for 1: d. Justification: In general, \(\mathbb{P}[A|B] \neq \mathbb{P}[B|A]\).
    Bayes’ rule provides the correct relationship between these two conditional probabilities.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 答案1：d. 理由：一般来说，\(\mathbb{P}[A|B] \neq \mathbb{P}[B|A]\)。贝叶斯定理提供了这两个条件概率之间的正确关系。
- en: 'Answer for 2: c. Justification: The text states, “Then \(A\) and \(B\) are
    conditionally independent given \(C\), denoted \(A \perp\!\!\!\perp B \mid C\),
    if \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B \mid C]\).”'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 答案2：c. 理由：文本中提到，“然后 \(A\) 和 \(B\) 在给定 \(C\) 的条件下是条件独立的，表示为 \(A \perp\!\!\!\perp
    B \mid C\)，如果 \(\mathbb{P}[A \cap B \mid C] = \mathbb{P}[A \mid C] \mathbb{P}[B
    \mid C]\).”
- en: 'Answer for 3: b. Justification: The text states, “Removing the edge from \(Y\)
    to \(Z\) gives the following graph, known as a fork. We denote this configuration
    as \(Y \leftarrow X \rightarrow Z\). […] The corresponding conditional independence
    relation is \(Z \perp\!\!\!\perp Y \mid X\).”'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 答案3：b. 证明：文本中提到，“从 \(Y\) 到 \(Z\) 移除边得到以下图，称为叉子。我们用 \(Y \leftarrow X \rightarrow
    Z\) 表示这种配置。[...] 对应的条件独立性关系是 \(Z \perp\!\!\!\perp Y \mid X\)。”
- en: 'Answer for 4: d. Justification: The text states, “Removing the edge from \(X\)
    to \(Y\) gives the following graph, known as a collider. We denote this configuration
    as \(X \rightarrow Z \leftarrow Y\). […] This time we have \(X \perp\!\!\!\perp
    Y\).”'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 答案4：d. 证明：文本中提到，“从 \(X\) 到 \(Y\) 移除边得到以下图，称为碰撞图。我们用 \(X \rightarrow Z \leftarrow
    Y\) 表示这种配置。[...] 这次我们有 \(X \perp\!\!\!\perp Y\)。”
- en: 'Answer for 5: c. Justification: The text states, “Graphically, this is similar
    to a fork with \(C\) at its center and \(M\) prongs for the \(X_m\)s.”'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 答案5：c. 证明：文本中提到，“从图形上看，这与一个以 \(C\) 为中心，\(M\) 为 \(X_m\) 的叉子相似。”
